diff -r 30 src/network/Makefile
--- a/src/network/Makefile	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/Makefile	Tue May 18 15:02:47 2021 +0530
@@ -11,7 +11,7 @@
 endif
 
 # Define offload drivers.
-offload_dirs := toecore t4_tom bonding iw_cxgb4 chtcp chcr
+offload_dirs := toecore t4_tom bonding iw_cxgb4 chcr
 
 #Define nic and storage drivers.
 nic_dirs := cxgb4
@@ -21,16 +21,12 @@
 #Define crypto driver
 crypto_dirs := chcr
 
-#Define chtcp driver
-ch_tcp_dirs := chtcp
-
 # Define offload options.
 txzcopy = 1
 offload_udp = 0
 disable_ipv6_offload = 0
 disable_mafo = 0
 disable_crypto = 0
-disable_ch_tcp = 0
 
 # Honor the -s (silent) make option.
 verbose := $(if $(filter s,$(MAKEFLAGS)),,-v)
@@ -144,7 +140,7 @@
 # driver. The configuration is not required for targets that are not
 # defined in 'config_targets'.
 config_targets = nic vnic iwarp rdma_krping toe chbonding lld bypass \
-                   rpm install uninstall storage crypto ch_tcp $(KBUILD_EXTMOD)
+                   rpm install uninstall storage crypto $(KBUILD_EXTMOD)
 override config = 1
 
 ifeq ($(MAKECMDGOALS),clean)
@@ -152,7 +148,7 @@
 endif
 
 ifeq ($(filter-out install uninstall clean,  $(MAKECMDGOALS)),)
-  override MAKECMDGOALS = toe vnic chbonding iwarp storage crypto ch_tcp
+  override MAKECMDGOALS = toe vnic chbonding iwarp storage crypto
 else
   # Don't compile/install any storage drivers if using 'toe' target.
   ifeq ($(filter toe,$(MAKECMDGOALS)),toe)
@@ -306,12 +302,6 @@
   cxgb4 chcr)
 endif
 
-# Compile/install chtcp drivers.
-ifeq ($(filter ch_tcp,$(MAKECMDGOALS)),ch_tcp)
-  KBUILD_EXTMOD := $(KBUILD_EXTMOD) $(filter-out $(KBUILD_EXTMOD), \
-  cxgb4 chtcp)
-endif
-
 # The following section of this makefile will be ignored if the target has
 # been defined as not requiring configuration. eg: clean
 ifeq ($(config),1)
@@ -379,19 +369,12 @@
 endif
 
 ifeq ($(modsym),1)
-ifeq ($(shell $(grep) -c '^output-symdump[[:space:]]*:\?=[[:space:]]*\$$(KBUILD_EXTMOD)' \
-                $(KSRC)/scripts/Makefile.modpost),1)
-  modulesymfile := $(shell $(grep) '^output-symdump[[:space:]]*:\?=[[:space:]]*\$$(KBUILD_EXTMOD)' \
-                             $(KSRC)/scripts/Makefile.modpost)
-  kernelsymfile := $(shell $(grep) '^input-symdump[[:space:]]*:\?=[[:space:]]*Module' \
-                             $(KSRC)/scripts/Makefile.modpost)
-else
-ifeq ($(shell $(grep) -c '^modulesymfile[[:space:]]*:\?=' \
-                $(KSRC)/scripts/Makefile.modpost),1)
 # Fix for variation of Module.symvers naming (thanks 2.6.17!).
 # I need to know the file name of the module symver generated by the kernel
 # during an external module build (MODPOST). Also used for kernels that don't
 # automatically generate the module symver file during MODPOST (2.6.0-2.6.17?).
+ifeq ($(shell $(grep) -c '^modulesymfile[[:space:]]*:\?=' \
+                $(KSRC)/scripts/Makefile.modpost),1)
   modulesymfile := $(shell $(grep) '^modulesymfile[[:space:]]*:\?=' \
                              $(KSRC)/scripts/Makefile.modpost)
   kernelsymfile := $(shell $(grep) '^kernelsymfile[[:space:]]*:\?=' \
@@ -410,28 +393,18 @@
             is not making sense.)
   $(error ERROR cannot determine module symvers file)
 endif
-endif
 
 # Gnu make (3.80) bug #1516, $(eval ...) inside conditionals causes errors.
 # This is fixed in v3.81 and some v3.80 (RHEL4/5) but not on SLES10.
 # Workaround: include a separate makefile that does the eval.
-ifeq ($(shell echo '$(modulesymfile)' | $(grep) -c '^[[:alnum:]-]\+[[:space:]]*:\?=[[:space:]]*.\+'),1)
-  modulesymfile := $(subst output-symdump,modulesymfile,$(modulesymfile))
-  modulesymfile := $(subst KBUILD_EXTMOD,firstword $$(KBUILD_EXTMOD),$(modulesymfile))
-  $(shell echo '$$(eval $$(modulesymfile))' > eval.mak)
-  include eval.mak
-else ifeq ($(shell echo '$(modulesymfile)' | $(grep) -c '^[[:alnum:]_]\+[[:space:]]*:\?=[[:space:]]*.\+'),1)
+ifeq ($(shell echo '$(modulesymfile)' | $(grep) -c '^[[:alnum:]_]\+[[:space:]]*:\?=[[:space:]]*.\+'),1)
   $(shell echo '$$(eval $$(modulesymfile))' > eval.mak)
   include eval.mak
   #$(eval $(modulesymfile))
 else
   modulesymfile =
 endif
-ifeq ($(shell echo '$(kernelsymfile)' | $(grep) -c '^[[:alnum:]-]\+[[:space:]]*:\?=[[:space:]]*.\+'),1)
-  kernelsymfile := $(subst input-symdump,kernelsymfile,$(kernelsymfile))
-  $(shell echo '$$(eval $$(kernelsymfile))' > eval.mak)
-  include eval.mak
-else ifeq ($(shell echo '$(kernelsymfile)' | $(grep) -c '^[[:alnum:]_]\+[[:space:]]*:\?=[[:space:]]*.\+'),1)
+ifeq ($(shell echo '$(kernelsymfile)' | $(grep) -c '^[[:alnum:]_]\+[[:space:]]*:\?=[[:space:]]*.\+'),1)
   $(shell echo '$$(eval $$(kernelsymfile))' > eval.mak)
   include eval.mak
   #$(eval $(kernelsymfile))
@@ -719,12 +692,6 @@
   INSTALLDIRS := $(filter-out iw_cxgb4,$(INSTALLDIRS))
 endif
 
-# Don't compile/install chtcp driver if defined 'disable_ch_tcp=1'.
-ifeq ($(disable_ch_tcp),1)
-  KBUILD_EXTMOD     := $(filter-out $(ch_tcp_dirs),$(KBUILD_EXTMOD))
-  INSTALLDIRS := $(filter-out $(ch_tcp_dirs),$(INSTALLDIRS))
-endif
-
 # PR16634. Disable TXZCOPY for RHEL6.0 and RHEL6.1.
 ifeq ($(RHEL_MAJOR), 6)
   ifeq ($(RHEL_MINOR), $(filter $(RHEL_MINOR), 0 1))
@@ -1261,9 +1228,6 @@
 .PHONY: crypto
 crypto: default
 
-.PHONY: ch_tcp
-ch_tcp: default
-
 .PHONY: default
 default: prep subdirs post
 
@@ -1409,7 +1373,6 @@
 	 echo " lld               - Build cxgb4 driver with offload support.";\
 	 echo " iwarp             - Build iwarp and cxgb4 drivers with offload support.";\
 	 echo " chbonding         - Build toecore, cxgb4, t4_tom and bonding drivers.";\
-	 echo " ch_tcp            - Build chtcp and cxgb4 drivers with offload support.";\
 	 echo " bypass            - Build driver with bypass adapter support.";\
 	 echo " storage           - Only build the csiostor driver.";\
 	 echo " rpm               - Generates a binary RPM. Can be used";\
@@ -1435,7 +1398,6 @@
 	 echo "                     toecore and tom drivers.";\
 	 echo " disable_bonding   - Don't build the bonding driver.";\
 	 echo " disable_storage   - Don't build the storage driver.";\
-	 echo " disable_ch_tcp=1  - Don't build the chtcp driver.";\
 	 echo " disable_cudbg     - Disable cudbg crash debugging in driver.";\
 	 echo " po_fcoe=1         - Enable POFCOE support for cxgb4 driver";\
 	 echo " enable_dcb=1      - Enable DCBx support for cxgb4 driver";\
diff -r 30 src/network/bonding/BONDING_KDIRS/4.0.9/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/4.0.9/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/bonding/BONDING_KDIRS/4.0.9/bond_main.c	Tue May 18 15:02:47 2021 +0530
@@ -1732,6 +1732,8 @@
 		return -EINVAL;
 	}
 
+	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
+
 	bond_sysfs_slave_del(slave);
 
 	/* recompute stats just before removing the slave */
@@ -1743,8 +1745,6 @@
 	 */
 	netdev_rx_handler_unregister(slave_dev);
 
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
 	if (BOND_MODE(bond) == BOND_MODE_8023AD)
 		bond_3ad_unbind_slave(slave);
 
diff -r 30 src/network/bonding/BONDING_KDIRS/4.1.0/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/4.1.0/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/bonding/BONDING_KDIRS/4.1.0/bond_main.c	Tue May 18 15:02:47 2021 +0530
@@ -1767,6 +1767,8 @@
 		return -EINVAL;
 	}
 
+	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
+
 	bond_sysfs_slave_del(slave);
 
 	/* recompute stats just before removing the slave */
@@ -1778,8 +1780,6 @@
 	 */
 	netdev_rx_handler_unregister(slave_dev);
 
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
 	if (BOND_MODE(bond) == BOND_MODE_8023AD)
 		bond_3ad_unbind_slave(slave);
 
diff -r 30 src/network/bonding/BONDING_KDIRS/4.14.0/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/4.14.0/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/bonding/BONDING_KDIRS/4.14.0/bond_main.c	Tue May 18 15:02:47 2021 +0530
@@ -1886,6 +1886,8 @@
 		return -EINVAL;
 	}
 
+	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
+
 	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
 
 	bond_sysfs_slave_del(slave);
@@ -1899,8 +1901,6 @@
 	 */
 	netdev_rx_handler_unregister(slave_dev);
 
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
 	if (BOND_MODE(bond) == BOND_MODE_8023AD)
 		bond_3ad_unbind_slave(slave);
 
diff -r 30 src/network/bonding/BONDING_KDIRS/4.14.77/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/4.14.77/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/bonding/BONDING_KDIRS/4.14.77/bond_main.c	Tue May 18 15:02:47 2021 +0530
@@ -1873,6 +1873,8 @@
 		return -EINVAL;
 	}
 
+	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
+
 	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
 
 	bond_sysfs_slave_del(slave);
@@ -1886,8 +1888,6 @@
 	 */
 	netdev_rx_handler_unregister(slave_dev);
 
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
 	if (BOND_MODE(bond) == BOND_MODE_8023AD)
 		bond_3ad_unbind_slave(slave);
 
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.0/bond_3ad.c
--- a/src/network/bonding/BONDING_KDIRS/4.19.0/bond_3ad.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/bonding/BONDING_KDIRS/4.19.0/bond_3ad.c	Tue May 18 15:02:47 2021 +0530
@@ -28,6 +28,7 @@
 #include <linux/etherdevice.h>
 #include <linux/if_bonding.h>
 #include <linux/pkt_sched.h>
+#include <linux/toedev.h>
 #include <net/net_namespace.h>
 #include <net/bonding.h>
 #include <net/bond_3ad.h>
@@ -209,8 +210,11 @@
 {
 	struct slave *slave = port->slave;
 
-	if ((slave->link == BOND_LINK_UP) && bond_slave_is_up(slave))
+	if ((slave->link == BOND_LINK_UP) && bond_slave_is_up(slave)) {
 		bond_set_slave_active_flags(slave, BOND_SLAVE_NOTIFY_LATER);
+		toe_failover(netdev_master_upper_dev_get_rcu(port->slave->dev),
+			     port->slave->dev, TOE_LINK_UP, NULL);
+	}
 }
 
 /**
@@ -2520,6 +2524,8 @@
 		/* link has failed */
 		port->is_enabled = false;
 		ad_update_actor_keys(port, true);
+		toe_failover(netdev_master_upper_dev_get(slave->dev),
+			     slave->dev, TOE_LINK_DOWN, NULL);
 	}
 	agg = __get_first_agg(port);
 	ad_agg_selection_logic(agg, &dummy);
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.0/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/4.19.0/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/bonding/BONDING_KDIRS/4.19.0/bond_main.c	Tue May 18 15:02:47 2021 +0530
@@ -1892,6 +1892,8 @@
 		return -EINVAL;
 	}
 
+	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
+
 	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
 
 	bond_sysfs_slave_del(slave);
@@ -1905,8 +1907,6 @@
 	 */
 	netdev_rx_handler_unregister(slave_dev);
 
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
 	if (BOND_MODE(bond) == BOND_MODE_8023AD)
 		bond_3ad_unbind_slave(slave);
 
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.103/bond_3ad.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.103/bond_3ad.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,2686 @@
+/*
+ * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the Free
+ * Software Foundation; either version 2 of the License, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc., 59
+ * Temple Place - Suite 330, Boston, MA  02111-1307, USA.
+ *
+ * The full GNU General Public License is included in this distribution in the
+ * file called LICENSE.
+ *
+ */
+
+#include <linux/skbuff.h>
+#include <linux/if_ether.h>
+#include <linux/netdevice.h>
+#include <linux/spinlock.h>
+#include <linux/ethtool.h>
+#include <linux/etherdevice.h>
+#include <linux/if_bonding.h>
+#include <linux/pkt_sched.h>
+#include <linux/toedev.h>
+#include <net/net_namespace.h>
+#include <net/bonding.h>
+#include <net/bond_3ad.h>
+
+/* General definitions */
+#define AD_SHORT_TIMEOUT           1
+#define AD_LONG_TIMEOUT            0
+#define AD_STANDBY                 0x2
+#define AD_MAX_TX_IN_SECOND        3
+#define AD_COLLECTOR_MAX_DELAY     0
+
+/* Timer definitions (43.4.4 in the 802.3ad standard) */
+#define AD_FAST_PERIODIC_TIME      1
+#define AD_SLOW_PERIODIC_TIME      30
+#define AD_SHORT_TIMEOUT_TIME      (3*AD_FAST_PERIODIC_TIME)
+#define AD_LONG_TIMEOUT_TIME       (3*AD_SLOW_PERIODIC_TIME)
+#define AD_CHURN_DETECTION_TIME    60
+#define AD_AGGREGATE_WAIT_TIME     2
+
+/* Port state definitions (43.4.2.2 in the 802.3ad standard) */
+#define AD_STATE_LACP_ACTIVITY   0x1
+#define AD_STATE_LACP_TIMEOUT    0x2
+#define AD_STATE_AGGREGATION     0x4
+#define AD_STATE_SYNCHRONIZATION 0x8
+#define AD_STATE_COLLECTING      0x10
+#define AD_STATE_DISTRIBUTING    0x20
+#define AD_STATE_DEFAULTED       0x40
+#define AD_STATE_EXPIRED         0x80
+
+/* Port Variables definitions used by the State Machines (43.4.7 in the
+ * 802.3ad standard)
+ */
+#define AD_PORT_BEGIN           0x1
+#define AD_PORT_LACP_ENABLED    0x2
+#define AD_PORT_ACTOR_CHURN     0x4
+#define AD_PORT_PARTNER_CHURN   0x8
+#define AD_PORT_READY           0x10
+#define AD_PORT_READY_N         0x20
+#define AD_PORT_MATCHED         0x40
+#define AD_PORT_STANDBY         0x80
+#define AD_PORT_SELECTED        0x100
+#define AD_PORT_MOVED           0x200
+#define AD_PORT_CHURNED         (AD_PORT_ACTOR_CHURN | AD_PORT_PARTNER_CHURN)
+
+/* Port Key definitions
+ * key is determined according to the link speed, duplex and
+ * user key (which is yet not supported)
+ *           --------------------------------------------------------------
+ * Port key  | User key (10 bits)           | Speed (5 bits)      | Duplex|
+ *           --------------------------------------------------------------
+ *           |15                           6|5                   1|0
+ */
+#define  AD_DUPLEX_KEY_MASKS    0x1
+#define  AD_SPEED_KEY_MASKS     0x3E
+#define  AD_USER_KEY_MASKS      0xFFC0
+
+enum ad_link_speed_type {
+	AD_LINK_SPEED_1MBPS = 1,
+	AD_LINK_SPEED_10MBPS,
+	AD_LINK_SPEED_100MBPS,
+	AD_LINK_SPEED_1000MBPS,
+	AD_LINK_SPEED_2500MBPS,
+	AD_LINK_SPEED_5000MBPS,
+	AD_LINK_SPEED_10000MBPS,
+	AD_LINK_SPEED_14000MBPS,
+	AD_LINK_SPEED_20000MBPS,
+	AD_LINK_SPEED_25000MBPS,
+	AD_LINK_SPEED_40000MBPS,
+	AD_LINK_SPEED_50000MBPS,
+	AD_LINK_SPEED_56000MBPS,
+	AD_LINK_SPEED_100000MBPS,
+};
+
+/* compare MAC addresses */
+#define MAC_ADDRESS_EQUAL(A, B)	\
+	ether_addr_equal_64bits((const u8 *)A, (const u8 *)B)
+
+static const u8 null_mac_addr[ETH_ALEN + 2] __long_aligned = {
+	0, 0, 0, 0, 0, 0
+};
+static u16 ad_ticks_per_sec;
+static const int ad_delta_in_ticks = (AD_TIMER_INTERVAL * HZ) / 1000;
+
+static const u8 lacpdu_mcast_addr[ETH_ALEN + 2] __long_aligned =
+	MULTICAST_LACPDU_ADDR;
+
+/* ================= main 802.3ad protocol functions ================== */
+static int ad_lacpdu_send(struct port *port);
+static int ad_marker_send(struct port *port, struct bond_marker *marker);
+static void ad_mux_machine(struct port *port, bool *update_slave_arr);
+static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port);
+static void ad_tx_machine(struct port *port);
+static void ad_periodic_machine(struct port *port);
+static void ad_port_selection_logic(struct port *port, bool *update_slave_arr);
+static void ad_agg_selection_logic(struct aggregator *aggregator,
+				   bool *update_slave_arr);
+static void ad_clear_agg(struct aggregator *aggregator);
+static void ad_initialize_agg(struct aggregator *aggregator);
+static void ad_initialize_port(struct port *port, int lacp_fast);
+static void ad_enable_collecting_distributing(struct port *port,
+					      bool *update_slave_arr);
+static void ad_disable_collecting_distributing(struct port *port,
+					       bool *update_slave_arr);
+static void ad_marker_info_received(struct bond_marker *marker_info,
+				    struct port *port);
+static void ad_marker_response_received(struct bond_marker *marker,
+					struct port *port);
+static void ad_update_actor_keys(struct port *port, bool reset);
+
+
+/* ================= api to bonding and kernel code ================== */
+
+/**
+ * __get_bond_by_port - get the port's bonding struct
+ * @port: the port we're looking at
+ *
+ * Return @port's bonding struct, or %NULL if it can't be found.
+ */
+static inline struct bonding *__get_bond_by_port(struct port *port)
+{
+	if (port->slave == NULL)
+		return NULL;
+
+	return bond_get_bond_by_slave(port->slave);
+}
+
+/**
+ * __get_first_agg - get the first aggregator in the bond
+ * @bond: the bond we're looking at
+ *
+ * Return the aggregator of the first slave in @bond, or %NULL if it can't be
+ * found.
+ * The caller must hold RCU or RTNL lock.
+ */
+static inline struct aggregator *__get_first_agg(struct port *port)
+{
+	struct bonding *bond = __get_bond_by_port(port);
+	struct slave *first_slave;
+	struct aggregator *agg;
+
+	/* If there's no bond for this port, or bond has no slaves */
+	if (bond == NULL)
+		return NULL;
+
+	rcu_read_lock();
+	first_slave = bond_first_slave_rcu(bond);
+	agg = first_slave ? &(SLAVE_AD_INFO(first_slave)->aggregator) : NULL;
+	rcu_read_unlock();
+
+	return agg;
+}
+
+/**
+ * __agg_has_partner - see if we have a partner
+ * @agg: the agregator we're looking at
+ *
+ * Return nonzero if aggregator has a partner (denoted by a non-zero ether
+ * address for the partner). Return 0 if not.
+ */
+static inline int __agg_has_partner(struct aggregator *agg)
+{
+	return !is_zero_ether_addr(agg->partner_system.mac_addr_value);
+}
+
+/**
+ * __disable_port - disable the port's slave
+ * @port: the port we're looking at
+ */
+static inline void __disable_port(struct port *port)
+{
+	bond_set_slave_inactive_flags(port->slave, BOND_SLAVE_NOTIFY_LATER);
+}
+
+/**
+ * __enable_port - enable the port's slave, if it's up
+ * @port: the port we're looking at
+ */
+static inline void __enable_port(struct port *port)
+{
+	struct slave *slave = port->slave;
+
+	if ((slave->link == BOND_LINK_UP) && bond_slave_is_up(slave)) {
+		bond_set_slave_active_flags(slave, BOND_SLAVE_NOTIFY_LATER);
+		toe_failover(netdev_master_upper_dev_get_rcu(port->slave->dev),
+			     port->slave->dev, TOE_LINK_UP, NULL);
+	}
+}
+
+/**
+ * __port_is_enabled - check if the port's slave is in active state
+ * @port: the port we're looking at
+ */
+static inline int __port_is_enabled(struct port *port)
+{
+	return bond_is_active_slave(port->slave);
+}
+
+/**
+ * __get_agg_selection_mode - get the aggregator selection mode
+ * @port: the port we're looking at
+ *
+ * Get the aggregator selection mode. Can be %STABLE, %BANDWIDTH or %COUNT.
+ */
+static inline u32 __get_agg_selection_mode(struct port *port)
+{
+	struct bonding *bond = __get_bond_by_port(port);
+
+	if (bond == NULL)
+		return BOND_AD_STABLE;
+
+	return bond->params.ad_select;
+}
+
+/**
+ * __check_agg_selection_timer - check if the selection timer has expired
+ * @port: the port we're looking at
+ */
+static inline int __check_agg_selection_timer(struct port *port)
+{
+	struct bonding *bond = __get_bond_by_port(port);
+
+	if (bond == NULL)
+		return 0;
+
+	return BOND_AD_INFO(bond).agg_select_timer ? 1 : 0;
+}
+
+/**
+ * __get_link_speed - get a port's speed
+ * @port: the port we're looking at
+ *
+ * Return @port's speed in 802.3ad enum format. i.e. one of:
+ *     0,
+ *     %AD_LINK_SPEED_10MBPS,
+ *     %AD_LINK_SPEED_100MBPS,
+ *     %AD_LINK_SPEED_1000MBPS,
+ *     %AD_LINK_SPEED_2500MBPS,
+ *     %AD_LINK_SPEED_5000MBPS,
+ *     %AD_LINK_SPEED_10000MBPS
+ *     %AD_LINK_SPEED_14000MBPS,
+ *     %AD_LINK_SPEED_20000MBPS
+ *     %AD_LINK_SPEED_25000MBPS
+ *     %AD_LINK_SPEED_40000MBPS
+ *     %AD_LINK_SPEED_50000MBPS
+ *     %AD_LINK_SPEED_56000MBPS
+ *     %AD_LINK_SPEED_100000MBPS
+ */
+static u16 __get_link_speed(struct port *port)
+{
+	struct slave *slave = port->slave;
+	u16 speed;
+
+	/* this if covers only a special case: when the configuration starts
+	 * with link down, it sets the speed to 0.
+	 * This is done in spite of the fact that the e100 driver reports 0
+	 * to be compatible with MVT in the future.
+	 */
+	if (slave->link != BOND_LINK_UP)
+		speed = 0;
+	else {
+		switch (slave->speed) {
+		case SPEED_10:
+			speed = AD_LINK_SPEED_10MBPS;
+			break;
+
+		case SPEED_100:
+			speed = AD_LINK_SPEED_100MBPS;
+			break;
+
+		case SPEED_1000:
+			speed = AD_LINK_SPEED_1000MBPS;
+			break;
+
+		case SPEED_2500:
+			speed = AD_LINK_SPEED_2500MBPS;
+			break;
+
+		case SPEED_5000:
+			speed = AD_LINK_SPEED_5000MBPS;
+			break;
+
+		case SPEED_10000:
+			speed = AD_LINK_SPEED_10000MBPS;
+			break;
+
+		case SPEED_14000:
+			speed = AD_LINK_SPEED_14000MBPS;
+			break;
+
+		case SPEED_20000:
+			speed = AD_LINK_SPEED_20000MBPS;
+			break;
+
+		case SPEED_25000:
+			speed = AD_LINK_SPEED_25000MBPS;
+			break;
+
+		case SPEED_40000:
+			speed = AD_LINK_SPEED_40000MBPS;
+			break;
+
+		case SPEED_50000:
+			speed = AD_LINK_SPEED_50000MBPS;
+			break;
+
+		case SPEED_56000:
+			speed = AD_LINK_SPEED_56000MBPS;
+			break;
+
+		case SPEED_100000:
+			speed = AD_LINK_SPEED_100000MBPS;
+			break;
+
+		default:
+			/* unknown speed value from ethtool. shouldn't happen */
+			if (slave->speed != SPEED_UNKNOWN)
+				pr_warn_once("%s: unknown ethtool speed (%d) for port %d (set it to 0)\n",
+					     slave->bond->dev->name,
+					     slave->speed,
+					     port->actor_port_number);
+			speed = 0;
+			break;
+		}
+	}
+
+	netdev_dbg(slave->bond->dev, "Port %d Received link speed %d update from adapter\n",
+		   port->actor_port_number, speed);
+	return speed;
+}
+
+/**
+ * __get_duplex - get a port's duplex
+ * @port: the port we're looking at
+ *
+ * Return @port's duplex in 802.3ad bitmask format. i.e.:
+ *     0x01 if in full duplex
+ *     0x00 otherwise
+ */
+static u8 __get_duplex(struct port *port)
+{
+	struct slave *slave = port->slave;
+	u8 retval = 0x0;
+
+	/* handling a special case: when the configuration starts with
+	 * link down, it sets the duplex to 0.
+	 */
+	if (slave->link == BOND_LINK_UP) {
+		switch (slave->duplex) {
+		case DUPLEX_FULL:
+			retval = 0x1;
+			netdev_dbg(slave->bond->dev, "Port %d Received status full duplex update from adapter\n",
+				   port->actor_port_number);
+			break;
+		case DUPLEX_HALF:
+		default:
+			retval = 0x0;
+			netdev_dbg(slave->bond->dev, "Port %d Received status NOT full duplex update from adapter\n",
+				   port->actor_port_number);
+			break;
+		}
+	}
+	return retval;
+}
+
+static void __ad_actor_update_port(struct port *port)
+{
+	const struct bonding *bond = bond_get_bond_by_slave(port->slave);
+
+	port->actor_system = BOND_AD_INFO(bond).system.sys_mac_addr;
+	port->actor_system_priority = BOND_AD_INFO(bond).system.sys_priority;
+}
+
+/* Conversions */
+
+/**
+ * __ad_timer_to_ticks - convert a given timer type to AD module ticks
+ * @timer_type:	which timer to operate
+ * @par: timer parameter. see below
+ *
+ * If @timer_type is %current_while_timer, @par indicates long/short timer.
+ * If @timer_type is %periodic_timer, @par is one of %FAST_PERIODIC_TIME,
+ *						     %SLOW_PERIODIC_TIME.
+ */
+static u16 __ad_timer_to_ticks(u16 timer_type, u16 par)
+{
+	u16 retval = 0; /* to silence the compiler */
+
+	switch (timer_type) {
+	case AD_CURRENT_WHILE_TIMER:	/* for rx machine usage */
+		if (par)
+			retval = (AD_SHORT_TIMEOUT_TIME*ad_ticks_per_sec);
+		else
+			retval = (AD_LONG_TIMEOUT_TIME*ad_ticks_per_sec);
+		break;
+	case AD_ACTOR_CHURN_TIMER:	/* for local churn machine */
+		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
+		break;
+	case AD_PERIODIC_TIMER:		/* for periodic machine */
+		retval = (par*ad_ticks_per_sec); /* long timeout */
+		break;
+	case AD_PARTNER_CHURN_TIMER:	/* for remote churn machine */
+		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
+		break;
+	case AD_WAIT_WHILE_TIMER:	/* for selection machine */
+		retval = (AD_AGGREGATE_WAIT_TIME*ad_ticks_per_sec);
+		break;
+	}
+
+	return retval;
+}
+
+
+/* ================= ad_rx_machine helper functions ================== */
+
+/**
+ * __choose_matched - update a port's matched variable from a received lacpdu
+ * @lacpdu: the lacpdu we've received
+ * @port: the port we're looking at
+ *
+ * Update the value of the matched variable, using parameter values from a
+ * newly received lacpdu. Parameter values for the partner carried in the
+ * received PDU are compared with the corresponding operational parameter
+ * values for the actor. Matched is set to TRUE if all of these parameters
+ * match and the PDU parameter partner_state.aggregation has the same value as
+ * actor_oper_port_state.aggregation and lacp will actively maintain the link
+ * in the aggregation. Matched is also set to TRUE if the value of
+ * actor_state.aggregation in the received PDU is set to FALSE, i.e., indicates
+ * an individual link and lacp will actively maintain the link. Otherwise,
+ * matched is set to FALSE. LACP is considered to be actively maintaining the
+ * link if either the PDU's actor_state.lacp_activity variable is TRUE or both
+ * the actor's actor_oper_port_state.lacp_activity and the PDU's
+ * partner_state.lacp_activity variables are TRUE.
+ *
+ * Note: the AD_PORT_MATCHED "variable" is not specified by 802.3ad; it is
+ * used here to implement the language from 802.3ad 43.4.9 that requires
+ * recordPDU to "match" the LACPDU parameters to the stored values.
+ */
+static void __choose_matched(struct lacpdu *lacpdu, struct port *port)
+{
+	/* check if all parameters are alike
+	 * or this is individual link(aggregation == FALSE)
+	 * then update the state machine Matched variable.
+	 */
+	if (((ntohs(lacpdu->partner_port) == port->actor_port_number) &&
+	     (ntohs(lacpdu->partner_port_priority) == port->actor_port_priority) &&
+	     MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) &&
+	     (ntohs(lacpdu->partner_system_priority) == port->actor_system_priority) &&
+	     (ntohs(lacpdu->partner_key) == port->actor_oper_port_key) &&
+	     ((lacpdu->partner_state & AD_STATE_AGGREGATION) == (port->actor_oper_port_state & AD_STATE_AGGREGATION))) ||
+	    ((lacpdu->actor_state & AD_STATE_AGGREGATION) == 0)
+		) {
+		port->sm_vars |= AD_PORT_MATCHED;
+	} else {
+		port->sm_vars &= ~AD_PORT_MATCHED;
+	}
+}
+
+/**
+ * __record_pdu - record parameters from a received lacpdu
+ * @lacpdu: the lacpdu we've received
+ * @port: the port we're looking at
+ *
+ * Record the parameter values for the Actor carried in a received lacpdu as
+ * the current partner operational parameter values and sets
+ * actor_oper_port_state.defaulted to FALSE.
+ */
+static void __record_pdu(struct lacpdu *lacpdu, struct port *port)
+{
+	if (lacpdu && port) {
+		struct port_params *partner = &port->partner_oper;
+
+		__choose_matched(lacpdu, port);
+		/* record the new parameter values for the partner
+		 * operational
+		 */
+		partner->port_number = ntohs(lacpdu->actor_port);
+		partner->port_priority = ntohs(lacpdu->actor_port_priority);
+		partner->system = lacpdu->actor_system;
+		partner->system_priority = ntohs(lacpdu->actor_system_priority);
+		partner->key = ntohs(lacpdu->actor_key);
+		partner->port_state = lacpdu->actor_state;
+
+		/* set actor_oper_port_state.defaulted to FALSE */
+		port->actor_oper_port_state &= ~AD_STATE_DEFAULTED;
+
+		/* set the partner sync. to on if the partner is sync,
+		 * and the port is matched
+		 */
+		if ((port->sm_vars & AD_PORT_MATCHED) &&
+		    (lacpdu->actor_state & AD_STATE_SYNCHRONIZATION)) {
+			partner->port_state |= AD_STATE_SYNCHRONIZATION;
+			pr_debug("%s partner sync=1\n", port->slave->dev->name);
+		} else {
+			partner->port_state &= ~AD_STATE_SYNCHRONIZATION;
+			pr_debug("%s partner sync=0\n", port->slave->dev->name);
+		}
+	}
+}
+
+/**
+ * __record_default - record default parameters
+ * @port: the port we're looking at
+ *
+ * This function records the default parameter values for the partner carried
+ * in the Partner Admin parameters as the current partner operational parameter
+ * values and sets actor_oper_port_state.defaulted to TRUE.
+ */
+static void __record_default(struct port *port)
+{
+	if (port) {
+		/* record the partner admin parameters */
+		memcpy(&port->partner_oper, &port->partner_admin,
+		       sizeof(struct port_params));
+
+		/* set actor_oper_port_state.defaulted to true */
+		port->actor_oper_port_state |= AD_STATE_DEFAULTED;
+	}
+}
+
+/**
+ * __update_selected - update a port's Selected variable from a received lacpdu
+ * @lacpdu: the lacpdu we've received
+ * @port: the port we're looking at
+ *
+ * Update the value of the selected variable, using parameter values from a
+ * newly received lacpdu. The parameter values for the Actor carried in the
+ * received PDU are compared with the corresponding operational parameter
+ * values for the ports partner. If one or more of the comparisons shows that
+ * the value(s) received in the PDU differ from the current operational values,
+ * then selected is set to FALSE and actor_oper_port_state.synchronization is
+ * set to out_of_sync. Otherwise, selected remains unchanged.
+ */
+static void __update_selected(struct lacpdu *lacpdu, struct port *port)
+{
+	if (lacpdu && port) {
+		const struct port_params *partner = &port->partner_oper;
+
+		/* check if any parameter is different then
+		 * update the state machine selected variable.
+		 */
+		if (ntohs(lacpdu->actor_port) != partner->port_number ||
+		    ntohs(lacpdu->actor_port_priority) != partner->port_priority ||
+		    !MAC_ADDRESS_EQUAL(&lacpdu->actor_system, &partner->system) ||
+		    ntohs(lacpdu->actor_system_priority) != partner->system_priority ||
+		    ntohs(lacpdu->actor_key) != partner->key ||
+		    (lacpdu->actor_state & AD_STATE_AGGREGATION) != (partner->port_state & AD_STATE_AGGREGATION)) {
+			port->sm_vars &= ~AD_PORT_SELECTED;
+		}
+	}
+}
+
+/**
+ * __update_default_selected - update a port's Selected variable from Partner
+ * @port: the port we're looking at
+ *
+ * This function updates the value of the selected variable, using the partner
+ * administrative parameter values. The administrative values are compared with
+ * the corresponding operational parameter values for the partner. If one or
+ * more of the comparisons shows that the administrative value(s) differ from
+ * the current operational values, then Selected is set to FALSE and
+ * actor_oper_port_state.synchronization is set to OUT_OF_SYNC. Otherwise,
+ * Selected remains unchanged.
+ */
+static void __update_default_selected(struct port *port)
+{
+	if (port) {
+		const struct port_params *admin = &port->partner_admin;
+		const struct port_params *oper = &port->partner_oper;
+
+		/* check if any parameter is different then
+		 * update the state machine selected variable.
+		 */
+		if (admin->port_number != oper->port_number ||
+		    admin->port_priority != oper->port_priority ||
+		    !MAC_ADDRESS_EQUAL(&admin->system, &oper->system) ||
+		    admin->system_priority != oper->system_priority ||
+		    admin->key != oper->key ||
+		    (admin->port_state & AD_STATE_AGGREGATION)
+			!= (oper->port_state & AD_STATE_AGGREGATION)) {
+			port->sm_vars &= ~AD_PORT_SELECTED;
+		}
+	}
+}
+
+/**
+ * __update_ntt - update a port's ntt variable from a received lacpdu
+ * @lacpdu: the lacpdu we've received
+ * @port: the port we're looking at
+ *
+ * Updates the value of the ntt variable, using parameter values from a newly
+ * received lacpdu. The parameter values for the partner carried in the
+ * received PDU are compared with the corresponding operational parameter
+ * values for the Actor. If one or more of the comparisons shows that the
+ * value(s) received in the PDU differ from the current operational values,
+ * then ntt is set to TRUE. Otherwise, ntt remains unchanged.
+ */
+static void __update_ntt(struct lacpdu *lacpdu, struct port *port)
+{
+	/* validate lacpdu and port */
+	if (lacpdu && port) {
+		/* check if any parameter is different then
+		 * update the port->ntt.
+		 */
+		if ((ntohs(lacpdu->partner_port) != port->actor_port_number) ||
+		    (ntohs(lacpdu->partner_port_priority) != port->actor_port_priority) ||
+		    !MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) ||
+		    (ntohs(lacpdu->partner_system_priority) != port->actor_system_priority) ||
+		    (ntohs(lacpdu->partner_key) != port->actor_oper_port_key) ||
+		    ((lacpdu->partner_state & AD_STATE_LACP_ACTIVITY) != (port->actor_oper_port_state & AD_STATE_LACP_ACTIVITY)) ||
+		    ((lacpdu->partner_state & AD_STATE_LACP_TIMEOUT) != (port->actor_oper_port_state & AD_STATE_LACP_TIMEOUT)) ||
+		    ((lacpdu->partner_state & AD_STATE_SYNCHRONIZATION) != (port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION)) ||
+		    ((lacpdu->partner_state & AD_STATE_AGGREGATION) != (port->actor_oper_port_state & AD_STATE_AGGREGATION))
+		   ) {
+			port->ntt = true;
+		}
+	}
+}
+
+/**
+ * __agg_ports_are_ready - check if all ports in an aggregator are ready
+ * @aggregator: the aggregator we're looking at
+ *
+ */
+static int __agg_ports_are_ready(struct aggregator *aggregator)
+{
+	struct port *port;
+	int retval = 1;
+
+	if (aggregator) {
+		/* scan all ports in this aggregator to verfy if they are
+		 * all ready.
+		 */
+		for (port = aggregator->lag_ports;
+		     port;
+		     port = port->next_port_in_aggregator) {
+			if (!(port->sm_vars & AD_PORT_READY_N)) {
+				retval = 0;
+				break;
+			}
+		}
+	}
+
+	return retval;
+}
+
+/**
+ * __set_agg_ports_ready - set value of Ready bit in all ports of an aggregator
+ * @aggregator: the aggregator we're looking at
+ * @val: Should the ports' ready bit be set on or off
+ *
+ */
+static void __set_agg_ports_ready(struct aggregator *aggregator, int val)
+{
+	struct port *port;
+
+	for (port = aggregator->lag_ports; port;
+	     port = port->next_port_in_aggregator) {
+		if (val)
+			port->sm_vars |= AD_PORT_READY;
+		else
+			port->sm_vars &= ~AD_PORT_READY;
+	}
+}
+
+static int __agg_active_ports(struct aggregator *agg)
+{
+	struct port *port;
+	int active = 0;
+
+	for (port = agg->lag_ports; port;
+	     port = port->next_port_in_aggregator) {
+		if (port->is_enabled)
+			active++;
+	}
+
+	return active;
+}
+
+/**
+ * __get_agg_bandwidth - get the total bandwidth of an aggregator
+ * @aggregator: the aggregator we're looking at
+ *
+ */
+static u32 __get_agg_bandwidth(struct aggregator *aggregator)
+{
+	int nports = __agg_active_ports(aggregator);
+	u32 bandwidth = 0;
+
+	if (nports) {
+		switch (__get_link_speed(aggregator->lag_ports)) {
+		case AD_LINK_SPEED_1MBPS:
+			bandwidth = nports;
+			break;
+		case AD_LINK_SPEED_10MBPS:
+			bandwidth = nports * 10;
+			break;
+		case AD_LINK_SPEED_100MBPS:
+			bandwidth = nports * 100;
+			break;
+		case AD_LINK_SPEED_1000MBPS:
+			bandwidth = nports * 1000;
+			break;
+		case AD_LINK_SPEED_2500MBPS:
+			bandwidth = nports * 2500;
+			break;
+		case AD_LINK_SPEED_5000MBPS:
+			bandwidth = nports * 5000;
+			break;
+		case AD_LINK_SPEED_10000MBPS:
+			bandwidth = nports * 10000;
+			break;
+		case AD_LINK_SPEED_14000MBPS:
+			bandwidth = nports * 14000;
+			break;
+		case AD_LINK_SPEED_20000MBPS:
+			bandwidth = nports * 20000;
+			break;
+		case AD_LINK_SPEED_25000MBPS:
+			bandwidth = nports * 25000;
+			break;
+		case AD_LINK_SPEED_40000MBPS:
+			bandwidth = nports * 40000;
+			break;
+		case AD_LINK_SPEED_50000MBPS:
+			bandwidth = nports * 50000;
+			break;
+		case AD_LINK_SPEED_56000MBPS:
+			bandwidth = nports * 56000;
+			break;
+		case AD_LINK_SPEED_100000MBPS:
+			bandwidth = nports * 100000;
+			break;
+		default:
+			bandwidth = 0; /* to silence the compiler */
+		}
+	}
+	return bandwidth;
+}
+
+/**
+ * __get_active_agg - get the current active aggregator
+ * @aggregator: the aggregator we're looking at
+ *
+ * Caller must hold RCU lock.
+ */
+static struct aggregator *__get_active_agg(struct aggregator *aggregator)
+{
+	struct bonding *bond = aggregator->slave->bond;
+	struct list_head *iter;
+	struct slave *slave;
+
+	bond_for_each_slave_rcu(bond, slave, iter)
+		if (SLAVE_AD_INFO(slave)->aggregator.is_active)
+			return &(SLAVE_AD_INFO(slave)->aggregator);
+
+	return NULL;
+}
+
+/**
+ * __update_lacpdu_from_port - update a port's lacpdu fields
+ * @port: the port we're looking at
+ */
+static inline void __update_lacpdu_from_port(struct port *port)
+{
+	struct lacpdu *lacpdu = &port->lacpdu;
+	const struct port_params *partner = &port->partner_oper;
+
+	/* update current actual Actor parameters
+	 * lacpdu->subtype                   initialized
+	 * lacpdu->version_number            initialized
+	 * lacpdu->tlv_type_actor_info       initialized
+	 * lacpdu->actor_information_length  initialized
+	 */
+
+	lacpdu->actor_system_priority = htons(port->actor_system_priority);
+	lacpdu->actor_system = port->actor_system;
+	lacpdu->actor_key = htons(port->actor_oper_port_key);
+	lacpdu->actor_port_priority = htons(port->actor_port_priority);
+	lacpdu->actor_port = htons(port->actor_port_number);
+	lacpdu->actor_state = port->actor_oper_port_state;
+	pr_debug("update lacpdu: %s, actor port state %x\n",
+		 port->slave->dev->name, port->actor_oper_port_state);
+
+	/* lacpdu->reserved_3_1              initialized
+	 * lacpdu->tlv_type_partner_info     initialized
+	 * lacpdu->partner_information_length initialized
+	 */
+
+	lacpdu->partner_system_priority = htons(partner->system_priority);
+	lacpdu->partner_system = partner->system;
+	lacpdu->partner_key = htons(partner->key);
+	lacpdu->partner_port_priority = htons(partner->port_priority);
+	lacpdu->partner_port = htons(partner->port_number);
+	lacpdu->partner_state = partner->port_state;
+
+	/* lacpdu->reserved_3_2              initialized
+	 * lacpdu->tlv_type_collector_info   initialized
+	 * lacpdu->collector_information_length initialized
+	 * collector_max_delay                initialized
+	 * reserved_12[12]                   initialized
+	 * tlv_type_terminator               initialized
+	 * terminator_length                 initialized
+	 * reserved_50[50]                   initialized
+	 */
+}
+
+/* ================= main 802.3ad protocol code ========================= */
+
+/**
+ * ad_lacpdu_send - send out a lacpdu packet on a given port
+ * @port: the port we're looking at
+ *
+ * Returns:   0 on success
+ *          < 0 on error
+ */
+static int ad_lacpdu_send(struct port *port)
+{
+	struct slave *slave = port->slave;
+	struct sk_buff *skb;
+	struct lacpdu_header *lacpdu_header;
+	int length = sizeof(struct lacpdu_header);
+
+	skb = dev_alloc_skb(length);
+	if (!skb)
+		return -ENOMEM;
+
+	skb->dev = slave->dev;
+	skb_reset_mac_header(skb);
+	skb->network_header = skb->mac_header + ETH_HLEN;
+	skb->protocol = PKT_TYPE_LACPDU;
+	skb->priority = TC_PRIO_CONTROL;
+
+	lacpdu_header = skb_put(skb, length);
+
+	ether_addr_copy(lacpdu_header->hdr.h_dest, lacpdu_mcast_addr);
+	/* Note: source address is set to be the member's PERMANENT address,
+	 * because we use it to identify loopback lacpdus in receive.
+	 */
+	ether_addr_copy(lacpdu_header->hdr.h_source, slave->perm_hwaddr);
+	lacpdu_header->hdr.h_proto = PKT_TYPE_LACPDU;
+
+	lacpdu_header->lacpdu = port->lacpdu;
+
+	dev_queue_xmit(skb);
+
+	return 0;
+}
+
+/**
+ * ad_marker_send - send marker information/response on a given port
+ * @port: the port we're looking at
+ * @marker: marker data to send
+ *
+ * Returns:   0 on success
+ *          < 0 on error
+ */
+static int ad_marker_send(struct port *port, struct bond_marker *marker)
+{
+	struct slave *slave = port->slave;
+	struct sk_buff *skb;
+	struct bond_marker_header *marker_header;
+	int length = sizeof(struct bond_marker_header);
+
+	skb = dev_alloc_skb(length + 16);
+	if (!skb)
+		return -ENOMEM;
+
+	skb_reserve(skb, 16);
+
+	skb->dev = slave->dev;
+	skb_reset_mac_header(skb);
+	skb->network_header = skb->mac_header + ETH_HLEN;
+	skb->protocol = PKT_TYPE_LACPDU;
+
+	marker_header = skb_put(skb, length);
+
+	ether_addr_copy(marker_header->hdr.h_dest, lacpdu_mcast_addr);
+	/* Note: source address is set to be the member's PERMANENT address,
+	 * because we use it to identify loopback MARKERs in receive.
+	 */
+	ether_addr_copy(marker_header->hdr.h_source, slave->perm_hwaddr);
+	marker_header->hdr.h_proto = PKT_TYPE_LACPDU;
+
+	marker_header->marker = *marker;
+
+	dev_queue_xmit(skb);
+
+	return 0;
+}
+
+/**
+ * ad_mux_machine - handle a port's mux state machine
+ * @port: the port we're looking at
+ * @update_slave_arr: Does slave array need update?
+ */
+static void ad_mux_machine(struct port *port, bool *update_slave_arr)
+{
+	mux_states_t last_state;
+
+	/* keep current State Machine state to compare later if it was
+	 * changed
+	 */
+	last_state = port->sm_mux_state;
+
+	if (port->sm_vars & AD_PORT_BEGIN) {
+		port->sm_mux_state = AD_MUX_DETACHED;
+	} else {
+		switch (port->sm_mux_state) {
+		case AD_MUX_DETACHED:
+			if ((port->sm_vars & AD_PORT_SELECTED)
+			    || (port->sm_vars & AD_PORT_STANDBY))
+				/* if SELECTED or STANDBY */
+				port->sm_mux_state = AD_MUX_WAITING;
+			break;
+		case AD_MUX_WAITING:
+			/* if SELECTED == FALSE return to DETACH state */
+			if (!(port->sm_vars & AD_PORT_SELECTED)) {
+				port->sm_vars &= ~AD_PORT_READY_N;
+				/* in order to withhold the Selection Logic to
+				 * check all ports READY_N value every callback
+				 * cycle to update ready variable, we check
+				 * READY_N and update READY here
+				 */
+				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
+				port->sm_mux_state = AD_MUX_DETACHED;
+				break;
+			}
+
+			/* check if the wait_while_timer expired */
+			if (port->sm_mux_timer_counter
+			    && !(--port->sm_mux_timer_counter))
+				port->sm_vars |= AD_PORT_READY_N;
+
+			/* in order to withhold the selection logic to check
+			 * all ports READY_N value every callback cycle to
+			 * update ready variable, we check READY_N and update
+			 * READY here
+			 */
+			__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
+
+			/* if the wait_while_timer expired, and the port is
+			 * in READY state, move to ATTACHED state
+			 */
+			if ((port->sm_vars & AD_PORT_READY)
+			    && !port->sm_mux_timer_counter)
+				port->sm_mux_state = AD_MUX_ATTACHED;
+			break;
+		case AD_MUX_ATTACHED:
+			/* check also if agg_select_timer expired (so the
+			 * edable port will take place only after this timer)
+			 */
+			if ((port->sm_vars & AD_PORT_SELECTED) &&
+			    (port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) &&
+			    !__check_agg_selection_timer(port)) {
+				if (port->aggregator->is_active)
+					port->sm_mux_state =
+					    AD_MUX_COLLECTING_DISTRIBUTING;
+			} else if (!(port->sm_vars & AD_PORT_SELECTED) ||
+				   (port->sm_vars & AD_PORT_STANDBY)) {
+				/* if UNSELECTED or STANDBY */
+				port->sm_vars &= ~AD_PORT_READY_N;
+				/* in order to withhold the selection logic to
+				 * check all ports READY_N value every callback
+				 * cycle to update ready variable, we check
+				 * READY_N and update READY here
+				 */
+				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
+				port->sm_mux_state = AD_MUX_DETACHED;
+			} else if (port->aggregator->is_active) {
+				port->actor_oper_port_state |=
+				    AD_STATE_SYNCHRONIZATION;
+			}
+			break;
+		case AD_MUX_COLLECTING_DISTRIBUTING:
+			if (!(port->sm_vars & AD_PORT_SELECTED) ||
+			    (port->sm_vars & AD_PORT_STANDBY) ||
+			    !(port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) ||
+			    !(port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION)) {
+				port->sm_mux_state = AD_MUX_ATTACHED;
+			} else {
+				/* if port state hasn't changed make
+				 * sure that a collecting distributing
+				 * port in an active aggregator is enabled
+				 */
+				if (port->aggregator &&
+				    port->aggregator->is_active &&
+				    !__port_is_enabled(port)) {
+
+					__enable_port(port);
+				}
+			}
+			break;
+		default:
+			break;
+		}
+	}
+
+	/* check if the state machine was changed */
+	if (port->sm_mux_state != last_state) {
+		pr_debug("Mux Machine: Port=%d (%s), Last State=%d, Curr State=%d\n",
+			 port->actor_port_number,
+			 port->slave->dev->name,
+			 last_state,
+			 port->sm_mux_state);
+		switch (port->sm_mux_state) {
+		case AD_MUX_DETACHED:
+			port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
+			ad_disable_collecting_distributing(port,
+							   update_slave_arr);
+			port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
+			port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
+			port->ntt = true;
+			break;
+		case AD_MUX_WAITING:
+			port->sm_mux_timer_counter = __ad_timer_to_ticks(AD_WAIT_WHILE_TIMER, 0);
+			break;
+		case AD_MUX_ATTACHED:
+			if (port->aggregator->is_active)
+				port->actor_oper_port_state |=
+				    AD_STATE_SYNCHRONIZATION;
+			else
+				port->actor_oper_port_state &=
+				    ~AD_STATE_SYNCHRONIZATION;
+			port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
+			port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
+			ad_disable_collecting_distributing(port,
+							   update_slave_arr);
+			port->ntt = true;
+			break;
+		case AD_MUX_COLLECTING_DISTRIBUTING:
+			port->actor_oper_port_state |= AD_STATE_COLLECTING;
+			port->actor_oper_port_state |= AD_STATE_DISTRIBUTING;
+			port->actor_oper_port_state |= AD_STATE_SYNCHRONIZATION;
+			ad_enable_collecting_distributing(port,
+							  update_slave_arr);
+			port->ntt = true;
+			break;
+		default:
+			break;
+		}
+	}
+}
+
+/**
+ * ad_rx_machine - handle a port's rx State Machine
+ * @lacpdu: the lacpdu we've received
+ * @port: the port we're looking at
+ *
+ * If lacpdu arrived, stop previous timer (if exists) and set the next state as
+ * CURRENT. If timer expired set the state machine in the proper state.
+ * In other cases, this function checks if we need to switch to other state.
+ */
+static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port)
+{
+	rx_states_t last_state;
+
+	/* keep current State Machine state to compare later if it was
+	 * changed
+	 */
+	last_state = port->sm_rx_state;
+
+	/* check if state machine should change state */
+
+	/* first, check if port was reinitialized */
+	if (port->sm_vars & AD_PORT_BEGIN) {
+		port->sm_rx_state = AD_RX_INITIALIZE;
+		port->sm_vars |= AD_PORT_CHURNED;
+	/* check if port is not enabled */
+	} else if (!(port->sm_vars & AD_PORT_BEGIN) && !port->is_enabled)
+		port->sm_rx_state = AD_RX_PORT_DISABLED;
+	/* check if new lacpdu arrived */
+	else if (lacpdu && ((port->sm_rx_state == AD_RX_EXPIRED) ||
+		 (port->sm_rx_state == AD_RX_DEFAULTED) ||
+		 (port->sm_rx_state == AD_RX_CURRENT))) {
+		if (port->sm_rx_state != AD_RX_CURRENT)
+			port->sm_vars |= AD_PORT_CHURNED;
+		port->sm_rx_timer_counter = 0;
+		port->sm_rx_state = AD_RX_CURRENT;
+	} else {
+		/* if timer is on, and if it is expired */
+		if (port->sm_rx_timer_counter &&
+		    !(--port->sm_rx_timer_counter)) {
+			switch (port->sm_rx_state) {
+			case AD_RX_EXPIRED:
+				port->sm_rx_state = AD_RX_DEFAULTED;
+				break;
+			case AD_RX_CURRENT:
+				port->sm_rx_state = AD_RX_EXPIRED;
+				break;
+			default:
+				break;
+			}
+		} else {
+			/* if no lacpdu arrived and no timer is on */
+			switch (port->sm_rx_state) {
+			case AD_RX_PORT_DISABLED:
+				if (port->is_enabled &&
+				    (port->sm_vars & AD_PORT_LACP_ENABLED))
+					port->sm_rx_state = AD_RX_EXPIRED;
+				else if (port->is_enabled
+					 && ((port->sm_vars
+					      & AD_PORT_LACP_ENABLED) == 0))
+					port->sm_rx_state = AD_RX_LACP_DISABLED;
+				break;
+			default:
+				break;
+
+			}
+		}
+	}
+
+	/* check if the State machine was changed or new lacpdu arrived */
+	if ((port->sm_rx_state != last_state) || (lacpdu)) {
+		pr_debug("Rx Machine: Port=%d (%s), Last State=%d, Curr State=%d\n",
+			 port->actor_port_number,
+			 port->slave->dev->name,
+			 last_state,
+			 port->sm_rx_state);
+		switch (port->sm_rx_state) {
+		case AD_RX_INITIALIZE:
+			if (!(port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS))
+				port->sm_vars &= ~AD_PORT_LACP_ENABLED;
+			else
+				port->sm_vars |= AD_PORT_LACP_ENABLED;
+			port->sm_vars &= ~AD_PORT_SELECTED;
+			__record_default(port);
+			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
+			port->sm_rx_state = AD_RX_PORT_DISABLED;
+
+			/* Fall Through */
+		case AD_RX_PORT_DISABLED:
+			port->sm_vars &= ~AD_PORT_MATCHED;
+			break;
+		case AD_RX_LACP_DISABLED:
+			port->sm_vars &= ~AD_PORT_SELECTED;
+			__record_default(port);
+			port->partner_oper.port_state &= ~AD_STATE_AGGREGATION;
+			port->sm_vars |= AD_PORT_MATCHED;
+			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
+			break;
+		case AD_RX_EXPIRED:
+			/* Reset of the Synchronization flag (Standard 43.4.12)
+			 * This reset cause to disable this port in the
+			 * COLLECTING_DISTRIBUTING state of the mux machine in
+			 * case of EXPIRED even if LINK_DOWN didn't arrive for
+			 * the port.
+			 */
+			port->partner_oper.port_state &= ~AD_STATE_SYNCHRONIZATION;
+			port->sm_vars &= ~AD_PORT_MATCHED;
+			port->partner_oper.port_state |= AD_STATE_LACP_TIMEOUT;
+			port->partner_oper.port_state |= AD_STATE_LACP_ACTIVITY;
+			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(AD_SHORT_TIMEOUT));
+			port->actor_oper_port_state |= AD_STATE_EXPIRED;
+			port->sm_vars |= AD_PORT_CHURNED;
+			break;
+		case AD_RX_DEFAULTED:
+			__update_default_selected(port);
+			__record_default(port);
+			port->sm_vars |= AD_PORT_MATCHED;
+			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
+			break;
+		case AD_RX_CURRENT:
+			/* detect loopback situation */
+			if (MAC_ADDRESS_EQUAL(&(lacpdu->actor_system),
+					      &(port->actor_system))) {
+				netdev_err(port->slave->bond->dev, "An illegal loopback occurred on adapter (%s)\n"
+				       "Check the configuration to verify that all adapters are connected to 802.3ad compliant switch ports\n",
+				       port->slave->dev->name);
+				return;
+			}
+			__update_selected(lacpdu, port);
+			__update_ntt(lacpdu, port);
+			__record_pdu(lacpdu, port);
+			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(port->actor_oper_port_state & AD_STATE_LACP_TIMEOUT));
+			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
+			break;
+		default:
+			break;
+		}
+	}
+}
+
+/**
+ * ad_churn_machine - handle port churn's state machine
+ * @port: the port we're looking at
+ *
+ */
+static void ad_churn_machine(struct port *port)
+{
+	if (port->sm_vars & AD_PORT_CHURNED) {
+		port->sm_vars &= ~AD_PORT_CHURNED;
+		port->sm_churn_actor_state = AD_CHURN_MONITOR;
+		port->sm_churn_partner_state = AD_CHURN_MONITOR;
+		port->sm_churn_actor_timer_counter =
+			__ad_timer_to_ticks(AD_ACTOR_CHURN_TIMER, 0);
+		 port->sm_churn_partner_timer_counter =
+			 __ad_timer_to_ticks(AD_PARTNER_CHURN_TIMER, 0);
+		return;
+	}
+	if (port->sm_churn_actor_timer_counter &&
+	    !(--port->sm_churn_actor_timer_counter) &&
+	    port->sm_churn_actor_state == AD_CHURN_MONITOR) {
+		if (port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION) {
+			port->sm_churn_actor_state = AD_NO_CHURN;
+		} else {
+			port->churn_actor_count++;
+			port->sm_churn_actor_state = AD_CHURN;
+		}
+	}
+	if (port->sm_churn_partner_timer_counter &&
+	    !(--port->sm_churn_partner_timer_counter) &&
+	    port->sm_churn_partner_state == AD_CHURN_MONITOR) {
+		if (port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) {
+			port->sm_churn_partner_state = AD_NO_CHURN;
+		} else {
+			port->churn_partner_count++;
+			port->sm_churn_partner_state = AD_CHURN;
+		}
+	}
+}
+
+/**
+ * ad_tx_machine - handle a port's tx state machine
+ * @port: the port we're looking at
+ */
+static void ad_tx_machine(struct port *port)
+{
+	/* check if tx timer expired, to verify that we do not send more than
+	 * 3 packets per second
+	 */
+	if (port->sm_tx_timer_counter && !(--port->sm_tx_timer_counter)) {
+		/* check if there is something to send */
+		if (port->ntt && (port->sm_vars & AD_PORT_LACP_ENABLED)) {
+			__update_lacpdu_from_port(port);
+
+			if (ad_lacpdu_send(port) >= 0) {
+				pr_debug("Sent LACPDU on port %d\n",
+					 port->actor_port_number);
+
+				/* mark ntt as false, so it will not be sent
+				 * again until demanded
+				 */
+				port->ntt = false;
+			}
+		}
+		/* restart tx timer(to verify that we will not exceed
+		 * AD_MAX_TX_IN_SECOND
+		 */
+		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
+	}
+}
+
+/**
+ * ad_periodic_machine - handle a port's periodic state machine
+ * @port: the port we're looking at
+ *
+ * Turn ntt flag on priodically to perform periodic transmission of lacpdu's.
+ */
+static void ad_periodic_machine(struct port *port)
+{
+	periodic_states_t last_state;
+
+	/* keep current state machine state to compare later if it was changed */
+	last_state = port->sm_periodic_state;
+
+	/* check if port was reinitialized */
+	if (((port->sm_vars & AD_PORT_BEGIN) || !(port->sm_vars & AD_PORT_LACP_ENABLED) || !port->is_enabled) ||
+	    (!(port->actor_oper_port_state & AD_STATE_LACP_ACTIVITY) && !(port->partner_oper.port_state & AD_STATE_LACP_ACTIVITY))
+	   ) {
+		port->sm_periodic_state = AD_NO_PERIODIC;
+	}
+	/* check if state machine should change state */
+	else if (port->sm_periodic_timer_counter) {
+		/* check if periodic state machine expired */
+		if (!(--port->sm_periodic_timer_counter)) {
+			/* if expired then do tx */
+			port->sm_periodic_state = AD_PERIODIC_TX;
+		} else {
+			/* If not expired, check if there is some new timeout
+			 * parameter from the partner state
+			 */
+			switch (port->sm_periodic_state) {
+			case AD_FAST_PERIODIC:
+				if (!(port->partner_oper.port_state
+				      & AD_STATE_LACP_TIMEOUT))
+					port->sm_periodic_state = AD_SLOW_PERIODIC;
+				break;
+			case AD_SLOW_PERIODIC:
+				if ((port->partner_oper.port_state & AD_STATE_LACP_TIMEOUT)) {
+					port->sm_periodic_timer_counter = 0;
+					port->sm_periodic_state = AD_PERIODIC_TX;
+				}
+				break;
+			default:
+				break;
+			}
+		}
+	} else {
+		switch (port->sm_periodic_state) {
+		case AD_NO_PERIODIC:
+			port->sm_periodic_state = AD_FAST_PERIODIC;
+			break;
+		case AD_PERIODIC_TX:
+			if (!(port->partner_oper.port_state &
+			    AD_STATE_LACP_TIMEOUT))
+				port->sm_periodic_state = AD_SLOW_PERIODIC;
+			else
+				port->sm_periodic_state = AD_FAST_PERIODIC;
+			break;
+		default:
+			break;
+		}
+	}
+
+	/* check if the state machine was changed */
+	if (port->sm_periodic_state != last_state) {
+		pr_debug("Periodic Machine: Port=%d, Last State=%d, Curr State=%d\n",
+			 port->actor_port_number, last_state,
+			 port->sm_periodic_state);
+		switch (port->sm_periodic_state) {
+		case AD_NO_PERIODIC:
+			port->sm_periodic_timer_counter = 0;
+			break;
+		case AD_FAST_PERIODIC:
+			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
+			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_FAST_PERIODIC_TIME))-1;
+			break;
+		case AD_SLOW_PERIODIC:
+			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
+			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_SLOW_PERIODIC_TIME))-1;
+			break;
+		case AD_PERIODIC_TX:
+			port->ntt = true;
+			break;
+		default:
+			break;
+		}
+	}
+}
+
+/**
+ * ad_port_selection_logic - select aggregation groups
+ * @port: the port we're looking at
+ * @update_slave_arr: Does slave array need update?
+ *
+ * Select aggregation groups, and assign each port for it's aggregetor. The
+ * selection logic is called in the inititalization (after all the handshkes),
+ * and after every lacpdu receive (if selected is off).
+ */
+static void ad_port_selection_logic(struct port *port, bool *update_slave_arr)
+{
+	struct aggregator *aggregator, *free_aggregator = NULL, *temp_aggregator;
+	struct port *last_port = NULL, *curr_port;
+	struct list_head *iter;
+	struct bonding *bond;
+	struct slave *slave;
+	int found = 0;
+
+	/* if the port is already Selected, do nothing */
+	if (port->sm_vars & AD_PORT_SELECTED)
+		return;
+
+	bond = __get_bond_by_port(port);
+
+	/* if the port is connected to other aggregator, detach it */
+	if (port->aggregator) {
+		/* detach the port from its former aggregator */
+		temp_aggregator = port->aggregator;
+		for (curr_port = temp_aggregator->lag_ports; curr_port;
+		     last_port = curr_port,
+		     curr_port = curr_port->next_port_in_aggregator) {
+			if (curr_port == port) {
+				temp_aggregator->num_of_ports--;
+				/* if it is the first port attached to the
+				 * aggregator
+				 */
+				if (!last_port) {
+					temp_aggregator->lag_ports =
+						port->next_port_in_aggregator;
+				} else {
+					/* not the first port attached to the
+					 * aggregator
+					 */
+					last_port->next_port_in_aggregator =
+						port->next_port_in_aggregator;
+				}
+
+				/* clear the port's relations to this
+				 * aggregator
+				 */
+				port->aggregator = NULL;
+				port->next_port_in_aggregator = NULL;
+				port->actor_port_aggregator_identifier = 0;
+
+				netdev_dbg(bond->dev, "Port %d left LAG %d\n",
+					   port->actor_port_number,
+					   temp_aggregator->aggregator_identifier);
+				/* if the aggregator is empty, clear its
+				 * parameters, and set it ready to be attached
+				 */
+				if (!temp_aggregator->lag_ports)
+					ad_clear_agg(temp_aggregator);
+				break;
+			}
+		}
+		if (!curr_port) {
+			/* meaning: the port was related to an aggregator
+			 * but was not on the aggregator port list
+			 */
+			net_warn_ratelimited("%s: Warning: Port %d (on %s) was related to aggregator %d but was not on its port list\n",
+					     port->slave->bond->dev->name,
+					     port->actor_port_number,
+					     port->slave->dev->name,
+					     port->aggregator->aggregator_identifier);
+		}
+	}
+	/* search on all aggregators for a suitable aggregator for this port */
+	bond_for_each_slave(bond, slave, iter) {
+		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
+
+		/* keep a free aggregator for later use(if needed) */
+		if (!aggregator->lag_ports) {
+			if (!free_aggregator)
+				free_aggregator = aggregator;
+			continue;
+		}
+		/* check if current aggregator suits us */
+		if (((aggregator->actor_oper_aggregator_key == port->actor_oper_port_key) && /* if all parameters match AND */
+		     MAC_ADDRESS_EQUAL(&(aggregator->partner_system), &(port->partner_oper.system)) &&
+		     (aggregator->partner_system_priority == port->partner_oper.system_priority) &&
+		     (aggregator->partner_oper_aggregator_key == port->partner_oper.key)
+		    ) &&
+		    ((!MAC_ADDRESS_EQUAL(&(port->partner_oper.system), &(null_mac_addr)) && /* partner answers */
+		      !aggregator->is_individual)  /* but is not individual OR */
+		    )
+		   ) {
+			/* attach to the founded aggregator */
+			port->aggregator = aggregator;
+			port->actor_port_aggregator_identifier =
+				port->aggregator->aggregator_identifier;
+			port->next_port_in_aggregator = aggregator->lag_ports;
+			port->aggregator->num_of_ports++;
+			aggregator->lag_ports = port;
+			netdev_dbg(bond->dev, "Port %d joined LAG %d(existing LAG)\n",
+				   port->actor_port_number,
+				   port->aggregator->aggregator_identifier);
+
+			/* mark this port as selected */
+			port->sm_vars |= AD_PORT_SELECTED;
+			found = 1;
+			break;
+		}
+	}
+
+	/* the port couldn't find an aggregator - attach it to a new
+	 * aggregator
+	 */
+	if (!found) {
+		if (free_aggregator) {
+			/* assign port a new aggregator */
+			port->aggregator = free_aggregator;
+			port->actor_port_aggregator_identifier =
+				port->aggregator->aggregator_identifier;
+
+			/* update the new aggregator's parameters
+			 * if port was responsed from the end-user
+			 */
+			if (port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS)
+				/* if port is full duplex */
+				port->aggregator->is_individual = false;
+			else
+				port->aggregator->is_individual = true;
+
+			port->aggregator->actor_admin_aggregator_key =
+				port->actor_admin_port_key;
+			port->aggregator->actor_oper_aggregator_key =
+				port->actor_oper_port_key;
+			port->aggregator->partner_system =
+				port->partner_oper.system;
+			port->aggregator->partner_system_priority =
+				port->partner_oper.system_priority;
+			port->aggregator->partner_oper_aggregator_key = port->partner_oper.key;
+			port->aggregator->receive_state = 1;
+			port->aggregator->transmit_state = 1;
+			port->aggregator->lag_ports = port;
+			port->aggregator->num_of_ports++;
+
+			/* mark this port as selected */
+			port->sm_vars |= AD_PORT_SELECTED;
+
+			netdev_dbg(bond->dev, "Port %d joined LAG %d(new LAG)\n",
+				   port->actor_port_number,
+				   port->aggregator->aggregator_identifier);
+		} else {
+			netdev_err(bond->dev, "Port %d (on %s) did not find a suitable aggregator\n",
+			       port->actor_port_number, port->slave->dev->name);
+		}
+	}
+	/* if all aggregator's ports are READY_N == TRUE, set ready=TRUE
+	 * in all aggregator's ports, else set ready=FALSE in all
+	 * aggregator's ports
+	 */
+	__set_agg_ports_ready(port->aggregator,
+			      __agg_ports_are_ready(port->aggregator));
+
+	aggregator = __get_first_agg(port);
+	ad_agg_selection_logic(aggregator, update_slave_arr);
+
+	if (!port->aggregator->is_active)
+		port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
+}
+
+/* Decide if "agg" is a better choice for the new active aggregator that
+ * the current best, according to the ad_select policy.
+ */
+static struct aggregator *ad_agg_selection_test(struct aggregator *best,
+						struct aggregator *curr)
+{
+	/* 0. If no best, select current.
+	 *
+	 * 1. If the current agg is not individual, and the best is
+	 *    individual, select current.
+	 *
+	 * 2. If current agg is individual and the best is not, keep best.
+	 *
+	 * 3. Therefore, current and best are both individual or both not
+	 *    individual, so:
+	 *
+	 * 3a. If current agg partner replied, and best agg partner did not,
+	 *     select current.
+	 *
+	 * 3b. If current agg partner did not reply and best agg partner
+	 *     did reply, keep best.
+	 *
+	 * 4.  Therefore, current and best both have partner replies or
+	 *     both do not, so perform selection policy:
+	 *
+	 * BOND_AD_COUNT: Select by count of ports.  If count is equal,
+	 *     select by bandwidth.
+	 *
+	 * BOND_AD_STABLE, BOND_AD_BANDWIDTH: Select by bandwidth.
+	 */
+	if (!best)
+		return curr;
+
+	if (!curr->is_individual && best->is_individual)
+		return curr;
+
+	if (curr->is_individual && !best->is_individual)
+		return best;
+
+	if (__agg_has_partner(curr) && !__agg_has_partner(best))
+		return curr;
+
+	if (!__agg_has_partner(curr) && __agg_has_partner(best))
+		return best;
+
+	switch (__get_agg_selection_mode(curr->lag_ports)) {
+	case BOND_AD_COUNT:
+		if (__agg_active_ports(curr) > __agg_active_ports(best))
+			return curr;
+
+		if (__agg_active_ports(curr) < __agg_active_ports(best))
+			return best;
+
+		/*FALLTHROUGH*/
+	case BOND_AD_STABLE:
+	case BOND_AD_BANDWIDTH:
+		if (__get_agg_bandwidth(curr) > __get_agg_bandwidth(best))
+			return curr;
+
+		break;
+
+	default:
+		net_warn_ratelimited("%s: Impossible agg select mode %d\n",
+				     curr->slave->bond->dev->name,
+				     __get_agg_selection_mode(curr->lag_ports));
+		break;
+	}
+
+	return best;
+}
+
+static int agg_device_up(const struct aggregator *agg)
+{
+	struct port *port = agg->lag_ports;
+
+	if (!port)
+		return 0;
+
+	for (port = agg->lag_ports; port;
+	     port = port->next_port_in_aggregator) {
+		if (netif_running(port->slave->dev) &&
+		    netif_carrier_ok(port->slave->dev))
+			return 1;
+	}
+
+	return 0;
+}
+
+/**
+ * ad_agg_selection_logic - select an aggregation group for a team
+ * @aggregator: the aggregator we're looking at
+ * @update_slave_arr: Does slave array need update?
+ *
+ * It is assumed that only one aggregator may be selected for a team.
+ *
+ * The logic of this function is to select the aggregator according to
+ * the ad_select policy:
+ *
+ * BOND_AD_STABLE: select the aggregator with the most ports attached to
+ * it, and to reselect the active aggregator only if the previous
+ * aggregator has no more ports related to it.
+ *
+ * BOND_AD_BANDWIDTH: select the aggregator with the highest total
+ * bandwidth, and reselect whenever a link state change takes place or the
+ * set of slaves in the bond changes.
+ *
+ * BOND_AD_COUNT: select the aggregator with largest number of ports
+ * (slaves), and reselect whenever a link state change takes place or the
+ * set of slaves in the bond changes.
+ *
+ * FIXME: this function MUST be called with the first agg in the bond, or
+ * __get_active_agg() won't work correctly. This function should be better
+ * called with the bond itself, and retrieve the first agg from it.
+ */
+static void ad_agg_selection_logic(struct aggregator *agg,
+				   bool *update_slave_arr)
+{
+	struct aggregator *best, *active, *origin;
+	struct bonding *bond = agg->slave->bond;
+	struct list_head *iter;
+	struct slave *slave;
+	struct port *port;
+
+	rcu_read_lock();
+	origin = agg;
+	active = __get_active_agg(agg);
+	best = (active && agg_device_up(active)) ? active : NULL;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		agg = &(SLAVE_AD_INFO(slave)->aggregator);
+
+		agg->is_active = 0;
+
+		if (__agg_active_ports(agg) && agg_device_up(agg))
+			best = ad_agg_selection_test(best, agg);
+	}
+
+	if (best &&
+	    __get_agg_selection_mode(best->lag_ports) == BOND_AD_STABLE) {
+		/* For the STABLE policy, don't replace the old active
+		 * aggregator if it's still active (it has an answering
+		 * partner) or if both the best and active don't have an
+		 * answering partner.
+		 */
+		if (active && active->lag_ports &&
+		    __agg_active_ports(active) &&
+		    (__agg_has_partner(active) ||
+		     (!__agg_has_partner(active) &&
+		     !__agg_has_partner(best)))) {
+			if (!(!active->actor_oper_aggregator_key &&
+			      best->actor_oper_aggregator_key)) {
+				best = NULL;
+				active->is_active = 1;
+			}
+		}
+	}
+
+	if (best && (best == active)) {
+		best = NULL;
+		active->is_active = 1;
+	}
+
+	/* if there is new best aggregator, activate it */
+	if (best) {
+		netdev_dbg(bond->dev, "best Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
+			   best->aggregator_identifier, best->num_of_ports,
+			   best->actor_oper_aggregator_key,
+			   best->partner_oper_aggregator_key,
+			   best->is_individual, best->is_active);
+		netdev_dbg(bond->dev, "best ports %p slave %p %s\n",
+			   best->lag_ports, best->slave,
+			   best->slave ? best->slave->dev->name : "NULL");
+
+		bond_for_each_slave_rcu(bond, slave, iter) {
+			agg = &(SLAVE_AD_INFO(slave)->aggregator);
+
+			netdev_dbg(bond->dev, "Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
+				   agg->aggregator_identifier, agg->num_of_ports,
+				   agg->actor_oper_aggregator_key,
+				   agg->partner_oper_aggregator_key,
+				   agg->is_individual, agg->is_active);
+		}
+
+		/* check if any partner replys */
+		if (best->is_individual) {
+			net_warn_ratelimited("%s: Warning: No 802.3ad response from the link partner for any adapters in the bond\n",
+					     best->slave ?
+					     best->slave->bond->dev->name : "NULL");
+		}
+
+		best->is_active = 1;
+		netdev_dbg(bond->dev, "LAG %d chosen as the active LAG\n",
+			   best->aggregator_identifier);
+		netdev_dbg(bond->dev, "Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
+			   best->aggregator_identifier, best->num_of_ports,
+			   best->actor_oper_aggregator_key,
+			   best->partner_oper_aggregator_key,
+			   best->is_individual, best->is_active);
+
+		/* disable the ports that were related to the former
+		 * active_aggregator
+		 */
+		if (active) {
+			for (port = active->lag_ports; port;
+			     port = port->next_port_in_aggregator) {
+				__disable_port(port);
+			}
+		}
+		/* Slave array needs update. */
+		*update_slave_arr = true;
+	}
+
+	/* if the selected aggregator is of join individuals
+	 * (partner_system is NULL), enable their ports
+	 */
+	active = __get_active_agg(origin);
+
+	if (active) {
+		if (!__agg_has_partner(active)) {
+			for (port = active->lag_ports; port;
+			     port = port->next_port_in_aggregator) {
+				__enable_port(port);
+			}
+		}
+	}
+
+	rcu_read_unlock();
+
+	bond_3ad_set_carrier(bond);
+}
+
+/**
+ * ad_clear_agg - clear a given aggregator's parameters
+ * @aggregator: the aggregator we're looking at
+ */
+static void ad_clear_agg(struct aggregator *aggregator)
+{
+	if (aggregator) {
+		aggregator->is_individual = false;
+		aggregator->actor_admin_aggregator_key = 0;
+		aggregator->actor_oper_aggregator_key = 0;
+		eth_zero_addr(aggregator->partner_system.mac_addr_value);
+		aggregator->partner_system_priority = 0;
+		aggregator->partner_oper_aggregator_key = 0;
+		aggregator->receive_state = 0;
+		aggregator->transmit_state = 0;
+		aggregator->lag_ports = NULL;
+		aggregator->is_active = 0;
+		aggregator->num_of_ports = 0;
+		pr_debug("LAG %d was cleared\n",
+			 aggregator->aggregator_identifier);
+	}
+}
+
+/**
+ * ad_initialize_agg - initialize a given aggregator's parameters
+ * @aggregator: the aggregator we're looking at
+ */
+static void ad_initialize_agg(struct aggregator *aggregator)
+{
+	if (aggregator) {
+		ad_clear_agg(aggregator);
+
+		eth_zero_addr(aggregator->aggregator_mac_address.mac_addr_value);
+		aggregator->aggregator_identifier = 0;
+		aggregator->slave = NULL;
+	}
+}
+
+/**
+ * ad_initialize_port - initialize a given port's parameters
+ * @aggregator: the aggregator we're looking at
+ * @lacp_fast: boolean. whether fast periodic should be used
+ */
+static void ad_initialize_port(struct port *port, int lacp_fast)
+{
+	static const struct port_params tmpl = {
+		.system_priority = 0xffff,
+		.key             = 1,
+		.port_number     = 1,
+		.port_priority   = 0xff,
+		.port_state      = 1,
+	};
+	static const struct lacpdu lacpdu = {
+		.subtype		= 0x01,
+		.version_number = 0x01,
+		.tlv_type_actor_info = 0x01,
+		.actor_information_length = 0x14,
+		.tlv_type_partner_info = 0x02,
+		.partner_information_length = 0x14,
+		.tlv_type_collector_info = 0x03,
+		.collector_information_length = 0x10,
+		.collector_max_delay = htons(AD_COLLECTOR_MAX_DELAY),
+	};
+
+	if (port) {
+		port->actor_port_priority = 0xff;
+		port->actor_port_aggregator_identifier = 0;
+		port->ntt = false;
+		port->actor_admin_port_state = AD_STATE_AGGREGATION |
+					       AD_STATE_LACP_ACTIVITY;
+		port->actor_oper_port_state  = AD_STATE_AGGREGATION |
+					       AD_STATE_LACP_ACTIVITY;
+
+		if (lacp_fast)
+			port->actor_oper_port_state |= AD_STATE_LACP_TIMEOUT;
+
+		memcpy(&port->partner_admin, &tmpl, sizeof(tmpl));
+		memcpy(&port->partner_oper, &tmpl, sizeof(tmpl));
+
+		port->is_enabled = true;
+		/* private parameters */
+		port->sm_vars = AD_PORT_BEGIN | AD_PORT_LACP_ENABLED;
+		port->sm_rx_state = 0;
+		port->sm_rx_timer_counter = 0;
+		port->sm_periodic_state = 0;
+		port->sm_periodic_timer_counter = 0;
+		port->sm_mux_state = 0;
+		port->sm_mux_timer_counter = 0;
+		port->sm_tx_state = 0;
+		port->aggregator = NULL;
+		port->next_port_in_aggregator = NULL;
+		port->transaction_id = 0;
+
+		port->sm_churn_actor_timer_counter = 0;
+		port->sm_churn_actor_state = 0;
+		port->churn_actor_count = 0;
+		port->sm_churn_partner_timer_counter = 0;
+		port->sm_churn_partner_state = 0;
+		port->churn_partner_count = 0;
+
+		memcpy(&port->lacpdu, &lacpdu, sizeof(lacpdu));
+	}
+}
+
+/**
+ * ad_enable_collecting_distributing - enable a port's transmit/receive
+ * @port: the port we're looking at
+ * @update_slave_arr: Does slave array need update?
+ *
+ * Enable @port if it's in an active aggregator
+ */
+static void ad_enable_collecting_distributing(struct port *port,
+					      bool *update_slave_arr)
+{
+	if (port->aggregator->is_active) {
+		pr_debug("Enabling port %d(LAG %d)\n",
+			 port->actor_port_number,
+			 port->aggregator->aggregator_identifier);
+		__enable_port(port);
+		/* Slave array needs update */
+		*update_slave_arr = true;
+	}
+}
+
+/**
+ * ad_disable_collecting_distributing - disable a port's transmit/receive
+ * @port: the port we're looking at
+ * @update_slave_arr: Does slave array need update?
+ */
+static void ad_disable_collecting_distributing(struct port *port,
+					       bool *update_slave_arr)
+{
+	if (port->aggregator &&
+	    !MAC_ADDRESS_EQUAL(&(port->aggregator->partner_system),
+			       &(null_mac_addr))) {
+		pr_debug("Disabling port %d(LAG %d)\n",
+			 port->actor_port_number,
+			 port->aggregator->aggregator_identifier);
+		__disable_port(port);
+		/* Slave array needs an update */
+		*update_slave_arr = true;
+	}
+}
+
+/**
+ * ad_marker_info_received - handle receive of a Marker information frame
+ * @marker_info: Marker info received
+ * @port: the port we're looking at
+ */
+static void ad_marker_info_received(struct bond_marker *marker_info,
+	struct port *port)
+{
+	struct bond_marker marker;
+
+	/* copy the received marker data to the response marker */
+	memcpy(&marker, marker_info, sizeof(struct bond_marker));
+	/* change the marker subtype to marker response */
+	marker.tlv_type = AD_MARKER_RESPONSE_SUBTYPE;
+
+	/* send the marker response */
+	if (ad_marker_send(port, &marker) >= 0) {
+		pr_debug("Sent Marker Response on port %d\n",
+			 port->actor_port_number);
+	}
+}
+
+/**
+ * ad_marker_response_received - handle receive of a marker response frame
+ * @marker: marker PDU received
+ * @port: the port we're looking at
+ *
+ * This function does nothing since we decided not to implement send and handle
+ * response for marker PDU's, in this stage, but only to respond to marker
+ * information.
+ */
+static void ad_marker_response_received(struct bond_marker *marker,
+					struct port *port)
+{
+	/* DO NOTHING, SINCE WE DECIDED NOT TO IMPLEMENT THIS FEATURE FOR NOW */
+}
+
+/* ========= AD exported functions to the main bonding code ========= */
+
+/* Check aggregators status in team every T seconds */
+#define AD_AGGREGATOR_SELECTION_TIMER  8
+
+/**
+ * bond_3ad_initiate_agg_selection - initate aggregator selection
+ * @bond: bonding struct
+ *
+ * Set the aggregation selection timer, to initiate an agg selection in
+ * the very near future.  Called during first initialization, and during
+ * any down to up transitions of the bond.
+ */
+void bond_3ad_initiate_agg_selection(struct bonding *bond, int timeout)
+{
+	BOND_AD_INFO(bond).agg_select_timer = timeout;
+}
+
+/**
+ * bond_3ad_initialize - initialize a bond's 802.3ad parameters and structures
+ * @bond: bonding struct to work on
+ * @tick_resolution: tick duration (millisecond resolution)
+ *
+ * Can be called only after the mac address of the bond is set.
+ */
+void bond_3ad_initialize(struct bonding *bond, u16 tick_resolution)
+{
+	/* check that the bond is not initialized yet */
+	if (!MAC_ADDRESS_EQUAL(&(BOND_AD_INFO(bond).system.sys_mac_addr),
+				bond->dev->dev_addr)) {
+
+		BOND_AD_INFO(bond).aggregator_identifier = 0;
+
+		BOND_AD_INFO(bond).system.sys_priority =
+			bond->params.ad_actor_sys_prio;
+		if (is_zero_ether_addr(bond->params.ad_actor_system))
+			BOND_AD_INFO(bond).system.sys_mac_addr =
+			    *((struct mac_addr *)bond->dev->dev_addr);
+		else
+			BOND_AD_INFO(bond).system.sys_mac_addr =
+			    *((struct mac_addr *)bond->params.ad_actor_system);
+
+		/* initialize how many times this module is called in one
+		 * second (should be about every 100ms)
+		 */
+		ad_ticks_per_sec = tick_resolution;
+
+		bond_3ad_initiate_agg_selection(bond,
+						AD_AGGREGATOR_SELECTION_TIMER *
+						ad_ticks_per_sec);
+	}
+}
+
+/**
+ * bond_3ad_bind_slave - initialize a slave's port
+ * @slave: slave struct to work on
+ *
+ * Returns:   0 on success
+ *          < 0 on error
+ */
+void bond_3ad_bind_slave(struct slave *slave)
+{
+	struct bonding *bond = bond_get_bond_by_slave(slave);
+	struct port *port;
+	struct aggregator *aggregator;
+
+	/* check that the slave has not been initialized yet. */
+	if (SLAVE_AD_INFO(slave)->port.slave != slave) {
+
+		/* port initialization */
+		port = &(SLAVE_AD_INFO(slave)->port);
+
+		ad_initialize_port(port, bond->params.lacp_fast);
+
+		port->slave = slave;
+		port->actor_port_number = SLAVE_AD_INFO(slave)->id;
+		/* key is determined according to the link speed, duplex and
+		 * user key
+		 */
+		port->actor_admin_port_key = bond->params.ad_user_port_key << 6;
+		ad_update_actor_keys(port, false);
+		/* actor system is the bond's system */
+		__ad_actor_update_port(port);
+		/* tx timer(to verify that no more than MAX_TX_IN_SECOND
+		 * lacpdu's are sent in one second)
+		 */
+		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
+
+		__disable_port(port);
+
+		/* aggregator initialization */
+		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
+
+		ad_initialize_agg(aggregator);
+
+		aggregator->aggregator_mac_address = *((struct mac_addr *)bond->dev->dev_addr);
+		aggregator->aggregator_identifier = ++BOND_AD_INFO(bond).aggregator_identifier;
+		aggregator->slave = slave;
+		aggregator->is_active = 0;
+		aggregator->num_of_ports = 0;
+	}
+}
+
+/**
+ * bond_3ad_unbind_slave - deinitialize a slave's port
+ * @slave: slave struct to work on
+ *
+ * Search for the aggregator that is related to this port, remove the
+ * aggregator and assign another aggregator for other port related to it
+ * (if any), and remove the port.
+ */
+void bond_3ad_unbind_slave(struct slave *slave)
+{
+	struct port *port, *prev_port, *temp_port;
+	struct aggregator *aggregator, *new_aggregator, *temp_aggregator;
+	int select_new_active_agg = 0;
+	struct bonding *bond = slave->bond;
+	struct slave *slave_iter;
+	struct list_head *iter;
+	bool dummy_slave_update; /* Ignore this value as caller updates array */
+
+	/* Sync against bond_3ad_state_machine_handler() */
+	spin_lock_bh(&bond->mode_lock);
+	aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
+	port = &(SLAVE_AD_INFO(slave)->port);
+
+	/* if slave is null, the whole port is not initialized */
+	if (!port->slave) {
+		netdev_warn(bond->dev, "Trying to unbind an uninitialized port on %s\n",
+			    slave->dev->name);
+		goto out;
+	}
+
+	netdev_dbg(bond->dev, "Unbinding Link Aggregation Group %d\n",
+		   aggregator->aggregator_identifier);
+
+	/* Tell the partner that this port is not suitable for aggregation */
+	port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
+	port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
+	port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
+	port->actor_oper_port_state &= ~AD_STATE_AGGREGATION;
+	__update_lacpdu_from_port(port);
+	ad_lacpdu_send(port);
+
+	/* check if this aggregator is occupied */
+	if (aggregator->lag_ports) {
+		/* check if there are other ports related to this aggregator
+		 * except the port related to this slave(thats ensure us that
+		 * there is a reason to search for new aggregator, and that we
+		 * will find one
+		 */
+		if ((aggregator->lag_ports != port) ||
+		    (aggregator->lag_ports->next_port_in_aggregator)) {
+			/* find new aggregator for the related port(s) */
+			bond_for_each_slave(bond, slave_iter, iter) {
+				new_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
+				/* if the new aggregator is empty, or it is
+				 * connected to our port only
+				 */
+				if (!new_aggregator->lag_ports ||
+				    ((new_aggregator->lag_ports == port) &&
+				     !new_aggregator->lag_ports->next_port_in_aggregator))
+					break;
+			}
+			if (!slave_iter)
+				new_aggregator = NULL;
+
+			/* if new aggregator found, copy the aggregator's
+			 * parameters and connect the related lag_ports to the
+			 * new aggregator
+			 */
+			if ((new_aggregator) && ((!new_aggregator->lag_ports) || ((new_aggregator->lag_ports == port) && !new_aggregator->lag_ports->next_port_in_aggregator))) {
+				netdev_dbg(bond->dev, "Some port(s) related to LAG %d - replacing with LAG %d\n",
+					   aggregator->aggregator_identifier,
+					   new_aggregator->aggregator_identifier);
+
+				if ((new_aggregator->lag_ports == port) &&
+				    new_aggregator->is_active) {
+					netdev_info(bond->dev, "Removing an active aggregator\n");
+					 select_new_active_agg = 1;
+				}
+
+				new_aggregator->is_individual = aggregator->is_individual;
+				new_aggregator->actor_admin_aggregator_key = aggregator->actor_admin_aggregator_key;
+				new_aggregator->actor_oper_aggregator_key = aggregator->actor_oper_aggregator_key;
+				new_aggregator->partner_system = aggregator->partner_system;
+				new_aggregator->partner_system_priority = aggregator->partner_system_priority;
+				new_aggregator->partner_oper_aggregator_key = aggregator->partner_oper_aggregator_key;
+				new_aggregator->receive_state = aggregator->receive_state;
+				new_aggregator->transmit_state = aggregator->transmit_state;
+				new_aggregator->lag_ports = aggregator->lag_ports;
+				new_aggregator->is_active = aggregator->is_active;
+				new_aggregator->num_of_ports = aggregator->num_of_ports;
+
+				/* update the information that is written on
+				 * the ports about the aggregator
+				 */
+				for (temp_port = aggregator->lag_ports; temp_port;
+				     temp_port = temp_port->next_port_in_aggregator) {
+					temp_port->aggregator = new_aggregator;
+					temp_port->actor_port_aggregator_identifier = new_aggregator->aggregator_identifier;
+				}
+
+				ad_clear_agg(aggregator);
+
+				if (select_new_active_agg)
+					ad_agg_selection_logic(__get_first_agg(port),
+							       &dummy_slave_update);
+			} else {
+				netdev_warn(bond->dev, "unbinding aggregator, and could not find a new aggregator for its ports\n");
+			}
+		} else {
+			/* in case that the only port related to this
+			 * aggregator is the one we want to remove
+			 */
+			select_new_active_agg = aggregator->is_active;
+			ad_clear_agg(aggregator);
+			if (select_new_active_agg) {
+				netdev_info(bond->dev, "Removing an active aggregator\n");
+				/* select new active aggregator */
+				temp_aggregator = __get_first_agg(port);
+				if (temp_aggregator)
+					ad_agg_selection_logic(temp_aggregator,
+							       &dummy_slave_update);
+			}
+		}
+	}
+
+	netdev_dbg(bond->dev, "Unbinding port %d\n", port->actor_port_number);
+
+	/* find the aggregator that this port is connected to */
+	bond_for_each_slave(bond, slave_iter, iter) {
+		temp_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
+		prev_port = NULL;
+		/* search the port in the aggregator's related ports */
+		for (temp_port = temp_aggregator->lag_ports; temp_port;
+		     prev_port = temp_port,
+		     temp_port = temp_port->next_port_in_aggregator) {
+			if (temp_port == port) {
+				/* the aggregator found - detach the port from
+				 * this aggregator
+				 */
+				if (prev_port)
+					prev_port->next_port_in_aggregator = temp_port->next_port_in_aggregator;
+				else
+					temp_aggregator->lag_ports = temp_port->next_port_in_aggregator;
+				temp_aggregator->num_of_ports--;
+				if (__agg_active_ports(temp_aggregator) == 0) {
+					select_new_active_agg = temp_aggregator->is_active;
+					ad_clear_agg(temp_aggregator);
+					if (select_new_active_agg) {
+						netdev_info(bond->dev, "Removing an active aggregator\n");
+						/* select new active aggregator */
+						ad_agg_selection_logic(__get_first_agg(port),
+							               &dummy_slave_update);
+					}
+				}
+				break;
+			}
+		}
+	}
+	port->slave = NULL;
+
+out:
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/**
+ * bond_3ad_update_ad_actor_settings - reflect change of actor settings to ports
+ * @bond: bonding struct to work on
+ *
+ * If an ad_actor setting gets changed we need to update the individual port
+ * settings so the bond device will use the new values when it gets upped.
+ */
+void bond_3ad_update_ad_actor_settings(struct bonding *bond)
+{
+	struct list_head *iter;
+	struct slave *slave;
+
+	ASSERT_RTNL();
+
+	BOND_AD_INFO(bond).system.sys_priority = bond->params.ad_actor_sys_prio;
+	if (is_zero_ether_addr(bond->params.ad_actor_system))
+		BOND_AD_INFO(bond).system.sys_mac_addr =
+		    *((struct mac_addr *)bond->dev->dev_addr);
+	else
+		BOND_AD_INFO(bond).system.sys_mac_addr =
+		    *((struct mac_addr *)bond->params.ad_actor_system);
+
+	spin_lock_bh(&bond->mode_lock);
+	bond_for_each_slave(bond, slave, iter) {
+		struct port *port = &(SLAVE_AD_INFO(slave))->port;
+
+		__ad_actor_update_port(port);
+		port->ntt = true;
+	}
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/**
+ * bond_3ad_state_machine_handler - handle state machines timeout
+ * @bond: bonding struct to work on
+ *
+ * The state machine handling concept in this module is to check every tick
+ * which state machine should operate any function. The execution order is
+ * round robin, so when we have an interaction between state machines, the
+ * reply of one to each other might be delayed until next tick.
+ *
+ * This function also complete the initialization when the agg_select_timer
+ * times out, and it selects an aggregator for the ports that are yet not
+ * related to any aggregator, and selects the active aggregator for a bond.
+ */
+void bond_3ad_state_machine_handler(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    ad_work.work);
+	struct aggregator *aggregator;
+	struct list_head *iter;
+	struct slave *slave;
+	struct port *port;
+	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
+	bool update_slave_arr = false;
+
+	/* Lock to protect data accessed by all (e.g., port->sm_vars) and
+	 * against running with bond_3ad_unbind_slave. ad_rx_machine may run
+	 * concurrently due to incoming LACPDU as well.
+	 */
+	spin_lock_bh(&bond->mode_lock);
+	rcu_read_lock();
+
+	/* check if there are any slaves */
+	if (!bond_has_slaves(bond))
+		goto re_arm;
+
+	/* check if agg_select_timer timer after initialize is timed out */
+	if (BOND_AD_INFO(bond).agg_select_timer &&
+	    !(--BOND_AD_INFO(bond).agg_select_timer)) {
+		slave = bond_first_slave_rcu(bond);
+		port = slave ? &(SLAVE_AD_INFO(slave)->port) : NULL;
+
+		/* select the active aggregator for the bond */
+		if (port) {
+			if (!port->slave) {
+				net_warn_ratelimited("%s: Warning: bond's first port is uninitialized\n",
+						     bond->dev->name);
+				goto re_arm;
+			}
+
+			aggregator = __get_first_agg(port);
+			ad_agg_selection_logic(aggregator, &update_slave_arr);
+		}
+		bond_3ad_set_carrier(bond);
+	}
+
+	/* for each port run the state machines */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		port = &(SLAVE_AD_INFO(slave)->port);
+		if (!port->slave) {
+			net_warn_ratelimited("%s: Warning: Found an uninitialized port\n",
+					    bond->dev->name);
+			goto re_arm;
+		}
+
+		ad_rx_machine(NULL, port);
+		ad_periodic_machine(port);
+		ad_port_selection_logic(port, &update_slave_arr);
+		ad_mux_machine(port, &update_slave_arr);
+		ad_tx_machine(port);
+		ad_churn_machine(port);
+
+		/* turn off the BEGIN bit, since we already handled it */
+		if (port->sm_vars & AD_PORT_BEGIN)
+			port->sm_vars &= ~AD_PORT_BEGIN;
+	}
+
+re_arm:
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (slave->should_notify) {
+			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
+			break;
+		}
+	}
+	rcu_read_unlock();
+	spin_unlock_bh(&bond->mode_lock);
+
+	if (update_slave_arr)
+		bond_slave_arr_work_rearm(bond, 0);
+
+	if (should_notify_rtnl && rtnl_trylock()) {
+		bond_slave_state_notify(bond);
+		rtnl_unlock();
+	}
+	queue_delayed_work(bond->wq, &bond->ad_work, ad_delta_in_ticks);
+}
+
+/**
+ * bond_3ad_rx_indication - handle a received frame
+ * @lacpdu: received lacpdu
+ * @slave: slave struct to work on
+ * @length: length of the data received
+ *
+ * It is assumed that frames that were sent on this NIC don't returned as new
+ * received frames (loopback). Since only the payload is given to this
+ * function, it check for loopback.
+ */
+static int bond_3ad_rx_indication(struct lacpdu *lacpdu, struct slave *slave,
+				  u16 length)
+{
+	struct port *port;
+	int ret = RX_HANDLER_ANOTHER;
+
+	if (length >= sizeof(struct lacpdu)) {
+
+		port = &(SLAVE_AD_INFO(slave)->port);
+
+		if (!port->slave) {
+			net_warn_ratelimited("%s: Warning: port of slave %s is uninitialized\n",
+					     slave->dev->name, slave->bond->dev->name);
+			return ret;
+		}
+
+		switch (lacpdu->subtype) {
+		case AD_TYPE_LACPDU:
+			ret = RX_HANDLER_CONSUMED;
+			netdev_dbg(slave->bond->dev,
+				   "Received LACPDU on port %d slave %s\n",
+				   port->actor_port_number,
+				   slave->dev->name);
+			/* Protect against concurrent state machines */
+			spin_lock(&slave->bond->mode_lock);
+			ad_rx_machine(lacpdu, port);
+			spin_unlock(&slave->bond->mode_lock);
+			break;
+
+		case AD_TYPE_MARKER:
+			ret = RX_HANDLER_CONSUMED;
+			/* No need to convert fields to Little Endian since we
+			 * don't use the marker's fields.
+			 */
+
+			switch (((struct bond_marker *)lacpdu)->tlv_type) {
+			case AD_MARKER_INFORMATION_SUBTYPE:
+				netdev_dbg(slave->bond->dev, "Received Marker Information on port %d\n",
+					   port->actor_port_number);
+				ad_marker_info_received((struct bond_marker *)lacpdu, port);
+				break;
+
+			case AD_MARKER_RESPONSE_SUBTYPE:
+				netdev_dbg(slave->bond->dev, "Received Marker Response on port %d\n",
+					   port->actor_port_number);
+				ad_marker_response_received((struct bond_marker *)lacpdu, port);
+				break;
+
+			default:
+				netdev_dbg(slave->bond->dev, "Received an unknown Marker subtype on slot %d\n",
+					   port->actor_port_number);
+			}
+		}
+	}
+	return ret;
+}
+
+/**
+ * ad_update_actor_keys - Update the oper / admin keys for a port based on
+ * its current speed and duplex settings.
+ *
+ * @port: the port we'are looking at
+ * @reset: Boolean to just reset the speed and the duplex part of the key
+ *
+ * The logic to change the oper / admin keys is:
+ * (a) A full duplex port can participate in LACP with partner.
+ * (b) When the speed is changed, LACP need to be reinitiated.
+ */
+static void ad_update_actor_keys(struct port *port, bool reset)
+{
+	u8 duplex = 0;
+	u16 ospeed = 0, speed = 0;
+	u16 old_oper_key = port->actor_oper_port_key;
+
+	port->actor_admin_port_key &= ~(AD_SPEED_KEY_MASKS|AD_DUPLEX_KEY_MASKS);
+	if (!reset) {
+		speed = __get_link_speed(port);
+		ospeed = (old_oper_key & AD_SPEED_KEY_MASKS) >> 1;
+		duplex = __get_duplex(port);
+		port->actor_admin_port_key |= (speed << 1) | duplex;
+	}
+	port->actor_oper_port_key = port->actor_admin_port_key;
+
+	if (old_oper_key != port->actor_oper_port_key) {
+		/* Only 'duplex' port participates in LACP */
+		if (duplex)
+			port->sm_vars |= AD_PORT_LACP_ENABLED;
+		else
+			port->sm_vars &= ~AD_PORT_LACP_ENABLED;
+
+		if (!reset) {
+			if (!speed) {
+				netdev_err(port->slave->dev,
+					   "speed changed to 0 for port %s",
+					   port->slave->dev->name);
+			} else if (duplex && ospeed != speed) {
+				/* Speed change restarts LACP state-machine */
+				port->sm_vars |= AD_PORT_BEGIN;
+			}
+		}
+	}
+}
+
+/**
+ * bond_3ad_adapter_speed_duplex_changed - handle a slave's speed / duplex
+ * change indication
+ *
+ * @slave: slave struct to work on
+ *
+ * Handle reselection of aggregator (if needed) for this port.
+ */
+void bond_3ad_adapter_speed_duplex_changed(struct slave *slave)
+{
+	struct port *port;
+
+	port = &(SLAVE_AD_INFO(slave)->port);
+
+	/* if slave is null, the whole port is not initialized */
+	if (!port->slave) {
+		netdev_warn(slave->bond->dev,
+			    "speed/duplex changed for uninitialized port %s\n",
+			    slave->dev->name);
+		return;
+	}
+
+	spin_lock_bh(&slave->bond->mode_lock);
+	ad_update_actor_keys(port, false);
+	spin_unlock_bh(&slave->bond->mode_lock);
+	netdev_dbg(slave->bond->dev, "Port %d slave %s changed speed/duplex\n",
+		   port->actor_port_number, slave->dev->name);
+}
+
+/**
+ * bond_3ad_handle_link_change - handle a slave's link status change indication
+ * @slave: slave struct to work on
+ * @status: whether the link is now up or down
+ *
+ * Handle reselection of aggregator (if needed) for this port.
+ */
+void bond_3ad_handle_link_change(struct slave *slave, char link)
+{
+	struct aggregator *agg;
+	struct port *port;
+	bool dummy;
+
+	port = &(SLAVE_AD_INFO(slave)->port);
+
+	/* if slave is null, the whole port is not initialized */
+	if (!port->slave) {
+		netdev_warn(slave->bond->dev, "link status changed for uninitialized port on %s\n",
+			    slave->dev->name);
+		return;
+	}
+
+	spin_lock_bh(&slave->bond->mode_lock);
+	/* on link down we are zeroing duplex and speed since
+	 * some of the adaptors(ce1000.lan) report full duplex/speed
+	 * instead of N/A(duplex) / 0(speed).
+	 *
+	 * on link up we are forcing recheck on the duplex and speed since
+	 * some of he adaptors(ce1000.lan) report.
+	 */
+	if (link == BOND_LINK_UP) {
+		port->is_enabled = true;
+		ad_update_actor_keys(port, false);
+	} else {
+		/* link has failed */
+		port->is_enabled = false;
+		ad_update_actor_keys(port, true);
+		toe_failover(netdev_master_upper_dev_get(slave->dev),
+			     slave->dev, TOE_LINK_DOWN, NULL);
+	}
+	agg = __get_first_agg(port);
+	ad_agg_selection_logic(agg, &dummy);
+
+	spin_unlock_bh(&slave->bond->mode_lock);
+
+	netdev_dbg(slave->bond->dev, "Port %d changed link status to %s\n",
+		   port->actor_port_number,
+		   link == BOND_LINK_UP ? "UP" : "DOWN");
+
+	/* RTNL is held and mode_lock is released so it's safe
+	 * to update slave_array here.
+	 */
+	bond_update_slave_arr(slave->bond, NULL);
+}
+
+/**
+ * bond_3ad_set_carrier - set link state for bonding master
+ * @bond - bonding structure
+ *
+ * if we have an active aggregator, we're up, if not, we're down.
+ * Presumes that we cannot have an active aggregator if there are
+ * no slaves with link up.
+ *
+ * This behavior complies with IEEE 802.3 section 43.3.9.
+ *
+ * Called by bond_set_carrier(). Return zero if carrier state does not
+ * change, nonzero if it does.
+ */
+int bond_3ad_set_carrier(struct bonding *bond)
+{
+	struct aggregator *active;
+	struct slave *first_slave;
+	int ret = 1;
+
+	rcu_read_lock();
+	first_slave = bond_first_slave_rcu(bond);
+	if (!first_slave) {
+		ret = 0;
+		goto out;
+	}
+	active = __get_active_agg(&(SLAVE_AD_INFO(first_slave)->aggregator));
+	if (active) {
+		/* are enough slaves available to consider link up? */
+		if (__agg_active_ports(active) < bond->params.min_links) {
+			if (netif_carrier_ok(bond->dev)) {
+				netif_carrier_off(bond->dev);
+				goto out;
+			}
+		} else if (!netif_carrier_ok(bond->dev)) {
+			netif_carrier_on(bond->dev);
+			goto out;
+		}
+	} else if (netif_carrier_ok(bond->dev)) {
+		netif_carrier_off(bond->dev);
+	}
+out:
+	rcu_read_unlock();
+	return ret;
+}
+
+/**
+ * __bond_3ad_get_active_agg_info - get information of the active aggregator
+ * @bond: bonding struct to work on
+ * @ad_info: ad_info struct to fill with the bond's info
+ *
+ * Returns:   0 on success
+ *          < 0 on error
+ */
+int __bond_3ad_get_active_agg_info(struct bonding *bond,
+				   struct ad_info *ad_info)
+{
+	struct aggregator *aggregator = NULL;
+	struct list_head *iter;
+	struct slave *slave;
+	struct port *port;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		port = &(SLAVE_AD_INFO(slave)->port);
+		if (port->aggregator && port->aggregator->is_active) {
+			aggregator = port->aggregator;
+			break;
+		}
+	}
+
+	if (!aggregator)
+		return -1;
+
+	ad_info->aggregator_id = aggregator->aggregator_identifier;
+	ad_info->ports = __agg_active_ports(aggregator);
+	ad_info->actor_key = aggregator->actor_oper_aggregator_key;
+	ad_info->partner_key = aggregator->partner_oper_aggregator_key;
+	ether_addr_copy(ad_info->partner_system,
+			aggregator->partner_system.mac_addr_value);
+	return 0;
+}
+
+int bond_3ad_get_active_agg_info(struct bonding *bond, struct ad_info *ad_info)
+{
+	int ret;
+
+	rcu_read_lock();
+	ret = __bond_3ad_get_active_agg_info(bond, ad_info);
+	rcu_read_unlock();
+
+	return ret;
+}
+
+int bond_3ad_lacpdu_recv(const struct sk_buff *skb, struct bonding *bond,
+			 struct slave *slave)
+{
+	struct lacpdu *lacpdu, _lacpdu;
+
+	if (skb->protocol != PKT_TYPE_LACPDU)
+		return RX_HANDLER_ANOTHER;
+
+	if (!MAC_ADDRESS_EQUAL(eth_hdr(skb)->h_dest, lacpdu_mcast_addr))
+		return RX_HANDLER_ANOTHER;
+
+	lacpdu = skb_header_pointer(skb, 0, sizeof(_lacpdu), &_lacpdu);
+	if (!lacpdu)
+		return RX_HANDLER_ANOTHER;
+
+	return bond_3ad_rx_indication(lacpdu, slave, skb->len);
+}
+
+/**
+ * bond_3ad_update_lacp_rate - change the lacp rate
+ * @bond - bonding struct
+ *
+ * When modify lacp_rate parameter via sysfs,
+ * update actor_oper_port_state of each port.
+ *
+ * Hold bond->mode_lock,
+ * so we can modify port->actor_oper_port_state,
+ * no matter bond is up or down.
+ */
+void bond_3ad_update_lacp_rate(struct bonding *bond)
+{
+	struct port *port = NULL;
+	struct list_head *iter;
+	struct slave *slave;
+	int lacp_fast;
+
+	lacp_fast = bond->params.lacp_fast;
+	spin_lock_bh(&bond->mode_lock);
+	bond_for_each_slave(bond, slave, iter) {
+		port = &(SLAVE_AD_INFO(slave)->port);
+		if (lacp_fast)
+			port->actor_oper_port_state |= AD_STATE_LACP_TIMEOUT;
+		else
+			port->actor_oper_port_state &= ~AD_STATE_LACP_TIMEOUT;
+	}
+	spin_unlock_bh(&bond->mode_lock);
+}
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.103/bond_alb.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.103/bond_alb.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,1826 @@
+/*
+ * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, see <http://www.gnu.org/licenses/>.
+ *
+ * The full GNU General Public License is included in this distribution in the
+ * file called LICENSE.
+ *
+ */
+
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/pkt_sched.h>
+#include <linux/spinlock.h>
+#include <linux/slab.h>
+#include <linux/timer.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <linux/if_arp.h>
+#include <linux/if_ether.h>
+#include <linux/if_bonding.h>
+#include <linux/if_vlan.h>
+#include <linux/in.h>
+#include <net/ipx.h>
+#include <net/arp.h>
+#include <net/ipv6.h>
+#include <asm/byteorder.h>
+#include <net/bonding.h>
+#include <net/bond_alb.h>
+
+static const u8 mac_v6_allmcast[ETH_ALEN + 2] __long_aligned = {
+	0x33, 0x33, 0x00, 0x00, 0x00, 0x01
+};
+static const int alb_delta_in_ticks = HZ / ALB_TIMER_TICKS_PER_SEC;
+
+#pragma pack(1)
+struct learning_pkt {
+	u8 mac_dst[ETH_ALEN];
+	u8 mac_src[ETH_ALEN];
+	__be16 type;
+	u8 padding[ETH_ZLEN - ETH_HLEN];
+};
+
+struct arp_pkt {
+	__be16  hw_addr_space;
+	__be16  prot_addr_space;
+	u8      hw_addr_len;
+	u8      prot_addr_len;
+	__be16  op_code;
+	u8      mac_src[ETH_ALEN];	/* sender hardware address */
+	__be32  ip_src;			/* sender IP address */
+	u8      mac_dst[ETH_ALEN];	/* target hardware address */
+	__be32  ip_dst;			/* target IP address */
+};
+#pragma pack()
+
+static inline struct arp_pkt *arp_pkt(const struct sk_buff *skb)
+{
+	return (struct arp_pkt *)skb_network_header(skb);
+}
+
+/* Forward declaration */
+static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
+				      bool strict_match);
+static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp);
+static void rlb_src_unlink(struct bonding *bond, u32 index);
+static void rlb_src_link(struct bonding *bond, u32 ip_src_hash,
+			 u32 ip_dst_hash);
+
+static inline u8 _simple_hash(const u8 *hash_start, int hash_size)
+{
+	int i;
+	u8 hash = 0;
+
+	for (i = 0; i < hash_size; i++)
+		hash ^= hash_start[i];
+
+	return hash;
+}
+
+/*********************** tlb specific functions ***************************/
+
+static inline void tlb_init_table_entry(struct tlb_client_info *entry, int save_load)
+{
+	if (save_load) {
+		entry->load_history = 1 + entry->tx_bytes /
+				      BOND_TLB_REBALANCE_INTERVAL;
+		entry->tx_bytes = 0;
+	}
+
+	entry->tx_slave = NULL;
+	entry->next = TLB_NULL_INDEX;
+	entry->prev = TLB_NULL_INDEX;
+}
+
+static inline void tlb_init_slave(struct slave *slave)
+{
+	SLAVE_TLB_INFO(slave).load = 0;
+	SLAVE_TLB_INFO(slave).head = TLB_NULL_INDEX;
+}
+
+static void __tlb_clear_slave(struct bonding *bond, struct slave *slave,
+			 int save_load)
+{
+	struct tlb_client_info *tx_hash_table;
+	u32 index;
+
+	/* clear slave from tx_hashtbl */
+	tx_hash_table = BOND_ALB_INFO(bond).tx_hashtbl;
+
+	/* skip this if we've already freed the tx hash table */
+	if (tx_hash_table) {
+		index = SLAVE_TLB_INFO(slave).head;
+		while (index != TLB_NULL_INDEX) {
+			u32 next_index = tx_hash_table[index].next;
+			tlb_init_table_entry(&tx_hash_table[index], save_load);
+			index = next_index;
+		}
+	}
+
+	tlb_init_slave(slave);
+}
+
+static void tlb_clear_slave(struct bonding *bond, struct slave *slave,
+			 int save_load)
+{
+	spin_lock_bh(&bond->mode_lock);
+	__tlb_clear_slave(bond, slave, save_load);
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/* Must be called before starting the monitor timer */
+static int tlb_initialize(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	int size = TLB_HASH_TABLE_SIZE * sizeof(struct tlb_client_info);
+	struct tlb_client_info *new_hashtbl;
+	int i;
+
+	new_hashtbl = kzalloc(size, GFP_KERNEL);
+	if (!new_hashtbl)
+		return -ENOMEM;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	bond_info->tx_hashtbl = new_hashtbl;
+
+	for (i = 0; i < TLB_HASH_TABLE_SIZE; i++)
+		tlb_init_table_entry(&bond_info->tx_hashtbl[i], 0);
+
+	spin_unlock_bh(&bond->mode_lock);
+
+	return 0;
+}
+
+/* Must be called only after all slaves have been released */
+static void tlb_deinitialize(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+
+	spin_lock_bh(&bond->mode_lock);
+
+	kfree(bond_info->tx_hashtbl);
+	bond_info->tx_hashtbl = NULL;
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+static long long compute_gap(struct slave *slave)
+{
+	return (s64) (slave->speed << 20) - /* Convert to Megabit per sec */
+	       (s64) (SLAVE_TLB_INFO(slave).load << 3); /* Bytes to bits */
+}
+
+static struct slave *tlb_get_least_loaded_slave(struct bonding *bond)
+{
+	struct slave *slave, *least_loaded;
+	struct list_head *iter;
+	long long max_gap;
+
+	least_loaded = NULL;
+	max_gap = LLONG_MIN;
+
+	/* Find the slave with the largest gap */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (bond_slave_can_tx(slave)) {
+			long long gap = compute_gap(slave);
+
+			if (max_gap < gap) {
+				least_loaded = slave;
+				max_gap = gap;
+			}
+		}
+	}
+
+	return least_loaded;
+}
+
+static struct slave *__tlb_choose_channel(struct bonding *bond, u32 hash_index,
+						u32 skb_len)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct tlb_client_info *hash_table;
+	struct slave *assigned_slave;
+
+	hash_table = bond_info->tx_hashtbl;
+	assigned_slave = hash_table[hash_index].tx_slave;
+	if (!assigned_slave) {
+		assigned_slave = tlb_get_least_loaded_slave(bond);
+
+		if (assigned_slave) {
+			struct tlb_slave_info *slave_info =
+				&(SLAVE_TLB_INFO(assigned_slave));
+			u32 next_index = slave_info->head;
+
+			hash_table[hash_index].tx_slave = assigned_slave;
+			hash_table[hash_index].next = next_index;
+			hash_table[hash_index].prev = TLB_NULL_INDEX;
+
+			if (next_index != TLB_NULL_INDEX)
+				hash_table[next_index].prev = hash_index;
+
+			slave_info->head = hash_index;
+			slave_info->load +=
+				hash_table[hash_index].load_history;
+		}
+	}
+
+	if (assigned_slave)
+		hash_table[hash_index].tx_bytes += skb_len;
+
+	return assigned_slave;
+}
+
+static struct slave *tlb_choose_channel(struct bonding *bond, u32 hash_index,
+					u32 skb_len)
+{
+	struct slave *tx_slave;
+
+	/* We don't need to disable softirq here, becase
+	 * tlb_choose_channel() is only called by bond_alb_xmit()
+	 * which already has softirq disabled.
+	 */
+	spin_lock(&bond->mode_lock);
+	tx_slave = __tlb_choose_channel(bond, hash_index, skb_len);
+	spin_unlock(&bond->mode_lock);
+
+	return tx_slave;
+}
+
+/*********************** rlb specific functions ***************************/
+
+/* when an ARP REPLY is received from a client update its info
+ * in the rx_hashtbl
+ */
+static void rlb_update_entry_from_arp(struct bonding *bond, struct arp_pkt *arp)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *client_info;
+	u32 hash_index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	hash_index = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
+	client_info = &(bond_info->rx_hashtbl[hash_index]);
+
+	if ((client_info->assigned) &&
+	    (client_info->ip_src == arp->ip_dst) &&
+	    (client_info->ip_dst == arp->ip_src) &&
+	    (!ether_addr_equal_64bits(client_info->mac_dst, arp->mac_src))) {
+		/* update the clients MAC address */
+		ether_addr_copy(client_info->mac_dst, arp->mac_src);
+		client_info->ntt = 1;
+		bond_info->rx_ntt = 1;
+	}
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+static int rlb_arp_recv(const struct sk_buff *skb, struct bonding *bond,
+			struct slave *slave)
+{
+	struct arp_pkt *arp, _arp;
+
+	if (skb->protocol != cpu_to_be16(ETH_P_ARP))
+		goto out;
+
+	arp = skb_header_pointer(skb, 0, sizeof(_arp), &_arp);
+	if (!arp)
+		goto out;
+
+	/* We received an ARP from arp->ip_src.
+	 * We might have used this IP address previously (on the bonding host
+	 * itself or on a system that is bridged together with the bond).
+	 * However, if arp->mac_src is different than what is stored in
+	 * rx_hashtbl, some other host is now using the IP and we must prevent
+	 * sending out client updates with this IP address and the old MAC
+	 * address.
+	 * Clean up all hash table entries that have this address as ip_src but
+	 * have a different mac_src.
+	 */
+	rlb_purge_src_ip(bond, arp);
+
+	if (arp->op_code == htons(ARPOP_REPLY)) {
+		/* update rx hash table for this ARP */
+		rlb_update_entry_from_arp(bond, arp);
+		netdev_dbg(bond->dev, "Server received an ARP Reply from client\n");
+	}
+out:
+	return RX_HANDLER_ANOTHER;
+}
+
+/* Caller must hold rcu_read_lock() */
+static struct slave *__rlb_next_rx_slave(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct slave *before = NULL, *rx_slave = NULL, *slave;
+	struct list_head *iter;
+	bool found = false;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (!bond_slave_can_tx(slave))
+			continue;
+		if (!found) {
+			if (!before || before->speed < slave->speed)
+				before = slave;
+		} else {
+			if (!rx_slave || rx_slave->speed < slave->speed)
+				rx_slave = slave;
+		}
+		if (slave == bond_info->rx_slave)
+			found = true;
+	}
+	/* we didn't find anything after the current or we have something
+	 * better before and up to the current slave
+	 */
+	if (!rx_slave || (before && rx_slave->speed < before->speed))
+		rx_slave = before;
+
+	if (rx_slave)
+		bond_info->rx_slave = rx_slave;
+
+	return rx_slave;
+}
+
+/* Caller must hold RTNL, rcu_read_lock is obtained only to silence checkers */
+static struct slave *rlb_next_rx_slave(struct bonding *bond)
+{
+	struct slave *rx_slave;
+
+	ASSERT_RTNL();
+
+	rcu_read_lock();
+	rx_slave = __rlb_next_rx_slave(bond);
+	rcu_read_unlock();
+
+	return rx_slave;
+}
+
+/* teach the switch the mac of a disabled slave
+ * on the primary for fault tolerance
+ *
+ * Caller must hold RTNL
+ */
+static void rlb_teach_disabled_mac_on_primary(struct bonding *bond, u8 addr[])
+{
+	struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
+
+	if (!curr_active)
+		return;
+
+	if (!bond->alb_info.primary_is_promisc) {
+		if (!dev_set_promiscuity(curr_active->dev, 1))
+			bond->alb_info.primary_is_promisc = 1;
+		else
+			bond->alb_info.primary_is_promisc = 0;
+	}
+
+	bond->alb_info.rlb_promisc_timeout_counter = 0;
+
+	alb_send_learning_packets(curr_active, addr, true);
+}
+
+/* slave being removed should not be active at this point
+ *
+ * Caller must hold rtnl.
+ */
+static void rlb_clear_slave(struct bonding *bond, struct slave *slave)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *rx_hash_table;
+	u32 index, next_index;
+
+	/* clear slave from rx_hashtbl */
+	spin_lock_bh(&bond->mode_lock);
+
+	rx_hash_table = bond_info->rx_hashtbl;
+	index = bond_info->rx_hashtbl_used_head;
+	for (; index != RLB_NULL_INDEX; index = next_index) {
+		next_index = rx_hash_table[index].used_next;
+		if (rx_hash_table[index].slave == slave) {
+			struct slave *assigned_slave = rlb_next_rx_slave(bond);
+
+			if (assigned_slave) {
+				rx_hash_table[index].slave = assigned_slave;
+				if (is_valid_ether_addr(rx_hash_table[index].mac_dst)) {
+					bond_info->rx_hashtbl[index].ntt = 1;
+					bond_info->rx_ntt = 1;
+					/* A slave has been removed from the
+					 * table because it is either disabled
+					 * or being released. We must retry the
+					 * update to avoid clients from not
+					 * being updated & disconnecting when
+					 * there is stress
+					 */
+					bond_info->rlb_update_retry_counter =
+						RLB_UPDATE_RETRY;
+				}
+			} else {  /* there is no active slave */
+				rx_hash_table[index].slave = NULL;
+			}
+		}
+	}
+
+	spin_unlock_bh(&bond->mode_lock);
+
+	if (slave != rtnl_dereference(bond->curr_active_slave))
+		rlb_teach_disabled_mac_on_primary(bond, slave->dev->dev_addr);
+}
+
+static void rlb_update_client(struct rlb_client_info *client_info)
+{
+	int i;
+
+	if (!client_info->slave || !is_valid_ether_addr(client_info->mac_dst))
+		return;
+
+	for (i = 0; i < RLB_ARP_BURST_SIZE; i++) {
+		struct sk_buff *skb;
+
+		skb = arp_create(ARPOP_REPLY, ETH_P_ARP,
+				 client_info->ip_dst,
+				 client_info->slave->dev,
+				 client_info->ip_src,
+				 client_info->mac_dst,
+				 client_info->slave->dev->dev_addr,
+				 client_info->mac_dst);
+		if (!skb) {
+			netdev_err(client_info->slave->bond->dev,
+				   "failed to create an ARP packet\n");
+			continue;
+		}
+
+		skb->dev = client_info->slave->dev;
+
+		if (client_info->vlan_id) {
+			__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),
+					       client_info->vlan_id);
+		}
+
+		arp_xmit(skb);
+	}
+}
+
+/* sends ARP REPLIES that update the clients that need updating */
+static void rlb_update_rx_clients(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *client_info;
+	u32 hash_index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	hash_index = bond_info->rx_hashtbl_used_head;
+	for (; hash_index != RLB_NULL_INDEX;
+	     hash_index = client_info->used_next) {
+		client_info = &(bond_info->rx_hashtbl[hash_index]);
+		if (client_info->ntt) {
+			rlb_update_client(client_info);
+			if (bond_info->rlb_update_retry_counter == 0)
+				client_info->ntt = 0;
+		}
+	}
+
+	/* do not update the entries again until this counter is zero so that
+	 * not to confuse the clients.
+	 */
+	bond_info->rlb_update_delay_counter = RLB_UPDATE_DELAY;
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/* The slave was assigned a new mac address - update the clients */
+static void rlb_req_update_slave_clients(struct bonding *bond, struct slave *slave)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *client_info;
+	int ntt = 0;
+	u32 hash_index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	hash_index = bond_info->rx_hashtbl_used_head;
+	for (; hash_index != RLB_NULL_INDEX;
+	     hash_index = client_info->used_next) {
+		client_info = &(bond_info->rx_hashtbl[hash_index]);
+
+		if ((client_info->slave == slave) &&
+		    is_valid_ether_addr(client_info->mac_dst)) {
+			client_info->ntt = 1;
+			ntt = 1;
+		}
+	}
+
+	/* update the team's flag only after the whole iteration */
+	if (ntt) {
+		bond_info->rx_ntt = 1;
+		/* fasten the change */
+		bond_info->rlb_update_retry_counter = RLB_UPDATE_RETRY;
+	}
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/* mark all clients using src_ip to be updated */
+static void rlb_req_update_subnet_clients(struct bonding *bond, __be32 src_ip)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *client_info;
+	u32 hash_index;
+
+	spin_lock(&bond->mode_lock);
+
+	hash_index = bond_info->rx_hashtbl_used_head;
+	for (; hash_index != RLB_NULL_INDEX;
+	     hash_index = client_info->used_next) {
+		client_info = &(bond_info->rx_hashtbl[hash_index]);
+
+		if (!client_info->slave) {
+			netdev_err(bond->dev, "found a client with no channel in the client's hash table\n");
+			continue;
+		}
+		/* update all clients using this src_ip, that are not assigned
+		 * to the team's address (curr_active_slave) and have a known
+		 * unicast mac address.
+		 */
+		if ((client_info->ip_src == src_ip) &&
+		    !ether_addr_equal_64bits(client_info->slave->dev->dev_addr,
+					     bond->dev->dev_addr) &&
+		    is_valid_ether_addr(client_info->mac_dst)) {
+			client_info->ntt = 1;
+			bond_info->rx_ntt = 1;
+		}
+	}
+
+	spin_unlock(&bond->mode_lock);
+}
+
+static struct slave *rlb_choose_channel(struct sk_buff *skb, struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct arp_pkt *arp = arp_pkt(skb);
+	struct slave *assigned_slave, *curr_active_slave;
+	struct rlb_client_info *client_info;
+	u32 hash_index = 0;
+
+	spin_lock(&bond->mode_lock);
+
+	curr_active_slave = rcu_dereference(bond->curr_active_slave);
+
+	hash_index = _simple_hash((u8 *)&arp->ip_dst, sizeof(arp->ip_dst));
+	client_info = &(bond_info->rx_hashtbl[hash_index]);
+
+	if (client_info->assigned) {
+		if ((client_info->ip_src == arp->ip_src) &&
+		    (client_info->ip_dst == arp->ip_dst)) {
+			/* the entry is already assigned to this client */
+			if (!is_broadcast_ether_addr(arp->mac_dst)) {
+				/* update mac address from arp */
+				ether_addr_copy(client_info->mac_dst, arp->mac_dst);
+			}
+			ether_addr_copy(client_info->mac_src, arp->mac_src);
+
+			assigned_slave = client_info->slave;
+			if (assigned_slave) {
+				spin_unlock(&bond->mode_lock);
+				return assigned_slave;
+			}
+		} else {
+			/* the entry is already assigned to some other client,
+			 * move the old client to primary (curr_active_slave) so
+			 * that the new client can be assigned to this entry.
+			 */
+			if (curr_active_slave &&
+			    client_info->slave != curr_active_slave) {
+				client_info->slave = curr_active_slave;
+				rlb_update_client(client_info);
+			}
+		}
+	}
+	/* assign a new slave */
+	assigned_slave = __rlb_next_rx_slave(bond);
+
+	if (assigned_slave) {
+		if (!(client_info->assigned &&
+		      client_info->ip_src == arp->ip_src)) {
+			/* ip_src is going to be updated,
+			 * fix the src hash list
+			 */
+			u32 hash_src = _simple_hash((u8 *)&arp->ip_src,
+						    sizeof(arp->ip_src));
+			rlb_src_unlink(bond, hash_index);
+			rlb_src_link(bond, hash_src, hash_index);
+		}
+
+		client_info->ip_src = arp->ip_src;
+		client_info->ip_dst = arp->ip_dst;
+		/* arp->mac_dst is broadcast for arp reqeusts.
+		 * will be updated with clients actual unicast mac address
+		 * upon receiving an arp reply.
+		 */
+		ether_addr_copy(client_info->mac_dst, arp->mac_dst);
+		ether_addr_copy(client_info->mac_src, arp->mac_src);
+		client_info->slave = assigned_slave;
+
+		if (is_valid_ether_addr(client_info->mac_dst)) {
+			client_info->ntt = 1;
+			bond->alb_info.rx_ntt = 1;
+		} else {
+			client_info->ntt = 0;
+		}
+
+		if (vlan_get_tag(skb, &client_info->vlan_id))
+			client_info->vlan_id = 0;
+
+		if (!client_info->assigned) {
+			u32 prev_tbl_head = bond_info->rx_hashtbl_used_head;
+			bond_info->rx_hashtbl_used_head = hash_index;
+			client_info->used_next = prev_tbl_head;
+			if (prev_tbl_head != RLB_NULL_INDEX) {
+				bond_info->rx_hashtbl[prev_tbl_head].used_prev =
+					hash_index;
+			}
+			client_info->assigned = 1;
+		}
+	}
+
+	spin_unlock(&bond->mode_lock);
+
+	return assigned_slave;
+}
+
+/* chooses (and returns) transmit channel for arp reply
+ * does not choose channel for other arp types since they are
+ * sent on the curr_active_slave
+ */
+static struct slave *rlb_arp_xmit(struct sk_buff *skb, struct bonding *bond)
+{
+	struct arp_pkt *arp = arp_pkt(skb);
+	struct slave *tx_slave = NULL;
+
+	/* Don't modify or load balance ARPs that do not originate locally
+	 * (e.g.,arrive via a bridge).
+	 */
+	if (!bond_slave_has_mac_rx(bond, arp->mac_src))
+		return NULL;
+
+	if (arp->op_code == htons(ARPOP_REPLY)) {
+		/* the arp must be sent on the selected rx channel */
+		tx_slave = rlb_choose_channel(skb, bond);
+		if (tx_slave)
+			bond_hw_addr_copy(arp->mac_src, tx_slave->dev->dev_addr,
+					  tx_slave->dev->addr_len);
+		netdev_dbg(bond->dev, "Server sent ARP Reply packet\n");
+	} else if (arp->op_code == htons(ARPOP_REQUEST)) {
+		/* Create an entry in the rx_hashtbl for this client as a
+		 * place holder.
+		 * When the arp reply is received the entry will be updated
+		 * with the correct unicast address of the client.
+		 */
+		rlb_choose_channel(skb, bond);
+
+		/* The ARP reply packets must be delayed so that
+		 * they can cancel out the influence of the ARP request.
+		 */
+		bond->alb_info.rlb_update_delay_counter = RLB_UPDATE_DELAY;
+
+		/* arp requests are broadcast and are sent on the primary
+		 * the arp request will collapse all clients on the subnet to
+		 * the primary slave. We must register these clients to be
+		 * updated with their assigned mac.
+		 */
+		rlb_req_update_subnet_clients(bond, arp->ip_src);
+		netdev_dbg(bond->dev, "Server sent ARP Request packet\n");
+	}
+
+	return tx_slave;
+}
+
+static void rlb_rebalance(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct slave *assigned_slave;
+	struct rlb_client_info *client_info;
+	int ntt;
+	u32 hash_index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	ntt = 0;
+	hash_index = bond_info->rx_hashtbl_used_head;
+	for (; hash_index != RLB_NULL_INDEX;
+	     hash_index = client_info->used_next) {
+		client_info = &(bond_info->rx_hashtbl[hash_index]);
+		assigned_slave = __rlb_next_rx_slave(bond);
+		if (assigned_slave && (client_info->slave != assigned_slave)) {
+			client_info->slave = assigned_slave;
+			if (!is_zero_ether_addr(client_info->mac_dst)) {
+				client_info->ntt = 1;
+				ntt = 1;
+			}
+		}
+	}
+
+	/* update the team's flag only after the whole iteration */
+	if (ntt)
+		bond_info->rx_ntt = 1;
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/* Caller must hold mode_lock */
+static void rlb_init_table_entry_dst(struct rlb_client_info *entry)
+{
+	entry->used_next = RLB_NULL_INDEX;
+	entry->used_prev = RLB_NULL_INDEX;
+	entry->assigned = 0;
+	entry->slave = NULL;
+	entry->vlan_id = 0;
+}
+static void rlb_init_table_entry_src(struct rlb_client_info *entry)
+{
+	entry->src_first = RLB_NULL_INDEX;
+	entry->src_prev = RLB_NULL_INDEX;
+	entry->src_next = RLB_NULL_INDEX;
+}
+
+static void rlb_init_table_entry(struct rlb_client_info *entry)
+{
+	memset(entry, 0, sizeof(struct rlb_client_info));
+	rlb_init_table_entry_dst(entry);
+	rlb_init_table_entry_src(entry);
+}
+
+static void rlb_delete_table_entry_dst(struct bonding *bond, u32 index)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	u32 next_index = bond_info->rx_hashtbl[index].used_next;
+	u32 prev_index = bond_info->rx_hashtbl[index].used_prev;
+
+	if (index == bond_info->rx_hashtbl_used_head)
+		bond_info->rx_hashtbl_used_head = next_index;
+	if (prev_index != RLB_NULL_INDEX)
+		bond_info->rx_hashtbl[prev_index].used_next = next_index;
+	if (next_index != RLB_NULL_INDEX)
+		bond_info->rx_hashtbl[next_index].used_prev = prev_index;
+}
+
+/* unlink a rlb hash table entry from the src list */
+static void rlb_src_unlink(struct bonding *bond, u32 index)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	u32 next_index = bond_info->rx_hashtbl[index].src_next;
+	u32 prev_index = bond_info->rx_hashtbl[index].src_prev;
+
+	bond_info->rx_hashtbl[index].src_next = RLB_NULL_INDEX;
+	bond_info->rx_hashtbl[index].src_prev = RLB_NULL_INDEX;
+
+	if (next_index != RLB_NULL_INDEX)
+		bond_info->rx_hashtbl[next_index].src_prev = prev_index;
+
+	if (prev_index == RLB_NULL_INDEX)
+		return;
+
+	/* is prev_index pointing to the head of this list? */
+	if (bond_info->rx_hashtbl[prev_index].src_first == index)
+		bond_info->rx_hashtbl[prev_index].src_first = next_index;
+	else
+		bond_info->rx_hashtbl[prev_index].src_next = next_index;
+
+}
+
+static void rlb_delete_table_entry(struct bonding *bond, u32 index)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
+
+	rlb_delete_table_entry_dst(bond, index);
+	rlb_init_table_entry_dst(entry);
+
+	rlb_src_unlink(bond, index);
+}
+
+/* add the rx_hashtbl[ip_dst_hash] entry to the list
+ * of entries with identical ip_src_hash
+ */
+static void rlb_src_link(struct bonding *bond, u32 ip_src_hash, u32 ip_dst_hash)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	u32 next;
+
+	bond_info->rx_hashtbl[ip_dst_hash].src_prev = ip_src_hash;
+	next = bond_info->rx_hashtbl[ip_src_hash].src_first;
+	bond_info->rx_hashtbl[ip_dst_hash].src_next = next;
+	if (next != RLB_NULL_INDEX)
+		bond_info->rx_hashtbl[next].src_prev = ip_dst_hash;
+	bond_info->rx_hashtbl[ip_src_hash].src_first = ip_dst_hash;
+}
+
+/* deletes all rx_hashtbl entries with arp->ip_src if their mac_src does
+ * not match arp->mac_src
+ */
+static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	u32 ip_src_hash = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
+	u32 index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	index = bond_info->rx_hashtbl[ip_src_hash].src_first;
+	while (index != RLB_NULL_INDEX) {
+		struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
+		u32 next_index = entry->src_next;
+		if (entry->ip_src == arp->ip_src &&
+		    !ether_addr_equal_64bits(arp->mac_src, entry->mac_src))
+				rlb_delete_table_entry(bond, index);
+		index = next_index;
+	}
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+static int rlb_initialize(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info	*new_hashtbl;
+	int size = RLB_HASH_TABLE_SIZE * sizeof(struct rlb_client_info);
+	int i;
+
+	new_hashtbl = kmalloc(size, GFP_KERNEL);
+	if (!new_hashtbl)
+		return -1;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	bond_info->rx_hashtbl = new_hashtbl;
+
+	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
+
+	for (i = 0; i < RLB_HASH_TABLE_SIZE; i++)
+		rlb_init_table_entry(bond_info->rx_hashtbl + i);
+
+	spin_unlock_bh(&bond->mode_lock);
+
+	/* register to receive ARPs */
+	bond->recv_probe = rlb_arp_recv;
+
+	return 0;
+}
+
+static void rlb_deinitialize(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+
+	spin_lock_bh(&bond->mode_lock);
+
+	kfree(bond_info->rx_hashtbl);
+	bond_info->rx_hashtbl = NULL;
+	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+static void rlb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	u32 curr_index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	curr_index = bond_info->rx_hashtbl_used_head;
+	while (curr_index != RLB_NULL_INDEX) {
+		struct rlb_client_info *curr = &(bond_info->rx_hashtbl[curr_index]);
+		u32 next_index = bond_info->rx_hashtbl[curr_index].used_next;
+
+		if (curr->vlan_id == vlan_id)
+			rlb_delete_table_entry(bond, curr_index);
+
+		curr_index = next_index;
+	}
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/*********************** tlb/rlb shared functions *********************/
+
+static void alb_send_lp_vid(struct slave *slave, u8 mac_addr[],
+			    __be16 vlan_proto, u16 vid)
+{
+	struct learning_pkt pkt;
+	struct sk_buff *skb;
+	int size = sizeof(struct learning_pkt);
+
+	memset(&pkt, 0, size);
+	ether_addr_copy(pkt.mac_dst, mac_addr);
+	ether_addr_copy(pkt.mac_src, mac_addr);
+	pkt.type = cpu_to_be16(ETH_P_LOOPBACK);
+
+	skb = dev_alloc_skb(size);
+	if (!skb)
+		return;
+
+	skb_put_data(skb, &pkt, size);
+
+	skb_reset_mac_header(skb);
+	skb->network_header = skb->mac_header + ETH_HLEN;
+	skb->protocol = pkt.type;
+	skb->priority = TC_PRIO_CONTROL;
+	skb->dev = slave->dev;
+
+	netdev_dbg(slave->bond->dev,
+		   "Send learning packet: dev %s mac %pM vlan %d\n",
+		   slave->dev->name, mac_addr, vid);
+
+	if (vid)
+		__vlan_hwaccel_put_tag(skb, vlan_proto, vid);
+
+	dev_queue_xmit(skb);
+}
+
+struct alb_walk_data {
+	struct bonding *bond;
+	struct slave *slave;
+	u8 *mac_addr;
+	bool strict_match;
+};
+
+static int alb_upper_dev_walk(struct net_device *upper, void *_data)
+{
+	struct alb_walk_data *data = _data;
+	bool strict_match = data->strict_match;
+	struct bonding *bond = data->bond;
+	struct slave *slave = data->slave;
+	u8 *mac_addr = data->mac_addr;
+	struct bond_vlan_tag *tags;
+
+	if (is_vlan_dev(upper) &&
+	    bond->nest_level == vlan_get_encap_level(upper) - 1) {
+		if (upper->addr_assign_type == NET_ADDR_STOLEN) {
+			alb_send_lp_vid(slave, mac_addr,
+					vlan_dev_vlan_proto(upper),
+					vlan_dev_vlan_id(upper));
+		} else {
+			alb_send_lp_vid(slave, upper->dev_addr,
+					vlan_dev_vlan_proto(upper),
+					vlan_dev_vlan_id(upper));
+		}
+	}
+
+	/* If this is a macvlan device, then only send updates
+	 * when strict_match is turned off.
+	 */
+	if (netif_is_macvlan(upper) && !strict_match) {
+		tags = bond_verify_device_path(bond->dev, upper, 0);
+		if (IS_ERR_OR_NULL(tags))
+			BUG();
+		alb_send_lp_vid(slave, upper->dev_addr,
+				tags[0].vlan_proto, tags[0].vlan_id);
+		kfree(tags);
+	}
+
+	return 0;
+}
+
+static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
+				      bool strict_match)
+{
+	struct bonding *bond = bond_get_bond_by_slave(slave);
+	struct alb_walk_data data = {
+		.strict_match = strict_match,
+		.mac_addr = mac_addr,
+		.slave = slave,
+		.bond = bond,
+	};
+
+	/* send untagged */
+	alb_send_lp_vid(slave, mac_addr, 0, 0);
+
+	/* loop through all devices and see if we need to send a packet
+	 * for that device.
+	 */
+	rcu_read_lock();
+	netdev_walk_all_upper_dev_rcu(bond->dev, alb_upper_dev_walk, &data);
+	rcu_read_unlock();
+}
+
+static int alb_set_slave_mac_addr(struct slave *slave, u8 addr[],
+				  unsigned int len)
+{
+	struct net_device *dev = slave->dev;
+	struct sockaddr_storage ss;
+
+	if (BOND_MODE(slave->bond) == BOND_MODE_TLB) {
+		memcpy(dev->dev_addr, addr, len);
+		return 0;
+	}
+
+	/* for rlb each slave must have a unique hw mac addresses so that
+	 * each slave will receive packets destined to a different mac
+	 */
+	memcpy(ss.__data, addr, len);
+	ss.ss_family = dev->type;
+	if (dev_set_mac_address(dev, (struct sockaddr *)&ss)) {
+		netdev_err(slave->bond->dev, "dev_set_mac_address of dev %s failed! ALB mode requires that the base driver support setting the hw address also when the network device's interface is open\n",
+			   dev->name);
+		return -EOPNOTSUPP;
+	}
+	return 0;
+}
+
+/* Swap MAC addresses between two slaves.
+ *
+ * Called with RTNL held, and no other locks.
+ */
+static void alb_swap_mac_addr(struct slave *slave1, struct slave *slave2)
+{
+	u8 tmp_mac_addr[MAX_ADDR_LEN];
+
+	bond_hw_addr_copy(tmp_mac_addr, slave1->dev->dev_addr,
+			  slave1->dev->addr_len);
+	alb_set_slave_mac_addr(slave1, slave2->dev->dev_addr,
+			       slave2->dev->addr_len);
+	alb_set_slave_mac_addr(slave2, tmp_mac_addr,
+			       slave1->dev->addr_len);
+
+}
+
+/* Send learning packets after MAC address swap.
+ *
+ * Called with RTNL and no other locks
+ */
+static void alb_fasten_mac_swap(struct bonding *bond, struct slave *slave1,
+				struct slave *slave2)
+{
+	int slaves_state_differ = (bond_slave_can_tx(slave1) != bond_slave_can_tx(slave2));
+	struct slave *disabled_slave = NULL;
+
+	ASSERT_RTNL();
+
+	/* fasten the change in the switch */
+	if (bond_slave_can_tx(slave1)) {
+		alb_send_learning_packets(slave1, slave1->dev->dev_addr, false);
+		if (bond->alb_info.rlb_enabled) {
+			/* inform the clients that the mac address
+			 * has changed
+			 */
+			rlb_req_update_slave_clients(bond, slave1);
+		}
+	} else {
+		disabled_slave = slave1;
+	}
+
+	if (bond_slave_can_tx(slave2)) {
+		alb_send_learning_packets(slave2, slave2->dev->dev_addr, false);
+		if (bond->alb_info.rlb_enabled) {
+			/* inform the clients that the mac address
+			 * has changed
+			 */
+			rlb_req_update_slave_clients(bond, slave2);
+		}
+	} else {
+		disabled_slave = slave2;
+	}
+
+	if (bond->alb_info.rlb_enabled && slaves_state_differ) {
+		/* A disabled slave was assigned an active mac addr */
+		rlb_teach_disabled_mac_on_primary(bond,
+						  disabled_slave->dev->dev_addr);
+	}
+}
+
+/**
+ * alb_change_hw_addr_on_detach
+ * @bond: bonding we're working on
+ * @slave: the slave that was just detached
+ *
+ * We assume that @slave was already detached from the slave list.
+ *
+ * If @slave's permanent hw address is different both from its current
+ * address and from @bond's address, then somewhere in the bond there's
+ * a slave that has @slave's permanet address as its current address.
+ * We'll make sure that that slave no longer uses @slave's permanent address.
+ *
+ * Caller must hold RTNL and no other locks
+ */
+static void alb_change_hw_addr_on_detach(struct bonding *bond, struct slave *slave)
+{
+	int perm_curr_diff;
+	int perm_bond_diff;
+	struct slave *found_slave;
+
+	perm_curr_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
+						  slave->dev->dev_addr);
+	perm_bond_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
+						  bond->dev->dev_addr);
+
+	if (perm_curr_diff && perm_bond_diff) {
+		found_slave = bond_slave_has_mac(bond, slave->perm_hwaddr);
+
+		if (found_slave) {
+			alb_swap_mac_addr(slave, found_slave);
+			alb_fasten_mac_swap(bond, slave, found_slave);
+		}
+	}
+}
+
+/**
+ * alb_handle_addr_collision_on_attach
+ * @bond: bonding we're working on
+ * @slave: the slave that was just attached
+ *
+ * checks uniqueness of slave's mac address and handles the case the
+ * new slave uses the bonds mac address.
+ *
+ * If the permanent hw address of @slave is @bond's hw address, we need to
+ * find a different hw address to give @slave, that isn't in use by any other
+ * slave in the bond. This address must be, of course, one of the permanent
+ * addresses of the other slaves.
+ *
+ * We go over the slave list, and for each slave there we compare its
+ * permanent hw address with the current address of all the other slaves.
+ * If no match was found, then we've found a slave with a permanent address
+ * that isn't used by any other slave in the bond, so we can assign it to
+ * @slave.
+ *
+ * assumption: this function is called before @slave is attached to the
+ *	       bond slave list.
+ */
+static int alb_handle_addr_collision_on_attach(struct bonding *bond, struct slave *slave)
+{
+	struct slave *has_bond_addr = rcu_access_pointer(bond->curr_active_slave);
+	struct slave *tmp_slave1, *free_mac_slave = NULL;
+	struct list_head *iter;
+
+	if (!bond_has_slaves(bond)) {
+		/* this is the first slave */
+		return 0;
+	}
+
+	/* if slave's mac address differs from bond's mac address
+	 * check uniqueness of slave's mac address against the other
+	 * slaves in the bond.
+	 */
+	if (!ether_addr_equal_64bits(slave->perm_hwaddr, bond->dev->dev_addr)) {
+		if (!bond_slave_has_mac(bond, slave->dev->dev_addr))
+			return 0;
+
+		/* Try setting slave mac to bond address and fall-through
+		 * to code handling that situation below...
+		 */
+		alb_set_slave_mac_addr(slave, bond->dev->dev_addr,
+				       bond->dev->addr_len);
+	}
+
+	/* The slave's address is equal to the address of the bond.
+	 * Search for a spare address in the bond for this slave.
+	 */
+	bond_for_each_slave(bond, tmp_slave1, iter) {
+		if (!bond_slave_has_mac(bond, tmp_slave1->perm_hwaddr)) {
+			/* no slave has tmp_slave1's perm addr
+			 * as its curr addr
+			 */
+			free_mac_slave = tmp_slave1;
+			break;
+		}
+
+		if (!has_bond_addr) {
+			if (ether_addr_equal_64bits(tmp_slave1->dev->dev_addr,
+						    bond->dev->dev_addr)) {
+
+				has_bond_addr = tmp_slave1;
+			}
+		}
+	}
+
+	if (free_mac_slave) {
+		alb_set_slave_mac_addr(slave, free_mac_slave->perm_hwaddr,
+				       free_mac_slave->dev->addr_len);
+
+		netdev_warn(bond->dev, "the hw address of slave %s is in use by the bond; giving it the hw address of %s\n",
+			    slave->dev->name, free_mac_slave->dev->name);
+
+	} else if (has_bond_addr) {
+		netdev_err(bond->dev, "the hw address of slave %s is in use by the bond; couldn't find a slave with a free hw address to give it (this should not have happened)\n",
+			   slave->dev->name);
+		return -EFAULT;
+	}
+
+	return 0;
+}
+
+/**
+ * alb_set_mac_address
+ * @bond:
+ * @addr:
+ *
+ * In TLB mode all slaves are configured to the bond's hw address, but set
+ * their dev_addr field to different addresses (based on their permanent hw
+ * addresses).
+ *
+ * For each slave, this function sets the interface to the new address and then
+ * changes its dev_addr field to its previous value.
+ *
+ * Unwinding assumes bond's mac address has not yet changed.
+ */
+static int alb_set_mac_address(struct bonding *bond, void *addr)
+{
+	struct slave *slave, *rollback_slave;
+	struct list_head *iter;
+	struct sockaddr_storage ss;
+	char tmp_addr[MAX_ADDR_LEN];
+	int res;
+
+	if (bond->alb_info.rlb_enabled)
+		return 0;
+
+	bond_for_each_slave(bond, slave, iter) {
+		/* save net_device's current hw address */
+		bond_hw_addr_copy(tmp_addr, slave->dev->dev_addr,
+				  slave->dev->addr_len);
+
+		res = dev_set_mac_address(slave->dev, addr);
+
+		/* restore net_device's hw address */
+		bond_hw_addr_copy(slave->dev->dev_addr, tmp_addr,
+				  slave->dev->addr_len);
+
+		if (res)
+			goto unwind;
+	}
+
+	return 0;
+
+unwind:
+	memcpy(ss.__data, bond->dev->dev_addr, bond->dev->addr_len);
+	ss.ss_family = bond->dev->type;
+
+	/* unwind from head to the slave that failed */
+	bond_for_each_slave(bond, rollback_slave, iter) {
+		if (rollback_slave == slave)
+			break;
+		bond_hw_addr_copy(tmp_addr, rollback_slave->dev->dev_addr,
+				  rollback_slave->dev->addr_len);
+		dev_set_mac_address(rollback_slave->dev,
+				    (struct sockaddr *)&ss);
+		bond_hw_addr_copy(rollback_slave->dev->dev_addr, tmp_addr,
+				  rollback_slave->dev->addr_len);
+	}
+
+	return res;
+}
+
+/************************ exported alb funcions ************************/
+
+int bond_alb_initialize(struct bonding *bond, int rlb_enabled)
+{
+	int res;
+
+	res = tlb_initialize(bond);
+	if (res)
+		return res;
+
+	if (rlb_enabled) {
+		bond->alb_info.rlb_enabled = 1;
+		res = rlb_initialize(bond);
+		if (res) {
+			tlb_deinitialize(bond);
+			return res;
+		}
+	} else {
+		bond->alb_info.rlb_enabled = 0;
+	}
+
+	return 0;
+}
+
+void bond_alb_deinitialize(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+
+	tlb_deinitialize(bond);
+
+	if (bond_info->rlb_enabled)
+		rlb_deinitialize(bond);
+}
+
+static netdev_tx_t bond_do_alb_xmit(struct sk_buff *skb, struct bonding *bond,
+				    struct slave *tx_slave)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct ethhdr *eth_data = eth_hdr(skb);
+
+	if (!tx_slave) {
+		/* unbalanced or unassigned, send through primary */
+		tx_slave = rcu_dereference(bond->curr_active_slave);
+		if (bond->params.tlb_dynamic_lb)
+			bond_info->unbalanced_load += skb->len;
+	}
+
+	if (tx_slave && bond_slave_can_tx(tx_slave)) {
+		if (tx_slave != rcu_access_pointer(bond->curr_active_slave)) {
+			ether_addr_copy(eth_data->h_source,
+					tx_slave->dev->dev_addr);
+		}
+
+		bond_dev_queue_xmit(bond, skb, tx_slave->dev);
+		goto out;
+	}
+
+	if (tx_slave && bond->params.tlb_dynamic_lb) {
+		spin_lock(&bond->mode_lock);
+		__tlb_clear_slave(bond, tx_slave, 0);
+		spin_unlock(&bond->mode_lock);
+	}
+
+	/* no suitable interface, frame not sent */
+	bond_tx_drop(bond->dev, skb);
+out:
+	return NETDEV_TX_OK;
+}
+
+netdev_tx_t bond_tlb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct ethhdr *eth_data;
+	struct slave *tx_slave = NULL;
+	u32 hash_index;
+
+	skb_reset_mac_header(skb);
+	eth_data = eth_hdr(skb);
+
+	/* Do not TX balance any multicast or broadcast */
+	if (!is_multicast_ether_addr(eth_data->h_dest)) {
+		switch (skb->protocol) {
+		case htons(ETH_P_IP):
+		case htons(ETH_P_IPX):
+		    /* In case of IPX, it will falback to L2 hash */
+		case htons(ETH_P_IPV6):
+			hash_index = bond_xmit_hash(bond, skb);
+			if (bond->params.tlb_dynamic_lb) {
+				tx_slave = tlb_choose_channel(bond,
+							      hash_index & 0xFF,
+							      skb->len);
+			} else {
+				struct bond_up_slave *slaves;
+				unsigned int count;
+
+				slaves = rcu_dereference(bond->slave_arr);
+				count = slaves ? READ_ONCE(slaves->count) : 0;
+				if (likely(count))
+					tx_slave = slaves->arr[hash_index %
+							       count];
+			}
+			break;
+		}
+	}
+	return bond_do_alb_xmit(skb, bond, tx_slave);
+}
+
+netdev_tx_t bond_alb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct ethhdr *eth_data;
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct slave *tx_slave = NULL;
+	static const __be32 ip_bcast = htonl(0xffffffff);
+	int hash_size = 0;
+	bool do_tx_balance = true;
+	u32 hash_index = 0;
+	const u8 *hash_start = NULL;
+
+	skb_reset_mac_header(skb);
+	eth_data = eth_hdr(skb);
+
+	switch (ntohs(skb->protocol)) {
+	case ETH_P_IP: {
+		const struct iphdr *iph;
+
+		if (is_broadcast_ether_addr(eth_data->h_dest) ||
+		    !pskb_network_may_pull(skb, sizeof(*iph))) {
+			do_tx_balance = false;
+			break;
+		}
+		iph = ip_hdr(skb);
+		if (iph->daddr == ip_bcast || iph->protocol == IPPROTO_IGMP) {
+			do_tx_balance = false;
+			break;
+		}
+		hash_start = (char *)&(iph->daddr);
+		hash_size = sizeof(iph->daddr);
+		break;
+	}
+	case ETH_P_IPV6: {
+		const struct ipv6hdr *ip6hdr;
+
+		/* IPv6 doesn't really use broadcast mac address, but leave
+		 * that here just in case.
+		 */
+		if (is_broadcast_ether_addr(eth_data->h_dest)) {
+			do_tx_balance = false;
+			break;
+		}
+
+		/* IPv6 uses all-nodes multicast as an equivalent to
+		 * broadcasts in IPv4.
+		 */
+		if (ether_addr_equal_64bits(eth_data->h_dest, mac_v6_allmcast)) {
+			do_tx_balance = false;
+			break;
+		}
+
+		if (!pskb_network_may_pull(skb, sizeof(*ip6hdr))) {
+			do_tx_balance = false;
+			break;
+		}
+		/* Additionally, DAD probes should not be tx-balanced as that
+		 * will lead to false positives for duplicate addresses and
+		 * prevent address configuration from working.
+		 */
+		ip6hdr = ipv6_hdr(skb);
+		if (ipv6_addr_any(&ip6hdr->saddr)) {
+			do_tx_balance = false;
+			break;
+		}
+
+		hash_start = (char *)&ip6hdr->daddr;
+		hash_size = sizeof(ip6hdr->daddr);
+		break;
+	}
+	case ETH_P_IPX: {
+		const struct ipxhdr *ipxhdr;
+
+		if (pskb_network_may_pull(skb, sizeof(*ipxhdr))) {
+			do_tx_balance = false;
+			break;
+		}
+		ipxhdr = (struct ipxhdr *)skb_network_header(skb);
+
+		if (ipxhdr->ipx_checksum != IPX_NO_CHECKSUM) {
+			/* something is wrong with this packet */
+			do_tx_balance = false;
+			break;
+		}
+
+		if (ipxhdr->ipx_type != IPX_TYPE_NCP) {
+			/* The only protocol worth balancing in
+			 * this family since it has an "ARP" like
+			 * mechanism
+			 */
+			do_tx_balance = false;
+			break;
+		}
+
+		eth_data = eth_hdr(skb);
+		hash_start = (char *)eth_data->h_dest;
+		hash_size = ETH_ALEN;
+		break;
+	}
+	case ETH_P_ARP:
+		do_tx_balance = false;
+		if (bond_info->rlb_enabled)
+			tx_slave = rlb_arp_xmit(skb, bond);
+		break;
+	default:
+		do_tx_balance = false;
+		break;
+	}
+
+	if (do_tx_balance) {
+		if (bond->params.tlb_dynamic_lb) {
+			hash_index = _simple_hash(hash_start, hash_size);
+			tx_slave = tlb_choose_channel(bond, hash_index, skb->len);
+		} else {
+			/*
+			 * do_tx_balance means we are free to select the tx_slave
+			 * So we do exactly what tlb would do for hash selection
+			 */
+
+			struct bond_up_slave *slaves;
+			unsigned int count;
+
+			slaves = rcu_dereference(bond->slave_arr);
+			count = slaves ? READ_ONCE(slaves->count) : 0;
+			if (likely(count))
+				tx_slave = slaves->arr[bond_xmit_hash(bond, skb) %
+						       count];
+		}
+	}
+
+	return bond_do_alb_xmit(skb, bond, tx_slave);
+}
+
+void bond_alb_monitor(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    alb_work.work);
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct list_head *iter;
+	struct slave *slave;
+
+	if (!bond_has_slaves(bond)) {
+		bond_info->tx_rebalance_counter = 0;
+		bond_info->lp_counter = 0;
+		goto re_arm;
+	}
+
+	rcu_read_lock();
+
+	bond_info->tx_rebalance_counter++;
+	bond_info->lp_counter++;
+
+	/* send learning packets */
+	if (bond_info->lp_counter >= BOND_ALB_LP_TICKS(bond)) {
+		bool strict_match;
+
+		bond_for_each_slave_rcu(bond, slave, iter) {
+			/* If updating current_active, use all currently
+			 * user mac addreses (!strict_match).  Otherwise, only
+			 * use mac of the slave device.
+			 * In RLB mode, we always use strict matches.
+			 */
+			strict_match = (slave != rcu_access_pointer(bond->curr_active_slave) ||
+					bond_info->rlb_enabled);
+			alb_send_learning_packets(slave, slave->dev->dev_addr,
+						  strict_match);
+		}
+		bond_info->lp_counter = 0;
+	}
+
+	/* rebalance tx traffic */
+	if (bond_info->tx_rebalance_counter >= BOND_TLB_REBALANCE_TICKS) {
+		bond_for_each_slave_rcu(bond, slave, iter) {
+			tlb_clear_slave(bond, slave, 1);
+			if (slave == rcu_access_pointer(bond->curr_active_slave)) {
+				SLAVE_TLB_INFO(slave).load =
+					bond_info->unbalanced_load /
+						BOND_TLB_REBALANCE_INTERVAL;
+				bond_info->unbalanced_load = 0;
+			}
+		}
+		bond_info->tx_rebalance_counter = 0;
+	}
+
+	if (bond_info->rlb_enabled) {
+		if (bond_info->primary_is_promisc &&
+		    (++bond_info->rlb_promisc_timeout_counter >= RLB_PROMISC_TIMEOUT)) {
+
+			/* dev_set_promiscuity requires rtnl and
+			 * nothing else.  Avoid race with bond_close.
+			 */
+			rcu_read_unlock();
+			if (!rtnl_trylock())
+				goto re_arm;
+
+			bond_info->rlb_promisc_timeout_counter = 0;
+
+			/* If the primary was set to promiscuous mode
+			 * because a slave was disabled then
+			 * it can now leave promiscuous mode.
+			 */
+			dev_set_promiscuity(rtnl_dereference(bond->curr_active_slave)->dev,
+					    -1);
+			bond_info->primary_is_promisc = 0;
+
+			rtnl_unlock();
+			rcu_read_lock();
+		}
+
+		if (bond_info->rlb_rebalance) {
+			bond_info->rlb_rebalance = 0;
+			rlb_rebalance(bond);
+		}
+
+		/* check if clients need updating */
+		if (bond_info->rx_ntt) {
+			if (bond_info->rlb_update_delay_counter) {
+				--bond_info->rlb_update_delay_counter;
+			} else {
+				rlb_update_rx_clients(bond);
+				if (bond_info->rlb_update_retry_counter)
+					--bond_info->rlb_update_retry_counter;
+				else
+					bond_info->rx_ntt = 0;
+			}
+		}
+	}
+	rcu_read_unlock();
+re_arm:
+	queue_delayed_work(bond->wq, &bond->alb_work, alb_delta_in_ticks);
+}
+
+/* assumption: called before the slave is attached to the bond
+ * and not locked by the bond lock
+ */
+int bond_alb_init_slave(struct bonding *bond, struct slave *slave)
+{
+	int res;
+
+	res = alb_set_slave_mac_addr(slave, slave->perm_hwaddr,
+				     slave->dev->addr_len);
+	if (res)
+		return res;
+
+	res = alb_handle_addr_collision_on_attach(bond, slave);
+	if (res)
+		return res;
+
+	tlb_init_slave(slave);
+
+	/* order a rebalance ASAP */
+	bond->alb_info.tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
+
+	if (bond->alb_info.rlb_enabled)
+		bond->alb_info.rlb_rebalance = 1;
+
+	return 0;
+}
+
+/* Remove slave from tlb and rlb hash tables, and fix up MAC addresses
+ * if necessary.
+ *
+ * Caller must hold RTNL and no other locks
+ */
+void bond_alb_deinit_slave(struct bonding *bond, struct slave *slave)
+{
+	if (bond_has_slaves(bond))
+		alb_change_hw_addr_on_detach(bond, slave);
+
+	tlb_clear_slave(bond, slave, 0);
+
+	if (bond->alb_info.rlb_enabled) {
+		bond->alb_info.rx_slave = NULL;
+		rlb_clear_slave(bond, slave);
+	}
+
+}
+
+void bond_alb_handle_link_change(struct bonding *bond, struct slave *slave, char link)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+
+	if (link == BOND_LINK_DOWN) {
+		tlb_clear_slave(bond, slave, 0);
+		if (bond->alb_info.rlb_enabled)
+			rlb_clear_slave(bond, slave);
+	} else if (link == BOND_LINK_UP) {
+		/* order a rebalance ASAP */
+		bond_info->tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
+		if (bond->alb_info.rlb_enabled) {
+			bond->alb_info.rlb_rebalance = 1;
+			/* If the updelay module parameter is smaller than the
+			 * forwarding delay of the switch the rebalance will
+			 * not work because the rebalance arp replies will
+			 * not be forwarded to the clients..
+			 */
+		}
+	}
+
+	if (bond_is_nondyn_tlb(bond)) {
+		if (bond_update_slave_arr(bond, NULL))
+			pr_err("Failed to build slave-array for TLB mode.\n");
+	}
+}
+
+/**
+ * bond_alb_handle_active_change - assign new curr_active_slave
+ * @bond: our bonding struct
+ * @new_slave: new slave to assign
+ *
+ * Set the bond->curr_active_slave to @new_slave and handle
+ * mac address swapping and promiscuity changes as needed.
+ *
+ * Caller must hold RTNL
+ */
+void bond_alb_handle_active_change(struct bonding *bond, struct slave *new_slave)
+{
+	struct slave *swap_slave;
+	struct slave *curr_active;
+
+	curr_active = rtnl_dereference(bond->curr_active_slave);
+	if (curr_active == new_slave)
+		return;
+
+	if (curr_active && bond->alb_info.primary_is_promisc) {
+		dev_set_promiscuity(curr_active->dev, -1);
+		bond->alb_info.primary_is_promisc = 0;
+		bond->alb_info.rlb_promisc_timeout_counter = 0;
+	}
+
+	swap_slave = curr_active;
+	rcu_assign_pointer(bond->curr_active_slave, new_slave);
+
+	if (!new_slave || !bond_has_slaves(bond))
+		return;
+
+	/* set the new curr_active_slave to the bonds mac address
+	 * i.e. swap mac addresses of old curr_active_slave and new curr_active_slave
+	 */
+	if (!swap_slave)
+		swap_slave = bond_slave_has_mac(bond, bond->dev->dev_addr);
+
+	/* Arrange for swap_slave and new_slave to temporarily be
+	 * ignored so we can mess with their MAC addresses without
+	 * fear of interference from transmit activity.
+	 */
+	if (swap_slave)
+		tlb_clear_slave(bond, swap_slave, 1);
+	tlb_clear_slave(bond, new_slave, 1);
+
+	/* in TLB mode, the slave might flip down/up with the old dev_addr,
+	 * and thus filter bond->dev_addr's packets, so force bond's mac
+	 */
+	if (BOND_MODE(bond) == BOND_MODE_TLB) {
+		struct sockaddr_storage ss;
+		u8 tmp_addr[MAX_ADDR_LEN];
+
+		bond_hw_addr_copy(tmp_addr, new_slave->dev->dev_addr,
+				  new_slave->dev->addr_len);
+
+		bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
+				  bond->dev->addr_len);
+		ss.ss_family = bond->dev->type;
+		/* we don't care if it can't change its mac, best effort */
+		dev_set_mac_address(new_slave->dev, (struct sockaddr *)&ss);
+
+		bond_hw_addr_copy(new_slave->dev->dev_addr, tmp_addr,
+				  new_slave->dev->addr_len);
+	}
+
+	/* curr_active_slave must be set before calling alb_swap_mac_addr */
+	if (swap_slave) {
+		/* swap mac address */
+		alb_swap_mac_addr(swap_slave, new_slave);
+		alb_fasten_mac_swap(bond, swap_slave, new_slave);
+	} else {
+		/* set the new_slave to the bond mac address */
+		alb_set_slave_mac_addr(new_slave, bond->dev->dev_addr,
+				       bond->dev->addr_len);
+		alb_send_learning_packets(new_slave, bond->dev->dev_addr,
+					  false);
+	}
+}
+
+/* Called with RTNL */
+int bond_alb_set_mac_address(struct net_device *bond_dev, void *addr)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct sockaddr_storage *ss = addr;
+	struct slave *curr_active;
+	struct slave *swap_slave;
+	int res;
+
+	if (!is_valid_ether_addr(ss->__data))
+		return -EADDRNOTAVAIL;
+
+	res = alb_set_mac_address(bond, addr);
+	if (res)
+		return res;
+
+	bond_hw_addr_copy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
+
+	/* If there is no curr_active_slave there is nothing else to do.
+	 * Otherwise we'll need to pass the new address to it and handle
+	 * duplications.
+	 */
+	curr_active = rtnl_dereference(bond->curr_active_slave);
+	if (!curr_active)
+		return 0;
+
+	swap_slave = bond_slave_has_mac(bond, bond_dev->dev_addr);
+
+	if (swap_slave) {
+		alb_swap_mac_addr(swap_slave, curr_active);
+		alb_fasten_mac_swap(bond, swap_slave, curr_active);
+	} else {
+		alb_set_slave_mac_addr(curr_active, bond_dev->dev_addr,
+				       bond_dev->addr_len);
+
+		alb_send_learning_packets(curr_active,
+					  bond_dev->dev_addr, false);
+		if (bond->alb_info.rlb_enabled) {
+			/* inform clients mac address has changed */
+			rlb_req_update_slave_clients(bond, curr_active);
+		}
+	}
+
+	return 0;
+}
+
+void bond_alb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
+{
+	if (bond->alb_info.rlb_enabled)
+		rlb_clear_vlan(bond, vlan_id);
+}
+
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.103/bond_debugfs.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.103/bond_debugfs.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,142 @@
+// SPDX-License-Identifier: GPL-2.0
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/netdevice.h>
+
+#include <net/bonding.h>
+#include <net/bond_alb.h>
+
+#if defined(CONFIG_DEBUG_FS) && !defined(CONFIG_NET_NS)
+
+#include <linux/debugfs.h>
+#include <linux/seq_file.h>
+
+static struct dentry *bonding_debug_root;
+
+/* Show RLB hash table */
+static int bond_debug_rlb_hash_show(struct seq_file *m, void *v)
+{
+	struct bonding *bond = m->private;
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *client_info;
+	u32 hash_index;
+
+	if (BOND_MODE(bond) != BOND_MODE_ALB)
+		return 0;
+
+	seq_printf(m, "SourceIP        DestinationIP   "
+			"Destination MAC   DEV\n");
+
+	spin_lock_bh(&bond->mode_lock);
+
+	hash_index = bond_info->rx_hashtbl_used_head;
+	for (; hash_index != RLB_NULL_INDEX;
+	     hash_index = client_info->used_next) {
+		client_info = &(bond_info->rx_hashtbl[hash_index]);
+		seq_printf(m, "%-15pI4 %-15pI4 %-17pM %s\n",
+			&client_info->ip_src,
+			&client_info->ip_dst,
+			&client_info->mac_dst,
+			client_info->slave->dev->name);
+	}
+
+	spin_unlock_bh(&bond->mode_lock);
+
+	return 0;
+}
+
+static int bond_debug_rlb_hash_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, bond_debug_rlb_hash_show, inode->i_private);
+}
+
+static const struct file_operations bond_debug_rlb_hash_fops = {
+	.owner		= THIS_MODULE,
+	.open		= bond_debug_rlb_hash_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+void bond_debug_register(struct bonding *bond)
+{
+	if (!bonding_debug_root)
+		return;
+
+	bond->debug_dir =
+		debugfs_create_dir(bond->dev->name, bonding_debug_root);
+
+	if (!bond->debug_dir) {
+		netdev_warn(bond->dev, "failed to register to debugfs\n");
+		return;
+	}
+
+	debugfs_create_file("rlb_hash_table", 0400, bond->debug_dir,
+				bond, &bond_debug_rlb_hash_fops);
+}
+
+void bond_debug_unregister(struct bonding *bond)
+{
+	if (!bonding_debug_root)
+		return;
+
+	debugfs_remove_recursive(bond->debug_dir);
+}
+
+void bond_debug_reregister(struct bonding *bond)
+{
+	struct dentry *d;
+
+	if (!bonding_debug_root)
+		return;
+
+	d = debugfs_rename(bonding_debug_root, bond->debug_dir,
+			   bonding_debug_root, bond->dev->name);
+	if (d) {
+		bond->debug_dir = d;
+	} else {
+		netdev_warn(bond->dev, "failed to reregister, so just unregister old one\n");
+		bond_debug_unregister(bond);
+	}
+}
+
+void bond_create_debugfs(void)
+{
+	bonding_debug_root = debugfs_create_dir("bonding", NULL);
+
+	if (!bonding_debug_root) {
+		pr_warn("Warning: Cannot create bonding directory in debugfs\n");
+	}
+}
+
+void bond_destroy_debugfs(void)
+{
+	debugfs_remove_recursive(bonding_debug_root);
+	bonding_debug_root = NULL;
+}
+
+
+#else /* !CONFIG_DEBUG_FS */
+
+void bond_debug_register(struct bonding *bond)
+{
+}
+
+void bond_debug_unregister(struct bonding *bond)
+{
+}
+
+void bond_debug_reregister(struct bonding *bond)
+{
+}
+
+void bond_create_debugfs(void)
+{
+}
+
+void bond_destroy_debugfs(void)
+{
+}
+
+#endif /* CONFIG_DEBUG_FS */
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.103/bond_main.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.103/bond_main.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,5037 @@
+/*
+ * originally based on the dummy device.
+ *
+ * Copyright 1999, Thomas Davis, tadavis@lbl.gov.
+ * Licensed under the GPL. Based on dummy.c, and eql.c devices.
+ *
+ * bonding.c: an Ethernet Bonding driver
+ *
+ * This is useful to talk to a Cisco EtherChannel compatible equipment:
+ *	Cisco 5500
+ *	Sun Trunking (Solaris)
+ *	Alteon AceDirector Trunks
+ *	Linux Bonding
+ *	and probably many L2 switches ...
+ *
+ * How it works:
+ *    ifconfig bond0 ipaddress netmask up
+ *      will setup a network device, with an ip address.  No mac address
+ *	will be assigned at this time.  The hw mac address will come from
+ *	the first slave bonded to the channel.  All slaves will then use
+ *	this hw mac address.
+ *
+ *    ifconfig bond0 down
+ *         will release all slaves, marking them as down.
+ *
+ *    ifenslave bond0 eth0
+ *	will attach eth0 to bond0 as a slave.  eth0 hw mac address will either
+ *	a: be used as initial mac address
+ *	b: if a hw mac address already is there, eth0's hw mac address
+ *	   will then be set from bond0.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/fcntl.h>
+#include <linux/interrupt.h>
+#include <linux/ptrace.h>
+#include <linux/ioport.h>
+#include <linux/in.h>
+#include <net/ip.h>
+#include <linux/ip.h>
+#include <linux/tcp.h>
+#include <linux/udp.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/init.h>
+#include <linux/timer.h>
+#include <linux/socket.h>
+#include <linux/ctype.h>
+#include <linux/inet.h>
+#include <linux/bitops.h>
+#include <linux/io.h>
+#include <asm/dma.h>
+#include <linux/uaccess.h>
+#include <linux/errno.h>
+#include <linux/netdevice.h>
+#include <linux/inetdevice.h>
+#include <linux/igmp.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <net/sock.h>
+#include <linux/rtnetlink.h>
+#include <linux/smp.h>
+#include <linux/if_ether.h>
+#include <net/arp.h>
+#include <linux/mii.h>
+#include <linux/ethtool.h>
+#include <linux/if_vlan.h>
+#include <linux/if_bonding.h>
+#include <linux/jiffies.h>
+#include <linux/preempt.h>
+#include <net/route.h>
+#include <net/net_namespace.h>
+#include <net/netns/generic.h>
+#include <net/pkt_sched.h>
+#include <linux/rculist.h>
+#include <linux/toedev.h>
+#include <net/flow_dissector.h>
+#include <net/switchdev.h>
+#include <net/bonding.h>
+#include <net/bond_3ad.h>
+#include <net/bond_alb.h>
+
+#include "bonding_priv.h"
+
+/*---------------------------- Module parameters ----------------------------*/
+
+/* monitor all links that often (in milliseconds). <=0 disables monitoring */
+
+static int max_bonds	= BOND_DEFAULT_MAX_BONDS;
+static int tx_queues	= BOND_DEFAULT_TX_QUEUES;
+static int num_peer_notif = 1;
+static int miimon;
+static int updelay;
+static int downdelay;
+static int use_carrier	= 1;
+static char *mode;
+static char *primary;
+static char *primary_reselect;
+static char *lacp_rate;
+static int min_links;
+static char *ad_select;
+static char *xmit_hash_policy;
+static int arp_interval;
+static char *arp_ip_target[BOND_MAX_ARP_TARGETS];
+static char *arp_validate;
+static char *arp_all_targets;
+static char *fail_over_mac;
+static int all_slaves_active;
+static struct bond_params bonding_defaults;
+static int resend_igmp = BOND_DEFAULT_RESEND_IGMP;
+static int packets_per_slave = 1;
+static int lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
+
+module_param(max_bonds, int, 0);
+MODULE_PARM_DESC(max_bonds, "Max number of bonded devices");
+module_param(tx_queues, int, 0);
+MODULE_PARM_DESC(tx_queues, "Max number of transmit queues (default = 16)");
+module_param_named(num_grat_arp, num_peer_notif, int, 0644);
+MODULE_PARM_DESC(num_grat_arp, "Number of peer notifications to send on "
+			       "failover event (alias of num_unsol_na)");
+module_param_named(num_unsol_na, num_peer_notif, int, 0644);
+MODULE_PARM_DESC(num_unsol_na, "Number of peer notifications to send on "
+			       "failover event (alias of num_grat_arp)");
+module_param(miimon, int, 0);
+MODULE_PARM_DESC(miimon, "Link check interval in milliseconds");
+module_param(updelay, int, 0);
+MODULE_PARM_DESC(updelay, "Delay before considering link up, in milliseconds");
+module_param(downdelay, int, 0);
+MODULE_PARM_DESC(downdelay, "Delay before considering link down, "
+			    "in milliseconds");
+module_param(use_carrier, int, 0);
+MODULE_PARM_DESC(use_carrier, "Use netif_carrier_ok (vs MII ioctls) in miimon; "
+			      "0 for off, 1 for on (default)");
+module_param(mode, charp, 0);
+MODULE_PARM_DESC(mode, "Mode of operation; 0 for balance-rr, "
+		       "1 for active-backup, 2 for balance-xor, "
+		       "3 for broadcast, 4 for 802.3ad, 5 for balance-tlb, "
+		       "6 for balance-alb");
+module_param(primary, charp, 0);
+MODULE_PARM_DESC(primary, "Primary network device to use");
+module_param(primary_reselect, charp, 0);
+MODULE_PARM_DESC(primary_reselect, "Reselect primary slave "
+				   "once it comes up; "
+				   "0 for always (default), "
+				   "1 for only if speed of primary is "
+				   "better, "
+				   "2 for only on active slave "
+				   "failure");
+module_param(lacp_rate, charp, 0);
+MODULE_PARM_DESC(lacp_rate, "LACPDU tx rate to request from 802.3ad partner; "
+			    "0 for slow, 1 for fast");
+module_param(ad_select, charp, 0);
+MODULE_PARM_DESC(ad_select, "802.3ad aggregation selection logic; "
+			    "0 for stable (default), 1 for bandwidth, "
+			    "2 for count");
+module_param(min_links, int, 0);
+MODULE_PARM_DESC(min_links, "Minimum number of available links before turning on carrier");
+
+module_param(xmit_hash_policy, charp, 0);
+MODULE_PARM_DESC(xmit_hash_policy, "balance-alb, balance-tlb, balance-xor, 802.3ad hashing method; "
+				   "0 for layer 2 (default), 1 for layer 3+4, "
+				   "2 for layer 2+3, 3 for encap layer 2+3, "
+				   "4 for encap layer 3+4");
+module_param(arp_interval, int, 0);
+MODULE_PARM_DESC(arp_interval, "arp interval in milliseconds");
+module_param_array(arp_ip_target, charp, NULL, 0);
+MODULE_PARM_DESC(arp_ip_target, "arp targets in n.n.n.n form");
+module_param(arp_validate, charp, 0);
+MODULE_PARM_DESC(arp_validate, "validate src/dst of ARP probes; "
+			       "0 for none (default), 1 for active, "
+			       "2 for backup, 3 for all");
+module_param(arp_all_targets, charp, 0);
+MODULE_PARM_DESC(arp_all_targets, "fail on any/all arp targets timeout; 0 for any (default), 1 for all");
+module_param(fail_over_mac, charp, 0);
+MODULE_PARM_DESC(fail_over_mac, "For active-backup, do not set all slaves to "
+				"the same MAC; 0 for none (default), "
+				"1 for active, 2 for follow");
+module_param(all_slaves_active, int, 0);
+MODULE_PARM_DESC(all_slaves_active, "Keep all frames received on an interface "
+				     "by setting active flag for all slaves; "
+				     "0 for never (default), 1 for always.");
+module_param(resend_igmp, int, 0);
+MODULE_PARM_DESC(resend_igmp, "Number of IGMP membership reports to send on "
+			      "link failure");
+module_param(packets_per_slave, int, 0);
+MODULE_PARM_DESC(packets_per_slave, "Packets to send per slave in balance-rr "
+				    "mode; 0 for a random slave, 1 packet per "
+				    "slave (default), >1 packets per slave.");
+module_param(lp_interval, uint, 0);
+MODULE_PARM_DESC(lp_interval, "The number of seconds between instances where "
+			      "the bonding driver sends learning packets to "
+			      "each slaves peer switch. The default is 1.");
+
+/*----------------------------- Global variables ----------------------------*/
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+atomic_t netpoll_block_tx = ATOMIC_INIT(0);
+#endif
+
+unsigned int bond_net_id __read_mostly;
+
+/*-------------------------- Forward declarations ---------------------------*/
+
+static int bond_init(struct net_device *bond_dev);
+static void bond_uninit(struct net_device *bond_dev);
+static void bond_get_stats(struct net_device *bond_dev,
+			   struct rtnl_link_stats64 *stats);
+static void bond_slave_arr_handler(struct work_struct *work);
+static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
+				  int mod);
+static void bond_netdev_notify_work(struct work_struct *work);
+
+/*---------------------------- General routines -----------------------------*/
+
+const char *bond_mode_name(int mode)
+{
+	static const char *names[] = {
+		[BOND_MODE_ROUNDROBIN] = "load balancing (round-robin)",
+		[BOND_MODE_ACTIVEBACKUP] = "fault-tolerance (active-backup)",
+		[BOND_MODE_XOR] = "load balancing (xor)",
+		[BOND_MODE_BROADCAST] = "fault-tolerance (broadcast)",
+		[BOND_MODE_8023AD] = "IEEE 802.3ad Dynamic link aggregation",
+		[BOND_MODE_TLB] = "transmit load balancing",
+		[BOND_MODE_ALB] = "adaptive load balancing",
+	};
+
+	if (mode < BOND_MODE_ROUNDROBIN || mode > BOND_MODE_ALB)
+		return "unknown";
+
+	return names[mode];
+}
+
+/*---------------------------------- VLAN -----------------------------------*/
+
+/**
+ * bond_dev_queue_xmit - Prepare skb for xmit.
+ *
+ * @bond: bond device that got this skb for tx.
+ * @skb: hw accel VLAN tagged skb to transmit
+ * @slave_dev: slave that is supposed to xmit this skbuff
+ */
+void bond_dev_queue_xmit(struct bonding *bond, struct sk_buff *skb,
+			struct net_device *slave_dev)
+{
+	skb->dev = slave_dev;
+
+	BUILD_BUG_ON(sizeof(skb->queue_mapping) !=
+		     sizeof(qdisc_skb_cb(skb)->slave_dev_queue_mapping));
+	skb_set_queue_mapping(skb, qdisc_skb_cb(skb)->slave_dev_queue_mapping);
+
+	if (unlikely(netpoll_tx_running(bond->dev)))
+		bond_netpoll_send_skb(bond_get_slave_by_dev(bond, slave_dev), skb);
+	else
+		dev_queue_xmit(skb);
+}
+
+/* In the following 2 functions, bond_vlan_rx_add_vid and bond_vlan_rx_kill_vid,
+ * We don't protect the slave list iteration with a lock because:
+ * a. This operation is performed in IOCTL context,
+ * b. The operation is protected by the RTNL semaphore in the 8021q code,
+ * c. Holding a lock with BH disabled while directly calling a base driver
+ *    entry point is generally a BAD idea.
+ *
+ * The design of synchronization/protection for this operation in the 8021q
+ * module is good for one or more VLAN devices over a single physical device
+ * and cannot be extended for a teaming solution like bonding, so there is a
+ * potential race condition here where a net device from the vlan group might
+ * be referenced (either by a base driver or the 8021q code) while it is being
+ * removed from the system. However, it turns out we're not making matters
+ * worse, and if it works for regular VLAN usage it will work here too.
+*/
+
+/**
+ * bond_vlan_rx_add_vid - Propagates adding an id to slaves
+ * @bond_dev: bonding net device that got called
+ * @vid: vlan id being added
+ */
+static int bond_vlan_rx_add_vid(struct net_device *bond_dev,
+				__be16 proto, u16 vid)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave, *rollback_slave;
+	struct list_head *iter;
+	int res;
+
+	bond_for_each_slave(bond, slave, iter) {
+		res = vlan_vid_add(slave->dev, proto, vid);
+		if (res)
+			goto unwind;
+	}
+
+	return 0;
+
+unwind:
+	/* unwind to the slave that failed */
+	bond_for_each_slave(bond, rollback_slave, iter) {
+		if (rollback_slave == slave)
+			break;
+
+		vlan_vid_del(rollback_slave->dev, proto, vid);
+	}
+
+	return res;
+}
+
+/**
+ * bond_vlan_rx_kill_vid - Propagates deleting an id to slaves
+ * @bond_dev: bonding net device that got called
+ * @vid: vlan id being removed
+ */
+static int bond_vlan_rx_kill_vid(struct net_device *bond_dev,
+				 __be16 proto, u16 vid)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	struct slave *slave;
+
+	bond_for_each_slave(bond, slave, iter)
+		vlan_vid_del(slave->dev, proto, vid);
+
+	if (bond_is_lb(bond))
+		bond_alb_clear_vlan(bond, vid);
+
+	return 0;
+}
+
+/*------------------------------- Link status -------------------------------*/
+
+/* Set the carrier state for the master according to the state of its
+ * slaves.  If any slaves are up, the master is up.  In 802.3ad mode,
+ * do special 802.3ad magic.
+ *
+ * Returns zero if carrier state does not change, nonzero if it does.
+ */
+int bond_set_carrier(struct bonding *bond)
+{
+	struct list_head *iter;
+	struct slave *slave;
+
+	if (!bond_has_slaves(bond))
+		goto down;
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD)
+		return bond_3ad_set_carrier(bond);
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (slave->link == BOND_LINK_UP) {
+			if (!netif_carrier_ok(bond->dev)) {
+				netif_carrier_on(bond->dev);
+				return 1;
+			}
+			return 0;
+		}
+	}
+
+down:
+	if (netif_carrier_ok(bond->dev)) {
+		netif_carrier_off(bond->dev);
+		return 1;
+	}
+	return 0;
+}
+
+/* Get link speed and duplex from the slave's base driver
+ * using ethtool. If for some reason the call fails or the
+ * values are invalid, set speed and duplex to -1,
+ * and return. Return 1 if speed or duplex settings are
+ * UNKNOWN; 0 otherwise.
+ */
+static int bond_update_speed_duplex(struct slave *slave)
+{
+	struct net_device *slave_dev = slave->dev;
+	struct ethtool_link_ksettings ecmd;
+	int res;
+
+	slave->speed = SPEED_UNKNOWN;
+	slave->duplex = DUPLEX_UNKNOWN;
+
+	res = __ethtool_get_link_ksettings(slave_dev, &ecmd);
+	if (res < 0)
+		return 1;
+	if (ecmd.base.speed == 0 || ecmd.base.speed == ((__u32)-1))
+		return 1;
+	switch (ecmd.base.duplex) {
+	case DUPLEX_FULL:
+	case DUPLEX_HALF:
+		break;
+	default:
+		return 1;
+	}
+
+	slave->speed = ecmd.base.speed;
+	slave->duplex = ecmd.base.duplex;
+
+	return 0;
+}
+
+const char *bond_slave_link_status(s8 link)
+{
+	switch (link) {
+	case BOND_LINK_UP:
+		return "up";
+	case BOND_LINK_FAIL:
+		return "going down";
+	case BOND_LINK_DOWN:
+		return "down";
+	case BOND_LINK_BACK:
+		return "going back";
+	default:
+		return "unknown";
+	}
+}
+
+/* if <dev> supports MII link status reporting, check its link status.
+ *
+ * We either do MII/ETHTOOL ioctls, or check netif_carrier_ok(),
+ * depending upon the setting of the use_carrier parameter.
+ *
+ * Return either BMSR_LSTATUS, meaning that the link is up (or we
+ * can't tell and just pretend it is), or 0, meaning that the link is
+ * down.
+ *
+ * If reporting is non-zero, instead of faking link up, return -1 if
+ * both ETHTOOL and MII ioctls fail (meaning the device does not
+ * support them).  If use_carrier is set, return whatever it says.
+ * It'd be nice if there was a good way to tell if a driver supports
+ * netif_carrier, but there really isn't.
+ */
+static int bond_check_dev_link(struct bonding *bond,
+			       struct net_device *slave_dev, int reporting)
+{
+	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
+	int (*ioctl)(struct net_device *, struct ifreq *, int);
+	struct ifreq ifr;
+	struct mii_ioctl_data *mii;
+
+	if (!reporting && !netif_running(slave_dev))
+		return 0;
+
+	if (bond->params.use_carrier)
+		return netif_carrier_ok(slave_dev) ? BMSR_LSTATUS : 0;
+
+	/* Try to get link status using Ethtool first. */
+	if (slave_dev->ethtool_ops->get_link)
+		return slave_dev->ethtool_ops->get_link(slave_dev) ?
+			BMSR_LSTATUS : 0;
+
+	/* Ethtool can't be used, fallback to MII ioctls. */
+	ioctl = slave_ops->ndo_do_ioctl;
+	if (ioctl) {
+		/* TODO: set pointer to correct ioctl on a per team member
+		 *       bases to make this more efficient. that is, once
+		 *       we determine the correct ioctl, we will always
+		 *       call it and not the others for that team
+		 *       member.
+		 */
+
+		/* We cannot assume that SIOCGMIIPHY will also read a
+		 * register; not all network drivers (e.g., e100)
+		 * support that.
+		 */
+
+		/* Yes, the mii is overlaid on the ifreq.ifr_ifru */
+		strncpy(ifr.ifr_name, slave_dev->name, IFNAMSIZ);
+		mii = if_mii(&ifr);
+		if (ioctl(slave_dev, &ifr, SIOCGMIIPHY) == 0) {
+			mii->reg_num = MII_BMSR;
+			if (ioctl(slave_dev, &ifr, SIOCGMIIREG) == 0)
+				return mii->val_out & BMSR_LSTATUS;
+		}
+	}
+
+	/* If reporting, report that either there's no dev->do_ioctl,
+	 * or both SIOCGMIIREG and get_link failed (meaning that we
+	 * cannot report link status).  If not reporting, pretend
+	 * we're ok.
+	 */
+	return reporting ? -1 : BMSR_LSTATUS;
+}
+
+/*----------------------------- Multicast list ------------------------------*/
+
+/* Push the promiscuity flag down to appropriate slaves */
+static int bond_set_promiscuity(struct bonding *bond, int inc)
+{
+	struct list_head *iter;
+	int err = 0;
+
+	if (bond_uses_primary(bond)) {
+		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
+
+		if (curr_active)
+			err = dev_set_promiscuity(curr_active->dev, inc);
+	} else {
+		struct slave *slave;
+
+		bond_for_each_slave(bond, slave, iter) {
+			err = dev_set_promiscuity(slave->dev, inc);
+			if (err)
+				return err;
+		}
+	}
+	return err;
+}
+
+/* Push the allmulti flag down to all slaves */
+static int bond_set_allmulti(struct bonding *bond, int inc)
+{
+	struct list_head *iter;
+	int err = 0;
+
+	if (bond_uses_primary(bond)) {
+		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
+
+		if (curr_active)
+			err = dev_set_allmulti(curr_active->dev, inc);
+	} else {
+		struct slave *slave;
+
+		bond_for_each_slave(bond, slave, iter) {
+			err = dev_set_allmulti(slave->dev, inc);
+			if (err)
+				return err;
+		}
+	}
+	return err;
+}
+
+/* Retrieve the list of registered multicast addresses for the bonding
+ * device and retransmit an IGMP JOIN request to the current active
+ * slave.
+ */
+static void bond_resend_igmp_join_requests_delayed(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    mcast_work.work);
+
+	if (!rtnl_trylock()) {
+		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
+		return;
+	}
+	call_netdevice_notifiers(NETDEV_RESEND_IGMP, bond->dev);
+
+	if (bond->igmp_retrans > 1) {
+		bond->igmp_retrans--;
+		queue_delayed_work(bond->wq, &bond->mcast_work, HZ/5);
+	}
+	rtnl_unlock();
+}
+
+/* Flush bond's hardware addresses from slave */
+static void bond_hw_addr_flush(struct net_device *bond_dev,
+			       struct net_device *slave_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+
+	dev_uc_unsync(slave_dev, bond_dev);
+	dev_mc_unsync(slave_dev, bond_dev);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		/* del lacpdu mc addr from mc list */
+		u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
+
+		dev_mc_del(slave_dev, lacpdu_multicast);
+	}
+}
+
+/*--------------------------- Active slave change ---------------------------*/
+
+/* Update the hardware address list and promisc/allmulti for the new and
+ * old active slaves (if any).  Modes that are not using primary keep all
+ * slaves up date at all times; only the modes that use primary need to call
+ * this function to swap these settings during a failover.
+ */
+static void bond_hw_addr_swap(struct bonding *bond, struct slave *new_active,
+			      struct slave *old_active)
+{
+	if (old_active) {
+		if (bond->dev->flags & IFF_PROMISC)
+			dev_set_promiscuity(old_active->dev, -1);
+
+		if (bond->dev->flags & IFF_ALLMULTI)
+			dev_set_allmulti(old_active->dev, -1);
+
+		bond_hw_addr_flush(bond->dev, old_active->dev);
+	}
+
+	if (new_active) {
+		/* FIXME: Signal errors upstream. */
+		if (bond->dev->flags & IFF_PROMISC)
+			dev_set_promiscuity(new_active->dev, 1);
+
+		if (bond->dev->flags & IFF_ALLMULTI)
+			dev_set_allmulti(new_active->dev, 1);
+
+		netif_addr_lock_bh(bond->dev);
+		dev_uc_sync(new_active->dev, bond->dev);
+		dev_mc_sync(new_active->dev, bond->dev);
+		netif_addr_unlock_bh(bond->dev);
+	}
+}
+
+/**
+ * bond_set_dev_addr - clone slave's address to bond
+ * @bond_dev: bond net device
+ * @slave_dev: slave net device
+ *
+ * Should be called with RTNL held.
+ */
+static void bond_set_dev_addr(struct net_device *bond_dev,
+			      struct net_device *slave_dev)
+{
+	netdev_dbg(bond_dev, "bond_dev=%p slave_dev=%p slave_dev->name=%s slave_dev->addr_len=%d\n",
+		   bond_dev, slave_dev, slave_dev->name, slave_dev->addr_len);
+	memcpy(bond_dev->dev_addr, slave_dev->dev_addr, slave_dev->addr_len);
+	bond_dev->addr_assign_type = NET_ADDR_STOLEN;
+	call_netdevice_notifiers(NETDEV_CHANGEADDR, bond_dev);
+}
+
+static struct slave *bond_get_old_active(struct bonding *bond,
+					 struct slave *new_active)
+{
+	struct slave *slave;
+	struct list_head *iter;
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (slave == new_active)
+			continue;
+
+		if (ether_addr_equal(bond->dev->dev_addr, slave->dev->dev_addr))
+			return slave;
+	}
+
+	return NULL;
+}
+
+/* bond_do_fail_over_mac
+ *
+ * Perform special MAC address swapping for fail_over_mac settings
+ *
+ * Called with RTNL
+ */
+static void bond_do_fail_over_mac(struct bonding *bond,
+				  struct slave *new_active,
+				  struct slave *old_active)
+{
+	u8 tmp_mac[MAX_ADDR_LEN];
+	struct sockaddr_storage ss;
+	int rv;
+
+	switch (bond->params.fail_over_mac) {
+	case BOND_FOM_ACTIVE:
+		if (new_active)
+			bond_set_dev_addr(bond->dev, new_active->dev);
+		break;
+	case BOND_FOM_FOLLOW:
+		/* if new_active && old_active, swap them
+		 * if just old_active, do nothing (going to no active slave)
+		 * if just new_active, set new_active to bond's MAC
+		 */
+		if (!new_active)
+			return;
+
+		if (!old_active)
+			old_active = bond_get_old_active(bond, new_active);
+
+		if (old_active) {
+			bond_hw_addr_copy(tmp_mac, new_active->dev->dev_addr,
+					  new_active->dev->addr_len);
+			bond_hw_addr_copy(ss.__data,
+					  old_active->dev->dev_addr,
+					  old_active->dev->addr_len);
+			ss.ss_family = new_active->dev->type;
+		} else {
+			bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
+					  bond->dev->addr_len);
+			ss.ss_family = bond->dev->type;
+		}
+
+		rv = dev_set_mac_address(new_active->dev,
+					 (struct sockaddr *)&ss);
+		if (rv) {
+			netdev_err(bond->dev, "Error %d setting MAC of slave %s\n",
+				   -rv, new_active->dev->name);
+			goto out;
+		}
+
+		if (!old_active)
+			goto out;
+
+		bond_hw_addr_copy(ss.__data, tmp_mac,
+				  new_active->dev->addr_len);
+		ss.ss_family = old_active->dev->type;
+
+		rv = dev_set_mac_address(old_active->dev,
+					 (struct sockaddr *)&ss);
+		if (rv)
+			netdev_err(bond->dev, "Error %d setting MAC of slave %s\n",
+				   -rv, new_active->dev->name);
+out:
+		break;
+	default:
+		netdev_err(bond->dev, "bond_do_fail_over_mac impossible: bad policy %d\n",
+			   bond->params.fail_over_mac);
+		break;
+	}
+
+}
+
+static struct slave *bond_choose_primary_or_current(struct bonding *bond)
+{
+	struct slave *prim = rtnl_dereference(bond->primary_slave);
+	struct slave *curr = rtnl_dereference(bond->curr_active_slave);
+
+	if (!prim || prim->link != BOND_LINK_UP) {
+		if (!curr || curr->link != BOND_LINK_UP)
+			return NULL;
+		return curr;
+	}
+
+	if (bond->force_primary) {
+		bond->force_primary = false;
+		return prim;
+	}
+
+	if (!curr || curr->link != BOND_LINK_UP)
+		return prim;
+
+	/* At this point, prim and curr are both up */
+	switch (bond->params.primary_reselect) {
+	case BOND_PRI_RESELECT_ALWAYS:
+		return prim;
+	case BOND_PRI_RESELECT_BETTER:
+		if (prim->speed < curr->speed)
+			return curr;
+		if (prim->speed == curr->speed && prim->duplex <= curr->duplex)
+			return curr;
+		return prim;
+	case BOND_PRI_RESELECT_FAILURE:
+		return curr;
+	default:
+		netdev_err(bond->dev, "impossible primary_reselect %d\n",
+			   bond->params.primary_reselect);
+		return curr;
+	}
+}
+
+/**
+ * bond_find_best_slave - select the best available slave to be the active one
+ * @bond: our bonding struct
+ */
+static struct slave *bond_find_best_slave(struct bonding *bond)
+{
+	struct slave *slave, *bestslave = NULL;
+	struct list_head *iter;
+	int mintime = bond->params.updelay;
+
+	slave = bond_choose_primary_or_current(bond);
+	if (slave)
+		return slave;
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (slave->link == BOND_LINK_UP)
+			return slave;
+		if (slave->link == BOND_LINK_BACK && bond_slave_is_up(slave) &&
+		    slave->delay < mintime) {
+			mintime = slave->delay;
+			bestslave = slave;
+		}
+	}
+
+	return bestslave;
+}
+
+static bool bond_should_notify_peers(struct bonding *bond)
+{
+	struct slave *slave;
+
+	rcu_read_lock();
+	slave = rcu_dereference(bond->curr_active_slave);
+	rcu_read_unlock();
+
+	netdev_dbg(bond->dev, "bond_should_notify_peers: slave %s\n",
+		   slave ? slave->dev->name : "NULL");
+
+	if (!slave || !bond->send_peer_notif ||
+	    !netif_carrier_ok(bond->dev) ||
+	    test_bit(__LINK_STATE_LINKWATCH_PENDING, &slave->dev->state))
+		return false;
+
+	return true;
+}
+
+/**
+ * change_active_interface - change the active slave into the specified one
+ * @bond: our bonding struct
+ * @new: the new slave to make the active one
+ *
+ * Set the new slave to the bond's settings and unset them on the old
+ * curr_active_slave.
+ * Setting include flags, mc-list, promiscuity, allmulti, etc.
+ *
+ * If @new's link state is %BOND_LINK_BACK we'll set it to %BOND_LINK_UP,
+ * because it is apparently the best available slave we have, even though its
+ * updelay hasn't timed out yet.
+ *
+ * Caller must hold RTNL.
+ */
+void bond_change_active_slave(struct bonding *bond, struct slave *new_active)
+{
+	struct slave *old_active;
+
+	ASSERT_RTNL();
+
+	old_active = rtnl_dereference(bond->curr_active_slave);
+
+	if (old_active == new_active)
+		return;
+
+	if (new_active) {
+		new_active->last_link_up = jiffies;
+
+		if (new_active->link == BOND_LINK_BACK) {
+			if (bond_uses_primary(bond)) {
+				netdev_info(bond->dev, "making interface %s the new active one %d ms earlier\n",
+					    new_active->dev->name,
+					    (bond->params.updelay - new_active->delay) * bond->params.miimon);
+			}
+
+			new_active->delay = 0;
+			bond_set_slave_link_state(new_active, BOND_LINK_UP,
+						  BOND_SLAVE_NOTIFY_NOW);
+
+			if (BOND_MODE(bond) == BOND_MODE_8023AD)
+				bond_3ad_handle_link_change(new_active, BOND_LINK_UP);
+
+			if (bond_is_lb(bond))
+				bond_alb_handle_link_change(bond, new_active, BOND_LINK_UP);
+		} else {
+			if (bond_uses_primary(bond)) {
+				netdev_info(bond->dev, "making interface %s the new active one\n",
+					    new_active->dev->name);
+			}
+		}
+	}
+
+	if (bond_uses_primary(bond))
+		bond_hw_addr_swap(bond, new_active, old_active);
+
+	if (bond_is_lb(bond)) {
+		bond_alb_handle_active_change(bond, new_active);
+		if (old_active)
+			bond_set_slave_inactive_flags(old_active,
+						      BOND_SLAVE_NOTIFY_NOW);
+		if (new_active)
+			bond_set_slave_active_flags(new_active,
+						    BOND_SLAVE_NOTIFY_NOW);
+	} else {
+		rcu_assign_pointer(bond->curr_active_slave, new_active);
+	}
+
+	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP) {
+		if (old_active)
+			bond_set_slave_inactive_flags(old_active,
+						      BOND_SLAVE_NOTIFY_NOW);
+
+		if (new_active) {
+			bool should_notify_peers = false;
+
+			bond_set_slave_active_flags(new_active,
+						    BOND_SLAVE_NOTIFY_NOW);
+
+			if (bond->params.fail_over_mac)
+				bond_do_fail_over_mac(bond, new_active,
+						      old_active);
+
+			if (netif_running(bond->dev)) {
+				bond->send_peer_notif =
+					bond->params.num_peer_notif;
+				should_notify_peers =
+					bond_should_notify_peers(bond);
+			}
+
+			call_netdevice_notifiers(NETDEV_BONDING_FAILOVER, bond->dev);
+			if (should_notify_peers)
+				call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
+							 bond->dev);
+		}
+	}
+
+	/* resend IGMP joins since active slave has changed or
+	 * all were sent on curr_active_slave.
+	 * resend only if bond is brought up with the affected
+	 * bonding modes and the retransmission is enabled
+	 */
+	if (netif_running(bond->dev) && (bond->params.resend_igmp > 0) &&
+	    ((bond_uses_primary(bond) && new_active) ||
+	     BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)) {
+		bond->igmp_retrans = bond->params.resend_igmp;
+		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
+	}
+}
+
+/**
+ * bond_select_active_slave - select a new active slave, if needed
+ * @bond: our bonding struct
+ *
+ * This functions should be called when one of the following occurs:
+ * - The old curr_active_slave has been released or lost its link.
+ * - The primary_slave has got its link back.
+ * - A slave has got its link back and there's no old curr_active_slave.
+ *
+ * Caller must hold RTNL.
+ */
+void bond_select_active_slave(struct bonding *bond)
+{
+	struct slave *best_slave;
+	int rv;
+
+	ASSERT_RTNL();
+
+	best_slave = bond_find_best_slave(bond);
+	if (best_slave != rtnl_dereference(bond->curr_active_slave)) {
+		struct slave *last_slave = bond->curr_active_slave;
+
+		bond_change_active_slave(bond, best_slave);
+		toe_failover(bond->dev,
+			     bond->curr_active_slave ?
+			     bond->curr_active_slave->dev : NULL,
+			     TOE_ACTIVE_SLAVE,
+			     last_slave ? last_slave->dev : NULL);
+
+		rv = bond_set_carrier(bond);
+		if (!rv)
+			return;
+
+		if (netif_carrier_ok(bond->dev))
+			netdev_info(bond->dev, "first active interface up!\n");
+		else
+			netdev_info(bond->dev, "now running without any active interface!\n");
+	}
+}
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+static inline int slave_enable_netpoll(struct slave *slave)
+{
+	struct netpoll *np;
+	int err = 0;
+
+	np = kzalloc(sizeof(*np), GFP_KERNEL);
+	err = -ENOMEM;
+	if (!np)
+		goto out;
+
+	err = __netpoll_setup(np, slave->dev);
+	if (err) {
+		kfree(np);
+		goto out;
+	}
+	slave->np = np;
+out:
+	return err;
+}
+static inline void slave_disable_netpoll(struct slave *slave)
+{
+	struct netpoll *np = slave->np;
+
+	if (!np)
+		return;
+
+	slave->np = NULL;
+	__netpoll_free_async(np);
+}
+
+static void bond_poll_controller(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave = NULL;
+	struct list_head *iter;
+	struct ad_info ad_info;
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD)
+		if (bond_3ad_get_active_agg_info(bond, &ad_info))
+			return;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (!bond_slave_is_up(slave))
+			continue;
+
+		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+			struct aggregator *agg =
+			    SLAVE_AD_INFO(slave)->port.aggregator;
+
+			if (agg &&
+			    agg->aggregator_identifier != ad_info.aggregator_id)
+				continue;
+		}
+
+		netpoll_poll_dev(slave->dev);
+	}
+}
+
+static void bond_netpoll_cleanup(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	struct slave *slave;
+
+	bond_for_each_slave(bond, slave, iter)
+		if (bond_slave_is_up(slave))
+			slave_disable_netpoll(slave);
+}
+
+static int bond_netpoll_setup(struct net_device *dev, struct netpoll_info *ni)
+{
+	struct bonding *bond = netdev_priv(dev);
+	struct list_head *iter;
+	struct slave *slave;
+	int err = 0;
+
+	bond_for_each_slave(bond, slave, iter) {
+		err = slave_enable_netpoll(slave);
+		if (err) {
+			bond_netpoll_cleanup(dev);
+			break;
+		}
+	}
+	return err;
+}
+#else
+static inline int slave_enable_netpoll(struct slave *slave)
+{
+	return 0;
+}
+static inline void slave_disable_netpoll(struct slave *slave)
+{
+}
+static void bond_netpoll_cleanup(struct net_device *bond_dev)
+{
+}
+#endif
+
+/*---------------------------------- IOCTL ----------------------------------*/
+
+static netdev_features_t bond_fix_features(struct net_device *dev,
+					   netdev_features_t features)
+{
+	struct bonding *bond = netdev_priv(dev);
+	struct list_head *iter;
+	netdev_features_t mask;
+	struct slave *slave;
+
+	mask = features;
+
+	features &= ~NETIF_F_ONE_FOR_ALL;
+	features |= NETIF_F_ALL_FOR_ALL;
+
+	bond_for_each_slave(bond, slave, iter) {
+		features = netdev_increment_features(features,
+						     slave->dev->features,
+						     mask);
+	}
+	features = netdev_add_tso_features(features, mask);
+
+	return features;
+}
+
+#define BOND_VLAN_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
+				 NETIF_F_FRAGLIST | NETIF_F_ALL_TSO | \
+				 NETIF_F_HIGHDMA | NETIF_F_LRO)
+
+#define BOND_ENC_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
+				 NETIF_F_RXCSUM | NETIF_F_ALL_TSO)
+
+static void bond_compute_features(struct bonding *bond)
+{
+	unsigned int dst_release_flag = IFF_XMIT_DST_RELEASE |
+					IFF_XMIT_DST_RELEASE_PERM;
+	netdev_features_t vlan_features = BOND_VLAN_FEATURES;
+	netdev_features_t enc_features  = BOND_ENC_FEATURES;
+	struct net_device *bond_dev = bond->dev;
+	struct list_head *iter;
+	struct slave *slave;
+	unsigned short max_hard_header_len = ETH_HLEN;
+	unsigned int gso_max_size = GSO_MAX_SIZE;
+	u16 gso_max_segs = GSO_MAX_SEGS;
+
+	if (!bond_has_slaves(bond))
+		goto done;
+	vlan_features &= NETIF_F_ALL_FOR_ALL;
+
+	bond_for_each_slave(bond, slave, iter) {
+		vlan_features = netdev_increment_features(vlan_features,
+			slave->dev->vlan_features, BOND_VLAN_FEATURES);
+
+		enc_features = netdev_increment_features(enc_features,
+							 slave->dev->hw_enc_features,
+							 BOND_ENC_FEATURES);
+		dst_release_flag &= slave->dev->priv_flags;
+		if (slave->dev->hard_header_len > max_hard_header_len)
+			max_hard_header_len = slave->dev->hard_header_len;
+
+		gso_max_size = min(gso_max_size, slave->dev->gso_max_size);
+		gso_max_segs = min(gso_max_segs, slave->dev->gso_max_segs);
+	}
+	bond_dev->hard_header_len = max_hard_header_len;
+
+done:
+	bond_dev->vlan_features = vlan_features;
+	bond_dev->hw_enc_features = enc_features | NETIF_F_GSO_ENCAP_ALL |
+				    NETIF_F_HW_VLAN_CTAG_TX |
+				    NETIF_F_HW_VLAN_STAG_TX |
+				    NETIF_F_GSO_UDP_L4;
+	bond_dev->gso_max_segs = gso_max_segs;
+	netif_set_gso_max_size(bond_dev, gso_max_size);
+
+	bond_dev->priv_flags &= ~IFF_XMIT_DST_RELEASE;
+	if ((bond_dev->priv_flags & IFF_XMIT_DST_RELEASE_PERM) &&
+	    dst_release_flag == (IFF_XMIT_DST_RELEASE | IFF_XMIT_DST_RELEASE_PERM))
+		bond_dev->priv_flags |= IFF_XMIT_DST_RELEASE;
+
+	netdev_change_features(bond_dev);
+}
+
+static void bond_setup_by_slave(struct net_device *bond_dev,
+				struct net_device *slave_dev)
+{
+	bond_dev->header_ops	    = slave_dev->header_ops;
+
+	bond_dev->type		    = slave_dev->type;
+	bond_dev->hard_header_len   = slave_dev->hard_header_len;
+	bond_dev->addr_len	    = slave_dev->addr_len;
+
+	memcpy(bond_dev->broadcast, slave_dev->broadcast,
+		slave_dev->addr_len);
+}
+
+/* On bonding slaves other than the currently active slave, suppress
+ * duplicates except for alb non-mcast/bcast.
+ */
+static bool bond_should_deliver_exact_match(struct sk_buff *skb,
+					    struct slave *slave,
+					    struct bonding *bond)
+{
+	if (bond_is_slave_inactive(slave)) {
+		if (BOND_MODE(bond) == BOND_MODE_ALB &&
+		    skb->pkt_type != PACKET_BROADCAST &&
+		    skb->pkt_type != PACKET_MULTICAST)
+			return false;
+		return true;
+	}
+	return false;
+}
+
+static rx_handler_result_t bond_handle_frame(struct sk_buff **pskb)
+{
+	struct sk_buff *skb = *pskb;
+	struct slave *slave;
+	struct bonding *bond;
+	int (*recv_probe)(const struct sk_buff *, struct bonding *,
+			  struct slave *);
+	int ret = RX_HANDLER_ANOTHER;
+
+	skb = skb_share_check(skb, GFP_ATOMIC);
+	if (unlikely(!skb))
+		return RX_HANDLER_CONSUMED;
+
+	*pskb = skb;
+
+	slave = bond_slave_get_rcu(skb->dev);
+	bond = slave->bond;
+
+	recv_probe = READ_ONCE(bond->recv_probe);
+	if (recv_probe) {
+		ret = recv_probe(skb, bond, slave);
+		if (ret == RX_HANDLER_CONSUMED) {
+			consume_skb(skb);
+			return ret;
+		}
+	}
+
+	/*
+	 * For packets determined by bond_should_deliver_exact_match() call to
+	 * be suppressed we want to make an exception for link-local packets.
+	 * This is necessary for e.g. LLDP daemons to be able to monitor
+	 * inactive slave links without being forced to bind to them
+	 * explicitly.
+	 *
+	 * At the same time, packets that are passed to the bonding master
+	 * (including link-local ones) can have their originating interface
+	 * determined via PACKET_ORIGDEV socket option.
+	 */
+	if (bond_should_deliver_exact_match(skb, slave, bond)) {
+		if (is_link_local_ether_addr(eth_hdr(skb)->h_dest))
+			return RX_HANDLER_PASS;
+		return RX_HANDLER_EXACT;
+	}
+
+	skb->dev = bond->dev;
+
+	if (BOND_MODE(bond) == BOND_MODE_ALB &&
+	    bond->dev->priv_flags & IFF_BRIDGE_PORT &&
+	    skb->pkt_type == PACKET_HOST) {
+
+		if (unlikely(skb_cow_head(skb,
+					  skb->data - skb_mac_header(skb)))) {
+			kfree_skb(skb);
+			return RX_HANDLER_CONSUMED;
+		}
+		bond_hw_addr_copy(eth_hdr(skb)->h_dest, bond->dev->dev_addr,
+				  bond->dev->addr_len);
+	}
+
+	return ret;
+}
+
+static enum netdev_lag_tx_type bond_lag_tx_type(struct bonding *bond)
+{
+	switch (BOND_MODE(bond)) {
+	case BOND_MODE_ROUNDROBIN:
+		return NETDEV_LAG_TX_TYPE_ROUNDROBIN;
+	case BOND_MODE_ACTIVEBACKUP:
+		return NETDEV_LAG_TX_TYPE_ACTIVEBACKUP;
+	case BOND_MODE_BROADCAST:
+		return NETDEV_LAG_TX_TYPE_BROADCAST;
+	case BOND_MODE_XOR:
+	case BOND_MODE_8023AD:
+		return NETDEV_LAG_TX_TYPE_HASH;
+	default:
+		return NETDEV_LAG_TX_TYPE_UNKNOWN;
+	}
+}
+
+static enum netdev_lag_hash bond_lag_hash_type(struct bonding *bond,
+					       enum netdev_lag_tx_type type)
+{
+	if (type != NETDEV_LAG_TX_TYPE_HASH)
+		return NETDEV_LAG_HASH_NONE;
+
+	switch (bond->params.xmit_policy) {
+	case BOND_XMIT_POLICY_LAYER2:
+		return NETDEV_LAG_HASH_L2;
+	case BOND_XMIT_POLICY_LAYER34:
+		return NETDEV_LAG_HASH_L34;
+	case BOND_XMIT_POLICY_LAYER23:
+		return NETDEV_LAG_HASH_L23;
+	case BOND_XMIT_POLICY_ENCAP23:
+		return NETDEV_LAG_HASH_E23;
+	case BOND_XMIT_POLICY_ENCAP34:
+		return NETDEV_LAG_HASH_E34;
+	default:
+		return NETDEV_LAG_HASH_UNKNOWN;
+	}
+}
+
+static int bond_master_upper_dev_link(struct bonding *bond, struct slave *slave,
+				      struct netlink_ext_ack *extack)
+{
+	struct netdev_lag_upper_info lag_upper_info;
+	enum netdev_lag_tx_type type;
+
+	type = bond_lag_tx_type(bond);
+	lag_upper_info.tx_type = type;
+	lag_upper_info.hash_type = bond_lag_hash_type(bond, type);
+
+	return netdev_master_upper_dev_link(slave->dev, bond->dev, slave,
+					    &lag_upper_info, extack);
+}
+
+static void bond_upper_dev_unlink(struct bonding *bond, struct slave *slave)
+{
+	netdev_upper_dev_unlink(slave->dev, bond->dev);
+	slave->dev->flags &= ~IFF_SLAVE;
+}
+
+static struct slave *bond_alloc_slave(struct bonding *bond)
+{
+	struct slave *slave = NULL;
+
+	slave = kzalloc(sizeof(*slave), GFP_KERNEL);
+	if (!slave)
+		return NULL;
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		SLAVE_AD_INFO(slave) = kzalloc(sizeof(struct ad_slave_info),
+					       GFP_KERNEL);
+		if (!SLAVE_AD_INFO(slave)) {
+			kfree(slave);
+			return NULL;
+		}
+	}
+	INIT_DELAYED_WORK(&slave->notify_work, bond_netdev_notify_work);
+
+	return slave;
+}
+
+static void bond_free_slave(struct slave *slave)
+{
+	struct bonding *bond = bond_get_bond_by_slave(slave);
+
+	cancel_delayed_work_sync(&slave->notify_work);
+	if (BOND_MODE(bond) == BOND_MODE_8023AD)
+		kfree(SLAVE_AD_INFO(slave));
+
+	kfree(slave);
+}
+
+static void bond_fill_ifbond(struct bonding *bond, struct ifbond *info)
+{
+	info->bond_mode = BOND_MODE(bond);
+	info->miimon = bond->params.miimon;
+	info->num_slaves = bond->slave_cnt;
+}
+
+static void bond_fill_ifslave(struct slave *slave, struct ifslave *info)
+{
+	strcpy(info->slave_name, slave->dev->name);
+	info->link = slave->link;
+	info->state = bond_slave_state(slave);
+	info->link_failure_count = slave->link_failure_count;
+}
+
+static void bond_netdev_notify_work(struct work_struct *_work)
+{
+	struct slave *slave = container_of(_work, struct slave,
+					   notify_work.work);
+
+	if (rtnl_trylock()) {
+		struct netdev_bonding_info binfo;
+
+		bond_fill_ifslave(slave, &binfo.slave);
+		bond_fill_ifbond(slave->bond, &binfo.master);
+		netdev_bonding_info_change(slave->dev, &binfo);
+		rtnl_unlock();
+	} else {
+		queue_delayed_work(slave->bond->wq, &slave->notify_work, 1);
+	}
+}
+
+void bond_queue_slave_event(struct slave *slave)
+{
+	queue_delayed_work(slave->bond->wq, &slave->notify_work, 0);
+}
+
+void bond_lower_state_changed(struct slave *slave)
+{
+	struct netdev_lag_lower_state_info info;
+
+	info.link_up = slave->link == BOND_LINK_UP ||
+		       slave->link == BOND_LINK_FAIL;
+	info.tx_enabled = bond_is_active_slave(slave);
+	netdev_lower_state_changed(slave->dev, &info);
+}
+
+/* enslave device <slave> to bond device <master> */
+int bond_enslave(struct net_device *bond_dev, struct net_device *slave_dev,
+		 struct netlink_ext_ack *extack)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
+	struct slave *new_slave = NULL, *prev_slave;
+	struct sockaddr_storage ss;
+	int link_reporting;
+	int res = 0, i;
+
+	if (!bond->params.use_carrier &&
+	    slave_dev->ethtool_ops->get_link == NULL &&
+	    slave_ops->ndo_do_ioctl == NULL) {
+		netdev_warn(bond_dev, "no link monitoring support for %s\n",
+			    slave_dev->name);
+	}
+
+	/* already in-use? */
+	if (netdev_is_rx_handler_busy(slave_dev)) {
+		NL_SET_ERR_MSG(extack, "Device is in use and cannot be enslaved");
+		netdev_err(bond_dev,
+			   "Error: Device is in use and cannot be enslaved\n");
+		return -EBUSY;
+	}
+
+	if (bond_dev == slave_dev) {
+		NL_SET_ERR_MSG(extack, "Cannot enslave bond to itself.");
+		netdev_err(bond_dev, "cannot enslave bond to itself.\n");
+		return -EPERM;
+	}
+
+	/* vlan challenged mutual exclusion */
+	/* no need to lock since we're protected by rtnl_lock */
+	if (slave_dev->features & NETIF_F_VLAN_CHALLENGED) {
+		netdev_dbg(bond_dev, "%s is NETIF_F_VLAN_CHALLENGED\n",
+			   slave_dev->name);
+		if (vlan_uses_dev(bond_dev)) {
+			NL_SET_ERR_MSG(extack, "Can not enslave VLAN challenged device to VLAN enabled bond");
+			netdev_err(bond_dev, "Error: cannot enslave VLAN challenged slave %s on VLAN enabled bond %s\n",
+				   slave_dev->name, bond_dev->name);
+			return -EPERM;
+		} else {
+			netdev_warn(bond_dev, "enslaved VLAN challenged slave %s. Adding VLANs will be blocked as long as %s is part of bond %s\n",
+				    slave_dev->name, slave_dev->name,
+				    bond_dev->name);
+		}
+	} else {
+		netdev_dbg(bond_dev, "%s is !NETIF_F_VLAN_CHALLENGED\n",
+			   slave_dev->name);
+	}
+
+	/* Old ifenslave binaries are no longer supported.  These can
+	 * be identified with moderate accuracy by the state of the slave:
+	 * the current ifenslave will set the interface down prior to
+	 * enslaving it; the old ifenslave will not.
+	 */
+	if (slave_dev->flags & IFF_UP) {
+		NL_SET_ERR_MSG(extack, "Device can not be enslaved while up");
+		netdev_err(bond_dev, "%s is up - this may be due to an out of date ifenslave\n",
+			   slave_dev->name);
+		return -EPERM;
+	}
+
+	/* set bonding device ether type by slave - bonding netdevices are
+	 * created with ether_setup, so when the slave type is not ARPHRD_ETHER
+	 * there is a need to override some of the type dependent attribs/funcs.
+	 *
+	 * bond ether type mutual exclusion - don't allow slaves of dissimilar
+	 * ether type (eg ARPHRD_ETHER and ARPHRD_INFINIBAND) share the same bond
+	 */
+	if (!bond_has_slaves(bond)) {
+		if (bond_dev->type != slave_dev->type) {
+			netdev_dbg(bond_dev, "change device type from %d to %d\n",
+				   bond_dev->type, slave_dev->type);
+
+			res = call_netdevice_notifiers(NETDEV_PRE_TYPE_CHANGE,
+						       bond_dev);
+			res = notifier_to_errno(res);
+			if (res) {
+				netdev_err(bond_dev, "refused to change device type\n");
+				return -EBUSY;
+			}
+
+			/* Flush unicast and multicast addresses */
+			dev_uc_flush(bond_dev);
+			dev_mc_flush(bond_dev);
+
+			if (slave_dev->type != ARPHRD_ETHER)
+				bond_setup_by_slave(bond_dev, slave_dev);
+			else {
+				ether_setup(bond_dev);
+				bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
+			}
+
+			call_netdevice_notifiers(NETDEV_POST_TYPE_CHANGE,
+						 bond_dev);
+		}
+	} else if (bond_dev->type != slave_dev->type) {
+		NL_SET_ERR_MSG(extack, "Device type is different from other slaves");
+		netdev_err(bond_dev, "%s ether type (%d) is different from other slaves (%d), can not enslave it\n",
+			   slave_dev->name, slave_dev->type, bond_dev->type);
+		return -EINVAL;
+	}
+
+	if (slave_dev->type == ARPHRD_INFINIBAND &&
+	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
+		NL_SET_ERR_MSG(extack, "Only active-backup mode is supported for infiniband slaves");
+		netdev_warn(bond_dev, "Type (%d) supports only active-backup mode\n",
+			    slave_dev->type);
+		res = -EOPNOTSUPP;
+		goto err_undo_flags;
+	}
+
+	if (!slave_ops->ndo_set_mac_address ||
+	    slave_dev->type == ARPHRD_INFINIBAND) {
+		netdev_warn(bond_dev, "The slave device specified does not support setting the MAC address\n");
+		if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
+		    bond->params.fail_over_mac != BOND_FOM_ACTIVE) {
+			if (!bond_has_slaves(bond)) {
+				bond->params.fail_over_mac = BOND_FOM_ACTIVE;
+				netdev_warn(bond_dev, "Setting fail_over_mac to active for active-backup mode\n");
+			} else {
+				NL_SET_ERR_MSG(extack, "Slave device does not support setting the MAC address, but fail_over_mac is not set to active");
+				netdev_err(bond_dev, "The slave device specified does not support setting the MAC address, but fail_over_mac is not set to active\n");
+				res = -EOPNOTSUPP;
+				goto err_undo_flags;
+			}
+		}
+	}
+
+	call_netdevice_notifiers(NETDEV_JOIN, slave_dev);
+
+	/* If this is the first slave, then we need to set the master's hardware
+	 * address to be the same as the slave's.
+	 */
+	if (!bond_has_slaves(bond) &&
+	    bond->dev->addr_assign_type == NET_ADDR_RANDOM)
+		bond_set_dev_addr(bond->dev, slave_dev);
+
+	new_slave = bond_alloc_slave(bond);
+	if (!new_slave) {
+		res = -ENOMEM;
+		goto err_undo_flags;
+	}
+
+	new_slave->bond = bond;
+	new_slave->dev = slave_dev;
+	/* Set the new_slave's queue_id to be zero.  Queue ID mapping
+	 * is set via sysfs or module option if desired.
+	 */
+	new_slave->queue_id = 0;
+
+	/* Save slave's original mtu and then set it to match the bond */
+	new_slave->original_mtu = slave_dev->mtu;
+	res = dev_set_mtu(slave_dev, bond->dev->mtu);
+	if (res) {
+		netdev_dbg(bond_dev, "Error %d calling dev_set_mtu\n", res);
+		goto err_free;
+	}
+
+	/* Save slave's original ("permanent") mac address for modes
+	 * that need it, and for restoring it upon release, and then
+	 * set it to the master's address
+	 */
+	bond_hw_addr_copy(new_slave->perm_hwaddr, slave_dev->dev_addr,
+			  slave_dev->addr_len);
+
+	if (!bond->params.fail_over_mac ||
+	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
+		/* Set slave to master's mac address.  The application already
+		 * set the master's mac address to that of the first slave
+		 */
+		memcpy(ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
+		ss.ss_family = slave_dev->type;
+		res = dev_set_mac_address(slave_dev, (struct sockaddr *)&ss);
+		if (res) {
+			netdev_dbg(bond_dev, "Error %d calling set_mac_address\n", res);
+			goto err_restore_mtu;
+		}
+	}
+
+	/* set slave flag before open to prevent IPv6 addrconf */
+	slave_dev->flags |= IFF_SLAVE;
+
+	/* open the slave since the application closed it */
+	res = dev_open(slave_dev);
+	if (res) {
+		netdev_dbg(bond_dev, "Opening slave %s failed\n", slave_dev->name);
+		goto err_restore_mac;
+	}
+
+	slave_dev->priv_flags |= IFF_BONDING;
+	/* initialize slave stats */
+	dev_get_stats(new_slave->dev, &new_slave->slave_stats);
+
+	if (bond_is_lb(bond)) {
+		/* bond_alb_init_slave() must be called before all other stages since
+		 * it might fail and we do not want to have to undo everything
+		 */
+		res = bond_alb_init_slave(bond, new_slave);
+		if (res)
+			goto err_close;
+	}
+
+	res = vlan_vids_add_by_dev(slave_dev, bond_dev);
+	if (res) {
+		netdev_err(bond_dev, "Couldn't add bond vlan ids to %s\n",
+			   slave_dev->name);
+		goto err_close;
+	}
+
+	prev_slave = bond_last_slave(bond);
+
+	new_slave->delay = 0;
+	new_slave->link_failure_count = 0;
+
+	if (bond_update_speed_duplex(new_slave) &&
+	    bond_needs_speed_duplex(bond))
+		new_slave->link = BOND_LINK_DOWN;
+
+	new_slave->last_rx = jiffies -
+		(msecs_to_jiffies(bond->params.arp_interval) + 1);
+	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
+		new_slave->target_last_arp_rx[i] = new_slave->last_rx;
+
+	if (bond->params.miimon && !bond->params.use_carrier) {
+		link_reporting = bond_check_dev_link(bond, slave_dev, 1);
+
+		if ((link_reporting == -1) && !bond->params.arp_interval) {
+			/* miimon is set but a bonded network driver
+			 * does not support ETHTOOL/MII and
+			 * arp_interval is not set.  Note: if
+			 * use_carrier is enabled, we will never go
+			 * here (because netif_carrier is always
+			 * supported); thus, we don't need to change
+			 * the messages for netif_carrier.
+			 */
+			netdev_warn(bond_dev, "MII and ETHTOOL support not available for interface %s, and arp_interval/arp_ip_target module parameters not specified, thus bonding will not detect link failures! see bonding.txt for details\n",
+				    slave_dev->name);
+		} else if (link_reporting == -1) {
+			/* unable get link status using mii/ethtool */
+			netdev_warn(bond_dev, "can't get link status from interface %s; the network driver associated with this interface does not support MII or ETHTOOL link status reporting, thus miimon has no effect on this interface\n",
+				    slave_dev->name);
+		}
+	}
+
+	/* check for initial state */
+	new_slave->link = BOND_LINK_NOCHANGE;
+	if (bond->params.miimon) {
+		if (bond_check_dev_link(bond, slave_dev, 0) == BMSR_LSTATUS) {
+			if (bond->params.updelay) {
+				bond_set_slave_link_state(new_slave,
+							  BOND_LINK_BACK,
+							  BOND_SLAVE_NOTIFY_NOW);
+				new_slave->delay = bond->params.updelay;
+			} else {
+				bond_set_slave_link_state(new_slave,
+							  BOND_LINK_UP,
+							  BOND_SLAVE_NOTIFY_NOW);
+			}
+		} else {
+			bond_set_slave_link_state(new_slave, BOND_LINK_DOWN,
+						  BOND_SLAVE_NOTIFY_NOW);
+		}
+	} else if (bond->params.arp_interval) {
+		bond_set_slave_link_state(new_slave,
+					  (netif_carrier_ok(slave_dev) ?
+					  BOND_LINK_UP : BOND_LINK_DOWN),
+					  BOND_SLAVE_NOTIFY_NOW);
+	} else {
+		bond_set_slave_link_state(new_slave, BOND_LINK_UP,
+					  BOND_SLAVE_NOTIFY_NOW);
+	}
+
+	if (new_slave->link != BOND_LINK_DOWN)
+		new_slave->last_link_up = jiffies;
+	netdev_dbg(bond_dev, "Initial state of slave_dev is BOND_LINK_%s\n",
+		   new_slave->link == BOND_LINK_DOWN ? "DOWN" :
+		   (new_slave->link == BOND_LINK_UP ? "UP" : "BACK"));
+
+	if (bond_uses_primary(bond) && bond->params.primary[0]) {
+		/* if there is a primary slave, remember it */
+		if (strcmp(bond->params.primary, new_slave->dev->name) == 0) {
+			rcu_assign_pointer(bond->primary_slave, new_slave);
+			bond->force_primary = true;
+		}
+	}
+
+	switch (BOND_MODE(bond)) {
+	case BOND_MODE_ACTIVEBACKUP:
+		bond_set_slave_inactive_flags(new_slave,
+					      BOND_SLAVE_NOTIFY_NOW);
+		break;
+	case BOND_MODE_8023AD:
+		/* in 802.3ad mode, the internal mechanism
+		 * will activate the slaves in the selected
+		 * aggregator
+		 */
+		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
+		/* if this is the first slave */
+		if (!prev_slave) {
+			SLAVE_AD_INFO(new_slave)->id = 1;
+			/* Initialize AD with the number of times that the AD timer is called in 1 second
+			 * can be called only after the mac address of the bond is set
+			 */
+			bond_3ad_initialize(bond, 1000/AD_TIMER_INTERVAL);
+		} else {
+			SLAVE_AD_INFO(new_slave)->id =
+				SLAVE_AD_INFO(prev_slave)->id + 1;
+		}
+
+		bond_3ad_bind_slave(new_slave);
+		break;
+	case BOND_MODE_TLB:
+	case BOND_MODE_ALB:
+		bond_set_active_slave(new_slave);
+		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
+		break;
+	default:
+		netdev_dbg(bond_dev, "This slave is always active in trunk mode\n");
+
+		/* always active in trunk mode */
+		bond_set_active_slave(new_slave);
+
+		/* In trunking mode there is little meaning to curr_active_slave
+		 * anyway (it holds no special properties of the bond device),
+		 * so we can change it without calling change_active_interface()
+		 */
+		if (!rcu_access_pointer(bond->curr_active_slave) &&
+		    new_slave->link == BOND_LINK_UP)
+			rcu_assign_pointer(bond->curr_active_slave, new_slave);
+
+		break;
+	} /* switch(bond_mode) */
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	if (bond->dev->npinfo) {
+		if (slave_enable_netpoll(new_slave)) {
+			netdev_info(bond_dev, "master_dev is using netpoll, but new slave device does not support netpoll\n");
+			res = -EBUSY;
+			goto err_detach;
+		}
+	}
+#endif
+
+	if (!(bond_dev->features & NETIF_F_LRO))
+		dev_disable_lro(slave_dev);
+
+	res = netdev_rx_handler_register(slave_dev, bond_handle_frame,
+					 new_slave);
+	if (res) {
+		netdev_dbg(bond_dev, "Error %d calling netdev_rx_handler_register\n", res);
+		goto err_detach;
+	}
+
+	res = bond_master_upper_dev_link(bond, new_slave, extack);
+	if (res) {
+		netdev_dbg(bond_dev, "Error %d calling bond_master_upper_dev_link\n", res);
+		goto err_unregister;
+	}
+
+	res = bond_sysfs_slave_add(new_slave);
+	if (res) {
+		netdev_dbg(bond_dev, "Error %d calling bond_sysfs_slave_add\n", res);
+		goto err_upper_unlink;
+	}
+
+	bond->nest_level = dev_get_nest_level(bond_dev) + 1;
+
+	/* If the mode uses primary, then the following is handled by
+	 * bond_change_active_slave().
+	 */
+	if (!bond_uses_primary(bond)) {
+		/* set promiscuity level to new slave */
+		if (bond_dev->flags & IFF_PROMISC) {
+			res = dev_set_promiscuity(slave_dev, 1);
+			if (res)
+				goto err_sysfs_del;
+		}
+
+		/* set allmulti level to new slave */
+		if (bond_dev->flags & IFF_ALLMULTI) {
+			res = dev_set_allmulti(slave_dev, 1);
+			if (res) {
+				if (bond_dev->flags & IFF_PROMISC)
+					dev_set_promiscuity(slave_dev, -1);
+				goto err_sysfs_del;
+			}
+		}
+
+		netif_addr_lock_bh(bond_dev);
+		dev_mc_sync_multiple(slave_dev, bond_dev);
+		dev_uc_sync_multiple(slave_dev, bond_dev);
+		netif_addr_unlock_bh(bond_dev);
+
+		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+			/* add lacpdu mc addr to mc list */
+			u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
+
+			dev_mc_add(slave_dev, lacpdu_multicast);
+		}
+	}
+
+	bond->slave_cnt++;
+	bond_compute_features(bond);
+	bond_set_carrier(bond);
+
+	if (bond_uses_primary(bond)) {
+		block_netpoll_tx();
+		bond_select_active_slave(bond);
+		unblock_netpoll_tx();
+	}
+
+	if (bond_mode_can_use_xmit_hash(bond))
+		bond_update_slave_arr(bond, NULL);
+
+
+	netdev_info(bond_dev, "Enslaving %s as %s interface with %s link\n",
+		    slave_dev->name,
+		    bond_is_active_slave(new_slave) ? "an active" : "a backup",
+		    new_slave->link != BOND_LINK_DOWN ? "an up" : "a down");
+
+	/* enslave is successful */
+	bond_queue_slave_event(new_slave);
+	return 0;
+
+/* Undo stages on error */
+err_sysfs_del:
+	bond_sysfs_slave_del(new_slave);
+
+err_upper_unlink:
+	bond_upper_dev_unlink(bond, new_slave);
+
+err_unregister:
+	netdev_rx_handler_unregister(slave_dev);
+
+err_detach:
+	vlan_vids_del_by_dev(slave_dev, bond_dev);
+	if (rcu_access_pointer(bond->primary_slave) == new_slave)
+		RCU_INIT_POINTER(bond->primary_slave, NULL);
+	if (rcu_access_pointer(bond->curr_active_slave) == new_slave) {
+		block_netpoll_tx();
+		bond_change_active_slave(bond, NULL);
+		bond_select_active_slave(bond);
+		unblock_netpoll_tx();
+	}
+	/* either primary_slave or curr_active_slave might've changed */
+	synchronize_rcu();
+	slave_disable_netpoll(new_slave);
+
+err_close:
+	if (!netif_is_bond_master(slave_dev))
+		slave_dev->priv_flags &= ~IFF_BONDING;
+	dev_close(slave_dev);
+
+err_restore_mac:
+	slave_dev->flags &= ~IFF_SLAVE;
+	if (!bond->params.fail_over_mac ||
+	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
+		/* XXX TODO - fom follow mode needs to change master's
+		 * MAC if this slave's MAC is in use by the bond, or at
+		 * least print a warning.
+		 */
+		bond_hw_addr_copy(ss.__data, new_slave->perm_hwaddr,
+				  new_slave->dev->addr_len);
+		ss.ss_family = slave_dev->type;
+		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss);
+	}
+
+err_restore_mtu:
+	dev_set_mtu(slave_dev, new_slave->original_mtu);
+
+err_free:
+	bond_free_slave(new_slave);
+
+err_undo_flags:
+	/* Enslave of first slave has failed and we need to fix master's mac */
+	if (!bond_has_slaves(bond)) {
+		if (ether_addr_equal_64bits(bond_dev->dev_addr,
+					    slave_dev->dev_addr))
+			eth_hw_addr_random(bond_dev);
+		if (bond_dev->type != ARPHRD_ETHER) {
+			dev_close(bond_dev);
+			ether_setup(bond_dev);
+			bond_dev->flags |= IFF_MASTER;
+			bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
+		}
+	}
+
+	return res;
+}
+
+/* Try to release the slave device <slave> from the bond device <master>
+ * It is legal to access curr_active_slave without a lock because all the function
+ * is RTNL-locked. If "all" is true it means that the function is being called
+ * while destroying a bond interface and all slaves are being released.
+ *
+ * The rules for slave state should be:
+ *   for Active/Backup:
+ *     Active stays on all backups go down
+ *   for Bonded connections:
+ *     The first up interface should be left on and all others downed.
+ */
+static int __bond_release_one(struct net_device *bond_dev,
+			      struct net_device *slave_dev,
+			      bool all, bool unregister)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave, *oldcurrent;
+	struct sockaddr_storage ss;
+	int old_flags = bond_dev->flags;
+	netdev_features_t old_features = bond_dev->features;
+
+	/* slave is not a slave or master is not master of this slave */
+	if (!(slave_dev->flags & IFF_SLAVE) ||
+	    !netdev_has_upper_dev(slave_dev, bond_dev)) {
+		netdev_dbg(bond_dev, "cannot release %s\n",
+			   slave_dev->name);
+		return -EINVAL;
+	}
+
+	block_netpoll_tx();
+
+	slave = bond_get_slave_by_dev(bond, slave_dev);
+	if (!slave) {
+		/* not a slave of this bond */
+		netdev_info(bond_dev, "%s not enslaved\n",
+			    slave_dev->name);
+		unblock_netpoll_tx();
+		return -EINVAL;
+	}
+
+	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
+
+	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
+
+	bond_sysfs_slave_del(slave);
+
+	/* recompute stats just before removing the slave */
+	bond_get_stats(bond->dev, &bond->bond_stats);
+
+	bond_upper_dev_unlink(bond, slave);
+	/* unregister rx_handler early so bond_handle_frame wouldn't be called
+	 * for this slave anymore.
+	 */
+	netdev_rx_handler_unregister(slave_dev);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD)
+		bond_3ad_unbind_slave(slave);
+
+	if (bond_mode_can_use_xmit_hash(bond))
+		bond_update_slave_arr(bond, slave);
+
+	netdev_info(bond_dev, "Releasing %s interface %s\n",
+		    bond_is_active_slave(slave) ? "active" : "backup",
+		    slave_dev->name);
+
+	oldcurrent = rcu_access_pointer(bond->curr_active_slave);
+
+	RCU_INIT_POINTER(bond->current_arp_slave, NULL);
+
+	if (!all && (!bond->params.fail_over_mac ||
+		     BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP)) {
+		if (ether_addr_equal_64bits(bond_dev->dev_addr, slave->perm_hwaddr) &&
+		    bond_has_slaves(bond))
+			netdev_warn(bond_dev, "the permanent HWaddr of %s - %pM - is still in use by %s - set the HWaddr of %s to a different address to avoid conflicts\n",
+				    slave_dev->name, slave->perm_hwaddr,
+				    bond_dev->name, slave_dev->name);
+	}
+
+	if (rtnl_dereference(bond->primary_slave) == slave)
+		RCU_INIT_POINTER(bond->primary_slave, NULL);
+
+	if (oldcurrent == slave)
+		bond_change_active_slave(bond, NULL);
+
+	if (bond_is_lb(bond)) {
+		/* Must be called only after the slave has been
+		 * detached from the list and the curr_active_slave
+		 * has been cleared (if our_slave == old_current),
+		 * but before a new active slave is selected.
+		 */
+		bond_alb_deinit_slave(bond, slave);
+	}
+
+	if (all) {
+		toe_failover(bond_dev, NULL, TOE_RELEASE_ALL, NULL);
+		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
+	} else if (oldcurrent == slave) {
+		/* Note that we hold RTNL over this sequence, so there
+		 * is no concern that another slave add/remove event
+		 * will interfere.
+		 */
+		bond_select_active_slave(bond);
+	}
+
+	if (!bond_has_slaves(bond)) {
+		bond_set_carrier(bond);
+		eth_hw_addr_random(bond_dev);
+		bond->nest_level = SINGLE_DEPTH_NESTING;
+	} else {
+		bond->nest_level = dev_get_nest_level(bond_dev) + 1;
+	}
+
+	unblock_netpoll_tx();
+	synchronize_rcu();
+	bond->slave_cnt--;
+
+	if (!bond_has_slaves(bond)) {
+		call_netdevice_notifiers(NETDEV_CHANGEADDR, bond->dev);
+		call_netdevice_notifiers(NETDEV_RELEASE, bond->dev);
+	}
+
+	bond_compute_features(bond);
+	if (!(bond_dev->features & NETIF_F_VLAN_CHALLENGED) &&
+	    (old_features & NETIF_F_VLAN_CHALLENGED))
+		netdev_info(bond_dev, "last VLAN challenged slave %s left bond %s - VLAN blocking is removed\n",
+			    slave_dev->name, bond_dev->name);
+
+	vlan_vids_del_by_dev(slave_dev, bond_dev);
+
+	/* If the mode uses primary, then this case was handled above by
+	 * bond_change_active_slave(..., NULL)
+	 */
+	if (!bond_uses_primary(bond)) {
+		/* unset promiscuity level from slave
+		 * NOTE: The NETDEV_CHANGEADDR call above may change the value
+		 * of the IFF_PROMISC flag in the bond_dev, but we need the
+		 * value of that flag before that change, as that was the value
+		 * when this slave was attached, so we cache at the start of the
+		 * function and use it here. Same goes for ALLMULTI below
+		 */
+		if (old_flags & IFF_PROMISC)
+			dev_set_promiscuity(slave_dev, -1);
+
+		/* unset allmulti level from slave */
+		if (old_flags & IFF_ALLMULTI)
+			dev_set_allmulti(slave_dev, -1);
+
+		bond_hw_addr_flush(bond_dev, slave_dev);
+	}
+
+	slave_disable_netpoll(slave);
+
+	/* close slave before restoring its mac address */
+	dev_close(slave_dev);
+
+	if (bond->params.fail_over_mac != BOND_FOM_ACTIVE ||
+	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
+		/* restore original ("permanent") mac address */
+		bond_hw_addr_copy(ss.__data, slave->perm_hwaddr,
+				  slave->dev->addr_len);
+		ss.ss_family = slave_dev->type;
+		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss);
+	}
+
+	if (unregister)
+		__dev_set_mtu(slave_dev, slave->original_mtu);
+	else
+		dev_set_mtu(slave_dev, slave->original_mtu);
+
+	if (!netif_is_bond_master(slave_dev))
+		slave_dev->priv_flags &= ~IFF_BONDING;
+
+	bond_free_slave(slave);
+
+	return 0;
+}
+
+/* A wrapper used because of ndo_del_link */
+int bond_release(struct net_device *bond_dev, struct net_device *slave_dev)
+{
+	return __bond_release_one(bond_dev, slave_dev, false, false);
+}
+
+/* First release a slave and then destroy the bond if no more slaves are left.
+ * Must be under rtnl_lock when this function is called.
+ */
+static int  bond_release_and_destroy(struct net_device *bond_dev,
+				     struct net_device *slave_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	int ret;
+
+	ret = __bond_release_one(bond_dev, slave_dev, false, true);
+	if (ret == 0 && !bond_has_slaves(bond)) {
+		bond_dev->priv_flags |= IFF_DISABLE_NETPOLL;
+		netdev_info(bond_dev, "Destroying bond %s\n",
+			    bond_dev->name);
+		bond_remove_proc_entry(bond);
+		unregister_netdevice(bond_dev);
+	}
+	return ret;
+}
+
+static void bond_info_query(struct net_device *bond_dev, struct ifbond *info)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	bond_fill_ifbond(bond, info);
+}
+
+static int bond_slave_info_query(struct net_device *bond_dev, struct ifslave *info)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	int i = 0, res = -ENODEV;
+	struct slave *slave;
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (i++ == (int)info->slave_id) {
+			res = 0;
+			bond_fill_ifslave(slave, info);
+			break;
+		}
+	}
+
+	return res;
+}
+
+/*-------------------------------- Monitoring -------------------------------*/
+
+/* called with rcu_read_lock() */
+static int bond_miimon_inspect(struct bonding *bond)
+{
+	int link_state, commit = 0;
+	struct list_head *iter;
+	struct slave *slave;
+	bool ignore_updelay;
+
+	ignore_updelay = !rcu_dereference(bond->curr_active_slave);
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
+
+		link_state = bond_check_dev_link(bond, slave->dev, 0);
+
+		switch (slave->link) {
+		case BOND_LINK_UP:
+			if (link_state)
+				continue;
+
+			bond_propose_link_state(slave, BOND_LINK_FAIL);
+			commit++;
+			slave->delay = bond->params.downdelay;
+			if (slave->delay) {
+				netdev_info(bond->dev, "link status down for %sinterface %s, disabling it in %d ms\n",
+					    (BOND_MODE(bond) ==
+					     BOND_MODE_ACTIVEBACKUP) ?
+					     (bond_is_active_slave(slave) ?
+					      "active " : "backup ") : "",
+					    slave->dev->name,
+					    bond->params.downdelay * bond->params.miimon);
+			}
+			/*FALLTHRU*/
+		case BOND_LINK_FAIL:
+			if (link_state) {
+				/* recovered before downdelay expired */
+				bond_propose_link_state(slave, BOND_LINK_UP);
+				slave->last_link_up = jiffies;
+				netdev_info(bond->dev, "link status up again after %d ms for interface %s\n",
+					    (bond->params.downdelay - slave->delay) *
+					    bond->params.miimon,
+					    slave->dev->name);
+				commit++;
+				continue;
+			}
+
+			if (slave->delay <= 0) {
+				bond_propose_link_state(slave, BOND_LINK_DOWN);
+				commit++;
+				continue;
+			}
+
+			slave->delay--;
+			break;
+
+		case BOND_LINK_DOWN:
+			if (!link_state)
+				continue;
+
+			bond_propose_link_state(slave, BOND_LINK_BACK);
+			commit++;
+			slave->delay = bond->params.updelay;
+
+			if (slave->delay) {
+				netdev_info(bond->dev, "link status up for interface %s, enabling it in %d ms\n",
+					    slave->dev->name,
+					    ignore_updelay ? 0 :
+					    bond->params.updelay *
+					    bond->params.miimon);
+			}
+			/*FALLTHRU*/
+		case BOND_LINK_BACK:
+			if (!link_state) {
+				bond_propose_link_state(slave, BOND_LINK_DOWN);
+				netdev_info(bond->dev, "link status down again after %d ms for interface %s\n",
+					    (bond->params.updelay - slave->delay) *
+					    bond->params.miimon,
+					    slave->dev->name);
+				commit++;
+				continue;
+			}
+
+			if (ignore_updelay)
+				slave->delay = 0;
+
+			if (slave->delay <= 0) {
+				bond_propose_link_state(slave, BOND_LINK_UP);
+				commit++;
+				ignore_updelay = false;
+				continue;
+			}
+
+			slave->delay--;
+			break;
+		}
+	}
+
+	return commit;
+}
+
+static void bond_miimon_link_change(struct bonding *bond,
+				    struct slave *slave,
+				    char link)
+{
+	switch (BOND_MODE(bond)) {
+	case BOND_MODE_8023AD:
+		bond_3ad_handle_link_change(slave, link);
+		break;
+	case BOND_MODE_TLB:
+	case BOND_MODE_ALB:
+		bond_alb_handle_link_change(bond, slave, link);
+		break;
+	case BOND_MODE_XOR:
+		bond_update_slave_arr(bond, NULL);
+		break;
+	}
+}
+
+static void bond_miimon_commit(struct bonding *bond)
+{
+	struct list_head *iter;
+	struct slave *slave, *primary;
+
+	bond_for_each_slave(bond, slave, iter) {
+		switch (slave->link_new_state) {
+		case BOND_LINK_NOCHANGE:
+			/* For 802.3ad mode, check current slave speed and
+			 * duplex again in case its port was disabled after
+			 * invalid speed/duplex reporting but recovered before
+			 * link monitoring could make a decision on the actual
+			 * link status
+			 */
+			if (BOND_MODE(bond) == BOND_MODE_8023AD &&
+			    slave->link == BOND_LINK_UP)
+				bond_3ad_adapter_speed_duplex_changed(slave);
+			continue;
+
+		case BOND_LINK_UP:
+			if (bond_update_speed_duplex(slave) &&
+			    bond_needs_speed_duplex(bond)) {
+				slave->link = BOND_LINK_DOWN;
+				if (net_ratelimit())
+					netdev_warn(bond->dev,
+						    "failed to get link speed/duplex for %s\n",
+						    slave->dev->name);
+				continue;
+			}
+			bond_set_slave_link_state(slave, BOND_LINK_UP,
+						  BOND_SLAVE_NOTIFY_NOW);
+			slave->last_link_up = jiffies;
+
+			primary = rtnl_dereference(bond->primary_slave);
+			if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+				/* prevent it from being the active one */
+				bond_set_backup_slave(slave);
+			} else if (BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
+				/* make it immediately active */
+				bond_set_active_slave(slave);
+			}
+
+			netdev_info(bond->dev, "link status definitely up for interface %s, %u Mbps %s duplex\n",
+				    slave->dev->name,
+				    slave->speed == SPEED_UNKNOWN ? 0 : slave->speed,
+				    slave->duplex ? "full" : "half");
+
+			bond_miimon_link_change(bond, slave, BOND_LINK_UP);
+
+			if (BOND_MODE(bond) == BOND_MODE_XOR ||
+			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
+				toe_failover(netdev_master_upper_dev_get(slave->dev),
+					     slave->dev, TOE_LINK_UP, NULL);
+			if (!bond->curr_active_slave || slave == primary)
+				goto do_failover;
+
+			continue;
+
+		case BOND_LINK_DOWN:
+			if (slave->link_failure_count < UINT_MAX)
+				slave->link_failure_count++;
+
+			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
+						  BOND_SLAVE_NOTIFY_NOW);
+
+			if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP ||
+			    BOND_MODE(bond) == BOND_MODE_8023AD)
+				bond_set_slave_inactive_flags(slave,
+							      BOND_SLAVE_NOTIFY_NOW);
+
+			netdev_info(bond->dev, "link status definitely down for interface %s, disabling it\n",
+				    slave->dev->name);
+
+			bond_miimon_link_change(bond, slave, BOND_LINK_DOWN);
+
+			if (BOND_MODE(bond) == BOND_MODE_XOR ||
+			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
+				toe_failover(netdev_master_upper_dev_get(slave->dev),
+					     slave->dev, TOE_LINK_DOWN, NULL);
+			if (slave == rcu_access_pointer(bond->curr_active_slave))
+				goto do_failover;
+
+			continue;
+
+		default:
+			netdev_err(bond->dev, "invalid new link %d on slave %s\n",
+				   slave->link_new_state, slave->dev->name);
+			bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
+
+			continue;
+		}
+
+do_failover:
+		block_netpoll_tx();
+		bond_select_active_slave(bond);
+		unblock_netpoll_tx();
+	}
+
+	bond_set_carrier(bond);
+}
+
+/* bond_mii_monitor
+ *
+ * Really a wrapper that splits the mii monitor into two phases: an
+ * inspection, then (if inspection indicates something needs to be done)
+ * an acquisition of appropriate locks followed by a commit phase to
+ * implement whatever link state changes are indicated.
+ */
+static void bond_mii_monitor(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    mii_work.work);
+	bool should_notify_peers = false;
+	unsigned long delay;
+	struct slave *slave;
+	struct list_head *iter;
+
+	delay = msecs_to_jiffies(bond->params.miimon);
+
+	if (!bond_has_slaves(bond))
+		goto re_arm;
+
+	rcu_read_lock();
+
+	should_notify_peers = bond_should_notify_peers(bond);
+
+	if (bond_miimon_inspect(bond)) {
+		rcu_read_unlock();
+
+		/* Race avoidance with bond_close cancel of workqueue */
+		if (!rtnl_trylock()) {
+			delay = 1;
+			should_notify_peers = false;
+			goto re_arm;
+		}
+
+		bond_for_each_slave(bond, slave, iter) {
+			bond_commit_link_state(slave, BOND_SLAVE_NOTIFY_LATER);
+		}
+		bond_miimon_commit(bond);
+
+		rtnl_unlock();	/* might sleep, hold no other locks */
+	} else
+		rcu_read_unlock();
+
+re_arm:
+	if (bond->params.miimon)
+		queue_delayed_work(bond->wq, &bond->mii_work, delay);
+
+	if (should_notify_peers) {
+		if (!rtnl_trylock())
+			return;
+		call_netdevice_notifiers(NETDEV_NOTIFY_PEERS, bond->dev);
+		rtnl_unlock();
+	}
+}
+
+static int bond_upper_dev_walk(struct net_device *upper, void *data)
+{
+	__be32 ip = *((__be32 *)data);
+
+	return ip == bond_confirm_addr(upper, 0, ip);
+}
+
+static bool bond_has_this_ip(struct bonding *bond, __be32 ip)
+{
+	bool ret = false;
+
+	if (ip == bond_confirm_addr(bond->dev, 0, ip))
+		return true;
+
+	rcu_read_lock();
+	if (netdev_walk_all_upper_dev_rcu(bond->dev, bond_upper_dev_walk, &ip))
+		ret = true;
+	rcu_read_unlock();
+
+	return ret;
+}
+
+/* We go to the (large) trouble of VLAN tagging ARP frames because
+ * switches in VLAN mode (especially if ports are configured as
+ * "native" to a VLAN) might not pass non-tagged frames.
+ */
+static void bond_arp_send(struct net_device *slave_dev, int arp_op,
+			  __be32 dest_ip, __be32 src_ip,
+			  struct bond_vlan_tag *tags)
+{
+	struct sk_buff *skb;
+	struct bond_vlan_tag *outer_tag = tags;
+
+	netdev_dbg(slave_dev, "arp %d on slave %s: dst %pI4 src %pI4\n",
+		   arp_op, slave_dev->name, &dest_ip, &src_ip);
+
+	skb = arp_create(arp_op, ETH_P_ARP, dest_ip, slave_dev, src_ip,
+			 NULL, slave_dev->dev_addr, NULL);
+
+	if (!skb) {
+		net_err_ratelimited("ARP packet allocation failed\n");
+		return;
+	}
+
+	if (!tags || tags->vlan_proto == VLAN_N_VID)
+		goto xmit;
+
+	tags++;
+
+	/* Go through all the tags backwards and add them to the packet */
+	while (tags->vlan_proto != VLAN_N_VID) {
+		if (!tags->vlan_id) {
+			tags++;
+			continue;
+		}
+
+		netdev_dbg(slave_dev, "inner tag: proto %X vid %X\n",
+			   ntohs(outer_tag->vlan_proto), tags->vlan_id);
+		skb = vlan_insert_tag_set_proto(skb, tags->vlan_proto,
+						tags->vlan_id);
+		if (!skb) {
+			net_err_ratelimited("failed to insert inner VLAN tag\n");
+			return;
+		}
+
+		tags++;
+	}
+	/* Set the outer tag */
+	if (outer_tag->vlan_id) {
+		netdev_dbg(slave_dev, "outer tag: proto %X vid %X\n",
+			   ntohs(outer_tag->vlan_proto), outer_tag->vlan_id);
+		__vlan_hwaccel_put_tag(skb, outer_tag->vlan_proto,
+				       outer_tag->vlan_id);
+	}
+
+xmit:
+	arp_xmit(skb);
+}
+
+/* Validate the device path between the @start_dev and the @end_dev.
+ * The path is valid if the @end_dev is reachable through device
+ * stacking.
+ * When the path is validated, collect any vlan information in the
+ * path.
+ */
+struct bond_vlan_tag *bond_verify_device_path(struct net_device *start_dev,
+					      struct net_device *end_dev,
+					      int level)
+{
+	struct bond_vlan_tag *tags;
+	struct net_device *upper;
+	struct list_head  *iter;
+
+	if (start_dev == end_dev) {
+		tags = kcalloc(level + 1, sizeof(*tags), GFP_ATOMIC);
+		if (!tags)
+			return ERR_PTR(-ENOMEM);
+		tags[level].vlan_proto = VLAN_N_VID;
+		return tags;
+	}
+
+	netdev_for_each_upper_dev_rcu(start_dev, upper, iter) {
+		tags = bond_verify_device_path(upper, end_dev, level + 1);
+		if (IS_ERR_OR_NULL(tags)) {
+			if (IS_ERR(tags))
+				return tags;
+			continue;
+		}
+		if (is_vlan_dev(upper)) {
+			tags[level].vlan_proto = vlan_dev_vlan_proto(upper);
+			tags[level].vlan_id = vlan_dev_vlan_id(upper);
+		}
+
+		return tags;
+	}
+
+	return NULL;
+}
+
+static void bond_arp_send_all(struct bonding *bond, struct slave *slave)
+{
+	struct rtable *rt;
+	struct bond_vlan_tag *tags;
+	__be32 *targets = bond->params.arp_targets, addr;
+	int i;
+
+	for (i = 0; i < BOND_MAX_ARP_TARGETS && targets[i]; i++) {
+		netdev_dbg(bond->dev, "basa: target %pI4\n", &targets[i]);
+		tags = NULL;
+
+		/* Find out through which dev should the packet go */
+		rt = ip_route_output(dev_net(bond->dev), targets[i], 0,
+				     RTO_ONLINK, 0);
+		if (IS_ERR(rt)) {
+			/* there's no route to target - try to send arp
+			 * probe to generate any traffic (arp_validate=0)
+			 */
+			if (bond->params.arp_validate)
+				net_warn_ratelimited("%s: no route to arp_ip_target %pI4 and arp_validate is set\n",
+						     bond->dev->name,
+						     &targets[i]);
+			bond_arp_send(slave->dev, ARPOP_REQUEST, targets[i],
+				      0, tags);
+			continue;
+		}
+
+		/* bond device itself */
+		if (rt->dst.dev == bond->dev)
+			goto found;
+
+		rcu_read_lock();
+		tags = bond_verify_device_path(bond->dev, rt->dst.dev, 0);
+		rcu_read_unlock();
+
+		if (!IS_ERR_OR_NULL(tags))
+			goto found;
+
+		/* Not our device - skip */
+		netdev_dbg(bond->dev, "no path to arp_ip_target %pI4 via rt.dev %s\n",
+			   &targets[i], rt->dst.dev ? rt->dst.dev->name : "NULL");
+
+		ip_rt_put(rt);
+		continue;
+
+found:
+		addr = bond_confirm_addr(rt->dst.dev, targets[i], 0);
+		ip_rt_put(rt);
+		bond_arp_send(slave->dev, ARPOP_REQUEST, targets[i],
+			      addr, tags);
+		kfree(tags);
+	}
+}
+
+static void bond_validate_arp(struct bonding *bond, struct slave *slave, __be32 sip, __be32 tip)
+{
+	int i;
+
+	if (!sip || !bond_has_this_ip(bond, tip)) {
+		netdev_dbg(bond->dev, "bva: sip %pI4 tip %pI4 not found\n",
+			   &sip, &tip);
+		return;
+	}
+
+	i = bond_get_targets_ip(bond->params.arp_targets, sip);
+	if (i == -1) {
+		netdev_dbg(bond->dev, "bva: sip %pI4 not found in targets\n",
+			   &sip);
+		return;
+	}
+	slave->last_rx = jiffies;
+	slave->target_last_arp_rx[i] = jiffies;
+}
+
+int bond_arp_rcv(const struct sk_buff *skb, struct bonding *bond,
+		 struct slave *slave)
+{
+	struct arphdr *arp = (struct arphdr *)skb->data;
+	struct slave *curr_active_slave, *curr_arp_slave;
+	unsigned char *arp_ptr;
+	__be32 sip, tip;
+	int is_arp = skb->protocol == __cpu_to_be16(ETH_P_ARP);
+	unsigned int alen;
+
+	if (!slave_do_arp_validate(bond, slave)) {
+		if ((slave_do_arp_validate_only(bond) && is_arp) ||
+		    !slave_do_arp_validate_only(bond))
+			slave->last_rx = jiffies;
+		return RX_HANDLER_ANOTHER;
+	} else if (!is_arp) {
+		return RX_HANDLER_ANOTHER;
+	}
+
+	alen = arp_hdr_len(bond->dev);
+
+	netdev_dbg(bond->dev, "bond_arp_rcv: skb->dev %s\n",
+		   skb->dev->name);
+
+	if (alen > skb_headlen(skb)) {
+		arp = kmalloc(alen, GFP_ATOMIC);
+		if (!arp)
+			goto out_unlock;
+		if (skb_copy_bits(skb, 0, arp, alen) < 0)
+			goto out_unlock;
+	}
+
+	if (arp->ar_hln != bond->dev->addr_len ||
+	    skb->pkt_type == PACKET_OTHERHOST ||
+	    skb->pkt_type == PACKET_LOOPBACK ||
+	    arp->ar_hrd != htons(ARPHRD_ETHER) ||
+	    arp->ar_pro != htons(ETH_P_IP) ||
+	    arp->ar_pln != 4)
+		goto out_unlock;
+
+	arp_ptr = (unsigned char *)(arp + 1);
+	arp_ptr += bond->dev->addr_len;
+	memcpy(&sip, arp_ptr, 4);
+	arp_ptr += 4 + bond->dev->addr_len;
+	memcpy(&tip, arp_ptr, 4);
+
+	netdev_dbg(bond->dev, "bond_arp_rcv: %s/%d av %d sv %d sip %pI4 tip %pI4\n",
+		   slave->dev->name, bond_slave_state(slave),
+		     bond->params.arp_validate, slave_do_arp_validate(bond, slave),
+		     &sip, &tip);
+
+	curr_active_slave = rcu_dereference(bond->curr_active_slave);
+	curr_arp_slave = rcu_dereference(bond->current_arp_slave);
+
+	/* We 'trust' the received ARP enough to validate it if:
+	 *
+	 * (a) the slave receiving the ARP is active (which includes the
+	 * current ARP slave, if any), or
+	 *
+	 * (b) the receiving slave isn't active, but there is a currently
+	 * active slave and it received valid arp reply(s) after it became
+	 * the currently active slave, or
+	 *
+	 * (c) there is an ARP slave that sent an ARP during the prior ARP
+	 * interval, and we receive an ARP reply on any slave.  We accept
+	 * these because switch FDB update delays may deliver the ARP
+	 * reply to a slave other than the sender of the ARP request.
+	 *
+	 * Note: for (b), backup slaves are receiving the broadcast ARP
+	 * request, not a reply.  This request passes from the sending
+	 * slave through the L2 switch(es) to the receiving slave.  Since
+	 * this is checking the request, sip/tip are swapped for
+	 * validation.
+	 *
+	 * This is done to avoid endless looping when we can't reach the
+	 * arp_ip_target and fool ourselves with our own arp requests.
+	 */
+	if (bond_is_active_slave(slave))
+		bond_validate_arp(bond, slave, sip, tip);
+	else if (curr_active_slave &&
+		 time_after(slave_last_rx(bond, curr_active_slave),
+			    curr_active_slave->last_link_up))
+		bond_validate_arp(bond, slave, tip, sip);
+	else if (curr_arp_slave && (arp->ar_op == htons(ARPOP_REPLY)) &&
+		 bond_time_in_interval(bond,
+				       dev_trans_start(curr_arp_slave->dev), 1))
+		bond_validate_arp(bond, slave, sip, tip);
+
+out_unlock:
+	if (arp != (struct arphdr *)skb->data)
+		kfree(arp);
+	return RX_HANDLER_ANOTHER;
+}
+
+/* function to verify if we're in the arp_interval timeslice, returns true if
+ * (last_act - arp_interval) <= jiffies <= (last_act + mod * arp_interval +
+ * arp_interval/2) . the arp_interval/2 is needed for really fast networks.
+ */
+static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
+				  int mod)
+{
+	int delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
+
+	return time_in_range(jiffies,
+			     last_act - delta_in_ticks,
+			     last_act + mod * delta_in_ticks + delta_in_ticks/2);
+}
+
+/* This function is called regularly to monitor each slave's link
+ * ensuring that traffic is being sent and received when arp monitoring
+ * is used in load-balancing mode. if the adapter has been dormant, then an
+ * arp is transmitted to generate traffic. see activebackup_arp_monitor for
+ * arp monitoring in active backup mode.
+ */
+static void bond_loadbalance_arp_mon(struct bonding *bond)
+{
+	struct slave *slave, *oldcurrent;
+	struct list_head *iter;
+	int do_failover = 0, slave_state_changed = 0;
+
+	if (!bond_has_slaves(bond))
+		goto re_arm;
+
+	rcu_read_lock();
+
+	oldcurrent = rcu_dereference(bond->curr_active_slave);
+	/* see if any of the previous devices are up now (i.e. they have
+	 * xmt and rcv traffic). the curr_active_slave does not come into
+	 * the picture unless it is null. also, slave->last_link_up is not
+	 * needed here because we send an arp on each slave and give a slave
+	 * as long as it needs to get the tx/rx within the delta.
+	 * TODO: what about up/down delay in arp mode? it wasn't here before
+	 *       so it can wait
+	 */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		unsigned long trans_start = dev_trans_start(slave->dev);
+
+		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
+
+		if (slave->link != BOND_LINK_UP) {
+			if (bond_time_in_interval(bond, trans_start, 1) &&
+			    bond_time_in_interval(bond, slave->last_rx, 1)) {
+
+				bond_propose_link_state(slave, BOND_LINK_UP);
+				slave_state_changed = 1;
+
+				/* primary_slave has no meaning in round-robin
+				 * mode. the window of a slave being up and
+				 * curr_active_slave being null after enslaving
+				 * is closed.
+				 */
+				if (!oldcurrent) {
+					netdev_info(bond->dev, "link status definitely up for interface %s\n",
+						    slave->dev->name);
+					do_failover = 1;
+				} else {
+					netdev_info(bond->dev, "interface %s is now up\n",
+						    slave->dev->name);
+				}
+			}
+		} else {
+			/* slave->link == BOND_LINK_UP */
+
+			/* not all switches will respond to an arp request
+			 * when the source ip is 0, so don't take the link down
+			 * if we don't know our ip yet
+			 */
+			if (!bond_time_in_interval(bond, trans_start, 2) ||
+			    !bond_time_in_interval(bond, slave->last_rx, 2)) {
+
+				bond_propose_link_state(slave, BOND_LINK_DOWN);
+				slave_state_changed = 1;
+
+				if (slave->link_failure_count < UINT_MAX)
+					slave->link_failure_count++;
+
+				netdev_info(bond->dev, "interface %s is now down\n",
+					    slave->dev->name);
+
+				if (slave == oldcurrent)
+					do_failover = 1;
+			}
+		}
+
+		/* note: if switch is in round-robin mode, all links
+		 * must tx arp to ensure all links rx an arp - otherwise
+		 * links may oscillate or not come up at all; if switch is
+		 * in something like xor mode, there is nothing we can
+		 * do - all replies will be rx'ed on same link causing slaves
+		 * to be unstable during low/no traffic periods
+		 */
+		if (bond_slave_is_up(slave))
+			bond_arp_send_all(bond, slave);
+	}
+
+	rcu_read_unlock();
+
+	if (do_failover || slave_state_changed) {
+		if (!rtnl_trylock())
+			goto re_arm;
+
+		bond_for_each_slave(bond, slave, iter) {
+			if (slave->link_new_state != BOND_LINK_NOCHANGE)
+				slave->link = slave->link_new_state;
+		}
+
+		if (slave_state_changed) {
+			bond_slave_state_change(bond);
+			if (BOND_MODE(bond) == BOND_MODE_XOR)
+				bond_update_slave_arr(bond, NULL);
+		}
+		if (do_failover) {
+			block_netpoll_tx();
+			bond_select_active_slave(bond);
+			unblock_netpoll_tx();
+		}
+		rtnl_unlock();
+	}
+
+re_arm:
+	if (bond->params.arp_interval)
+		queue_delayed_work(bond->wq, &bond->arp_work,
+				   msecs_to_jiffies(bond->params.arp_interval));
+}
+
+/* Called to inspect slaves for active-backup mode ARP monitor link state
+ * changes.  Sets proposed link state in slaves to specify what action
+ * should take place for the slave.  Returns 0 if no changes are found, >0
+ * if changes to link states must be committed.
+ *
+ * Called with rcu_read_lock held.
+ */
+static int bond_ab_arp_inspect(struct bonding *bond)
+{
+	unsigned long trans_start, last_rx;
+	struct list_head *iter;
+	struct slave *slave;
+	int commit = 0;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
+		last_rx = slave_last_rx(bond, slave);
+
+		if (slave->link != BOND_LINK_UP) {
+			if (bond_time_in_interval(bond, last_rx, 1)) {
+				bond_propose_link_state(slave, BOND_LINK_UP);
+				commit++;
+			}
+			continue;
+		}
+
+		/* Give slaves 2*delta after being enslaved or made
+		 * active.  This avoids bouncing, as the last receive
+		 * times need a full ARP monitor cycle to be updated.
+		 */
+		if (bond_time_in_interval(bond, slave->last_link_up, 2))
+			continue;
+
+		/* Backup slave is down if:
+		 * - No current_arp_slave AND
+		 * - more than 3*delta since last receive AND
+		 * - the bond has an IP address
+		 *
+		 * Note: a non-null current_arp_slave indicates
+		 * the curr_active_slave went down and we are
+		 * searching for a new one; under this condition
+		 * we only take the curr_active_slave down - this
+		 * gives each slave a chance to tx/rx traffic
+		 * before being taken out
+		 */
+		if (!bond_is_active_slave(slave) &&
+		    !rcu_access_pointer(bond->current_arp_slave) &&
+		    !bond_time_in_interval(bond, last_rx, 3)) {
+			bond_propose_link_state(slave, BOND_LINK_DOWN);
+			commit++;
+		}
+
+		/* Active slave is down if:
+		 * - more than 2*delta since transmitting OR
+		 * - (more than 2*delta since receive AND
+		 *    the bond has an IP address)
+		 */
+		trans_start = dev_trans_start(slave->dev);
+		if (bond_is_active_slave(slave) &&
+		    (!bond_time_in_interval(bond, trans_start, 2) ||
+		     !bond_time_in_interval(bond, last_rx, 2))) {
+			bond_propose_link_state(slave, BOND_LINK_DOWN);
+			commit++;
+		}
+	}
+
+	return commit;
+}
+
+/* Called to commit link state changes noted by inspection step of
+ * active-backup mode ARP monitor.
+ *
+ * Called with RTNL hold.
+ */
+static void bond_ab_arp_commit(struct bonding *bond)
+{
+	unsigned long trans_start;
+	struct list_head *iter;
+	struct slave *slave;
+
+	bond_for_each_slave(bond, slave, iter) {
+		switch (slave->link_new_state) {
+		case BOND_LINK_NOCHANGE:
+			continue;
+
+		case BOND_LINK_UP:
+			trans_start = dev_trans_start(slave->dev);
+			if (rtnl_dereference(bond->curr_active_slave) != slave ||
+			    (!rtnl_dereference(bond->curr_active_slave) &&
+			     bond_time_in_interval(bond, trans_start, 1))) {
+				struct slave *current_arp_slave;
+
+				current_arp_slave = rtnl_dereference(bond->current_arp_slave);
+				bond_set_slave_link_state(slave, BOND_LINK_UP,
+							  BOND_SLAVE_NOTIFY_NOW);
+				if (current_arp_slave) {
+					bond_set_slave_inactive_flags(
+						current_arp_slave,
+						BOND_SLAVE_NOTIFY_NOW);
+					RCU_INIT_POINTER(bond->current_arp_slave, NULL);
+				}
+
+				netdev_info(bond->dev, "link status definitely up for interface %s\n",
+					    slave->dev->name);
+
+				if (!rtnl_dereference(bond->curr_active_slave) ||
+				    slave == rtnl_dereference(bond->primary_slave))
+					goto do_failover;
+
+			}
+
+			continue;
+
+		case BOND_LINK_DOWN:
+			if (slave->link_failure_count < UINT_MAX)
+				slave->link_failure_count++;
+
+			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
+						  BOND_SLAVE_NOTIFY_NOW);
+			bond_set_slave_inactive_flags(slave,
+						      BOND_SLAVE_NOTIFY_NOW);
+
+			netdev_info(bond->dev, "link status definitely down for interface %s, disabling it\n",
+				    slave->dev->name);
+
+			if (slave == rtnl_dereference(bond->curr_active_slave)) {
+				RCU_INIT_POINTER(bond->current_arp_slave, NULL);
+				goto do_failover;
+			}
+
+			continue;
+
+		default:
+			netdev_err(bond->dev, "impossible: new_link %d on slave %s\n",
+				   slave->link_new_state, slave->dev->name);
+			continue;
+		}
+
+do_failover:
+		block_netpoll_tx();
+		bond_select_active_slave(bond);
+		unblock_netpoll_tx();
+	}
+
+	bond_set_carrier(bond);
+}
+
+/* Send ARP probes for active-backup mode ARP monitor.
+ *
+ * Called with rcu_read_lock held.
+ */
+static bool bond_ab_arp_probe(struct bonding *bond)
+{
+	struct slave *slave, *before = NULL, *new_slave = NULL,
+		     *curr_arp_slave = rcu_dereference(bond->current_arp_slave),
+		     *curr_active_slave = rcu_dereference(bond->curr_active_slave);
+	struct list_head *iter;
+	bool found = false;
+	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
+
+	if (curr_arp_slave && curr_active_slave)
+		netdev_info(bond->dev, "PROBE: c_arp %s && cas %s BAD\n",
+			    curr_arp_slave->dev->name,
+			    curr_active_slave->dev->name);
+
+	if (curr_active_slave) {
+		bond_arp_send_all(bond, curr_active_slave);
+		return should_notify_rtnl;
+	}
+
+	/* if we don't have a curr_active_slave, search for the next available
+	 * backup slave from the current_arp_slave and make it the candidate
+	 * for becoming the curr_active_slave
+	 */
+
+	if (!curr_arp_slave) {
+		curr_arp_slave = bond_first_slave_rcu(bond);
+		if (!curr_arp_slave)
+			return should_notify_rtnl;
+	}
+
+	bond_set_slave_inactive_flags(curr_arp_slave, BOND_SLAVE_NOTIFY_LATER);
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (!found && !before && bond_slave_is_up(slave))
+			before = slave;
+
+		if (found && !new_slave && bond_slave_is_up(slave))
+			new_slave = slave;
+		/* if the link state is up at this point, we
+		 * mark it down - this can happen if we have
+		 * simultaneous link failures and
+		 * reselect_active_interface doesn't make this
+		 * one the current slave so it is still marked
+		 * up when it is actually down
+		 */
+		if (!bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
+			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
+						  BOND_SLAVE_NOTIFY_LATER);
+			if (slave->link_failure_count < UINT_MAX)
+				slave->link_failure_count++;
+
+			bond_set_slave_inactive_flags(slave,
+						      BOND_SLAVE_NOTIFY_LATER);
+
+			netdev_info(bond->dev, "backup interface %s is now down\n",
+				    slave->dev->name);
+		}
+		if (slave == curr_arp_slave)
+			found = true;
+	}
+
+	if (!new_slave && before)
+		new_slave = before;
+
+	if (!new_slave)
+		goto check_state;
+
+	bond_set_slave_link_state(new_slave, BOND_LINK_BACK,
+				  BOND_SLAVE_NOTIFY_LATER);
+	bond_set_slave_active_flags(new_slave, BOND_SLAVE_NOTIFY_LATER);
+	bond_arp_send_all(bond, new_slave);
+	new_slave->last_link_up = jiffies;
+	rcu_assign_pointer(bond->current_arp_slave, new_slave);
+
+check_state:
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (slave->should_notify || slave->should_notify_link) {
+			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
+			break;
+		}
+	}
+	return should_notify_rtnl;
+}
+
+static void bond_activebackup_arp_mon(struct bonding *bond)
+{
+	bool should_notify_peers = false;
+	bool should_notify_rtnl = false;
+	int delta_in_ticks;
+
+	delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
+
+	if (!bond_has_slaves(bond))
+		goto re_arm;
+
+	rcu_read_lock();
+
+	should_notify_peers = bond_should_notify_peers(bond);
+
+	if (bond_ab_arp_inspect(bond)) {
+		rcu_read_unlock();
+
+		/* Race avoidance with bond_close flush of workqueue */
+		if (!rtnl_trylock()) {
+			delta_in_ticks = 1;
+			should_notify_peers = false;
+			goto re_arm;
+		}
+
+		bond_ab_arp_commit(bond);
+
+		rtnl_unlock();
+		rcu_read_lock();
+	}
+
+	should_notify_rtnl = bond_ab_arp_probe(bond);
+	rcu_read_unlock();
+
+re_arm:
+	if (bond->params.arp_interval)
+		queue_delayed_work(bond->wq, &bond->arp_work, delta_in_ticks);
+
+	if (should_notify_peers || should_notify_rtnl) {
+		if (!rtnl_trylock())
+			return;
+
+		if (should_notify_peers)
+			call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
+						 bond->dev);
+		if (should_notify_rtnl) {
+			bond_slave_state_notify(bond);
+			bond_slave_link_notify(bond);
+		}
+
+		rtnl_unlock();
+	}
+}
+
+static void bond_arp_monitor(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    arp_work.work);
+
+	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
+		bond_activebackup_arp_mon(bond);
+	else
+		bond_loadbalance_arp_mon(bond);
+}
+
+/*-------------------------- netdev event handling --------------------------*/
+
+/* Change device name */
+static int bond_event_changename(struct bonding *bond)
+{
+	bond_remove_proc_entry(bond);
+	bond_create_proc_entry(bond);
+
+	bond_debug_reregister(bond);
+
+	return NOTIFY_DONE;
+}
+
+static int bond_master_netdev_event(unsigned long event,
+				    struct net_device *bond_dev)
+{
+	struct bonding *event_bond = netdev_priv(bond_dev);
+
+	switch (event) {
+	case NETDEV_CHANGENAME:
+		return bond_event_changename(event_bond);
+	case NETDEV_UNREGISTER:
+		bond_remove_proc_entry(event_bond);
+		break;
+	case NETDEV_REGISTER:
+		bond_create_proc_entry(event_bond);
+		break;
+	case NETDEV_NOTIFY_PEERS:
+		if (event_bond->send_peer_notif)
+			event_bond->send_peer_notif--;
+		break;
+	case NETDEV_DOWN: {
+		struct slave *slave = bond_first_slave(event_bond);
+
+		toe_failover(bond_dev, slave ? slave->dev : NULL,
+			     TOE_BOND_DOWN, NULL);
+		break;
+	}
+	case NETDEV_UP: {
+		struct slave *slave = bond_first_slave(event_bond);
+
+		toe_failover(bond_dev, slave ? slave->dev : NULL,
+			     TOE_BOND_UP, NULL);
+		break;
+	}
+	default:
+		break;
+	}
+
+	return NOTIFY_DONE;
+}
+
+static int bond_slave_netdev_event(unsigned long event,
+				   struct net_device *slave_dev)
+{
+	struct slave *slave = bond_slave_get_rtnl(slave_dev), *primary;
+	struct bonding *bond;
+	struct net_device *bond_dev;
+
+	/* A netdev event can be generated while enslaving a device
+	 * before netdev_rx_handler_register is called in which case
+	 * slave will be NULL
+	 */
+	if (!slave)
+		return NOTIFY_DONE;
+	bond_dev = slave->bond->dev;
+	bond = slave->bond;
+	primary = rtnl_dereference(bond->primary_slave);
+
+	switch (event) {
+	case NETDEV_UNREGISTER:
+		if (bond_dev->type != ARPHRD_ETHER)
+			bond_release_and_destroy(bond_dev, slave_dev);
+		else
+			__bond_release_one(bond_dev, slave_dev, false, true);
+		break;
+	case NETDEV_UP:
+	case NETDEV_CHANGE:
+		/* For 802.3ad mode only:
+		 * Getting invalid Speed/Duplex values here will put slave
+		 * in weird state. Mark it as link-fail if the link was
+		 * previously up or link-down if it hasn't yet come up, and
+		 * let link-monitoring (miimon) set it right when correct
+		 * speeds/duplex are available.
+		 */
+		if (bond_update_speed_duplex(slave) &&
+		    BOND_MODE(bond) == BOND_MODE_8023AD) {
+			if (slave->last_link_up)
+				slave->link = BOND_LINK_FAIL;
+			else
+				slave->link = BOND_LINK_DOWN;
+		}
+
+		if (BOND_MODE(bond) == BOND_MODE_8023AD)
+			bond_3ad_adapter_speed_duplex_changed(slave);
+		/* Fallthrough */
+	case NETDEV_DOWN:
+		/* Refresh slave-array if applicable!
+		 * If the setup does not use miimon or arpmon (mode-specific!),
+		 * then these events will not cause the slave-array to be
+		 * refreshed. This will cause xmit to use a slave that is not
+		 * usable. Avoid such situation by refeshing the array at these
+		 * events. If these (miimon/arpmon) parameters are configured
+		 * then array gets refreshed twice and that should be fine!
+		 */
+		if (bond_mode_can_use_xmit_hash(bond))
+			bond_update_slave_arr(bond, NULL);
+		break;
+	case NETDEV_CHANGEMTU:
+		/* TODO: Should slaves be allowed to
+		 * independently alter their MTU?  For
+		 * an active-backup bond, slaves need
+		 * not be the same type of device, so
+		 * MTUs may vary.  For other modes,
+		 * slaves arguably should have the
+		 * same MTUs. To do this, we'd need to
+		 * take over the slave's change_mtu
+		 * function for the duration of their
+		 * servitude.
+		 */
+		break;
+	case NETDEV_CHANGENAME:
+		/* we don't care if we don't have primary set */
+		if (!bond_uses_primary(bond) ||
+		    !bond->params.primary[0])
+			break;
+
+		if (slave == primary) {
+			/* slave's name changed - he's no longer primary */
+			RCU_INIT_POINTER(bond->primary_slave, NULL);
+		} else if (!strcmp(slave_dev->name, bond->params.primary)) {
+			/* we have a new primary slave */
+			rcu_assign_pointer(bond->primary_slave, slave);
+		} else { /* we didn't change primary - exit */
+			break;
+		}
+
+		netdev_info(bond->dev, "Primary slave changed to %s, reselecting active slave\n",
+			    primary ? slave_dev->name : "none");
+
+		block_netpoll_tx();
+		bond_select_active_slave(bond);
+		unblock_netpoll_tx();
+		break;
+	case NETDEV_FEAT_CHANGE:
+		bond_compute_features(bond);
+		break;
+	case NETDEV_RESEND_IGMP:
+		/* Propagate to master device */
+		call_netdevice_notifiers(event, slave->bond->dev);
+		break;
+	default:
+		break;
+	}
+
+	return NOTIFY_DONE;
+}
+
+/* bond_netdev_event: handle netdev notifier chain events.
+ *
+ * This function receives events for the netdev chain.  The caller (an
+ * ioctl handler calling blocking_notifier_call_chain) holds the necessary
+ * locks for us to safely manipulate the slave devices (RTNL lock,
+ * dev_probe_lock).
+ */
+static int bond_netdev_event(struct notifier_block *this,
+			     unsigned long event, void *ptr)
+{
+	struct net_device *event_dev = netdev_notifier_info_to_dev(ptr);
+
+	netdev_dbg(event_dev, "event: %lx\n", event);
+
+	if (!(event_dev->priv_flags & IFF_BONDING))
+		return NOTIFY_DONE;
+
+	if (event_dev->flags & IFF_MASTER) {
+		int ret;
+
+		netdev_dbg(event_dev, "IFF_MASTER\n");
+		ret = bond_master_netdev_event(event, event_dev);
+		if (ret != NOTIFY_DONE)
+			return ret;
+	}
+
+	if (event_dev->flags & IFF_SLAVE) {
+		netdev_dbg(event_dev, "IFF_SLAVE\n");
+		return bond_slave_netdev_event(event, event_dev);
+	}
+
+	return NOTIFY_DONE;
+}
+
+static struct notifier_block bond_netdev_notifier = {
+	.notifier_call = bond_netdev_event,
+};
+
+/*---------------------------- Hashing Policies -----------------------------*/
+
+/* L2 hash helper */
+static inline u32 bond_eth_hash(struct sk_buff *skb)
+{
+	struct ethhdr *ep, hdr_tmp;
+
+	ep = skb_header_pointer(skb, 0, sizeof(hdr_tmp), &hdr_tmp);
+	if (ep)
+		return ep->h_dest[5] ^ ep->h_source[5] ^ ep->h_proto;
+	return 0;
+}
+
+/* Extract the appropriate headers based on bond's xmit policy */
+static bool bond_flow_dissect(struct bonding *bond, struct sk_buff *skb,
+			      struct flow_keys *fk)
+{
+	const struct ipv6hdr *iph6;
+	const struct iphdr *iph;
+	int noff, proto = -1;
+
+	if (bond->params.xmit_policy > BOND_XMIT_POLICY_LAYER23)
+		return skb_flow_dissect_flow_keys(skb, fk, 0);
+
+	fk->ports.ports = 0;
+	noff = skb_network_offset(skb);
+	if (skb->protocol == htons(ETH_P_IP)) {
+		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
+			return false;
+		iph = ip_hdr(skb);
+		iph_to_flow_copy_v4addrs(fk, iph);
+		noff += iph->ihl << 2;
+		if (!ip_is_fragment(iph))
+			proto = iph->protocol;
+	} else if (skb->protocol == htons(ETH_P_IPV6)) {
+		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph6))))
+			return false;
+		iph6 = ipv6_hdr(skb);
+		iph_to_flow_copy_v6addrs(fk, iph6);
+		noff += sizeof(*iph6);
+		proto = iph6->nexthdr;
+	} else {
+		return false;
+	}
+	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER34 && proto >= 0)
+		fk->ports.ports = skb_flow_get_ports(skb, noff, proto);
+
+	return true;
+}
+
+/**
+ * bond_xmit_hash - generate a hash value based on the xmit policy
+ * @bond: bonding device
+ * @skb: buffer to use for headers
+ *
+ * This function will extract the necessary headers from the skb buffer and use
+ * them to generate a hash based on the xmit_policy set in the bonding device
+ */
+u32 bond_xmit_hash(struct bonding *bond, struct sk_buff *skb)
+{
+	struct flow_keys flow;
+	u32 hash;
+
+	if (bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP34 &&
+	    skb->l4_hash)
+		return skb->hash;
+
+	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER2 ||
+	    !bond_flow_dissect(bond, skb, &flow))
+		return bond_eth_hash(skb);
+
+	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER23 ||
+	    bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP23)
+		hash = bond_eth_hash(skb);
+	else
+		hash = (__force u32)flow.ports.ports;
+	hash ^= (__force u32)flow_get_u32_dst(&flow) ^
+		(__force u32)flow_get_u32_src(&flow);
+	hash ^= (hash >> 16);
+	hash ^= (hash >> 8);
+
+	return hash >> 1;
+}
+
+/*-------------------------- Device entry points ----------------------------*/
+
+void bond_work_init_all(struct bonding *bond)
+{
+	INIT_DELAYED_WORK(&bond->mcast_work,
+			  bond_resend_igmp_join_requests_delayed);
+	INIT_DELAYED_WORK(&bond->alb_work, bond_alb_monitor);
+	INIT_DELAYED_WORK(&bond->mii_work, bond_mii_monitor);
+	INIT_DELAYED_WORK(&bond->arp_work, bond_arp_monitor);
+	INIT_DELAYED_WORK(&bond->ad_work, bond_3ad_state_machine_handler);
+	INIT_DELAYED_WORK(&bond->slave_arr_work, bond_slave_arr_handler);
+}
+
+static void bond_work_cancel_all(struct bonding *bond)
+{
+	cancel_delayed_work_sync(&bond->mii_work);
+	cancel_delayed_work_sync(&bond->arp_work);
+	cancel_delayed_work_sync(&bond->alb_work);
+	cancel_delayed_work_sync(&bond->ad_work);
+	cancel_delayed_work_sync(&bond->mcast_work);
+	cancel_delayed_work_sync(&bond->slave_arr_work);
+}
+
+static int bond_open(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	struct slave *slave;
+
+	/* reset slave->backup and slave->inactive */
+	if (bond_has_slaves(bond)) {
+		bond_for_each_slave(bond, slave, iter) {
+			if (bond_uses_primary(bond) &&
+			    slave != rcu_access_pointer(bond->curr_active_slave)) {
+				bond_set_slave_inactive_flags(slave,
+							      BOND_SLAVE_NOTIFY_NOW);
+			} else if (BOND_MODE(bond) != BOND_MODE_8023AD) {
+				bond_set_slave_active_flags(slave,
+							    BOND_SLAVE_NOTIFY_NOW);
+			}
+		}
+	}
+
+	if (bond_is_lb(bond)) {
+		/* bond_alb_initialize must be called before the timer
+		 * is started.
+		 */
+		if (bond_alb_initialize(bond, (BOND_MODE(bond) == BOND_MODE_ALB)))
+			return -ENOMEM;
+		if (bond->params.tlb_dynamic_lb || BOND_MODE(bond) == BOND_MODE_ALB)
+			queue_delayed_work(bond->wq, &bond->alb_work, 0);
+	}
+
+	if (bond->params.miimon)  /* link check interval, in milliseconds. */
+		queue_delayed_work(bond->wq, &bond->mii_work, 0);
+
+	if (bond->params.arp_interval) {  /* arp interval, in milliseconds. */
+		queue_delayed_work(bond->wq, &bond->arp_work, 0);
+		bond->recv_probe = bond_arp_rcv;
+	}
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		queue_delayed_work(bond->wq, &bond->ad_work, 0);
+		/* register to receive LACPDUs */
+		bond->recv_probe = bond_3ad_lacpdu_recv;
+		bond_3ad_initiate_agg_selection(bond, 1);
+	}
+
+	if (bond_mode_can_use_xmit_hash(bond))
+		bond_update_slave_arr(bond, NULL);
+
+	return 0;
+}
+
+static int bond_close(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+
+	bond_work_cancel_all(bond);
+	bond->send_peer_notif = 0;
+	if (bond_is_lb(bond))
+		bond_alb_deinitialize(bond);
+	bond->recv_probe = NULL;
+
+	return 0;
+}
+
+/* fold stats, assuming all rtnl_link_stats64 fields are u64, but
+ * that some drivers can provide 32bit values only.
+ */
+static void bond_fold_stats(struct rtnl_link_stats64 *_res,
+			    const struct rtnl_link_stats64 *_new,
+			    const struct rtnl_link_stats64 *_old)
+{
+	const u64 *new = (const u64 *)_new;
+	const u64 *old = (const u64 *)_old;
+	u64 *res = (u64 *)_res;
+	int i;
+
+	for (i = 0; i < sizeof(*_res) / sizeof(u64); i++) {
+		u64 nv = new[i];
+		u64 ov = old[i];
+		s64 delta = nv - ov;
+
+		/* detects if this particular field is 32bit only */
+		if (((nv | ov) >> 32) == 0)
+			delta = (s64)(s32)((u32)nv - (u32)ov);
+
+		/* filter anomalies, some drivers reset their stats
+		 * at down/up events.
+		 */
+		if (delta > 0)
+			res[i] += delta;
+	}
+}
+
+static int bond_get_nest_level(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+
+	return bond->nest_level;
+}
+
+static void bond_get_stats(struct net_device *bond_dev,
+			   struct rtnl_link_stats64 *stats)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct rtnl_link_stats64 temp;
+	struct list_head *iter;
+	struct slave *slave;
+
+	spin_lock_nested(&bond->stats_lock, bond_get_nest_level(bond_dev));
+	memcpy(stats, &bond->bond_stats, sizeof(*stats));
+
+	rcu_read_lock();
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		const struct rtnl_link_stats64 *new =
+			dev_get_stats(slave->dev, &temp);
+
+		bond_fold_stats(stats, new, &slave->slave_stats);
+
+		/* save off the slave stats for the next run */
+		memcpy(&slave->slave_stats, new, sizeof(*new));
+	}
+	rcu_read_unlock();
+
+	memcpy(&bond->bond_stats, stats, sizeof(*stats));
+	spin_unlock(&bond->stats_lock);
+}
+
+static int bond_do_ioctl(struct net_device *bond_dev, struct ifreq *ifr, int cmd)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct net_device *slave_dev = NULL;
+	struct ifbond k_binfo;
+	struct ifbond __user *u_binfo = NULL;
+	struct ifslave k_sinfo;
+	struct ifslave __user *u_sinfo = NULL;
+	struct mii_ioctl_data *mii = NULL;
+	struct bond_opt_value newval;
+	struct net *net;
+	int res = 0;
+
+	netdev_dbg(bond_dev, "bond_ioctl: cmd=%d\n", cmd);
+
+	switch (cmd) {
+	case SIOCGMIIPHY:
+		mii = if_mii(ifr);
+		if (!mii)
+			return -EINVAL;
+
+		mii->phy_id = 0;
+		/* Fall Through */
+	case SIOCGMIIREG:
+		/* We do this again just in case we were called by SIOCGMIIREG
+		 * instead of SIOCGMIIPHY.
+		 */
+		mii = if_mii(ifr);
+		if (!mii)
+			return -EINVAL;
+
+		if (mii->reg_num == 1) {
+			mii->val_out = 0;
+			if (netif_carrier_ok(bond->dev))
+				mii->val_out = BMSR_LSTATUS;
+		}
+
+		return 0;
+	case BOND_INFO_QUERY_OLD:
+	case SIOCBONDINFOQUERY:
+		u_binfo = (struct ifbond __user *)ifr->ifr_data;
+
+		if (copy_from_user(&k_binfo, u_binfo, sizeof(ifbond)))
+			return -EFAULT;
+
+		bond_info_query(bond_dev, &k_binfo);
+		if (copy_to_user(u_binfo, &k_binfo, sizeof(ifbond)))
+			return -EFAULT;
+
+		return 0;
+	case BOND_SLAVE_INFO_QUERY_OLD:
+	case SIOCBONDSLAVEINFOQUERY:
+		u_sinfo = (struct ifslave __user *)ifr->ifr_data;
+
+		if (copy_from_user(&k_sinfo, u_sinfo, sizeof(ifslave)))
+			return -EFAULT;
+
+		res = bond_slave_info_query(bond_dev, &k_sinfo);
+		if (res == 0 &&
+		    copy_to_user(u_sinfo, &k_sinfo, sizeof(ifslave)))
+			return -EFAULT;
+
+		return res;
+	default:
+		break;
+	}
+
+	net = dev_net(bond_dev);
+
+	if (!ns_capable(net->user_ns, CAP_NET_ADMIN))
+		return -EPERM;
+
+	slave_dev = __dev_get_by_name(net, ifr->ifr_slave);
+
+	netdev_dbg(bond_dev, "slave_dev=%p:\n", slave_dev);
+
+	if (!slave_dev)
+		return -ENODEV;
+
+	netdev_dbg(bond_dev, "slave_dev->name=%s:\n", slave_dev->name);
+	switch (cmd) {
+	case BOND_ENSLAVE_OLD:
+	case SIOCBONDENSLAVE:
+		res = bond_enslave(bond_dev, slave_dev, NULL);
+		break;
+	case BOND_RELEASE_OLD:
+	case SIOCBONDRELEASE:
+		res = bond_release(bond_dev, slave_dev);
+		break;
+	case BOND_SETHWADDR_OLD:
+	case SIOCBONDSETHWADDR:
+		bond_set_dev_addr(bond_dev, slave_dev);
+		res = 0;
+		break;
+	case BOND_CHANGE_ACTIVE_OLD:
+	case SIOCBONDCHANGEACTIVE:
+		bond_opt_initstr(&newval, slave_dev->name);
+		res = __bond_opt_set_notify(bond, BOND_OPT_ACTIVE_SLAVE,
+					    &newval);
+		break;
+	default:
+		res = -EOPNOTSUPP;
+	}
+
+	return res;
+}
+
+static void bond_change_rx_flags(struct net_device *bond_dev, int change)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+
+	if (change & IFF_PROMISC)
+		bond_set_promiscuity(bond,
+				     bond_dev->flags & IFF_PROMISC ? 1 : -1);
+
+	if (change & IFF_ALLMULTI)
+		bond_set_allmulti(bond,
+				  bond_dev->flags & IFF_ALLMULTI ? 1 : -1);
+}
+
+static void bond_set_rx_mode(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	struct slave *slave;
+
+	rcu_read_lock();
+	if (bond_uses_primary(bond)) {
+		slave = rcu_dereference(bond->curr_active_slave);
+		if (slave) {
+			dev_uc_sync(slave->dev, bond_dev);
+			dev_mc_sync(slave->dev, bond_dev);
+		}
+	} else {
+		bond_for_each_slave_rcu(bond, slave, iter) {
+			dev_uc_sync_multiple(slave->dev, bond_dev);
+			dev_mc_sync_multiple(slave->dev, bond_dev);
+		}
+	}
+	rcu_read_unlock();
+}
+
+static int bond_neigh_init(struct neighbour *n)
+{
+	struct bonding *bond = netdev_priv(n->dev);
+	const struct net_device_ops *slave_ops;
+	struct neigh_parms parms;
+	struct slave *slave;
+	int ret;
+
+	slave = bond_first_slave(bond);
+	if (!slave)
+		return 0;
+	slave_ops = slave->dev->netdev_ops;
+	if (!slave_ops->ndo_neigh_setup)
+		return 0;
+
+	parms.neigh_setup = NULL;
+	parms.neigh_cleanup = NULL;
+	ret = slave_ops->ndo_neigh_setup(slave->dev, &parms);
+	if (ret)
+		return ret;
+
+	/* Assign slave's neigh_cleanup to neighbour in case cleanup is called
+	 * after the last slave has been detached.  Assumes that all slaves
+	 * utilize the same neigh_cleanup (true at this writing as only user
+	 * is ipoib).
+	 */
+	n->parms->neigh_cleanup = parms.neigh_cleanup;
+
+	if (!parms.neigh_setup)
+		return 0;
+
+	return parms.neigh_setup(n);
+}
+
+/* The bonding ndo_neigh_setup is called at init time beofre any
+ * slave exists. So we must declare proxy setup function which will
+ * be used at run time to resolve the actual slave neigh param setup.
+ *
+ * It's also called by master devices (such as vlans) to setup their
+ * underlying devices. In that case - do nothing, we're already set up from
+ * our init.
+ */
+static int bond_neigh_setup(struct net_device *dev,
+			    struct neigh_parms *parms)
+{
+	/* modify only our neigh_parms */
+	if (parms->dev == dev)
+		parms->neigh_setup = bond_neigh_init;
+
+	return 0;
+}
+
+/* Change the MTU of all of a master's slaves to match the master */
+static int bond_change_mtu(struct net_device *bond_dev, int new_mtu)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave, *rollback_slave;
+	struct list_head *iter;
+	int res = 0;
+
+	netdev_dbg(bond_dev, "bond=%p, new_mtu=%d\n", bond, new_mtu);
+
+	bond_for_each_slave(bond, slave, iter) {
+		netdev_dbg(bond_dev, "s %p c_m %p\n",
+			   slave, slave->dev->netdev_ops->ndo_change_mtu);
+
+		res = dev_set_mtu(slave->dev, new_mtu);
+
+		if (res) {
+			/* If we failed to set the slave's mtu to the new value
+			 * we must abort the operation even in ACTIVE_BACKUP
+			 * mode, because if we allow the backup slaves to have
+			 * different mtu values than the active slave we'll
+			 * need to change their mtu when doing a failover. That
+			 * means changing their mtu from timer context, which
+			 * is probably not a good idea.
+			 */
+			netdev_dbg(bond_dev, "err %d %s\n", res,
+				   slave->dev->name);
+			goto unwind;
+		}
+	}
+
+	bond_dev->mtu = new_mtu;
+
+	return 0;
+
+unwind:
+	/* unwind from head to the slave that failed */
+	bond_for_each_slave(bond, rollback_slave, iter) {
+		int tmp_res;
+
+		if (rollback_slave == slave)
+			break;
+
+		tmp_res = dev_set_mtu(rollback_slave->dev, bond_dev->mtu);
+		if (tmp_res) {
+			netdev_dbg(bond_dev, "unwind err %d dev %s\n",
+				   tmp_res, rollback_slave->dev->name);
+		}
+	}
+
+	return res;
+}
+
+/* Change HW address
+ *
+ * Note that many devices must be down to change the HW address, and
+ * downing the master releases all slaves.  We can make bonds full of
+ * bonding devices to test this, however.
+ */
+static int bond_set_mac_address(struct net_device *bond_dev, void *addr)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave, *rollback_slave;
+	struct sockaddr_storage *ss = addr, tmp_ss;
+	struct list_head *iter;
+	int res = 0;
+
+	if (BOND_MODE(bond) == BOND_MODE_ALB)
+		return bond_alb_set_mac_address(bond_dev, addr);
+
+
+	netdev_dbg(bond_dev, "bond=%p\n", bond);
+
+	/* If fail_over_mac is enabled, do nothing and return success.
+	 * Returning an error causes ifenslave to fail.
+	 */
+	if (bond->params.fail_over_mac &&
+	    BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
+		return 0;
+
+	if (!is_valid_ether_addr(ss->__data))
+		return -EADDRNOTAVAIL;
+
+	bond_for_each_slave(bond, slave, iter) {
+		netdev_dbg(bond_dev, "slave %p %s\n", slave, slave->dev->name);
+		res = dev_set_mac_address(slave->dev, addr);
+		if (res) {
+			/* TODO: consider downing the slave
+			 * and retry ?
+			 * User should expect communications
+			 * breakage anyway until ARP finish
+			 * updating, so...
+			 */
+			netdev_dbg(bond_dev, "err %d %s\n", res, slave->dev->name);
+			goto unwind;
+		}
+	}
+
+	/* success */
+	memcpy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
+	return 0;
+
+unwind:
+	memcpy(tmp_ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
+	tmp_ss.ss_family = bond_dev->type;
+
+	/* unwind from head to the slave that failed */
+	bond_for_each_slave(bond, rollback_slave, iter) {
+		int tmp_res;
+
+		if (rollback_slave == slave)
+			break;
+
+		tmp_res = dev_set_mac_address(rollback_slave->dev,
+					      (struct sockaddr *)&tmp_ss);
+		if (tmp_res) {
+			netdev_dbg(bond_dev, "unwind err %d dev %s\n",
+				   tmp_res, rollback_slave->dev->name);
+		}
+	}
+
+	return res;
+}
+
+static struct net_device *bond_xmit_slave_id_select(struct bonding *bond, int slave_id)
+{
+	struct list_head *iter;
+	struct slave *slave;
+	struct net_device *slave_dev = NULL;
+	int i = slave_id;
+
+	/* Here we start from the slave with slave_id */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (--i < 0) {
+			if (bond_slave_can_tx(slave)) {
+				slave_dev = slave->dev;
+				return slave_dev;
+			}
+		}
+	}
+
+	/* Here we start from the first slave up to slave_id */
+	i = slave_id;
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (--i < 0)
+			break;
+		if (bond_slave_can_tx(slave)) {
+			slave_dev = slave->dev;
+			return slave_dev;
+		}
+	}
+	return slave_dev;
+}
+
+/**
+ * bond_xmit_slave_id - transmit skb through slave with slave_id
+ * @bond: bonding device that is transmitting
+ * @skb: buffer to transmit
+ * @slave_id: slave id up to slave_cnt-1 through which to transmit
+ *
+ * This function tries to transmit through slave with slave_id but in case
+ * it fails, it tries to find the first available slave for transmission.
+ * The skb is consumed in all cases, thus the function is void.
+ */
+static void bond_xmit_slave_id(struct bonding *bond, struct sk_buff *skb, int slave_id)
+{
+	struct list_head *iter;
+	struct slave *slave;
+	int i = slave_id;
+
+	/* Here we start from the slave with slave_id */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (--i < 0) {
+			if (bond_slave_can_tx(slave)) {
+				bond_dev_queue_xmit(bond, skb, slave->dev);
+				return;
+			}
+		}
+	}
+
+	/* Here we start from the first slave up to slave_id */
+	i = slave_id;
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (--i < 0)
+			break;
+		if (bond_slave_can_tx(slave)) {
+			bond_dev_queue_xmit(bond, skb, slave->dev);
+			return;
+		}
+	}
+	/* no slave that can tx has been found */
+	bond_tx_drop(bond->dev, skb);
+}
+
+/**
+ * bond_rr_gen_slave_id - generate slave id based on packets_per_slave
+ * @bond: bonding device to use
+ *
+ * Based on the value of the bonding device's packets_per_slave parameter
+ * this function generates a slave id, which is usually used as the next
+ * slave to transmit through.
+ */
+static u32 bond_rr_gen_slave_id(struct bonding *bond)
+{
+	u32 slave_id;
+	struct reciprocal_value reciprocal_packets_per_slave;
+	int packets_per_slave = bond->params.packets_per_slave;
+
+	switch (packets_per_slave) {
+	case 0:
+		slave_id = prandom_u32();
+		break;
+	case 1:
+		slave_id = bond->rr_tx_counter;
+		break;
+	default:
+		reciprocal_packets_per_slave =
+			bond->params.reciprocal_packets_per_slave;
+		slave_id = reciprocal_divide(bond->rr_tx_counter,
+					     reciprocal_packets_per_slave);
+		break;
+	}
+	bond->rr_tx_counter++;
+
+	return slave_id;
+}
+
+static struct net_device *bond_xmit_roundrobin_select(int slave_id,
+						     struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+
+	return bond_xmit_slave_id_select(bond, slave_id);
+}
+
+static netdev_tx_t bond_xmit_roundrobin(struct sk_buff *skb,
+					struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave;
+	int slave_cnt;
+	u32 slave_id;
+
+	/* Start with the curr_active_slave that joined the bond as the
+	 * default for sending IGMP traffic.  For failover purposes one
+	 * needs to maintain some consistency for the interface that will
+	 * send the join/membership reports.  The curr_active_slave found
+	 * will send all of this type of traffic.
+	 */
+	if (skb->protocol == htons(ETH_P_IP)) {
+		int noff = skb_network_offset(skb);
+		struct iphdr *iph;
+
+		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
+			goto non_igmp;
+
+		iph = ip_hdr(skb);
+		if (iph->protocol == IPPROTO_IGMP) {
+			slave = rcu_dereference(bond->curr_active_slave);
+			if (slave)
+				bond_dev_queue_xmit(bond, skb, slave->dev);
+			else
+				bond_xmit_slave_id(bond, skb, 0);
+			return NETDEV_TX_OK;
+		}
+	}
+
+non_igmp:
+	slave_cnt = READ_ONCE(bond->slave_cnt);
+	if (likely(slave_cnt)) {
+		slave_id = bond_rr_gen_slave_id(bond);
+		bond_xmit_slave_id(bond, skb, slave_id % slave_cnt);
+	} else {
+		bond_tx_drop(bond_dev, skb);
+	}
+	return NETDEV_TX_OK;
+}
+
+static struct net_device *bond_xmit_activebackup_select(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct net_device *slave_dev = NULL;
+	struct slave *slave;
+
+	slave = rcu_dereference(bond->curr_active_slave);
+	if (slave)
+		slave_dev = slave->dev;
+
+	return slave_dev;
+}
+
+/* In active-backup mode, we know that bond->curr_active_slave is always valid if
+ * the bond has a usable interface.
+ */
+static netdev_tx_t bond_xmit_activebackup(struct sk_buff *skb,
+					  struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave;
+
+	slave = rcu_dereference(bond->curr_active_slave);
+	if (slave)
+		bond_dev_queue_xmit(bond, skb, slave->dev);
+	else
+		bond_tx_drop(bond_dev, skb);
+
+	return NETDEV_TX_OK;
+}
+
+/* Use this to update slave_array when (a) it's not appropriate to update
+ * slave_array right away (note that update_slave_array() may sleep)
+ * and / or (b) RTNL is not held.
+ */
+void bond_slave_arr_work_rearm(struct bonding *bond, unsigned long delay)
+{
+	queue_delayed_work(bond->wq, &bond->slave_arr_work, delay);
+}
+
+/* Slave array work handler. Holds only RTNL */
+static void bond_slave_arr_handler(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    slave_arr_work.work);
+	int ret;
+
+	if (!rtnl_trylock())
+		goto err;
+
+	ret = bond_update_slave_arr(bond, NULL);
+	rtnl_unlock();
+	if (ret) {
+		pr_warn_ratelimited("Failed to update slave array from WT\n");
+		goto err;
+	}
+	return;
+
+err:
+	bond_slave_arr_work_rearm(bond, 1);
+}
+
+/* Build the usable slaves array in control path for modes that use xmit-hash
+ * to determine the slave interface -
+ * (a) BOND_MODE_8023AD
+ * (b) BOND_MODE_XOR
+ * (c) (BOND_MODE_TLB || BOND_MODE_ALB) && tlb_dynamic_lb == 0
+ *
+ * The caller is expected to hold RTNL only and NO other lock!
+ */
+int bond_update_slave_arr(struct bonding *bond, struct slave *skipslave)
+{
+	struct slave *slave;
+	struct list_head *iter;
+	struct bond_up_slave *new_arr, *old_arr;
+	int agg_id = 0;
+	int ret = 0;
+
+#ifdef CONFIG_LOCKDEP
+	WARN_ON(lockdep_is_held(&bond->mode_lock));
+#endif
+
+	new_arr = kzalloc(offsetof(struct bond_up_slave, arr[bond->slave_cnt]),
+			  GFP_KERNEL);
+	if (!new_arr) {
+		ret = -ENOMEM;
+		pr_err("Failed to build slave-array.\n");
+		goto out;
+	}
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		struct ad_info ad_info;
+
+		if (bond_3ad_get_active_agg_info(bond, &ad_info)) {
+			pr_debug("bond_3ad_get_active_agg_info failed\n");
+			kfree_rcu(new_arr, rcu);
+			/* No active aggragator means it's not safe to use
+			 * the previous array.
+			 */
+			old_arr = rtnl_dereference(bond->slave_arr);
+			if (old_arr) {
+				RCU_INIT_POINTER(bond->slave_arr, NULL);
+				kfree_rcu(old_arr, rcu);
+			}
+			goto out;
+		}
+		agg_id = ad_info.aggregator_id;
+	}
+	bond_for_each_slave(bond, slave, iter) {
+		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+			struct aggregator *agg;
+
+			agg = SLAVE_AD_INFO(slave)->port.aggregator;
+			if (!agg || agg->aggregator_identifier != agg_id)
+				continue;
+		}
+		if (!bond_slave_can_tx(slave))
+			continue;
+		if (skipslave == slave)
+			continue;
+
+		netdev_dbg(bond->dev,
+			   "Adding slave dev %s to tx hash array[%d]\n",
+			   slave->dev->name, new_arr->count);
+
+		new_arr->arr[new_arr->count++] = slave;
+	}
+
+	old_arr = rtnl_dereference(bond->slave_arr);
+	rcu_assign_pointer(bond->slave_arr, new_arr);
+	if (old_arr)
+		kfree_rcu(old_arr, rcu);
+out:
+	if (ret != 0 && skipslave) {
+		int idx;
+
+		/* Rare situation where caller has asked to skip a specific
+		 * slave but allocation failed (most likely!). BTW this is
+		 * only possible when the call is initiated from
+		 * __bond_release_one(). In this situation; overwrite the
+		 * skipslave entry in the array with the last entry from the
+		 * array to avoid a situation where the xmit path may choose
+		 * this to-be-skipped slave to send a packet out.
+		 */
+		old_arr = rtnl_dereference(bond->slave_arr);
+		for (idx = 0; old_arr != NULL && idx < old_arr->count; idx++) {
+			if (skipslave == old_arr->arr[idx]) {
+				old_arr->arr[idx] =
+				    old_arr->arr[old_arr->count-1];
+				old_arr->count--;
+				break;
+			}
+		}
+	}
+	return ret;
+}
+
+static struct net_device *bond_xmit_xor_select(int slave_id,
+					       struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct bond_up_slave *slaves;
+	struct slave *slave;
+	struct net_device *slave_dev = NULL;
+	unsigned int count;
+
+	slaves = rcu_dereference(bond->slave_arr);
+	count = slaves ? READ_ONCE(slaves->count) : 0;
+	if (likely(count)) {
+		slave = slaves->arr[slave_id];
+		if (slave)
+			slave_dev = slave->dev;
+	}
+	return slave_dev;
+}
+
+/* Use this Xmit function for 3AD as well as XOR modes. The current
+ * usable slave array is formed in the control path. The xmit function
+ * just calculates hash and sends the packet out.
+ */
+static netdev_tx_t bond_3ad_xor_xmit(struct sk_buff *skb,
+				     struct net_device *dev)
+{
+	struct bonding *bond = netdev_priv(dev);
+	struct slave *slave;
+	struct bond_up_slave *slaves;
+	unsigned int count;
+
+	slaves = rcu_dereference(bond->slave_arr);
+	count = slaves ? READ_ONCE(slaves->count) : 0;
+	if (likely(count)) {
+		slave = slaves->arr[bond_xmit_hash(bond, skb) % count];
+		bond_dev_queue_xmit(bond, skb, slave->dev);
+	} else {
+		bond_tx_drop(dev, skb);
+	}
+
+	return NETDEV_TX_OK;
+}
+
+/* in broadcast mode, we send everything to all usable interfaces. */
+static netdev_tx_t bond_xmit_broadcast(struct sk_buff *skb,
+				       struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave = NULL;
+	struct list_head *iter;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (bond_is_last_slave(bond, slave))
+			break;
+		if (bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
+			struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
+
+			if (!skb2) {
+				net_err_ratelimited("%s: Error: %s: skb_clone() failed\n",
+						    bond_dev->name, __func__);
+				continue;
+			}
+			bond_dev_queue_xmit(bond, skb2, slave->dev);
+		}
+	}
+	if (slave && bond_slave_is_up(slave) && slave->link == BOND_LINK_UP)
+		bond_dev_queue_xmit(bond, skb, slave->dev);
+	else
+		bond_tx_drop(bond_dev, skb);
+
+	return NETDEV_TX_OK;
+}
+
+/*------------------------- Device initialization ---------------------------*/
+
+/* Lookup the slave that corresponds to a qid */
+static inline int bond_slave_override(struct bonding *bond,
+				      struct sk_buff *skb)
+{
+	struct slave *slave = NULL;
+	struct list_head *iter;
+
+	if (!skb_rx_queue_recorded(skb))
+		return 1;
+
+	/* Find out if any slaves have the same mapping as this skb. */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (slave->queue_id == skb_get_queue_mapping(skb)) {
+			if (bond_slave_is_up(slave) &&
+			    slave->link == BOND_LINK_UP) {
+				bond_dev_queue_xmit(bond, skb, slave->dev);
+				return 0;
+			}
+			/* If the slave isn't UP, use default transmit policy. */
+			break;
+		}
+	}
+
+	return 1;
+}
+
+
+static u16 bond_select_queue(struct net_device *dev, struct sk_buff *skb,
+			     struct net_device *sb_dev,
+			     select_queue_fallback_t fallback)
+{
+	/* This helper function exists to help dev_pick_tx get the correct
+	 * destination queue.  Using a helper function skips a call to
+	 * skb_tx_hash and will put the skbs in the queue we expect on their
+	 * way down to the bonding driver.
+	 */
+	u16 txq = skb_rx_queue_recorded(skb) ? skb_get_rx_queue(skb) : 0;
+
+	/* Save the original txq to restore before passing to the driver */
+	qdisc_skb_cb(skb)->slave_dev_queue_mapping = skb_get_queue_mapping(skb);
+
+	if (unlikely(txq >= dev->real_num_tx_queues)) {
+		do {
+			txq -= dev->real_num_tx_queues;
+		} while (txq >= dev->real_num_tx_queues);
+	}
+	return txq;
+}
+
+static netdev_tx_t __bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct bonding *bond = netdev_priv(dev);
+
+	if (bond_should_override_tx_queue(bond) &&
+	    !bond_slave_override(bond, skb))
+		return NETDEV_TX_OK;
+
+	switch (BOND_MODE(bond)) {
+	case BOND_MODE_ROUNDROBIN:
+		return bond_xmit_roundrobin(skb, dev);
+	case BOND_MODE_ACTIVEBACKUP:
+		return bond_xmit_activebackup(skb, dev);
+	case BOND_MODE_8023AD:
+	case BOND_MODE_XOR:
+		return bond_3ad_xor_xmit(skb, dev);
+	case BOND_MODE_BROADCAST:
+		return bond_xmit_broadcast(skb, dev);
+	case BOND_MODE_ALB:
+		return bond_alb_xmit(skb, dev);
+	case BOND_MODE_TLB:
+		return bond_tlb_xmit(skb, dev);
+	default:
+		/* Should never happen, mode already checked */
+		netdev_err(dev, "Unknown bonding mode %d\n", BOND_MODE(bond));
+		WARN_ON_ONCE(1);
+		bond_tx_drop(dev, skb);
+		return NETDEV_TX_OK;
+	}
+}
+
+static netdev_tx_t bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct bonding *bond = netdev_priv(dev);
+	netdev_tx_t ret = NETDEV_TX_OK;
+
+	/* If we risk deadlock from transmitting this in the
+	 * netpoll path, tell netpoll to queue the frame for later tx
+	 */
+	if (unlikely(is_netpoll_tx_blocked(dev)))
+		return NETDEV_TX_BUSY;
+
+	rcu_read_lock();
+	if (bond_has_slaves(bond))
+		ret = __bond_start_xmit(skb, dev);
+	else
+		bond_tx_drop(dev, skb);
+	rcu_read_unlock();
+
+	return ret;
+}
+
+static int bond_ethtool_get_link_ksettings(struct net_device *bond_dev,
+					   struct ethtool_link_ksettings *cmd)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	unsigned long speed = 0;
+	struct list_head *iter;
+	struct slave *slave;
+
+	cmd->base.duplex = DUPLEX_UNKNOWN;
+	cmd->base.port = PORT_OTHER;
+
+	/* Since bond_slave_can_tx returns false for all inactive or down slaves, we
+	 * do not need to check mode.  Though link speed might not represent
+	 * the true receive or transmit bandwidth (not all modes are symmetric)
+	 * this is an accurate maximum.
+	 */
+	bond_for_each_slave(bond, slave, iter) {
+		if (bond_slave_can_tx(slave)) {
+			if (slave->speed != SPEED_UNKNOWN)
+				speed += slave->speed;
+			if (cmd->base.duplex == DUPLEX_UNKNOWN &&
+			    slave->duplex != DUPLEX_UNKNOWN)
+				cmd->base.duplex = slave->duplex;
+		}
+	}
+	cmd->base.speed = speed ? : SPEED_UNKNOWN;
+
+	return 0;
+}
+
+static void bond_ethtool_get_drvinfo(struct net_device *bond_dev,
+				     struct ethtool_drvinfo *drvinfo)
+{
+	strlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));
+	strlcpy(drvinfo->version, DRV_VERSION, sizeof(drvinfo->version));
+	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version), "%d",
+		 BOND_ABI_VERSION);
+}
+
+static const struct ethtool_ops bond_ethtool_ops = {
+	.get_drvinfo		= bond_ethtool_get_drvinfo,
+	.get_link		= ethtool_op_get_link,
+	.get_link_ksettings	= bond_ethtool_get_link_ksettings,
+};
+
+static const struct net_device_ops bond_netdev_ops = {
+	.ndo_init		= bond_init,
+	.ndo_uninit		= bond_uninit,
+	.ndo_open		= bond_open,
+	.ndo_stop		= bond_close,
+	.ndo_start_xmit		= bond_start_xmit,
+	.ndo_select_queue	= bond_select_queue,
+	.ndo_get_stats64	= bond_get_stats,
+	.ndo_do_ioctl		= bond_do_ioctl,
+	.ndo_change_rx_flags	= bond_change_rx_flags,
+	.ndo_set_rx_mode	= bond_set_rx_mode,
+	.ndo_change_mtu		= bond_change_mtu,
+	.ndo_set_mac_address	= bond_set_mac_address,
+	.ndo_neigh_setup	= bond_neigh_setup,
+	.ndo_vlan_rx_add_vid	= bond_vlan_rx_add_vid,
+	.ndo_vlan_rx_kill_vid	= bond_vlan_rx_kill_vid,
+	.ndo_get_lock_subclass  = bond_get_nest_level,
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	.ndo_netpoll_setup	= bond_netpoll_setup,
+	.ndo_netpoll_cleanup	= bond_netpoll_cleanup,
+	.ndo_poll_controller	= bond_poll_controller,
+#endif
+	.ndo_add_slave		= bond_enslave,
+	.ndo_del_slave		= bond_release,
+	.ndo_fix_features	= bond_fix_features,
+	.ndo_features_check	= passthru_features_check,
+};
+
+static const struct device_type bond_type = {
+	.name = "bond",
+};
+
+static void bond_destructor(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	if (bond->wq)
+		destroy_workqueue(bond->wq);
+}
+
+void bond_setup(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+
+	spin_lock_init(&bond->mode_lock);
+	spin_lock_init(&bond->stats_lock);
+	bond->params = bonding_defaults;
+
+	/* Initialize pointers */
+	bond->dev = bond_dev;
+
+	/* Initialize the device entry points */
+	ether_setup(bond_dev);
+	bond_dev->max_mtu = ETH_MAX_MTU;
+	bond_dev->netdev_ops = &bond_netdev_ops;
+	bond_dev->ethtool_ops = &bond_ethtool_ops;
+
+	bond_dev->needs_free_netdev = true;
+	bond_dev->priv_destructor = bond_destructor;
+
+	SET_NETDEV_DEVTYPE(bond_dev, &bond_type);
+
+	/* Initialize the device options */
+	bond_dev->flags |= IFF_MASTER;
+	bond_dev->priv_flags |= IFF_BONDING | IFF_UNICAST_FLT | IFF_NO_QUEUE;
+	bond_dev->priv_flags &= ~(IFF_XMIT_DST_RELEASE | IFF_TX_SKB_SHARING);
+
+	/* don't acquire bond device's netif_tx_lock when transmitting */
+	bond_dev->features |= NETIF_F_LLTX;
+
+	/* By default, we declare the bond to be fully
+	 * VLAN hardware accelerated capable. Special
+	 * care is taken in the various xmit functions
+	 * when there are slaves that are not hw accel
+	 * capable
+	 */
+
+	/* Don't allow bond devices to change network namespaces. */
+	bond_dev->features |= NETIF_F_NETNS_LOCAL;
+
+	bond_dev->hw_features = BOND_VLAN_FEATURES |
+				NETIF_F_HW_VLAN_CTAG_RX |
+				NETIF_F_HW_VLAN_CTAG_FILTER;
+
+	bond_dev->hw_features |= NETIF_F_GSO_ENCAP_ALL | NETIF_F_GSO_UDP_L4;
+	bond_dev->features |= bond_dev->hw_features;
+	bond_dev->features |= NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_STAG_TX;
+}
+
+/* Destroy a bonding device.
+ * Must be under rtnl_lock when this function is called.
+ */
+static void bond_uninit(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	struct slave *slave;
+	struct bond_up_slave *arr;
+
+	bond_netpoll_cleanup(bond_dev);
+
+	/* Release the bonded slaves */
+	bond_for_each_slave(bond, slave, iter)
+		__bond_release_one(bond_dev, slave->dev, true, true);
+	netdev_info(bond_dev, "Released all slaves\n");
+
+	arr = rtnl_dereference(bond->slave_arr);
+	if (arr) {
+		RCU_INIT_POINTER(bond->slave_arr, NULL);
+		kfree_rcu(arr, rcu);
+	}
+
+	list_del(&bond->bond_list);
+
+	bond_debug_unregister(bond);
+}
+
+/*------------------------- Module initialization ---------------------------*/
+
+static int bond_check_params(struct bond_params *params)
+{
+	int arp_validate_value, fail_over_mac_value, primary_reselect_value, i;
+	struct bond_opt_value newval;
+	const struct bond_opt_value *valptr;
+	int arp_all_targets_value = 0;
+	u16 ad_actor_sys_prio = 0;
+	u16 ad_user_port_key = 0;
+	__be32 arp_target[BOND_MAX_ARP_TARGETS] = { 0 };
+	int arp_ip_count;
+	int bond_mode	= BOND_MODE_ROUNDROBIN;
+	int xmit_hashtype = BOND_XMIT_POLICY_LAYER2;
+	int lacp_fast = 0;
+	int tlb_dynamic_lb;
+
+	/* Convert string parameters. */
+	if (mode) {
+		bond_opt_initstr(&newval, mode);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_MODE), &newval);
+		if (!valptr) {
+			pr_err("Error: Invalid bonding mode \"%s\"\n", mode);
+			return -EINVAL;
+		}
+		bond_mode = valptr->value;
+	}
+
+	if (xmit_hash_policy) {
+		if (bond_mode == BOND_MODE_ROUNDROBIN ||
+		    bond_mode == BOND_MODE_ACTIVEBACKUP ||
+		    bond_mode == BOND_MODE_BROADCAST) {
+			pr_info("xmit_hash_policy param is irrelevant in mode %s\n",
+				bond_mode_name(bond_mode));
+		} else {
+			bond_opt_initstr(&newval, xmit_hash_policy);
+			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_XMIT_HASH),
+						&newval);
+			if (!valptr) {
+				pr_err("Error: Invalid xmit_hash_policy \"%s\"\n",
+				       xmit_hash_policy);
+				return -EINVAL;
+			}
+			xmit_hashtype = valptr->value;
+		}
+	}
+
+	if (lacp_rate) {
+		if (bond_mode != BOND_MODE_8023AD) {
+			pr_info("lacp_rate param is irrelevant in mode %s\n",
+				bond_mode_name(bond_mode));
+		} else {
+			bond_opt_initstr(&newval, lacp_rate);
+			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_LACP_RATE),
+						&newval);
+			if (!valptr) {
+				pr_err("Error: Invalid lacp rate \"%s\"\n",
+				       lacp_rate);
+				return -EINVAL;
+			}
+			lacp_fast = valptr->value;
+		}
+	}
+
+	if (ad_select) {
+		bond_opt_initstr(&newval, ad_select);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_SELECT),
+					&newval);
+		if (!valptr) {
+			pr_err("Error: Invalid ad_select \"%s\"\n", ad_select);
+			return -EINVAL;
+		}
+		params->ad_select = valptr->value;
+		if (bond_mode != BOND_MODE_8023AD)
+			pr_warn("ad_select param only affects 802.3ad mode\n");
+	} else {
+		params->ad_select = BOND_AD_STABLE;
+	}
+
+	if (max_bonds < 0) {
+		pr_warn("Warning: max_bonds (%d) not in range %d-%d, so it was reset to BOND_DEFAULT_MAX_BONDS (%d)\n",
+			max_bonds, 0, INT_MAX, BOND_DEFAULT_MAX_BONDS);
+		max_bonds = BOND_DEFAULT_MAX_BONDS;
+	}
+
+	if (miimon < 0) {
+		pr_warn("Warning: miimon module parameter (%d), not in range 0-%d, so it was reset to 0\n",
+			miimon, INT_MAX);
+		miimon = 0;
+	}
+
+	if (updelay < 0) {
+		pr_warn("Warning: updelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
+			updelay, INT_MAX);
+		updelay = 0;
+	}
+
+	if (downdelay < 0) {
+		pr_warn("Warning: downdelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
+			downdelay, INT_MAX);
+		downdelay = 0;
+	}
+
+	if ((use_carrier != 0) && (use_carrier != 1)) {
+		pr_warn("Warning: use_carrier module parameter (%d), not of valid value (0/1), so it was set to 1\n",
+			use_carrier);
+		use_carrier = 1;
+	}
+
+	if (num_peer_notif < 0 || num_peer_notif > 255) {
+		pr_warn("Warning: num_grat_arp/num_unsol_na (%d) not in range 0-255 so it was reset to 1\n",
+			num_peer_notif);
+		num_peer_notif = 1;
+	}
+
+	/* reset values for 802.3ad/TLB/ALB */
+	if (!bond_mode_uses_arp(bond_mode)) {
+		if (!miimon) {
+			pr_warn("Warning: miimon must be specified, otherwise bonding will not detect link failure, speed and duplex which are essential for 802.3ad operation\n");
+			pr_warn("Forcing miimon to 100msec\n");
+			miimon = BOND_DEFAULT_MIIMON;
+		}
+	}
+
+	if (tx_queues < 1 || tx_queues > 255) {
+		pr_warn("Warning: tx_queues (%d) should be between 1 and 255, resetting to %d\n",
+			tx_queues, BOND_DEFAULT_TX_QUEUES);
+		tx_queues = BOND_DEFAULT_TX_QUEUES;
+	}
+
+	if ((all_slaves_active != 0) && (all_slaves_active != 1)) {
+		pr_warn("Warning: all_slaves_active module parameter (%d), not of valid value (0/1), so it was set to 0\n",
+			all_slaves_active);
+		all_slaves_active = 0;
+	}
+
+	if (resend_igmp < 0 || resend_igmp > 255) {
+		pr_warn("Warning: resend_igmp (%d) should be between 0 and 255, resetting to %d\n",
+			resend_igmp, BOND_DEFAULT_RESEND_IGMP);
+		resend_igmp = BOND_DEFAULT_RESEND_IGMP;
+	}
+
+	bond_opt_initval(&newval, packets_per_slave);
+	if (!bond_opt_parse(bond_opt_get(BOND_OPT_PACKETS_PER_SLAVE), &newval)) {
+		pr_warn("Warning: packets_per_slave (%d) should be between 0 and %u resetting to 1\n",
+			packets_per_slave, USHRT_MAX);
+		packets_per_slave = 1;
+	}
+
+	if (bond_mode == BOND_MODE_ALB) {
+		pr_notice("In ALB mode you might experience client disconnections upon reconnection of a link if the bonding module updelay parameter (%d msec) is incompatible with the forwarding delay time of the switch\n",
+			  updelay);
+	}
+
+	if (!miimon) {
+		if (updelay || downdelay) {
+			/* just warn the user the up/down delay will have
+			 * no effect since miimon is zero...
+			 */
+			pr_warn("Warning: miimon module parameter not set and updelay (%d) or downdelay (%d) module parameter is set; updelay and downdelay have no effect unless miimon is set\n",
+				updelay, downdelay);
+		}
+	} else {
+		/* don't allow arp monitoring */
+		if (arp_interval) {
+			pr_warn("Warning: miimon (%d) and arp_interval (%d) can't be used simultaneously, disabling ARP monitoring\n",
+				miimon, arp_interval);
+			arp_interval = 0;
+		}
+
+		if ((updelay % miimon) != 0) {
+			pr_warn("Warning: updelay (%d) is not a multiple of miimon (%d), updelay rounded to %d ms\n",
+				updelay, miimon, (updelay / miimon) * miimon);
+		}
+
+		updelay /= miimon;
+
+		if ((downdelay % miimon) != 0) {
+			pr_warn("Warning: downdelay (%d) is not a multiple of miimon (%d), downdelay rounded to %d ms\n",
+				downdelay, miimon,
+				(downdelay / miimon) * miimon);
+		}
+
+		downdelay /= miimon;
+	}
+
+	if (arp_interval < 0) {
+		pr_warn("Warning: arp_interval module parameter (%d), not in range 0-%d, so it was reset to 0\n",
+			arp_interval, INT_MAX);
+		arp_interval = 0;
+	}
+
+	for (arp_ip_count = 0, i = 0;
+	     (arp_ip_count < BOND_MAX_ARP_TARGETS) && arp_ip_target[i]; i++) {
+		__be32 ip;
+
+		/* not a complete check, but good enough to catch mistakes */
+		if (!in4_pton(arp_ip_target[i], -1, (u8 *)&ip, -1, NULL) ||
+		    !bond_is_ip_target_ok(ip)) {
+			pr_warn("Warning: bad arp_ip_target module parameter (%s), ARP monitoring will not be performed\n",
+				arp_ip_target[i]);
+			arp_interval = 0;
+		} else {
+			if (bond_get_targets_ip(arp_target, ip) == -1)
+				arp_target[arp_ip_count++] = ip;
+			else
+				pr_warn("Warning: duplicate address %pI4 in arp_ip_target, skipping\n",
+					&ip);
+		}
+	}
+
+	if (arp_interval && !arp_ip_count) {
+		/* don't allow arping if no arp_ip_target given... */
+		pr_warn("Warning: arp_interval module parameter (%d) specified without providing an arp_ip_target parameter, arp_interval was reset to 0\n",
+			arp_interval);
+		arp_interval = 0;
+	}
+
+	if (arp_validate) {
+		if (!arp_interval) {
+			pr_err("arp_validate requires arp_interval\n");
+			return -EINVAL;
+		}
+
+		bond_opt_initstr(&newval, arp_validate);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_VALIDATE),
+					&newval);
+		if (!valptr) {
+			pr_err("Error: invalid arp_validate \"%s\"\n",
+			       arp_validate);
+			return -EINVAL;
+		}
+		arp_validate_value = valptr->value;
+	} else {
+		arp_validate_value = 0;
+	}
+
+	if (arp_all_targets) {
+		bond_opt_initstr(&newval, arp_all_targets);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_ALL_TARGETS),
+					&newval);
+		if (!valptr) {
+			pr_err("Error: invalid arp_all_targets_value \"%s\"\n",
+			       arp_all_targets);
+			arp_all_targets_value = 0;
+		} else {
+			arp_all_targets_value = valptr->value;
+		}
+	}
+
+	if (miimon) {
+		pr_info("MII link monitoring set to %d ms\n", miimon);
+	} else if (arp_interval) {
+		valptr = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
+					  arp_validate_value);
+		pr_info("ARP monitoring set to %d ms, validate %s, with %d target(s):",
+			arp_interval, valptr->string, arp_ip_count);
+
+		for (i = 0; i < arp_ip_count; i++)
+			pr_cont(" %s", arp_ip_target[i]);
+
+		pr_cont("\n");
+
+	} else if (max_bonds) {
+		/* miimon and arp_interval not set, we need one so things
+		 * work as expected, see bonding.txt for details
+		 */
+		pr_debug("Warning: either miimon or arp_interval and arp_ip_target module parameters must be specified, otherwise bonding will not detect link failures! see bonding.txt for details\n");
+	}
+
+	if (primary && !bond_mode_uses_primary(bond_mode)) {
+		/* currently, using a primary only makes sense
+		 * in active backup, TLB or ALB modes
+		 */
+		pr_warn("Warning: %s primary device specified but has no effect in %s mode\n",
+			primary, bond_mode_name(bond_mode));
+		primary = NULL;
+	}
+
+	if (primary && primary_reselect) {
+		bond_opt_initstr(&newval, primary_reselect);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_PRIMARY_RESELECT),
+					&newval);
+		if (!valptr) {
+			pr_err("Error: Invalid primary_reselect \"%s\"\n",
+			       primary_reselect);
+			return -EINVAL;
+		}
+		primary_reselect_value = valptr->value;
+	} else {
+		primary_reselect_value = BOND_PRI_RESELECT_ALWAYS;
+	}
+
+	if (fail_over_mac) {
+		bond_opt_initstr(&newval, fail_over_mac);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_FAIL_OVER_MAC),
+					&newval);
+		if (!valptr) {
+			pr_err("Error: invalid fail_over_mac \"%s\"\n",
+			       fail_over_mac);
+			return -EINVAL;
+		}
+		fail_over_mac_value = valptr->value;
+		if (bond_mode != BOND_MODE_ACTIVEBACKUP)
+			pr_warn("Warning: fail_over_mac only affects active-backup mode\n");
+	} else {
+		fail_over_mac_value = BOND_FOM_NONE;
+	}
+
+	bond_opt_initstr(&newval, "default");
+	valptr = bond_opt_parse(
+			bond_opt_get(BOND_OPT_AD_ACTOR_SYS_PRIO),
+				     &newval);
+	if (!valptr) {
+		pr_err("Error: No ad_actor_sys_prio default value");
+		return -EINVAL;
+	}
+	ad_actor_sys_prio = valptr->value;
+
+	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_USER_PORT_KEY),
+				&newval);
+	if (!valptr) {
+		pr_err("Error: No ad_user_port_key default value");
+		return -EINVAL;
+	}
+	ad_user_port_key = valptr->value;
+
+	bond_opt_initstr(&newval, "default");
+	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_TLB_DYNAMIC_LB), &newval);
+	if (!valptr) {
+		pr_err("Error: No tlb_dynamic_lb default value");
+		return -EINVAL;
+	}
+	tlb_dynamic_lb = valptr->value;
+
+	if (lp_interval == 0) {
+		pr_warn("Warning: ip_interval must be between 1 and %d, so it was reset to %d\n",
+			INT_MAX, BOND_ALB_DEFAULT_LP_INTERVAL);
+		lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
+	}
+
+	/* fill params struct with the proper values */
+	params->mode = bond_mode;
+	params->xmit_policy = xmit_hashtype;
+	params->miimon = miimon;
+	params->num_peer_notif = num_peer_notif;
+	params->arp_interval = arp_interval;
+	params->arp_validate = arp_validate_value;
+	params->arp_all_targets = arp_all_targets_value;
+	params->updelay = updelay;
+	params->downdelay = downdelay;
+	params->use_carrier = use_carrier;
+	params->lacp_fast = lacp_fast;
+	params->primary[0] = 0;
+	params->primary_reselect = primary_reselect_value;
+	params->fail_over_mac = fail_over_mac_value;
+	params->tx_queues = tx_queues;
+	params->all_slaves_active = all_slaves_active;
+	params->resend_igmp = resend_igmp;
+	params->min_links = min_links;
+	params->lp_interval = lp_interval;
+	params->packets_per_slave = packets_per_slave;
+	params->tlb_dynamic_lb = tlb_dynamic_lb;
+	params->ad_actor_sys_prio = ad_actor_sys_prio;
+	eth_zero_addr(params->ad_actor_system);
+	params->ad_user_port_key = ad_user_port_key;
+	if (packets_per_slave > 0) {
+		params->reciprocal_packets_per_slave =
+			reciprocal_value(packets_per_slave);
+	} else {
+		/* reciprocal_packets_per_slave is unused if
+		 * packets_per_slave is 0 or 1, just initialize it
+		 */
+		params->reciprocal_packets_per_slave =
+			(struct reciprocal_value) { 0 };
+	}
+
+	if (primary) {
+		strncpy(params->primary, primary, IFNAMSIZ);
+		params->primary[IFNAMSIZ - 1] = 0;
+	}
+
+	memcpy(params->arp_targets, arp_target, sizeof(arp_target));
+
+	return 0;
+}
+
+/* Called from registration process */
+static int bond_init(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
+
+	netdev_dbg(bond_dev, "Begin bond_init\n");
+
+	bond->wq = alloc_ordered_workqueue(bond_dev->name, WQ_MEM_RECLAIM);
+	if (!bond->wq)
+		return -ENOMEM;
+
+	bond->nest_level = SINGLE_DEPTH_NESTING;
+	netdev_lockdep_set_classes(bond_dev);
+
+	list_add_tail(&bond->bond_list, &bn->dev_list);
+
+	bond_prepare_sysfs_group(bond);
+
+	bond_debug_register(bond);
+
+	/* Ensure valid dev_addr */
+	if (is_zero_ether_addr(bond_dev->dev_addr) &&
+	    bond_dev->addr_assign_type == NET_ADDR_PERM)
+		eth_hw_addr_random(bond_dev);
+
+	return 0;
+}
+
+unsigned int bond_get_num_tx_queues(void)
+{
+	return tx_queues;
+}
+
+/* Create a new bond based on the specified name and bonding parameters.
+ * If name is NULL, obtain a suitable "bond%d" name for us.
+ * Caller must NOT hold rtnl_lock; we need to release it here before we
+ * set up our sysfs entries.
+ */
+int bond_create(struct net *net, const char *name)
+{
+	struct net_device *bond_dev;
+	struct bonding *bond;
+	struct alb_bond_info *bond_info;
+	int res;
+
+	rtnl_lock();
+
+	bond_dev = alloc_netdev_mq(sizeof(struct bonding),
+				   name ? name : "bond%d", NET_NAME_UNKNOWN,
+				   bond_setup, tx_queues);
+	if (!bond_dev) {
+		pr_err("%s: eek! can't alloc netdev!\n", name);
+		rtnl_unlock();
+		return -ENOMEM;
+	}
+
+	/*
+	 * Initialize rx_hashtbl_used_head to RLB_NULL_INDEX.
+	 * It is set to 0 by default which is wrong.
+	 */
+	bond = netdev_priv(bond_dev);
+	bond_info = &(BOND_ALB_INFO(bond));
+	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
+
+	dev_net_set(bond_dev, net);
+	bond_dev->rtnl_link_ops = &bond_link_ops;
+
+	res = register_netdevice(bond_dev);
+
+	netif_carrier_off(bond_dev);
+
+	bond_work_init_all(bond);
+
+	rtnl_unlock();
+	if (res < 0)
+		free_netdev(bond_dev);
+	return res;
+}
+
+static int __net_init bond_net_init(struct net *net)
+{
+	struct bond_net *bn = net_generic(net, bond_net_id);
+
+	bn->net = net;
+	INIT_LIST_HEAD(&bn->dev_list);
+
+	bond_create_proc_dir(bn);
+	bond_create_sysfs(bn);
+
+	return 0;
+}
+
+static void __net_exit bond_net_exit(struct net *net)
+{
+	struct bond_net *bn = net_generic(net, bond_net_id);
+	struct bonding *bond, *tmp_bond;
+	LIST_HEAD(list);
+
+	bond_destroy_sysfs(bn);
+
+	/* Kill off any bonds created after unregistering bond rtnl ops */
+	rtnl_lock();
+	list_for_each_entry_safe(bond, tmp_bond, &bn->dev_list, bond_list)
+		unregister_netdevice_queue(bond->dev, &list);
+	unregister_netdevice_many(&list);
+	rtnl_unlock();
+
+	bond_destroy_proc_dir(bn);
+}
+
+static struct pernet_operations bond_net_ops = {
+	.init = bond_net_init,
+	.exit = bond_net_exit,
+	.id   = &bond_net_id,
+	.size = sizeof(struct bond_net),
+};
+
+static int __init bonding_init(void)
+{
+	int i;
+	int res;
+
+	pr_info("%s", bond_version);
+
+	res = bond_check_params(&bonding_defaults);
+	if (res)
+		goto out;
+
+	res = register_pernet_subsys(&bond_net_ops);
+	if (res)
+		goto out;
+
+	res = bond_netlink_init();
+	if (res)
+		goto err_link;
+
+	bond_create_debugfs();
+
+	for (i = 0; i < max_bonds; i++) {
+		res = bond_create(&init_net, NULL);
+		if (res)
+			goto err;
+	}
+
+	register_netdevice_notifier(&bond_netdev_notifier);
+
+	register_toe_bond_rr_select_cb(bond_xmit_roundrobin_select);
+	register_toe_bond_acb_select_cb(bond_xmit_activebackup_select);
+	register_toe_bond_8023AD_select_cb(bond_xmit_xor_select);
+	register_toe_bond_xor_select_cb(bond_xmit_xor_select);
+out:
+	return res;
+err:
+	bond_destroy_debugfs();
+	bond_netlink_fini();
+err_link:
+	unregister_pernet_subsys(&bond_net_ops);
+	goto out;
+
+}
+
+static void __exit bonding_exit(void)
+{
+	unregister_netdevice_notifier(&bond_netdev_notifier);
+
+	bond_destroy_debugfs();
+
+	bond_netlink_fini();
+	unregister_pernet_subsys(&bond_net_ops);
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	/* Make sure we don't have an imbalance on our netpoll blocking */
+	WARN_ON(atomic_read(&netpoll_block_tx));
+#endif
+}
+
+module_init(bonding_init);
+module_exit(bonding_exit);
+MODULE_LICENSE("GPL");
+MODULE_VERSION(DRV_VERSION);
+MODULE_DESCRIPTION(DRV_DESCRIPTION ", v" DRV_VERSION);
+MODULE_AUTHOR("Thomas Davis, tadavis@lbl.gov and many others");
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.103/bond_netlink.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.103/bond_netlink.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,709 @@
+/*
+ * drivers/net/bond/bond_netlink.c - Netlink interface for bonding
+ * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
+ * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#include <linux/module.h>
+#include <linux/errno.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/if_link.h>
+#include <linux/if_ether.h>
+#include <net/netlink.h>
+#include <net/rtnetlink.h>
+#include <net/bonding.h>
+
+static size_t bond_get_slave_size(const struct net_device *bond_dev,
+				  const struct net_device *slave_dev)
+{
+	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_STATE */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_MII_STATUS */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_SLAVE_LINK_FAILURE_COUNT */
+		nla_total_size(MAX_ADDR_LEN) +	/* IFLA_BOND_SLAVE_PERM_HWADDR */
+		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_QUEUE_ID */
+		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_AGGREGATOR_ID */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE */
+		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE */
+		0;
+}
+
+static int bond_fill_slave_info(struct sk_buff *skb,
+				const struct net_device *bond_dev,
+				const struct net_device *slave_dev)
+{
+	struct slave *slave = bond_slave_get_rtnl(slave_dev);
+
+	if (nla_put_u8(skb, IFLA_BOND_SLAVE_STATE, bond_slave_state(slave)))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_SLAVE_MII_STATUS, slave->link))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_SLAVE_LINK_FAILURE_COUNT,
+			slave->link_failure_count))
+		goto nla_put_failure;
+
+	if (nla_put(skb, IFLA_BOND_SLAVE_PERM_HWADDR,
+		    slave_dev->addr_len, slave->perm_hwaddr))
+		goto nla_put_failure;
+
+	if (nla_put_u16(skb, IFLA_BOND_SLAVE_QUEUE_ID, slave->queue_id))
+		goto nla_put_failure;
+
+	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
+		const struct aggregator *agg;
+		const struct port *ad_port;
+
+		ad_port = &SLAVE_AD_INFO(slave)->port;
+		agg = SLAVE_AD_INFO(slave)->port.aggregator;
+		if (agg) {
+			if (nla_put_u16(skb, IFLA_BOND_SLAVE_AD_AGGREGATOR_ID,
+					agg->aggregator_identifier))
+				goto nla_put_failure;
+			if (nla_put_u8(skb,
+				       IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE,
+				       ad_port->actor_oper_port_state))
+				goto nla_put_failure;
+			if (nla_put_u16(skb,
+					IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE,
+					ad_port->partner_oper.port_state))
+				goto nla_put_failure;
+		}
+	}
+
+	return 0;
+
+nla_put_failure:
+	return -EMSGSIZE;
+}
+
+static const struct nla_policy bond_policy[IFLA_BOND_MAX + 1] = {
+	[IFLA_BOND_MODE]		= { .type = NLA_U8 },
+	[IFLA_BOND_ACTIVE_SLAVE]	= { .type = NLA_U32 },
+	[IFLA_BOND_MIIMON]		= { .type = NLA_U32 },
+	[IFLA_BOND_UPDELAY]		= { .type = NLA_U32 },
+	[IFLA_BOND_DOWNDELAY]		= { .type = NLA_U32 },
+	[IFLA_BOND_USE_CARRIER]		= { .type = NLA_U8 },
+	[IFLA_BOND_ARP_INTERVAL]	= { .type = NLA_U32 },
+	[IFLA_BOND_ARP_IP_TARGET]	= { .type = NLA_NESTED },
+	[IFLA_BOND_ARP_VALIDATE]	= { .type = NLA_U32 },
+	[IFLA_BOND_ARP_ALL_TARGETS]	= { .type = NLA_U32 },
+	[IFLA_BOND_PRIMARY]		= { .type = NLA_U32 },
+	[IFLA_BOND_PRIMARY_RESELECT]	= { .type = NLA_U8 },
+	[IFLA_BOND_FAIL_OVER_MAC]	= { .type = NLA_U8 },
+	[IFLA_BOND_XMIT_HASH_POLICY]	= { .type = NLA_U8 },
+	[IFLA_BOND_RESEND_IGMP]		= { .type = NLA_U32 },
+	[IFLA_BOND_NUM_PEER_NOTIF]	= { .type = NLA_U8 },
+	[IFLA_BOND_ALL_SLAVES_ACTIVE]	= { .type = NLA_U8 },
+	[IFLA_BOND_MIN_LINKS]		= { .type = NLA_U32 },
+	[IFLA_BOND_LP_INTERVAL]		= { .type = NLA_U32 },
+	[IFLA_BOND_PACKETS_PER_SLAVE]	= { .type = NLA_U32 },
+	[IFLA_BOND_AD_LACP_RATE]	= { .type = NLA_U8 },
+	[IFLA_BOND_AD_SELECT]		= { .type = NLA_U8 },
+	[IFLA_BOND_AD_INFO]		= { .type = NLA_NESTED },
+	[IFLA_BOND_AD_ACTOR_SYS_PRIO]	= { .type = NLA_U16 },
+	[IFLA_BOND_AD_USER_PORT_KEY]	= { .type = NLA_U16 },
+	[IFLA_BOND_AD_ACTOR_SYSTEM]	= { .type = NLA_BINARY,
+					    .len  = ETH_ALEN },
+	[IFLA_BOND_TLB_DYNAMIC_LB]	= { .type = NLA_U8 },
+};
+
+static const struct nla_policy bond_slave_policy[IFLA_BOND_SLAVE_MAX + 1] = {
+	[IFLA_BOND_SLAVE_QUEUE_ID]	= { .type = NLA_U16 },
+};
+
+static int bond_validate(struct nlattr *tb[], struct nlattr *data[],
+			 struct netlink_ext_ack *extack)
+{
+	if (tb[IFLA_ADDRESS]) {
+		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN)
+			return -EINVAL;
+		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS])))
+			return -EADDRNOTAVAIL;
+	}
+	return 0;
+}
+
+static int bond_slave_changelink(struct net_device *bond_dev,
+				 struct net_device *slave_dev,
+				 struct nlattr *tb[], struct nlattr *data[],
+				 struct netlink_ext_ack *extack)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct bond_opt_value newval;
+	int err;
+
+	if (!data)
+		return 0;
+
+	if (data[IFLA_BOND_SLAVE_QUEUE_ID]) {
+		u16 queue_id = nla_get_u16(data[IFLA_BOND_SLAVE_QUEUE_ID]);
+		char queue_id_str[IFNAMSIZ + 7];
+
+		/* queue_id option setting expects slave_name:queue_id */
+		snprintf(queue_id_str, sizeof(queue_id_str), "%s:%u\n",
+			 slave_dev->name, queue_id);
+		bond_opt_initstr(&newval, queue_id_str);
+		err = __bond_opt_set(bond, BOND_OPT_QUEUE_ID, &newval);
+		if (err)
+			return err;
+	}
+
+	return 0;
+}
+
+static int bond_changelink(struct net_device *bond_dev, struct nlattr *tb[],
+			   struct nlattr *data[],
+			   struct netlink_ext_ack *extack)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct bond_opt_value newval;
+	int miimon = 0;
+	int err;
+
+	if (!data)
+		return 0;
+
+	if (data[IFLA_BOND_MODE]) {
+		int mode = nla_get_u8(data[IFLA_BOND_MODE]);
+
+		bond_opt_initval(&newval, mode);
+		err = __bond_opt_set(bond, BOND_OPT_MODE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ACTIVE_SLAVE]) {
+		int ifindex = nla_get_u32(data[IFLA_BOND_ACTIVE_SLAVE]);
+		struct net_device *slave_dev;
+		char *active_slave = "";
+
+		if (ifindex != 0) {
+			slave_dev = __dev_get_by_index(dev_net(bond_dev),
+						       ifindex);
+			if (!slave_dev)
+				return -ENODEV;
+			active_slave = slave_dev->name;
+		}
+		bond_opt_initstr(&newval, active_slave);
+		err = __bond_opt_set(bond, BOND_OPT_ACTIVE_SLAVE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_MIIMON]) {
+		miimon = nla_get_u32(data[IFLA_BOND_MIIMON]);
+
+		bond_opt_initval(&newval, miimon);
+		err = __bond_opt_set(bond, BOND_OPT_MIIMON, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_UPDELAY]) {
+		int updelay = nla_get_u32(data[IFLA_BOND_UPDELAY]);
+
+		bond_opt_initval(&newval, updelay);
+		err = __bond_opt_set(bond, BOND_OPT_UPDELAY, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_DOWNDELAY]) {
+		int downdelay = nla_get_u32(data[IFLA_BOND_DOWNDELAY]);
+
+		bond_opt_initval(&newval, downdelay);
+		err = __bond_opt_set(bond, BOND_OPT_DOWNDELAY, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_USE_CARRIER]) {
+		int use_carrier = nla_get_u8(data[IFLA_BOND_USE_CARRIER]);
+
+		bond_opt_initval(&newval, use_carrier);
+		err = __bond_opt_set(bond, BOND_OPT_USE_CARRIER, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ARP_INTERVAL]) {
+		int arp_interval = nla_get_u32(data[IFLA_BOND_ARP_INTERVAL]);
+
+		if (arp_interval && miimon) {
+			netdev_err(bond->dev, "ARP monitoring cannot be used with MII monitoring\n");
+			return -EINVAL;
+		}
+
+		bond_opt_initval(&newval, arp_interval);
+		err = __bond_opt_set(bond, BOND_OPT_ARP_INTERVAL, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ARP_IP_TARGET]) {
+		struct nlattr *attr;
+		int i = 0, rem;
+
+		bond_option_arp_ip_targets_clear(bond);
+		nla_for_each_nested(attr, data[IFLA_BOND_ARP_IP_TARGET], rem) {
+			__be32 target;
+
+			if (nla_len(attr) < sizeof(target))
+				return -EINVAL;
+
+			target = nla_get_be32(attr);
+
+			bond_opt_initval(&newval, (__force u64)target);
+			err = __bond_opt_set(bond, BOND_OPT_ARP_TARGETS,
+					     &newval);
+			if (err)
+				break;
+			i++;
+		}
+		if (i == 0 && bond->params.arp_interval)
+			netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ARP_VALIDATE]) {
+		int arp_validate = nla_get_u32(data[IFLA_BOND_ARP_VALIDATE]);
+
+		if (arp_validate && miimon) {
+			netdev_err(bond->dev, "ARP validating cannot be used with MII monitoring\n");
+			return -EINVAL;
+		}
+
+		bond_opt_initval(&newval, arp_validate);
+		err = __bond_opt_set(bond, BOND_OPT_ARP_VALIDATE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ARP_ALL_TARGETS]) {
+		int arp_all_targets =
+			nla_get_u32(data[IFLA_BOND_ARP_ALL_TARGETS]);
+
+		bond_opt_initval(&newval, arp_all_targets);
+		err = __bond_opt_set(bond, BOND_OPT_ARP_ALL_TARGETS, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_PRIMARY]) {
+		int ifindex = nla_get_u32(data[IFLA_BOND_PRIMARY]);
+		struct net_device *dev;
+		char *primary = "";
+
+		dev = __dev_get_by_index(dev_net(bond_dev), ifindex);
+		if (dev)
+			primary = dev->name;
+
+		bond_opt_initstr(&newval, primary);
+		err = __bond_opt_set(bond, BOND_OPT_PRIMARY, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_PRIMARY_RESELECT]) {
+		int primary_reselect =
+			nla_get_u8(data[IFLA_BOND_PRIMARY_RESELECT]);
+
+		bond_opt_initval(&newval, primary_reselect);
+		err = __bond_opt_set(bond, BOND_OPT_PRIMARY_RESELECT, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_FAIL_OVER_MAC]) {
+		int fail_over_mac =
+			nla_get_u8(data[IFLA_BOND_FAIL_OVER_MAC]);
+
+		bond_opt_initval(&newval, fail_over_mac);
+		err = __bond_opt_set(bond, BOND_OPT_FAIL_OVER_MAC, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_XMIT_HASH_POLICY]) {
+		int xmit_hash_policy =
+			nla_get_u8(data[IFLA_BOND_XMIT_HASH_POLICY]);
+
+		bond_opt_initval(&newval, xmit_hash_policy);
+		err = __bond_opt_set(bond, BOND_OPT_XMIT_HASH, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_RESEND_IGMP]) {
+		int resend_igmp =
+			nla_get_u32(data[IFLA_BOND_RESEND_IGMP]);
+
+		bond_opt_initval(&newval, resend_igmp);
+		err = __bond_opt_set(bond, BOND_OPT_RESEND_IGMP, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_NUM_PEER_NOTIF]) {
+		int num_peer_notif =
+			nla_get_u8(data[IFLA_BOND_NUM_PEER_NOTIF]);
+
+		bond_opt_initval(&newval, num_peer_notif);
+		err = __bond_opt_set(bond, BOND_OPT_NUM_PEER_NOTIF, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ALL_SLAVES_ACTIVE]) {
+		int all_slaves_active =
+			nla_get_u8(data[IFLA_BOND_ALL_SLAVES_ACTIVE]);
+
+		bond_opt_initval(&newval, all_slaves_active);
+		err = __bond_opt_set(bond, BOND_OPT_ALL_SLAVES_ACTIVE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_MIN_LINKS]) {
+		int min_links =
+			nla_get_u32(data[IFLA_BOND_MIN_LINKS]);
+
+		bond_opt_initval(&newval, min_links);
+		err = __bond_opt_set(bond, BOND_OPT_MINLINKS, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_LP_INTERVAL]) {
+		int lp_interval =
+			nla_get_u32(data[IFLA_BOND_LP_INTERVAL]);
+
+		bond_opt_initval(&newval, lp_interval);
+		err = __bond_opt_set(bond, BOND_OPT_LP_INTERVAL, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_PACKETS_PER_SLAVE]) {
+		int packets_per_slave =
+			nla_get_u32(data[IFLA_BOND_PACKETS_PER_SLAVE]);
+
+		bond_opt_initval(&newval, packets_per_slave);
+		err = __bond_opt_set(bond, BOND_OPT_PACKETS_PER_SLAVE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_AD_LACP_RATE]) {
+		int lacp_rate =
+			nla_get_u8(data[IFLA_BOND_AD_LACP_RATE]);
+
+		bond_opt_initval(&newval, lacp_rate);
+		err = __bond_opt_set(bond, BOND_OPT_LACP_RATE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_AD_SELECT]) {
+		int ad_select =
+			nla_get_u8(data[IFLA_BOND_AD_SELECT]);
+
+		bond_opt_initval(&newval, ad_select);
+		err = __bond_opt_set(bond, BOND_OPT_AD_SELECT, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_AD_ACTOR_SYS_PRIO]) {
+		int actor_sys_prio =
+			nla_get_u16(data[IFLA_BOND_AD_ACTOR_SYS_PRIO]);
+
+		bond_opt_initval(&newval, actor_sys_prio);
+		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYS_PRIO, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_AD_USER_PORT_KEY]) {
+		int port_key =
+			nla_get_u16(data[IFLA_BOND_AD_USER_PORT_KEY]);
+
+		bond_opt_initval(&newval, port_key);
+		err = __bond_opt_set(bond, BOND_OPT_AD_USER_PORT_KEY, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_AD_ACTOR_SYSTEM]) {
+		if (nla_len(data[IFLA_BOND_AD_ACTOR_SYSTEM]) != ETH_ALEN)
+			return -EINVAL;
+
+		bond_opt_initval(&newval,
+				 nla_get_u64(data[IFLA_BOND_AD_ACTOR_SYSTEM]));
+		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYSTEM, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_TLB_DYNAMIC_LB]) {
+		int dynamic_lb = nla_get_u8(data[IFLA_BOND_TLB_DYNAMIC_LB]);
+
+		bond_opt_initval(&newval, dynamic_lb);
+		err = __bond_opt_set(bond, BOND_OPT_TLB_DYNAMIC_LB, &newval);
+		if (err)
+			return err;
+	}
+
+	return 0;
+}
+
+static int bond_newlink(struct net *src_net, struct net_device *bond_dev,
+			struct nlattr *tb[], struct nlattr *data[],
+			struct netlink_ext_ack *extack)
+{
+	int err;
+
+	err = bond_changelink(bond_dev, tb, data, extack);
+	if (err < 0)
+		return err;
+
+	err = register_netdevice(bond_dev);
+
+	netif_carrier_off(bond_dev);
+	if (!err) {
+		struct bonding *bond = netdev_priv(bond_dev);
+
+		bond_work_init_all(bond);
+	}
+
+	return err;
+}
+
+static size_t bond_get_size(const struct net_device *bond_dev)
+{
+	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_MODE */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ACTIVE_SLAVE */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIIMON */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_UPDELAY */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_DOWNDELAY */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_USE_CARRIER */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_INTERVAL */
+						/* IFLA_BOND_ARP_IP_TARGET */
+		nla_total_size(sizeof(struct nlattr)) +
+		nla_total_size(sizeof(u32)) * BOND_MAX_ARP_TARGETS +
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_VALIDATE */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_ALL_TARGETS */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PRIMARY */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_PRIMARY_RESELECT */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_FAIL_OVER_MAC */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_XMIT_HASH_POLICY */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_RESEND_IGMP */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_NUM_PEER_NOTIF */
+		nla_total_size(sizeof(u8)) +   /* IFLA_BOND_ALL_SLAVES_ACTIVE */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIN_LINKS */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_LP_INTERVAL */
+		nla_total_size(sizeof(u32)) +  /* IFLA_BOND_PACKETS_PER_SLAVE */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_LACP_RATE */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_SELECT */
+		nla_total_size(sizeof(struct nlattr)) + /* IFLA_BOND_AD_INFO */
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_AGGREGATOR */
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_NUM_PORTS */
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_ACTOR_KEY */
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_PARTNER_KEY*/
+		nla_total_size(ETH_ALEN) +    /* IFLA_BOND_AD_INFO_PARTNER_MAC*/
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_ACTOR_SYS_PRIO */
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_USER_PORT_KEY */
+		nla_total_size(ETH_ALEN) + /* IFLA_BOND_AD_ACTOR_SYSTEM */
+		nla_total_size(sizeof(u8)) + /* IFLA_BOND_TLB_DYNAMIC_LB */
+		0;
+}
+
+static int bond_option_active_slave_get_ifindex(struct bonding *bond)
+{
+	const struct net_device *slave;
+	int ifindex;
+
+	rcu_read_lock();
+	slave = bond_option_active_slave_get_rcu(bond);
+	ifindex = slave ? slave->ifindex : 0;
+	rcu_read_unlock();
+	return ifindex;
+}
+
+static int bond_fill_info(struct sk_buff *skb,
+			  const struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	unsigned int packets_per_slave;
+	int ifindex, i, targets_added;
+	struct nlattr *targets;
+	struct slave *primary;
+
+	if (nla_put_u8(skb, IFLA_BOND_MODE, BOND_MODE(bond)))
+		goto nla_put_failure;
+
+	ifindex = bond_option_active_slave_get_ifindex(bond);
+	if (ifindex && nla_put_u32(skb, IFLA_BOND_ACTIVE_SLAVE, ifindex))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_MIIMON, bond->params.miimon))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_UPDELAY,
+			bond->params.updelay * bond->params.miimon))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_DOWNDELAY,
+			bond->params.downdelay * bond->params.miimon))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_USE_CARRIER, bond->params.use_carrier))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_ARP_INTERVAL, bond->params.arp_interval))
+		goto nla_put_failure;
+
+	targets = nla_nest_start(skb, IFLA_BOND_ARP_IP_TARGET);
+	if (!targets)
+		goto nla_put_failure;
+
+	targets_added = 0;
+	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
+		if (bond->params.arp_targets[i]) {
+			if (nla_put_be32(skb, i, bond->params.arp_targets[i]))
+				goto nla_put_failure;
+			targets_added = 1;
+		}
+	}
+
+	if (targets_added)
+		nla_nest_end(skb, targets);
+	else
+		nla_nest_cancel(skb, targets);
+
+	if (nla_put_u32(skb, IFLA_BOND_ARP_VALIDATE, bond->params.arp_validate))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_ARP_ALL_TARGETS,
+			bond->params.arp_all_targets))
+		goto nla_put_failure;
+
+	primary = rtnl_dereference(bond->primary_slave);
+	if (primary &&
+	    nla_put_u32(skb, IFLA_BOND_PRIMARY, primary->dev->ifindex))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_PRIMARY_RESELECT,
+		       bond->params.primary_reselect))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_FAIL_OVER_MAC,
+		       bond->params.fail_over_mac))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_XMIT_HASH_POLICY,
+		       bond->params.xmit_policy))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_RESEND_IGMP,
+		        bond->params.resend_igmp))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_NUM_PEER_NOTIF,
+		       bond->params.num_peer_notif))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_ALL_SLAVES_ACTIVE,
+		       bond->params.all_slaves_active))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_MIN_LINKS,
+			bond->params.min_links))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_LP_INTERVAL,
+			bond->params.lp_interval))
+		goto nla_put_failure;
+
+	packets_per_slave = bond->params.packets_per_slave;
+	if (nla_put_u32(skb, IFLA_BOND_PACKETS_PER_SLAVE,
+			packets_per_slave))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_AD_LACP_RATE,
+		       bond->params.lacp_fast))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_AD_SELECT,
+		       bond->params.ad_select))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_TLB_DYNAMIC_LB,
+		       bond->params.tlb_dynamic_lb))
+		goto nla_put_failure;
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		struct ad_info info;
+
+		if (capable(CAP_NET_ADMIN)) {
+			if (nla_put_u16(skb, IFLA_BOND_AD_ACTOR_SYS_PRIO,
+					bond->params.ad_actor_sys_prio))
+				goto nla_put_failure;
+
+			if (nla_put_u16(skb, IFLA_BOND_AD_USER_PORT_KEY,
+					bond->params.ad_user_port_key))
+				goto nla_put_failure;
+
+			if (nla_put(skb, IFLA_BOND_AD_ACTOR_SYSTEM,
+				    ETH_ALEN, &bond->params.ad_actor_system))
+				goto nla_put_failure;
+		}
+		if (!bond_3ad_get_active_agg_info(bond, &info)) {
+			struct nlattr *nest;
+
+			nest = nla_nest_start(skb, IFLA_BOND_AD_INFO);
+			if (!nest)
+				goto nla_put_failure;
+
+			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_AGGREGATOR,
+					info.aggregator_id))
+				goto nla_put_failure;
+			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_NUM_PORTS,
+					info.ports))
+				goto nla_put_failure;
+			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_ACTOR_KEY,
+					info.actor_key))
+				goto nla_put_failure;
+			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_PARTNER_KEY,
+					info.partner_key))
+				goto nla_put_failure;
+			if (nla_put(skb, IFLA_BOND_AD_INFO_PARTNER_MAC,
+				    sizeof(info.partner_system),
+				    &info.partner_system))
+				goto nla_put_failure;
+
+			nla_nest_end(skb, nest);
+		}
+	}
+
+	return 0;
+
+nla_put_failure:
+	return -EMSGSIZE;
+}
+
+struct rtnl_link_ops bond_link_ops __read_mostly = {
+	.kind			= "bond",
+	.priv_size		= sizeof(struct bonding),
+	.setup			= bond_setup,
+	.maxtype		= IFLA_BOND_MAX,
+	.policy			= bond_policy,
+	.validate		= bond_validate,
+	.newlink		= bond_newlink,
+	.changelink		= bond_changelink,
+	.get_size		= bond_get_size,
+	.fill_info		= bond_fill_info,
+	.get_num_tx_queues	= bond_get_num_tx_queues,
+	.get_num_rx_queues	= bond_get_num_tx_queues, /* Use the same number
+							     as for TX queues */
+	.slave_maxtype		= IFLA_BOND_SLAVE_MAX,
+	.slave_policy		= bond_slave_policy,
+	.slave_changelink	= bond_slave_changelink,
+	.get_slave_size		= bond_get_slave_size,
+	.fill_slave_info	= bond_fill_slave_info,
+};
+
+int __init bond_netlink_init(void)
+{
+	return rtnl_link_register(&bond_link_ops);
+}
+
+void bond_netlink_fini(void)
+{
+	rtnl_link_unregister(&bond_link_ops);
+}
+
+MODULE_ALIAS_RTNL_LINK("bond");
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.103/bond_options.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.103/bond_options.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,1464 @@
+/*
+ * drivers/net/bond/bond_options.c - bonding options
+ * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
+ * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#include <linux/errno.h>
+#include <linux/if.h>
+#include <linux/netdevice.h>
+#include <linux/spinlock.h>
+#include <linux/rcupdate.h>
+#include <linux/ctype.h>
+#include <linux/inet.h>
+#include <linux/sched/signal.h>
+
+#include <net/bonding.h>
+
+static int bond_option_active_slave_set(struct bonding *bond,
+					const struct bond_opt_value *newval);
+static int bond_option_miimon_set(struct bonding *bond,
+				  const struct bond_opt_value *newval);
+static int bond_option_updelay_set(struct bonding *bond,
+				   const struct bond_opt_value *newval);
+static int bond_option_downdelay_set(struct bonding *bond,
+				     const struct bond_opt_value *newval);
+static int bond_option_use_carrier_set(struct bonding *bond,
+				       const struct bond_opt_value *newval);
+static int bond_option_arp_interval_set(struct bonding *bond,
+					const struct bond_opt_value *newval);
+static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target);
+static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target);
+static int bond_option_arp_ip_targets_set(struct bonding *bond,
+					  const struct bond_opt_value *newval);
+static int bond_option_arp_validate_set(struct bonding *bond,
+					const struct bond_opt_value *newval);
+static int bond_option_arp_all_targets_set(struct bonding *bond,
+					   const struct bond_opt_value *newval);
+static int bond_option_primary_set(struct bonding *bond,
+				   const struct bond_opt_value *newval);
+static int bond_option_primary_reselect_set(struct bonding *bond,
+					    const struct bond_opt_value *newval);
+static int bond_option_fail_over_mac_set(struct bonding *bond,
+					 const struct bond_opt_value *newval);
+static int bond_option_xmit_hash_policy_set(struct bonding *bond,
+					    const struct bond_opt_value *newval);
+static int bond_option_resend_igmp_set(struct bonding *bond,
+				       const struct bond_opt_value *newval);
+static int bond_option_num_peer_notif_set(struct bonding *bond,
+					  const struct bond_opt_value *newval);
+static int bond_option_all_slaves_active_set(struct bonding *bond,
+					     const struct bond_opt_value *newval);
+static int bond_option_min_links_set(struct bonding *bond,
+				     const struct bond_opt_value *newval);
+static int bond_option_lp_interval_set(struct bonding *bond,
+				       const struct bond_opt_value *newval);
+static int bond_option_pps_set(struct bonding *bond,
+			       const struct bond_opt_value *newval);
+static int bond_option_lacp_rate_set(struct bonding *bond,
+				     const struct bond_opt_value *newval);
+static int bond_option_ad_select_set(struct bonding *bond,
+				     const struct bond_opt_value *newval);
+static int bond_option_queue_id_set(struct bonding *bond,
+				    const struct bond_opt_value *newval);
+static int bond_option_mode_set(struct bonding *bond,
+				const struct bond_opt_value *newval);
+static int bond_option_slaves_set(struct bonding *bond,
+				  const struct bond_opt_value *newval);
+static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
+				  const struct bond_opt_value *newval);
+static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
+					     const struct bond_opt_value *newval);
+static int bond_option_ad_actor_system_set(struct bonding *bond,
+					   const struct bond_opt_value *newval);
+static int bond_option_ad_user_port_key_set(struct bonding *bond,
+					    const struct bond_opt_value *newval);
+
+
+static const struct bond_opt_value bond_mode_tbl[] = {
+	{ "balance-rr",    BOND_MODE_ROUNDROBIN,   BOND_VALFLAG_DEFAULT},
+	{ "active-backup", BOND_MODE_ACTIVEBACKUP, 0},
+	{ "balance-xor",   BOND_MODE_XOR,          0},
+	{ "broadcast",     BOND_MODE_BROADCAST,    0},
+	{ "802.3ad",       BOND_MODE_8023AD,       0},
+	{ "balance-tlb",   BOND_MODE_TLB,          0},
+	{ "balance-alb",   BOND_MODE_ALB,          0},
+	{ NULL,            -1,                     0},
+};
+
+static const struct bond_opt_value bond_pps_tbl[] = {
+	{ "default", 1,         BOND_VALFLAG_DEFAULT},
+	{ "maxval",  USHRT_MAX, BOND_VALFLAG_MAX},
+	{ NULL,      -1,        0},
+};
+
+static const struct bond_opt_value bond_xmit_hashtype_tbl[] = {
+	{ "layer2",   BOND_XMIT_POLICY_LAYER2, BOND_VALFLAG_DEFAULT},
+	{ "layer3+4", BOND_XMIT_POLICY_LAYER34, 0},
+	{ "layer2+3", BOND_XMIT_POLICY_LAYER23, 0},
+	{ "encap2+3", BOND_XMIT_POLICY_ENCAP23, 0},
+	{ "encap3+4", BOND_XMIT_POLICY_ENCAP34, 0},
+	{ NULL,       -1,                       0},
+};
+
+static const struct bond_opt_value bond_arp_validate_tbl[] = {
+	{ "none",		BOND_ARP_VALIDATE_NONE,		BOND_VALFLAG_DEFAULT},
+	{ "active",		BOND_ARP_VALIDATE_ACTIVE,	0},
+	{ "backup",		BOND_ARP_VALIDATE_BACKUP,	0},
+	{ "all",		BOND_ARP_VALIDATE_ALL,		0},
+	{ "filter",		BOND_ARP_FILTER,		0},
+	{ "filter_active",	BOND_ARP_FILTER_ACTIVE,		0},
+	{ "filter_backup",	BOND_ARP_FILTER_BACKUP,		0},
+	{ NULL,			-1,				0},
+};
+
+static const struct bond_opt_value bond_arp_all_targets_tbl[] = {
+	{ "any", BOND_ARP_TARGETS_ANY, BOND_VALFLAG_DEFAULT},
+	{ "all", BOND_ARP_TARGETS_ALL, 0},
+	{ NULL,  -1,                   0},
+};
+
+static const struct bond_opt_value bond_fail_over_mac_tbl[] = {
+	{ "none",   BOND_FOM_NONE,   BOND_VALFLAG_DEFAULT},
+	{ "active", BOND_FOM_ACTIVE, 0},
+	{ "follow", BOND_FOM_FOLLOW, 0},
+	{ NULL,     -1,              0},
+};
+
+static const struct bond_opt_value bond_intmax_tbl[] = {
+	{ "off",     0,       BOND_VALFLAG_DEFAULT},
+	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
+	{ NULL,      -1,      0}
+};
+
+static const struct bond_opt_value bond_lacp_rate_tbl[] = {
+	{ "slow", AD_LACP_SLOW, 0},
+	{ "fast", AD_LACP_FAST, 0},
+	{ NULL,   -1,           0},
+};
+
+static const struct bond_opt_value bond_ad_select_tbl[] = {
+	{ "stable",    BOND_AD_STABLE,    BOND_VALFLAG_DEFAULT},
+	{ "bandwidth", BOND_AD_BANDWIDTH, 0},
+	{ "count",     BOND_AD_COUNT,     0},
+	{ NULL,        -1,                0},
+};
+
+static const struct bond_opt_value bond_num_peer_notif_tbl[] = {
+	{ "off",     0,   0},
+	{ "maxval",  255, BOND_VALFLAG_MAX},
+	{ "default", 1,   BOND_VALFLAG_DEFAULT},
+	{ NULL,      -1,  0}
+};
+
+static const struct bond_opt_value bond_primary_reselect_tbl[] = {
+	{ "always",  BOND_PRI_RESELECT_ALWAYS,  BOND_VALFLAG_DEFAULT},
+	{ "better",  BOND_PRI_RESELECT_BETTER,  0},
+	{ "failure", BOND_PRI_RESELECT_FAILURE, 0},
+	{ NULL,      -1},
+};
+
+static const struct bond_opt_value bond_use_carrier_tbl[] = {
+	{ "off", 0,  0},
+	{ "on",  1,  BOND_VALFLAG_DEFAULT},
+	{ NULL,  -1, 0}
+};
+
+static const struct bond_opt_value bond_all_slaves_active_tbl[] = {
+	{ "off", 0,  BOND_VALFLAG_DEFAULT},
+	{ "on",  1,  0},
+	{ NULL,  -1, 0}
+};
+
+static const struct bond_opt_value bond_resend_igmp_tbl[] = {
+	{ "off",     0,   0},
+	{ "maxval",  255, BOND_VALFLAG_MAX},
+	{ "default", 1,   BOND_VALFLAG_DEFAULT},
+	{ NULL,      -1,  0}
+};
+
+static const struct bond_opt_value bond_lp_interval_tbl[] = {
+	{ "minval",  1,       BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
+	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
+	{ NULL,      -1,      0},
+};
+
+static const struct bond_opt_value bond_tlb_dynamic_lb_tbl[] = {
+	{ "off", 0,  0},
+	{ "on",  1,  BOND_VALFLAG_DEFAULT},
+	{ NULL,  -1, 0}
+};
+
+static const struct bond_opt_value bond_ad_actor_sys_prio_tbl[] = {
+	{ "minval",  1,     BOND_VALFLAG_MIN},
+	{ "maxval",  65535, BOND_VALFLAG_MAX | BOND_VALFLAG_DEFAULT},
+	{ NULL,      -1,    0},
+};
+
+static const struct bond_opt_value bond_ad_user_port_key_tbl[] = {
+	{ "minval",  0,     BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
+	{ "maxval",  1023,  BOND_VALFLAG_MAX},
+	{ NULL,      -1,    0},
+};
+
+static const struct bond_option bond_opts[BOND_OPT_LAST] = {
+	[BOND_OPT_MODE] = {
+		.id = BOND_OPT_MODE,
+		.name = "mode",
+		.desc = "bond device mode",
+		.flags = BOND_OPTFLAG_NOSLAVES | BOND_OPTFLAG_IFDOWN,
+		.values = bond_mode_tbl,
+		.set = bond_option_mode_set
+	},
+	[BOND_OPT_PACKETS_PER_SLAVE] = {
+		.id = BOND_OPT_PACKETS_PER_SLAVE,
+		.name = "packets_per_slave",
+		.desc = "Packets to send per slave in RR mode",
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ROUNDROBIN)),
+		.values = bond_pps_tbl,
+		.set = bond_option_pps_set
+	},
+	[BOND_OPT_XMIT_HASH] = {
+		.id = BOND_OPT_XMIT_HASH,
+		.name = "xmit_hash_policy",
+		.desc = "balance-xor, 802.3ad, and tlb hashing method",
+		.values = bond_xmit_hashtype_tbl,
+		.set = bond_option_xmit_hash_policy_set
+	},
+	[BOND_OPT_ARP_VALIDATE] = {
+		.id = BOND_OPT_ARP_VALIDATE,
+		.name = "arp_validate",
+		.desc = "validate src/dst of ARP probes",
+		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
+			       BIT(BOND_MODE_ALB),
+		.values = bond_arp_validate_tbl,
+		.set = bond_option_arp_validate_set
+	},
+	[BOND_OPT_ARP_ALL_TARGETS] = {
+		.id = BOND_OPT_ARP_ALL_TARGETS,
+		.name = "arp_all_targets",
+		.desc = "fail on any/all arp targets timeout",
+		.values = bond_arp_all_targets_tbl,
+		.set = bond_option_arp_all_targets_set
+	},
+	[BOND_OPT_FAIL_OVER_MAC] = {
+		.id = BOND_OPT_FAIL_OVER_MAC,
+		.name = "fail_over_mac",
+		.desc = "For active-backup, do not set all slaves to the same MAC",
+		.flags = BOND_OPTFLAG_NOSLAVES,
+		.values = bond_fail_over_mac_tbl,
+		.set = bond_option_fail_over_mac_set
+	},
+	[BOND_OPT_ARP_INTERVAL] = {
+		.id = BOND_OPT_ARP_INTERVAL,
+		.name = "arp_interval",
+		.desc = "arp interval in milliseconds",
+		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
+			       BIT(BOND_MODE_ALB),
+		.values = bond_intmax_tbl,
+		.set = bond_option_arp_interval_set
+	},
+	[BOND_OPT_ARP_TARGETS] = {
+		.id = BOND_OPT_ARP_TARGETS,
+		.name = "arp_ip_target",
+		.desc = "arp targets in n.n.n.n form",
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.set = bond_option_arp_ip_targets_set
+	},
+	[BOND_OPT_DOWNDELAY] = {
+		.id = BOND_OPT_DOWNDELAY,
+		.name = "downdelay",
+		.desc = "Delay before considering link down, in milliseconds",
+		.values = bond_intmax_tbl,
+		.set = bond_option_downdelay_set
+	},
+	[BOND_OPT_UPDELAY] = {
+		.id = BOND_OPT_UPDELAY,
+		.name = "updelay",
+		.desc = "Delay before considering link up, in milliseconds",
+		.values = bond_intmax_tbl,
+		.set = bond_option_updelay_set
+	},
+	[BOND_OPT_LACP_RATE] = {
+		.id = BOND_OPT_LACP_RATE,
+		.name = "lacp_rate",
+		.desc = "LACPDU tx rate to request from 802.3ad partner",
+		.flags = BOND_OPTFLAG_IFDOWN,
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
+		.values = bond_lacp_rate_tbl,
+		.set = bond_option_lacp_rate_set
+	},
+	[BOND_OPT_MINLINKS] = {
+		.id = BOND_OPT_MINLINKS,
+		.name = "min_links",
+		.desc = "Minimum number of available links before turning on carrier",
+		.values = bond_intmax_tbl,
+		.set = bond_option_min_links_set
+	},
+	[BOND_OPT_AD_SELECT] = {
+		.id = BOND_OPT_AD_SELECT,
+		.name = "ad_select",
+		.desc = "802.3ad aggregation selection logic",
+		.flags = BOND_OPTFLAG_IFDOWN,
+		.values = bond_ad_select_tbl,
+		.set = bond_option_ad_select_set
+	},
+	[BOND_OPT_NUM_PEER_NOTIF] = {
+		.id = BOND_OPT_NUM_PEER_NOTIF,
+		.name = "num_unsol_na",
+		.desc = "Number of peer notifications to send on failover event",
+		.values = bond_num_peer_notif_tbl,
+		.set = bond_option_num_peer_notif_set
+	},
+	[BOND_OPT_MIIMON] = {
+		.id = BOND_OPT_MIIMON,
+		.name = "miimon",
+		.desc = "Link check interval in milliseconds",
+		.values = bond_intmax_tbl,
+		.set = bond_option_miimon_set
+	},
+	[BOND_OPT_PRIMARY] = {
+		.id = BOND_OPT_PRIMARY,
+		.name = "primary",
+		.desc = "Primary network device to use",
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
+						BIT(BOND_MODE_TLB) |
+						BIT(BOND_MODE_ALB)),
+		.set = bond_option_primary_set
+	},
+	[BOND_OPT_PRIMARY_RESELECT] = {
+		.id = BOND_OPT_PRIMARY_RESELECT,
+		.name = "primary_reselect",
+		.desc = "Reselect primary slave once it comes up",
+		.values = bond_primary_reselect_tbl,
+		.set = bond_option_primary_reselect_set
+	},
+	[BOND_OPT_USE_CARRIER] = {
+		.id = BOND_OPT_USE_CARRIER,
+		.name = "use_carrier",
+		.desc = "Use netif_carrier_ok (vs MII ioctls) in miimon",
+		.values = bond_use_carrier_tbl,
+		.set = bond_option_use_carrier_set
+	},
+	[BOND_OPT_ACTIVE_SLAVE] = {
+		.id = BOND_OPT_ACTIVE_SLAVE,
+		.name = "active_slave",
+		.desc = "Currently active slave",
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
+						BIT(BOND_MODE_TLB) |
+						BIT(BOND_MODE_ALB)),
+		.set = bond_option_active_slave_set
+	},
+	[BOND_OPT_QUEUE_ID] = {
+		.id = BOND_OPT_QUEUE_ID,
+		.name = "queue_id",
+		.desc = "Set queue id of a slave",
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.set = bond_option_queue_id_set
+	},
+	[BOND_OPT_ALL_SLAVES_ACTIVE] = {
+		.id = BOND_OPT_ALL_SLAVES_ACTIVE,
+		.name = "all_slaves_active",
+		.desc = "Keep all frames received on an interface by setting active flag for all slaves",
+		.values = bond_all_slaves_active_tbl,
+		.set = bond_option_all_slaves_active_set
+	},
+	[BOND_OPT_RESEND_IGMP] = {
+		.id = BOND_OPT_RESEND_IGMP,
+		.name = "resend_igmp",
+		.desc = "Number of IGMP membership reports to send on link failure",
+		.values = bond_resend_igmp_tbl,
+		.set = bond_option_resend_igmp_set
+	},
+	[BOND_OPT_LP_INTERVAL] = {
+		.id = BOND_OPT_LP_INTERVAL,
+		.name = "lp_interval",
+		.desc = "The number of seconds between instances where the bonding driver sends learning packets to each slave's peer switch",
+		.values = bond_lp_interval_tbl,
+		.set = bond_option_lp_interval_set
+	},
+	[BOND_OPT_SLAVES] = {
+		.id = BOND_OPT_SLAVES,
+		.name = "slaves",
+		.desc = "Slave membership management",
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.set = bond_option_slaves_set
+	},
+	[BOND_OPT_TLB_DYNAMIC_LB] = {
+		.id = BOND_OPT_TLB_DYNAMIC_LB,
+		.name = "tlb_dynamic_lb",
+		.desc = "Enable dynamic flow shuffling",
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_TLB) | BIT(BOND_MODE_ALB)),
+		.values = bond_tlb_dynamic_lb_tbl,
+		.flags = BOND_OPTFLAG_IFDOWN,
+		.set = bond_option_tlb_dynamic_lb_set,
+	},
+	[BOND_OPT_AD_ACTOR_SYS_PRIO] = {
+		.id = BOND_OPT_AD_ACTOR_SYS_PRIO,
+		.name = "ad_actor_sys_prio",
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
+		.values = bond_ad_actor_sys_prio_tbl,
+		.set = bond_option_ad_actor_sys_prio_set,
+	},
+	[BOND_OPT_AD_ACTOR_SYSTEM] = {
+		.id = BOND_OPT_AD_ACTOR_SYSTEM,
+		.name = "ad_actor_system",
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.set = bond_option_ad_actor_system_set,
+	},
+	[BOND_OPT_AD_USER_PORT_KEY] = {
+		.id = BOND_OPT_AD_USER_PORT_KEY,
+		.name = "ad_user_port_key",
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
+		.flags = BOND_OPTFLAG_IFDOWN,
+		.values = bond_ad_user_port_key_tbl,
+		.set = bond_option_ad_user_port_key_set,
+	},
+	[BOND_OPT_NUM_PEER_NOTIF_ALIAS] = {
+		.id = BOND_OPT_NUM_PEER_NOTIF_ALIAS,
+		.name = "num_grat_arp",
+		.desc = "Number of peer notifications to send on failover event",
+		.values = bond_num_peer_notif_tbl,
+		.set = bond_option_num_peer_notif_set
+	}
+};
+
+/* Searches for an option by name */
+const struct bond_option *bond_opt_get_by_name(const char *name)
+{
+	const struct bond_option *opt;
+	int option;
+
+	for (option = 0; option < BOND_OPT_LAST; option++) {
+		opt = bond_opt_get(option);
+		if (opt && !strcmp(opt->name, name))
+			return opt;
+	}
+
+	return NULL;
+}
+
+/* Searches for a value in opt's values[] table */
+const struct bond_opt_value *bond_opt_get_val(unsigned int option, u64 val)
+{
+	const struct bond_option *opt;
+	int i;
+
+	opt = bond_opt_get(option);
+	if (WARN_ON(!opt))
+		return NULL;
+	for (i = 0; opt->values && opt->values[i].string; i++)
+		if (opt->values[i].value == val)
+			return &opt->values[i];
+
+	return NULL;
+}
+
+/* Searches for a value in opt's values[] table which matches the flagmask */
+static const struct bond_opt_value *bond_opt_get_flags(const struct bond_option *opt,
+						       u32 flagmask)
+{
+	int i;
+
+	for (i = 0; opt->values && opt->values[i].string; i++)
+		if (opt->values[i].flags & flagmask)
+			return &opt->values[i];
+
+	return NULL;
+}
+
+/* If maxval is missing then there's no range to check. In case minval is
+ * missing then it's considered to be 0.
+ */
+static bool bond_opt_check_range(const struct bond_option *opt, u64 val)
+{
+	const struct bond_opt_value *minval, *maxval;
+
+	minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
+	maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
+	if (!maxval || (minval && val < minval->value) || val > maxval->value)
+		return false;
+
+	return true;
+}
+
+/**
+ * bond_opt_parse - parse option value
+ * @opt: the option to parse against
+ * @val: value to parse
+ *
+ * This function tries to extract the value from @val and check if it's
+ * a possible match for the option and returns NULL if a match isn't found,
+ * or the struct_opt_value that matched. It also strips the new line from
+ * @val->string if it's present.
+ */
+const struct bond_opt_value *bond_opt_parse(const struct bond_option *opt,
+					    struct bond_opt_value *val)
+{
+	char *p, valstr[BOND_OPT_MAX_NAMELEN + 1] = { 0, };
+	const struct bond_opt_value *tbl;
+	const struct bond_opt_value *ret = NULL;
+	bool checkval;
+	int i, rv;
+
+	/* No parsing if the option wants a raw val */
+	if (opt->flags & BOND_OPTFLAG_RAWVAL)
+		return val;
+
+	tbl = opt->values;
+	if (!tbl)
+		goto out;
+
+	/* ULLONG_MAX is used to bypass string processing */
+	checkval = val->value != ULLONG_MAX;
+	if (!checkval) {
+		if (!val->string)
+			goto out;
+		p = strchr(val->string, '\n');
+		if (p)
+			*p = '\0';
+		for (p = val->string; *p; p++)
+			if (!(isdigit(*p) || isspace(*p)))
+				break;
+		/* The following code extracts the string to match or the value
+		 * and sets checkval appropriately
+		 */
+		if (*p) {
+			rv = sscanf(val->string, "%32s", valstr);
+		} else {
+			rv = sscanf(val->string, "%llu", &val->value);
+			checkval = true;
+		}
+		if (!rv)
+			goto out;
+	}
+
+	for (i = 0; tbl[i].string; i++) {
+		/* Check for exact match */
+		if (checkval) {
+			if (val->value == tbl[i].value)
+				ret = &tbl[i];
+		} else {
+			if (!strcmp(valstr, "default") &&
+			    (tbl[i].flags & BOND_VALFLAG_DEFAULT))
+				ret = &tbl[i];
+
+			if (!strcmp(valstr, tbl[i].string))
+				ret = &tbl[i];
+		}
+		/* Found an exact match */
+		if (ret)
+			goto out;
+	}
+	/* Possible range match */
+	if (checkval && bond_opt_check_range(opt, val->value))
+		ret = val;
+out:
+	return ret;
+}
+
+/* Check opt's dependencies against bond mode and currently set options */
+static int bond_opt_check_deps(struct bonding *bond,
+			       const struct bond_option *opt)
+{
+	struct bond_params *params = &bond->params;
+
+	if (test_bit(params->mode, &opt->unsuppmodes))
+		return -EACCES;
+	if ((opt->flags & BOND_OPTFLAG_NOSLAVES) && bond_has_slaves(bond))
+		return -ENOTEMPTY;
+	if ((opt->flags & BOND_OPTFLAG_IFDOWN) && (bond->dev->flags & IFF_UP))
+		return -EBUSY;
+
+	return 0;
+}
+
+static void bond_opt_dep_print(struct bonding *bond,
+			       const struct bond_option *opt)
+{
+	const struct bond_opt_value *modeval;
+	struct bond_params *params;
+
+	params = &bond->params;
+	modeval = bond_opt_get_val(BOND_OPT_MODE, params->mode);
+	if (test_bit(params->mode, &opt->unsuppmodes))
+		netdev_err(bond->dev, "option %s: mode dependency failed, not supported in mode %s(%llu)\n",
+			   opt->name, modeval->string, modeval->value);
+}
+
+static void bond_opt_error_interpret(struct bonding *bond,
+				     const struct bond_option *opt,
+				     int error, const struct bond_opt_value *val)
+{
+	const struct bond_opt_value *minval, *maxval;
+	char *p;
+
+	switch (error) {
+	case -EINVAL:
+		if (val) {
+			if (val->string) {
+				/* sometimes RAWVAL opts may have new lines */
+				p = strchr(val->string, '\n');
+				if (p)
+					*p = '\0';
+				netdev_err(bond->dev, "option %s: invalid value (%s)\n",
+					   opt->name, val->string);
+			} else {
+				netdev_err(bond->dev, "option %s: invalid value (%llu)\n",
+					   opt->name, val->value);
+			}
+		}
+		minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
+		maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
+		if (!maxval)
+			break;
+		netdev_err(bond->dev, "option %s: allowed values %llu - %llu\n",
+			   opt->name, minval ? minval->value : 0, maxval->value);
+		break;
+	case -EACCES:
+		bond_opt_dep_print(bond, opt);
+		break;
+	case -ENOTEMPTY:
+		netdev_err(bond->dev, "option %s: unable to set because the bond device has slaves\n",
+			   opt->name);
+		break;
+	case -EBUSY:
+		netdev_err(bond->dev, "option %s: unable to set because the bond device is up\n",
+			   opt->name);
+		break;
+	default:
+		break;
+	}
+}
+
+/**
+ * __bond_opt_set - set a bonding option
+ * @bond: target bond device
+ * @option: option to set
+ * @val: value to set it to
+ *
+ * This function is used to change the bond's option value, it can be
+ * used for both enabling/changing an option and for disabling it. RTNL lock
+ * must be obtained before calling this function.
+ */
+int __bond_opt_set(struct bonding *bond,
+		   unsigned int option, struct bond_opt_value *val)
+{
+	const struct bond_opt_value *retval = NULL;
+	const struct bond_option *opt;
+	int ret = -ENOENT;
+
+	ASSERT_RTNL();
+
+	opt = bond_opt_get(option);
+	if (WARN_ON(!val) || WARN_ON(!opt))
+		goto out;
+	ret = bond_opt_check_deps(bond, opt);
+	if (ret)
+		goto out;
+	retval = bond_opt_parse(opt, val);
+	if (!retval) {
+		ret = -EINVAL;
+		goto out;
+	}
+	ret = opt->set(bond, retval);
+out:
+	if (ret)
+		bond_opt_error_interpret(bond, opt, ret, val);
+
+	return ret;
+}
+/**
+ * __bond_opt_set_notify - set a bonding option
+ * @bond: target bond device
+ * @option: option to set
+ * @val: value to set it to
+ *
+ * This function is used to change the bond's option value and trigger
+ * a notification to user sapce. It can be used for both enabling/changing
+ * an option and for disabling it. RTNL lock must be obtained before calling
+ * this function.
+ */
+int __bond_opt_set_notify(struct bonding *bond,
+			  unsigned int option, struct bond_opt_value *val)
+{
+	int ret = -ENOENT;
+
+	ASSERT_RTNL();
+
+	ret = __bond_opt_set(bond, option, val);
+
+	if (!ret && (bond->dev->reg_state == NETREG_REGISTERED))
+		call_netdevice_notifiers(NETDEV_CHANGEINFODATA, bond->dev);
+
+	return ret;
+}
+
+/**
+ * bond_opt_tryset_rtnl - try to acquire rtnl and call __bond_opt_set
+ * @bond: target bond device
+ * @option: option to set
+ * @buf: value to set it to
+ *
+ * This function tries to acquire RTNL without blocking and if successful
+ * calls __bond_opt_set. It is mainly used for sysfs option manipulation.
+ */
+int bond_opt_tryset_rtnl(struct bonding *bond, unsigned int option, char *buf)
+{
+	struct bond_opt_value optval;
+	int ret;
+
+	if (!rtnl_trylock())
+		return restart_syscall();
+	bond_opt_initstr(&optval, buf);
+	ret = __bond_opt_set_notify(bond, option, &optval);
+	rtnl_unlock();
+
+	return ret;
+}
+
+/**
+ * bond_opt_get - get a pointer to an option
+ * @option: option for which to return a pointer
+ *
+ * This function checks if option is valid and if so returns a pointer
+ * to its entry in the bond_opts[] option array.
+ */
+const struct bond_option *bond_opt_get(unsigned int option)
+{
+	if (!BOND_OPT_VALID(option))
+		return NULL;
+
+	return &bond_opts[option];
+}
+
+static int bond_option_mode_set(struct bonding *bond,
+				const struct bond_opt_value *newval)
+{
+	if (!bond_mode_uses_arp(newval->value)) {
+		if (bond->params.arp_interval) {
+			netdev_dbg(bond->dev, "%s mode is incompatible with arp monitoring, start mii monitoring\n",
+				   newval->string);
+			/* disable arp monitoring */
+			bond->params.arp_interval = 0;
+		}
+
+		if (!bond->params.miimon) {
+			/* set miimon to default value */
+			bond->params.miimon = BOND_DEFAULT_MIIMON;
+			netdev_dbg(bond->dev, "Setting MII monitoring interval to %d\n",
+				   bond->params.miimon);
+		}
+	}
+
+	if (newval->value == BOND_MODE_ALB)
+		bond->params.tlb_dynamic_lb = 1;
+
+	/* don't cache arp_validate between modes */
+	bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
+	bond->params.mode = newval->value;
+
+	return 0;
+}
+
+static int bond_option_active_slave_set(struct bonding *bond,
+					const struct bond_opt_value *newval)
+{
+	char ifname[IFNAMSIZ] = { 0, };
+	struct net_device *slave_dev;
+	int ret = 0;
+
+	sscanf(newval->string, "%15s", ifname); /* IFNAMSIZ */
+	if (!strlen(ifname) || newval->string[0] == '\n') {
+		slave_dev = NULL;
+	} else {
+		slave_dev = __dev_get_by_name(dev_net(bond->dev), ifname);
+		if (!slave_dev)
+			return -ENODEV;
+	}
+
+	if (slave_dev) {
+		if (!netif_is_bond_slave(slave_dev)) {
+			netdev_err(bond->dev, "Device %s is not bonding slave\n",
+				   slave_dev->name);
+			return -EINVAL;
+		}
+
+		if (bond->dev != netdev_master_upper_dev_get(slave_dev)) {
+			netdev_err(bond->dev, "Device %s is not our slave\n",
+				   slave_dev->name);
+			return -EINVAL;
+		}
+	}
+
+	block_netpoll_tx();
+	/* check to see if we are clearing active */
+	if (!slave_dev) {
+		netdev_dbg(bond->dev, "Clearing current active slave\n");
+		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
+		bond_select_active_slave(bond);
+	} else {
+		struct slave *old_active = rtnl_dereference(bond->curr_active_slave);
+		struct slave *new_active = bond_slave_get_rtnl(slave_dev);
+
+		BUG_ON(!new_active);
+
+		if (new_active == old_active) {
+			/* do nothing */
+			netdev_dbg(bond->dev, "%s is already the current active slave\n",
+				   new_active->dev->name);
+		} else {
+			if (old_active && (new_active->link == BOND_LINK_UP) &&
+			    bond_slave_is_up(new_active)) {
+				netdev_dbg(bond->dev, "Setting %s as active slave\n",
+					   new_active->dev->name);
+				bond_change_active_slave(bond, new_active);
+			} else {
+				netdev_err(bond->dev, "Could not set %s as active slave; either %s is down or the link is down\n",
+					   new_active->dev->name,
+					   new_active->dev->name);
+				ret = -EINVAL;
+			}
+		}
+	}
+	unblock_netpoll_tx();
+
+	return ret;
+}
+
+/* There are two tricky bits here.  First, if MII monitoring is activated, then
+ * we must disable ARP monitoring.  Second, if the timer isn't running, we must
+ * start it.
+ */
+static int bond_option_miimon_set(struct bonding *bond,
+				  const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting MII monitoring interval to %llu\n",
+		   newval->value);
+	bond->params.miimon = newval->value;
+	if (bond->params.updelay)
+		netdev_dbg(bond->dev, "Note: Updating updelay (to %d) since it is a multiple of the miimon value\n",
+			   bond->params.updelay * bond->params.miimon);
+	if (bond->params.downdelay)
+		netdev_dbg(bond->dev, "Note: Updating downdelay (to %d) since it is a multiple of the miimon value\n",
+			   bond->params.downdelay * bond->params.miimon);
+	if (newval->value && bond->params.arp_interval) {
+		netdev_dbg(bond->dev, "MII monitoring cannot be used with ARP monitoring - disabling ARP monitoring...\n");
+		bond->params.arp_interval = 0;
+		if (bond->params.arp_validate)
+			bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
+	}
+	if (bond->dev->flags & IFF_UP) {
+		/* If the interface is up, we may need to fire off
+		 * the MII timer. If the interface is down, the
+		 * timer will get fired off when the open function
+		 * is called.
+		 */
+		if (!newval->value) {
+			cancel_delayed_work_sync(&bond->mii_work);
+		} else {
+			cancel_delayed_work_sync(&bond->arp_work);
+			queue_delayed_work(bond->wq, &bond->mii_work, 0);
+		}
+	}
+
+	return 0;
+}
+
+/* Set up and down delays. These must be multiples of the
+ * MII monitoring value, and are stored internally as the multiplier.
+ * Thus, we must translate to MS for the real world.
+ */
+static int bond_option_updelay_set(struct bonding *bond,
+				   const struct bond_opt_value *newval)
+{
+	int value = newval->value;
+
+	if (!bond->params.miimon) {
+		netdev_err(bond->dev, "Unable to set up delay as MII monitoring is disabled\n");
+		return -EPERM;
+	}
+	if ((value % bond->params.miimon) != 0) {
+		netdev_warn(bond->dev, "up delay (%d) is not a multiple of miimon (%d), updelay rounded to %d ms\n",
+			    value, bond->params.miimon,
+			    (value / bond->params.miimon) *
+			    bond->params.miimon);
+	}
+	bond->params.updelay = value / bond->params.miimon;
+	netdev_dbg(bond->dev, "Setting up delay to %d\n",
+		   bond->params.updelay * bond->params.miimon);
+
+	return 0;
+}
+
+static int bond_option_downdelay_set(struct bonding *bond,
+				     const struct bond_opt_value *newval)
+{
+	int value = newval->value;
+
+	if (!bond->params.miimon) {
+		netdev_err(bond->dev, "Unable to set down delay as MII monitoring is disabled\n");
+		return -EPERM;
+	}
+	if ((value % bond->params.miimon) != 0) {
+		netdev_warn(bond->dev, "down delay (%d) is not a multiple of miimon (%d), delay rounded to %d ms\n",
+			    value, bond->params.miimon,
+			    (value / bond->params.miimon) *
+			    bond->params.miimon);
+	}
+	bond->params.downdelay = value / bond->params.miimon;
+	netdev_dbg(bond->dev, "Setting down delay to %d\n",
+		   bond->params.downdelay * bond->params.miimon);
+
+	return 0;
+}
+
+static int bond_option_use_carrier_set(struct bonding *bond,
+				       const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting use_carrier to %llu\n",
+		   newval->value);
+	bond->params.use_carrier = newval->value;
+
+	return 0;
+}
+
+/* There are two tricky bits here.  First, if ARP monitoring is activated, then
+ * we must disable MII monitoring.  Second, if the ARP timer isn't running,
+ * we must start it.
+ */
+static int bond_option_arp_interval_set(struct bonding *bond,
+					const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting ARP monitoring interval to %llu\n",
+		   newval->value);
+	bond->params.arp_interval = newval->value;
+	if (newval->value) {
+		if (bond->params.miimon) {
+			netdev_dbg(bond->dev, "ARP monitoring cannot be used with MII monitoring. Disabling MII monitoring\n");
+			bond->params.miimon = 0;
+		}
+		if (!bond->params.arp_targets[0])
+			netdev_dbg(bond->dev, "ARP monitoring has been set up, but no ARP targets have been specified\n");
+	}
+	if (bond->dev->flags & IFF_UP) {
+		/* If the interface is up, we may need to fire off
+		 * the ARP timer.  If the interface is down, the
+		 * timer will get fired off when the open function
+		 * is called.
+		 */
+		if (!newval->value) {
+			if (bond->params.arp_validate)
+				bond->recv_probe = NULL;
+			cancel_delayed_work_sync(&bond->arp_work);
+		} else {
+			/* arp_validate can be set only in active-backup mode */
+			bond->recv_probe = bond_arp_rcv;
+			cancel_delayed_work_sync(&bond->mii_work);
+			queue_delayed_work(bond->wq, &bond->arp_work, 0);
+		}
+	}
+
+	return 0;
+}
+
+static void _bond_options_arp_ip_target_set(struct bonding *bond, int slot,
+					    __be32 target,
+					    unsigned long last_rx)
+{
+	__be32 *targets = bond->params.arp_targets;
+	struct list_head *iter;
+	struct slave *slave;
+
+	if (slot >= 0 && slot < BOND_MAX_ARP_TARGETS) {
+		bond_for_each_slave(bond, slave, iter)
+			slave->target_last_arp_rx[slot] = last_rx;
+		targets[slot] = target;
+	}
+}
+
+static int _bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
+{
+	__be32 *targets = bond->params.arp_targets;
+	int ind;
+
+	if (!bond_is_ip_target_ok(target)) {
+		netdev_err(bond->dev, "invalid ARP target %pI4 specified for addition\n",
+			   &target);
+		return -EINVAL;
+	}
+
+	if (bond_get_targets_ip(targets, target) != -1) { /* dup */
+		netdev_err(bond->dev, "ARP target %pI4 is already present\n",
+			   &target);
+		return -EINVAL;
+	}
+
+	ind = bond_get_targets_ip(targets, 0); /* first free slot */
+	if (ind == -1) {
+		netdev_err(bond->dev, "ARP target table is full!\n");
+		return -EINVAL;
+	}
+
+	netdev_dbg(bond->dev, "Adding ARP target %pI4\n", &target);
+
+	_bond_options_arp_ip_target_set(bond, ind, target, jiffies);
+
+	return 0;
+}
+
+static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
+{
+	return _bond_option_arp_ip_target_add(bond, target);
+}
+
+static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target)
+{
+	__be32 *targets = bond->params.arp_targets;
+	struct list_head *iter;
+	struct slave *slave;
+	unsigned long *targets_rx;
+	int ind, i;
+
+	if (!bond_is_ip_target_ok(target)) {
+		netdev_err(bond->dev, "invalid ARP target %pI4 specified for removal\n",
+			   &target);
+		return -EINVAL;
+	}
+
+	ind = bond_get_targets_ip(targets, target);
+	if (ind == -1) {
+		netdev_err(bond->dev, "unable to remove nonexistent ARP target %pI4\n",
+			   &target);
+		return -EINVAL;
+	}
+
+	if (ind == 0 && !targets[1] && bond->params.arp_interval)
+		netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
+
+	netdev_dbg(bond->dev, "Removing ARP target %pI4\n", &target);
+
+	bond_for_each_slave(bond, slave, iter) {
+		targets_rx = slave->target_last_arp_rx;
+		for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
+			targets_rx[i] = targets_rx[i+1];
+		targets_rx[i] = 0;
+	}
+	for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
+		targets[i] = targets[i+1];
+	targets[i] = 0;
+
+	return 0;
+}
+
+void bond_option_arp_ip_targets_clear(struct bonding *bond)
+{
+	int i;
+
+	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
+		_bond_options_arp_ip_target_set(bond, i, 0, 0);
+}
+
+static int bond_option_arp_ip_targets_set(struct bonding *bond,
+					  const struct bond_opt_value *newval)
+{
+	int ret = -EPERM;
+	__be32 target;
+
+	if (newval->string) {
+		if (!in4_pton(newval->string+1, -1, (u8 *)&target, -1, NULL)) {
+			netdev_err(bond->dev, "invalid ARP target %pI4 specified\n",
+				   &target);
+			return ret;
+		}
+		if (newval->string[0] == '+')
+			ret = bond_option_arp_ip_target_add(bond, target);
+		else if (newval->string[0] == '-')
+			ret = bond_option_arp_ip_target_rem(bond, target);
+		else
+			netdev_err(bond->dev, "no command found in arp_ip_targets file - use +<addr> or -<addr>\n");
+	} else {
+		target = newval->value;
+		ret = bond_option_arp_ip_target_add(bond, target);
+	}
+
+	return ret;
+}
+
+static int bond_option_arp_validate_set(struct bonding *bond,
+					const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting arp_validate to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.arp_validate = newval->value;
+
+	return 0;
+}
+
+static int bond_option_arp_all_targets_set(struct bonding *bond,
+					   const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting arp_all_targets to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.arp_all_targets = newval->value;
+
+	return 0;
+}
+
+static int bond_option_primary_set(struct bonding *bond,
+				   const struct bond_opt_value *newval)
+{
+	char *p, *primary = newval->string;
+	struct list_head *iter;
+	struct slave *slave;
+
+	block_netpoll_tx();
+
+	p = strchr(primary, '\n');
+	if (p)
+		*p = '\0';
+	/* check to see if we are clearing primary */
+	if (!strlen(primary)) {
+		netdev_dbg(bond->dev, "Setting primary slave to None\n");
+		RCU_INIT_POINTER(bond->primary_slave, NULL);
+		memset(bond->params.primary, 0, sizeof(bond->params.primary));
+		bond_select_active_slave(bond);
+		goto out;
+	}
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (strncmp(slave->dev->name, primary, IFNAMSIZ) == 0) {
+			netdev_dbg(bond->dev, "Setting %s as primary slave\n",
+				   slave->dev->name);
+			rcu_assign_pointer(bond->primary_slave, slave);
+			strcpy(bond->params.primary, slave->dev->name);
+			bond->force_primary = true;
+			bond_select_active_slave(bond);
+			goto out;
+		}
+	}
+
+	if (rtnl_dereference(bond->primary_slave)) {
+		netdev_dbg(bond->dev, "Setting primary slave to None\n");
+		RCU_INIT_POINTER(bond->primary_slave, NULL);
+		bond_select_active_slave(bond);
+	}
+	strncpy(bond->params.primary, primary, IFNAMSIZ);
+	bond->params.primary[IFNAMSIZ - 1] = 0;
+
+	netdev_dbg(bond->dev, "Recording %s as primary, but it has not been enslaved to %s yet\n",
+		   primary, bond->dev->name);
+
+out:
+	unblock_netpoll_tx();
+
+	return 0;
+}
+
+static int bond_option_primary_reselect_set(struct bonding *bond,
+					    const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting primary_reselect to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.primary_reselect = newval->value;
+
+	block_netpoll_tx();
+	bond_select_active_slave(bond);
+	unblock_netpoll_tx();
+
+	return 0;
+}
+
+static int bond_option_fail_over_mac_set(struct bonding *bond,
+					 const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting fail_over_mac to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.fail_over_mac = newval->value;
+
+	return 0;
+}
+
+static int bond_option_xmit_hash_policy_set(struct bonding *bond,
+					    const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting xmit hash policy to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.xmit_policy = newval->value;
+
+	return 0;
+}
+
+static int bond_option_resend_igmp_set(struct bonding *bond,
+				       const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting resend_igmp to %llu\n",
+		   newval->value);
+	bond->params.resend_igmp = newval->value;
+
+	return 0;
+}
+
+static int bond_option_num_peer_notif_set(struct bonding *bond,
+				   const struct bond_opt_value *newval)
+{
+	bond->params.num_peer_notif = newval->value;
+
+	return 0;
+}
+
+static int bond_option_all_slaves_active_set(struct bonding *bond,
+					     const struct bond_opt_value *newval)
+{
+	struct list_head *iter;
+	struct slave *slave;
+
+	if (newval->value == bond->params.all_slaves_active)
+		return 0;
+	bond->params.all_slaves_active = newval->value;
+	bond_for_each_slave(bond, slave, iter) {
+		if (!bond_is_active_slave(slave)) {
+			if (newval->value)
+				slave->inactive = 0;
+			else
+				slave->inactive = 1;
+		}
+	}
+
+	return 0;
+}
+
+static int bond_option_min_links_set(struct bonding *bond,
+				     const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting min links value to %llu\n",
+		   newval->value);
+	bond->params.min_links = newval->value;
+	bond_set_carrier(bond);
+
+	return 0;
+}
+
+static int bond_option_lp_interval_set(struct bonding *bond,
+				       const struct bond_opt_value *newval)
+{
+	bond->params.lp_interval = newval->value;
+
+	return 0;
+}
+
+static int bond_option_pps_set(struct bonding *bond,
+			       const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting packets per slave to %llu\n",
+		   newval->value);
+	bond->params.packets_per_slave = newval->value;
+	if (newval->value > 0) {
+		bond->params.reciprocal_packets_per_slave =
+			reciprocal_value(newval->value);
+	} else {
+		/* reciprocal_packets_per_slave is unused if
+		 * packets_per_slave is 0 or 1, just initialize it
+		 */
+		bond->params.reciprocal_packets_per_slave =
+			(struct reciprocal_value) { 0 };
+	}
+
+	return 0;
+}
+
+static int bond_option_lacp_rate_set(struct bonding *bond,
+				     const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting LACP rate to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.lacp_fast = newval->value;
+	bond_3ad_update_lacp_rate(bond);
+
+	return 0;
+}
+
+static int bond_option_ad_select_set(struct bonding *bond,
+				     const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting ad_select to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.ad_select = newval->value;
+
+	return 0;
+}
+
+static int bond_option_queue_id_set(struct bonding *bond,
+				    const struct bond_opt_value *newval)
+{
+	struct slave *slave, *update_slave;
+	struct net_device *sdev;
+	struct list_head *iter;
+	char *delim;
+	int ret = 0;
+	u16 qid;
+
+	/* delim will point to queue id if successful */
+	delim = strchr(newval->string, ':');
+	if (!delim)
+		goto err_no_cmd;
+
+	/* Terminate string that points to device name and bump it
+	 * up one, so we can read the queue id there.
+	 */
+	*delim = '\0';
+	if (sscanf(++delim, "%hd\n", &qid) != 1)
+		goto err_no_cmd;
+
+	/* Check buffer length, valid ifname and queue id */
+	if (!dev_valid_name(newval->string) ||
+	    qid > bond->dev->real_num_tx_queues)
+		goto err_no_cmd;
+
+	/* Get the pointer to that interface if it exists */
+	sdev = __dev_get_by_name(dev_net(bond->dev), newval->string);
+	if (!sdev)
+		goto err_no_cmd;
+
+	/* Search for thes slave and check for duplicate qids */
+	update_slave = NULL;
+	bond_for_each_slave(bond, slave, iter) {
+		if (sdev == slave->dev)
+			/* We don't need to check the matching
+			 * slave for dups, since we're overwriting it
+			 */
+			update_slave = slave;
+		else if (qid && qid == slave->queue_id) {
+			goto err_no_cmd;
+		}
+	}
+
+	if (!update_slave)
+		goto err_no_cmd;
+
+	/* Actually set the qids for the slave */
+	update_slave->queue_id = qid;
+
+out:
+	return ret;
+
+err_no_cmd:
+	netdev_dbg(bond->dev, "invalid input for queue_id set\n");
+	ret = -EPERM;
+	goto out;
+
+}
+
+static int bond_option_slaves_set(struct bonding *bond,
+				  const struct bond_opt_value *newval)
+{
+	char command[IFNAMSIZ + 1] = { 0, };
+	struct net_device *dev;
+	char *ifname;
+	int ret;
+
+	sscanf(newval->string, "%16s", command); /* IFNAMSIZ*/
+	ifname = command + 1;
+	if ((strlen(command) <= 1) ||
+	    !dev_valid_name(ifname))
+		goto err_no_cmd;
+
+	dev = __dev_get_by_name(dev_net(bond->dev), ifname);
+	if (!dev) {
+		netdev_dbg(bond->dev, "interface %s does not exist!\n",
+			   ifname);
+		ret = -ENODEV;
+		goto out;
+	}
+
+	switch (command[0]) {
+	case '+':
+		netdev_dbg(bond->dev, "Adding slave %s\n", dev->name);
+		ret = bond_enslave(bond->dev, dev, NULL);
+		break;
+
+	case '-':
+		netdev_dbg(bond->dev, "Removing slave %s\n", dev->name);
+		ret = bond_release(bond->dev, dev);
+		break;
+
+	default:
+		goto err_no_cmd;
+	}
+
+out:
+	return ret;
+
+err_no_cmd:
+	netdev_err(bond->dev, "no command found in slaves file - use +ifname or -ifname\n");
+	ret = -EPERM;
+	goto out;
+}
+
+static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
+					  const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting dynamic-lb to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.tlb_dynamic_lb = newval->value;
+
+	return 0;
+}
+
+static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
+					     const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting ad_actor_sys_prio to %llu\n",
+		   newval->value);
+
+	bond->params.ad_actor_sys_prio = newval->value;
+	bond_3ad_update_ad_actor_settings(bond);
+
+	return 0;
+}
+
+static int bond_option_ad_actor_system_set(struct bonding *bond,
+					   const struct bond_opt_value *newval)
+{
+	u8 macaddr[ETH_ALEN];
+	u8 *mac;
+
+	if (newval->string) {
+		if (!mac_pton(newval->string, macaddr))
+			goto err;
+		mac = macaddr;
+	} else {
+		mac = (u8 *)&newval->value;
+	}
+
+	if (!is_valid_ether_addr(mac))
+		goto err;
+
+	netdev_dbg(bond->dev, "Setting ad_actor_system to %pM\n", mac);
+	ether_addr_copy(bond->params.ad_actor_system, mac);
+	bond_3ad_update_ad_actor_settings(bond);
+
+	return 0;
+
+err:
+	netdev_err(bond->dev, "Invalid MAC address.\n");
+	return -EINVAL;
+}
+
+static int bond_option_ad_user_port_key_set(struct bonding *bond,
+					    const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting ad_user_port_key to %llu\n",
+		   newval->value);
+
+	bond->params.ad_user_port_key = newval->value;
+	return 0;
+}
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.103/bond_procfs.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.103/bond_procfs.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,310 @@
+// SPDX-License-Identifier: GPL-2.0
+#include <linux/proc_fs.h>
+#include <linux/export.h>
+#include <net/net_namespace.h>
+#include <net/netns/generic.h>
+#include <net/bonding.h>
+
+#include "bonding_priv.h"
+
+static void *bond_info_seq_start(struct seq_file *seq, loff_t *pos)
+	__acquires(RCU)
+{
+	struct bonding *bond = PDE_DATA(file_inode(seq->file));
+	struct list_head *iter;
+	struct slave *slave;
+	loff_t off = 0;
+
+	rcu_read_lock();
+
+	if (*pos == 0)
+		return SEQ_START_TOKEN;
+
+	bond_for_each_slave_rcu(bond, slave, iter)
+		if (++off == *pos)
+			return slave;
+
+	return NULL;
+}
+
+static void *bond_info_seq_next(struct seq_file *seq, void *v, loff_t *pos)
+{
+	struct bonding *bond = PDE_DATA(file_inode(seq->file));
+	struct list_head *iter;
+	struct slave *slave;
+	bool found = false;
+
+	++*pos;
+	if (v == SEQ_START_TOKEN)
+		return bond_first_slave_rcu(bond);
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (found)
+			return slave;
+		if (slave == v)
+			found = true;
+	}
+
+	return NULL;
+}
+
+static void bond_info_seq_stop(struct seq_file *seq, void *v)
+	__releases(RCU)
+{
+	rcu_read_unlock();
+}
+
+static void bond_info_show_master(struct seq_file *seq)
+{
+	struct bonding *bond = PDE_DATA(file_inode(seq->file));
+	const struct bond_opt_value *optval;
+	struct slave *curr, *primary;
+	int i;
+
+	curr = rcu_dereference(bond->curr_active_slave);
+
+	seq_printf(seq, "Bonding Mode: %s",
+		   bond_mode_name(BOND_MODE(bond)));
+
+	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
+	    bond->params.fail_over_mac) {
+		optval = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
+					  bond->params.fail_over_mac);
+		seq_printf(seq, " (fail_over_mac %s)", optval->string);
+	}
+
+	seq_printf(seq, "\n");
+
+	if (bond_mode_uses_xmit_hash(bond)) {
+		optval = bond_opt_get_val(BOND_OPT_XMIT_HASH,
+					  bond->params.xmit_policy);
+		seq_printf(seq, "Transmit Hash Policy: %s (%d)\n",
+			   optval->string, bond->params.xmit_policy);
+	}
+
+	if (bond_uses_primary(bond)) {
+		primary = rcu_dereference(bond->primary_slave);
+		seq_printf(seq, "Primary Slave: %s",
+			   primary ? primary->dev->name : "None");
+		if (primary) {
+			optval = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
+						  bond->params.primary_reselect);
+			seq_printf(seq, " (primary_reselect %s)",
+				   optval->string);
+		}
+
+		seq_printf(seq, "\nCurrently Active Slave: %s\n",
+			   (curr) ? curr->dev->name : "None");
+	}
+
+	seq_printf(seq, "MII Status: %s\n", netif_carrier_ok(bond->dev) ?
+		   "up" : "down");
+	seq_printf(seq, "MII Polling Interval (ms): %d\n", bond->params.miimon);
+	seq_printf(seq, "Up Delay (ms): %d\n",
+		   bond->params.updelay * bond->params.miimon);
+	seq_printf(seq, "Down Delay (ms): %d\n",
+		   bond->params.downdelay * bond->params.miimon);
+
+
+	/* ARP information */
+	if (bond->params.arp_interval > 0) {
+		int printed = 0;
+		seq_printf(seq, "ARP Polling Interval (ms): %d\n",
+				bond->params.arp_interval);
+
+		seq_printf(seq, "ARP IP target/s (n.n.n.n form):");
+
+		for (i = 0; (i < BOND_MAX_ARP_TARGETS); i++) {
+			if (!bond->params.arp_targets[i])
+				break;
+			if (printed)
+				seq_printf(seq, ",");
+			seq_printf(seq, " %pI4", &bond->params.arp_targets[i]);
+			printed = 1;
+		}
+		seq_printf(seq, "\n");
+	}
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		struct ad_info ad_info;
+
+		seq_puts(seq, "\n802.3ad info\n");
+		seq_printf(seq, "LACP rate: %s\n",
+			   (bond->params.lacp_fast) ? "fast" : "slow");
+		seq_printf(seq, "Min links: %d\n", bond->params.min_links);
+		optval = bond_opt_get_val(BOND_OPT_AD_SELECT,
+					  bond->params.ad_select);
+		seq_printf(seq, "Aggregator selection policy (ad_select): %s\n",
+			   optval->string);
+		if (capable(CAP_NET_ADMIN)) {
+			seq_printf(seq, "System priority: %d\n",
+				   BOND_AD_INFO(bond).system.sys_priority);
+			seq_printf(seq, "System MAC address: %pM\n",
+				   &BOND_AD_INFO(bond).system.sys_mac_addr);
+
+			if (__bond_3ad_get_active_agg_info(bond, &ad_info)) {
+				seq_printf(seq,
+					   "bond %s has no active aggregator\n",
+					   bond->dev->name);
+			} else {
+				seq_printf(seq, "Active Aggregator Info:\n");
+
+				seq_printf(seq, "\tAggregator ID: %d\n",
+					   ad_info.aggregator_id);
+				seq_printf(seq, "\tNumber of ports: %d\n",
+					   ad_info.ports);
+				seq_printf(seq, "\tActor Key: %d\n",
+					   ad_info.actor_key);
+				seq_printf(seq, "\tPartner Key: %d\n",
+					   ad_info.partner_key);
+				seq_printf(seq, "\tPartner Mac Address: %pM\n",
+					   ad_info.partner_system);
+			}
+		}
+	}
+}
+
+static void bond_info_show_slave(struct seq_file *seq,
+				 const struct slave *slave)
+{
+	struct bonding *bond = PDE_DATA(file_inode(seq->file));
+
+	seq_printf(seq, "\nSlave Interface: %s\n", slave->dev->name);
+	seq_printf(seq, "MII Status: %s\n", bond_slave_link_status(slave->link));
+	if (slave->speed == SPEED_UNKNOWN)
+		seq_printf(seq, "Speed: %s\n", "Unknown");
+	else
+		seq_printf(seq, "Speed: %d Mbps\n", slave->speed);
+
+	if (slave->duplex == DUPLEX_UNKNOWN)
+		seq_printf(seq, "Duplex: %s\n", "Unknown");
+	else
+		seq_printf(seq, "Duplex: %s\n", slave->duplex ? "full" : "half");
+
+	seq_printf(seq, "Link Failure Count: %u\n",
+		   slave->link_failure_count);
+
+	seq_printf(seq, "Permanent HW addr: %*phC\n",
+		   slave->dev->addr_len, slave->perm_hwaddr);
+	seq_printf(seq, "Slave queue ID: %d\n", slave->queue_id);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		const struct port *port = &SLAVE_AD_INFO(slave)->port;
+		const struct aggregator *agg = port->aggregator;
+
+		if (agg) {
+			seq_printf(seq, "Aggregator ID: %d\n",
+				   agg->aggregator_identifier);
+			seq_printf(seq, "Actor Churn State: %s\n",
+				   bond_3ad_churn_desc(port->sm_churn_actor_state));
+			seq_printf(seq, "Partner Churn State: %s\n",
+				   bond_3ad_churn_desc(port->sm_churn_partner_state));
+			seq_printf(seq, "Actor Churned Count: %d\n",
+				   port->churn_actor_count);
+			seq_printf(seq, "Partner Churned Count: %d\n",
+				   port->churn_partner_count);
+
+			if (capable(CAP_NET_ADMIN)) {
+				seq_puts(seq, "details actor lacp pdu:\n");
+				seq_printf(seq, "    system priority: %d\n",
+					   port->actor_system_priority);
+				seq_printf(seq, "    system mac address: %pM\n",
+					   &port->actor_system);
+				seq_printf(seq, "    port key: %d\n",
+					   port->actor_oper_port_key);
+				seq_printf(seq, "    port priority: %d\n",
+					   port->actor_port_priority);
+				seq_printf(seq, "    port number: %d\n",
+					   port->actor_port_number);
+				seq_printf(seq, "    port state: %d\n",
+					   port->actor_oper_port_state);
+
+				seq_puts(seq, "details partner lacp pdu:\n");
+				seq_printf(seq, "    system priority: %d\n",
+					   port->partner_oper.system_priority);
+				seq_printf(seq, "    system mac address: %pM\n",
+					   &port->partner_oper.system);
+				seq_printf(seq, "    oper key: %d\n",
+					   port->partner_oper.key);
+				seq_printf(seq, "    port priority: %d\n",
+					   port->partner_oper.port_priority);
+				seq_printf(seq, "    port number: %d\n",
+					   port->partner_oper.port_number);
+				seq_printf(seq, "    port state: %d\n",
+					   port->partner_oper.port_state);
+			}
+		} else {
+			seq_puts(seq, "Aggregator ID: N/A\n");
+		}
+	}
+}
+
+static int bond_info_seq_show(struct seq_file *seq, void *v)
+{
+	if (v == SEQ_START_TOKEN) {
+		seq_printf(seq, "%s\n", bond_version);
+		bond_info_show_master(seq);
+	} else
+		bond_info_show_slave(seq, v);
+
+	return 0;
+}
+
+static const struct seq_operations bond_info_seq_ops = {
+	.start = bond_info_seq_start,
+	.next  = bond_info_seq_next,
+	.stop  = bond_info_seq_stop,
+	.show  = bond_info_seq_show,
+};
+
+void bond_create_proc_entry(struct bonding *bond)
+{
+	struct net_device *bond_dev = bond->dev;
+	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
+
+	if (bn->proc_dir) {
+		bond->proc_entry = proc_create_seq_data(bond_dev->name, 0444,
+				bn->proc_dir, &bond_info_seq_ops, bond);
+		if (bond->proc_entry == NULL)
+			netdev_warn(bond_dev, "Cannot create /proc/net/%s/%s\n",
+				    DRV_NAME, bond_dev->name);
+		else
+			memcpy(bond->proc_file_name, bond_dev->name, IFNAMSIZ);
+	}
+}
+
+void bond_remove_proc_entry(struct bonding *bond)
+{
+	struct net_device *bond_dev = bond->dev;
+	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
+
+	if (bn->proc_dir && bond->proc_entry) {
+		remove_proc_entry(bond->proc_file_name, bn->proc_dir);
+		memset(bond->proc_file_name, 0, IFNAMSIZ);
+		bond->proc_entry = NULL;
+	}
+}
+
+/* Create the bonding directory under /proc/net, if doesn't exist yet.
+ * Caller must hold rtnl_lock.
+ */
+void __net_init bond_create_proc_dir(struct bond_net *bn)
+{
+	if (!bn->proc_dir) {
+		bn->proc_dir = proc_mkdir(DRV_NAME, bn->net->proc_net);
+		if (!bn->proc_dir)
+			pr_warn("Warning: Cannot create /proc/net/%s\n",
+				DRV_NAME);
+	}
+}
+
+/* Destroy the bonding directory under /proc/net, if empty.
+ * Caller must hold rtnl_lock.
+ */
+void __net_exit bond_destroy_proc_dir(struct bond_net *bn)
+{
+	if (bn->proc_dir) {
+		remove_proc_entry(DRV_NAME, bn->net->proc_net);
+		bn->proc_dir = NULL;
+	}
+}
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.103/bond_sysfs.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.103/bond_sysfs.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,819 @@
+/*
+ * Copyright(c) 2004-2005 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, see <http://www.gnu.org/licenses/>.
+ *
+ * The full GNU General Public License is included in this distribution in the
+ * file called LICENSE.
+ *
+ */
+
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/sched/signal.h>
+#include <linux/fs.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/netdevice.h>
+#include <linux/inetdevice.h>
+#include <linux/in.h>
+#include <linux/sysfs.h>
+#include <linux/ctype.h>
+#include <linux/inet.h>
+#include <linux/rtnetlink.h>
+#include <linux/etherdevice.h>
+#include <net/net_namespace.h>
+#include <net/netns/generic.h>
+#include <linux/nsproxy.h>
+
+#include <net/bonding.h>
+
+#define to_bond(cd)	((struct bonding *)(netdev_priv(to_net_dev(cd))))
+
+/* "show" function for the bond_masters attribute.
+ * The class parameter is ignored.
+ */
+static ssize_t bonding_show_bonds(struct class *cls,
+				  struct class_attribute *attr,
+				  char *buf)
+{
+	struct bond_net *bn =
+		container_of(attr, struct bond_net, class_attr_bonding_masters);
+	int res = 0;
+	struct bonding *bond;
+
+	rtnl_lock();
+
+	list_for_each_entry(bond, &bn->dev_list, bond_list) {
+		if (res > (PAGE_SIZE - IFNAMSIZ)) {
+			/* not enough space for another interface name */
+			if ((PAGE_SIZE - res) > 10)
+				res = PAGE_SIZE - 10;
+			res += sprintf(buf + res, "++more++ ");
+			break;
+		}
+		res += sprintf(buf + res, "%s ", bond->dev->name);
+	}
+	if (res)
+		buf[res-1] = '\n'; /* eat the leftover space */
+
+	rtnl_unlock();
+	return res;
+}
+
+static struct net_device *bond_get_by_name(struct bond_net *bn, const char *ifname)
+{
+	struct bonding *bond;
+
+	list_for_each_entry(bond, &bn->dev_list, bond_list) {
+		if (strncmp(bond->dev->name, ifname, IFNAMSIZ) == 0)
+			return bond->dev;
+	}
+	return NULL;
+}
+
+/* "store" function for the bond_masters attribute.  This is what
+ * creates and deletes entire bonds.
+ *
+ * The class parameter is ignored.
+ */
+static ssize_t bonding_store_bonds(struct class *cls,
+				   struct class_attribute *attr,
+				   const char *buffer, size_t count)
+{
+	struct bond_net *bn =
+		container_of(attr, struct bond_net, class_attr_bonding_masters);
+	char command[IFNAMSIZ + 1] = {0, };
+	char *ifname;
+	int rv, res = count;
+
+	sscanf(buffer, "%16s", command); /* IFNAMSIZ*/
+	ifname = command + 1;
+	if ((strlen(command) <= 1) ||
+	    !dev_valid_name(ifname))
+		goto err_no_cmd;
+
+	if (command[0] == '+') {
+		pr_info("%s is being created...\n", ifname);
+		rv = bond_create(bn->net, ifname);
+		if (rv) {
+			if (rv == -EEXIST)
+				pr_info("%s already exists\n", ifname);
+			else
+				pr_info("%s creation failed\n", ifname);
+			res = rv;
+		}
+	} else if (command[0] == '-') {
+		struct net_device *bond_dev;
+
+		rtnl_lock();
+		bond_dev = bond_get_by_name(bn, ifname);
+		if (bond_dev) {
+			pr_info("%s is being deleted...\n", ifname);
+			unregister_netdevice(bond_dev);
+		} else {
+			pr_err("unable to delete non-existent %s\n", ifname);
+			res = -ENODEV;
+		}
+		rtnl_unlock();
+	} else
+		goto err_no_cmd;
+
+	/* Always return either count or an error.  If you return 0, you'll
+	 * get called forever, which is bad.
+	 */
+	return res;
+
+err_no_cmd:
+	pr_err("no command found in bonding_masters - use +ifname or -ifname\n");
+	return -EPERM;
+}
+
+/* class attribute for bond_masters file.  This ends up in /sys/class/net */
+static const struct class_attribute class_attr_bonding_masters = {
+	.attr = {
+		.name = "bonding_masters",
+		.mode = 0644,
+	},
+	.show = bonding_show_bonds,
+	.store = bonding_store_bonds,
+};
+
+/* Generic "store" method for bonding sysfs option setting */
+static ssize_t bonding_sysfs_store_option(struct device *d,
+					  struct device_attribute *attr,
+					  const char *buffer, size_t count)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_option *opt;
+	char *buffer_clone;
+	int ret;
+
+	opt = bond_opt_get_by_name(attr->attr.name);
+	if (WARN_ON(!opt))
+		return -ENOENT;
+	buffer_clone = kstrndup(buffer, count, GFP_KERNEL);
+	if (!buffer_clone)
+		return -ENOMEM;
+	ret = bond_opt_tryset_rtnl(bond, opt->id, buffer_clone);
+	if (!ret)
+		ret = count;
+	kfree(buffer_clone);
+
+	return ret;
+}
+
+/* Show the slaves in the current bond. */
+static ssize_t bonding_show_slaves(struct device *d,
+				   struct device_attribute *attr, char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	struct list_head *iter;
+	struct slave *slave;
+	int res = 0;
+
+	if (!rtnl_trylock())
+		return restart_syscall();
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (res > (PAGE_SIZE - IFNAMSIZ)) {
+			/* not enough space for another interface name */
+			if ((PAGE_SIZE - res) > 10)
+				res = PAGE_SIZE - 10;
+			res += sprintf(buf + res, "++more++ ");
+			break;
+		}
+		res += sprintf(buf + res, "%s ", slave->dev->name);
+	}
+
+	rtnl_unlock();
+
+	if (res)
+		buf[res-1] = '\n'; /* eat the leftover space */
+
+	return res;
+}
+static DEVICE_ATTR(slaves, 0644, bonding_show_slaves,
+		   bonding_sysfs_store_option);
+
+/* Show the bonding mode. */
+static ssize_t bonding_show_mode(struct device *d,
+				 struct device_attribute *attr, char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_MODE, BOND_MODE(bond));
+
+	return sprintf(buf, "%s %d\n", val->string, BOND_MODE(bond));
+}
+static DEVICE_ATTR(mode, 0644, bonding_show_mode, bonding_sysfs_store_option);
+
+/* Show the bonding transmit hash method. */
+static ssize_t bonding_show_xmit_hash(struct device *d,
+				      struct device_attribute *attr,
+				      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_XMIT_HASH, bond->params.xmit_policy);
+
+	return sprintf(buf, "%s %d\n", val->string, bond->params.xmit_policy);
+}
+static DEVICE_ATTR(xmit_hash_policy, 0644,
+		   bonding_show_xmit_hash, bonding_sysfs_store_option);
+
+/* Show arp_validate. */
+static ssize_t bonding_show_arp_validate(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
+			       bond->params.arp_validate);
+
+	return sprintf(buf, "%s %d\n", val->string, bond->params.arp_validate);
+}
+static DEVICE_ATTR(arp_validate, 0644, bonding_show_arp_validate,
+		   bonding_sysfs_store_option);
+
+/* Show arp_all_targets. */
+static ssize_t bonding_show_arp_all_targets(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_ARP_ALL_TARGETS,
+			       bond->params.arp_all_targets);
+	return sprintf(buf, "%s %d\n",
+		       val->string, bond->params.arp_all_targets);
+}
+static DEVICE_ATTR(arp_all_targets, 0644,
+		   bonding_show_arp_all_targets, bonding_sysfs_store_option);
+
+/* Show fail_over_mac. */
+static ssize_t bonding_show_fail_over_mac(struct device *d,
+					  struct device_attribute *attr,
+					  char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
+			       bond->params.fail_over_mac);
+
+	return sprintf(buf, "%s %d\n", val->string, bond->params.fail_over_mac);
+}
+static DEVICE_ATTR(fail_over_mac, 0644,
+		   bonding_show_fail_over_mac, bonding_sysfs_store_option);
+
+/* Show the arp timer interval. */
+static ssize_t bonding_show_arp_interval(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.arp_interval);
+}
+static DEVICE_ATTR(arp_interval, 0644,
+		   bonding_show_arp_interval, bonding_sysfs_store_option);
+
+/* Show the arp targets. */
+static ssize_t bonding_show_arp_targets(struct device *d,
+					struct device_attribute *attr,
+					char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	int i, res = 0;
+
+	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
+		if (bond->params.arp_targets[i])
+			res += sprintf(buf + res, "%pI4 ",
+				       &bond->params.arp_targets[i]);
+	}
+	if (res)
+		buf[res-1] = '\n'; /* eat the leftover space */
+
+	return res;
+}
+static DEVICE_ATTR(arp_ip_target, 0644,
+		   bonding_show_arp_targets, bonding_sysfs_store_option);
+
+/* Show the up and down delays. */
+static ssize_t bonding_show_downdelay(struct device *d,
+				      struct device_attribute *attr,
+				      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.downdelay * bond->params.miimon);
+}
+static DEVICE_ATTR(downdelay, 0644,
+		   bonding_show_downdelay, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_updelay(struct device *d,
+				    struct device_attribute *attr,
+				    char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.updelay * bond->params.miimon);
+
+}
+static DEVICE_ATTR(updelay, 0644,
+		   bonding_show_updelay, bonding_sysfs_store_option);
+
+/* Show the LACP interval. */
+static ssize_t bonding_show_lacp(struct device *d,
+				 struct device_attribute *attr,
+				 char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_LACP_RATE, bond->params.lacp_fast);
+
+	return sprintf(buf, "%s %d\n", val->string, bond->params.lacp_fast);
+}
+static DEVICE_ATTR(lacp_rate, 0644,
+		   bonding_show_lacp, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_min_links(struct device *d,
+				      struct device_attribute *attr,
+				      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%u\n", bond->params.min_links);
+}
+static DEVICE_ATTR(min_links, 0644,
+		   bonding_show_min_links, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_ad_select(struct device *d,
+				      struct device_attribute *attr,
+				      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_AD_SELECT, bond->params.ad_select);
+
+	return sprintf(buf, "%s %d\n", val->string, bond->params.ad_select);
+}
+static DEVICE_ATTR(ad_select, 0644,
+		   bonding_show_ad_select, bonding_sysfs_store_option);
+
+/* Show the number of peer notifications to send after a failover event. */
+static ssize_t bonding_show_num_peer_notif(struct device *d,
+					   struct device_attribute *attr,
+					   char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	return sprintf(buf, "%d\n", bond->params.num_peer_notif);
+}
+static DEVICE_ATTR(num_grat_arp, 0644,
+		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
+static DEVICE_ATTR(num_unsol_na, 0644,
+		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
+
+/* Show the MII monitor interval. */
+static ssize_t bonding_show_miimon(struct device *d,
+				   struct device_attribute *attr,
+				   char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.miimon);
+}
+static DEVICE_ATTR(miimon, 0644,
+		   bonding_show_miimon, bonding_sysfs_store_option);
+
+/* Show the primary slave. */
+static ssize_t bonding_show_primary(struct device *d,
+				    struct device_attribute *attr,
+				    char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	struct slave *primary;
+	int count = 0;
+
+	rcu_read_lock();
+	primary = rcu_dereference(bond->primary_slave);
+	if (primary)
+		count = sprintf(buf, "%s\n", primary->dev->name);
+	rcu_read_unlock();
+
+	return count;
+}
+static DEVICE_ATTR(primary, 0644,
+		   bonding_show_primary, bonding_sysfs_store_option);
+
+/* Show the primary_reselect flag. */
+static ssize_t bonding_show_primary_reselect(struct device *d,
+					     struct device_attribute *attr,
+					     char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
+			       bond->params.primary_reselect);
+
+	return sprintf(buf, "%s %d\n",
+		       val->string, bond->params.primary_reselect);
+}
+static DEVICE_ATTR(primary_reselect, 0644,
+		   bonding_show_primary_reselect, bonding_sysfs_store_option);
+
+/* Show the use_carrier flag. */
+static ssize_t bonding_show_carrier(struct device *d,
+				    struct device_attribute *attr,
+				    char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.use_carrier);
+}
+static DEVICE_ATTR(use_carrier, 0644,
+		   bonding_show_carrier, bonding_sysfs_store_option);
+
+
+/* Show currently active_slave. */
+static ssize_t bonding_show_active_slave(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	struct net_device *slave_dev;
+	int count = 0;
+
+	rcu_read_lock();
+	slave_dev = bond_option_active_slave_get_rcu(bond);
+	if (slave_dev)
+		count = sprintf(buf, "%s\n", slave_dev->name);
+	rcu_read_unlock();
+
+	return count;
+}
+static DEVICE_ATTR(active_slave, 0644,
+		   bonding_show_active_slave, bonding_sysfs_store_option);
+
+/* Show link status of the bond interface. */
+static ssize_t bonding_show_mii_status(struct device *d,
+				       struct device_attribute *attr,
+				       char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	bool active = netif_carrier_ok(bond->dev);
+
+	return sprintf(buf, "%s\n", active ? "up" : "down");
+}
+static DEVICE_ATTR(mii_status, 0444, bonding_show_mii_status, NULL);
+
+/* Show current 802.3ad aggregator ID. */
+static ssize_t bonding_show_ad_aggregator(struct device *d,
+					  struct device_attribute *attr,
+					  char *buf)
+{
+	int count = 0;
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		struct ad_info ad_info;
+		count = sprintf(buf, "%d\n",
+				bond_3ad_get_active_agg_info(bond, &ad_info)
+				?  0 : ad_info.aggregator_id);
+	}
+
+	return count;
+}
+static DEVICE_ATTR(ad_aggregator, 0444, bonding_show_ad_aggregator, NULL);
+
+
+/* Show number of active 802.3ad ports. */
+static ssize_t bonding_show_ad_num_ports(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	int count = 0;
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		struct ad_info ad_info;
+		count = sprintf(buf, "%d\n",
+				bond_3ad_get_active_agg_info(bond, &ad_info)
+				?  0 : ad_info.ports);
+	}
+
+	return count;
+}
+static DEVICE_ATTR(ad_num_ports, 0444, bonding_show_ad_num_ports, NULL);
+
+
+/* Show current 802.3ad actor key. */
+static ssize_t bonding_show_ad_actor_key(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	int count = 0;
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
+		struct ad_info ad_info;
+		count = sprintf(buf, "%d\n",
+				bond_3ad_get_active_agg_info(bond, &ad_info)
+				?  0 : ad_info.actor_key);
+	}
+
+	return count;
+}
+static DEVICE_ATTR(ad_actor_key, 0444, bonding_show_ad_actor_key, NULL);
+
+
+/* Show current 802.3ad partner key. */
+static ssize_t bonding_show_ad_partner_key(struct device *d,
+					   struct device_attribute *attr,
+					   char *buf)
+{
+	int count = 0;
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
+		struct ad_info ad_info;
+		count = sprintf(buf, "%d\n",
+				bond_3ad_get_active_agg_info(bond, &ad_info)
+				?  0 : ad_info.partner_key);
+	}
+
+	return count;
+}
+static DEVICE_ATTR(ad_partner_key, 0444, bonding_show_ad_partner_key, NULL);
+
+
+/* Show current 802.3ad partner mac. */
+static ssize_t bonding_show_ad_partner_mac(struct device *d,
+					   struct device_attribute *attr,
+					   char *buf)
+{
+	int count = 0;
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
+		struct ad_info ad_info;
+		if (!bond_3ad_get_active_agg_info(bond, &ad_info))
+			count = sprintf(buf, "%pM\n", ad_info.partner_system);
+	}
+
+	return count;
+}
+static DEVICE_ATTR(ad_partner_mac, 0444, bonding_show_ad_partner_mac, NULL);
+
+/* Show the queue_ids of the slaves in the current bond. */
+static ssize_t bonding_show_queue_id(struct device *d,
+				     struct device_attribute *attr,
+				     char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	struct list_head *iter;
+	struct slave *slave;
+	int res = 0;
+
+	if (!rtnl_trylock())
+		return restart_syscall();
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (res > (PAGE_SIZE - IFNAMSIZ - 6)) {
+			/* not enough space for another interface_name:queue_id pair */
+			if ((PAGE_SIZE - res) > 10)
+				res = PAGE_SIZE - 10;
+			res += sprintf(buf + res, "++more++ ");
+			break;
+		}
+		res += sprintf(buf + res, "%s:%d ",
+			       slave->dev->name, slave->queue_id);
+	}
+	if (res)
+		buf[res-1] = '\n'; /* eat the leftover space */
+
+	rtnl_unlock();
+
+	return res;
+}
+static DEVICE_ATTR(queue_id, 0644, bonding_show_queue_id,
+		   bonding_sysfs_store_option);
+
+
+/* Show the all_slaves_active flag. */
+static ssize_t bonding_show_slaves_active(struct device *d,
+					  struct device_attribute *attr,
+					  char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.all_slaves_active);
+}
+static DEVICE_ATTR(all_slaves_active, 0644,
+		   bonding_show_slaves_active, bonding_sysfs_store_option);
+
+/* Show the number of IGMP membership reports to send on link failure */
+static ssize_t bonding_show_resend_igmp(struct device *d,
+					struct device_attribute *attr,
+					char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.resend_igmp);
+}
+static DEVICE_ATTR(resend_igmp, 0644,
+		   bonding_show_resend_igmp, bonding_sysfs_store_option);
+
+
+static ssize_t bonding_show_lp_interval(struct device *d,
+					struct device_attribute *attr,
+					char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.lp_interval);
+}
+static DEVICE_ATTR(lp_interval, 0644,
+		   bonding_show_lp_interval, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_tlb_dynamic_lb(struct device *d,
+					   struct device_attribute *attr,
+					   char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	return sprintf(buf, "%d\n", bond->params.tlb_dynamic_lb);
+}
+static DEVICE_ATTR(tlb_dynamic_lb, 0644,
+		   bonding_show_tlb_dynamic_lb, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_packets_per_slave(struct device *d,
+					      struct device_attribute *attr,
+					      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	unsigned int packets_per_slave = bond->params.packets_per_slave;
+
+	return sprintf(buf, "%u\n", packets_per_slave);
+}
+static DEVICE_ATTR(packets_per_slave, 0644,
+		   bonding_show_packets_per_slave, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_ad_actor_sys_prio(struct device *d,
+					      struct device_attribute *attr,
+					      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
+		return sprintf(buf, "%hu\n", bond->params.ad_actor_sys_prio);
+
+	return 0;
+}
+static DEVICE_ATTR(ad_actor_sys_prio, 0644,
+		   bonding_show_ad_actor_sys_prio, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_ad_actor_system(struct device *d,
+					    struct device_attribute *attr,
+					    char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
+		return sprintf(buf, "%pM\n", bond->params.ad_actor_system);
+
+	return 0;
+}
+
+static DEVICE_ATTR(ad_actor_system, 0644,
+		   bonding_show_ad_actor_system, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_ad_user_port_key(struct device *d,
+					     struct device_attribute *attr,
+					     char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
+		return sprintf(buf, "%hu\n", bond->params.ad_user_port_key);
+
+	return 0;
+}
+static DEVICE_ATTR(ad_user_port_key, 0644,
+		   bonding_show_ad_user_port_key, bonding_sysfs_store_option);
+
+static struct attribute *per_bond_attrs[] = {
+	&dev_attr_slaves.attr,
+	&dev_attr_mode.attr,
+	&dev_attr_fail_over_mac.attr,
+	&dev_attr_arp_validate.attr,
+	&dev_attr_arp_all_targets.attr,
+	&dev_attr_arp_interval.attr,
+	&dev_attr_arp_ip_target.attr,
+	&dev_attr_downdelay.attr,
+	&dev_attr_updelay.attr,
+	&dev_attr_lacp_rate.attr,
+	&dev_attr_ad_select.attr,
+	&dev_attr_xmit_hash_policy.attr,
+	&dev_attr_num_grat_arp.attr,
+	&dev_attr_num_unsol_na.attr,
+	&dev_attr_miimon.attr,
+	&dev_attr_primary.attr,
+	&dev_attr_primary_reselect.attr,
+	&dev_attr_use_carrier.attr,
+	&dev_attr_active_slave.attr,
+	&dev_attr_mii_status.attr,
+	&dev_attr_ad_aggregator.attr,
+	&dev_attr_ad_num_ports.attr,
+	&dev_attr_ad_actor_key.attr,
+	&dev_attr_ad_partner_key.attr,
+	&dev_attr_ad_partner_mac.attr,
+	&dev_attr_queue_id.attr,
+	&dev_attr_all_slaves_active.attr,
+	&dev_attr_resend_igmp.attr,
+	&dev_attr_min_links.attr,
+	&dev_attr_lp_interval.attr,
+	&dev_attr_packets_per_slave.attr,
+	&dev_attr_tlb_dynamic_lb.attr,
+	&dev_attr_ad_actor_sys_prio.attr,
+	&dev_attr_ad_actor_system.attr,
+	&dev_attr_ad_user_port_key.attr,
+	NULL,
+};
+
+static const struct attribute_group bonding_group = {
+	.name = "bonding",
+	.attrs = per_bond_attrs,
+};
+
+/* Initialize sysfs.  This sets up the bonding_masters file in
+ * /sys/class/net.
+ */
+int bond_create_sysfs(struct bond_net *bn)
+{
+	int ret;
+
+	bn->class_attr_bonding_masters = class_attr_bonding_masters;
+	sysfs_attr_init(&bn->class_attr_bonding_masters.attr);
+
+	ret = netdev_class_create_file_ns(&bn->class_attr_bonding_masters,
+					  bn->net);
+	/* Permit multiple loads of the module by ignoring failures to
+	 * create the bonding_masters sysfs file.  Bonding devices
+	 * created by second or subsequent loads of the module will
+	 * not be listed in, or controllable by, bonding_masters, but
+	 * will have the usual "bonding" sysfs directory.
+	 *
+	 * This is done to preserve backwards compatibility for
+	 * initscripts/sysconfig, which load bonding multiple times to
+	 * configure multiple bonding devices.
+	 */
+	if (ret == -EEXIST) {
+		/* Is someone being kinky and naming a device bonding_master? */
+		if (__dev_get_by_name(bn->net,
+				      class_attr_bonding_masters.attr.name))
+			pr_err("network device named %s already exists in sysfs\n",
+			       class_attr_bonding_masters.attr.name);
+		ret = 0;
+	}
+
+	return ret;
+
+}
+
+/* Remove /sys/class/net/bonding_masters. */
+void bond_destroy_sysfs(struct bond_net *bn)
+{
+	netdev_class_remove_file_ns(&bn->class_attr_bonding_masters, bn->net);
+}
+
+/* Initialize sysfs for each bond.  This sets up and registers
+ * the 'bondctl' directory for each individual bond under /sys/class/net.
+ */
+void bond_prepare_sysfs_group(struct bonding *bond)
+{
+	bond->dev->sysfs_groups[0] = &bonding_group;
+}
+
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.103/bond_sysfs_slave.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.103/bond_sysfs_slave.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,178 @@
+/*	Sysfs attributes of bond slaves
+ *
+ *      Copyright (c) 2014 Scott Feldman <sfeldma@cumulusnetworks.com>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *	modify it under the terms of the GNU General Public License
+ *	as published by the Free Software Foundation; either version
+ *	2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+
+#include <net/bonding.h>
+
+struct slave_attribute {
+	struct attribute attr;
+	ssize_t (*show)(struct slave *, char *);
+};
+
+#define SLAVE_ATTR(_name, _mode, _show)				\
+const struct slave_attribute slave_attr_##_name = {		\
+	.attr = {.name = __stringify(_name),			\
+		 .mode = _mode },				\
+	.show	= _show,					\
+};
+#define SLAVE_ATTR_RO(_name)					\
+	SLAVE_ATTR(_name, 0444, _name##_show)
+
+static ssize_t state_show(struct slave *slave, char *buf)
+{
+	switch (bond_slave_state(slave)) {
+	case BOND_STATE_ACTIVE:
+		return sprintf(buf, "active\n");
+	case BOND_STATE_BACKUP:
+		return sprintf(buf, "backup\n");
+	default:
+		return sprintf(buf, "UNKNOWN\n");
+	}
+}
+static SLAVE_ATTR_RO(state);
+
+static ssize_t mii_status_show(struct slave *slave, char *buf)
+{
+	return sprintf(buf, "%s\n", bond_slave_link_status(slave->link));
+}
+static SLAVE_ATTR_RO(mii_status);
+
+static ssize_t link_failure_count_show(struct slave *slave, char *buf)
+{
+	return sprintf(buf, "%d\n", slave->link_failure_count);
+}
+static SLAVE_ATTR_RO(link_failure_count);
+
+static ssize_t perm_hwaddr_show(struct slave *slave, char *buf)
+{
+	return sprintf(buf, "%*phC\n",
+		       slave->dev->addr_len,
+		       slave->perm_hwaddr);
+}
+static SLAVE_ATTR_RO(perm_hwaddr);
+
+static ssize_t queue_id_show(struct slave *slave, char *buf)
+{
+	return sprintf(buf, "%d\n", slave->queue_id);
+}
+static SLAVE_ATTR_RO(queue_id);
+
+static ssize_t ad_aggregator_id_show(struct slave *slave, char *buf)
+{
+	const struct aggregator *agg;
+
+	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
+		agg = SLAVE_AD_INFO(slave)->port.aggregator;
+		if (agg)
+			return sprintf(buf, "%d\n",
+				       agg->aggregator_identifier);
+	}
+
+	return sprintf(buf, "N/A\n");
+}
+static SLAVE_ATTR_RO(ad_aggregator_id);
+
+static ssize_t ad_actor_oper_port_state_show(struct slave *slave, char *buf)
+{
+	const struct port *ad_port;
+
+	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
+		ad_port = &SLAVE_AD_INFO(slave)->port;
+		if (ad_port->aggregator)
+			return sprintf(buf, "%u\n",
+				       ad_port->actor_oper_port_state);
+	}
+
+	return sprintf(buf, "N/A\n");
+}
+static SLAVE_ATTR_RO(ad_actor_oper_port_state);
+
+static ssize_t ad_partner_oper_port_state_show(struct slave *slave, char *buf)
+{
+	const struct port *ad_port;
+
+	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
+		ad_port = &SLAVE_AD_INFO(slave)->port;
+		if (ad_port->aggregator)
+			return sprintf(buf, "%u\n",
+				       ad_port->partner_oper.port_state);
+	}
+
+	return sprintf(buf, "N/A\n");
+}
+static SLAVE_ATTR_RO(ad_partner_oper_port_state);
+
+static const struct slave_attribute *slave_attrs[] = {
+	&slave_attr_state,
+	&slave_attr_mii_status,
+	&slave_attr_link_failure_count,
+	&slave_attr_perm_hwaddr,
+	&slave_attr_queue_id,
+	&slave_attr_ad_aggregator_id,
+	&slave_attr_ad_actor_oper_port_state,
+	&slave_attr_ad_partner_oper_port_state,
+	NULL
+};
+
+#define to_slave_attr(_at) container_of(_at, struct slave_attribute, attr)
+#define to_slave(obj)	container_of(obj, struct slave, kobj)
+
+static ssize_t slave_show(struct kobject *kobj,
+			  struct attribute *attr, char *buf)
+{
+	struct slave_attribute *slave_attr = to_slave_attr(attr);
+	struct slave *slave = to_slave(kobj);
+
+	return slave_attr->show(slave, buf);
+}
+
+static const struct sysfs_ops slave_sysfs_ops = {
+	.show = slave_show,
+};
+
+static struct kobj_type slave_ktype = {
+#ifdef CONFIG_SYSFS
+	.sysfs_ops = &slave_sysfs_ops,
+#endif
+};
+
+int bond_sysfs_slave_add(struct slave *slave)
+{
+	const struct slave_attribute **a;
+	int err;
+
+	err = kobject_init_and_add(&slave->kobj, &slave_ktype,
+				   &(slave->dev->dev.kobj), "bonding_slave");
+	if (err)
+		return err;
+
+	for (a = slave_attrs; *a; ++a) {
+		err = sysfs_create_file(&slave->kobj, &((*a)->attr));
+		if (err) {
+			kobject_put(&slave->kobj);
+			return err;
+		}
+	}
+
+	return 0;
+}
+
+void bond_sysfs_slave_del(struct slave *slave)
+{
+	const struct slave_attribute **a;
+
+	for (a = slave_attrs; *a; ++a)
+		sysfs_remove_file(&slave->kobj, &((*a)->attr));
+
+	kobject_put(&slave->kobj);
+}
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.103/bonding_priv.h
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.103/bonding_priv.h	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,25 @@
+/*
+ * Bond several ethernet interfaces into a Cisco, running 'Etherchannel'.
+ *
+ * Portions are (c) Copyright 1995 Simon "Guru Aleph-Null" Janes
+ * NCM: Network and Communications Management, Inc.
+ *
+ * BUT, I'm the one who modified it for ethernet, so:
+ * (c) Copyright 1999, Thomas Davis, tadavis@lbl.gov
+ *
+ *	This software may be used and distributed according to the terms
+ *	of the GNU Public License, incorporated herein by reference.
+ *
+ */
+
+#ifndef _BONDING_PRIV_H
+#define _BONDING_PRIV_H
+
+#define DRV_VERSION	"3.7.1-chelsio"
+#define DRV_RELDATE	"April 27, 2011"
+#define DRV_NAME	"bonding"
+#define DRV_DESCRIPTION	"Ethernet Channel Bonding Driver with Offload"
+
+#define bond_version DRV_DESCRIPTION ": v" DRV_VERSION " (" DRV_RELDATE ")\n"
+
+#endif
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.164/bond_3ad.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.164/bond_3ad.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,2686 @@
+/*
+ * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the Free
+ * Software Foundation; either version 2 of the License, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc., 59
+ * Temple Place - Suite 330, Boston, MA  02111-1307, USA.
+ *
+ * The full GNU General Public License is included in this distribution in the
+ * file called LICENSE.
+ *
+ */
+
+#include <linux/skbuff.h>
+#include <linux/if_ether.h>
+#include <linux/netdevice.h>
+#include <linux/spinlock.h>
+#include <linux/ethtool.h>
+#include <linux/etherdevice.h>
+#include <linux/if_bonding.h>
+#include <linux/pkt_sched.h>
+#include <linux/toedev.h>
+#include <net/net_namespace.h>
+#include <net/bonding.h>
+#include <net/bond_3ad.h>
+
+/* General definitions */
+#define AD_SHORT_TIMEOUT           1
+#define AD_LONG_TIMEOUT            0
+#define AD_STANDBY                 0x2
+#define AD_MAX_TX_IN_SECOND        3
+#define AD_COLLECTOR_MAX_DELAY     0
+
+/* Timer definitions (43.4.4 in the 802.3ad standard) */
+#define AD_FAST_PERIODIC_TIME      1
+#define AD_SLOW_PERIODIC_TIME      30
+#define AD_SHORT_TIMEOUT_TIME      (3*AD_FAST_PERIODIC_TIME)
+#define AD_LONG_TIMEOUT_TIME       (3*AD_SLOW_PERIODIC_TIME)
+#define AD_CHURN_DETECTION_TIME    60
+#define AD_AGGREGATE_WAIT_TIME     2
+
+/* Port state definitions (43.4.2.2 in the 802.3ad standard) */
+#define AD_STATE_LACP_ACTIVITY   0x1
+#define AD_STATE_LACP_TIMEOUT    0x2
+#define AD_STATE_AGGREGATION     0x4
+#define AD_STATE_SYNCHRONIZATION 0x8
+#define AD_STATE_COLLECTING      0x10
+#define AD_STATE_DISTRIBUTING    0x20
+#define AD_STATE_DEFAULTED       0x40
+#define AD_STATE_EXPIRED         0x80
+
+/* Port Variables definitions used by the State Machines (43.4.7 in the
+ * 802.3ad standard)
+ */
+#define AD_PORT_BEGIN           0x1
+#define AD_PORT_LACP_ENABLED    0x2
+#define AD_PORT_ACTOR_CHURN     0x4
+#define AD_PORT_PARTNER_CHURN   0x8
+#define AD_PORT_READY           0x10
+#define AD_PORT_READY_N         0x20
+#define AD_PORT_MATCHED         0x40
+#define AD_PORT_STANDBY         0x80
+#define AD_PORT_SELECTED        0x100
+#define AD_PORT_MOVED           0x200
+#define AD_PORT_CHURNED         (AD_PORT_ACTOR_CHURN | AD_PORT_PARTNER_CHURN)
+
+/* Port Key definitions
+ * key is determined according to the link speed, duplex and
+ * user key (which is yet not supported)
+ *           --------------------------------------------------------------
+ * Port key  | User key (10 bits)           | Speed (5 bits)      | Duplex|
+ *           --------------------------------------------------------------
+ *           |15                           6|5                   1|0
+ */
+#define  AD_DUPLEX_KEY_MASKS    0x1
+#define  AD_SPEED_KEY_MASKS     0x3E
+#define  AD_USER_KEY_MASKS      0xFFC0
+
+enum ad_link_speed_type {
+	AD_LINK_SPEED_1MBPS = 1,
+	AD_LINK_SPEED_10MBPS,
+	AD_LINK_SPEED_100MBPS,
+	AD_LINK_SPEED_1000MBPS,
+	AD_LINK_SPEED_2500MBPS,
+	AD_LINK_SPEED_5000MBPS,
+	AD_LINK_SPEED_10000MBPS,
+	AD_LINK_SPEED_14000MBPS,
+	AD_LINK_SPEED_20000MBPS,
+	AD_LINK_SPEED_25000MBPS,
+	AD_LINK_SPEED_40000MBPS,
+	AD_LINK_SPEED_50000MBPS,
+	AD_LINK_SPEED_56000MBPS,
+	AD_LINK_SPEED_100000MBPS,
+};
+
+/* compare MAC addresses */
+#define MAC_ADDRESS_EQUAL(A, B)	\
+	ether_addr_equal_64bits((const u8 *)A, (const u8 *)B)
+
+static const u8 null_mac_addr[ETH_ALEN + 2] __long_aligned = {
+	0, 0, 0, 0, 0, 0
+};
+static u16 ad_ticks_per_sec;
+static const int ad_delta_in_ticks = (AD_TIMER_INTERVAL * HZ) / 1000;
+
+static const u8 lacpdu_mcast_addr[ETH_ALEN + 2] __long_aligned =
+	MULTICAST_LACPDU_ADDR;
+
+/* ================= main 802.3ad protocol functions ================== */
+static int ad_lacpdu_send(struct port *port);
+static int ad_marker_send(struct port *port, struct bond_marker *marker);
+static void ad_mux_machine(struct port *port, bool *update_slave_arr);
+static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port);
+static void ad_tx_machine(struct port *port);
+static void ad_periodic_machine(struct port *port);
+static void ad_port_selection_logic(struct port *port, bool *update_slave_arr);
+static void ad_agg_selection_logic(struct aggregator *aggregator,
+				   bool *update_slave_arr);
+static void ad_clear_agg(struct aggregator *aggregator);
+static void ad_initialize_agg(struct aggregator *aggregator);
+static void ad_initialize_port(struct port *port, int lacp_fast);
+static void ad_enable_collecting_distributing(struct port *port,
+					      bool *update_slave_arr);
+static void ad_disable_collecting_distributing(struct port *port,
+					       bool *update_slave_arr);
+static void ad_marker_info_received(struct bond_marker *marker_info,
+				    struct port *port);
+static void ad_marker_response_received(struct bond_marker *marker,
+					struct port *port);
+static void ad_update_actor_keys(struct port *port, bool reset);
+
+
+/* ================= api to bonding and kernel code ================== */
+
+/**
+ * __get_bond_by_port - get the port's bonding struct
+ * @port: the port we're looking at
+ *
+ * Return @port's bonding struct, or %NULL if it can't be found.
+ */
+static inline struct bonding *__get_bond_by_port(struct port *port)
+{
+	if (port->slave == NULL)
+		return NULL;
+
+	return bond_get_bond_by_slave(port->slave);
+}
+
+/**
+ * __get_first_agg - get the first aggregator in the bond
+ * @bond: the bond we're looking at
+ *
+ * Return the aggregator of the first slave in @bond, or %NULL if it can't be
+ * found.
+ * The caller must hold RCU or RTNL lock.
+ */
+static inline struct aggregator *__get_first_agg(struct port *port)
+{
+	struct bonding *bond = __get_bond_by_port(port);
+	struct slave *first_slave;
+	struct aggregator *agg;
+
+	/* If there's no bond for this port, or bond has no slaves */
+	if (bond == NULL)
+		return NULL;
+
+	rcu_read_lock();
+	first_slave = bond_first_slave_rcu(bond);
+	agg = first_slave ? &(SLAVE_AD_INFO(first_slave)->aggregator) : NULL;
+	rcu_read_unlock();
+
+	return agg;
+}
+
+/**
+ * __agg_has_partner - see if we have a partner
+ * @agg: the agregator we're looking at
+ *
+ * Return nonzero if aggregator has a partner (denoted by a non-zero ether
+ * address for the partner). Return 0 if not.
+ */
+static inline int __agg_has_partner(struct aggregator *agg)
+{
+	return !is_zero_ether_addr(agg->partner_system.mac_addr_value);
+}
+
+/**
+ * __disable_port - disable the port's slave
+ * @port: the port we're looking at
+ */
+static inline void __disable_port(struct port *port)
+{
+	bond_set_slave_inactive_flags(port->slave, BOND_SLAVE_NOTIFY_LATER);
+}
+
+/**
+ * __enable_port - enable the port's slave, if it's up
+ * @port: the port we're looking at
+ */
+static inline void __enable_port(struct port *port)
+{
+	struct slave *slave = port->slave;
+
+	if ((slave->link == BOND_LINK_UP) && bond_slave_is_up(slave)) {
+		bond_set_slave_active_flags(slave, BOND_SLAVE_NOTIFY_LATER);
+		toe_failover(netdev_master_upper_dev_get_rcu(port->slave->dev),
+			     port->slave->dev, TOE_LINK_UP, NULL);
+	}
+}
+
+/**
+ * __port_is_enabled - check if the port's slave is in active state
+ * @port: the port we're looking at
+ */
+static inline int __port_is_enabled(struct port *port)
+{
+	return bond_is_active_slave(port->slave);
+}
+
+/**
+ * __get_agg_selection_mode - get the aggregator selection mode
+ * @port: the port we're looking at
+ *
+ * Get the aggregator selection mode. Can be %STABLE, %BANDWIDTH or %COUNT.
+ */
+static inline u32 __get_agg_selection_mode(struct port *port)
+{
+	struct bonding *bond = __get_bond_by_port(port);
+
+	if (bond == NULL)
+		return BOND_AD_STABLE;
+
+	return bond->params.ad_select;
+}
+
+/**
+ * __check_agg_selection_timer - check if the selection timer has expired
+ * @port: the port we're looking at
+ */
+static inline int __check_agg_selection_timer(struct port *port)
+{
+	struct bonding *bond = __get_bond_by_port(port);
+
+	if (bond == NULL)
+		return 0;
+
+	return BOND_AD_INFO(bond).agg_select_timer ? 1 : 0;
+}
+
+/**
+ * __get_link_speed - get a port's speed
+ * @port: the port we're looking at
+ *
+ * Return @port's speed in 802.3ad enum format. i.e. one of:
+ *     0,
+ *     %AD_LINK_SPEED_10MBPS,
+ *     %AD_LINK_SPEED_100MBPS,
+ *     %AD_LINK_SPEED_1000MBPS,
+ *     %AD_LINK_SPEED_2500MBPS,
+ *     %AD_LINK_SPEED_5000MBPS,
+ *     %AD_LINK_SPEED_10000MBPS
+ *     %AD_LINK_SPEED_14000MBPS,
+ *     %AD_LINK_SPEED_20000MBPS
+ *     %AD_LINK_SPEED_25000MBPS
+ *     %AD_LINK_SPEED_40000MBPS
+ *     %AD_LINK_SPEED_50000MBPS
+ *     %AD_LINK_SPEED_56000MBPS
+ *     %AD_LINK_SPEED_100000MBPS
+ */
+static u16 __get_link_speed(struct port *port)
+{
+	struct slave *slave = port->slave;
+	u16 speed;
+
+	/* this if covers only a special case: when the configuration starts
+	 * with link down, it sets the speed to 0.
+	 * This is done in spite of the fact that the e100 driver reports 0
+	 * to be compatible with MVT in the future.
+	 */
+	if (slave->link != BOND_LINK_UP)
+		speed = 0;
+	else {
+		switch (slave->speed) {
+		case SPEED_10:
+			speed = AD_LINK_SPEED_10MBPS;
+			break;
+
+		case SPEED_100:
+			speed = AD_LINK_SPEED_100MBPS;
+			break;
+
+		case SPEED_1000:
+			speed = AD_LINK_SPEED_1000MBPS;
+			break;
+
+		case SPEED_2500:
+			speed = AD_LINK_SPEED_2500MBPS;
+			break;
+
+		case SPEED_5000:
+			speed = AD_LINK_SPEED_5000MBPS;
+			break;
+
+		case SPEED_10000:
+			speed = AD_LINK_SPEED_10000MBPS;
+			break;
+
+		case SPEED_14000:
+			speed = AD_LINK_SPEED_14000MBPS;
+			break;
+
+		case SPEED_20000:
+			speed = AD_LINK_SPEED_20000MBPS;
+			break;
+
+		case SPEED_25000:
+			speed = AD_LINK_SPEED_25000MBPS;
+			break;
+
+		case SPEED_40000:
+			speed = AD_LINK_SPEED_40000MBPS;
+			break;
+
+		case SPEED_50000:
+			speed = AD_LINK_SPEED_50000MBPS;
+			break;
+
+		case SPEED_56000:
+			speed = AD_LINK_SPEED_56000MBPS;
+			break;
+
+		case SPEED_100000:
+			speed = AD_LINK_SPEED_100000MBPS;
+			break;
+
+		default:
+			/* unknown speed value from ethtool. shouldn't happen */
+			if (slave->speed != SPEED_UNKNOWN)
+				pr_warn_once("%s: unknown ethtool speed (%d) for port %d (set it to 0)\n",
+					     slave->bond->dev->name,
+					     slave->speed,
+					     port->actor_port_number);
+			speed = 0;
+			break;
+		}
+	}
+
+	netdev_dbg(slave->bond->dev, "Port %d Received link speed %d update from adapter\n",
+		   port->actor_port_number, speed);
+	return speed;
+}
+
+/**
+ * __get_duplex - get a port's duplex
+ * @port: the port we're looking at
+ *
+ * Return @port's duplex in 802.3ad bitmask format. i.e.:
+ *     0x01 if in full duplex
+ *     0x00 otherwise
+ */
+static u8 __get_duplex(struct port *port)
+{
+	struct slave *slave = port->slave;
+	u8 retval = 0x0;
+
+	/* handling a special case: when the configuration starts with
+	 * link down, it sets the duplex to 0.
+	 */
+	if (slave->link == BOND_LINK_UP) {
+		switch (slave->duplex) {
+		case DUPLEX_FULL:
+			retval = 0x1;
+			netdev_dbg(slave->bond->dev, "Port %d Received status full duplex update from adapter\n",
+				   port->actor_port_number);
+			break;
+		case DUPLEX_HALF:
+		default:
+			retval = 0x0;
+			netdev_dbg(slave->bond->dev, "Port %d Received status NOT full duplex update from adapter\n",
+				   port->actor_port_number);
+			break;
+		}
+	}
+	return retval;
+}
+
+static void __ad_actor_update_port(struct port *port)
+{
+	const struct bonding *bond = bond_get_bond_by_slave(port->slave);
+
+	port->actor_system = BOND_AD_INFO(bond).system.sys_mac_addr;
+	port->actor_system_priority = BOND_AD_INFO(bond).system.sys_priority;
+}
+
+/* Conversions */
+
+/**
+ * __ad_timer_to_ticks - convert a given timer type to AD module ticks
+ * @timer_type:	which timer to operate
+ * @par: timer parameter. see below
+ *
+ * If @timer_type is %current_while_timer, @par indicates long/short timer.
+ * If @timer_type is %periodic_timer, @par is one of %FAST_PERIODIC_TIME,
+ *						     %SLOW_PERIODIC_TIME.
+ */
+static u16 __ad_timer_to_ticks(u16 timer_type, u16 par)
+{
+	u16 retval = 0; /* to silence the compiler */
+
+	switch (timer_type) {
+	case AD_CURRENT_WHILE_TIMER:	/* for rx machine usage */
+		if (par)
+			retval = (AD_SHORT_TIMEOUT_TIME*ad_ticks_per_sec);
+		else
+			retval = (AD_LONG_TIMEOUT_TIME*ad_ticks_per_sec);
+		break;
+	case AD_ACTOR_CHURN_TIMER:	/* for local churn machine */
+		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
+		break;
+	case AD_PERIODIC_TIMER:		/* for periodic machine */
+		retval = (par*ad_ticks_per_sec); /* long timeout */
+		break;
+	case AD_PARTNER_CHURN_TIMER:	/* for remote churn machine */
+		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
+		break;
+	case AD_WAIT_WHILE_TIMER:	/* for selection machine */
+		retval = (AD_AGGREGATE_WAIT_TIME*ad_ticks_per_sec);
+		break;
+	}
+
+	return retval;
+}
+
+
+/* ================= ad_rx_machine helper functions ================== */
+
+/**
+ * __choose_matched - update a port's matched variable from a received lacpdu
+ * @lacpdu: the lacpdu we've received
+ * @port: the port we're looking at
+ *
+ * Update the value of the matched variable, using parameter values from a
+ * newly received lacpdu. Parameter values for the partner carried in the
+ * received PDU are compared with the corresponding operational parameter
+ * values for the actor. Matched is set to TRUE if all of these parameters
+ * match and the PDU parameter partner_state.aggregation has the same value as
+ * actor_oper_port_state.aggregation and lacp will actively maintain the link
+ * in the aggregation. Matched is also set to TRUE if the value of
+ * actor_state.aggregation in the received PDU is set to FALSE, i.e., indicates
+ * an individual link and lacp will actively maintain the link. Otherwise,
+ * matched is set to FALSE. LACP is considered to be actively maintaining the
+ * link if either the PDU's actor_state.lacp_activity variable is TRUE or both
+ * the actor's actor_oper_port_state.lacp_activity and the PDU's
+ * partner_state.lacp_activity variables are TRUE.
+ *
+ * Note: the AD_PORT_MATCHED "variable" is not specified by 802.3ad; it is
+ * used here to implement the language from 802.3ad 43.4.9 that requires
+ * recordPDU to "match" the LACPDU parameters to the stored values.
+ */
+static void __choose_matched(struct lacpdu *lacpdu, struct port *port)
+{
+	/* check if all parameters are alike
+	 * or this is individual link(aggregation == FALSE)
+	 * then update the state machine Matched variable.
+	 */
+	if (((ntohs(lacpdu->partner_port) == port->actor_port_number) &&
+	     (ntohs(lacpdu->partner_port_priority) == port->actor_port_priority) &&
+	     MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) &&
+	     (ntohs(lacpdu->partner_system_priority) == port->actor_system_priority) &&
+	     (ntohs(lacpdu->partner_key) == port->actor_oper_port_key) &&
+	     ((lacpdu->partner_state & AD_STATE_AGGREGATION) == (port->actor_oper_port_state & AD_STATE_AGGREGATION))) ||
+	    ((lacpdu->actor_state & AD_STATE_AGGREGATION) == 0)
+		) {
+		port->sm_vars |= AD_PORT_MATCHED;
+	} else {
+		port->sm_vars &= ~AD_PORT_MATCHED;
+	}
+}
+
+/**
+ * __record_pdu - record parameters from a received lacpdu
+ * @lacpdu: the lacpdu we've received
+ * @port: the port we're looking at
+ *
+ * Record the parameter values for the Actor carried in a received lacpdu as
+ * the current partner operational parameter values and sets
+ * actor_oper_port_state.defaulted to FALSE.
+ */
+static void __record_pdu(struct lacpdu *lacpdu, struct port *port)
+{
+	if (lacpdu && port) {
+		struct port_params *partner = &port->partner_oper;
+
+		__choose_matched(lacpdu, port);
+		/* record the new parameter values for the partner
+		 * operational
+		 */
+		partner->port_number = ntohs(lacpdu->actor_port);
+		partner->port_priority = ntohs(lacpdu->actor_port_priority);
+		partner->system = lacpdu->actor_system;
+		partner->system_priority = ntohs(lacpdu->actor_system_priority);
+		partner->key = ntohs(lacpdu->actor_key);
+		partner->port_state = lacpdu->actor_state;
+
+		/* set actor_oper_port_state.defaulted to FALSE */
+		port->actor_oper_port_state &= ~AD_STATE_DEFAULTED;
+
+		/* set the partner sync. to on if the partner is sync,
+		 * and the port is matched
+		 */
+		if ((port->sm_vars & AD_PORT_MATCHED) &&
+		    (lacpdu->actor_state & AD_STATE_SYNCHRONIZATION)) {
+			partner->port_state |= AD_STATE_SYNCHRONIZATION;
+			pr_debug("%s partner sync=1\n", port->slave->dev->name);
+		} else {
+			partner->port_state &= ~AD_STATE_SYNCHRONIZATION;
+			pr_debug("%s partner sync=0\n", port->slave->dev->name);
+		}
+	}
+}
+
+/**
+ * __record_default - record default parameters
+ * @port: the port we're looking at
+ *
+ * This function records the default parameter values for the partner carried
+ * in the Partner Admin parameters as the current partner operational parameter
+ * values and sets actor_oper_port_state.defaulted to TRUE.
+ */
+static void __record_default(struct port *port)
+{
+	if (port) {
+		/* record the partner admin parameters */
+		memcpy(&port->partner_oper, &port->partner_admin,
+		       sizeof(struct port_params));
+
+		/* set actor_oper_port_state.defaulted to true */
+		port->actor_oper_port_state |= AD_STATE_DEFAULTED;
+	}
+}
+
+/**
+ * __update_selected - update a port's Selected variable from a received lacpdu
+ * @lacpdu: the lacpdu we've received
+ * @port: the port we're looking at
+ *
+ * Update the value of the selected variable, using parameter values from a
+ * newly received lacpdu. The parameter values for the Actor carried in the
+ * received PDU are compared with the corresponding operational parameter
+ * values for the ports partner. If one or more of the comparisons shows that
+ * the value(s) received in the PDU differ from the current operational values,
+ * then selected is set to FALSE and actor_oper_port_state.synchronization is
+ * set to out_of_sync. Otherwise, selected remains unchanged.
+ */
+static void __update_selected(struct lacpdu *lacpdu, struct port *port)
+{
+	if (lacpdu && port) {
+		const struct port_params *partner = &port->partner_oper;
+
+		/* check if any parameter is different then
+		 * update the state machine selected variable.
+		 */
+		if (ntohs(lacpdu->actor_port) != partner->port_number ||
+		    ntohs(lacpdu->actor_port_priority) != partner->port_priority ||
+		    !MAC_ADDRESS_EQUAL(&lacpdu->actor_system, &partner->system) ||
+		    ntohs(lacpdu->actor_system_priority) != partner->system_priority ||
+		    ntohs(lacpdu->actor_key) != partner->key ||
+		    (lacpdu->actor_state & AD_STATE_AGGREGATION) != (partner->port_state & AD_STATE_AGGREGATION)) {
+			port->sm_vars &= ~AD_PORT_SELECTED;
+		}
+	}
+}
+
+/**
+ * __update_default_selected - update a port's Selected variable from Partner
+ * @port: the port we're looking at
+ *
+ * This function updates the value of the selected variable, using the partner
+ * administrative parameter values. The administrative values are compared with
+ * the corresponding operational parameter values for the partner. If one or
+ * more of the comparisons shows that the administrative value(s) differ from
+ * the current operational values, then Selected is set to FALSE and
+ * actor_oper_port_state.synchronization is set to OUT_OF_SYNC. Otherwise,
+ * Selected remains unchanged.
+ */
+static void __update_default_selected(struct port *port)
+{
+	if (port) {
+		const struct port_params *admin = &port->partner_admin;
+		const struct port_params *oper = &port->partner_oper;
+
+		/* check if any parameter is different then
+		 * update the state machine selected variable.
+		 */
+		if (admin->port_number != oper->port_number ||
+		    admin->port_priority != oper->port_priority ||
+		    !MAC_ADDRESS_EQUAL(&admin->system, &oper->system) ||
+		    admin->system_priority != oper->system_priority ||
+		    admin->key != oper->key ||
+		    (admin->port_state & AD_STATE_AGGREGATION)
+			!= (oper->port_state & AD_STATE_AGGREGATION)) {
+			port->sm_vars &= ~AD_PORT_SELECTED;
+		}
+	}
+}
+
+/**
+ * __update_ntt - update a port's ntt variable from a received lacpdu
+ * @lacpdu: the lacpdu we've received
+ * @port: the port we're looking at
+ *
+ * Updates the value of the ntt variable, using parameter values from a newly
+ * received lacpdu. The parameter values for the partner carried in the
+ * received PDU are compared with the corresponding operational parameter
+ * values for the Actor. If one or more of the comparisons shows that the
+ * value(s) received in the PDU differ from the current operational values,
+ * then ntt is set to TRUE. Otherwise, ntt remains unchanged.
+ */
+static void __update_ntt(struct lacpdu *lacpdu, struct port *port)
+{
+	/* validate lacpdu and port */
+	if (lacpdu && port) {
+		/* check if any parameter is different then
+		 * update the port->ntt.
+		 */
+		if ((ntohs(lacpdu->partner_port) != port->actor_port_number) ||
+		    (ntohs(lacpdu->partner_port_priority) != port->actor_port_priority) ||
+		    !MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) ||
+		    (ntohs(lacpdu->partner_system_priority) != port->actor_system_priority) ||
+		    (ntohs(lacpdu->partner_key) != port->actor_oper_port_key) ||
+		    ((lacpdu->partner_state & AD_STATE_LACP_ACTIVITY) != (port->actor_oper_port_state & AD_STATE_LACP_ACTIVITY)) ||
+		    ((lacpdu->partner_state & AD_STATE_LACP_TIMEOUT) != (port->actor_oper_port_state & AD_STATE_LACP_TIMEOUT)) ||
+		    ((lacpdu->partner_state & AD_STATE_SYNCHRONIZATION) != (port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION)) ||
+		    ((lacpdu->partner_state & AD_STATE_AGGREGATION) != (port->actor_oper_port_state & AD_STATE_AGGREGATION))
+		   ) {
+			port->ntt = true;
+		}
+	}
+}
+
+/**
+ * __agg_ports_are_ready - check if all ports in an aggregator are ready
+ * @aggregator: the aggregator we're looking at
+ *
+ */
+static int __agg_ports_are_ready(struct aggregator *aggregator)
+{
+	struct port *port;
+	int retval = 1;
+
+	if (aggregator) {
+		/* scan all ports in this aggregator to verfy if they are
+		 * all ready.
+		 */
+		for (port = aggregator->lag_ports;
+		     port;
+		     port = port->next_port_in_aggregator) {
+			if (!(port->sm_vars & AD_PORT_READY_N)) {
+				retval = 0;
+				break;
+			}
+		}
+	}
+
+	return retval;
+}
+
+/**
+ * __set_agg_ports_ready - set value of Ready bit in all ports of an aggregator
+ * @aggregator: the aggregator we're looking at
+ * @val: Should the ports' ready bit be set on or off
+ *
+ */
+static void __set_agg_ports_ready(struct aggregator *aggregator, int val)
+{
+	struct port *port;
+
+	for (port = aggregator->lag_ports; port;
+	     port = port->next_port_in_aggregator) {
+		if (val)
+			port->sm_vars |= AD_PORT_READY;
+		else
+			port->sm_vars &= ~AD_PORT_READY;
+	}
+}
+
+static int __agg_active_ports(struct aggregator *agg)
+{
+	struct port *port;
+	int active = 0;
+
+	for (port = agg->lag_ports; port;
+	     port = port->next_port_in_aggregator) {
+		if (port->is_enabled)
+			active++;
+	}
+
+	return active;
+}
+
+/**
+ * __get_agg_bandwidth - get the total bandwidth of an aggregator
+ * @aggregator: the aggregator we're looking at
+ *
+ */
+static u32 __get_agg_bandwidth(struct aggregator *aggregator)
+{
+	int nports = __agg_active_ports(aggregator);
+	u32 bandwidth = 0;
+
+	if (nports) {
+		switch (__get_link_speed(aggregator->lag_ports)) {
+		case AD_LINK_SPEED_1MBPS:
+			bandwidth = nports;
+			break;
+		case AD_LINK_SPEED_10MBPS:
+			bandwidth = nports * 10;
+			break;
+		case AD_LINK_SPEED_100MBPS:
+			bandwidth = nports * 100;
+			break;
+		case AD_LINK_SPEED_1000MBPS:
+			bandwidth = nports * 1000;
+			break;
+		case AD_LINK_SPEED_2500MBPS:
+			bandwidth = nports * 2500;
+			break;
+		case AD_LINK_SPEED_5000MBPS:
+			bandwidth = nports * 5000;
+			break;
+		case AD_LINK_SPEED_10000MBPS:
+			bandwidth = nports * 10000;
+			break;
+		case AD_LINK_SPEED_14000MBPS:
+			bandwidth = nports * 14000;
+			break;
+		case AD_LINK_SPEED_20000MBPS:
+			bandwidth = nports * 20000;
+			break;
+		case AD_LINK_SPEED_25000MBPS:
+			bandwidth = nports * 25000;
+			break;
+		case AD_LINK_SPEED_40000MBPS:
+			bandwidth = nports * 40000;
+			break;
+		case AD_LINK_SPEED_50000MBPS:
+			bandwidth = nports * 50000;
+			break;
+		case AD_LINK_SPEED_56000MBPS:
+			bandwidth = nports * 56000;
+			break;
+		case AD_LINK_SPEED_100000MBPS:
+			bandwidth = nports * 100000;
+			break;
+		default:
+			bandwidth = 0; /* to silence the compiler */
+		}
+	}
+	return bandwidth;
+}
+
+/**
+ * __get_active_agg - get the current active aggregator
+ * @aggregator: the aggregator we're looking at
+ *
+ * Caller must hold RCU lock.
+ */
+static struct aggregator *__get_active_agg(struct aggregator *aggregator)
+{
+	struct bonding *bond = aggregator->slave->bond;
+	struct list_head *iter;
+	struct slave *slave;
+
+	bond_for_each_slave_rcu(bond, slave, iter)
+		if (SLAVE_AD_INFO(slave)->aggregator.is_active)
+			return &(SLAVE_AD_INFO(slave)->aggregator);
+
+	return NULL;
+}
+
+/**
+ * __update_lacpdu_from_port - update a port's lacpdu fields
+ * @port: the port we're looking at
+ */
+static inline void __update_lacpdu_from_port(struct port *port)
+{
+	struct lacpdu *lacpdu = &port->lacpdu;
+	const struct port_params *partner = &port->partner_oper;
+
+	/* update current actual Actor parameters
+	 * lacpdu->subtype                   initialized
+	 * lacpdu->version_number            initialized
+	 * lacpdu->tlv_type_actor_info       initialized
+	 * lacpdu->actor_information_length  initialized
+	 */
+
+	lacpdu->actor_system_priority = htons(port->actor_system_priority);
+	lacpdu->actor_system = port->actor_system;
+	lacpdu->actor_key = htons(port->actor_oper_port_key);
+	lacpdu->actor_port_priority = htons(port->actor_port_priority);
+	lacpdu->actor_port = htons(port->actor_port_number);
+	lacpdu->actor_state = port->actor_oper_port_state;
+	pr_debug("update lacpdu: %s, actor port state %x\n",
+		 port->slave->dev->name, port->actor_oper_port_state);
+
+	/* lacpdu->reserved_3_1              initialized
+	 * lacpdu->tlv_type_partner_info     initialized
+	 * lacpdu->partner_information_length initialized
+	 */
+
+	lacpdu->partner_system_priority = htons(partner->system_priority);
+	lacpdu->partner_system = partner->system;
+	lacpdu->partner_key = htons(partner->key);
+	lacpdu->partner_port_priority = htons(partner->port_priority);
+	lacpdu->partner_port = htons(partner->port_number);
+	lacpdu->partner_state = partner->port_state;
+
+	/* lacpdu->reserved_3_2              initialized
+	 * lacpdu->tlv_type_collector_info   initialized
+	 * lacpdu->collector_information_length initialized
+	 * collector_max_delay                initialized
+	 * reserved_12[12]                   initialized
+	 * tlv_type_terminator               initialized
+	 * terminator_length                 initialized
+	 * reserved_50[50]                   initialized
+	 */
+}
+
+/* ================= main 802.3ad protocol code ========================= */
+
+/**
+ * ad_lacpdu_send - send out a lacpdu packet on a given port
+ * @port: the port we're looking at
+ *
+ * Returns:   0 on success
+ *          < 0 on error
+ */
+static int ad_lacpdu_send(struct port *port)
+{
+	struct slave *slave = port->slave;
+	struct sk_buff *skb;
+	struct lacpdu_header *lacpdu_header;
+	int length = sizeof(struct lacpdu_header);
+
+	skb = dev_alloc_skb(length);
+	if (!skb)
+		return -ENOMEM;
+
+	skb->dev = slave->dev;
+	skb_reset_mac_header(skb);
+	skb->network_header = skb->mac_header + ETH_HLEN;
+	skb->protocol = PKT_TYPE_LACPDU;
+	skb->priority = TC_PRIO_CONTROL;
+
+	lacpdu_header = skb_put(skb, length);
+
+	ether_addr_copy(lacpdu_header->hdr.h_dest, lacpdu_mcast_addr);
+	/* Note: source address is set to be the member's PERMANENT address,
+	 * because we use it to identify loopback lacpdus in receive.
+	 */
+	ether_addr_copy(lacpdu_header->hdr.h_source, slave->perm_hwaddr);
+	lacpdu_header->hdr.h_proto = PKT_TYPE_LACPDU;
+
+	lacpdu_header->lacpdu = port->lacpdu;
+
+	dev_queue_xmit(skb);
+
+	return 0;
+}
+
+/**
+ * ad_marker_send - send marker information/response on a given port
+ * @port: the port we're looking at
+ * @marker: marker data to send
+ *
+ * Returns:   0 on success
+ *          < 0 on error
+ */
+static int ad_marker_send(struct port *port, struct bond_marker *marker)
+{
+	struct slave *slave = port->slave;
+	struct sk_buff *skb;
+	struct bond_marker_header *marker_header;
+	int length = sizeof(struct bond_marker_header);
+
+	skb = dev_alloc_skb(length + 16);
+	if (!skb)
+		return -ENOMEM;
+
+	skb_reserve(skb, 16);
+
+	skb->dev = slave->dev;
+	skb_reset_mac_header(skb);
+	skb->network_header = skb->mac_header + ETH_HLEN;
+	skb->protocol = PKT_TYPE_LACPDU;
+
+	marker_header = skb_put(skb, length);
+
+	ether_addr_copy(marker_header->hdr.h_dest, lacpdu_mcast_addr);
+	/* Note: source address is set to be the member's PERMANENT address,
+	 * because we use it to identify loopback MARKERs in receive.
+	 */
+	ether_addr_copy(marker_header->hdr.h_source, slave->perm_hwaddr);
+	marker_header->hdr.h_proto = PKT_TYPE_LACPDU;
+
+	marker_header->marker = *marker;
+
+	dev_queue_xmit(skb);
+
+	return 0;
+}
+
+/**
+ * ad_mux_machine - handle a port's mux state machine
+ * @port: the port we're looking at
+ * @update_slave_arr: Does slave array need update?
+ */
+static void ad_mux_machine(struct port *port, bool *update_slave_arr)
+{
+	mux_states_t last_state;
+
+	/* keep current State Machine state to compare later if it was
+	 * changed
+	 */
+	last_state = port->sm_mux_state;
+
+	if (port->sm_vars & AD_PORT_BEGIN) {
+		port->sm_mux_state = AD_MUX_DETACHED;
+	} else {
+		switch (port->sm_mux_state) {
+		case AD_MUX_DETACHED:
+			if ((port->sm_vars & AD_PORT_SELECTED)
+			    || (port->sm_vars & AD_PORT_STANDBY))
+				/* if SELECTED or STANDBY */
+				port->sm_mux_state = AD_MUX_WAITING;
+			break;
+		case AD_MUX_WAITING:
+			/* if SELECTED == FALSE return to DETACH state */
+			if (!(port->sm_vars & AD_PORT_SELECTED)) {
+				port->sm_vars &= ~AD_PORT_READY_N;
+				/* in order to withhold the Selection Logic to
+				 * check all ports READY_N value every callback
+				 * cycle to update ready variable, we check
+				 * READY_N and update READY here
+				 */
+				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
+				port->sm_mux_state = AD_MUX_DETACHED;
+				break;
+			}
+
+			/* check if the wait_while_timer expired */
+			if (port->sm_mux_timer_counter
+			    && !(--port->sm_mux_timer_counter))
+				port->sm_vars |= AD_PORT_READY_N;
+
+			/* in order to withhold the selection logic to check
+			 * all ports READY_N value every callback cycle to
+			 * update ready variable, we check READY_N and update
+			 * READY here
+			 */
+			__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
+
+			/* if the wait_while_timer expired, and the port is
+			 * in READY state, move to ATTACHED state
+			 */
+			if ((port->sm_vars & AD_PORT_READY)
+			    && !port->sm_mux_timer_counter)
+				port->sm_mux_state = AD_MUX_ATTACHED;
+			break;
+		case AD_MUX_ATTACHED:
+			/* check also if agg_select_timer expired (so the
+			 * edable port will take place only after this timer)
+			 */
+			if ((port->sm_vars & AD_PORT_SELECTED) &&
+			    (port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) &&
+			    !__check_agg_selection_timer(port)) {
+				if (port->aggregator->is_active)
+					port->sm_mux_state =
+					    AD_MUX_COLLECTING_DISTRIBUTING;
+			} else if (!(port->sm_vars & AD_PORT_SELECTED) ||
+				   (port->sm_vars & AD_PORT_STANDBY)) {
+				/* if UNSELECTED or STANDBY */
+				port->sm_vars &= ~AD_PORT_READY_N;
+				/* in order to withhold the selection logic to
+				 * check all ports READY_N value every callback
+				 * cycle to update ready variable, we check
+				 * READY_N and update READY here
+				 */
+				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
+				port->sm_mux_state = AD_MUX_DETACHED;
+			} else if (port->aggregator->is_active) {
+				port->actor_oper_port_state |=
+				    AD_STATE_SYNCHRONIZATION;
+			}
+			break;
+		case AD_MUX_COLLECTING_DISTRIBUTING:
+			if (!(port->sm_vars & AD_PORT_SELECTED) ||
+			    (port->sm_vars & AD_PORT_STANDBY) ||
+			    !(port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) ||
+			    !(port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION)) {
+				port->sm_mux_state = AD_MUX_ATTACHED;
+			} else {
+				/* if port state hasn't changed make
+				 * sure that a collecting distributing
+				 * port in an active aggregator is enabled
+				 */
+				if (port->aggregator &&
+				    port->aggregator->is_active &&
+				    !__port_is_enabled(port)) {
+
+					__enable_port(port);
+				}
+			}
+			break;
+		default:
+			break;
+		}
+	}
+
+	/* check if the state machine was changed */
+	if (port->sm_mux_state != last_state) {
+		pr_debug("Mux Machine: Port=%d (%s), Last State=%d, Curr State=%d\n",
+			 port->actor_port_number,
+			 port->slave->dev->name,
+			 last_state,
+			 port->sm_mux_state);
+		switch (port->sm_mux_state) {
+		case AD_MUX_DETACHED:
+			port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
+			ad_disable_collecting_distributing(port,
+							   update_slave_arr);
+			port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
+			port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
+			port->ntt = true;
+			break;
+		case AD_MUX_WAITING:
+			port->sm_mux_timer_counter = __ad_timer_to_ticks(AD_WAIT_WHILE_TIMER, 0);
+			break;
+		case AD_MUX_ATTACHED:
+			if (port->aggregator->is_active)
+				port->actor_oper_port_state |=
+				    AD_STATE_SYNCHRONIZATION;
+			else
+				port->actor_oper_port_state &=
+				    ~AD_STATE_SYNCHRONIZATION;
+			port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
+			port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
+			ad_disable_collecting_distributing(port,
+							   update_slave_arr);
+			port->ntt = true;
+			break;
+		case AD_MUX_COLLECTING_DISTRIBUTING:
+			port->actor_oper_port_state |= AD_STATE_COLLECTING;
+			port->actor_oper_port_state |= AD_STATE_DISTRIBUTING;
+			port->actor_oper_port_state |= AD_STATE_SYNCHRONIZATION;
+			ad_enable_collecting_distributing(port,
+							  update_slave_arr);
+			port->ntt = true;
+			break;
+		default:
+			break;
+		}
+	}
+}
+
+/**
+ * ad_rx_machine - handle a port's rx State Machine
+ * @lacpdu: the lacpdu we've received
+ * @port: the port we're looking at
+ *
+ * If lacpdu arrived, stop previous timer (if exists) and set the next state as
+ * CURRENT. If timer expired set the state machine in the proper state.
+ * In other cases, this function checks if we need to switch to other state.
+ */
+static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port)
+{
+	rx_states_t last_state;
+
+	/* keep current State Machine state to compare later if it was
+	 * changed
+	 */
+	last_state = port->sm_rx_state;
+
+	/* check if state machine should change state */
+
+	/* first, check if port was reinitialized */
+	if (port->sm_vars & AD_PORT_BEGIN) {
+		port->sm_rx_state = AD_RX_INITIALIZE;
+		port->sm_vars |= AD_PORT_CHURNED;
+	/* check if port is not enabled */
+	} else if (!(port->sm_vars & AD_PORT_BEGIN) && !port->is_enabled)
+		port->sm_rx_state = AD_RX_PORT_DISABLED;
+	/* check if new lacpdu arrived */
+	else if (lacpdu && ((port->sm_rx_state == AD_RX_EXPIRED) ||
+		 (port->sm_rx_state == AD_RX_DEFAULTED) ||
+		 (port->sm_rx_state == AD_RX_CURRENT))) {
+		if (port->sm_rx_state != AD_RX_CURRENT)
+			port->sm_vars |= AD_PORT_CHURNED;
+		port->sm_rx_timer_counter = 0;
+		port->sm_rx_state = AD_RX_CURRENT;
+	} else {
+		/* if timer is on, and if it is expired */
+		if (port->sm_rx_timer_counter &&
+		    !(--port->sm_rx_timer_counter)) {
+			switch (port->sm_rx_state) {
+			case AD_RX_EXPIRED:
+				port->sm_rx_state = AD_RX_DEFAULTED;
+				break;
+			case AD_RX_CURRENT:
+				port->sm_rx_state = AD_RX_EXPIRED;
+				break;
+			default:
+				break;
+			}
+		} else {
+			/* if no lacpdu arrived and no timer is on */
+			switch (port->sm_rx_state) {
+			case AD_RX_PORT_DISABLED:
+				if (port->is_enabled &&
+				    (port->sm_vars & AD_PORT_LACP_ENABLED))
+					port->sm_rx_state = AD_RX_EXPIRED;
+				else if (port->is_enabled
+					 && ((port->sm_vars
+					      & AD_PORT_LACP_ENABLED) == 0))
+					port->sm_rx_state = AD_RX_LACP_DISABLED;
+				break;
+			default:
+				break;
+
+			}
+		}
+	}
+
+	/* check if the State machine was changed or new lacpdu arrived */
+	if ((port->sm_rx_state != last_state) || (lacpdu)) {
+		pr_debug("Rx Machine: Port=%d (%s), Last State=%d, Curr State=%d\n",
+			 port->actor_port_number,
+			 port->slave->dev->name,
+			 last_state,
+			 port->sm_rx_state);
+		switch (port->sm_rx_state) {
+		case AD_RX_INITIALIZE:
+			if (!(port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS))
+				port->sm_vars &= ~AD_PORT_LACP_ENABLED;
+			else
+				port->sm_vars |= AD_PORT_LACP_ENABLED;
+			port->sm_vars &= ~AD_PORT_SELECTED;
+			__record_default(port);
+			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
+			port->sm_rx_state = AD_RX_PORT_DISABLED;
+
+			/* Fall Through */
+		case AD_RX_PORT_DISABLED:
+			port->sm_vars &= ~AD_PORT_MATCHED;
+			break;
+		case AD_RX_LACP_DISABLED:
+			port->sm_vars &= ~AD_PORT_SELECTED;
+			__record_default(port);
+			port->partner_oper.port_state &= ~AD_STATE_AGGREGATION;
+			port->sm_vars |= AD_PORT_MATCHED;
+			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
+			break;
+		case AD_RX_EXPIRED:
+			/* Reset of the Synchronization flag (Standard 43.4.12)
+			 * This reset cause to disable this port in the
+			 * COLLECTING_DISTRIBUTING state of the mux machine in
+			 * case of EXPIRED even if LINK_DOWN didn't arrive for
+			 * the port.
+			 */
+			port->partner_oper.port_state &= ~AD_STATE_SYNCHRONIZATION;
+			port->sm_vars &= ~AD_PORT_MATCHED;
+			port->partner_oper.port_state |= AD_STATE_LACP_TIMEOUT;
+			port->partner_oper.port_state |= AD_STATE_LACP_ACTIVITY;
+			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(AD_SHORT_TIMEOUT));
+			port->actor_oper_port_state |= AD_STATE_EXPIRED;
+			port->sm_vars |= AD_PORT_CHURNED;
+			break;
+		case AD_RX_DEFAULTED:
+			__update_default_selected(port);
+			__record_default(port);
+			port->sm_vars |= AD_PORT_MATCHED;
+			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
+			break;
+		case AD_RX_CURRENT:
+			/* detect loopback situation */
+			if (MAC_ADDRESS_EQUAL(&(lacpdu->actor_system),
+					      &(port->actor_system))) {
+				netdev_err(port->slave->bond->dev, "An illegal loopback occurred on adapter (%s)\n"
+				       "Check the configuration to verify that all adapters are connected to 802.3ad compliant switch ports\n",
+				       port->slave->dev->name);
+				return;
+			}
+			__update_selected(lacpdu, port);
+			__update_ntt(lacpdu, port);
+			__record_pdu(lacpdu, port);
+			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(port->actor_oper_port_state & AD_STATE_LACP_TIMEOUT));
+			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
+			break;
+		default:
+			break;
+		}
+	}
+}
+
+/**
+ * ad_churn_machine - handle port churn's state machine
+ * @port: the port we're looking at
+ *
+ */
+static void ad_churn_machine(struct port *port)
+{
+	if (port->sm_vars & AD_PORT_CHURNED) {
+		port->sm_vars &= ~AD_PORT_CHURNED;
+		port->sm_churn_actor_state = AD_CHURN_MONITOR;
+		port->sm_churn_partner_state = AD_CHURN_MONITOR;
+		port->sm_churn_actor_timer_counter =
+			__ad_timer_to_ticks(AD_ACTOR_CHURN_TIMER, 0);
+		 port->sm_churn_partner_timer_counter =
+			 __ad_timer_to_ticks(AD_PARTNER_CHURN_TIMER, 0);
+		return;
+	}
+	if (port->sm_churn_actor_timer_counter &&
+	    !(--port->sm_churn_actor_timer_counter) &&
+	    port->sm_churn_actor_state == AD_CHURN_MONITOR) {
+		if (port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION) {
+			port->sm_churn_actor_state = AD_NO_CHURN;
+		} else {
+			port->churn_actor_count++;
+			port->sm_churn_actor_state = AD_CHURN;
+		}
+	}
+	if (port->sm_churn_partner_timer_counter &&
+	    !(--port->sm_churn_partner_timer_counter) &&
+	    port->sm_churn_partner_state == AD_CHURN_MONITOR) {
+		if (port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) {
+			port->sm_churn_partner_state = AD_NO_CHURN;
+		} else {
+			port->churn_partner_count++;
+			port->sm_churn_partner_state = AD_CHURN;
+		}
+	}
+}
+
+/**
+ * ad_tx_machine - handle a port's tx state machine
+ * @port: the port we're looking at
+ */
+static void ad_tx_machine(struct port *port)
+{
+	/* check if tx timer expired, to verify that we do not send more than
+	 * 3 packets per second
+	 */
+	if (port->sm_tx_timer_counter && !(--port->sm_tx_timer_counter)) {
+		/* check if there is something to send */
+		if (port->ntt && (port->sm_vars & AD_PORT_LACP_ENABLED)) {
+			__update_lacpdu_from_port(port);
+
+			if (ad_lacpdu_send(port) >= 0) {
+				pr_debug("Sent LACPDU on port %d\n",
+					 port->actor_port_number);
+
+				/* mark ntt as false, so it will not be sent
+				 * again until demanded
+				 */
+				port->ntt = false;
+			}
+		}
+		/* restart tx timer(to verify that we will not exceed
+		 * AD_MAX_TX_IN_SECOND
+		 */
+		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
+	}
+}
+
+/**
+ * ad_periodic_machine - handle a port's periodic state machine
+ * @port: the port we're looking at
+ *
+ * Turn ntt flag on priodically to perform periodic transmission of lacpdu's.
+ */
+static void ad_periodic_machine(struct port *port)
+{
+	periodic_states_t last_state;
+
+	/* keep current state machine state to compare later if it was changed */
+	last_state = port->sm_periodic_state;
+
+	/* check if port was reinitialized */
+	if (((port->sm_vars & AD_PORT_BEGIN) || !(port->sm_vars & AD_PORT_LACP_ENABLED) || !port->is_enabled) ||
+	    (!(port->actor_oper_port_state & AD_STATE_LACP_ACTIVITY) && !(port->partner_oper.port_state & AD_STATE_LACP_ACTIVITY))
+	   ) {
+		port->sm_periodic_state = AD_NO_PERIODIC;
+	}
+	/* check if state machine should change state */
+	else if (port->sm_periodic_timer_counter) {
+		/* check if periodic state machine expired */
+		if (!(--port->sm_periodic_timer_counter)) {
+			/* if expired then do tx */
+			port->sm_periodic_state = AD_PERIODIC_TX;
+		} else {
+			/* If not expired, check if there is some new timeout
+			 * parameter from the partner state
+			 */
+			switch (port->sm_periodic_state) {
+			case AD_FAST_PERIODIC:
+				if (!(port->partner_oper.port_state
+				      & AD_STATE_LACP_TIMEOUT))
+					port->sm_periodic_state = AD_SLOW_PERIODIC;
+				break;
+			case AD_SLOW_PERIODIC:
+				if ((port->partner_oper.port_state & AD_STATE_LACP_TIMEOUT)) {
+					port->sm_periodic_timer_counter = 0;
+					port->sm_periodic_state = AD_PERIODIC_TX;
+				}
+				break;
+			default:
+				break;
+			}
+		}
+	} else {
+		switch (port->sm_periodic_state) {
+		case AD_NO_PERIODIC:
+			port->sm_periodic_state = AD_FAST_PERIODIC;
+			break;
+		case AD_PERIODIC_TX:
+			if (!(port->partner_oper.port_state &
+			    AD_STATE_LACP_TIMEOUT))
+				port->sm_periodic_state = AD_SLOW_PERIODIC;
+			else
+				port->sm_periodic_state = AD_FAST_PERIODIC;
+			break;
+		default:
+			break;
+		}
+	}
+
+	/* check if the state machine was changed */
+	if (port->sm_periodic_state != last_state) {
+		pr_debug("Periodic Machine: Port=%d, Last State=%d, Curr State=%d\n",
+			 port->actor_port_number, last_state,
+			 port->sm_periodic_state);
+		switch (port->sm_periodic_state) {
+		case AD_NO_PERIODIC:
+			port->sm_periodic_timer_counter = 0;
+			break;
+		case AD_FAST_PERIODIC:
+			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
+			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_FAST_PERIODIC_TIME))-1;
+			break;
+		case AD_SLOW_PERIODIC:
+			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
+			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_SLOW_PERIODIC_TIME))-1;
+			break;
+		case AD_PERIODIC_TX:
+			port->ntt = true;
+			break;
+		default:
+			break;
+		}
+	}
+}
+
+/**
+ * ad_port_selection_logic - select aggregation groups
+ * @port: the port we're looking at
+ * @update_slave_arr: Does slave array need update?
+ *
+ * Select aggregation groups, and assign each port for it's aggregetor. The
+ * selection logic is called in the inititalization (after all the handshkes),
+ * and after every lacpdu receive (if selected is off).
+ */
+static void ad_port_selection_logic(struct port *port, bool *update_slave_arr)
+{
+	struct aggregator *aggregator, *free_aggregator = NULL, *temp_aggregator;
+	struct port *last_port = NULL, *curr_port;
+	struct list_head *iter;
+	struct bonding *bond;
+	struct slave *slave;
+	int found = 0;
+
+	/* if the port is already Selected, do nothing */
+	if (port->sm_vars & AD_PORT_SELECTED)
+		return;
+
+	bond = __get_bond_by_port(port);
+
+	/* if the port is connected to other aggregator, detach it */
+	if (port->aggregator) {
+		/* detach the port from its former aggregator */
+		temp_aggregator = port->aggregator;
+		for (curr_port = temp_aggregator->lag_ports; curr_port;
+		     last_port = curr_port,
+		     curr_port = curr_port->next_port_in_aggregator) {
+			if (curr_port == port) {
+				temp_aggregator->num_of_ports--;
+				/* if it is the first port attached to the
+				 * aggregator
+				 */
+				if (!last_port) {
+					temp_aggregator->lag_ports =
+						port->next_port_in_aggregator;
+				} else {
+					/* not the first port attached to the
+					 * aggregator
+					 */
+					last_port->next_port_in_aggregator =
+						port->next_port_in_aggregator;
+				}
+
+				/* clear the port's relations to this
+				 * aggregator
+				 */
+				port->aggregator = NULL;
+				port->next_port_in_aggregator = NULL;
+				port->actor_port_aggregator_identifier = 0;
+
+				netdev_dbg(bond->dev, "Port %d left LAG %d\n",
+					   port->actor_port_number,
+					   temp_aggregator->aggregator_identifier);
+				/* if the aggregator is empty, clear its
+				 * parameters, and set it ready to be attached
+				 */
+				if (!temp_aggregator->lag_ports)
+					ad_clear_agg(temp_aggregator);
+				break;
+			}
+		}
+		if (!curr_port) {
+			/* meaning: the port was related to an aggregator
+			 * but was not on the aggregator port list
+			 */
+			net_warn_ratelimited("%s: Warning: Port %d (on %s) was related to aggregator %d but was not on its port list\n",
+					     port->slave->bond->dev->name,
+					     port->actor_port_number,
+					     port->slave->dev->name,
+					     port->aggregator->aggregator_identifier);
+		}
+	}
+	/* search on all aggregators for a suitable aggregator for this port */
+	bond_for_each_slave(bond, slave, iter) {
+		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
+
+		/* keep a free aggregator for later use(if needed) */
+		if (!aggregator->lag_ports) {
+			if (!free_aggregator)
+				free_aggregator = aggregator;
+			continue;
+		}
+		/* check if current aggregator suits us */
+		if (((aggregator->actor_oper_aggregator_key == port->actor_oper_port_key) && /* if all parameters match AND */
+		     MAC_ADDRESS_EQUAL(&(aggregator->partner_system), &(port->partner_oper.system)) &&
+		     (aggregator->partner_system_priority == port->partner_oper.system_priority) &&
+		     (aggregator->partner_oper_aggregator_key == port->partner_oper.key)
+		    ) &&
+		    ((!MAC_ADDRESS_EQUAL(&(port->partner_oper.system), &(null_mac_addr)) && /* partner answers */
+		      !aggregator->is_individual)  /* but is not individual OR */
+		    )
+		   ) {
+			/* attach to the founded aggregator */
+			port->aggregator = aggregator;
+			port->actor_port_aggregator_identifier =
+				port->aggregator->aggregator_identifier;
+			port->next_port_in_aggregator = aggregator->lag_ports;
+			port->aggregator->num_of_ports++;
+			aggregator->lag_ports = port;
+			netdev_dbg(bond->dev, "Port %d joined LAG %d(existing LAG)\n",
+				   port->actor_port_number,
+				   port->aggregator->aggregator_identifier);
+
+			/* mark this port as selected */
+			port->sm_vars |= AD_PORT_SELECTED;
+			found = 1;
+			break;
+		}
+	}
+
+	/* the port couldn't find an aggregator - attach it to a new
+	 * aggregator
+	 */
+	if (!found) {
+		if (free_aggregator) {
+			/* assign port a new aggregator */
+			port->aggregator = free_aggregator;
+			port->actor_port_aggregator_identifier =
+				port->aggregator->aggregator_identifier;
+
+			/* update the new aggregator's parameters
+			 * if port was responsed from the end-user
+			 */
+			if (port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS)
+				/* if port is full duplex */
+				port->aggregator->is_individual = false;
+			else
+				port->aggregator->is_individual = true;
+
+			port->aggregator->actor_admin_aggregator_key =
+				port->actor_admin_port_key;
+			port->aggregator->actor_oper_aggregator_key =
+				port->actor_oper_port_key;
+			port->aggregator->partner_system =
+				port->partner_oper.system;
+			port->aggregator->partner_system_priority =
+				port->partner_oper.system_priority;
+			port->aggregator->partner_oper_aggregator_key = port->partner_oper.key;
+			port->aggregator->receive_state = 1;
+			port->aggregator->transmit_state = 1;
+			port->aggregator->lag_ports = port;
+			port->aggregator->num_of_ports++;
+
+			/* mark this port as selected */
+			port->sm_vars |= AD_PORT_SELECTED;
+
+			netdev_dbg(bond->dev, "Port %d joined LAG %d(new LAG)\n",
+				   port->actor_port_number,
+				   port->aggregator->aggregator_identifier);
+		} else {
+			netdev_err(bond->dev, "Port %d (on %s) did not find a suitable aggregator\n",
+			       port->actor_port_number, port->slave->dev->name);
+		}
+	}
+	/* if all aggregator's ports are READY_N == TRUE, set ready=TRUE
+	 * in all aggregator's ports, else set ready=FALSE in all
+	 * aggregator's ports
+	 */
+	__set_agg_ports_ready(port->aggregator,
+			      __agg_ports_are_ready(port->aggregator));
+
+	aggregator = __get_first_agg(port);
+	ad_agg_selection_logic(aggregator, update_slave_arr);
+
+	if (!port->aggregator->is_active)
+		port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
+}
+
+/* Decide if "agg" is a better choice for the new active aggregator that
+ * the current best, according to the ad_select policy.
+ */
+static struct aggregator *ad_agg_selection_test(struct aggregator *best,
+						struct aggregator *curr)
+{
+	/* 0. If no best, select current.
+	 *
+	 * 1. If the current agg is not individual, and the best is
+	 *    individual, select current.
+	 *
+	 * 2. If current agg is individual and the best is not, keep best.
+	 *
+	 * 3. Therefore, current and best are both individual or both not
+	 *    individual, so:
+	 *
+	 * 3a. If current agg partner replied, and best agg partner did not,
+	 *     select current.
+	 *
+	 * 3b. If current agg partner did not reply and best agg partner
+	 *     did reply, keep best.
+	 *
+	 * 4.  Therefore, current and best both have partner replies or
+	 *     both do not, so perform selection policy:
+	 *
+	 * BOND_AD_COUNT: Select by count of ports.  If count is equal,
+	 *     select by bandwidth.
+	 *
+	 * BOND_AD_STABLE, BOND_AD_BANDWIDTH: Select by bandwidth.
+	 */
+	if (!best)
+		return curr;
+
+	if (!curr->is_individual && best->is_individual)
+		return curr;
+
+	if (curr->is_individual && !best->is_individual)
+		return best;
+
+	if (__agg_has_partner(curr) && !__agg_has_partner(best))
+		return curr;
+
+	if (!__agg_has_partner(curr) && __agg_has_partner(best))
+		return best;
+
+	switch (__get_agg_selection_mode(curr->lag_ports)) {
+	case BOND_AD_COUNT:
+		if (__agg_active_ports(curr) > __agg_active_ports(best))
+			return curr;
+
+		if (__agg_active_ports(curr) < __agg_active_ports(best))
+			return best;
+
+		/*FALLTHROUGH*/
+	case BOND_AD_STABLE:
+	case BOND_AD_BANDWIDTH:
+		if (__get_agg_bandwidth(curr) > __get_agg_bandwidth(best))
+			return curr;
+
+		break;
+
+	default:
+		net_warn_ratelimited("%s: Impossible agg select mode %d\n",
+				     curr->slave->bond->dev->name,
+				     __get_agg_selection_mode(curr->lag_ports));
+		break;
+	}
+
+	return best;
+}
+
+static int agg_device_up(const struct aggregator *agg)
+{
+	struct port *port = agg->lag_ports;
+
+	if (!port)
+		return 0;
+
+	for (port = agg->lag_ports; port;
+	     port = port->next_port_in_aggregator) {
+		if (netif_running(port->slave->dev) &&
+		    netif_carrier_ok(port->slave->dev))
+			return 1;
+	}
+
+	return 0;
+}
+
+/**
+ * ad_agg_selection_logic - select an aggregation group for a team
+ * @aggregator: the aggregator we're looking at
+ * @update_slave_arr: Does slave array need update?
+ *
+ * It is assumed that only one aggregator may be selected for a team.
+ *
+ * The logic of this function is to select the aggregator according to
+ * the ad_select policy:
+ *
+ * BOND_AD_STABLE: select the aggregator with the most ports attached to
+ * it, and to reselect the active aggregator only if the previous
+ * aggregator has no more ports related to it.
+ *
+ * BOND_AD_BANDWIDTH: select the aggregator with the highest total
+ * bandwidth, and reselect whenever a link state change takes place or the
+ * set of slaves in the bond changes.
+ *
+ * BOND_AD_COUNT: select the aggregator with largest number of ports
+ * (slaves), and reselect whenever a link state change takes place or the
+ * set of slaves in the bond changes.
+ *
+ * FIXME: this function MUST be called with the first agg in the bond, or
+ * __get_active_agg() won't work correctly. This function should be better
+ * called with the bond itself, and retrieve the first agg from it.
+ */
+static void ad_agg_selection_logic(struct aggregator *agg,
+				   bool *update_slave_arr)
+{
+	struct aggregator *best, *active, *origin;
+	struct bonding *bond = agg->slave->bond;
+	struct list_head *iter;
+	struct slave *slave;
+	struct port *port;
+
+	rcu_read_lock();
+	origin = agg;
+	active = __get_active_agg(agg);
+	best = (active && agg_device_up(active)) ? active : NULL;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		agg = &(SLAVE_AD_INFO(slave)->aggregator);
+
+		agg->is_active = 0;
+
+		if (__agg_active_ports(agg) && agg_device_up(agg))
+			best = ad_agg_selection_test(best, agg);
+	}
+
+	if (best &&
+	    __get_agg_selection_mode(best->lag_ports) == BOND_AD_STABLE) {
+		/* For the STABLE policy, don't replace the old active
+		 * aggregator if it's still active (it has an answering
+		 * partner) or if both the best and active don't have an
+		 * answering partner.
+		 */
+		if (active && active->lag_ports &&
+		    __agg_active_ports(active) &&
+		    (__agg_has_partner(active) ||
+		     (!__agg_has_partner(active) &&
+		     !__agg_has_partner(best)))) {
+			if (!(!active->actor_oper_aggregator_key &&
+			      best->actor_oper_aggregator_key)) {
+				best = NULL;
+				active->is_active = 1;
+			}
+		}
+	}
+
+	if (best && (best == active)) {
+		best = NULL;
+		active->is_active = 1;
+	}
+
+	/* if there is new best aggregator, activate it */
+	if (best) {
+		netdev_dbg(bond->dev, "best Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
+			   best->aggregator_identifier, best->num_of_ports,
+			   best->actor_oper_aggregator_key,
+			   best->partner_oper_aggregator_key,
+			   best->is_individual, best->is_active);
+		netdev_dbg(bond->dev, "best ports %p slave %p %s\n",
+			   best->lag_ports, best->slave,
+			   best->slave ? best->slave->dev->name : "NULL");
+
+		bond_for_each_slave_rcu(bond, slave, iter) {
+			agg = &(SLAVE_AD_INFO(slave)->aggregator);
+
+			netdev_dbg(bond->dev, "Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
+				   agg->aggregator_identifier, agg->num_of_ports,
+				   agg->actor_oper_aggregator_key,
+				   agg->partner_oper_aggregator_key,
+				   agg->is_individual, agg->is_active);
+		}
+
+		/* check if any partner replys */
+		if (best->is_individual) {
+			net_warn_ratelimited("%s: Warning: No 802.3ad response from the link partner for any adapters in the bond\n",
+					     best->slave ?
+					     best->slave->bond->dev->name : "NULL");
+		}
+
+		best->is_active = 1;
+		netdev_dbg(bond->dev, "LAG %d chosen as the active LAG\n",
+			   best->aggregator_identifier);
+		netdev_dbg(bond->dev, "Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
+			   best->aggregator_identifier, best->num_of_ports,
+			   best->actor_oper_aggregator_key,
+			   best->partner_oper_aggregator_key,
+			   best->is_individual, best->is_active);
+
+		/* disable the ports that were related to the former
+		 * active_aggregator
+		 */
+		if (active) {
+			for (port = active->lag_ports; port;
+			     port = port->next_port_in_aggregator) {
+				__disable_port(port);
+			}
+		}
+		/* Slave array needs update. */
+		*update_slave_arr = true;
+	}
+
+	/* if the selected aggregator is of join individuals
+	 * (partner_system is NULL), enable their ports
+	 */
+	active = __get_active_agg(origin);
+
+	if (active) {
+		if (!__agg_has_partner(active)) {
+			for (port = active->lag_ports; port;
+			     port = port->next_port_in_aggregator) {
+				__enable_port(port);
+			}
+		}
+	}
+
+	rcu_read_unlock();
+
+	bond_3ad_set_carrier(bond);
+}
+
+/**
+ * ad_clear_agg - clear a given aggregator's parameters
+ * @aggregator: the aggregator we're looking at
+ */
+static void ad_clear_agg(struct aggregator *aggregator)
+{
+	if (aggregator) {
+		aggregator->is_individual = false;
+		aggregator->actor_admin_aggregator_key = 0;
+		aggregator->actor_oper_aggregator_key = 0;
+		eth_zero_addr(aggregator->partner_system.mac_addr_value);
+		aggregator->partner_system_priority = 0;
+		aggregator->partner_oper_aggregator_key = 0;
+		aggregator->receive_state = 0;
+		aggregator->transmit_state = 0;
+		aggregator->lag_ports = NULL;
+		aggregator->is_active = 0;
+		aggregator->num_of_ports = 0;
+		pr_debug("LAG %d was cleared\n",
+			 aggregator->aggregator_identifier);
+	}
+}
+
+/**
+ * ad_initialize_agg - initialize a given aggregator's parameters
+ * @aggregator: the aggregator we're looking at
+ */
+static void ad_initialize_agg(struct aggregator *aggregator)
+{
+	if (aggregator) {
+		ad_clear_agg(aggregator);
+
+		eth_zero_addr(aggregator->aggregator_mac_address.mac_addr_value);
+		aggregator->aggregator_identifier = 0;
+		aggregator->slave = NULL;
+	}
+}
+
+/**
+ * ad_initialize_port - initialize a given port's parameters
+ * @aggregator: the aggregator we're looking at
+ * @lacp_fast: boolean. whether fast periodic should be used
+ */
+static void ad_initialize_port(struct port *port, int lacp_fast)
+{
+	static const struct port_params tmpl = {
+		.system_priority = 0xffff,
+		.key             = 1,
+		.port_number     = 1,
+		.port_priority   = 0xff,
+		.port_state      = 1,
+	};
+	static const struct lacpdu lacpdu = {
+		.subtype		= 0x01,
+		.version_number = 0x01,
+		.tlv_type_actor_info = 0x01,
+		.actor_information_length = 0x14,
+		.tlv_type_partner_info = 0x02,
+		.partner_information_length = 0x14,
+		.tlv_type_collector_info = 0x03,
+		.collector_information_length = 0x10,
+		.collector_max_delay = htons(AD_COLLECTOR_MAX_DELAY),
+	};
+
+	if (port) {
+		port->actor_port_priority = 0xff;
+		port->actor_port_aggregator_identifier = 0;
+		port->ntt = false;
+		port->actor_admin_port_state = AD_STATE_AGGREGATION |
+					       AD_STATE_LACP_ACTIVITY;
+		port->actor_oper_port_state  = AD_STATE_AGGREGATION |
+					       AD_STATE_LACP_ACTIVITY;
+
+		if (lacp_fast)
+			port->actor_oper_port_state |= AD_STATE_LACP_TIMEOUT;
+
+		memcpy(&port->partner_admin, &tmpl, sizeof(tmpl));
+		memcpy(&port->partner_oper, &tmpl, sizeof(tmpl));
+
+		port->is_enabled = true;
+		/* private parameters */
+		port->sm_vars = AD_PORT_BEGIN | AD_PORT_LACP_ENABLED;
+		port->sm_rx_state = 0;
+		port->sm_rx_timer_counter = 0;
+		port->sm_periodic_state = 0;
+		port->sm_periodic_timer_counter = 0;
+		port->sm_mux_state = 0;
+		port->sm_mux_timer_counter = 0;
+		port->sm_tx_state = 0;
+		port->aggregator = NULL;
+		port->next_port_in_aggregator = NULL;
+		port->transaction_id = 0;
+
+		port->sm_churn_actor_timer_counter = 0;
+		port->sm_churn_actor_state = 0;
+		port->churn_actor_count = 0;
+		port->sm_churn_partner_timer_counter = 0;
+		port->sm_churn_partner_state = 0;
+		port->churn_partner_count = 0;
+
+		memcpy(&port->lacpdu, &lacpdu, sizeof(lacpdu));
+	}
+}
+
+/**
+ * ad_enable_collecting_distributing - enable a port's transmit/receive
+ * @port: the port we're looking at
+ * @update_slave_arr: Does slave array need update?
+ *
+ * Enable @port if it's in an active aggregator
+ */
+static void ad_enable_collecting_distributing(struct port *port,
+					      bool *update_slave_arr)
+{
+	if (port->aggregator->is_active) {
+		pr_debug("Enabling port %d(LAG %d)\n",
+			 port->actor_port_number,
+			 port->aggregator->aggregator_identifier);
+		__enable_port(port);
+		/* Slave array needs update */
+		*update_slave_arr = true;
+	}
+}
+
+/**
+ * ad_disable_collecting_distributing - disable a port's transmit/receive
+ * @port: the port we're looking at
+ * @update_slave_arr: Does slave array need update?
+ */
+static void ad_disable_collecting_distributing(struct port *port,
+					       bool *update_slave_arr)
+{
+	if (port->aggregator &&
+	    !MAC_ADDRESS_EQUAL(&(port->aggregator->partner_system),
+			       &(null_mac_addr))) {
+		pr_debug("Disabling port %d(LAG %d)\n",
+			 port->actor_port_number,
+			 port->aggregator->aggregator_identifier);
+		__disable_port(port);
+		/* Slave array needs an update */
+		*update_slave_arr = true;
+	}
+}
+
+/**
+ * ad_marker_info_received - handle receive of a Marker information frame
+ * @marker_info: Marker info received
+ * @port: the port we're looking at
+ */
+static void ad_marker_info_received(struct bond_marker *marker_info,
+	struct port *port)
+{
+	struct bond_marker marker;
+
+	/* copy the received marker data to the response marker */
+	memcpy(&marker, marker_info, sizeof(struct bond_marker));
+	/* change the marker subtype to marker response */
+	marker.tlv_type = AD_MARKER_RESPONSE_SUBTYPE;
+
+	/* send the marker response */
+	if (ad_marker_send(port, &marker) >= 0) {
+		pr_debug("Sent Marker Response on port %d\n",
+			 port->actor_port_number);
+	}
+}
+
+/**
+ * ad_marker_response_received - handle receive of a marker response frame
+ * @marker: marker PDU received
+ * @port: the port we're looking at
+ *
+ * This function does nothing since we decided not to implement send and handle
+ * response for marker PDU's, in this stage, but only to respond to marker
+ * information.
+ */
+static void ad_marker_response_received(struct bond_marker *marker,
+					struct port *port)
+{
+	/* DO NOTHING, SINCE WE DECIDED NOT TO IMPLEMENT THIS FEATURE FOR NOW */
+}
+
+/* ========= AD exported functions to the main bonding code ========= */
+
+/* Check aggregators status in team every T seconds */
+#define AD_AGGREGATOR_SELECTION_TIMER  8
+
+/**
+ * bond_3ad_initiate_agg_selection - initate aggregator selection
+ * @bond: bonding struct
+ *
+ * Set the aggregation selection timer, to initiate an agg selection in
+ * the very near future.  Called during first initialization, and during
+ * any down to up transitions of the bond.
+ */
+void bond_3ad_initiate_agg_selection(struct bonding *bond, int timeout)
+{
+	BOND_AD_INFO(bond).agg_select_timer = timeout;
+}
+
+/**
+ * bond_3ad_initialize - initialize a bond's 802.3ad parameters and structures
+ * @bond: bonding struct to work on
+ * @tick_resolution: tick duration (millisecond resolution)
+ *
+ * Can be called only after the mac address of the bond is set.
+ */
+void bond_3ad_initialize(struct bonding *bond, u16 tick_resolution)
+{
+	/* check that the bond is not initialized yet */
+	if (!MAC_ADDRESS_EQUAL(&(BOND_AD_INFO(bond).system.sys_mac_addr),
+				bond->dev->dev_addr)) {
+
+		BOND_AD_INFO(bond).aggregator_identifier = 0;
+
+		BOND_AD_INFO(bond).system.sys_priority =
+			bond->params.ad_actor_sys_prio;
+		if (is_zero_ether_addr(bond->params.ad_actor_system))
+			BOND_AD_INFO(bond).system.sys_mac_addr =
+			    *((struct mac_addr *)bond->dev->dev_addr);
+		else
+			BOND_AD_INFO(bond).system.sys_mac_addr =
+			    *((struct mac_addr *)bond->params.ad_actor_system);
+
+		/* initialize how many times this module is called in one
+		 * second (should be about every 100ms)
+		 */
+		ad_ticks_per_sec = tick_resolution;
+
+		bond_3ad_initiate_agg_selection(bond,
+						AD_AGGREGATOR_SELECTION_TIMER *
+						ad_ticks_per_sec);
+	}
+}
+
+/**
+ * bond_3ad_bind_slave - initialize a slave's port
+ * @slave: slave struct to work on
+ *
+ * Returns:   0 on success
+ *          < 0 on error
+ */
+void bond_3ad_bind_slave(struct slave *slave)
+{
+	struct bonding *bond = bond_get_bond_by_slave(slave);
+	struct port *port;
+	struct aggregator *aggregator;
+
+	/* check that the slave has not been initialized yet. */
+	if (SLAVE_AD_INFO(slave)->port.slave != slave) {
+
+		/* port initialization */
+		port = &(SLAVE_AD_INFO(slave)->port);
+
+		ad_initialize_port(port, bond->params.lacp_fast);
+
+		port->slave = slave;
+		port->actor_port_number = SLAVE_AD_INFO(slave)->id;
+		/* key is determined according to the link speed, duplex and
+		 * user key
+		 */
+		port->actor_admin_port_key = bond->params.ad_user_port_key << 6;
+		ad_update_actor_keys(port, false);
+		/* actor system is the bond's system */
+		__ad_actor_update_port(port);
+		/* tx timer(to verify that no more than MAX_TX_IN_SECOND
+		 * lacpdu's are sent in one second)
+		 */
+		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
+
+		__disable_port(port);
+
+		/* aggregator initialization */
+		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
+
+		ad_initialize_agg(aggregator);
+
+		aggregator->aggregator_mac_address = *((struct mac_addr *)bond->dev->dev_addr);
+		aggregator->aggregator_identifier = ++BOND_AD_INFO(bond).aggregator_identifier;
+		aggregator->slave = slave;
+		aggregator->is_active = 0;
+		aggregator->num_of_ports = 0;
+	}
+}
+
+/**
+ * bond_3ad_unbind_slave - deinitialize a slave's port
+ * @slave: slave struct to work on
+ *
+ * Search for the aggregator that is related to this port, remove the
+ * aggregator and assign another aggregator for other port related to it
+ * (if any), and remove the port.
+ */
+void bond_3ad_unbind_slave(struct slave *slave)
+{
+	struct port *port, *prev_port, *temp_port;
+	struct aggregator *aggregator, *new_aggregator, *temp_aggregator;
+	int select_new_active_agg = 0;
+	struct bonding *bond = slave->bond;
+	struct slave *slave_iter;
+	struct list_head *iter;
+	bool dummy_slave_update; /* Ignore this value as caller updates array */
+
+	/* Sync against bond_3ad_state_machine_handler() */
+	spin_lock_bh(&bond->mode_lock);
+	aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
+	port = &(SLAVE_AD_INFO(slave)->port);
+
+	/* if slave is null, the whole port is not initialized */
+	if (!port->slave) {
+		netdev_warn(bond->dev, "Trying to unbind an uninitialized port on %s\n",
+			    slave->dev->name);
+		goto out;
+	}
+
+	netdev_dbg(bond->dev, "Unbinding Link Aggregation Group %d\n",
+		   aggregator->aggregator_identifier);
+
+	/* Tell the partner that this port is not suitable for aggregation */
+	port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
+	port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
+	port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
+	port->actor_oper_port_state &= ~AD_STATE_AGGREGATION;
+	__update_lacpdu_from_port(port);
+	ad_lacpdu_send(port);
+
+	/* check if this aggregator is occupied */
+	if (aggregator->lag_ports) {
+		/* check if there are other ports related to this aggregator
+		 * except the port related to this slave(thats ensure us that
+		 * there is a reason to search for new aggregator, and that we
+		 * will find one
+		 */
+		if ((aggregator->lag_ports != port) ||
+		    (aggregator->lag_ports->next_port_in_aggregator)) {
+			/* find new aggregator for the related port(s) */
+			bond_for_each_slave(bond, slave_iter, iter) {
+				new_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
+				/* if the new aggregator is empty, or it is
+				 * connected to our port only
+				 */
+				if (!new_aggregator->lag_ports ||
+				    ((new_aggregator->lag_ports == port) &&
+				     !new_aggregator->lag_ports->next_port_in_aggregator))
+					break;
+			}
+			if (!slave_iter)
+				new_aggregator = NULL;
+
+			/* if new aggregator found, copy the aggregator's
+			 * parameters and connect the related lag_ports to the
+			 * new aggregator
+			 */
+			if ((new_aggregator) && ((!new_aggregator->lag_ports) || ((new_aggregator->lag_ports == port) && !new_aggregator->lag_ports->next_port_in_aggregator))) {
+				netdev_dbg(bond->dev, "Some port(s) related to LAG %d - replacing with LAG %d\n",
+					   aggregator->aggregator_identifier,
+					   new_aggregator->aggregator_identifier);
+
+				if ((new_aggregator->lag_ports == port) &&
+				    new_aggregator->is_active) {
+					netdev_info(bond->dev, "Removing an active aggregator\n");
+					 select_new_active_agg = 1;
+				}
+
+				new_aggregator->is_individual = aggregator->is_individual;
+				new_aggregator->actor_admin_aggregator_key = aggregator->actor_admin_aggregator_key;
+				new_aggregator->actor_oper_aggregator_key = aggregator->actor_oper_aggregator_key;
+				new_aggregator->partner_system = aggregator->partner_system;
+				new_aggregator->partner_system_priority = aggregator->partner_system_priority;
+				new_aggregator->partner_oper_aggregator_key = aggregator->partner_oper_aggregator_key;
+				new_aggregator->receive_state = aggregator->receive_state;
+				new_aggregator->transmit_state = aggregator->transmit_state;
+				new_aggregator->lag_ports = aggregator->lag_ports;
+				new_aggregator->is_active = aggregator->is_active;
+				new_aggregator->num_of_ports = aggregator->num_of_ports;
+
+				/* update the information that is written on
+				 * the ports about the aggregator
+				 */
+				for (temp_port = aggregator->lag_ports; temp_port;
+				     temp_port = temp_port->next_port_in_aggregator) {
+					temp_port->aggregator = new_aggregator;
+					temp_port->actor_port_aggregator_identifier = new_aggregator->aggregator_identifier;
+				}
+
+				ad_clear_agg(aggregator);
+
+				if (select_new_active_agg)
+					ad_agg_selection_logic(__get_first_agg(port),
+							       &dummy_slave_update);
+			} else {
+				netdev_warn(bond->dev, "unbinding aggregator, and could not find a new aggregator for its ports\n");
+			}
+		} else {
+			/* in case that the only port related to this
+			 * aggregator is the one we want to remove
+			 */
+			select_new_active_agg = aggregator->is_active;
+			ad_clear_agg(aggregator);
+			if (select_new_active_agg) {
+				netdev_info(bond->dev, "Removing an active aggregator\n");
+				/* select new active aggregator */
+				temp_aggregator = __get_first_agg(port);
+				if (temp_aggregator)
+					ad_agg_selection_logic(temp_aggregator,
+							       &dummy_slave_update);
+			}
+		}
+	}
+
+	netdev_dbg(bond->dev, "Unbinding port %d\n", port->actor_port_number);
+
+	/* find the aggregator that this port is connected to */
+	bond_for_each_slave(bond, slave_iter, iter) {
+		temp_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
+		prev_port = NULL;
+		/* search the port in the aggregator's related ports */
+		for (temp_port = temp_aggregator->lag_ports; temp_port;
+		     prev_port = temp_port,
+		     temp_port = temp_port->next_port_in_aggregator) {
+			if (temp_port == port) {
+				/* the aggregator found - detach the port from
+				 * this aggregator
+				 */
+				if (prev_port)
+					prev_port->next_port_in_aggregator = temp_port->next_port_in_aggregator;
+				else
+					temp_aggregator->lag_ports = temp_port->next_port_in_aggregator;
+				temp_aggregator->num_of_ports--;
+				if (__agg_active_ports(temp_aggregator) == 0) {
+					select_new_active_agg = temp_aggregator->is_active;
+					ad_clear_agg(temp_aggregator);
+					if (select_new_active_agg) {
+						netdev_info(bond->dev, "Removing an active aggregator\n");
+						/* select new active aggregator */
+						ad_agg_selection_logic(__get_first_agg(port),
+							               &dummy_slave_update);
+					}
+				}
+				break;
+			}
+		}
+	}
+	port->slave = NULL;
+
+out:
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/**
+ * bond_3ad_update_ad_actor_settings - reflect change of actor settings to ports
+ * @bond: bonding struct to work on
+ *
+ * If an ad_actor setting gets changed we need to update the individual port
+ * settings so the bond device will use the new values when it gets upped.
+ */
+void bond_3ad_update_ad_actor_settings(struct bonding *bond)
+{
+	struct list_head *iter;
+	struct slave *slave;
+
+	ASSERT_RTNL();
+
+	BOND_AD_INFO(bond).system.sys_priority = bond->params.ad_actor_sys_prio;
+	if (is_zero_ether_addr(bond->params.ad_actor_system))
+		BOND_AD_INFO(bond).system.sys_mac_addr =
+		    *((struct mac_addr *)bond->dev->dev_addr);
+	else
+		BOND_AD_INFO(bond).system.sys_mac_addr =
+		    *((struct mac_addr *)bond->params.ad_actor_system);
+
+	spin_lock_bh(&bond->mode_lock);
+	bond_for_each_slave(bond, slave, iter) {
+		struct port *port = &(SLAVE_AD_INFO(slave))->port;
+
+		__ad_actor_update_port(port);
+		port->ntt = true;
+	}
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/**
+ * bond_3ad_state_machine_handler - handle state machines timeout
+ * @bond: bonding struct to work on
+ *
+ * The state machine handling concept in this module is to check every tick
+ * which state machine should operate any function. The execution order is
+ * round robin, so when we have an interaction between state machines, the
+ * reply of one to each other might be delayed until next tick.
+ *
+ * This function also complete the initialization when the agg_select_timer
+ * times out, and it selects an aggregator for the ports that are yet not
+ * related to any aggregator, and selects the active aggregator for a bond.
+ */
+void bond_3ad_state_machine_handler(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    ad_work.work);
+	struct aggregator *aggregator;
+	struct list_head *iter;
+	struct slave *slave;
+	struct port *port;
+	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
+	bool update_slave_arr = false;
+
+	/* Lock to protect data accessed by all (e.g., port->sm_vars) and
+	 * against running with bond_3ad_unbind_slave. ad_rx_machine may run
+	 * concurrently due to incoming LACPDU as well.
+	 */
+	spin_lock_bh(&bond->mode_lock);
+	rcu_read_lock();
+
+	/* check if there are any slaves */
+	if (!bond_has_slaves(bond))
+		goto re_arm;
+
+	/* check if agg_select_timer timer after initialize is timed out */
+	if (BOND_AD_INFO(bond).agg_select_timer &&
+	    !(--BOND_AD_INFO(bond).agg_select_timer)) {
+		slave = bond_first_slave_rcu(bond);
+		port = slave ? &(SLAVE_AD_INFO(slave)->port) : NULL;
+
+		/* select the active aggregator for the bond */
+		if (port) {
+			if (!port->slave) {
+				net_warn_ratelimited("%s: Warning: bond's first port is uninitialized\n",
+						     bond->dev->name);
+				goto re_arm;
+			}
+
+			aggregator = __get_first_agg(port);
+			ad_agg_selection_logic(aggregator, &update_slave_arr);
+		}
+		bond_3ad_set_carrier(bond);
+	}
+
+	/* for each port run the state machines */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		port = &(SLAVE_AD_INFO(slave)->port);
+		if (!port->slave) {
+			net_warn_ratelimited("%s: Warning: Found an uninitialized port\n",
+					    bond->dev->name);
+			goto re_arm;
+		}
+
+		ad_rx_machine(NULL, port);
+		ad_periodic_machine(port);
+		ad_port_selection_logic(port, &update_slave_arr);
+		ad_mux_machine(port, &update_slave_arr);
+		ad_tx_machine(port);
+		ad_churn_machine(port);
+
+		/* turn off the BEGIN bit, since we already handled it */
+		if (port->sm_vars & AD_PORT_BEGIN)
+			port->sm_vars &= ~AD_PORT_BEGIN;
+	}
+
+re_arm:
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (slave->should_notify) {
+			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
+			break;
+		}
+	}
+	rcu_read_unlock();
+	spin_unlock_bh(&bond->mode_lock);
+
+	if (update_slave_arr)
+		bond_slave_arr_work_rearm(bond, 0);
+
+	if (should_notify_rtnl && rtnl_trylock()) {
+		bond_slave_state_notify(bond);
+		rtnl_unlock();
+	}
+	queue_delayed_work(bond->wq, &bond->ad_work, ad_delta_in_ticks);
+}
+
+/**
+ * bond_3ad_rx_indication - handle a received frame
+ * @lacpdu: received lacpdu
+ * @slave: slave struct to work on
+ * @length: length of the data received
+ *
+ * It is assumed that frames that were sent on this NIC don't returned as new
+ * received frames (loopback). Since only the payload is given to this
+ * function, it check for loopback.
+ */
+static int bond_3ad_rx_indication(struct lacpdu *lacpdu, struct slave *slave,
+				  u16 length)
+{
+	struct port *port;
+	int ret = RX_HANDLER_ANOTHER;
+
+	if (length >= sizeof(struct lacpdu)) {
+
+		port = &(SLAVE_AD_INFO(slave)->port);
+
+		if (!port->slave) {
+			net_warn_ratelimited("%s: Warning: port of slave %s is uninitialized\n",
+					     slave->dev->name, slave->bond->dev->name);
+			return ret;
+		}
+
+		switch (lacpdu->subtype) {
+		case AD_TYPE_LACPDU:
+			ret = RX_HANDLER_CONSUMED;
+			netdev_dbg(slave->bond->dev,
+				   "Received LACPDU on port %d slave %s\n",
+				   port->actor_port_number,
+				   slave->dev->name);
+			/* Protect against concurrent state machines */
+			spin_lock(&slave->bond->mode_lock);
+			ad_rx_machine(lacpdu, port);
+			spin_unlock(&slave->bond->mode_lock);
+			break;
+
+		case AD_TYPE_MARKER:
+			ret = RX_HANDLER_CONSUMED;
+			/* No need to convert fields to Little Endian since we
+			 * don't use the marker's fields.
+			 */
+
+			switch (((struct bond_marker *)lacpdu)->tlv_type) {
+			case AD_MARKER_INFORMATION_SUBTYPE:
+				netdev_dbg(slave->bond->dev, "Received Marker Information on port %d\n",
+					   port->actor_port_number);
+				ad_marker_info_received((struct bond_marker *)lacpdu, port);
+				break;
+
+			case AD_MARKER_RESPONSE_SUBTYPE:
+				netdev_dbg(slave->bond->dev, "Received Marker Response on port %d\n",
+					   port->actor_port_number);
+				ad_marker_response_received((struct bond_marker *)lacpdu, port);
+				break;
+
+			default:
+				netdev_dbg(slave->bond->dev, "Received an unknown Marker subtype on slot %d\n",
+					   port->actor_port_number);
+			}
+		}
+	}
+	return ret;
+}
+
+/**
+ * ad_update_actor_keys - Update the oper / admin keys for a port based on
+ * its current speed and duplex settings.
+ *
+ * @port: the port we'are looking at
+ * @reset: Boolean to just reset the speed and the duplex part of the key
+ *
+ * The logic to change the oper / admin keys is:
+ * (a) A full duplex port can participate in LACP with partner.
+ * (b) When the speed is changed, LACP need to be reinitiated.
+ */
+static void ad_update_actor_keys(struct port *port, bool reset)
+{
+	u8 duplex = 0;
+	u16 ospeed = 0, speed = 0;
+	u16 old_oper_key = port->actor_oper_port_key;
+
+	port->actor_admin_port_key &= ~(AD_SPEED_KEY_MASKS|AD_DUPLEX_KEY_MASKS);
+	if (!reset) {
+		speed = __get_link_speed(port);
+		ospeed = (old_oper_key & AD_SPEED_KEY_MASKS) >> 1;
+		duplex = __get_duplex(port);
+		port->actor_admin_port_key |= (speed << 1) | duplex;
+	}
+	port->actor_oper_port_key = port->actor_admin_port_key;
+
+	if (old_oper_key != port->actor_oper_port_key) {
+		/* Only 'duplex' port participates in LACP */
+		if (duplex)
+			port->sm_vars |= AD_PORT_LACP_ENABLED;
+		else
+			port->sm_vars &= ~AD_PORT_LACP_ENABLED;
+
+		if (!reset) {
+			if (!speed) {
+				netdev_err(port->slave->dev,
+					   "speed changed to 0 for port %s",
+					   port->slave->dev->name);
+			} else if (duplex && ospeed != speed) {
+				/* Speed change restarts LACP state-machine */
+				port->sm_vars |= AD_PORT_BEGIN;
+			}
+		}
+	}
+}
+
+/**
+ * bond_3ad_adapter_speed_duplex_changed - handle a slave's speed / duplex
+ * change indication
+ *
+ * @slave: slave struct to work on
+ *
+ * Handle reselection of aggregator (if needed) for this port.
+ */
+void bond_3ad_adapter_speed_duplex_changed(struct slave *slave)
+{
+	struct port *port;
+
+	port = &(SLAVE_AD_INFO(slave)->port);
+
+	/* if slave is null, the whole port is not initialized */
+	if (!port->slave) {
+		netdev_warn(slave->bond->dev,
+			    "speed/duplex changed for uninitialized port %s\n",
+			    slave->dev->name);
+		return;
+	}
+
+	spin_lock_bh(&slave->bond->mode_lock);
+	ad_update_actor_keys(port, false);
+	spin_unlock_bh(&slave->bond->mode_lock);
+	netdev_dbg(slave->bond->dev, "Port %d slave %s changed speed/duplex\n",
+		   port->actor_port_number, slave->dev->name);
+}
+
+/**
+ * bond_3ad_handle_link_change - handle a slave's link status change indication
+ * @slave: slave struct to work on
+ * @status: whether the link is now up or down
+ *
+ * Handle reselection of aggregator (if needed) for this port.
+ */
+void bond_3ad_handle_link_change(struct slave *slave, char link)
+{
+	struct aggregator *agg;
+	struct port *port;
+	bool dummy;
+
+	port = &(SLAVE_AD_INFO(slave)->port);
+
+	/* if slave is null, the whole port is not initialized */
+	if (!port->slave) {
+		netdev_warn(slave->bond->dev, "link status changed for uninitialized port on %s\n",
+			    slave->dev->name);
+		return;
+	}
+
+	spin_lock_bh(&slave->bond->mode_lock);
+	/* on link down we are zeroing duplex and speed since
+	 * some of the adaptors(ce1000.lan) report full duplex/speed
+	 * instead of N/A(duplex) / 0(speed).
+	 *
+	 * on link up we are forcing recheck on the duplex and speed since
+	 * some of he adaptors(ce1000.lan) report.
+	 */
+	if (link == BOND_LINK_UP) {
+		port->is_enabled = true;
+		ad_update_actor_keys(port, false);
+	} else {
+		/* link has failed */
+		port->is_enabled = false;
+		ad_update_actor_keys(port, true);
+		toe_failover(netdev_master_upper_dev_get(slave->dev),
+			     slave->dev, TOE_LINK_DOWN, NULL);
+	}
+	agg = __get_first_agg(port);
+	ad_agg_selection_logic(agg, &dummy);
+
+	spin_unlock_bh(&slave->bond->mode_lock);
+
+	netdev_dbg(slave->bond->dev, "Port %d changed link status to %s\n",
+		   port->actor_port_number,
+		   link == BOND_LINK_UP ? "UP" : "DOWN");
+
+	/* RTNL is held and mode_lock is released so it's safe
+	 * to update slave_array here.
+	 */
+	bond_update_slave_arr(slave->bond, NULL);
+}
+
+/**
+ * bond_3ad_set_carrier - set link state for bonding master
+ * @bond - bonding structure
+ *
+ * if we have an active aggregator, we're up, if not, we're down.
+ * Presumes that we cannot have an active aggregator if there are
+ * no slaves with link up.
+ *
+ * This behavior complies with IEEE 802.3 section 43.3.9.
+ *
+ * Called by bond_set_carrier(). Return zero if carrier state does not
+ * change, nonzero if it does.
+ */
+int bond_3ad_set_carrier(struct bonding *bond)
+{
+	struct aggregator *active;
+	struct slave *first_slave;
+	int ret = 1;
+
+	rcu_read_lock();
+	first_slave = bond_first_slave_rcu(bond);
+	if (!first_slave) {
+		ret = 0;
+		goto out;
+	}
+	active = __get_active_agg(&(SLAVE_AD_INFO(first_slave)->aggregator));
+	if (active) {
+		/* are enough slaves available to consider link up? */
+		if (__agg_active_ports(active) < bond->params.min_links) {
+			if (netif_carrier_ok(bond->dev)) {
+				netif_carrier_off(bond->dev);
+				goto out;
+			}
+		} else if (!netif_carrier_ok(bond->dev)) {
+			netif_carrier_on(bond->dev);
+			goto out;
+		}
+	} else if (netif_carrier_ok(bond->dev)) {
+		netif_carrier_off(bond->dev);
+	}
+out:
+	rcu_read_unlock();
+	return ret;
+}
+
+/**
+ * __bond_3ad_get_active_agg_info - get information of the active aggregator
+ * @bond: bonding struct to work on
+ * @ad_info: ad_info struct to fill with the bond's info
+ *
+ * Returns:   0 on success
+ *          < 0 on error
+ */
+int __bond_3ad_get_active_agg_info(struct bonding *bond,
+				   struct ad_info *ad_info)
+{
+	struct aggregator *aggregator = NULL;
+	struct list_head *iter;
+	struct slave *slave;
+	struct port *port;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		port = &(SLAVE_AD_INFO(slave)->port);
+		if (port->aggregator && port->aggregator->is_active) {
+			aggregator = port->aggregator;
+			break;
+		}
+	}
+
+	if (!aggregator)
+		return -1;
+
+	ad_info->aggregator_id = aggregator->aggregator_identifier;
+	ad_info->ports = __agg_active_ports(aggregator);
+	ad_info->actor_key = aggregator->actor_oper_aggregator_key;
+	ad_info->partner_key = aggregator->partner_oper_aggregator_key;
+	ether_addr_copy(ad_info->partner_system,
+			aggregator->partner_system.mac_addr_value);
+	return 0;
+}
+
+int bond_3ad_get_active_agg_info(struct bonding *bond, struct ad_info *ad_info)
+{
+	int ret;
+
+	rcu_read_lock();
+	ret = __bond_3ad_get_active_agg_info(bond, ad_info);
+	rcu_read_unlock();
+
+	return ret;
+}
+
+int bond_3ad_lacpdu_recv(const struct sk_buff *skb, struct bonding *bond,
+			 struct slave *slave)
+{
+	struct lacpdu *lacpdu, _lacpdu;
+
+	if (skb->protocol != PKT_TYPE_LACPDU)
+		return RX_HANDLER_ANOTHER;
+
+	if (!MAC_ADDRESS_EQUAL(eth_hdr(skb)->h_dest, lacpdu_mcast_addr))
+		return RX_HANDLER_ANOTHER;
+
+	lacpdu = skb_header_pointer(skb, 0, sizeof(_lacpdu), &_lacpdu);
+	if (!lacpdu)
+		return RX_HANDLER_ANOTHER;
+
+	return bond_3ad_rx_indication(lacpdu, slave, skb->len);
+}
+
+/**
+ * bond_3ad_update_lacp_rate - change the lacp rate
+ * @bond - bonding struct
+ *
+ * When modify lacp_rate parameter via sysfs,
+ * update actor_oper_port_state of each port.
+ *
+ * Hold bond->mode_lock,
+ * so we can modify port->actor_oper_port_state,
+ * no matter bond is up or down.
+ */
+void bond_3ad_update_lacp_rate(struct bonding *bond)
+{
+	struct port *port = NULL;
+	struct list_head *iter;
+	struct slave *slave;
+	int lacp_fast;
+
+	lacp_fast = bond->params.lacp_fast;
+	spin_lock_bh(&bond->mode_lock);
+	bond_for_each_slave(bond, slave, iter) {
+		port = &(SLAVE_AD_INFO(slave)->port);
+		if (lacp_fast)
+			port->actor_oper_port_state |= AD_STATE_LACP_TIMEOUT;
+		else
+			port->actor_oper_port_state &= ~AD_STATE_LACP_TIMEOUT;
+	}
+	spin_unlock_bh(&bond->mode_lock);
+}
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.164/bond_alb.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.164/bond_alb.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,1826 @@
+/*
+ * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, see <http://www.gnu.org/licenses/>.
+ *
+ * The full GNU General Public License is included in this distribution in the
+ * file called LICENSE.
+ *
+ */
+
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/pkt_sched.h>
+#include <linux/spinlock.h>
+#include <linux/slab.h>
+#include <linux/timer.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <linux/if_arp.h>
+#include <linux/if_ether.h>
+#include <linux/if_bonding.h>
+#include <linux/if_vlan.h>
+#include <linux/in.h>
+#include <net/ipx.h>
+#include <net/arp.h>
+#include <net/ipv6.h>
+#include <asm/byteorder.h>
+#include <net/bonding.h>
+#include <net/bond_alb.h>
+
+static const u8 mac_v6_allmcast[ETH_ALEN + 2] __long_aligned = {
+	0x33, 0x33, 0x00, 0x00, 0x00, 0x01
+};
+static const int alb_delta_in_ticks = HZ / ALB_TIMER_TICKS_PER_SEC;
+
+#pragma pack(1)
+struct learning_pkt {
+	u8 mac_dst[ETH_ALEN];
+	u8 mac_src[ETH_ALEN];
+	__be16 type;
+	u8 padding[ETH_ZLEN - ETH_HLEN];
+};
+
+struct arp_pkt {
+	__be16  hw_addr_space;
+	__be16  prot_addr_space;
+	u8      hw_addr_len;
+	u8      prot_addr_len;
+	__be16  op_code;
+	u8      mac_src[ETH_ALEN];	/* sender hardware address */
+	__be32  ip_src;			/* sender IP address */
+	u8      mac_dst[ETH_ALEN];	/* target hardware address */
+	__be32  ip_dst;			/* target IP address */
+};
+#pragma pack()
+
+/* Forward declaration */
+static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
+				      bool strict_match);
+static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp);
+static void rlb_src_unlink(struct bonding *bond, u32 index);
+static void rlb_src_link(struct bonding *bond, u32 ip_src_hash,
+			 u32 ip_dst_hash);
+
+static inline u8 _simple_hash(const u8 *hash_start, int hash_size)
+{
+	int i;
+	u8 hash = 0;
+
+	for (i = 0; i < hash_size; i++)
+		hash ^= hash_start[i];
+
+	return hash;
+}
+
+/*********************** tlb specific functions ***************************/
+
+static inline void tlb_init_table_entry(struct tlb_client_info *entry, int save_load)
+{
+	if (save_load) {
+		entry->load_history = 1 + entry->tx_bytes /
+				      BOND_TLB_REBALANCE_INTERVAL;
+		entry->tx_bytes = 0;
+	}
+
+	entry->tx_slave = NULL;
+	entry->next = TLB_NULL_INDEX;
+	entry->prev = TLB_NULL_INDEX;
+}
+
+static inline void tlb_init_slave(struct slave *slave)
+{
+	SLAVE_TLB_INFO(slave).load = 0;
+	SLAVE_TLB_INFO(slave).head = TLB_NULL_INDEX;
+}
+
+static void __tlb_clear_slave(struct bonding *bond, struct slave *slave,
+			 int save_load)
+{
+	struct tlb_client_info *tx_hash_table;
+	u32 index;
+
+	/* clear slave from tx_hashtbl */
+	tx_hash_table = BOND_ALB_INFO(bond).tx_hashtbl;
+
+	/* skip this if we've already freed the tx hash table */
+	if (tx_hash_table) {
+		index = SLAVE_TLB_INFO(slave).head;
+		while (index != TLB_NULL_INDEX) {
+			u32 next_index = tx_hash_table[index].next;
+			tlb_init_table_entry(&tx_hash_table[index], save_load);
+			index = next_index;
+		}
+	}
+
+	tlb_init_slave(slave);
+}
+
+static void tlb_clear_slave(struct bonding *bond, struct slave *slave,
+			 int save_load)
+{
+	spin_lock_bh(&bond->mode_lock);
+	__tlb_clear_slave(bond, slave, save_load);
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/* Must be called before starting the monitor timer */
+static int tlb_initialize(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	int size = TLB_HASH_TABLE_SIZE * sizeof(struct tlb_client_info);
+	struct tlb_client_info *new_hashtbl;
+	int i;
+
+	new_hashtbl = kzalloc(size, GFP_KERNEL);
+	if (!new_hashtbl)
+		return -ENOMEM;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	bond_info->tx_hashtbl = new_hashtbl;
+
+	for (i = 0; i < TLB_HASH_TABLE_SIZE; i++)
+		tlb_init_table_entry(&bond_info->tx_hashtbl[i], 0);
+
+	spin_unlock_bh(&bond->mode_lock);
+
+	return 0;
+}
+
+/* Must be called only after all slaves have been released */
+static void tlb_deinitialize(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+
+	spin_lock_bh(&bond->mode_lock);
+
+	kfree(bond_info->tx_hashtbl);
+	bond_info->tx_hashtbl = NULL;
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+static long long compute_gap(struct slave *slave)
+{
+	return (s64) (slave->speed << 20) - /* Convert to Megabit per sec */
+	       (s64) (SLAVE_TLB_INFO(slave).load << 3); /* Bytes to bits */
+}
+
+static struct slave *tlb_get_least_loaded_slave(struct bonding *bond)
+{
+	struct slave *slave, *least_loaded;
+	struct list_head *iter;
+	long long max_gap;
+
+	least_loaded = NULL;
+	max_gap = LLONG_MIN;
+
+	/* Find the slave with the largest gap */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (bond_slave_can_tx(slave)) {
+			long long gap = compute_gap(slave);
+
+			if (max_gap < gap) {
+				least_loaded = slave;
+				max_gap = gap;
+			}
+		}
+	}
+
+	return least_loaded;
+}
+
+static struct slave *__tlb_choose_channel(struct bonding *bond, u32 hash_index,
+						u32 skb_len)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct tlb_client_info *hash_table;
+	struct slave *assigned_slave;
+
+	hash_table = bond_info->tx_hashtbl;
+	assigned_slave = hash_table[hash_index].tx_slave;
+	if (!assigned_slave) {
+		assigned_slave = tlb_get_least_loaded_slave(bond);
+
+		if (assigned_slave) {
+			struct tlb_slave_info *slave_info =
+				&(SLAVE_TLB_INFO(assigned_slave));
+			u32 next_index = slave_info->head;
+
+			hash_table[hash_index].tx_slave = assigned_slave;
+			hash_table[hash_index].next = next_index;
+			hash_table[hash_index].prev = TLB_NULL_INDEX;
+
+			if (next_index != TLB_NULL_INDEX)
+				hash_table[next_index].prev = hash_index;
+
+			slave_info->head = hash_index;
+			slave_info->load +=
+				hash_table[hash_index].load_history;
+		}
+	}
+
+	if (assigned_slave)
+		hash_table[hash_index].tx_bytes += skb_len;
+
+	return assigned_slave;
+}
+
+static struct slave *tlb_choose_channel(struct bonding *bond, u32 hash_index,
+					u32 skb_len)
+{
+	struct slave *tx_slave;
+
+	/* We don't need to disable softirq here, becase
+	 * tlb_choose_channel() is only called by bond_alb_xmit()
+	 * which already has softirq disabled.
+	 */
+	spin_lock(&bond->mode_lock);
+	tx_slave = __tlb_choose_channel(bond, hash_index, skb_len);
+	spin_unlock(&bond->mode_lock);
+
+	return tx_slave;
+}
+
+/*********************** rlb specific functions ***************************/
+
+/* when an ARP REPLY is received from a client update its info
+ * in the rx_hashtbl
+ */
+static void rlb_update_entry_from_arp(struct bonding *bond, struct arp_pkt *arp)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *client_info;
+	u32 hash_index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	hash_index = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
+	client_info = &(bond_info->rx_hashtbl[hash_index]);
+
+	if ((client_info->assigned) &&
+	    (client_info->ip_src == arp->ip_dst) &&
+	    (client_info->ip_dst == arp->ip_src) &&
+	    (!ether_addr_equal_64bits(client_info->mac_dst, arp->mac_src))) {
+		/* update the clients MAC address */
+		ether_addr_copy(client_info->mac_dst, arp->mac_src);
+		client_info->ntt = 1;
+		bond_info->rx_ntt = 1;
+	}
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+static int rlb_arp_recv(const struct sk_buff *skb, struct bonding *bond,
+			struct slave *slave)
+{
+	struct arp_pkt *arp, _arp;
+
+	if (skb->protocol != cpu_to_be16(ETH_P_ARP))
+		goto out;
+
+	arp = skb_header_pointer(skb, 0, sizeof(_arp), &_arp);
+	if (!arp)
+		goto out;
+
+	/* We received an ARP from arp->ip_src.
+	 * We might have used this IP address previously (on the bonding host
+	 * itself or on a system that is bridged together with the bond).
+	 * However, if arp->mac_src is different than what is stored in
+	 * rx_hashtbl, some other host is now using the IP and we must prevent
+	 * sending out client updates with this IP address and the old MAC
+	 * address.
+	 * Clean up all hash table entries that have this address as ip_src but
+	 * have a different mac_src.
+	 */
+	rlb_purge_src_ip(bond, arp);
+
+	if (arp->op_code == htons(ARPOP_REPLY)) {
+		/* update rx hash table for this ARP */
+		rlb_update_entry_from_arp(bond, arp);
+		netdev_dbg(bond->dev, "Server received an ARP Reply from client\n");
+	}
+out:
+	return RX_HANDLER_ANOTHER;
+}
+
+/* Caller must hold rcu_read_lock() */
+static struct slave *__rlb_next_rx_slave(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct slave *before = NULL, *rx_slave = NULL, *slave;
+	struct list_head *iter;
+	bool found = false;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (!bond_slave_can_tx(slave))
+			continue;
+		if (!found) {
+			if (!before || before->speed < slave->speed)
+				before = slave;
+		} else {
+			if (!rx_slave || rx_slave->speed < slave->speed)
+				rx_slave = slave;
+		}
+		if (slave == bond_info->rx_slave)
+			found = true;
+	}
+	/* we didn't find anything after the current or we have something
+	 * better before and up to the current slave
+	 */
+	if (!rx_slave || (before && rx_slave->speed < before->speed))
+		rx_slave = before;
+
+	if (rx_slave)
+		bond_info->rx_slave = rx_slave;
+
+	return rx_slave;
+}
+
+/* Caller must hold RTNL, rcu_read_lock is obtained only to silence checkers */
+static struct slave *rlb_next_rx_slave(struct bonding *bond)
+{
+	struct slave *rx_slave;
+
+	ASSERT_RTNL();
+
+	rcu_read_lock();
+	rx_slave = __rlb_next_rx_slave(bond);
+	rcu_read_unlock();
+
+	return rx_slave;
+}
+
+/* teach the switch the mac of a disabled slave
+ * on the primary for fault tolerance
+ *
+ * Caller must hold RTNL
+ */
+static void rlb_teach_disabled_mac_on_primary(struct bonding *bond, u8 addr[])
+{
+	struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
+
+	if (!curr_active)
+		return;
+
+	if (!bond->alb_info.primary_is_promisc) {
+		if (!dev_set_promiscuity(curr_active->dev, 1))
+			bond->alb_info.primary_is_promisc = 1;
+		else
+			bond->alb_info.primary_is_promisc = 0;
+	}
+
+	bond->alb_info.rlb_promisc_timeout_counter = 0;
+
+	alb_send_learning_packets(curr_active, addr, true);
+}
+
+/* slave being removed should not be active at this point
+ *
+ * Caller must hold rtnl.
+ */
+static void rlb_clear_slave(struct bonding *bond, struct slave *slave)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *rx_hash_table;
+	u32 index, next_index;
+
+	/* clear slave from rx_hashtbl */
+	spin_lock_bh(&bond->mode_lock);
+
+	rx_hash_table = bond_info->rx_hashtbl;
+	index = bond_info->rx_hashtbl_used_head;
+	for (; index != RLB_NULL_INDEX; index = next_index) {
+		next_index = rx_hash_table[index].used_next;
+		if (rx_hash_table[index].slave == slave) {
+			struct slave *assigned_slave = rlb_next_rx_slave(bond);
+
+			if (assigned_slave) {
+				rx_hash_table[index].slave = assigned_slave;
+				if (is_valid_ether_addr(rx_hash_table[index].mac_dst)) {
+					bond_info->rx_hashtbl[index].ntt = 1;
+					bond_info->rx_ntt = 1;
+					/* A slave has been removed from the
+					 * table because it is either disabled
+					 * or being released. We must retry the
+					 * update to avoid clients from not
+					 * being updated & disconnecting when
+					 * there is stress
+					 */
+					bond_info->rlb_update_retry_counter =
+						RLB_UPDATE_RETRY;
+				}
+			} else {  /* there is no active slave */
+				rx_hash_table[index].slave = NULL;
+			}
+		}
+	}
+
+	spin_unlock_bh(&bond->mode_lock);
+
+	if (slave != rtnl_dereference(bond->curr_active_slave))
+		rlb_teach_disabled_mac_on_primary(bond, slave->dev->dev_addr);
+}
+
+static void rlb_update_client(struct rlb_client_info *client_info)
+{
+	int i;
+
+	if (!client_info->slave || !is_valid_ether_addr(client_info->mac_dst))
+		return;
+
+	for (i = 0; i < RLB_ARP_BURST_SIZE; i++) {
+		struct sk_buff *skb;
+
+		skb = arp_create(ARPOP_REPLY, ETH_P_ARP,
+				 client_info->ip_dst,
+				 client_info->slave->dev,
+				 client_info->ip_src,
+				 client_info->mac_dst,
+				 client_info->slave->dev->dev_addr,
+				 client_info->mac_dst);
+		if (!skb) {
+			netdev_err(client_info->slave->bond->dev,
+				   "failed to create an ARP packet\n");
+			continue;
+		}
+
+		skb->dev = client_info->slave->dev;
+
+		if (client_info->vlan_id) {
+			__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),
+					       client_info->vlan_id);
+		}
+
+		arp_xmit(skb);
+	}
+}
+
+/* sends ARP REPLIES that update the clients that need updating */
+static void rlb_update_rx_clients(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *client_info;
+	u32 hash_index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	hash_index = bond_info->rx_hashtbl_used_head;
+	for (; hash_index != RLB_NULL_INDEX;
+	     hash_index = client_info->used_next) {
+		client_info = &(bond_info->rx_hashtbl[hash_index]);
+		if (client_info->ntt) {
+			rlb_update_client(client_info);
+			if (bond_info->rlb_update_retry_counter == 0)
+				client_info->ntt = 0;
+		}
+	}
+
+	/* do not update the entries again until this counter is zero so that
+	 * not to confuse the clients.
+	 */
+	bond_info->rlb_update_delay_counter = RLB_UPDATE_DELAY;
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/* The slave was assigned a new mac address - update the clients */
+static void rlb_req_update_slave_clients(struct bonding *bond, struct slave *slave)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *client_info;
+	int ntt = 0;
+	u32 hash_index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	hash_index = bond_info->rx_hashtbl_used_head;
+	for (; hash_index != RLB_NULL_INDEX;
+	     hash_index = client_info->used_next) {
+		client_info = &(bond_info->rx_hashtbl[hash_index]);
+
+		if ((client_info->slave == slave) &&
+		    is_valid_ether_addr(client_info->mac_dst)) {
+			client_info->ntt = 1;
+			ntt = 1;
+		}
+	}
+
+	/* update the team's flag only after the whole iteration */
+	if (ntt) {
+		bond_info->rx_ntt = 1;
+		/* fasten the change */
+		bond_info->rlb_update_retry_counter = RLB_UPDATE_RETRY;
+	}
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/* mark all clients using src_ip to be updated */
+static void rlb_req_update_subnet_clients(struct bonding *bond, __be32 src_ip)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *client_info;
+	u32 hash_index;
+
+	spin_lock(&bond->mode_lock);
+
+	hash_index = bond_info->rx_hashtbl_used_head;
+	for (; hash_index != RLB_NULL_INDEX;
+	     hash_index = client_info->used_next) {
+		client_info = &(bond_info->rx_hashtbl[hash_index]);
+
+		if (!client_info->slave) {
+			netdev_err(bond->dev, "found a client with no channel in the client's hash table\n");
+			continue;
+		}
+		/* update all clients using this src_ip, that are not assigned
+		 * to the team's address (curr_active_slave) and have a known
+		 * unicast mac address.
+		 */
+		if ((client_info->ip_src == src_ip) &&
+		    !ether_addr_equal_64bits(client_info->slave->dev->dev_addr,
+					     bond->dev->dev_addr) &&
+		    is_valid_ether_addr(client_info->mac_dst)) {
+			client_info->ntt = 1;
+			bond_info->rx_ntt = 1;
+		}
+	}
+
+	spin_unlock(&bond->mode_lock);
+}
+
+static struct slave *rlb_choose_channel(struct sk_buff *skb,
+					struct bonding *bond,
+					const struct arp_pkt *arp)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct slave *assigned_slave, *curr_active_slave;
+	struct rlb_client_info *client_info;
+	u32 hash_index = 0;
+
+	spin_lock(&bond->mode_lock);
+
+	curr_active_slave = rcu_dereference(bond->curr_active_slave);
+
+	hash_index = _simple_hash((u8 *)&arp->ip_dst, sizeof(arp->ip_dst));
+	client_info = &(bond_info->rx_hashtbl[hash_index]);
+
+	if (client_info->assigned) {
+		if ((client_info->ip_src == arp->ip_src) &&
+		    (client_info->ip_dst == arp->ip_dst)) {
+			/* the entry is already assigned to this client */
+			if (!is_broadcast_ether_addr(arp->mac_dst)) {
+				/* update mac address from arp */
+				ether_addr_copy(client_info->mac_dst, arp->mac_dst);
+			}
+			ether_addr_copy(client_info->mac_src, arp->mac_src);
+
+			assigned_slave = client_info->slave;
+			if (assigned_slave) {
+				spin_unlock(&bond->mode_lock);
+				return assigned_slave;
+			}
+		} else {
+			/* the entry is already assigned to some other client,
+			 * move the old client to primary (curr_active_slave) so
+			 * that the new client can be assigned to this entry.
+			 */
+			if (curr_active_slave &&
+			    client_info->slave != curr_active_slave) {
+				client_info->slave = curr_active_slave;
+				rlb_update_client(client_info);
+			}
+		}
+	}
+	/* assign a new slave */
+	assigned_slave = __rlb_next_rx_slave(bond);
+
+	if (assigned_slave) {
+		if (!(client_info->assigned &&
+		      client_info->ip_src == arp->ip_src)) {
+			/* ip_src is going to be updated,
+			 * fix the src hash list
+			 */
+			u32 hash_src = _simple_hash((u8 *)&arp->ip_src,
+						    sizeof(arp->ip_src));
+			rlb_src_unlink(bond, hash_index);
+			rlb_src_link(bond, hash_src, hash_index);
+		}
+
+		client_info->ip_src = arp->ip_src;
+		client_info->ip_dst = arp->ip_dst;
+		/* arp->mac_dst is broadcast for arp reqeusts.
+		 * will be updated with clients actual unicast mac address
+		 * upon receiving an arp reply.
+		 */
+		ether_addr_copy(client_info->mac_dst, arp->mac_dst);
+		ether_addr_copy(client_info->mac_src, arp->mac_src);
+		client_info->slave = assigned_slave;
+
+		if (is_valid_ether_addr(client_info->mac_dst)) {
+			client_info->ntt = 1;
+			bond->alb_info.rx_ntt = 1;
+		} else {
+			client_info->ntt = 0;
+		}
+
+		if (vlan_get_tag(skb, &client_info->vlan_id))
+			client_info->vlan_id = 0;
+
+		if (!client_info->assigned) {
+			u32 prev_tbl_head = bond_info->rx_hashtbl_used_head;
+			bond_info->rx_hashtbl_used_head = hash_index;
+			client_info->used_next = prev_tbl_head;
+			if (prev_tbl_head != RLB_NULL_INDEX) {
+				bond_info->rx_hashtbl[prev_tbl_head].used_prev =
+					hash_index;
+			}
+			client_info->assigned = 1;
+		}
+	}
+
+	spin_unlock(&bond->mode_lock);
+
+	return assigned_slave;
+}
+
+/* chooses (and returns) transmit channel for arp reply
+ * does not choose channel for other arp types since they are
+ * sent on the curr_active_slave
+ */
+static struct slave *rlb_arp_xmit(struct sk_buff *skb, struct bonding *bond)
+{
+	struct slave *tx_slave = NULL;
+	struct arp_pkt *arp;
+
+	if (!pskb_network_may_pull(skb, sizeof(*arp)))
+		return NULL;
+	arp = (struct arp_pkt *)skb_network_header(skb);
+
+	/* Don't modify or load balance ARPs that do not originate locally
+	 * (e.g.,arrive via a bridge).
+	 */
+	if (!bond_slave_has_mac_rx(bond, arp->mac_src))
+		return NULL;
+
+	if (arp->op_code == htons(ARPOP_REPLY)) {
+		/* the arp must be sent on the selected rx channel */
+		tx_slave = rlb_choose_channel(skb, bond, arp);
+		if (tx_slave)
+			bond_hw_addr_copy(arp->mac_src, tx_slave->dev->dev_addr,
+					  tx_slave->dev->addr_len);
+		netdev_dbg(bond->dev, "Server sent ARP Reply packet\n");
+	} else if (arp->op_code == htons(ARPOP_REQUEST)) {
+		/* Create an entry in the rx_hashtbl for this client as a
+		 * place holder.
+		 * When the arp reply is received the entry will be updated
+		 * with the correct unicast address of the client.
+		 */
+		rlb_choose_channel(skb, bond, arp);
+
+		/* The ARP reply packets must be delayed so that
+		 * they can cancel out the influence of the ARP request.
+		 */
+		bond->alb_info.rlb_update_delay_counter = RLB_UPDATE_DELAY;
+
+		/* arp requests are broadcast and are sent on the primary
+		 * the arp request will collapse all clients on the subnet to
+		 * the primary slave. We must register these clients to be
+		 * updated with their assigned mac.
+		 */
+		rlb_req_update_subnet_clients(bond, arp->ip_src);
+		netdev_dbg(bond->dev, "Server sent ARP Request packet\n");
+	}
+
+	return tx_slave;
+}
+
+static void rlb_rebalance(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct slave *assigned_slave;
+	struct rlb_client_info *client_info;
+	int ntt;
+	u32 hash_index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	ntt = 0;
+	hash_index = bond_info->rx_hashtbl_used_head;
+	for (; hash_index != RLB_NULL_INDEX;
+	     hash_index = client_info->used_next) {
+		client_info = &(bond_info->rx_hashtbl[hash_index]);
+		assigned_slave = __rlb_next_rx_slave(bond);
+		if (assigned_slave && (client_info->slave != assigned_slave)) {
+			client_info->slave = assigned_slave;
+			if (!is_zero_ether_addr(client_info->mac_dst)) {
+				client_info->ntt = 1;
+				ntt = 1;
+			}
+		}
+	}
+
+	/* update the team's flag only after the whole iteration */
+	if (ntt)
+		bond_info->rx_ntt = 1;
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/* Caller must hold mode_lock */
+static void rlb_init_table_entry_dst(struct rlb_client_info *entry)
+{
+	entry->used_next = RLB_NULL_INDEX;
+	entry->used_prev = RLB_NULL_INDEX;
+	entry->assigned = 0;
+	entry->slave = NULL;
+	entry->vlan_id = 0;
+}
+static void rlb_init_table_entry_src(struct rlb_client_info *entry)
+{
+	entry->src_first = RLB_NULL_INDEX;
+	entry->src_prev = RLB_NULL_INDEX;
+	entry->src_next = RLB_NULL_INDEX;
+}
+
+static void rlb_init_table_entry(struct rlb_client_info *entry)
+{
+	memset(entry, 0, sizeof(struct rlb_client_info));
+	rlb_init_table_entry_dst(entry);
+	rlb_init_table_entry_src(entry);
+}
+
+static void rlb_delete_table_entry_dst(struct bonding *bond, u32 index)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	u32 next_index = bond_info->rx_hashtbl[index].used_next;
+	u32 prev_index = bond_info->rx_hashtbl[index].used_prev;
+
+	if (index == bond_info->rx_hashtbl_used_head)
+		bond_info->rx_hashtbl_used_head = next_index;
+	if (prev_index != RLB_NULL_INDEX)
+		bond_info->rx_hashtbl[prev_index].used_next = next_index;
+	if (next_index != RLB_NULL_INDEX)
+		bond_info->rx_hashtbl[next_index].used_prev = prev_index;
+}
+
+/* unlink a rlb hash table entry from the src list */
+static void rlb_src_unlink(struct bonding *bond, u32 index)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	u32 next_index = bond_info->rx_hashtbl[index].src_next;
+	u32 prev_index = bond_info->rx_hashtbl[index].src_prev;
+
+	bond_info->rx_hashtbl[index].src_next = RLB_NULL_INDEX;
+	bond_info->rx_hashtbl[index].src_prev = RLB_NULL_INDEX;
+
+	if (next_index != RLB_NULL_INDEX)
+		bond_info->rx_hashtbl[next_index].src_prev = prev_index;
+
+	if (prev_index == RLB_NULL_INDEX)
+		return;
+
+	/* is prev_index pointing to the head of this list? */
+	if (bond_info->rx_hashtbl[prev_index].src_first == index)
+		bond_info->rx_hashtbl[prev_index].src_first = next_index;
+	else
+		bond_info->rx_hashtbl[prev_index].src_next = next_index;
+
+}
+
+static void rlb_delete_table_entry(struct bonding *bond, u32 index)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
+
+	rlb_delete_table_entry_dst(bond, index);
+	rlb_init_table_entry_dst(entry);
+
+	rlb_src_unlink(bond, index);
+}
+
+/* add the rx_hashtbl[ip_dst_hash] entry to the list
+ * of entries with identical ip_src_hash
+ */
+static void rlb_src_link(struct bonding *bond, u32 ip_src_hash, u32 ip_dst_hash)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	u32 next;
+
+	bond_info->rx_hashtbl[ip_dst_hash].src_prev = ip_src_hash;
+	next = bond_info->rx_hashtbl[ip_src_hash].src_first;
+	bond_info->rx_hashtbl[ip_dst_hash].src_next = next;
+	if (next != RLB_NULL_INDEX)
+		bond_info->rx_hashtbl[next].src_prev = ip_dst_hash;
+	bond_info->rx_hashtbl[ip_src_hash].src_first = ip_dst_hash;
+}
+
+/* deletes all rx_hashtbl entries with arp->ip_src if their mac_src does
+ * not match arp->mac_src
+ */
+static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	u32 ip_src_hash = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
+	u32 index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	index = bond_info->rx_hashtbl[ip_src_hash].src_first;
+	while (index != RLB_NULL_INDEX) {
+		struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
+		u32 next_index = entry->src_next;
+		if (entry->ip_src == arp->ip_src &&
+		    !ether_addr_equal_64bits(arp->mac_src, entry->mac_src))
+				rlb_delete_table_entry(bond, index);
+		index = next_index;
+	}
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+static int rlb_initialize(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info	*new_hashtbl;
+	int size = RLB_HASH_TABLE_SIZE * sizeof(struct rlb_client_info);
+	int i;
+
+	new_hashtbl = kmalloc(size, GFP_KERNEL);
+	if (!new_hashtbl)
+		return -1;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	bond_info->rx_hashtbl = new_hashtbl;
+
+	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
+
+	for (i = 0; i < RLB_HASH_TABLE_SIZE; i++)
+		rlb_init_table_entry(bond_info->rx_hashtbl + i);
+
+	spin_unlock_bh(&bond->mode_lock);
+
+	/* register to receive ARPs */
+	bond->recv_probe = rlb_arp_recv;
+
+	return 0;
+}
+
+static void rlb_deinitialize(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+
+	spin_lock_bh(&bond->mode_lock);
+
+	kfree(bond_info->rx_hashtbl);
+	bond_info->rx_hashtbl = NULL;
+	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+static void rlb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	u32 curr_index;
+
+	spin_lock_bh(&bond->mode_lock);
+
+	curr_index = bond_info->rx_hashtbl_used_head;
+	while (curr_index != RLB_NULL_INDEX) {
+		struct rlb_client_info *curr = &(bond_info->rx_hashtbl[curr_index]);
+		u32 next_index = bond_info->rx_hashtbl[curr_index].used_next;
+
+		if (curr->vlan_id == vlan_id)
+			rlb_delete_table_entry(bond, curr_index);
+
+		curr_index = next_index;
+	}
+
+	spin_unlock_bh(&bond->mode_lock);
+}
+
+/*********************** tlb/rlb shared functions *********************/
+
+static void alb_send_lp_vid(struct slave *slave, u8 mac_addr[],
+			    __be16 vlan_proto, u16 vid)
+{
+	struct learning_pkt pkt;
+	struct sk_buff *skb;
+	int size = sizeof(struct learning_pkt);
+
+	memset(&pkt, 0, size);
+	ether_addr_copy(pkt.mac_dst, mac_addr);
+	ether_addr_copy(pkt.mac_src, mac_addr);
+	pkt.type = cpu_to_be16(ETH_P_LOOPBACK);
+
+	skb = dev_alloc_skb(size);
+	if (!skb)
+		return;
+
+	skb_put_data(skb, &pkt, size);
+
+	skb_reset_mac_header(skb);
+	skb->network_header = skb->mac_header + ETH_HLEN;
+	skb->protocol = pkt.type;
+	skb->priority = TC_PRIO_CONTROL;
+	skb->dev = slave->dev;
+
+	netdev_dbg(slave->bond->dev,
+		   "Send learning packet: dev %s mac %pM vlan %d\n",
+		   slave->dev->name, mac_addr, vid);
+
+	if (vid)
+		__vlan_hwaccel_put_tag(skb, vlan_proto, vid);
+
+	dev_queue_xmit(skb);
+}
+
+struct alb_walk_data {
+	struct bonding *bond;
+	struct slave *slave;
+	u8 *mac_addr;
+	bool strict_match;
+};
+
+static int alb_upper_dev_walk(struct net_device *upper, void *_data)
+{
+	struct alb_walk_data *data = _data;
+	bool strict_match = data->strict_match;
+	struct bonding *bond = data->bond;
+	struct slave *slave = data->slave;
+	u8 *mac_addr = data->mac_addr;
+	struct bond_vlan_tag *tags;
+
+	if (is_vlan_dev(upper) &&
+	    bond->nest_level == vlan_get_encap_level(upper) - 1) {
+		if (upper->addr_assign_type == NET_ADDR_STOLEN) {
+			alb_send_lp_vid(slave, mac_addr,
+					vlan_dev_vlan_proto(upper),
+					vlan_dev_vlan_id(upper));
+		} else {
+			alb_send_lp_vid(slave, upper->dev_addr,
+					vlan_dev_vlan_proto(upper),
+					vlan_dev_vlan_id(upper));
+		}
+	}
+
+	/* If this is a macvlan device, then only send updates
+	 * when strict_match is turned off.
+	 */
+	if (netif_is_macvlan(upper) && !strict_match) {
+		tags = bond_verify_device_path(bond->dev, upper, 0);
+		if (IS_ERR_OR_NULL(tags))
+			BUG();
+		alb_send_lp_vid(slave, upper->dev_addr,
+				tags[0].vlan_proto, tags[0].vlan_id);
+		kfree(tags);
+	}
+
+	return 0;
+}
+
+static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
+				      bool strict_match)
+{
+	struct bonding *bond = bond_get_bond_by_slave(slave);
+	struct alb_walk_data data = {
+		.strict_match = strict_match,
+		.mac_addr = mac_addr,
+		.slave = slave,
+		.bond = bond,
+	};
+
+	/* send untagged */
+	alb_send_lp_vid(slave, mac_addr, 0, 0);
+
+	/* loop through all devices and see if we need to send a packet
+	 * for that device.
+	 */
+	rcu_read_lock();
+	netdev_walk_all_upper_dev_rcu(bond->dev, alb_upper_dev_walk, &data);
+	rcu_read_unlock();
+}
+
+static int alb_set_slave_mac_addr(struct slave *slave, u8 addr[],
+				  unsigned int len)
+{
+	struct net_device *dev = slave->dev;
+	struct sockaddr_storage ss;
+
+	if (BOND_MODE(slave->bond) == BOND_MODE_TLB) {
+		memcpy(dev->dev_addr, addr, len);
+		return 0;
+	}
+
+	/* for rlb each slave must have a unique hw mac addresses so that
+	 * each slave will receive packets destined to a different mac
+	 */
+	memcpy(ss.__data, addr, len);
+	ss.ss_family = dev->type;
+	if (dev_set_mac_address(dev, (struct sockaddr *)&ss)) {
+		netdev_err(slave->bond->dev, "dev_set_mac_address of dev %s failed! ALB mode requires that the base driver support setting the hw address also when the network device's interface is open\n",
+			   dev->name);
+		return -EOPNOTSUPP;
+	}
+	return 0;
+}
+
+/* Swap MAC addresses between two slaves.
+ *
+ * Called with RTNL held, and no other locks.
+ */
+static void alb_swap_mac_addr(struct slave *slave1, struct slave *slave2)
+{
+	u8 tmp_mac_addr[MAX_ADDR_LEN];
+
+	bond_hw_addr_copy(tmp_mac_addr, slave1->dev->dev_addr,
+			  slave1->dev->addr_len);
+	alb_set_slave_mac_addr(slave1, slave2->dev->dev_addr,
+			       slave2->dev->addr_len);
+	alb_set_slave_mac_addr(slave2, tmp_mac_addr,
+			       slave1->dev->addr_len);
+
+}
+
+/* Send learning packets after MAC address swap.
+ *
+ * Called with RTNL and no other locks
+ */
+static void alb_fasten_mac_swap(struct bonding *bond, struct slave *slave1,
+				struct slave *slave2)
+{
+	int slaves_state_differ = (bond_slave_can_tx(slave1) != bond_slave_can_tx(slave2));
+	struct slave *disabled_slave = NULL;
+
+	ASSERT_RTNL();
+
+	/* fasten the change in the switch */
+	if (bond_slave_can_tx(slave1)) {
+		alb_send_learning_packets(slave1, slave1->dev->dev_addr, false);
+		if (bond->alb_info.rlb_enabled) {
+			/* inform the clients that the mac address
+			 * has changed
+			 */
+			rlb_req_update_slave_clients(bond, slave1);
+		}
+	} else {
+		disabled_slave = slave1;
+	}
+
+	if (bond_slave_can_tx(slave2)) {
+		alb_send_learning_packets(slave2, slave2->dev->dev_addr, false);
+		if (bond->alb_info.rlb_enabled) {
+			/* inform the clients that the mac address
+			 * has changed
+			 */
+			rlb_req_update_slave_clients(bond, slave2);
+		}
+	} else {
+		disabled_slave = slave2;
+	}
+
+	if (bond->alb_info.rlb_enabled && slaves_state_differ) {
+		/* A disabled slave was assigned an active mac addr */
+		rlb_teach_disabled_mac_on_primary(bond,
+						  disabled_slave->dev->dev_addr);
+	}
+}
+
+/**
+ * alb_change_hw_addr_on_detach
+ * @bond: bonding we're working on
+ * @slave: the slave that was just detached
+ *
+ * We assume that @slave was already detached from the slave list.
+ *
+ * If @slave's permanent hw address is different both from its current
+ * address and from @bond's address, then somewhere in the bond there's
+ * a slave that has @slave's permanet address as its current address.
+ * We'll make sure that that slave no longer uses @slave's permanent address.
+ *
+ * Caller must hold RTNL and no other locks
+ */
+static void alb_change_hw_addr_on_detach(struct bonding *bond, struct slave *slave)
+{
+	int perm_curr_diff;
+	int perm_bond_diff;
+	struct slave *found_slave;
+
+	perm_curr_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
+						  slave->dev->dev_addr);
+	perm_bond_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
+						  bond->dev->dev_addr);
+
+	if (perm_curr_diff && perm_bond_diff) {
+		found_slave = bond_slave_has_mac(bond, slave->perm_hwaddr);
+
+		if (found_slave) {
+			alb_swap_mac_addr(slave, found_slave);
+			alb_fasten_mac_swap(bond, slave, found_slave);
+		}
+	}
+}
+
+/**
+ * alb_handle_addr_collision_on_attach
+ * @bond: bonding we're working on
+ * @slave: the slave that was just attached
+ *
+ * checks uniqueness of slave's mac address and handles the case the
+ * new slave uses the bonds mac address.
+ *
+ * If the permanent hw address of @slave is @bond's hw address, we need to
+ * find a different hw address to give @slave, that isn't in use by any other
+ * slave in the bond. This address must be, of course, one of the permanent
+ * addresses of the other slaves.
+ *
+ * We go over the slave list, and for each slave there we compare its
+ * permanent hw address with the current address of all the other slaves.
+ * If no match was found, then we've found a slave with a permanent address
+ * that isn't used by any other slave in the bond, so we can assign it to
+ * @slave.
+ *
+ * assumption: this function is called before @slave is attached to the
+ *	       bond slave list.
+ */
+static int alb_handle_addr_collision_on_attach(struct bonding *bond, struct slave *slave)
+{
+	struct slave *has_bond_addr = rcu_access_pointer(bond->curr_active_slave);
+	struct slave *tmp_slave1, *free_mac_slave = NULL;
+	struct list_head *iter;
+
+	if (!bond_has_slaves(bond)) {
+		/* this is the first slave */
+		return 0;
+	}
+
+	/* if slave's mac address differs from bond's mac address
+	 * check uniqueness of slave's mac address against the other
+	 * slaves in the bond.
+	 */
+	if (!ether_addr_equal_64bits(slave->perm_hwaddr, bond->dev->dev_addr)) {
+		if (!bond_slave_has_mac(bond, slave->dev->dev_addr))
+			return 0;
+
+		/* Try setting slave mac to bond address and fall-through
+		 * to code handling that situation below...
+		 */
+		alb_set_slave_mac_addr(slave, bond->dev->dev_addr,
+				       bond->dev->addr_len);
+	}
+
+	/* The slave's address is equal to the address of the bond.
+	 * Search for a spare address in the bond for this slave.
+	 */
+	bond_for_each_slave(bond, tmp_slave1, iter) {
+		if (!bond_slave_has_mac(bond, tmp_slave1->perm_hwaddr)) {
+			/* no slave has tmp_slave1's perm addr
+			 * as its curr addr
+			 */
+			free_mac_slave = tmp_slave1;
+			break;
+		}
+
+		if (!has_bond_addr) {
+			if (ether_addr_equal_64bits(tmp_slave1->dev->dev_addr,
+						    bond->dev->dev_addr)) {
+
+				has_bond_addr = tmp_slave1;
+			}
+		}
+	}
+
+	if (free_mac_slave) {
+		alb_set_slave_mac_addr(slave, free_mac_slave->perm_hwaddr,
+				       free_mac_slave->dev->addr_len);
+
+		netdev_warn(bond->dev, "the hw address of slave %s is in use by the bond; giving it the hw address of %s\n",
+			    slave->dev->name, free_mac_slave->dev->name);
+
+	} else if (has_bond_addr) {
+		netdev_err(bond->dev, "the hw address of slave %s is in use by the bond; couldn't find a slave with a free hw address to give it (this should not have happened)\n",
+			   slave->dev->name);
+		return -EFAULT;
+	}
+
+	return 0;
+}
+
+/**
+ * alb_set_mac_address
+ * @bond:
+ * @addr:
+ *
+ * In TLB mode all slaves are configured to the bond's hw address, but set
+ * their dev_addr field to different addresses (based on their permanent hw
+ * addresses).
+ *
+ * For each slave, this function sets the interface to the new address and then
+ * changes its dev_addr field to its previous value.
+ *
+ * Unwinding assumes bond's mac address has not yet changed.
+ */
+static int alb_set_mac_address(struct bonding *bond, void *addr)
+{
+	struct slave *slave, *rollback_slave;
+	struct list_head *iter;
+	struct sockaddr_storage ss;
+	char tmp_addr[MAX_ADDR_LEN];
+	int res;
+
+	if (bond->alb_info.rlb_enabled)
+		return 0;
+
+	bond_for_each_slave(bond, slave, iter) {
+		/* save net_device's current hw address */
+		bond_hw_addr_copy(tmp_addr, slave->dev->dev_addr,
+				  slave->dev->addr_len);
+
+		res = dev_set_mac_address(slave->dev, addr);
+
+		/* restore net_device's hw address */
+		bond_hw_addr_copy(slave->dev->dev_addr, tmp_addr,
+				  slave->dev->addr_len);
+
+		if (res)
+			goto unwind;
+	}
+
+	return 0;
+
+unwind:
+	memcpy(ss.__data, bond->dev->dev_addr, bond->dev->addr_len);
+	ss.ss_family = bond->dev->type;
+
+	/* unwind from head to the slave that failed */
+	bond_for_each_slave(bond, rollback_slave, iter) {
+		if (rollback_slave == slave)
+			break;
+		bond_hw_addr_copy(tmp_addr, rollback_slave->dev->dev_addr,
+				  rollback_slave->dev->addr_len);
+		dev_set_mac_address(rollback_slave->dev,
+				    (struct sockaddr *)&ss);
+		bond_hw_addr_copy(rollback_slave->dev->dev_addr, tmp_addr,
+				  rollback_slave->dev->addr_len);
+	}
+
+	return res;
+}
+
+/************************ exported alb funcions ************************/
+
+int bond_alb_initialize(struct bonding *bond, int rlb_enabled)
+{
+	int res;
+
+	res = tlb_initialize(bond);
+	if (res)
+		return res;
+
+	if (rlb_enabled) {
+		bond->alb_info.rlb_enabled = 1;
+		res = rlb_initialize(bond);
+		if (res) {
+			tlb_deinitialize(bond);
+			return res;
+		}
+	} else {
+		bond->alb_info.rlb_enabled = 0;
+	}
+
+	return 0;
+}
+
+void bond_alb_deinitialize(struct bonding *bond)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+
+	tlb_deinitialize(bond);
+
+	if (bond_info->rlb_enabled)
+		rlb_deinitialize(bond);
+}
+
+static netdev_tx_t bond_do_alb_xmit(struct sk_buff *skb, struct bonding *bond,
+				    struct slave *tx_slave)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct ethhdr *eth_data = eth_hdr(skb);
+
+	if (!tx_slave) {
+		/* unbalanced or unassigned, send through primary */
+		tx_slave = rcu_dereference(bond->curr_active_slave);
+		if (bond->params.tlb_dynamic_lb)
+			bond_info->unbalanced_load += skb->len;
+	}
+
+	if (tx_slave && bond_slave_can_tx(tx_slave)) {
+		if (tx_slave != rcu_access_pointer(bond->curr_active_slave)) {
+			ether_addr_copy(eth_data->h_source,
+					tx_slave->dev->dev_addr);
+		}
+
+		bond_dev_queue_xmit(bond, skb, tx_slave->dev);
+		goto out;
+	}
+
+	if (tx_slave && bond->params.tlb_dynamic_lb) {
+		spin_lock(&bond->mode_lock);
+		__tlb_clear_slave(bond, tx_slave, 0);
+		spin_unlock(&bond->mode_lock);
+	}
+
+	/* no suitable interface, frame not sent */
+	bond_tx_drop(bond->dev, skb);
+out:
+	return NETDEV_TX_OK;
+}
+
+netdev_tx_t bond_tlb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct ethhdr *eth_data;
+	struct slave *tx_slave = NULL;
+	u32 hash_index;
+
+	skb_reset_mac_header(skb);
+	eth_data = eth_hdr(skb);
+
+	/* Do not TX balance any multicast or broadcast */
+	if (!is_multicast_ether_addr(eth_data->h_dest)) {
+		switch (skb->protocol) {
+		case htons(ETH_P_IP):
+		case htons(ETH_P_IPX):
+		    /* In case of IPX, it will falback to L2 hash */
+		case htons(ETH_P_IPV6):
+			hash_index = bond_xmit_hash(bond, skb);
+			if (bond->params.tlb_dynamic_lb) {
+				tx_slave = tlb_choose_channel(bond,
+							      hash_index & 0xFF,
+							      skb->len);
+			} else {
+				struct bond_up_slave *slaves;
+				unsigned int count;
+
+				slaves = rcu_dereference(bond->slave_arr);
+				count = slaves ? READ_ONCE(slaves->count) : 0;
+				if (likely(count))
+					tx_slave = slaves->arr[hash_index %
+							       count];
+			}
+			break;
+		}
+	}
+	return bond_do_alb_xmit(skb, bond, tx_slave);
+}
+
+netdev_tx_t bond_alb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct ethhdr *eth_data;
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct slave *tx_slave = NULL;
+	static const __be32 ip_bcast = htonl(0xffffffff);
+	int hash_size = 0;
+	bool do_tx_balance = true;
+	u32 hash_index = 0;
+	const u8 *hash_start = NULL;
+
+	skb_reset_mac_header(skb);
+	eth_data = eth_hdr(skb);
+
+	switch (ntohs(skb->protocol)) {
+	case ETH_P_IP: {
+		const struct iphdr *iph;
+
+		if (is_broadcast_ether_addr(eth_data->h_dest) ||
+		    !pskb_network_may_pull(skb, sizeof(*iph))) {
+			do_tx_balance = false;
+			break;
+		}
+		iph = ip_hdr(skb);
+		if (iph->daddr == ip_bcast || iph->protocol == IPPROTO_IGMP) {
+			do_tx_balance = false;
+			break;
+		}
+		hash_start = (char *)&(iph->daddr);
+		hash_size = sizeof(iph->daddr);
+		break;
+	}
+	case ETH_P_IPV6: {
+		const struct ipv6hdr *ip6hdr;
+
+		/* IPv6 doesn't really use broadcast mac address, but leave
+		 * that here just in case.
+		 */
+		if (is_broadcast_ether_addr(eth_data->h_dest)) {
+			do_tx_balance = false;
+			break;
+		}
+
+		/* IPv6 uses all-nodes multicast as an equivalent to
+		 * broadcasts in IPv4.
+		 */
+		if (ether_addr_equal_64bits(eth_data->h_dest, mac_v6_allmcast)) {
+			do_tx_balance = false;
+			break;
+		}
+
+		if (!pskb_network_may_pull(skb, sizeof(*ip6hdr))) {
+			do_tx_balance = false;
+			break;
+		}
+		/* Additionally, DAD probes should not be tx-balanced as that
+		 * will lead to false positives for duplicate addresses and
+		 * prevent address configuration from working.
+		 */
+		ip6hdr = ipv6_hdr(skb);
+		if (ipv6_addr_any(&ip6hdr->saddr)) {
+			do_tx_balance = false;
+			break;
+		}
+
+		hash_start = (char *)&ip6hdr->daddr;
+		hash_size = sizeof(ip6hdr->daddr);
+		break;
+	}
+	case ETH_P_IPX: {
+		const struct ipxhdr *ipxhdr;
+
+		if (pskb_network_may_pull(skb, sizeof(*ipxhdr))) {
+			do_tx_balance = false;
+			break;
+		}
+		ipxhdr = (struct ipxhdr *)skb_network_header(skb);
+
+		if (ipxhdr->ipx_checksum != IPX_NO_CHECKSUM) {
+			/* something is wrong with this packet */
+			do_tx_balance = false;
+			break;
+		}
+
+		if (ipxhdr->ipx_type != IPX_TYPE_NCP) {
+			/* The only protocol worth balancing in
+			 * this family since it has an "ARP" like
+			 * mechanism
+			 */
+			do_tx_balance = false;
+			break;
+		}
+
+		eth_data = eth_hdr(skb);
+		hash_start = (char *)eth_data->h_dest;
+		hash_size = ETH_ALEN;
+		break;
+	}
+	case ETH_P_ARP:
+		do_tx_balance = false;
+		if (bond_info->rlb_enabled)
+			tx_slave = rlb_arp_xmit(skb, bond);
+		break;
+	default:
+		do_tx_balance = false;
+		break;
+	}
+
+	if (do_tx_balance) {
+		if (bond->params.tlb_dynamic_lb) {
+			hash_index = _simple_hash(hash_start, hash_size);
+			tx_slave = tlb_choose_channel(bond, hash_index, skb->len);
+		} else {
+			/*
+			 * do_tx_balance means we are free to select the tx_slave
+			 * So we do exactly what tlb would do for hash selection
+			 */
+
+			struct bond_up_slave *slaves;
+			unsigned int count;
+
+			slaves = rcu_dereference(bond->slave_arr);
+			count = slaves ? READ_ONCE(slaves->count) : 0;
+			if (likely(count))
+				tx_slave = slaves->arr[bond_xmit_hash(bond, skb) %
+						       count];
+		}
+	}
+
+	return bond_do_alb_xmit(skb, bond, tx_slave);
+}
+
+void bond_alb_monitor(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    alb_work.work);
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct list_head *iter;
+	struct slave *slave;
+
+	if (!bond_has_slaves(bond)) {
+		bond_info->tx_rebalance_counter = 0;
+		bond_info->lp_counter = 0;
+		goto re_arm;
+	}
+
+	rcu_read_lock();
+
+	bond_info->tx_rebalance_counter++;
+	bond_info->lp_counter++;
+
+	/* send learning packets */
+	if (bond_info->lp_counter >= BOND_ALB_LP_TICKS(bond)) {
+		bool strict_match;
+
+		bond_for_each_slave_rcu(bond, slave, iter) {
+			/* If updating current_active, use all currently
+			 * user mac addreses (!strict_match).  Otherwise, only
+			 * use mac of the slave device.
+			 * In RLB mode, we always use strict matches.
+			 */
+			strict_match = (slave != rcu_access_pointer(bond->curr_active_slave) ||
+					bond_info->rlb_enabled);
+			alb_send_learning_packets(slave, slave->dev->dev_addr,
+						  strict_match);
+		}
+		bond_info->lp_counter = 0;
+	}
+
+	/* rebalance tx traffic */
+	if (bond_info->tx_rebalance_counter >= BOND_TLB_REBALANCE_TICKS) {
+		bond_for_each_slave_rcu(bond, slave, iter) {
+			tlb_clear_slave(bond, slave, 1);
+			if (slave == rcu_access_pointer(bond->curr_active_slave)) {
+				SLAVE_TLB_INFO(slave).load =
+					bond_info->unbalanced_load /
+						BOND_TLB_REBALANCE_INTERVAL;
+				bond_info->unbalanced_load = 0;
+			}
+		}
+		bond_info->tx_rebalance_counter = 0;
+	}
+
+	if (bond_info->rlb_enabled) {
+		if (bond_info->primary_is_promisc &&
+		    (++bond_info->rlb_promisc_timeout_counter >= RLB_PROMISC_TIMEOUT)) {
+
+			/* dev_set_promiscuity requires rtnl and
+			 * nothing else.  Avoid race with bond_close.
+			 */
+			rcu_read_unlock();
+			if (!rtnl_trylock())
+				goto re_arm;
+
+			bond_info->rlb_promisc_timeout_counter = 0;
+
+			/* If the primary was set to promiscuous mode
+			 * because a slave was disabled then
+			 * it can now leave promiscuous mode.
+			 */
+			dev_set_promiscuity(rtnl_dereference(bond->curr_active_slave)->dev,
+					    -1);
+			bond_info->primary_is_promisc = 0;
+
+			rtnl_unlock();
+			rcu_read_lock();
+		}
+
+		if (bond_info->rlb_rebalance) {
+			bond_info->rlb_rebalance = 0;
+			rlb_rebalance(bond);
+		}
+
+		/* check if clients need updating */
+		if (bond_info->rx_ntt) {
+			if (bond_info->rlb_update_delay_counter) {
+				--bond_info->rlb_update_delay_counter;
+			} else {
+				rlb_update_rx_clients(bond);
+				if (bond_info->rlb_update_retry_counter)
+					--bond_info->rlb_update_retry_counter;
+				else
+					bond_info->rx_ntt = 0;
+			}
+		}
+	}
+	rcu_read_unlock();
+re_arm:
+	queue_delayed_work(bond->wq, &bond->alb_work, alb_delta_in_ticks);
+}
+
+/* assumption: called before the slave is attached to the bond
+ * and not locked by the bond lock
+ */
+int bond_alb_init_slave(struct bonding *bond, struct slave *slave)
+{
+	int res;
+
+	res = alb_set_slave_mac_addr(slave, slave->perm_hwaddr,
+				     slave->dev->addr_len);
+	if (res)
+		return res;
+
+	res = alb_handle_addr_collision_on_attach(bond, slave);
+	if (res)
+		return res;
+
+	tlb_init_slave(slave);
+
+	/* order a rebalance ASAP */
+	bond->alb_info.tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
+
+	if (bond->alb_info.rlb_enabled)
+		bond->alb_info.rlb_rebalance = 1;
+
+	return 0;
+}
+
+/* Remove slave from tlb and rlb hash tables, and fix up MAC addresses
+ * if necessary.
+ *
+ * Caller must hold RTNL and no other locks
+ */
+void bond_alb_deinit_slave(struct bonding *bond, struct slave *slave)
+{
+	if (bond_has_slaves(bond))
+		alb_change_hw_addr_on_detach(bond, slave);
+
+	tlb_clear_slave(bond, slave, 0);
+
+	if (bond->alb_info.rlb_enabled) {
+		bond->alb_info.rx_slave = NULL;
+		rlb_clear_slave(bond, slave);
+	}
+
+}
+
+void bond_alb_handle_link_change(struct bonding *bond, struct slave *slave, char link)
+{
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+
+	if (link == BOND_LINK_DOWN) {
+		tlb_clear_slave(bond, slave, 0);
+		if (bond->alb_info.rlb_enabled)
+			rlb_clear_slave(bond, slave);
+	} else if (link == BOND_LINK_UP) {
+		/* order a rebalance ASAP */
+		bond_info->tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
+		if (bond->alb_info.rlb_enabled) {
+			bond->alb_info.rlb_rebalance = 1;
+			/* If the updelay module parameter is smaller than the
+			 * forwarding delay of the switch the rebalance will
+			 * not work because the rebalance arp replies will
+			 * not be forwarded to the clients..
+			 */
+		}
+	}
+
+	if (bond_is_nondyn_tlb(bond)) {
+		if (bond_update_slave_arr(bond, NULL))
+			pr_err("Failed to build slave-array for TLB mode.\n");
+	}
+}
+
+/**
+ * bond_alb_handle_active_change - assign new curr_active_slave
+ * @bond: our bonding struct
+ * @new_slave: new slave to assign
+ *
+ * Set the bond->curr_active_slave to @new_slave and handle
+ * mac address swapping and promiscuity changes as needed.
+ *
+ * Caller must hold RTNL
+ */
+void bond_alb_handle_active_change(struct bonding *bond, struct slave *new_slave)
+{
+	struct slave *swap_slave;
+	struct slave *curr_active;
+
+	curr_active = rtnl_dereference(bond->curr_active_slave);
+	if (curr_active == new_slave)
+		return;
+
+	if (curr_active && bond->alb_info.primary_is_promisc) {
+		dev_set_promiscuity(curr_active->dev, -1);
+		bond->alb_info.primary_is_promisc = 0;
+		bond->alb_info.rlb_promisc_timeout_counter = 0;
+	}
+
+	swap_slave = curr_active;
+	rcu_assign_pointer(bond->curr_active_slave, new_slave);
+
+	if (!new_slave || !bond_has_slaves(bond))
+		return;
+
+	/* set the new curr_active_slave to the bonds mac address
+	 * i.e. swap mac addresses of old curr_active_slave and new curr_active_slave
+	 */
+	if (!swap_slave)
+		swap_slave = bond_slave_has_mac(bond, bond->dev->dev_addr);
+
+	/* Arrange for swap_slave and new_slave to temporarily be
+	 * ignored so we can mess with their MAC addresses without
+	 * fear of interference from transmit activity.
+	 */
+	if (swap_slave)
+		tlb_clear_slave(bond, swap_slave, 1);
+	tlb_clear_slave(bond, new_slave, 1);
+
+	/* in TLB mode, the slave might flip down/up with the old dev_addr,
+	 * and thus filter bond->dev_addr's packets, so force bond's mac
+	 */
+	if (BOND_MODE(bond) == BOND_MODE_TLB) {
+		struct sockaddr_storage ss;
+		u8 tmp_addr[MAX_ADDR_LEN];
+
+		bond_hw_addr_copy(tmp_addr, new_slave->dev->dev_addr,
+				  new_slave->dev->addr_len);
+
+		bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
+				  bond->dev->addr_len);
+		ss.ss_family = bond->dev->type;
+		/* we don't care if it can't change its mac, best effort */
+		dev_set_mac_address(new_slave->dev, (struct sockaddr *)&ss);
+
+		bond_hw_addr_copy(new_slave->dev->dev_addr, tmp_addr,
+				  new_slave->dev->addr_len);
+	}
+
+	/* curr_active_slave must be set before calling alb_swap_mac_addr */
+	if (swap_slave) {
+		/* swap mac address */
+		alb_swap_mac_addr(swap_slave, new_slave);
+		alb_fasten_mac_swap(bond, swap_slave, new_slave);
+	} else {
+		/* set the new_slave to the bond mac address */
+		alb_set_slave_mac_addr(new_slave, bond->dev->dev_addr,
+				       bond->dev->addr_len);
+		alb_send_learning_packets(new_slave, bond->dev->dev_addr,
+					  false);
+	}
+}
+
+/* Called with RTNL */
+int bond_alb_set_mac_address(struct net_device *bond_dev, void *addr)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct sockaddr_storage *ss = addr;
+	struct slave *curr_active;
+	struct slave *swap_slave;
+	int res;
+
+	if (!is_valid_ether_addr(ss->__data))
+		return -EADDRNOTAVAIL;
+
+	res = alb_set_mac_address(bond, addr);
+	if (res)
+		return res;
+
+	bond_hw_addr_copy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
+
+	/* If there is no curr_active_slave there is nothing else to do.
+	 * Otherwise we'll need to pass the new address to it and handle
+	 * duplications.
+	 */
+	curr_active = rtnl_dereference(bond->curr_active_slave);
+	if (!curr_active)
+		return 0;
+
+	swap_slave = bond_slave_has_mac(bond, bond_dev->dev_addr);
+
+	if (swap_slave) {
+		alb_swap_mac_addr(swap_slave, curr_active);
+		alb_fasten_mac_swap(bond, swap_slave, curr_active);
+	} else {
+		alb_set_slave_mac_addr(curr_active, bond_dev->dev_addr,
+				       bond_dev->addr_len);
+
+		alb_send_learning_packets(curr_active,
+					  bond_dev->dev_addr, false);
+		if (bond->alb_info.rlb_enabled) {
+			/* inform clients mac address has changed */
+			rlb_req_update_slave_clients(bond, curr_active);
+		}
+	}
+
+	return 0;
+}
+
+void bond_alb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
+{
+	if (bond->alb_info.rlb_enabled)
+		rlb_clear_vlan(bond, vlan_id);
+}
+
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.164/bond_debugfs.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.164/bond_debugfs.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,142 @@
+// SPDX-License-Identifier: GPL-2.0
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/netdevice.h>
+
+#include <net/bonding.h>
+#include <net/bond_alb.h>
+
+#if defined(CONFIG_DEBUG_FS) && !defined(CONFIG_NET_NS)
+
+#include <linux/debugfs.h>
+#include <linux/seq_file.h>
+
+static struct dentry *bonding_debug_root;
+
+/* Show RLB hash table */
+static int bond_debug_rlb_hash_show(struct seq_file *m, void *v)
+{
+	struct bonding *bond = m->private;
+	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
+	struct rlb_client_info *client_info;
+	u32 hash_index;
+
+	if (BOND_MODE(bond) != BOND_MODE_ALB)
+		return 0;
+
+	seq_printf(m, "SourceIP        DestinationIP   "
+			"Destination MAC   DEV\n");
+
+	spin_lock_bh(&bond->mode_lock);
+
+	hash_index = bond_info->rx_hashtbl_used_head;
+	for (; hash_index != RLB_NULL_INDEX;
+	     hash_index = client_info->used_next) {
+		client_info = &(bond_info->rx_hashtbl[hash_index]);
+		seq_printf(m, "%-15pI4 %-15pI4 %-17pM %s\n",
+			&client_info->ip_src,
+			&client_info->ip_dst,
+			&client_info->mac_dst,
+			client_info->slave->dev->name);
+	}
+
+	spin_unlock_bh(&bond->mode_lock);
+
+	return 0;
+}
+
+static int bond_debug_rlb_hash_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, bond_debug_rlb_hash_show, inode->i_private);
+}
+
+static const struct file_operations bond_debug_rlb_hash_fops = {
+	.owner		= THIS_MODULE,
+	.open		= bond_debug_rlb_hash_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+void bond_debug_register(struct bonding *bond)
+{
+	if (!bonding_debug_root)
+		return;
+
+	bond->debug_dir =
+		debugfs_create_dir(bond->dev->name, bonding_debug_root);
+
+	if (!bond->debug_dir) {
+		netdev_warn(bond->dev, "failed to register to debugfs\n");
+		return;
+	}
+
+	debugfs_create_file("rlb_hash_table", 0400, bond->debug_dir,
+				bond, &bond_debug_rlb_hash_fops);
+}
+
+void bond_debug_unregister(struct bonding *bond)
+{
+	if (!bonding_debug_root)
+		return;
+
+	debugfs_remove_recursive(bond->debug_dir);
+}
+
+void bond_debug_reregister(struct bonding *bond)
+{
+	struct dentry *d;
+
+	if (!bonding_debug_root)
+		return;
+
+	d = debugfs_rename(bonding_debug_root, bond->debug_dir,
+			   bonding_debug_root, bond->dev->name);
+	if (d) {
+		bond->debug_dir = d;
+	} else {
+		netdev_warn(bond->dev, "failed to reregister, so just unregister old one\n");
+		bond_debug_unregister(bond);
+	}
+}
+
+void bond_create_debugfs(void)
+{
+	bonding_debug_root = debugfs_create_dir("bonding", NULL);
+
+	if (!bonding_debug_root) {
+		pr_warn("Warning: Cannot create bonding directory in debugfs\n");
+	}
+}
+
+void bond_destroy_debugfs(void)
+{
+	debugfs_remove_recursive(bonding_debug_root);
+	bonding_debug_root = NULL;
+}
+
+
+#else /* !CONFIG_DEBUG_FS */
+
+void bond_debug_register(struct bonding *bond)
+{
+}
+
+void bond_debug_unregister(struct bonding *bond)
+{
+}
+
+void bond_debug_reregister(struct bonding *bond)
+{
+}
+
+void bond_create_debugfs(void)
+{
+}
+
+void bond_destroy_debugfs(void)
+{
+}
+
+#endif /* CONFIG_DEBUG_FS */
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.164/bond_main.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.164/bond_main.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,5100 @@
+/*
+ * originally based on the dummy device.
+ *
+ * Copyright 1999, Thomas Davis, tadavis@lbl.gov.
+ * Licensed under the GPL. Based on dummy.c, and eql.c devices.
+ *
+ * bonding.c: an Ethernet Bonding driver
+ *
+ * This is useful to talk to a Cisco EtherChannel compatible equipment:
+ *	Cisco 5500
+ *	Sun Trunking (Solaris)
+ *	Alteon AceDirector Trunks
+ *	Linux Bonding
+ *	and probably many L2 switches ...
+ *
+ * How it works:
+ *    ifconfig bond0 ipaddress netmask up
+ *      will setup a network device, with an ip address.  No mac address
+ *	will be assigned at this time.  The hw mac address will come from
+ *	the first slave bonded to the channel.  All slaves will then use
+ *	this hw mac address.
+ *
+ *    ifconfig bond0 down
+ *         will release all slaves, marking them as down.
+ *
+ *    ifenslave bond0 eth0
+ *	will attach eth0 to bond0 as a slave.  eth0 hw mac address will either
+ *	a: be used as initial mac address
+ *	b: if a hw mac address already is there, eth0's hw mac address
+ *	   will then be set from bond0.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/fcntl.h>
+#include <linux/interrupt.h>
+#include <linux/ptrace.h>
+#include <linux/ioport.h>
+#include <linux/in.h>
+#include <net/ip.h>
+#include <linux/ip.h>
+#include <linux/tcp.h>
+#include <linux/udp.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/init.h>
+#include <linux/timer.h>
+#include <linux/socket.h>
+#include <linux/ctype.h>
+#include <linux/inet.h>
+#include <linux/bitops.h>
+#include <linux/io.h>
+#include <asm/dma.h>
+#include <linux/uaccess.h>
+#include <linux/errno.h>
+#include <linux/netdevice.h>
+#include <linux/inetdevice.h>
+#include <linux/igmp.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <net/sock.h>
+#include <linux/rtnetlink.h>
+#include <linux/smp.h>
+#include <linux/if_ether.h>
+#include <net/arp.h>
+#include <linux/mii.h>
+#include <linux/ethtool.h>
+#include <linux/if_vlan.h>
+#include <linux/if_bonding.h>
+#include <linux/jiffies.h>
+#include <linux/preempt.h>
+#include <net/route.h>
+#include <net/net_namespace.h>
+#include <net/netns/generic.h>
+#include <net/pkt_sched.h>
+#include <linux/rculist.h>
+#include <linux/toedev.h>
+#include <net/flow_dissector.h>
+#include <net/switchdev.h>
+#include <net/bonding.h>
+#include <net/bond_3ad.h>
+#include <net/bond_alb.h>
+
+#include "bonding_priv.h"
+
+/*---------------------------- Module parameters ----------------------------*/
+
+/* monitor all links that often (in milliseconds). <=0 disables monitoring */
+
+static int max_bonds	= BOND_DEFAULT_MAX_BONDS;
+static int tx_queues	= BOND_DEFAULT_TX_QUEUES;
+static int num_peer_notif = 1;
+static int miimon;
+static int updelay;
+static int downdelay;
+static int use_carrier	= 1;
+static char *mode;
+static char *primary;
+static char *primary_reselect;
+static char *lacp_rate;
+static int min_links;
+static char *ad_select;
+static char *xmit_hash_policy;
+static int arp_interval;
+static char *arp_ip_target[BOND_MAX_ARP_TARGETS];
+static char *arp_validate;
+static char *arp_all_targets;
+static char *fail_over_mac;
+static int all_slaves_active;
+static struct bond_params bonding_defaults;
+static int resend_igmp = BOND_DEFAULT_RESEND_IGMP;
+static int packets_per_slave = 1;
+static int lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
+
+module_param(max_bonds, int, 0);
+MODULE_PARM_DESC(max_bonds, "Max number of bonded devices");
+module_param(tx_queues, int, 0);
+MODULE_PARM_DESC(tx_queues, "Max number of transmit queues (default = 16)");
+module_param_named(num_grat_arp, num_peer_notif, int, 0644);
+MODULE_PARM_DESC(num_grat_arp, "Number of peer notifications to send on "
+			       "failover event (alias of num_unsol_na)");
+module_param_named(num_unsol_na, num_peer_notif, int, 0644);
+MODULE_PARM_DESC(num_unsol_na, "Number of peer notifications to send on "
+			       "failover event (alias of num_grat_arp)");
+module_param(miimon, int, 0);
+MODULE_PARM_DESC(miimon, "Link check interval in milliseconds");
+module_param(updelay, int, 0);
+MODULE_PARM_DESC(updelay, "Delay before considering link up, in milliseconds");
+module_param(downdelay, int, 0);
+MODULE_PARM_DESC(downdelay, "Delay before considering link down, "
+			    "in milliseconds");
+module_param(use_carrier, int, 0);
+MODULE_PARM_DESC(use_carrier, "Use netif_carrier_ok (vs MII ioctls) in miimon; "
+			      "0 for off, 1 for on (default)");
+module_param(mode, charp, 0);
+MODULE_PARM_DESC(mode, "Mode of operation; 0 for balance-rr, "
+		       "1 for active-backup, 2 for balance-xor, "
+		       "3 for broadcast, 4 for 802.3ad, 5 for balance-tlb, "
+		       "6 for balance-alb");
+module_param(primary, charp, 0);
+MODULE_PARM_DESC(primary, "Primary network device to use");
+module_param(primary_reselect, charp, 0);
+MODULE_PARM_DESC(primary_reselect, "Reselect primary slave "
+				   "once it comes up; "
+				   "0 for always (default), "
+				   "1 for only if speed of primary is "
+				   "better, "
+				   "2 for only on active slave "
+				   "failure");
+module_param(lacp_rate, charp, 0);
+MODULE_PARM_DESC(lacp_rate, "LACPDU tx rate to request from 802.3ad partner; "
+			    "0 for slow, 1 for fast");
+module_param(ad_select, charp, 0);
+MODULE_PARM_DESC(ad_select, "802.3ad aggregation selection logic; "
+			    "0 for stable (default), 1 for bandwidth, "
+			    "2 for count");
+module_param(min_links, int, 0);
+MODULE_PARM_DESC(min_links, "Minimum number of available links before turning on carrier");
+
+module_param(xmit_hash_policy, charp, 0);
+MODULE_PARM_DESC(xmit_hash_policy, "balance-alb, balance-tlb, balance-xor, 802.3ad hashing method; "
+				   "0 for layer 2 (default), 1 for layer 3+4, "
+				   "2 for layer 2+3, 3 for encap layer 2+3, "
+				   "4 for encap layer 3+4");
+module_param(arp_interval, int, 0);
+MODULE_PARM_DESC(arp_interval, "arp interval in milliseconds");
+module_param_array(arp_ip_target, charp, NULL, 0);
+MODULE_PARM_DESC(arp_ip_target, "arp targets in n.n.n.n form");
+module_param(arp_validate, charp, 0);
+MODULE_PARM_DESC(arp_validate, "validate src/dst of ARP probes; "
+			       "0 for none (default), 1 for active, "
+			       "2 for backup, 3 for all");
+module_param(arp_all_targets, charp, 0);
+MODULE_PARM_DESC(arp_all_targets, "fail on any/all arp targets timeout; 0 for any (default), 1 for all");
+module_param(fail_over_mac, charp, 0);
+MODULE_PARM_DESC(fail_over_mac, "For active-backup, do not set all slaves to "
+				"the same MAC; 0 for none (default), "
+				"1 for active, 2 for follow");
+module_param(all_slaves_active, int, 0);
+MODULE_PARM_DESC(all_slaves_active, "Keep all frames received on an interface "
+				     "by setting active flag for all slaves; "
+				     "0 for never (default), 1 for always.");
+module_param(resend_igmp, int, 0);
+MODULE_PARM_DESC(resend_igmp, "Number of IGMP membership reports to send on "
+			      "link failure");
+module_param(packets_per_slave, int, 0);
+MODULE_PARM_DESC(packets_per_slave, "Packets to send per slave in balance-rr "
+				    "mode; 0 for a random slave, 1 packet per "
+				    "slave (default), >1 packets per slave.");
+module_param(lp_interval, uint, 0);
+MODULE_PARM_DESC(lp_interval, "The number of seconds between instances where "
+			      "the bonding driver sends learning packets to "
+			      "each slaves peer switch. The default is 1.");
+
+/*----------------------------- Global variables ----------------------------*/
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+atomic_t netpoll_block_tx = ATOMIC_INIT(0);
+#endif
+
+unsigned int bond_net_id __read_mostly;
+
+/*-------------------------- Forward declarations ---------------------------*/
+
+static int bond_init(struct net_device *bond_dev);
+static void bond_uninit(struct net_device *bond_dev);
+static void bond_get_stats(struct net_device *bond_dev,
+			   struct rtnl_link_stats64 *stats);
+static void bond_slave_arr_handler(struct work_struct *work);
+static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
+				  int mod);
+static void bond_netdev_notify_work(struct work_struct *work);
+
+/*---------------------------- General routines -----------------------------*/
+
+const char *bond_mode_name(int mode)
+{
+	static const char *names[] = {
+		[BOND_MODE_ROUNDROBIN] = "load balancing (round-robin)",
+		[BOND_MODE_ACTIVEBACKUP] = "fault-tolerance (active-backup)",
+		[BOND_MODE_XOR] = "load balancing (xor)",
+		[BOND_MODE_BROADCAST] = "fault-tolerance (broadcast)",
+		[BOND_MODE_8023AD] = "IEEE 802.3ad Dynamic link aggregation",
+		[BOND_MODE_TLB] = "transmit load balancing",
+		[BOND_MODE_ALB] = "adaptive load balancing",
+	};
+
+	if (mode < BOND_MODE_ROUNDROBIN || mode > BOND_MODE_ALB)
+		return "unknown";
+
+	return names[mode];
+}
+
+/*---------------------------------- VLAN -----------------------------------*/
+
+/**
+ * bond_dev_queue_xmit - Prepare skb for xmit.
+ *
+ * @bond: bond device that got this skb for tx.
+ * @skb: hw accel VLAN tagged skb to transmit
+ * @slave_dev: slave that is supposed to xmit this skbuff
+ */
+void bond_dev_queue_xmit(struct bonding *bond, struct sk_buff *skb,
+			struct net_device *slave_dev)
+{
+	skb->dev = slave_dev;
+
+	BUILD_BUG_ON(sizeof(skb->queue_mapping) !=
+		     sizeof(qdisc_skb_cb(skb)->slave_dev_queue_mapping));
+	skb_set_queue_mapping(skb, qdisc_skb_cb(skb)->slave_dev_queue_mapping);
+
+	if (unlikely(netpoll_tx_running(bond->dev)))
+		bond_netpoll_send_skb(bond_get_slave_by_dev(bond, slave_dev), skb);
+	else
+		dev_queue_xmit(skb);
+}
+
+/* In the following 2 functions, bond_vlan_rx_add_vid and bond_vlan_rx_kill_vid,
+ * We don't protect the slave list iteration with a lock because:
+ * a. This operation is performed in IOCTL context,
+ * b. The operation is protected by the RTNL semaphore in the 8021q code,
+ * c. Holding a lock with BH disabled while directly calling a base driver
+ *    entry point is generally a BAD idea.
+ *
+ * The design of synchronization/protection for this operation in the 8021q
+ * module is good for one or more VLAN devices over a single physical device
+ * and cannot be extended for a teaming solution like bonding, so there is a
+ * potential race condition here where a net device from the vlan group might
+ * be referenced (either by a base driver or the 8021q code) while it is being
+ * removed from the system. However, it turns out we're not making matters
+ * worse, and if it works for regular VLAN usage it will work here too.
+*/
+
+/**
+ * bond_vlan_rx_add_vid - Propagates adding an id to slaves
+ * @bond_dev: bonding net device that got called
+ * @vid: vlan id being added
+ */
+static int bond_vlan_rx_add_vid(struct net_device *bond_dev,
+				__be16 proto, u16 vid)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave, *rollback_slave;
+	struct list_head *iter;
+	int res;
+
+	bond_for_each_slave(bond, slave, iter) {
+		res = vlan_vid_add(slave->dev, proto, vid);
+		if (res)
+			goto unwind;
+	}
+
+	return 0;
+
+unwind:
+	/* unwind to the slave that failed */
+	bond_for_each_slave(bond, rollback_slave, iter) {
+		if (rollback_slave == slave)
+			break;
+
+		vlan_vid_del(rollback_slave->dev, proto, vid);
+	}
+
+	return res;
+}
+
+/**
+ * bond_vlan_rx_kill_vid - Propagates deleting an id to slaves
+ * @bond_dev: bonding net device that got called
+ * @vid: vlan id being removed
+ */
+static int bond_vlan_rx_kill_vid(struct net_device *bond_dev,
+				 __be16 proto, u16 vid)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	struct slave *slave;
+
+	bond_for_each_slave(bond, slave, iter)
+		vlan_vid_del(slave->dev, proto, vid);
+
+	if (bond_is_lb(bond))
+		bond_alb_clear_vlan(bond, vid);
+
+	return 0;
+}
+
+/*------------------------------- Link status -------------------------------*/
+
+/* Set the carrier state for the master according to the state of its
+ * slaves.  If any slaves are up, the master is up.  In 802.3ad mode,
+ * do special 802.3ad magic.
+ *
+ * Returns zero if carrier state does not change, nonzero if it does.
+ */
+int bond_set_carrier(struct bonding *bond)
+{
+	struct list_head *iter;
+	struct slave *slave;
+
+	if (!bond_has_slaves(bond))
+		goto down;
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD)
+		return bond_3ad_set_carrier(bond);
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (slave->link == BOND_LINK_UP) {
+			if (!netif_carrier_ok(bond->dev)) {
+				netif_carrier_on(bond->dev);
+				return 1;
+			}
+			return 0;
+		}
+	}
+
+down:
+	if (netif_carrier_ok(bond->dev)) {
+		netif_carrier_off(bond->dev);
+		return 1;
+	}
+	return 0;
+}
+
+/* Get link speed and duplex from the slave's base driver
+ * using ethtool. If for some reason the call fails or the
+ * values are invalid, set speed and duplex to -1,
+ * and return. Return 1 if speed or duplex settings are
+ * UNKNOWN; 0 otherwise.
+ */
+static int bond_update_speed_duplex(struct slave *slave)
+{
+	struct net_device *slave_dev = slave->dev;
+	struct ethtool_link_ksettings ecmd;
+	int res;
+
+	slave->speed = SPEED_UNKNOWN;
+	slave->duplex = DUPLEX_UNKNOWN;
+
+	res = __ethtool_get_link_ksettings(slave_dev, &ecmd);
+	if (res < 0)
+		return 1;
+	if (ecmd.base.speed == 0 || ecmd.base.speed == ((__u32)-1))
+		return 1;
+	switch (ecmd.base.duplex) {
+	case DUPLEX_FULL:
+	case DUPLEX_HALF:
+		break;
+	default:
+		return 1;
+	}
+
+	slave->speed = ecmd.base.speed;
+	slave->duplex = ecmd.base.duplex;
+
+	return 0;
+}
+
+const char *bond_slave_link_status(s8 link)
+{
+	switch (link) {
+	case BOND_LINK_UP:
+		return "up";
+	case BOND_LINK_FAIL:
+		return "going down";
+	case BOND_LINK_DOWN:
+		return "down";
+	case BOND_LINK_BACK:
+		return "going back";
+	default:
+		return "unknown";
+	}
+}
+
+/* if <dev> supports MII link status reporting, check its link status.
+ *
+ * We either do MII/ETHTOOL ioctls, or check netif_carrier_ok(),
+ * depending upon the setting of the use_carrier parameter.
+ *
+ * Return either BMSR_LSTATUS, meaning that the link is up (or we
+ * can't tell and just pretend it is), or 0, meaning that the link is
+ * down.
+ *
+ * If reporting is non-zero, instead of faking link up, return -1 if
+ * both ETHTOOL and MII ioctls fail (meaning the device does not
+ * support them).  If use_carrier is set, return whatever it says.
+ * It'd be nice if there was a good way to tell if a driver supports
+ * netif_carrier, but there really isn't.
+ */
+static int bond_check_dev_link(struct bonding *bond,
+			       struct net_device *slave_dev, int reporting)
+{
+	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
+	int (*ioctl)(struct net_device *, struct ifreq *, int);
+	struct ifreq ifr;
+	struct mii_ioctl_data *mii;
+
+	if (!reporting && !netif_running(slave_dev))
+		return 0;
+
+	if (bond->params.use_carrier)
+		return netif_carrier_ok(slave_dev) ? BMSR_LSTATUS : 0;
+
+	/* Try to get link status using Ethtool first. */
+	if (slave_dev->ethtool_ops->get_link)
+		return slave_dev->ethtool_ops->get_link(slave_dev) ?
+			BMSR_LSTATUS : 0;
+
+	/* Ethtool can't be used, fallback to MII ioctls. */
+	ioctl = slave_ops->ndo_do_ioctl;
+	if (ioctl) {
+		/* TODO: set pointer to correct ioctl on a per team member
+		 *       bases to make this more efficient. that is, once
+		 *       we determine the correct ioctl, we will always
+		 *       call it and not the others for that team
+		 *       member.
+		 */
+
+		/* We cannot assume that SIOCGMIIPHY will also read a
+		 * register; not all network drivers (e.g., e100)
+		 * support that.
+		 */
+
+		/* Yes, the mii is overlaid on the ifreq.ifr_ifru */
+		strncpy(ifr.ifr_name, slave_dev->name, IFNAMSIZ);
+		mii = if_mii(&ifr);
+		if (ioctl(slave_dev, &ifr, SIOCGMIIPHY) == 0) {
+			mii->reg_num = MII_BMSR;
+			if (ioctl(slave_dev, &ifr, SIOCGMIIREG) == 0)
+				return mii->val_out & BMSR_LSTATUS;
+		}
+	}
+
+	/* If reporting, report that either there's no dev->do_ioctl,
+	 * or both SIOCGMIIREG and get_link failed (meaning that we
+	 * cannot report link status).  If not reporting, pretend
+	 * we're ok.
+	 */
+	return reporting ? -1 : BMSR_LSTATUS;
+}
+
+/*----------------------------- Multicast list ------------------------------*/
+
+/* Push the promiscuity flag down to appropriate slaves */
+static int bond_set_promiscuity(struct bonding *bond, int inc)
+{
+	struct list_head *iter;
+	int err = 0;
+
+	if (bond_uses_primary(bond)) {
+		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
+
+		if (curr_active)
+			err = dev_set_promiscuity(curr_active->dev, inc);
+	} else {
+		struct slave *slave;
+
+		bond_for_each_slave(bond, slave, iter) {
+			err = dev_set_promiscuity(slave->dev, inc);
+			if (err)
+				return err;
+		}
+	}
+	return err;
+}
+
+/* Push the allmulti flag down to all slaves */
+static int bond_set_allmulti(struct bonding *bond, int inc)
+{
+	struct list_head *iter;
+	int err = 0;
+
+	if (bond_uses_primary(bond)) {
+		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
+
+		if (curr_active)
+			err = dev_set_allmulti(curr_active->dev, inc);
+	} else {
+		struct slave *slave;
+
+		bond_for_each_slave(bond, slave, iter) {
+			err = dev_set_allmulti(slave->dev, inc);
+			if (err)
+				return err;
+		}
+	}
+	return err;
+}
+
+/* Retrieve the list of registered multicast addresses for the bonding
+ * device and retransmit an IGMP JOIN request to the current active
+ * slave.
+ */
+static void bond_resend_igmp_join_requests_delayed(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    mcast_work.work);
+
+	if (!rtnl_trylock()) {
+		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
+		return;
+	}
+	call_netdevice_notifiers(NETDEV_RESEND_IGMP, bond->dev);
+
+	if (bond->igmp_retrans > 1) {
+		bond->igmp_retrans--;
+		queue_delayed_work(bond->wq, &bond->mcast_work, HZ/5);
+	}
+	rtnl_unlock();
+}
+
+/* Flush bond's hardware addresses from slave */
+static void bond_hw_addr_flush(struct net_device *bond_dev,
+			       struct net_device *slave_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+
+	dev_uc_unsync(slave_dev, bond_dev);
+	dev_mc_unsync(slave_dev, bond_dev);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		/* del lacpdu mc addr from mc list */
+		u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
+
+		dev_mc_del(slave_dev, lacpdu_multicast);
+	}
+}
+
+/*--------------------------- Active slave change ---------------------------*/
+
+/* Update the hardware address list and promisc/allmulti for the new and
+ * old active slaves (if any).  Modes that are not using primary keep all
+ * slaves up date at all times; only the modes that use primary need to call
+ * this function to swap these settings during a failover.
+ */
+static void bond_hw_addr_swap(struct bonding *bond, struct slave *new_active,
+			      struct slave *old_active)
+{
+	if (old_active) {
+		if (bond->dev->flags & IFF_PROMISC)
+			dev_set_promiscuity(old_active->dev, -1);
+
+		if (bond->dev->flags & IFF_ALLMULTI)
+			dev_set_allmulti(old_active->dev, -1);
+
+		bond_hw_addr_flush(bond->dev, old_active->dev);
+	}
+
+	if (new_active) {
+		/* FIXME: Signal errors upstream. */
+		if (bond->dev->flags & IFF_PROMISC)
+			dev_set_promiscuity(new_active->dev, 1);
+
+		if (bond->dev->flags & IFF_ALLMULTI)
+			dev_set_allmulti(new_active->dev, 1);
+
+		netif_addr_lock_bh(bond->dev);
+		dev_uc_sync(new_active->dev, bond->dev);
+		dev_mc_sync(new_active->dev, bond->dev);
+		netif_addr_unlock_bh(bond->dev);
+	}
+}
+
+/**
+ * bond_set_dev_addr - clone slave's address to bond
+ * @bond_dev: bond net device
+ * @slave_dev: slave net device
+ *
+ * Should be called with RTNL held.
+ */
+static void bond_set_dev_addr(struct net_device *bond_dev,
+			      struct net_device *slave_dev)
+{
+	netdev_dbg(bond_dev, "bond_dev=%p slave_dev=%p slave_dev->name=%s slave_dev->addr_len=%d\n",
+		   bond_dev, slave_dev, slave_dev->name, slave_dev->addr_len);
+	memcpy(bond_dev->dev_addr, slave_dev->dev_addr, slave_dev->addr_len);
+	bond_dev->addr_assign_type = NET_ADDR_STOLEN;
+	call_netdevice_notifiers(NETDEV_CHANGEADDR, bond_dev);
+}
+
+static struct slave *bond_get_old_active(struct bonding *bond,
+					 struct slave *new_active)
+{
+	struct slave *slave;
+	struct list_head *iter;
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (slave == new_active)
+			continue;
+
+		if (ether_addr_equal(bond->dev->dev_addr, slave->dev->dev_addr))
+			return slave;
+	}
+
+	return NULL;
+}
+
+/* bond_do_fail_over_mac
+ *
+ * Perform special MAC address swapping for fail_over_mac settings
+ *
+ * Called with RTNL
+ */
+static void bond_do_fail_over_mac(struct bonding *bond,
+				  struct slave *new_active,
+				  struct slave *old_active)
+{
+	u8 tmp_mac[MAX_ADDR_LEN];
+	struct sockaddr_storage ss;
+	int rv;
+
+	switch (bond->params.fail_over_mac) {
+	case BOND_FOM_ACTIVE:
+		if (new_active)
+			bond_set_dev_addr(bond->dev, new_active->dev);
+		break;
+	case BOND_FOM_FOLLOW:
+		/* if new_active && old_active, swap them
+		 * if just old_active, do nothing (going to no active slave)
+		 * if just new_active, set new_active to bond's MAC
+		 */
+		if (!new_active)
+			return;
+
+		if (!old_active)
+			old_active = bond_get_old_active(bond, new_active);
+
+		if (old_active) {
+			bond_hw_addr_copy(tmp_mac, new_active->dev->dev_addr,
+					  new_active->dev->addr_len);
+			bond_hw_addr_copy(ss.__data,
+					  old_active->dev->dev_addr,
+					  old_active->dev->addr_len);
+			ss.ss_family = new_active->dev->type;
+		} else {
+			bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
+					  bond->dev->addr_len);
+			ss.ss_family = bond->dev->type;
+		}
+
+		rv = dev_set_mac_address(new_active->dev,
+					 (struct sockaddr *)&ss);
+		if (rv) {
+			netdev_err(bond->dev, "Error %d setting MAC of slave %s\n",
+				   -rv, new_active->dev->name);
+			goto out;
+		}
+
+		if (!old_active)
+			goto out;
+
+		bond_hw_addr_copy(ss.__data, tmp_mac,
+				  new_active->dev->addr_len);
+		ss.ss_family = old_active->dev->type;
+
+		rv = dev_set_mac_address(old_active->dev,
+					 (struct sockaddr *)&ss);
+		if (rv)
+			netdev_err(bond->dev, "Error %d setting MAC of slave %s\n",
+				   -rv, new_active->dev->name);
+out:
+		break;
+	default:
+		netdev_err(bond->dev, "bond_do_fail_over_mac impossible: bad policy %d\n",
+			   bond->params.fail_over_mac);
+		break;
+	}
+
+}
+
+static struct slave *bond_choose_primary_or_current(struct bonding *bond)
+{
+	struct slave *prim = rtnl_dereference(bond->primary_slave);
+	struct slave *curr = rtnl_dereference(bond->curr_active_slave);
+
+	if (!prim || prim->link != BOND_LINK_UP) {
+		if (!curr || curr->link != BOND_LINK_UP)
+			return NULL;
+		return curr;
+	}
+
+	if (bond->force_primary) {
+		bond->force_primary = false;
+		return prim;
+	}
+
+	if (!curr || curr->link != BOND_LINK_UP)
+		return prim;
+
+	/* At this point, prim and curr are both up */
+	switch (bond->params.primary_reselect) {
+	case BOND_PRI_RESELECT_ALWAYS:
+		return prim;
+	case BOND_PRI_RESELECT_BETTER:
+		if (prim->speed < curr->speed)
+			return curr;
+		if (prim->speed == curr->speed && prim->duplex <= curr->duplex)
+			return curr;
+		return prim;
+	case BOND_PRI_RESELECT_FAILURE:
+		return curr;
+	default:
+		netdev_err(bond->dev, "impossible primary_reselect %d\n",
+			   bond->params.primary_reselect);
+		return curr;
+	}
+}
+
+/**
+ * bond_find_best_slave - select the best available slave to be the active one
+ * @bond: our bonding struct
+ */
+static struct slave *bond_find_best_slave(struct bonding *bond)
+{
+	struct slave *slave, *bestslave = NULL;
+	struct list_head *iter;
+	int mintime = bond->params.updelay;
+
+	slave = bond_choose_primary_or_current(bond);
+	if (slave)
+		return slave;
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (slave->link == BOND_LINK_UP)
+			return slave;
+		if (slave->link == BOND_LINK_BACK && bond_slave_is_up(slave) &&
+		    slave->delay < mintime) {
+			mintime = slave->delay;
+			bestslave = slave;
+		}
+	}
+
+	return bestslave;
+}
+
+static bool bond_should_notify_peers(struct bonding *bond)
+{
+	struct slave *slave;
+
+	rcu_read_lock();
+	slave = rcu_dereference(bond->curr_active_slave);
+	rcu_read_unlock();
+
+	netdev_dbg(bond->dev, "bond_should_notify_peers: slave %s\n",
+		   slave ? slave->dev->name : "NULL");
+
+	if (!slave || !bond->send_peer_notif ||
+	    !netif_carrier_ok(bond->dev) ||
+	    test_bit(__LINK_STATE_LINKWATCH_PENDING, &slave->dev->state))
+		return false;
+
+	return true;
+}
+
+/**
+ * change_active_interface - change the active slave into the specified one
+ * @bond: our bonding struct
+ * @new: the new slave to make the active one
+ *
+ * Set the new slave to the bond's settings and unset them on the old
+ * curr_active_slave.
+ * Setting include flags, mc-list, promiscuity, allmulti, etc.
+ *
+ * If @new's link state is %BOND_LINK_BACK we'll set it to %BOND_LINK_UP,
+ * because it is apparently the best available slave we have, even though its
+ * updelay hasn't timed out yet.
+ *
+ * Caller must hold RTNL.
+ */
+void bond_change_active_slave(struct bonding *bond, struct slave *new_active)
+{
+	struct slave *old_active;
+
+	ASSERT_RTNL();
+
+	old_active = rtnl_dereference(bond->curr_active_slave);
+
+	if (old_active == new_active)
+		return;
+
+	if (new_active) {
+		new_active->last_link_up = jiffies;
+
+		if (new_active->link == BOND_LINK_BACK) {
+			if (bond_uses_primary(bond)) {
+				netdev_info(bond->dev, "making interface %s the new active one %d ms earlier\n",
+					    new_active->dev->name,
+					    (bond->params.updelay - new_active->delay) * bond->params.miimon);
+			}
+
+			new_active->delay = 0;
+			bond_set_slave_link_state(new_active, BOND_LINK_UP,
+						  BOND_SLAVE_NOTIFY_NOW);
+
+			if (BOND_MODE(bond) == BOND_MODE_8023AD)
+				bond_3ad_handle_link_change(new_active, BOND_LINK_UP);
+
+			if (bond_is_lb(bond))
+				bond_alb_handle_link_change(bond, new_active, BOND_LINK_UP);
+		} else {
+			if (bond_uses_primary(bond)) {
+				netdev_info(bond->dev, "making interface %s the new active one\n",
+					    new_active->dev->name);
+			}
+		}
+	}
+
+	if (bond_uses_primary(bond))
+		bond_hw_addr_swap(bond, new_active, old_active);
+
+	if (bond_is_lb(bond)) {
+		bond_alb_handle_active_change(bond, new_active);
+		if (old_active)
+			bond_set_slave_inactive_flags(old_active,
+						      BOND_SLAVE_NOTIFY_NOW);
+		if (new_active)
+			bond_set_slave_active_flags(new_active,
+						    BOND_SLAVE_NOTIFY_NOW);
+	} else {
+		rcu_assign_pointer(bond->curr_active_slave, new_active);
+	}
+
+	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP) {
+		if (old_active)
+			bond_set_slave_inactive_flags(old_active,
+						      BOND_SLAVE_NOTIFY_NOW);
+
+		if (new_active) {
+			bool should_notify_peers = false;
+
+			bond_set_slave_active_flags(new_active,
+						    BOND_SLAVE_NOTIFY_NOW);
+
+			if (bond->params.fail_over_mac)
+				bond_do_fail_over_mac(bond, new_active,
+						      old_active);
+
+			if (netif_running(bond->dev)) {
+				bond->send_peer_notif =
+					bond->params.num_peer_notif;
+				should_notify_peers =
+					bond_should_notify_peers(bond);
+			}
+
+			call_netdevice_notifiers(NETDEV_BONDING_FAILOVER, bond->dev);
+			if (should_notify_peers)
+				call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
+							 bond->dev);
+		}
+	}
+
+	/* resend IGMP joins since active slave has changed or
+	 * all were sent on curr_active_slave.
+	 * resend only if bond is brought up with the affected
+	 * bonding modes and the retransmission is enabled
+	 */
+	if (netif_running(bond->dev) && (bond->params.resend_igmp > 0) &&
+	    ((bond_uses_primary(bond) && new_active) ||
+	     BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)) {
+		bond->igmp_retrans = bond->params.resend_igmp;
+		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
+	}
+}
+
+/**
+ * bond_select_active_slave - select a new active slave, if needed
+ * @bond: our bonding struct
+ *
+ * This functions should be called when one of the following occurs:
+ * - The old curr_active_slave has been released or lost its link.
+ * - The primary_slave has got its link back.
+ * - A slave has got its link back and there's no old curr_active_slave.
+ *
+ * Caller must hold RTNL.
+ */
+void bond_select_active_slave(struct bonding *bond)
+{
+	struct slave *best_slave;
+	int rv;
+
+	ASSERT_RTNL();
+
+	best_slave = bond_find_best_slave(bond);
+	if (best_slave != rtnl_dereference(bond->curr_active_slave)) {
+		struct slave *last_slave = bond->curr_active_slave;
+
+		bond_change_active_slave(bond, best_slave);
+		toe_failover(bond->dev,
+			     bond->curr_active_slave ?
+			     bond->curr_active_slave->dev : NULL,
+			     TOE_ACTIVE_SLAVE,
+			     last_slave ? last_slave->dev : NULL);
+
+		rv = bond_set_carrier(bond);
+		if (!rv)
+			return;
+
+		if (netif_carrier_ok(bond->dev))
+			netdev_info(bond->dev, "first active interface up!\n");
+		else
+			netdev_info(bond->dev, "now running without any active interface!\n");
+	}
+}
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+static inline int slave_enable_netpoll(struct slave *slave)
+{
+	struct netpoll *np;
+	int err = 0;
+
+	np = kzalloc(sizeof(*np), GFP_KERNEL);
+	err = -ENOMEM;
+	if (!np)
+		goto out;
+
+	err = __netpoll_setup(np, slave->dev);
+	if (err) {
+		kfree(np);
+		goto out;
+	}
+	slave->np = np;
+out:
+	return err;
+}
+static inline void slave_disable_netpoll(struct slave *slave)
+{
+	struct netpoll *np = slave->np;
+
+	if (!np)
+		return;
+
+	slave->np = NULL;
+	__netpoll_free_async(np);
+}
+
+static void bond_poll_controller(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave = NULL;
+	struct list_head *iter;
+	struct ad_info ad_info;
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD)
+		if (bond_3ad_get_active_agg_info(bond, &ad_info))
+			return;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (!bond_slave_is_up(slave))
+			continue;
+
+		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+			struct aggregator *agg =
+			    SLAVE_AD_INFO(slave)->port.aggregator;
+
+			if (agg &&
+			    agg->aggregator_identifier != ad_info.aggregator_id)
+				continue;
+		}
+
+		netpoll_poll_dev(slave->dev);
+	}
+}
+
+static void bond_netpoll_cleanup(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	struct slave *slave;
+
+	bond_for_each_slave(bond, slave, iter)
+		if (bond_slave_is_up(slave))
+			slave_disable_netpoll(slave);
+}
+
+static int bond_netpoll_setup(struct net_device *dev, struct netpoll_info *ni)
+{
+	struct bonding *bond = netdev_priv(dev);
+	struct list_head *iter;
+	struct slave *slave;
+	int err = 0;
+
+	bond_for_each_slave(bond, slave, iter) {
+		err = slave_enable_netpoll(slave);
+		if (err) {
+			bond_netpoll_cleanup(dev);
+			break;
+		}
+	}
+	return err;
+}
+#else
+static inline int slave_enable_netpoll(struct slave *slave)
+{
+	return 0;
+}
+static inline void slave_disable_netpoll(struct slave *slave)
+{
+}
+static void bond_netpoll_cleanup(struct net_device *bond_dev)
+{
+}
+#endif
+
+/*---------------------------------- IOCTL ----------------------------------*/
+
+static netdev_features_t bond_fix_features(struct net_device *dev,
+					   netdev_features_t features)
+{
+	struct bonding *bond = netdev_priv(dev);
+	struct list_head *iter;
+	netdev_features_t mask;
+	struct slave *slave;
+
+	mask = features;
+
+	features &= ~NETIF_F_ONE_FOR_ALL;
+	features |= NETIF_F_ALL_FOR_ALL;
+
+	bond_for_each_slave(bond, slave, iter) {
+		features = netdev_increment_features(features,
+						     slave->dev->features,
+						     mask);
+	}
+	features = netdev_add_tso_features(features, mask);
+
+	return features;
+}
+
+#define BOND_VLAN_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
+				 NETIF_F_FRAGLIST | NETIF_F_ALL_TSO | \
+				 NETIF_F_HIGHDMA | NETIF_F_LRO)
+
+#define BOND_ENC_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
+				 NETIF_F_RXCSUM | NETIF_F_ALL_TSO)
+
+static void bond_compute_features(struct bonding *bond)
+{
+	unsigned int dst_release_flag = IFF_XMIT_DST_RELEASE |
+					IFF_XMIT_DST_RELEASE_PERM;
+	netdev_features_t vlan_features = BOND_VLAN_FEATURES;
+	netdev_features_t enc_features  = BOND_ENC_FEATURES;
+	struct net_device *bond_dev = bond->dev;
+	struct list_head *iter;
+	struct slave *slave;
+	unsigned short max_hard_header_len = ETH_HLEN;
+	unsigned int gso_max_size = GSO_MAX_SIZE;
+	u16 gso_max_segs = GSO_MAX_SEGS;
+
+	if (!bond_has_slaves(bond))
+		goto done;
+	vlan_features &= NETIF_F_ALL_FOR_ALL;
+
+	bond_for_each_slave(bond, slave, iter) {
+		vlan_features = netdev_increment_features(vlan_features,
+			slave->dev->vlan_features, BOND_VLAN_FEATURES);
+
+		enc_features = netdev_increment_features(enc_features,
+							 slave->dev->hw_enc_features,
+							 BOND_ENC_FEATURES);
+		dst_release_flag &= slave->dev->priv_flags;
+		if (slave->dev->hard_header_len > max_hard_header_len)
+			max_hard_header_len = slave->dev->hard_header_len;
+
+		gso_max_size = min(gso_max_size, slave->dev->gso_max_size);
+		gso_max_segs = min(gso_max_segs, slave->dev->gso_max_segs);
+	}
+	bond_dev->hard_header_len = max_hard_header_len;
+
+done:
+	bond_dev->vlan_features = vlan_features;
+	bond_dev->hw_enc_features = enc_features | NETIF_F_GSO_ENCAP_ALL |
+				    NETIF_F_HW_VLAN_CTAG_TX |
+				    NETIF_F_HW_VLAN_STAG_TX |
+				    NETIF_F_GSO_UDP_L4;
+	bond_dev->gso_max_segs = gso_max_segs;
+	netif_set_gso_max_size(bond_dev, gso_max_size);
+
+	bond_dev->priv_flags &= ~IFF_XMIT_DST_RELEASE;
+	if ((bond_dev->priv_flags & IFF_XMIT_DST_RELEASE_PERM) &&
+	    dst_release_flag == (IFF_XMIT_DST_RELEASE | IFF_XMIT_DST_RELEASE_PERM))
+		bond_dev->priv_flags |= IFF_XMIT_DST_RELEASE;
+
+	netdev_change_features(bond_dev);
+}
+
+static void bond_setup_by_slave(struct net_device *bond_dev,
+				struct net_device *slave_dev)
+{
+	bond_dev->header_ops	    = slave_dev->header_ops;
+
+	bond_dev->type		    = slave_dev->type;
+	bond_dev->hard_header_len   = slave_dev->hard_header_len;
+	bond_dev->needed_headroom   = slave_dev->needed_headroom;
+	bond_dev->addr_len	    = slave_dev->addr_len;
+
+	memcpy(bond_dev->broadcast, slave_dev->broadcast,
+		slave_dev->addr_len);
+}
+
+/* On bonding slaves other than the currently active slave, suppress
+ * duplicates except for alb non-mcast/bcast.
+ */
+static bool bond_should_deliver_exact_match(struct sk_buff *skb,
+					    struct slave *slave,
+					    struct bonding *bond)
+{
+	if (bond_is_slave_inactive(slave)) {
+		if (BOND_MODE(bond) == BOND_MODE_ALB &&
+		    skb->pkt_type != PACKET_BROADCAST &&
+		    skb->pkt_type != PACKET_MULTICAST)
+			return false;
+		return true;
+	}
+	return false;
+}
+
+static rx_handler_result_t bond_handle_frame(struct sk_buff **pskb)
+{
+	struct sk_buff *skb = *pskb;
+	struct slave *slave;
+	struct bonding *bond;
+	int (*recv_probe)(const struct sk_buff *, struct bonding *,
+			  struct slave *);
+	int ret = RX_HANDLER_ANOTHER;
+
+	skb = skb_share_check(skb, GFP_ATOMIC);
+	if (unlikely(!skb))
+		return RX_HANDLER_CONSUMED;
+
+	*pskb = skb;
+
+	slave = bond_slave_get_rcu(skb->dev);
+	bond = slave->bond;
+
+	recv_probe = READ_ONCE(bond->recv_probe);
+	if (recv_probe) {
+		ret = recv_probe(skb, bond, slave);
+		if (ret == RX_HANDLER_CONSUMED) {
+			consume_skb(skb);
+			return ret;
+		}
+	}
+
+	/*
+	 * For packets determined by bond_should_deliver_exact_match() call to
+	 * be suppressed we want to make an exception for link-local packets.
+	 * This is necessary for e.g. LLDP daemons to be able to monitor
+	 * inactive slave links without being forced to bind to them
+	 * explicitly.
+	 *
+	 * At the same time, packets that are passed to the bonding master
+	 * (including link-local ones) can have their originating interface
+	 * determined via PACKET_ORIGDEV socket option.
+	 */
+	if (bond_should_deliver_exact_match(skb, slave, bond)) {
+		if (is_link_local_ether_addr(eth_hdr(skb)->h_dest))
+			return RX_HANDLER_PASS;
+		return RX_HANDLER_EXACT;
+	}
+
+	skb->dev = bond->dev;
+
+	if (BOND_MODE(bond) == BOND_MODE_ALB &&
+	    bond->dev->priv_flags & IFF_BRIDGE_PORT &&
+	    skb->pkt_type == PACKET_HOST) {
+
+		if (unlikely(skb_cow_head(skb,
+					  skb->data - skb_mac_header(skb)))) {
+			kfree_skb(skb);
+			return RX_HANDLER_CONSUMED;
+		}
+		bond_hw_addr_copy(eth_hdr(skb)->h_dest, bond->dev->dev_addr,
+				  bond->dev->addr_len);
+	}
+
+	return ret;
+}
+
+static enum netdev_lag_tx_type bond_lag_tx_type(struct bonding *bond)
+{
+	switch (BOND_MODE(bond)) {
+	case BOND_MODE_ROUNDROBIN:
+		return NETDEV_LAG_TX_TYPE_ROUNDROBIN;
+	case BOND_MODE_ACTIVEBACKUP:
+		return NETDEV_LAG_TX_TYPE_ACTIVEBACKUP;
+	case BOND_MODE_BROADCAST:
+		return NETDEV_LAG_TX_TYPE_BROADCAST;
+	case BOND_MODE_XOR:
+	case BOND_MODE_8023AD:
+		return NETDEV_LAG_TX_TYPE_HASH;
+	default:
+		return NETDEV_LAG_TX_TYPE_UNKNOWN;
+	}
+}
+
+static enum netdev_lag_hash bond_lag_hash_type(struct bonding *bond,
+					       enum netdev_lag_tx_type type)
+{
+	if (type != NETDEV_LAG_TX_TYPE_HASH)
+		return NETDEV_LAG_HASH_NONE;
+
+	switch (bond->params.xmit_policy) {
+	case BOND_XMIT_POLICY_LAYER2:
+		return NETDEV_LAG_HASH_L2;
+	case BOND_XMIT_POLICY_LAYER34:
+		return NETDEV_LAG_HASH_L34;
+	case BOND_XMIT_POLICY_LAYER23:
+		return NETDEV_LAG_HASH_L23;
+	case BOND_XMIT_POLICY_ENCAP23:
+		return NETDEV_LAG_HASH_E23;
+	case BOND_XMIT_POLICY_ENCAP34:
+		return NETDEV_LAG_HASH_E34;
+	default:
+		return NETDEV_LAG_HASH_UNKNOWN;
+	}
+}
+
+static int bond_master_upper_dev_link(struct bonding *bond, struct slave *slave,
+				      struct netlink_ext_ack *extack)
+{
+	struct netdev_lag_upper_info lag_upper_info;
+	enum netdev_lag_tx_type type;
+
+	type = bond_lag_tx_type(bond);
+	lag_upper_info.tx_type = type;
+	lag_upper_info.hash_type = bond_lag_hash_type(bond, type);
+
+	return netdev_master_upper_dev_link(slave->dev, bond->dev, slave,
+					    &lag_upper_info, extack);
+}
+
+static void bond_upper_dev_unlink(struct bonding *bond, struct slave *slave)
+{
+	netdev_upper_dev_unlink(slave->dev, bond->dev);
+	slave->dev->flags &= ~IFF_SLAVE;
+}
+
+static void slave_kobj_release(struct kobject *kobj)
+{
+	struct slave *slave = to_slave(kobj);
+	struct bonding *bond = bond_get_bond_by_slave(slave);
+
+	cancel_delayed_work_sync(&slave->notify_work);
+	if (BOND_MODE(bond) == BOND_MODE_8023AD)
+		kfree(SLAVE_AD_INFO(slave));
+
+	kfree(slave);
+}
+
+static struct kobj_type slave_ktype = {
+	.release = slave_kobj_release,
+#ifdef CONFIG_SYSFS
+	.sysfs_ops = &slave_sysfs_ops,
+#endif
+};
+
+static int bond_kobj_init(struct slave *slave)
+{
+	int err;
+
+	err = kobject_init_and_add(&slave->kobj, &slave_ktype,
+				   &(slave->dev->dev.kobj), "bonding_slave");
+	if (err)
+		kobject_put(&slave->kobj);
+
+	return err;
+}
+
+static struct slave *bond_alloc_slave(struct bonding *bond,
+				      struct net_device *slave_dev)
+{
+	struct slave *slave = NULL;
+
+	slave = kzalloc(sizeof(*slave), GFP_KERNEL);
+	if (!slave)
+		return NULL;
+
+	slave->bond = bond;
+	slave->dev = slave_dev;
+
+	if (bond_kobj_init(slave))
+		return NULL;
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		SLAVE_AD_INFO(slave) = kzalloc(sizeof(struct ad_slave_info),
+					       GFP_KERNEL);
+		if (!SLAVE_AD_INFO(slave)) {
+			kobject_put(&slave->kobj);
+			return NULL;
+		}
+	}
+	INIT_DELAYED_WORK(&slave->notify_work, bond_netdev_notify_work);
+
+	return slave;
+}
+
+static void bond_fill_ifbond(struct bonding *bond, struct ifbond *info)
+{
+	info->bond_mode = BOND_MODE(bond);
+	info->miimon = bond->params.miimon;
+	info->num_slaves = bond->slave_cnt;
+}
+
+static void bond_fill_ifslave(struct slave *slave, struct ifslave *info)
+{
+	strcpy(info->slave_name, slave->dev->name);
+	info->link = slave->link;
+	info->state = bond_slave_state(slave);
+	info->link_failure_count = slave->link_failure_count;
+}
+
+static void bond_netdev_notify_work(struct work_struct *_work)
+{
+	struct slave *slave = container_of(_work, struct slave,
+					   notify_work.work);
+
+	if (rtnl_trylock()) {
+		struct netdev_bonding_info binfo;
+
+		bond_fill_ifslave(slave, &binfo.slave);
+		bond_fill_ifbond(slave->bond, &binfo.master);
+		netdev_bonding_info_change(slave->dev, &binfo);
+		rtnl_unlock();
+	} else {
+		queue_delayed_work(slave->bond->wq, &slave->notify_work, 1);
+	}
+}
+
+void bond_queue_slave_event(struct slave *slave)
+{
+	queue_delayed_work(slave->bond->wq, &slave->notify_work, 0);
+}
+
+void bond_lower_state_changed(struct slave *slave)
+{
+	struct netdev_lag_lower_state_info info;
+
+	info.link_up = slave->link == BOND_LINK_UP ||
+		       slave->link == BOND_LINK_FAIL;
+	info.tx_enabled = bond_is_active_slave(slave);
+	netdev_lower_state_changed(slave->dev, &info);
+}
+
+/* enslave device <slave> to bond device <master> */
+int bond_enslave(struct net_device *bond_dev, struct net_device *slave_dev,
+		 struct netlink_ext_ack *extack)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
+	struct slave *new_slave = NULL, *prev_slave;
+	struct sockaddr_storage ss;
+	int link_reporting;
+	int res = 0, i;
+
+	if (!bond->params.use_carrier &&
+	    slave_dev->ethtool_ops->get_link == NULL &&
+	    slave_ops->ndo_do_ioctl == NULL) {
+		netdev_warn(bond_dev, "no link monitoring support for %s\n",
+			    slave_dev->name);
+	}
+
+	/* already in-use? */
+	if (netdev_is_rx_handler_busy(slave_dev)) {
+		NL_SET_ERR_MSG(extack, "Device is in use and cannot be enslaved");
+		netdev_err(bond_dev,
+			   "Error: Device is in use and cannot be enslaved\n");
+		return -EBUSY;
+	}
+
+	if (bond_dev == slave_dev) {
+		NL_SET_ERR_MSG(extack, "Cannot enslave bond to itself.");
+		netdev_err(bond_dev, "cannot enslave bond to itself.\n");
+		return -EPERM;
+	}
+
+	/* vlan challenged mutual exclusion */
+	/* no need to lock since we're protected by rtnl_lock */
+	if (slave_dev->features & NETIF_F_VLAN_CHALLENGED) {
+		netdev_dbg(bond_dev, "%s is NETIF_F_VLAN_CHALLENGED\n",
+			   slave_dev->name);
+		if (vlan_uses_dev(bond_dev)) {
+			NL_SET_ERR_MSG(extack, "Can not enslave VLAN challenged device to VLAN enabled bond");
+			netdev_err(bond_dev, "Error: cannot enslave VLAN challenged slave %s on VLAN enabled bond %s\n",
+				   slave_dev->name, bond_dev->name);
+			return -EPERM;
+		} else {
+			netdev_warn(bond_dev, "enslaved VLAN challenged slave %s. Adding VLANs will be blocked as long as %s is part of bond %s\n",
+				    slave_dev->name, slave_dev->name,
+				    bond_dev->name);
+		}
+	} else {
+		netdev_dbg(bond_dev, "%s is !NETIF_F_VLAN_CHALLENGED\n",
+			   slave_dev->name);
+	}
+
+	/* Old ifenslave binaries are no longer supported.  These can
+	 * be identified with moderate accuracy by the state of the slave:
+	 * the current ifenslave will set the interface down prior to
+	 * enslaving it; the old ifenslave will not.
+	 */
+	if (slave_dev->flags & IFF_UP) {
+		NL_SET_ERR_MSG(extack, "Device can not be enslaved while up");
+		netdev_err(bond_dev, "%s is up - this may be due to an out of date ifenslave\n",
+			   slave_dev->name);
+		return -EPERM;
+	}
+
+	/* set bonding device ether type by slave - bonding netdevices are
+	 * created with ether_setup, so when the slave type is not ARPHRD_ETHER
+	 * there is a need to override some of the type dependent attribs/funcs.
+	 *
+	 * bond ether type mutual exclusion - don't allow slaves of dissimilar
+	 * ether type (eg ARPHRD_ETHER and ARPHRD_INFINIBAND) share the same bond
+	 */
+	if (!bond_has_slaves(bond)) {
+		if (bond_dev->type != slave_dev->type) {
+			netdev_dbg(bond_dev, "change device type from %d to %d\n",
+				   bond_dev->type, slave_dev->type);
+
+			res = call_netdevice_notifiers(NETDEV_PRE_TYPE_CHANGE,
+						       bond_dev);
+			res = notifier_to_errno(res);
+			if (res) {
+				netdev_err(bond_dev, "refused to change device type\n");
+				return -EBUSY;
+			}
+
+			/* Flush unicast and multicast addresses */
+			dev_uc_flush(bond_dev);
+			dev_mc_flush(bond_dev);
+
+			if (slave_dev->type != ARPHRD_ETHER)
+				bond_setup_by_slave(bond_dev, slave_dev);
+			else {
+				ether_setup(bond_dev);
+				bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
+			}
+
+			call_netdevice_notifiers(NETDEV_POST_TYPE_CHANGE,
+						 bond_dev);
+		}
+	} else if (bond_dev->type != slave_dev->type) {
+		NL_SET_ERR_MSG(extack, "Device type is different from other slaves");
+		netdev_err(bond_dev, "%s ether type (%d) is different from other slaves (%d), can not enslave it\n",
+			   slave_dev->name, slave_dev->type, bond_dev->type);
+		return -EINVAL;
+	}
+
+	if (slave_dev->type == ARPHRD_INFINIBAND &&
+	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
+		NL_SET_ERR_MSG(extack, "Only active-backup mode is supported for infiniband slaves");
+		netdev_warn(bond_dev, "Type (%d) supports only active-backup mode\n",
+			    slave_dev->type);
+		res = -EOPNOTSUPP;
+		goto err_undo_flags;
+	}
+
+	if (!slave_ops->ndo_set_mac_address ||
+	    slave_dev->type == ARPHRD_INFINIBAND) {
+		netdev_warn(bond_dev, "The slave device specified does not support setting the MAC address\n");
+		if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
+		    bond->params.fail_over_mac != BOND_FOM_ACTIVE) {
+			if (!bond_has_slaves(bond)) {
+				bond->params.fail_over_mac = BOND_FOM_ACTIVE;
+				netdev_warn(bond_dev, "Setting fail_over_mac to active for active-backup mode\n");
+			} else {
+				NL_SET_ERR_MSG(extack, "Slave device does not support setting the MAC address, but fail_over_mac is not set to active");
+				netdev_err(bond_dev, "The slave device specified does not support setting the MAC address, but fail_over_mac is not set to active\n");
+				res = -EOPNOTSUPP;
+				goto err_undo_flags;
+			}
+		}
+	}
+
+	call_netdevice_notifiers(NETDEV_JOIN, slave_dev);
+
+	/* If this is the first slave, then we need to set the master's hardware
+	 * address to be the same as the slave's.
+	 */
+	if (!bond_has_slaves(bond) &&
+	    bond->dev->addr_assign_type == NET_ADDR_RANDOM)
+		bond_set_dev_addr(bond->dev, slave_dev);
+
+	new_slave = bond_alloc_slave(bond, slave_dev);
+	if (!new_slave) {
+		res = -ENOMEM;
+		goto err_undo_flags;
+	}
+
+	/* Set the new_slave's queue_id to be zero.  Queue ID mapping
+	 * is set via sysfs or module option if desired.
+	 */
+	new_slave->queue_id = 0;
+
+	/* Save slave's original mtu and then set it to match the bond */
+	new_slave->original_mtu = slave_dev->mtu;
+	res = dev_set_mtu(slave_dev, bond->dev->mtu);
+	if (res) {
+		netdev_dbg(bond_dev, "Error %d calling dev_set_mtu\n", res);
+		goto err_free;
+	}
+
+	/* Save slave's original ("permanent") mac address for modes
+	 * that need it, and for restoring it upon release, and then
+	 * set it to the master's address
+	 */
+	bond_hw_addr_copy(new_slave->perm_hwaddr, slave_dev->dev_addr,
+			  slave_dev->addr_len);
+
+	if (!bond->params.fail_over_mac ||
+	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
+		/* Set slave to master's mac address.  The application already
+		 * set the master's mac address to that of the first slave
+		 */
+		memcpy(ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
+		ss.ss_family = slave_dev->type;
+		res = dev_set_mac_address(slave_dev, (struct sockaddr *)&ss);
+		if (res) {
+			netdev_dbg(bond_dev, "Error %d calling set_mac_address\n", res);
+			goto err_restore_mtu;
+		}
+	}
+
+	/* set slave flag before open to prevent IPv6 addrconf */
+	slave_dev->flags |= IFF_SLAVE;
+
+	/* open the slave since the application closed it */
+	res = dev_open(slave_dev);
+	if (res) {
+		netdev_dbg(bond_dev, "Opening slave %s failed\n", slave_dev->name);
+		goto err_restore_mac;
+	}
+
+	slave_dev->priv_flags |= IFF_BONDING;
+	/* initialize slave stats */
+	dev_get_stats(new_slave->dev, &new_slave->slave_stats);
+
+	if (bond_is_lb(bond)) {
+		/* bond_alb_init_slave() must be called before all other stages since
+		 * it might fail and we do not want to have to undo everything
+		 */
+		res = bond_alb_init_slave(bond, new_slave);
+		if (res)
+			goto err_close;
+	}
+
+	res = vlan_vids_add_by_dev(slave_dev, bond_dev);
+	if (res) {
+		netdev_err(bond_dev, "Couldn't add bond vlan ids to %s\n",
+			   slave_dev->name);
+		goto err_close;
+	}
+
+	prev_slave = bond_last_slave(bond);
+
+	new_slave->delay = 0;
+	new_slave->link_failure_count = 0;
+
+	if (bond_update_speed_duplex(new_slave) &&
+	    bond_needs_speed_duplex(bond))
+		new_slave->link = BOND_LINK_DOWN;
+
+	new_slave->last_rx = jiffies -
+		(msecs_to_jiffies(bond->params.arp_interval) + 1);
+	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
+		new_slave->target_last_arp_rx[i] = new_slave->last_rx;
+
+	if (bond->params.miimon && !bond->params.use_carrier) {
+		link_reporting = bond_check_dev_link(bond, slave_dev, 1);
+
+		if ((link_reporting == -1) && !bond->params.arp_interval) {
+			/* miimon is set but a bonded network driver
+			 * does not support ETHTOOL/MII and
+			 * arp_interval is not set.  Note: if
+			 * use_carrier is enabled, we will never go
+			 * here (because netif_carrier is always
+			 * supported); thus, we don't need to change
+			 * the messages for netif_carrier.
+			 */
+			netdev_warn(bond_dev, "MII and ETHTOOL support not available for interface %s, and arp_interval/arp_ip_target module parameters not specified, thus bonding will not detect link failures! see bonding.txt for details\n",
+				    slave_dev->name);
+		} else if (link_reporting == -1) {
+			/* unable get link status using mii/ethtool */
+			netdev_warn(bond_dev, "can't get link status from interface %s; the network driver associated with this interface does not support MII or ETHTOOL link status reporting, thus miimon has no effect on this interface\n",
+				    slave_dev->name);
+		}
+	}
+
+	/* check for initial state */
+	new_slave->link = BOND_LINK_NOCHANGE;
+	if (bond->params.miimon) {
+		if (bond_check_dev_link(bond, slave_dev, 0) == BMSR_LSTATUS) {
+			if (bond->params.updelay) {
+				bond_set_slave_link_state(new_slave,
+							  BOND_LINK_BACK,
+							  BOND_SLAVE_NOTIFY_NOW);
+				new_slave->delay = bond->params.updelay;
+			} else {
+				bond_set_slave_link_state(new_slave,
+							  BOND_LINK_UP,
+							  BOND_SLAVE_NOTIFY_NOW);
+			}
+		} else {
+			bond_set_slave_link_state(new_slave, BOND_LINK_DOWN,
+						  BOND_SLAVE_NOTIFY_NOW);
+		}
+	} else if (bond->params.arp_interval) {
+		bond_set_slave_link_state(new_slave,
+					  (netif_carrier_ok(slave_dev) ?
+					  BOND_LINK_UP : BOND_LINK_DOWN),
+					  BOND_SLAVE_NOTIFY_NOW);
+	} else {
+		bond_set_slave_link_state(new_slave, BOND_LINK_UP,
+					  BOND_SLAVE_NOTIFY_NOW);
+	}
+
+	if (new_slave->link != BOND_LINK_DOWN)
+		new_slave->last_link_up = jiffies;
+	netdev_dbg(bond_dev, "Initial state of slave_dev is BOND_LINK_%s\n",
+		   new_slave->link == BOND_LINK_DOWN ? "DOWN" :
+		   (new_slave->link == BOND_LINK_UP ? "UP" : "BACK"));
+
+	if (bond_uses_primary(bond) && bond->params.primary[0]) {
+		/* if there is a primary slave, remember it */
+		if (strcmp(bond->params.primary, new_slave->dev->name) == 0) {
+			rcu_assign_pointer(bond->primary_slave, new_slave);
+			bond->force_primary = true;
+		}
+	}
+
+	switch (BOND_MODE(bond)) {
+	case BOND_MODE_ACTIVEBACKUP:
+		bond_set_slave_inactive_flags(new_slave,
+					      BOND_SLAVE_NOTIFY_NOW);
+		break;
+	case BOND_MODE_8023AD:
+		/* in 802.3ad mode, the internal mechanism
+		 * will activate the slaves in the selected
+		 * aggregator
+		 */
+		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
+		/* if this is the first slave */
+		if (!prev_slave) {
+			SLAVE_AD_INFO(new_slave)->id = 1;
+			/* Initialize AD with the number of times that the AD timer is called in 1 second
+			 * can be called only after the mac address of the bond is set
+			 */
+			bond_3ad_initialize(bond, 1000/AD_TIMER_INTERVAL);
+		} else {
+			SLAVE_AD_INFO(new_slave)->id =
+				SLAVE_AD_INFO(prev_slave)->id + 1;
+		}
+
+		bond_3ad_bind_slave(new_slave);
+		break;
+	case BOND_MODE_TLB:
+	case BOND_MODE_ALB:
+		bond_set_active_slave(new_slave);
+		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
+		break;
+	default:
+		netdev_dbg(bond_dev, "This slave is always active in trunk mode\n");
+
+		/* always active in trunk mode */
+		bond_set_active_slave(new_slave);
+
+		/* In trunking mode there is little meaning to curr_active_slave
+		 * anyway (it holds no special properties of the bond device),
+		 * so we can change it without calling change_active_interface()
+		 */
+		if (!rcu_access_pointer(bond->curr_active_slave) &&
+		    new_slave->link == BOND_LINK_UP)
+			rcu_assign_pointer(bond->curr_active_slave, new_slave);
+
+		break;
+	} /* switch(bond_mode) */
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	if (bond->dev->npinfo) {
+		if (slave_enable_netpoll(new_slave)) {
+			netdev_info(bond_dev, "master_dev is using netpoll, but new slave device does not support netpoll\n");
+			res = -EBUSY;
+			goto err_detach;
+		}
+	}
+#endif
+
+	if (!(bond_dev->features & NETIF_F_LRO))
+		dev_disable_lro(slave_dev);
+
+	res = netdev_rx_handler_register(slave_dev, bond_handle_frame,
+					 new_slave);
+	if (res) {
+		netdev_dbg(bond_dev, "Error %d calling netdev_rx_handler_register\n", res);
+		goto err_detach;
+	}
+
+	res = bond_master_upper_dev_link(bond, new_slave, extack);
+	if (res) {
+		netdev_dbg(bond_dev, "Error %d calling bond_master_upper_dev_link\n", res);
+		goto err_unregister;
+	}
+
+	res = bond_sysfs_slave_add(new_slave);
+	if (res) {
+		netdev_dbg(bond_dev, "Error %d calling bond_sysfs_slave_add\n", res);
+		goto err_upper_unlink;
+	}
+
+	bond->nest_level = dev_get_nest_level(bond_dev) + 1;
+
+	/* If the mode uses primary, then the following is handled by
+	 * bond_change_active_slave().
+	 */
+	if (!bond_uses_primary(bond)) {
+		/* set promiscuity level to new slave */
+		if (bond_dev->flags & IFF_PROMISC) {
+			res = dev_set_promiscuity(slave_dev, 1);
+			if (res)
+				goto err_sysfs_del;
+		}
+
+		/* set allmulti level to new slave */
+		if (bond_dev->flags & IFF_ALLMULTI) {
+			res = dev_set_allmulti(slave_dev, 1);
+			if (res) {
+				if (bond_dev->flags & IFF_PROMISC)
+					dev_set_promiscuity(slave_dev, -1);
+				goto err_sysfs_del;
+			}
+		}
+
+		netif_addr_lock_bh(bond_dev);
+		dev_mc_sync_multiple(slave_dev, bond_dev);
+		dev_uc_sync_multiple(slave_dev, bond_dev);
+		netif_addr_unlock_bh(bond_dev);
+
+		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+			/* add lacpdu mc addr to mc list */
+			u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
+
+			dev_mc_add(slave_dev, lacpdu_multicast);
+		}
+	}
+
+	bond->slave_cnt++;
+	bond_compute_features(bond);
+	bond_set_carrier(bond);
+
+	if (bond_uses_primary(bond)) {
+		block_netpoll_tx();
+		bond_select_active_slave(bond);
+		unblock_netpoll_tx();
+	}
+
+	if (bond_mode_can_use_xmit_hash(bond))
+		bond_update_slave_arr(bond, NULL);
+
+
+	netdev_info(bond_dev, "Enslaving %s as %s interface with %s link\n",
+		    slave_dev->name,
+		    bond_is_active_slave(new_slave) ? "an active" : "a backup",
+		    new_slave->link != BOND_LINK_DOWN ? "an up" : "a down");
+
+	/* enslave is successful */
+	bond_queue_slave_event(new_slave);
+	return 0;
+
+/* Undo stages on error */
+err_sysfs_del:
+	bond_sysfs_slave_del(new_slave);
+
+err_upper_unlink:
+	bond_upper_dev_unlink(bond, new_slave);
+
+err_unregister:
+	netdev_rx_handler_unregister(slave_dev);
+
+err_detach:
+	vlan_vids_del_by_dev(slave_dev, bond_dev);
+	if (rcu_access_pointer(bond->primary_slave) == new_slave)
+		RCU_INIT_POINTER(bond->primary_slave, NULL);
+	if (rcu_access_pointer(bond->curr_active_slave) == new_slave) {
+		block_netpoll_tx();
+		bond_change_active_slave(bond, NULL);
+		bond_select_active_slave(bond);
+		unblock_netpoll_tx();
+	}
+	/* either primary_slave or curr_active_slave might've changed */
+	synchronize_rcu();
+	slave_disable_netpoll(new_slave);
+
+err_close:
+	if (!netif_is_bond_master(slave_dev))
+		slave_dev->priv_flags &= ~IFF_BONDING;
+	dev_close(slave_dev);
+
+err_restore_mac:
+	slave_dev->flags &= ~IFF_SLAVE;
+	if (!bond->params.fail_over_mac ||
+	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
+		/* XXX TODO - fom follow mode needs to change master's
+		 * MAC if this slave's MAC is in use by the bond, or at
+		 * least print a warning.
+		 */
+		bond_hw_addr_copy(ss.__data, new_slave->perm_hwaddr,
+				  new_slave->dev->addr_len);
+		ss.ss_family = slave_dev->type;
+		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss);
+	}
+
+err_restore_mtu:
+	dev_set_mtu(slave_dev, new_slave->original_mtu);
+
+err_free:
+	kobject_put(&new_slave->kobj);
+
+err_undo_flags:
+	/* Enslave of first slave has failed and we need to fix master's mac */
+	if (!bond_has_slaves(bond)) {
+		if (ether_addr_equal_64bits(bond_dev->dev_addr,
+					    slave_dev->dev_addr))
+			eth_hw_addr_random(bond_dev);
+		if (bond_dev->type != ARPHRD_ETHER) {
+			dev_close(bond_dev);
+			ether_setup(bond_dev);
+			bond_dev->flags |= IFF_MASTER;
+			bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
+		}
+	}
+
+	return res;
+}
+
+/* Try to release the slave device <slave> from the bond device <master>
+ * It is legal to access curr_active_slave without a lock because all the function
+ * is RTNL-locked. If "all" is true it means that the function is being called
+ * while destroying a bond interface and all slaves are being released.
+ *
+ * The rules for slave state should be:
+ *   for Active/Backup:
+ *     Active stays on all backups go down
+ *   for Bonded connections:
+ *     The first up interface should be left on and all others downed.
+ */
+static int __bond_release_one(struct net_device *bond_dev,
+			      struct net_device *slave_dev,
+			      bool all, bool unregister)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave, *oldcurrent;
+	struct sockaddr_storage ss;
+	int old_flags = bond_dev->flags;
+	netdev_features_t old_features = bond_dev->features;
+
+	/* slave is not a slave or master is not master of this slave */
+	if (!(slave_dev->flags & IFF_SLAVE) ||
+	    !netdev_has_upper_dev(slave_dev, bond_dev)) {
+		netdev_dbg(bond_dev, "cannot release %s\n",
+			   slave_dev->name);
+		return -EINVAL;
+	}
+
+	block_netpoll_tx();
+
+	slave = bond_get_slave_by_dev(bond, slave_dev);
+	if (!slave) {
+		/* not a slave of this bond */
+		netdev_info(bond_dev, "%s not enslaved\n",
+			    slave_dev->name);
+		unblock_netpoll_tx();
+		return -EINVAL;
+	}
+
+	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
+
+	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
+
+	bond_sysfs_slave_del(slave);
+
+	/* recompute stats just before removing the slave */
+	bond_get_stats(bond->dev, &bond->bond_stats);
+
+	bond_upper_dev_unlink(bond, slave);
+	/* unregister rx_handler early so bond_handle_frame wouldn't be called
+	 * for this slave anymore.
+	 */
+	netdev_rx_handler_unregister(slave_dev);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD)
+		bond_3ad_unbind_slave(slave);
+
+	if (bond_mode_can_use_xmit_hash(bond))
+		bond_update_slave_arr(bond, slave);
+
+	netdev_info(bond_dev, "Releasing %s interface %s\n",
+		    bond_is_active_slave(slave) ? "active" : "backup",
+		    slave_dev->name);
+
+	oldcurrent = rcu_access_pointer(bond->curr_active_slave);
+
+	RCU_INIT_POINTER(bond->current_arp_slave, NULL);
+
+	if (!all && (!bond->params.fail_over_mac ||
+		     BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP)) {
+		if (ether_addr_equal_64bits(bond_dev->dev_addr, slave->perm_hwaddr) &&
+		    bond_has_slaves(bond))
+			netdev_warn(bond_dev, "the permanent HWaddr of %s - %pM - is still in use by %s - set the HWaddr of %s to a different address to avoid conflicts\n",
+				    slave_dev->name, slave->perm_hwaddr,
+				    bond_dev->name, slave_dev->name);
+	}
+
+	if (rtnl_dereference(bond->primary_slave) == slave)
+		RCU_INIT_POINTER(bond->primary_slave, NULL);
+
+	if (oldcurrent == slave)
+		bond_change_active_slave(bond, NULL);
+
+	if (bond_is_lb(bond)) {
+		/* Must be called only after the slave has been
+		 * detached from the list and the curr_active_slave
+		 * has been cleared (if our_slave == old_current),
+		 * but before a new active slave is selected.
+		 */
+		bond_alb_deinit_slave(bond, slave);
+	}
+
+	if (all) {
+		toe_failover(bond_dev, NULL, TOE_RELEASE_ALL, NULL);
+		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
+	} else if (oldcurrent == slave) {
+		/* Note that we hold RTNL over this sequence, so there
+		 * is no concern that another slave add/remove event
+		 * will interfere.
+		 */
+		bond_select_active_slave(bond);
+	}
+
+	if (!bond_has_slaves(bond)) {
+		bond_set_carrier(bond);
+		eth_hw_addr_random(bond_dev);
+		bond->nest_level = SINGLE_DEPTH_NESTING;
+	} else {
+		bond->nest_level = dev_get_nest_level(bond_dev) + 1;
+	}
+
+	unblock_netpoll_tx();
+	synchronize_rcu();
+	bond->slave_cnt--;
+
+	if (!bond_has_slaves(bond)) {
+		call_netdevice_notifiers(NETDEV_CHANGEADDR, bond->dev);
+		call_netdevice_notifiers(NETDEV_RELEASE, bond->dev);
+	}
+
+	bond_compute_features(bond);
+	if (!(bond_dev->features & NETIF_F_VLAN_CHALLENGED) &&
+	    (old_features & NETIF_F_VLAN_CHALLENGED))
+		netdev_info(bond_dev, "last VLAN challenged slave %s left bond %s - VLAN blocking is removed\n",
+			    slave_dev->name, bond_dev->name);
+
+	vlan_vids_del_by_dev(slave_dev, bond_dev);
+
+	/* If the mode uses primary, then this case was handled above by
+	 * bond_change_active_slave(..., NULL)
+	 */
+	if (!bond_uses_primary(bond)) {
+		/* unset promiscuity level from slave
+		 * NOTE: The NETDEV_CHANGEADDR call above may change the value
+		 * of the IFF_PROMISC flag in the bond_dev, but we need the
+		 * value of that flag before that change, as that was the value
+		 * when this slave was attached, so we cache at the start of the
+		 * function and use it here. Same goes for ALLMULTI below
+		 */
+		if (old_flags & IFF_PROMISC)
+			dev_set_promiscuity(slave_dev, -1);
+
+		/* unset allmulti level from slave */
+		if (old_flags & IFF_ALLMULTI)
+			dev_set_allmulti(slave_dev, -1);
+
+		bond_hw_addr_flush(bond_dev, slave_dev);
+	}
+
+	slave_disable_netpoll(slave);
+
+	/* close slave before restoring its mac address */
+	dev_close(slave_dev);
+
+	if (bond->params.fail_over_mac != BOND_FOM_ACTIVE ||
+	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
+		/* restore original ("permanent") mac address */
+		bond_hw_addr_copy(ss.__data, slave->perm_hwaddr,
+				  slave->dev->addr_len);
+		ss.ss_family = slave_dev->type;
+		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss);
+	}
+
+	if (unregister)
+		__dev_set_mtu(slave_dev, slave->original_mtu);
+	else
+		dev_set_mtu(slave_dev, slave->original_mtu);
+
+	if (!netif_is_bond_master(slave_dev))
+		slave_dev->priv_flags &= ~IFF_BONDING;
+
+	kobject_put(&slave->kobj);
+
+	return 0;
+}
+
+/* A wrapper used because of ndo_del_link */
+int bond_release(struct net_device *bond_dev, struct net_device *slave_dev)
+{
+	return __bond_release_one(bond_dev, slave_dev, false, false);
+}
+
+/* First release a slave and then destroy the bond if no more slaves are left.
+ * Must be under rtnl_lock when this function is called.
+ */
+static int  bond_release_and_destroy(struct net_device *bond_dev,
+				     struct net_device *slave_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	int ret;
+
+	ret = __bond_release_one(bond_dev, slave_dev, false, true);
+	if (ret == 0 && !bond_has_slaves(bond) &&
+	    bond_dev->reg_state != NETREG_UNREGISTERING) {
+		bond_dev->priv_flags |= IFF_DISABLE_NETPOLL;
+		netdev_info(bond_dev, "Destroying bond %s\n",
+			    bond_dev->name);
+		bond_remove_proc_entry(bond);
+		unregister_netdevice(bond_dev);
+	}
+	return ret;
+}
+
+static void bond_info_query(struct net_device *bond_dev, struct ifbond *info)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	bond_fill_ifbond(bond, info);
+}
+
+static int bond_slave_info_query(struct net_device *bond_dev, struct ifslave *info)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	int i = 0, res = -ENODEV;
+	struct slave *slave;
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (i++ == (int)info->slave_id) {
+			res = 0;
+			bond_fill_ifslave(slave, info);
+			break;
+		}
+	}
+
+	return res;
+}
+
+/*-------------------------------- Monitoring -------------------------------*/
+
+/* called with rcu_read_lock() */
+static int bond_miimon_inspect(struct bonding *bond)
+{
+	int link_state, commit = 0;
+	struct list_head *iter;
+	struct slave *slave;
+	bool ignore_updelay;
+
+	ignore_updelay = !rcu_dereference(bond->curr_active_slave);
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
+
+		link_state = bond_check_dev_link(bond, slave->dev, 0);
+
+		switch (slave->link) {
+		case BOND_LINK_UP:
+			if (link_state)
+				continue;
+
+			bond_propose_link_state(slave, BOND_LINK_FAIL);
+			commit++;
+			slave->delay = bond->params.downdelay;
+			if (slave->delay) {
+				netdev_info(bond->dev, "link status down for %sinterface %s, disabling it in %d ms\n",
+					    (BOND_MODE(bond) ==
+					     BOND_MODE_ACTIVEBACKUP) ?
+					     (bond_is_active_slave(slave) ?
+					      "active " : "backup ") : "",
+					    slave->dev->name,
+					    bond->params.downdelay * bond->params.miimon);
+			}
+			/*FALLTHRU*/
+		case BOND_LINK_FAIL:
+			if (link_state) {
+				/* recovered before downdelay expired */
+				bond_propose_link_state(slave, BOND_LINK_UP);
+				slave->last_link_up = jiffies;
+				netdev_info(bond->dev, "link status up again after %d ms for interface %s\n",
+					    (bond->params.downdelay - slave->delay) *
+					    bond->params.miimon,
+					    slave->dev->name);
+				commit++;
+				continue;
+			}
+
+			if (slave->delay <= 0) {
+				bond_propose_link_state(slave, BOND_LINK_DOWN);
+				commit++;
+				continue;
+			}
+
+			slave->delay--;
+			break;
+
+		case BOND_LINK_DOWN:
+			if (!link_state)
+				continue;
+
+			bond_propose_link_state(slave, BOND_LINK_BACK);
+			commit++;
+			slave->delay = bond->params.updelay;
+
+			if (slave->delay) {
+				netdev_info(bond->dev, "link status up for interface %s, enabling it in %d ms\n",
+					    slave->dev->name,
+					    ignore_updelay ? 0 :
+					    bond->params.updelay *
+					    bond->params.miimon);
+			}
+			/*FALLTHRU*/
+		case BOND_LINK_BACK:
+			if (!link_state) {
+				bond_propose_link_state(slave, BOND_LINK_DOWN);
+				netdev_info(bond->dev, "link status down again after %d ms for interface %s\n",
+					    (bond->params.updelay - slave->delay) *
+					    bond->params.miimon,
+					    slave->dev->name);
+				commit++;
+				continue;
+			}
+
+			if (ignore_updelay)
+				slave->delay = 0;
+
+			if (slave->delay <= 0) {
+				bond_propose_link_state(slave, BOND_LINK_UP);
+				commit++;
+				ignore_updelay = false;
+				continue;
+			}
+
+			slave->delay--;
+			break;
+		}
+	}
+
+	return commit;
+}
+
+static void bond_miimon_link_change(struct bonding *bond,
+				    struct slave *slave,
+				    char link)
+{
+	switch (BOND_MODE(bond)) {
+	case BOND_MODE_8023AD:
+		bond_3ad_handle_link_change(slave, link);
+		break;
+	case BOND_MODE_TLB:
+	case BOND_MODE_ALB:
+		bond_alb_handle_link_change(bond, slave, link);
+		break;
+	case BOND_MODE_XOR:
+		bond_update_slave_arr(bond, NULL);
+		break;
+	}
+}
+
+static void bond_miimon_commit(struct bonding *bond)
+{
+	struct list_head *iter;
+	struct slave *slave, *primary;
+
+	bond_for_each_slave(bond, slave, iter) {
+		switch (slave->link_new_state) {
+		case BOND_LINK_NOCHANGE:
+			/* For 802.3ad mode, check current slave speed and
+			 * duplex again in case its port was disabled after
+			 * invalid speed/duplex reporting but recovered before
+			 * link monitoring could make a decision on the actual
+			 * link status
+			 */
+			if (BOND_MODE(bond) == BOND_MODE_8023AD &&
+			    slave->link == BOND_LINK_UP)
+				bond_3ad_adapter_speed_duplex_changed(slave);
+			continue;
+
+		case BOND_LINK_UP:
+			if (bond_update_speed_duplex(slave) &&
+			    bond_needs_speed_duplex(bond)) {
+				slave->link = BOND_LINK_DOWN;
+				if (net_ratelimit())
+					netdev_warn(bond->dev,
+						    "failed to get link speed/duplex for %s\n",
+						    slave->dev->name);
+				continue;
+			}
+			bond_set_slave_link_state(slave, BOND_LINK_UP,
+						  BOND_SLAVE_NOTIFY_NOW);
+			slave->last_link_up = jiffies;
+
+			primary = rtnl_dereference(bond->primary_slave);
+			if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+				/* prevent it from being the active one */
+				bond_set_backup_slave(slave);
+			} else if (BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
+				/* make it immediately active */
+				bond_set_active_slave(slave);
+			}
+
+			netdev_info(bond->dev, "link status definitely up for interface %s, %u Mbps %s duplex\n",
+				    slave->dev->name,
+				    slave->speed == SPEED_UNKNOWN ? 0 : slave->speed,
+				    slave->duplex ? "full" : "half");
+
+			bond_miimon_link_change(bond, slave, BOND_LINK_UP);
+
+			if (BOND_MODE(bond) == BOND_MODE_XOR ||
+			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
+				toe_failover(netdev_master_upper_dev_get(slave->dev),
+					     slave->dev, TOE_LINK_UP, NULL);
+
+			if (!bond->curr_active_slave || slave == primary)
+				goto do_failover;
+
+			continue;
+
+		case BOND_LINK_DOWN:
+			if (slave->link_failure_count < UINT_MAX)
+				slave->link_failure_count++;
+
+			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
+						  BOND_SLAVE_NOTIFY_NOW);
+
+			if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP ||
+			    BOND_MODE(bond) == BOND_MODE_8023AD)
+				bond_set_slave_inactive_flags(slave,
+							      BOND_SLAVE_NOTIFY_NOW);
+
+			netdev_info(bond->dev, "link status definitely down for interface %s, disabling it\n",
+				    slave->dev->name);
+
+			bond_miimon_link_change(bond, slave, BOND_LINK_DOWN);
+
+			if (BOND_MODE(bond) == BOND_MODE_XOR ||
+			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
+				toe_failover(netdev_master_upper_dev_get(slave->dev),
+					     slave->dev, TOE_LINK_DOWN, NULL);
+
+			if (slave == rcu_access_pointer(bond->curr_active_slave))
+				goto do_failover;
+
+			continue;
+
+		default:
+			netdev_err(bond->dev, "invalid new link %d on slave %s\n",
+				   slave->link_new_state, slave->dev->name);
+			bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
+
+			continue;
+		}
+
+do_failover:
+		block_netpoll_tx();
+		bond_select_active_slave(bond);
+		unblock_netpoll_tx();
+	}
+
+	bond_set_carrier(bond);
+}
+
+/* bond_mii_monitor
+ *
+ * Really a wrapper that splits the mii monitor into two phases: an
+ * inspection, then (if inspection indicates something needs to be done)
+ * an acquisition of appropriate locks followed by a commit phase to
+ * implement whatever link state changes are indicated.
+ */
+static void bond_mii_monitor(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    mii_work.work);
+	bool should_notify_peers = false;
+	unsigned long delay;
+	struct slave *slave;
+	struct list_head *iter;
+
+	delay = msecs_to_jiffies(bond->params.miimon);
+
+	if (!bond_has_slaves(bond))
+		goto re_arm;
+
+	rcu_read_lock();
+
+	should_notify_peers = bond_should_notify_peers(bond);
+
+	if (bond_miimon_inspect(bond)) {
+		rcu_read_unlock();
+
+		/* Race avoidance with bond_close cancel of workqueue */
+		if (!rtnl_trylock()) {
+			delay = 1;
+			should_notify_peers = false;
+			goto re_arm;
+		}
+
+		bond_for_each_slave(bond, slave, iter) {
+			bond_commit_link_state(slave, BOND_SLAVE_NOTIFY_LATER);
+		}
+		bond_miimon_commit(bond);
+
+		rtnl_unlock();	/* might sleep, hold no other locks */
+	} else
+		rcu_read_unlock();
+
+re_arm:
+	if (bond->params.miimon)
+		queue_delayed_work(bond->wq, &bond->mii_work, delay);
+
+	if (should_notify_peers) {
+		if (!rtnl_trylock())
+			return;
+		call_netdevice_notifiers(NETDEV_NOTIFY_PEERS, bond->dev);
+		rtnl_unlock();
+	}
+}
+
+static int bond_upper_dev_walk(struct net_device *upper, void *data)
+{
+	__be32 ip = *((__be32 *)data);
+
+	return ip == bond_confirm_addr(upper, 0, ip);
+}
+
+static bool bond_has_this_ip(struct bonding *bond, __be32 ip)
+{
+	bool ret = false;
+
+	if (ip == bond_confirm_addr(bond->dev, 0, ip))
+		return true;
+
+	rcu_read_lock();
+	if (netdev_walk_all_upper_dev_rcu(bond->dev, bond_upper_dev_walk, &ip))
+		ret = true;
+	rcu_read_unlock();
+
+	return ret;
+}
+
+/* We go to the (large) trouble of VLAN tagging ARP frames because
+ * switches in VLAN mode (especially if ports are configured as
+ * "native" to a VLAN) might not pass non-tagged frames.
+ */
+static void bond_arp_send(struct net_device *slave_dev, int arp_op,
+			  __be32 dest_ip, __be32 src_ip,
+			  struct bond_vlan_tag *tags)
+{
+	struct sk_buff *skb;
+	struct bond_vlan_tag *outer_tag = tags;
+
+	netdev_dbg(slave_dev, "arp %d on slave %s: dst %pI4 src %pI4\n",
+		   arp_op, slave_dev->name, &dest_ip, &src_ip);
+
+	skb = arp_create(arp_op, ETH_P_ARP, dest_ip, slave_dev, src_ip,
+			 NULL, slave_dev->dev_addr, NULL);
+
+	if (!skb) {
+		net_err_ratelimited("ARP packet allocation failed\n");
+		return;
+	}
+
+	if (!tags || tags->vlan_proto == VLAN_N_VID)
+		goto xmit;
+
+	tags++;
+
+	/* Go through all the tags backwards and add them to the packet */
+	while (tags->vlan_proto != VLAN_N_VID) {
+		if (!tags->vlan_id) {
+			tags++;
+			continue;
+		}
+
+		netdev_dbg(slave_dev, "inner tag: proto %X vid %X\n",
+			   ntohs(outer_tag->vlan_proto), tags->vlan_id);
+		skb = vlan_insert_tag_set_proto(skb, tags->vlan_proto,
+						tags->vlan_id);
+		if (!skb) {
+			net_err_ratelimited("failed to insert inner VLAN tag\n");
+			return;
+		}
+
+		tags++;
+	}
+	/* Set the outer tag */
+	if (outer_tag->vlan_id) {
+		netdev_dbg(slave_dev, "outer tag: proto %X vid %X\n",
+			   ntohs(outer_tag->vlan_proto), outer_tag->vlan_id);
+		__vlan_hwaccel_put_tag(skb, outer_tag->vlan_proto,
+				       outer_tag->vlan_id);
+	}
+
+xmit:
+	arp_xmit(skb);
+}
+
+/* Validate the device path between the @start_dev and the @end_dev.
+ * The path is valid if the @end_dev is reachable through device
+ * stacking.
+ * When the path is validated, collect any vlan information in the
+ * path.
+ */
+struct bond_vlan_tag *bond_verify_device_path(struct net_device *start_dev,
+					      struct net_device *end_dev,
+					      int level)
+{
+	struct bond_vlan_tag *tags;
+	struct net_device *upper;
+	struct list_head  *iter;
+
+	if (start_dev == end_dev) {
+		tags = kcalloc(level + 1, sizeof(*tags), GFP_ATOMIC);
+		if (!tags)
+			return ERR_PTR(-ENOMEM);
+		tags[level].vlan_proto = VLAN_N_VID;
+		return tags;
+	}
+
+	netdev_for_each_upper_dev_rcu(start_dev, upper, iter) {
+		tags = bond_verify_device_path(upper, end_dev, level + 1);
+		if (IS_ERR_OR_NULL(tags)) {
+			if (IS_ERR(tags))
+				return tags;
+			continue;
+		}
+		if (is_vlan_dev(upper)) {
+			tags[level].vlan_proto = vlan_dev_vlan_proto(upper);
+			tags[level].vlan_id = vlan_dev_vlan_id(upper);
+		}
+
+		return tags;
+	}
+
+	return NULL;
+}
+
+static void bond_arp_send_all(struct bonding *bond, struct slave *slave)
+{
+	struct rtable *rt;
+	struct bond_vlan_tag *tags;
+	__be32 *targets = bond->params.arp_targets, addr;
+	int i;
+
+	for (i = 0; i < BOND_MAX_ARP_TARGETS && targets[i]; i++) {
+		netdev_dbg(bond->dev, "basa: target %pI4\n", &targets[i]);
+		tags = NULL;
+
+		/* Find out through which dev should the packet go */
+		rt = ip_route_output(dev_net(bond->dev), targets[i], 0,
+				     RTO_ONLINK, 0);
+		if (IS_ERR(rt)) {
+			/* there's no route to target - try to send arp
+			 * probe to generate any traffic (arp_validate=0)
+			 */
+			if (bond->params.arp_validate)
+				net_warn_ratelimited("%s: no route to arp_ip_target %pI4 and arp_validate is set\n",
+						     bond->dev->name,
+						     &targets[i]);
+			bond_arp_send(slave->dev, ARPOP_REQUEST, targets[i],
+				      0, tags);
+			continue;
+		}
+
+		/* bond device itself */
+		if (rt->dst.dev == bond->dev)
+			goto found;
+
+		rcu_read_lock();
+		tags = bond_verify_device_path(bond->dev, rt->dst.dev, 0);
+		rcu_read_unlock();
+
+		if (!IS_ERR_OR_NULL(tags))
+			goto found;
+
+		/* Not our device - skip */
+		netdev_dbg(bond->dev, "no path to arp_ip_target %pI4 via rt.dev %s\n",
+			   &targets[i], rt->dst.dev ? rt->dst.dev->name : "NULL");
+
+		ip_rt_put(rt);
+		continue;
+
+found:
+		addr = bond_confirm_addr(rt->dst.dev, targets[i], 0);
+		ip_rt_put(rt);
+		bond_arp_send(slave->dev, ARPOP_REQUEST, targets[i],
+			      addr, tags);
+		kfree(tags);
+	}
+}
+
+static void bond_validate_arp(struct bonding *bond, struct slave *slave, __be32 sip, __be32 tip)
+{
+	int i;
+
+	if (!sip || !bond_has_this_ip(bond, tip)) {
+		netdev_dbg(bond->dev, "bva: sip %pI4 tip %pI4 not found\n",
+			   &sip, &tip);
+		return;
+	}
+
+	i = bond_get_targets_ip(bond->params.arp_targets, sip);
+	if (i == -1) {
+		netdev_dbg(bond->dev, "bva: sip %pI4 not found in targets\n",
+			   &sip);
+		return;
+	}
+	slave->last_rx = jiffies;
+	slave->target_last_arp_rx[i] = jiffies;
+}
+
+int bond_arp_rcv(const struct sk_buff *skb, struct bonding *bond,
+		 struct slave *slave)
+{
+	struct arphdr *arp = (struct arphdr *)skb->data;
+	struct slave *curr_active_slave, *curr_arp_slave;
+	unsigned char *arp_ptr;
+	__be32 sip, tip;
+	int is_arp = skb->protocol == __cpu_to_be16(ETH_P_ARP);
+	unsigned int alen;
+
+	if (!slave_do_arp_validate(bond, slave)) {
+		if ((slave_do_arp_validate_only(bond) && is_arp) ||
+		    !slave_do_arp_validate_only(bond))
+			slave->last_rx = jiffies;
+		return RX_HANDLER_ANOTHER;
+	} else if (!is_arp) {
+		return RX_HANDLER_ANOTHER;
+	}
+
+	alen = arp_hdr_len(bond->dev);
+
+	netdev_dbg(bond->dev, "bond_arp_rcv: skb->dev %s\n",
+		   skb->dev->name);
+
+	if (alen > skb_headlen(skb)) {
+		arp = kmalloc(alen, GFP_ATOMIC);
+		if (!arp)
+			goto out_unlock;
+		if (skb_copy_bits(skb, 0, arp, alen) < 0)
+			goto out_unlock;
+	}
+
+	if (arp->ar_hln != bond->dev->addr_len ||
+	    skb->pkt_type == PACKET_OTHERHOST ||
+	    skb->pkt_type == PACKET_LOOPBACK ||
+	    arp->ar_hrd != htons(ARPHRD_ETHER) ||
+	    arp->ar_pro != htons(ETH_P_IP) ||
+	    arp->ar_pln != 4)
+		goto out_unlock;
+
+	arp_ptr = (unsigned char *)(arp + 1);
+	arp_ptr += bond->dev->addr_len;
+	memcpy(&sip, arp_ptr, 4);
+	arp_ptr += 4 + bond->dev->addr_len;
+	memcpy(&tip, arp_ptr, 4);
+
+	netdev_dbg(bond->dev, "bond_arp_rcv: %s/%d av %d sv %d sip %pI4 tip %pI4\n",
+		   slave->dev->name, bond_slave_state(slave),
+		     bond->params.arp_validate, slave_do_arp_validate(bond, slave),
+		     &sip, &tip);
+
+	curr_active_slave = rcu_dereference(bond->curr_active_slave);
+	curr_arp_slave = rcu_dereference(bond->current_arp_slave);
+
+	/* We 'trust' the received ARP enough to validate it if:
+	 *
+	 * (a) the slave receiving the ARP is active (which includes the
+	 * current ARP slave, if any), or
+	 *
+	 * (b) the receiving slave isn't active, but there is a currently
+	 * active slave and it received valid arp reply(s) after it became
+	 * the currently active slave, or
+	 *
+	 * (c) there is an ARP slave that sent an ARP during the prior ARP
+	 * interval, and we receive an ARP reply on any slave.  We accept
+	 * these because switch FDB update delays may deliver the ARP
+	 * reply to a slave other than the sender of the ARP request.
+	 *
+	 * Note: for (b), backup slaves are receiving the broadcast ARP
+	 * request, not a reply.  This request passes from the sending
+	 * slave through the L2 switch(es) to the receiving slave.  Since
+	 * this is checking the request, sip/tip are swapped for
+	 * validation.
+	 *
+	 * This is done to avoid endless looping when we can't reach the
+	 * arp_ip_target and fool ourselves with our own arp requests.
+	 */
+	if (bond_is_active_slave(slave))
+		bond_validate_arp(bond, slave, sip, tip);
+	else if (curr_active_slave &&
+		 time_after(slave_last_rx(bond, curr_active_slave),
+			    curr_active_slave->last_link_up))
+		bond_validate_arp(bond, slave, tip, sip);
+	else if (curr_arp_slave && (arp->ar_op == htons(ARPOP_REPLY)) &&
+		 bond_time_in_interval(bond,
+				       dev_trans_start(curr_arp_slave->dev), 1))
+		bond_validate_arp(bond, slave, sip, tip);
+
+out_unlock:
+	if (arp != (struct arphdr *)skb->data)
+		kfree(arp);
+	return RX_HANDLER_ANOTHER;
+}
+
+/* function to verify if we're in the arp_interval timeslice, returns true if
+ * (last_act - arp_interval) <= jiffies <= (last_act + mod * arp_interval +
+ * arp_interval/2) . the arp_interval/2 is needed for really fast networks.
+ */
+static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
+				  int mod)
+{
+	int delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
+
+	return time_in_range(jiffies,
+			     last_act - delta_in_ticks,
+			     last_act + mod * delta_in_ticks + delta_in_ticks/2);
+}
+
+/* This function is called regularly to monitor each slave's link
+ * ensuring that traffic is being sent and received when arp monitoring
+ * is used in load-balancing mode. if the adapter has been dormant, then an
+ * arp is transmitted to generate traffic. see activebackup_arp_monitor for
+ * arp monitoring in active backup mode.
+ */
+static void bond_loadbalance_arp_mon(struct bonding *bond)
+{
+	struct slave *slave, *oldcurrent;
+	struct list_head *iter;
+	int do_failover = 0, slave_state_changed = 0;
+
+	if (!bond_has_slaves(bond))
+		goto re_arm;
+
+	rcu_read_lock();
+
+	oldcurrent = rcu_dereference(bond->curr_active_slave);
+	/* see if any of the previous devices are up now (i.e. they have
+	 * xmt and rcv traffic). the curr_active_slave does not come into
+	 * the picture unless it is null. also, slave->last_link_up is not
+	 * needed here because we send an arp on each slave and give a slave
+	 * as long as it needs to get the tx/rx within the delta.
+	 * TODO: what about up/down delay in arp mode? it wasn't here before
+	 *       so it can wait
+	 */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		unsigned long trans_start = dev_trans_start(slave->dev);
+
+		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
+
+		if (slave->link != BOND_LINK_UP) {
+			if (bond_time_in_interval(bond, trans_start, 1) &&
+			    bond_time_in_interval(bond, slave->last_rx, 1)) {
+
+				bond_propose_link_state(slave, BOND_LINK_UP);
+				slave_state_changed = 1;
+
+				/* primary_slave has no meaning in round-robin
+				 * mode. the window of a slave being up and
+				 * curr_active_slave being null after enslaving
+				 * is closed.
+				 */
+				if (!oldcurrent) {
+					netdev_info(bond->dev, "link status definitely up for interface %s\n",
+						    slave->dev->name);
+					do_failover = 1;
+				} else {
+					netdev_info(bond->dev, "interface %s is now up\n",
+						    slave->dev->name);
+				}
+			}
+		} else {
+			/* slave->link == BOND_LINK_UP */
+
+			/* not all switches will respond to an arp request
+			 * when the source ip is 0, so don't take the link down
+			 * if we don't know our ip yet
+			 */
+			if (!bond_time_in_interval(bond, trans_start, 2) ||
+			    !bond_time_in_interval(bond, slave->last_rx, 2)) {
+
+				bond_propose_link_state(slave, BOND_LINK_DOWN);
+				slave_state_changed = 1;
+
+				if (slave->link_failure_count < UINT_MAX)
+					slave->link_failure_count++;
+
+				netdev_info(bond->dev, "interface %s is now down\n",
+					    slave->dev->name);
+
+				if (slave == oldcurrent)
+					do_failover = 1;
+			}
+		}
+
+		/* note: if switch is in round-robin mode, all links
+		 * must tx arp to ensure all links rx an arp - otherwise
+		 * links may oscillate or not come up at all; if switch is
+		 * in something like xor mode, there is nothing we can
+		 * do - all replies will be rx'ed on same link causing slaves
+		 * to be unstable during low/no traffic periods
+		 */
+		if (bond_slave_is_up(slave))
+			bond_arp_send_all(bond, slave);
+	}
+
+	rcu_read_unlock();
+
+	if (do_failover || slave_state_changed) {
+		if (!rtnl_trylock())
+			goto re_arm;
+
+		bond_for_each_slave(bond, slave, iter) {
+			if (slave->link_new_state != BOND_LINK_NOCHANGE)
+				slave->link = slave->link_new_state;
+		}
+
+		if (slave_state_changed) {
+			bond_slave_state_change(bond);
+			if (BOND_MODE(bond) == BOND_MODE_XOR)
+				bond_update_slave_arr(bond, NULL);
+		}
+		if (do_failover) {
+			block_netpoll_tx();
+			bond_select_active_slave(bond);
+			unblock_netpoll_tx();
+		}
+		rtnl_unlock();
+	}
+
+re_arm:
+	if (bond->params.arp_interval)
+		queue_delayed_work(bond->wq, &bond->arp_work,
+				   msecs_to_jiffies(bond->params.arp_interval));
+}
+
+/* Called to inspect slaves for active-backup mode ARP monitor link state
+ * changes.  Sets proposed link state in slaves to specify what action
+ * should take place for the slave.  Returns 0 if no changes are found, >0
+ * if changes to link states must be committed.
+ *
+ * Called with rcu_read_lock held.
+ */
+static int bond_ab_arp_inspect(struct bonding *bond)
+{
+	unsigned long trans_start, last_rx;
+	struct list_head *iter;
+	struct slave *slave;
+	int commit = 0;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
+		last_rx = slave_last_rx(bond, slave);
+
+		if (slave->link != BOND_LINK_UP) {
+			if (bond_time_in_interval(bond, last_rx, 1)) {
+				bond_propose_link_state(slave, BOND_LINK_UP);
+				commit++;
+			} else if (slave->link == BOND_LINK_BACK) {
+				bond_propose_link_state(slave, BOND_LINK_FAIL);
+				commit++;
+			}
+			continue;
+		}
+
+		/* Give slaves 2*delta after being enslaved or made
+		 * active.  This avoids bouncing, as the last receive
+		 * times need a full ARP monitor cycle to be updated.
+		 */
+		if (bond_time_in_interval(bond, slave->last_link_up, 2))
+			continue;
+
+		/* Backup slave is down if:
+		 * - No current_arp_slave AND
+		 * - more than 3*delta since last receive AND
+		 * - the bond has an IP address
+		 *
+		 * Note: a non-null current_arp_slave indicates
+		 * the curr_active_slave went down and we are
+		 * searching for a new one; under this condition
+		 * we only take the curr_active_slave down - this
+		 * gives each slave a chance to tx/rx traffic
+		 * before being taken out
+		 */
+		if (!bond_is_active_slave(slave) &&
+		    !rcu_access_pointer(bond->current_arp_slave) &&
+		    !bond_time_in_interval(bond, last_rx, 3)) {
+			bond_propose_link_state(slave, BOND_LINK_DOWN);
+			commit++;
+		}
+
+		/* Active slave is down if:
+		 * - more than 2*delta since transmitting OR
+		 * - (more than 2*delta since receive AND
+		 *    the bond has an IP address)
+		 */
+		trans_start = dev_trans_start(slave->dev);
+		if (bond_is_active_slave(slave) &&
+		    (!bond_time_in_interval(bond, trans_start, 2) ||
+		     !bond_time_in_interval(bond, last_rx, 2))) {
+			bond_propose_link_state(slave, BOND_LINK_DOWN);
+			commit++;
+		}
+	}
+
+	return commit;
+}
+
+/* Called to commit link state changes noted by inspection step of
+ * active-backup mode ARP monitor.
+ *
+ * Called with RTNL hold.
+ */
+static void bond_ab_arp_commit(struct bonding *bond)
+{
+	unsigned long trans_start;
+	struct list_head *iter;
+	struct slave *slave;
+
+	bond_for_each_slave(bond, slave, iter) {
+		switch (slave->link_new_state) {
+		case BOND_LINK_NOCHANGE:
+			continue;
+
+		case BOND_LINK_UP:
+			trans_start = dev_trans_start(slave->dev);
+			if (rtnl_dereference(bond->curr_active_slave) != slave ||
+			    (!rtnl_dereference(bond->curr_active_slave) &&
+			     bond_time_in_interval(bond, trans_start, 1))) {
+				struct slave *current_arp_slave;
+
+				current_arp_slave = rtnl_dereference(bond->current_arp_slave);
+				bond_set_slave_link_state(slave, BOND_LINK_UP,
+							  BOND_SLAVE_NOTIFY_NOW);
+				if (current_arp_slave) {
+					bond_set_slave_inactive_flags(
+						current_arp_slave,
+						BOND_SLAVE_NOTIFY_NOW);
+					RCU_INIT_POINTER(bond->current_arp_slave, NULL);
+				}
+
+				netdev_info(bond->dev, "link status definitely up for interface %s\n",
+					    slave->dev->name);
+
+				if (!rtnl_dereference(bond->curr_active_slave) ||
+				    slave == rtnl_dereference(bond->primary_slave))
+					goto do_failover;
+
+			}
+
+			continue;
+
+		case BOND_LINK_DOWN:
+			if (slave->link_failure_count < UINT_MAX)
+				slave->link_failure_count++;
+
+			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
+						  BOND_SLAVE_NOTIFY_NOW);
+			bond_set_slave_inactive_flags(slave,
+						      BOND_SLAVE_NOTIFY_NOW);
+
+			netdev_info(bond->dev, "link status definitely down for interface %s, disabling it\n",
+				    slave->dev->name);
+
+			if (slave == rtnl_dereference(bond->curr_active_slave)) {
+				RCU_INIT_POINTER(bond->current_arp_slave, NULL);
+				goto do_failover;
+			}
+
+			continue;
+
+		case BOND_LINK_FAIL:
+			bond_set_slave_link_state(slave, BOND_LINK_FAIL,
+						  BOND_SLAVE_NOTIFY_NOW);
+			bond_set_slave_inactive_flags(slave,
+						      BOND_SLAVE_NOTIFY_NOW);
+
+			/* A slave has just been enslaved and has become
+			 * the current active slave.
+			 */
+			if (rtnl_dereference(bond->curr_active_slave))
+				RCU_INIT_POINTER(bond->current_arp_slave, NULL);
+			continue;
+
+		default:
+			netdev_err(bond->dev, "impossible: new_link %d on slave %s\n",
+				   slave->link_new_state, slave->dev->name);
+			continue;
+		}
+
+do_failover:
+		block_netpoll_tx();
+		bond_select_active_slave(bond);
+		unblock_netpoll_tx();
+	}
+
+	bond_set_carrier(bond);
+}
+
+/* Send ARP probes for active-backup mode ARP monitor.
+ *
+ * Called with rcu_read_lock held.
+ */
+static bool bond_ab_arp_probe(struct bonding *bond)
+{
+	struct slave *slave, *before = NULL, *new_slave = NULL,
+		     *curr_arp_slave = rcu_dereference(bond->current_arp_slave),
+		     *curr_active_slave = rcu_dereference(bond->curr_active_slave);
+	struct list_head *iter;
+	bool found = false;
+	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
+
+	if (curr_arp_slave && curr_active_slave)
+		netdev_info(bond->dev, "PROBE: c_arp %s && cas %s BAD\n",
+			    curr_arp_slave->dev->name,
+			    curr_active_slave->dev->name);
+
+	if (curr_active_slave) {
+		bond_arp_send_all(bond, curr_active_slave);
+		return should_notify_rtnl;
+	}
+
+	/* if we don't have a curr_active_slave, search for the next available
+	 * backup slave from the current_arp_slave and make it the candidate
+	 * for becoming the curr_active_slave
+	 */
+
+	if (!curr_arp_slave) {
+		curr_arp_slave = bond_first_slave_rcu(bond);
+		if (!curr_arp_slave)
+			return should_notify_rtnl;
+	}
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (!found && !before && bond_slave_is_up(slave))
+			before = slave;
+
+		if (found && !new_slave && bond_slave_is_up(slave))
+			new_slave = slave;
+		/* if the link state is up at this point, we
+		 * mark it down - this can happen if we have
+		 * simultaneous link failures and
+		 * reselect_active_interface doesn't make this
+		 * one the current slave so it is still marked
+		 * up when it is actually down
+		 */
+		if (!bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
+			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
+						  BOND_SLAVE_NOTIFY_LATER);
+			if (slave->link_failure_count < UINT_MAX)
+				slave->link_failure_count++;
+
+			bond_set_slave_inactive_flags(slave,
+						      BOND_SLAVE_NOTIFY_LATER);
+
+			netdev_info(bond->dev, "backup interface %s is now down\n",
+				    slave->dev->name);
+		}
+		if (slave == curr_arp_slave)
+			found = true;
+	}
+
+	if (!new_slave && before)
+		new_slave = before;
+
+	if (!new_slave)
+		goto check_state;
+
+	bond_set_slave_link_state(new_slave, BOND_LINK_BACK,
+				  BOND_SLAVE_NOTIFY_LATER);
+	bond_set_slave_active_flags(new_slave, BOND_SLAVE_NOTIFY_LATER);
+	bond_arp_send_all(bond, new_slave);
+	new_slave->last_link_up = jiffies;
+	rcu_assign_pointer(bond->current_arp_slave, new_slave);
+
+check_state:
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (slave->should_notify || slave->should_notify_link) {
+			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
+			break;
+		}
+	}
+	return should_notify_rtnl;
+}
+
+static void bond_activebackup_arp_mon(struct bonding *bond)
+{
+	bool should_notify_peers = false;
+	bool should_notify_rtnl = false;
+	int delta_in_ticks;
+
+	delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
+
+	if (!bond_has_slaves(bond))
+		goto re_arm;
+
+	rcu_read_lock();
+
+	should_notify_peers = bond_should_notify_peers(bond);
+
+	if (bond_ab_arp_inspect(bond)) {
+		rcu_read_unlock();
+
+		/* Race avoidance with bond_close flush of workqueue */
+		if (!rtnl_trylock()) {
+			delta_in_ticks = 1;
+			should_notify_peers = false;
+			goto re_arm;
+		}
+
+		bond_ab_arp_commit(bond);
+
+		rtnl_unlock();
+		rcu_read_lock();
+	}
+
+	should_notify_rtnl = bond_ab_arp_probe(bond);
+	rcu_read_unlock();
+
+re_arm:
+	if (bond->params.arp_interval)
+		queue_delayed_work(bond->wq, &bond->arp_work, delta_in_ticks);
+
+	if (should_notify_peers || should_notify_rtnl) {
+		if (!rtnl_trylock())
+			return;
+
+		if (should_notify_peers)
+			call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
+						 bond->dev);
+		if (should_notify_rtnl) {
+			bond_slave_state_notify(bond);
+			bond_slave_link_notify(bond);
+		}
+
+		rtnl_unlock();
+	}
+}
+
+static void bond_arp_monitor(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    arp_work.work);
+
+	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
+		bond_activebackup_arp_mon(bond);
+	else
+		bond_loadbalance_arp_mon(bond);
+}
+
+/*-------------------------- netdev event handling --------------------------*/
+
+/* Change device name */
+static int bond_event_changename(struct bonding *bond)
+{
+	bond_remove_proc_entry(bond);
+	bond_create_proc_entry(bond);
+
+	bond_debug_reregister(bond);
+
+	return NOTIFY_DONE;
+}
+
+static int bond_master_netdev_event(unsigned long event,
+				    struct net_device *bond_dev)
+{
+	struct bonding *event_bond = netdev_priv(bond_dev);
+
+	switch (event) {
+	case NETDEV_CHANGENAME:
+		return bond_event_changename(event_bond);
+	case NETDEV_UNREGISTER:
+		bond_remove_proc_entry(event_bond);
+		break;
+	case NETDEV_REGISTER:
+		bond_create_proc_entry(event_bond);
+		break;
+	case NETDEV_DOWN: {
+		struct slave *slave = bond_first_slave(event_bond);
+
+		toe_failover(bond_dev, slave ? slave->dev : NULL,
+			     TOE_BOND_DOWN, NULL);
+		break;
+	}
+	case NETDEV_UP: {
+		struct slave *slave = bond_first_slave(event_bond);
+
+		toe_failover(bond_dev, slave ? slave->dev : NULL,
+			     TOE_BOND_UP, NULL);
+		break;
+	}
+	case NETDEV_NOTIFY_PEERS:
+		if (event_bond->send_peer_notif)
+			event_bond->send_peer_notif--;
+		break;
+	default:
+		break;
+	}
+
+	return NOTIFY_DONE;
+}
+
+static int bond_slave_netdev_event(unsigned long event,
+				   struct net_device *slave_dev)
+{
+	struct slave *slave = bond_slave_get_rtnl(slave_dev), *primary;
+	struct bonding *bond;
+	struct net_device *bond_dev;
+
+	/* A netdev event can be generated while enslaving a device
+	 * before netdev_rx_handler_register is called in which case
+	 * slave will be NULL
+	 */
+	if (!slave)
+		return NOTIFY_DONE;
+	bond_dev = slave->bond->dev;
+	bond = slave->bond;
+	primary = rtnl_dereference(bond->primary_slave);
+
+	switch (event) {
+	case NETDEV_UNREGISTER:
+		if (bond_dev->type != ARPHRD_ETHER)
+			bond_release_and_destroy(bond_dev, slave_dev);
+		else
+			__bond_release_one(bond_dev, slave_dev, false, true);
+		break;
+	case NETDEV_UP:
+	case NETDEV_CHANGE:
+		/* For 802.3ad mode only:
+		 * Getting invalid Speed/Duplex values here will put slave
+		 * in weird state. Mark it as link-fail if the link was
+		 * previously up or link-down if it hasn't yet come up, and
+		 * let link-monitoring (miimon) set it right when correct
+		 * speeds/duplex are available.
+		 */
+		if (bond_update_speed_duplex(slave) &&
+		    BOND_MODE(bond) == BOND_MODE_8023AD) {
+			if (slave->last_link_up)
+				slave->link = BOND_LINK_FAIL;
+			else
+				slave->link = BOND_LINK_DOWN;
+		}
+
+		if (BOND_MODE(bond) == BOND_MODE_8023AD)
+			bond_3ad_adapter_speed_duplex_changed(slave);
+		/* Fallthrough */
+	case NETDEV_DOWN:
+		/* Refresh slave-array if applicable!
+		 * If the setup does not use miimon or arpmon (mode-specific!),
+		 * then these events will not cause the slave-array to be
+		 * refreshed. This will cause xmit to use a slave that is not
+		 * usable. Avoid such situation by refeshing the array at these
+		 * events. If these (miimon/arpmon) parameters are configured
+		 * then array gets refreshed twice and that should be fine!
+		 */
+		if (bond_mode_can_use_xmit_hash(bond))
+			bond_update_slave_arr(bond, NULL);
+		break;
+	case NETDEV_CHANGEMTU:
+		/* TODO: Should slaves be allowed to
+		 * independently alter their MTU?  For
+		 * an active-backup bond, slaves need
+		 * not be the same type of device, so
+		 * MTUs may vary.  For other modes,
+		 * slaves arguably should have the
+		 * same MTUs. To do this, we'd need to
+		 * take over the slave's change_mtu
+		 * function for the duration of their
+		 * servitude.
+		 */
+		break;
+	case NETDEV_CHANGENAME:
+		/* we don't care if we don't have primary set */
+		if (!bond_uses_primary(bond) ||
+		    !bond->params.primary[0])
+			break;
+
+		if (slave == primary) {
+			/* slave's name changed - he's no longer primary */
+			RCU_INIT_POINTER(bond->primary_slave, NULL);
+		} else if (!strcmp(slave_dev->name, bond->params.primary)) {
+			/* we have a new primary slave */
+			rcu_assign_pointer(bond->primary_slave, slave);
+		} else { /* we didn't change primary - exit */
+			break;
+		}
+
+		netdev_info(bond->dev, "Primary slave changed to %s, reselecting active slave\n",
+			    primary ? slave_dev->name : "none");
+
+		block_netpoll_tx();
+		bond_select_active_slave(bond);
+		unblock_netpoll_tx();
+		break;
+	case NETDEV_FEAT_CHANGE:
+		bond_compute_features(bond);
+		break;
+	case NETDEV_RESEND_IGMP:
+		/* Propagate to master device */
+		call_netdevice_notifiers(event, slave->bond->dev);
+		break;
+	default:
+		break;
+	}
+
+	return NOTIFY_DONE;
+}
+
+/* bond_netdev_event: handle netdev notifier chain events.
+ *
+ * This function receives events for the netdev chain.  The caller (an
+ * ioctl handler calling blocking_notifier_call_chain) holds the necessary
+ * locks for us to safely manipulate the slave devices (RTNL lock,
+ * dev_probe_lock).
+ */
+static int bond_netdev_event(struct notifier_block *this,
+			     unsigned long event, void *ptr)
+{
+	struct net_device *event_dev = netdev_notifier_info_to_dev(ptr);
+
+	netdev_dbg(event_dev, "event: %lx\n", event);
+
+	if (!(event_dev->priv_flags & IFF_BONDING))
+		return NOTIFY_DONE;
+
+	if (event_dev->flags & IFF_MASTER) {
+		int ret;
+
+		netdev_dbg(event_dev, "IFF_MASTER\n");
+		ret = bond_master_netdev_event(event, event_dev);
+		if (ret != NOTIFY_DONE)
+			return ret;
+	}
+
+	if (event_dev->flags & IFF_SLAVE) {
+		netdev_dbg(event_dev, "IFF_SLAVE\n");
+		return bond_slave_netdev_event(event, event_dev);
+	}
+
+	return NOTIFY_DONE;
+}
+
+static struct notifier_block bond_netdev_notifier = {
+	.notifier_call = bond_netdev_event,
+};
+
+/*---------------------------- Hashing Policies -----------------------------*/
+
+/* L2 hash helper */
+static inline u32 bond_eth_hash(struct sk_buff *skb)
+{
+	struct ethhdr *ep, hdr_tmp;
+
+	ep = skb_header_pointer(skb, 0, sizeof(hdr_tmp), &hdr_tmp);
+	if (ep)
+		return ep->h_dest[5] ^ ep->h_source[5] ^ ep->h_proto;
+	return 0;
+}
+
+/* Extract the appropriate headers based on bond's xmit policy */
+static bool bond_flow_dissect(struct bonding *bond, struct sk_buff *skb,
+			      struct flow_keys *fk)
+{
+	const struct ipv6hdr *iph6;
+	const struct iphdr *iph;
+	int noff, proto = -1;
+
+	if (bond->params.xmit_policy > BOND_XMIT_POLICY_LAYER23)
+		return skb_flow_dissect_flow_keys(skb, fk, 0);
+
+	fk->ports.ports = 0;
+	noff = skb_network_offset(skb);
+	if (skb->protocol == htons(ETH_P_IP)) {
+		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
+			return false;
+		iph = ip_hdr(skb);
+		iph_to_flow_copy_v4addrs(fk, iph);
+		noff += iph->ihl << 2;
+		if (!ip_is_fragment(iph))
+			proto = iph->protocol;
+	} else if (skb->protocol == htons(ETH_P_IPV6)) {
+		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph6))))
+			return false;
+		iph6 = ipv6_hdr(skb);
+		iph_to_flow_copy_v6addrs(fk, iph6);
+		noff += sizeof(*iph6);
+		proto = iph6->nexthdr;
+	} else {
+		return false;
+	}
+	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER34 && proto >= 0)
+		fk->ports.ports = skb_flow_get_ports(skb, noff, proto);
+
+	return true;
+}
+
+/**
+ * bond_xmit_hash - generate a hash value based on the xmit policy
+ * @bond: bonding device
+ * @skb: buffer to use for headers
+ *
+ * This function will extract the necessary headers from the skb buffer and use
+ * them to generate a hash based on the xmit_policy set in the bonding device
+ */
+u32 bond_xmit_hash(struct bonding *bond, struct sk_buff *skb)
+{
+	struct flow_keys flow;
+	u32 hash;
+
+	if (bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP34 &&
+	    skb->l4_hash)
+		return skb->hash;
+
+	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER2 ||
+	    !bond_flow_dissect(bond, skb, &flow))
+		return bond_eth_hash(skb);
+
+	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER23 ||
+	    bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP23)
+		hash = bond_eth_hash(skb);
+	else
+		hash = (__force u32)flow.ports.ports;
+	hash ^= (__force u32)flow_get_u32_dst(&flow) ^
+		(__force u32)flow_get_u32_src(&flow);
+	hash ^= (hash >> 16);
+	hash ^= (hash >> 8);
+
+	return hash >> 1;
+}
+
+/*-------------------------- Device entry points ----------------------------*/
+
+void bond_work_init_all(struct bonding *bond)
+{
+	INIT_DELAYED_WORK(&bond->mcast_work,
+			  bond_resend_igmp_join_requests_delayed);
+	INIT_DELAYED_WORK(&bond->alb_work, bond_alb_monitor);
+	INIT_DELAYED_WORK(&bond->mii_work, bond_mii_monitor);
+	INIT_DELAYED_WORK(&bond->arp_work, bond_arp_monitor);
+	INIT_DELAYED_WORK(&bond->ad_work, bond_3ad_state_machine_handler);
+	INIT_DELAYED_WORK(&bond->slave_arr_work, bond_slave_arr_handler);
+}
+
+static void bond_work_cancel_all(struct bonding *bond)
+{
+	cancel_delayed_work_sync(&bond->mii_work);
+	cancel_delayed_work_sync(&bond->arp_work);
+	cancel_delayed_work_sync(&bond->alb_work);
+	cancel_delayed_work_sync(&bond->ad_work);
+	cancel_delayed_work_sync(&bond->mcast_work);
+	cancel_delayed_work_sync(&bond->slave_arr_work);
+}
+
+static int bond_open(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	struct slave *slave;
+
+	/* reset slave->backup and slave->inactive */
+	if (bond_has_slaves(bond)) {
+		bond_for_each_slave(bond, slave, iter) {
+			if (bond_uses_primary(bond) &&
+			    slave != rcu_access_pointer(bond->curr_active_slave)) {
+				bond_set_slave_inactive_flags(slave,
+							      BOND_SLAVE_NOTIFY_NOW);
+			} else if (BOND_MODE(bond) != BOND_MODE_8023AD) {
+				bond_set_slave_active_flags(slave,
+							    BOND_SLAVE_NOTIFY_NOW);
+			}
+		}
+	}
+
+	if (bond_is_lb(bond)) {
+		/* bond_alb_initialize must be called before the timer
+		 * is started.
+		 */
+		if (bond_alb_initialize(bond, (BOND_MODE(bond) == BOND_MODE_ALB)))
+			return -ENOMEM;
+		if (bond->params.tlb_dynamic_lb || BOND_MODE(bond) == BOND_MODE_ALB)
+			queue_delayed_work(bond->wq, &bond->alb_work, 0);
+	}
+
+	if (bond->params.miimon)  /* link check interval, in milliseconds. */
+		queue_delayed_work(bond->wq, &bond->mii_work, 0);
+
+	if (bond->params.arp_interval) {  /* arp interval, in milliseconds. */
+		queue_delayed_work(bond->wq, &bond->arp_work, 0);
+		bond->recv_probe = bond_arp_rcv;
+	}
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		queue_delayed_work(bond->wq, &bond->ad_work, 0);
+		/* register to receive LACPDUs */
+		bond->recv_probe = bond_3ad_lacpdu_recv;
+		bond_3ad_initiate_agg_selection(bond, 1);
+	}
+
+	if (bond_mode_can_use_xmit_hash(bond))
+		bond_update_slave_arr(bond, NULL);
+
+	return 0;
+}
+
+static int bond_close(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+
+	bond_work_cancel_all(bond);
+	bond->send_peer_notif = 0;
+	if (bond_is_lb(bond))
+		bond_alb_deinitialize(bond);
+	bond->recv_probe = NULL;
+
+	return 0;
+}
+
+/* fold stats, assuming all rtnl_link_stats64 fields are u64, but
+ * that some drivers can provide 32bit values only.
+ */
+static void bond_fold_stats(struct rtnl_link_stats64 *_res,
+			    const struct rtnl_link_stats64 *_new,
+			    const struct rtnl_link_stats64 *_old)
+{
+	const u64 *new = (const u64 *)_new;
+	const u64 *old = (const u64 *)_old;
+	u64 *res = (u64 *)_res;
+	int i;
+
+	for (i = 0; i < sizeof(*_res) / sizeof(u64); i++) {
+		u64 nv = new[i];
+		u64 ov = old[i];
+		s64 delta = nv - ov;
+
+		/* detects if this particular field is 32bit only */
+		if (((nv | ov) >> 32) == 0)
+			delta = (s64)(s32)((u32)nv - (u32)ov);
+
+		/* filter anomalies, some drivers reset their stats
+		 * at down/up events.
+		 */
+		if (delta > 0)
+			res[i] += delta;
+	}
+}
+
+static int bond_get_nest_level(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+
+	return bond->nest_level;
+}
+
+static void bond_get_stats(struct net_device *bond_dev,
+			   struct rtnl_link_stats64 *stats)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct rtnl_link_stats64 temp;
+	struct list_head *iter;
+	struct slave *slave;
+
+	spin_lock_nested(&bond->stats_lock, bond_get_nest_level(bond_dev));
+	memcpy(stats, &bond->bond_stats, sizeof(*stats));
+
+	rcu_read_lock();
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		const struct rtnl_link_stats64 *new =
+			dev_get_stats(slave->dev, &temp);
+
+		bond_fold_stats(stats, new, &slave->slave_stats);
+
+		/* save off the slave stats for the next run */
+		memcpy(&slave->slave_stats, new, sizeof(*new));
+	}
+	rcu_read_unlock();
+
+	memcpy(&bond->bond_stats, stats, sizeof(*stats));
+	spin_unlock(&bond->stats_lock);
+}
+
+static int bond_do_ioctl(struct net_device *bond_dev, struct ifreq *ifr, int cmd)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct net_device *slave_dev = NULL;
+	struct ifbond k_binfo;
+	struct ifbond __user *u_binfo = NULL;
+	struct ifslave k_sinfo;
+	struct ifslave __user *u_sinfo = NULL;
+	struct mii_ioctl_data *mii = NULL;
+	struct bond_opt_value newval;
+	struct net *net;
+	int res = 0;
+
+	netdev_dbg(bond_dev, "bond_ioctl: cmd=%d\n", cmd);
+
+	switch (cmd) {
+	case SIOCGMIIPHY:
+		mii = if_mii(ifr);
+		if (!mii)
+			return -EINVAL;
+
+		mii->phy_id = 0;
+		/* Fall Through */
+	case SIOCGMIIREG:
+		/* We do this again just in case we were called by SIOCGMIIREG
+		 * instead of SIOCGMIIPHY.
+		 */
+		mii = if_mii(ifr);
+		if (!mii)
+			return -EINVAL;
+
+		if (mii->reg_num == 1) {
+			mii->val_out = 0;
+			if (netif_carrier_ok(bond->dev))
+				mii->val_out = BMSR_LSTATUS;
+		}
+
+		return 0;
+	case BOND_INFO_QUERY_OLD:
+	case SIOCBONDINFOQUERY:
+		u_binfo = (struct ifbond __user *)ifr->ifr_data;
+
+		if (copy_from_user(&k_binfo, u_binfo, sizeof(ifbond)))
+			return -EFAULT;
+
+		bond_info_query(bond_dev, &k_binfo);
+		if (copy_to_user(u_binfo, &k_binfo, sizeof(ifbond)))
+			return -EFAULT;
+
+		return 0;
+	case BOND_SLAVE_INFO_QUERY_OLD:
+	case SIOCBONDSLAVEINFOQUERY:
+		u_sinfo = (struct ifslave __user *)ifr->ifr_data;
+
+		if (copy_from_user(&k_sinfo, u_sinfo, sizeof(ifslave)))
+			return -EFAULT;
+
+		res = bond_slave_info_query(bond_dev, &k_sinfo);
+		if (res == 0 &&
+		    copy_to_user(u_sinfo, &k_sinfo, sizeof(ifslave)))
+			return -EFAULT;
+
+		return res;
+	default:
+		break;
+	}
+
+	net = dev_net(bond_dev);
+
+	if (!ns_capable(net->user_ns, CAP_NET_ADMIN))
+		return -EPERM;
+
+	slave_dev = __dev_get_by_name(net, ifr->ifr_slave);
+
+	netdev_dbg(bond_dev, "slave_dev=%p:\n", slave_dev);
+
+	if (!slave_dev)
+		return -ENODEV;
+
+	netdev_dbg(bond_dev, "slave_dev->name=%s:\n", slave_dev->name);
+	switch (cmd) {
+	case BOND_ENSLAVE_OLD:
+	case SIOCBONDENSLAVE:
+		res = bond_enslave(bond_dev, slave_dev, NULL);
+		break;
+	case BOND_RELEASE_OLD:
+	case SIOCBONDRELEASE:
+		res = bond_release(bond_dev, slave_dev);
+		break;
+	case BOND_SETHWADDR_OLD:
+	case SIOCBONDSETHWADDR:
+		bond_set_dev_addr(bond_dev, slave_dev);
+		res = 0;
+		break;
+	case BOND_CHANGE_ACTIVE_OLD:
+	case SIOCBONDCHANGEACTIVE:
+		bond_opt_initstr(&newval, slave_dev->name);
+		res = __bond_opt_set_notify(bond, BOND_OPT_ACTIVE_SLAVE,
+					    &newval);
+		break;
+	default:
+		res = -EOPNOTSUPP;
+	}
+
+	return res;
+}
+
+static void bond_change_rx_flags(struct net_device *bond_dev, int change)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+
+	if (change & IFF_PROMISC)
+		bond_set_promiscuity(bond,
+				     bond_dev->flags & IFF_PROMISC ? 1 : -1);
+
+	if (change & IFF_ALLMULTI)
+		bond_set_allmulti(bond,
+				  bond_dev->flags & IFF_ALLMULTI ? 1 : -1);
+}
+
+static void bond_set_rx_mode(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	struct slave *slave;
+
+	rcu_read_lock();
+	if (bond_uses_primary(bond)) {
+		slave = rcu_dereference(bond->curr_active_slave);
+		if (slave) {
+			dev_uc_sync(slave->dev, bond_dev);
+			dev_mc_sync(slave->dev, bond_dev);
+		}
+	} else {
+		bond_for_each_slave_rcu(bond, slave, iter) {
+			dev_uc_sync_multiple(slave->dev, bond_dev);
+			dev_mc_sync_multiple(slave->dev, bond_dev);
+		}
+	}
+	rcu_read_unlock();
+}
+
+static int bond_neigh_init(struct neighbour *n)
+{
+	struct bonding *bond = netdev_priv(n->dev);
+	const struct net_device_ops *slave_ops;
+	struct neigh_parms parms;
+	struct slave *slave;
+	int ret;
+
+	slave = bond_first_slave(bond);
+	if (!slave)
+		return 0;
+	slave_ops = slave->dev->netdev_ops;
+	if (!slave_ops->ndo_neigh_setup)
+		return 0;
+
+	parms.neigh_setup = NULL;
+	parms.neigh_cleanup = NULL;
+	ret = slave_ops->ndo_neigh_setup(slave->dev, &parms);
+	if (ret)
+		return ret;
+
+	/* Assign slave's neigh_cleanup to neighbour in case cleanup is called
+	 * after the last slave has been detached.  Assumes that all slaves
+	 * utilize the same neigh_cleanup (true at this writing as only user
+	 * is ipoib).
+	 */
+	n->parms->neigh_cleanup = parms.neigh_cleanup;
+
+	if (!parms.neigh_setup)
+		return 0;
+
+	return parms.neigh_setup(n);
+}
+
+/* The bonding ndo_neigh_setup is called at init time beofre any
+ * slave exists. So we must declare proxy setup function which will
+ * be used at run time to resolve the actual slave neigh param setup.
+ *
+ * It's also called by master devices (such as vlans) to setup their
+ * underlying devices. In that case - do nothing, we're already set up from
+ * our init.
+ */
+static int bond_neigh_setup(struct net_device *dev,
+			    struct neigh_parms *parms)
+{
+	/* modify only our neigh_parms */
+	if (parms->dev == dev)
+		parms->neigh_setup = bond_neigh_init;
+
+	return 0;
+}
+
+/* Change the MTU of all of a master's slaves to match the master */
+static int bond_change_mtu(struct net_device *bond_dev, int new_mtu)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave, *rollback_slave;
+	struct list_head *iter;
+	int res = 0;
+
+	netdev_dbg(bond_dev, "bond=%p, new_mtu=%d\n", bond, new_mtu);
+
+	bond_for_each_slave(bond, slave, iter) {
+		netdev_dbg(bond_dev, "s %p c_m %p\n",
+			   slave, slave->dev->netdev_ops->ndo_change_mtu);
+
+		res = dev_set_mtu(slave->dev, new_mtu);
+
+		if (res) {
+			/* If we failed to set the slave's mtu to the new value
+			 * we must abort the operation even in ACTIVE_BACKUP
+			 * mode, because if we allow the backup slaves to have
+			 * different mtu values than the active slave we'll
+			 * need to change their mtu when doing a failover. That
+			 * means changing their mtu from timer context, which
+			 * is probably not a good idea.
+			 */
+			netdev_dbg(bond_dev, "err %d %s\n", res,
+				   slave->dev->name);
+			goto unwind;
+		}
+	}
+
+	bond_dev->mtu = new_mtu;
+
+	return 0;
+
+unwind:
+	/* unwind from head to the slave that failed */
+	bond_for_each_slave(bond, rollback_slave, iter) {
+		int tmp_res;
+
+		if (rollback_slave == slave)
+			break;
+
+		tmp_res = dev_set_mtu(rollback_slave->dev, bond_dev->mtu);
+		if (tmp_res) {
+			netdev_dbg(bond_dev, "unwind err %d dev %s\n",
+				   tmp_res, rollback_slave->dev->name);
+		}
+	}
+
+	return res;
+}
+
+/* Change HW address
+ *
+ * Note that many devices must be down to change the HW address, and
+ * downing the master releases all slaves.  We can make bonds full of
+ * bonding devices to test this, however.
+ */
+static int bond_set_mac_address(struct net_device *bond_dev, void *addr)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave, *rollback_slave;
+	struct sockaddr_storage *ss = addr, tmp_ss;
+	struct list_head *iter;
+	int res = 0;
+
+	if (BOND_MODE(bond) == BOND_MODE_ALB)
+		return bond_alb_set_mac_address(bond_dev, addr);
+
+
+	netdev_dbg(bond_dev, "bond=%p\n", bond);
+
+	/* If fail_over_mac is enabled, do nothing and return success.
+	 * Returning an error causes ifenslave to fail.
+	 */
+	if (bond->params.fail_over_mac &&
+	    BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
+		return 0;
+
+	if (!is_valid_ether_addr(ss->__data))
+		return -EADDRNOTAVAIL;
+
+	bond_for_each_slave(bond, slave, iter) {
+		netdev_dbg(bond_dev, "slave %p %s\n", slave, slave->dev->name);
+		res = dev_set_mac_address(slave->dev, addr);
+		if (res) {
+			/* TODO: consider downing the slave
+			 * and retry ?
+			 * User should expect communications
+			 * breakage anyway until ARP finish
+			 * updating, so...
+			 */
+			netdev_dbg(bond_dev, "err %d %s\n", res, slave->dev->name);
+			goto unwind;
+		}
+	}
+
+	/* success */
+	memcpy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
+	return 0;
+
+unwind:
+	memcpy(tmp_ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
+	tmp_ss.ss_family = bond_dev->type;
+
+	/* unwind from head to the slave that failed */
+	bond_for_each_slave(bond, rollback_slave, iter) {
+		int tmp_res;
+
+		if (rollback_slave == slave)
+			break;
+
+		tmp_res = dev_set_mac_address(rollback_slave->dev,
+					      (struct sockaddr *)&tmp_ss);
+		if (tmp_res) {
+			netdev_dbg(bond_dev, "unwind err %d dev %s\n",
+				   tmp_res, rollback_slave->dev->name);
+		}
+	}
+
+	return res;
+}
+
+static struct net_device *bond_xmit_slave_id_select(struct bonding *bond,
+						    int slave_id)
+{
+	struct net_device *slave_dev = NULL;
+	struct list_head *iter;
+	struct slave *slave;
+	int i = slave_id;
+
+	/* Here we start from the slave with slave_id */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (--i < 0) {
+			if (bond_slave_can_tx(slave)) {
+				slave_dev = slave->dev;
+				return slave_dev;
+			}
+		}
+	}
+
+	/* Here we start from the first slave up to slave_id */
+	i = slave_id;
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (--i < 0)
+			break;
+		if (bond_slave_can_tx(slave)) {
+			slave_dev = slave->dev;
+			return slave_dev;
+		}
+	}
+	return slave_dev;
+}
+
+/**
+ * bond_xmit_slave_id - transmit skb through slave with slave_id
+ * @bond: bonding device that is transmitting
+ * @skb: buffer to transmit
+ * @slave_id: slave id up to slave_cnt-1 through which to transmit
+ *
+ * This function tries to transmit through slave with slave_id but in case
+ * it fails, it tries to find the first available slave for transmission.
+ * The skb is consumed in all cases, thus the function is void.
+ */
+static void bond_xmit_slave_id(struct bonding *bond, struct sk_buff *skb, int slave_id)
+{
+	struct list_head *iter;
+	struct slave *slave;
+	int i = slave_id;
+
+	/* Here we start from the slave with slave_id */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (--i < 0) {
+			if (bond_slave_can_tx(slave)) {
+				bond_dev_queue_xmit(bond, skb, slave->dev);
+				return;
+			}
+		}
+	}
+
+	/* Here we start from the first slave up to slave_id */
+	i = slave_id;
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (--i < 0)
+			break;
+		if (bond_slave_can_tx(slave)) {
+			bond_dev_queue_xmit(bond, skb, slave->dev);
+			return;
+		}
+	}
+	/* no slave that can tx has been found */
+	bond_tx_drop(bond->dev, skb);
+}
+
+/**
+ * bond_rr_gen_slave_id - generate slave id based on packets_per_slave
+ * @bond: bonding device to use
+ *
+ * Based on the value of the bonding device's packets_per_slave parameter
+ * this function generates a slave id, which is usually used as the next
+ * slave to transmit through.
+ */
+static u32 bond_rr_gen_slave_id(struct bonding *bond)
+{
+	u32 slave_id;
+	struct reciprocal_value reciprocal_packets_per_slave;
+	int packets_per_slave = bond->params.packets_per_slave;
+
+	switch (packets_per_slave) {
+	case 0:
+		slave_id = prandom_u32();
+		break;
+	case 1:
+		slave_id = bond->rr_tx_counter;
+		break;
+	default:
+		reciprocal_packets_per_slave =
+			bond->params.reciprocal_packets_per_slave;
+		slave_id = reciprocal_divide(bond->rr_tx_counter,
+					     reciprocal_packets_per_slave);
+		break;
+	}
+	bond->rr_tx_counter++;
+
+	return slave_id;
+}
+
+static struct net_device *bond_xmit_roundrobin_select(int slave_id,
+						      struct net_device *bond_dev)
+{
+		struct bonding *bond = netdev_priv(bond_dev);
+
+		return bond_xmit_slave_id_select(bond, slave_id);
+}
+
+static netdev_tx_t bond_xmit_roundrobin(struct sk_buff *skb,
+					struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave;
+	int slave_cnt;
+	u32 slave_id;
+
+	/* Start with the curr_active_slave that joined the bond as the
+	 * default for sending IGMP traffic.  For failover purposes one
+	 * needs to maintain some consistency for the interface that will
+	 * send the join/membership reports.  The curr_active_slave found
+	 * will send all of this type of traffic.
+	 */
+	if (skb->protocol == htons(ETH_P_IP)) {
+		int noff = skb_network_offset(skb);
+		struct iphdr *iph;
+
+		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
+			goto non_igmp;
+
+		iph = ip_hdr(skb);
+		if (iph->protocol == IPPROTO_IGMP) {
+			slave = rcu_dereference(bond->curr_active_slave);
+			if (slave)
+				bond_dev_queue_xmit(bond, skb, slave->dev);
+			else
+				bond_xmit_slave_id(bond, skb, 0);
+			return NETDEV_TX_OK;
+		}
+	}
+
+non_igmp:
+	slave_cnt = READ_ONCE(bond->slave_cnt);
+	if (likely(slave_cnt)) {
+		slave_id = bond_rr_gen_slave_id(bond);
+		bond_xmit_slave_id(bond, skb, slave_id % slave_cnt);
+	} else {
+		bond_tx_drop(bond_dev, skb);
+	}
+	return NETDEV_TX_OK;
+}
+
+static struct net_device *bond_xmit_activebackup_select(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct net_device *slave_dev = NULL;
+	struct slave *slave;
+
+	slave = rcu_dereference(bond->curr_active_slave);
+	if (slave)
+		slave_dev = slave->dev;
+
+	return slave_dev;
+}
+
+/* In active-backup mode, we know that bond->curr_active_slave is always valid if
+ * the bond has a usable interface.
+ */
+static netdev_tx_t bond_xmit_activebackup(struct sk_buff *skb,
+					  struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave;
+
+	slave = rcu_dereference(bond->curr_active_slave);
+	if (slave)
+		bond_dev_queue_xmit(bond, skb, slave->dev);
+	else
+		bond_tx_drop(bond_dev, skb);
+
+	return NETDEV_TX_OK;
+}
+
+/* Use this to update slave_array when (a) it's not appropriate to update
+ * slave_array right away (note that update_slave_array() may sleep)
+ * and / or (b) RTNL is not held.
+ */
+void bond_slave_arr_work_rearm(struct bonding *bond, unsigned long delay)
+{
+	queue_delayed_work(bond->wq, &bond->slave_arr_work, delay);
+}
+
+/* Slave array work handler. Holds only RTNL */
+static void bond_slave_arr_handler(struct work_struct *work)
+{
+	struct bonding *bond = container_of(work, struct bonding,
+					    slave_arr_work.work);
+	int ret;
+
+	if (!rtnl_trylock())
+		goto err;
+
+	ret = bond_update_slave_arr(bond, NULL);
+	rtnl_unlock();
+	if (ret) {
+		pr_warn_ratelimited("Failed to update slave array from WT\n");
+		goto err;
+	}
+	return;
+
+err:
+	bond_slave_arr_work_rearm(bond, 1);
+}
+
+/* Build the usable slaves array in control path for modes that use xmit-hash
+ * to determine the slave interface -
+ * (a) BOND_MODE_8023AD
+ * (b) BOND_MODE_XOR
+ * (c) (BOND_MODE_TLB || BOND_MODE_ALB) && tlb_dynamic_lb == 0
+ *
+ * The caller is expected to hold RTNL only and NO other lock!
+ */
+int bond_update_slave_arr(struct bonding *bond, struct slave *skipslave)
+{
+	struct slave *slave;
+	struct list_head *iter;
+	struct bond_up_slave *new_arr, *old_arr;
+	int agg_id = 0;
+	int ret = 0;
+
+#ifdef CONFIG_LOCKDEP
+	WARN_ON(lockdep_is_held(&bond->mode_lock));
+#endif
+
+	new_arr = kzalloc(offsetof(struct bond_up_slave, arr[bond->slave_cnt]),
+			  GFP_KERNEL);
+	if (!new_arr) {
+		ret = -ENOMEM;
+		pr_err("Failed to build slave-array.\n");
+		goto out;
+	}
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		struct ad_info ad_info;
+
+		if (bond_3ad_get_active_agg_info(bond, &ad_info)) {
+			pr_debug("bond_3ad_get_active_agg_info failed\n");
+			kfree_rcu(new_arr, rcu);
+			/* No active aggragator means it's not safe to use
+			 * the previous array.
+			 */
+			old_arr = rtnl_dereference(bond->slave_arr);
+			if (old_arr) {
+				RCU_INIT_POINTER(bond->slave_arr, NULL);
+				kfree_rcu(old_arr, rcu);
+			}
+			goto out;
+		}
+		agg_id = ad_info.aggregator_id;
+	}
+	bond_for_each_slave(bond, slave, iter) {
+		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+			struct aggregator *agg;
+
+			agg = SLAVE_AD_INFO(slave)->port.aggregator;
+			if (!agg || agg->aggregator_identifier != agg_id)
+				continue;
+		}
+		if (!bond_slave_can_tx(slave))
+			continue;
+		if (skipslave == slave)
+			continue;
+
+		netdev_dbg(bond->dev,
+			   "Adding slave dev %s to tx hash array[%d]\n",
+			   slave->dev->name, new_arr->count);
+
+		new_arr->arr[new_arr->count++] = slave;
+	}
+
+	old_arr = rtnl_dereference(bond->slave_arr);
+	rcu_assign_pointer(bond->slave_arr, new_arr);
+	if (old_arr)
+		kfree_rcu(old_arr, rcu);
+out:
+	if (ret != 0 && skipslave) {
+		int idx;
+
+		/* Rare situation where caller has asked to skip a specific
+		 * slave but allocation failed (most likely!). BTW this is
+		 * only possible when the call is initiated from
+		 * __bond_release_one(). In this situation; overwrite the
+		 * skipslave entry in the array with the last entry from the
+		 * array to avoid a situation where the xmit path may choose
+		 * this to-be-skipped slave to send a packet out.
+		 */
+		old_arr = rtnl_dereference(bond->slave_arr);
+		for (idx = 0; old_arr != NULL && idx < old_arr->count; idx++) {
+			if (skipslave == old_arr->arr[idx]) {
+				old_arr->arr[idx] =
+				    old_arr->arr[old_arr->count-1];
+				old_arr->count--;
+				break;
+			}
+		}
+	}
+	return ret;
+}
+
+static struct net_device *bond_xmit_xor_select(int slave_id,
+					       struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct net_device *slave_dev = NULL;
+	struct bond_up_slave *slaves;
+	struct slave *slave;
+	unsigned int count;
+
+	slaves = rcu_dereference(bond->slave_arr);
+	count = slaves ? READ_ONCE(slaves->count) : 0;
+	if (likely(count)) {
+		slave = slaves->arr[slave_id];
+		if (slave)
+			slave_dev = slave->dev;
+	}
+	return slave_dev;
+
+}
+
+/* Use this Xmit function for 3AD as well as XOR modes. The current
+ * usable slave array is formed in the control path. The xmit function
+ * just calculates hash and sends the packet out.
+ */
+static netdev_tx_t bond_3ad_xor_xmit(struct sk_buff *skb,
+				     struct net_device *dev)
+{
+	struct bonding *bond = netdev_priv(dev);
+	struct slave *slave;
+	struct bond_up_slave *slaves;
+	unsigned int count;
+
+	slaves = rcu_dereference(bond->slave_arr);
+	count = slaves ? READ_ONCE(slaves->count) : 0;
+	if (likely(count)) {
+		slave = slaves->arr[bond_xmit_hash(bond, skb) % count];
+		bond_dev_queue_xmit(bond, skb, slave->dev);
+	} else {
+		bond_tx_drop(dev, skb);
+	}
+
+	return NETDEV_TX_OK;
+}
+
+/* in broadcast mode, we send everything to all usable interfaces. */
+static netdev_tx_t bond_xmit_broadcast(struct sk_buff *skb,
+				       struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct slave *slave = NULL;
+	struct list_head *iter;
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (bond_is_last_slave(bond, slave))
+			break;
+		if (bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
+			struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
+
+			if (!skb2) {
+				net_err_ratelimited("%s: Error: %s: skb_clone() failed\n",
+						    bond_dev->name, __func__);
+				continue;
+			}
+			bond_dev_queue_xmit(bond, skb2, slave->dev);
+		}
+	}
+	if (slave && bond_slave_is_up(slave) && slave->link == BOND_LINK_UP)
+		bond_dev_queue_xmit(bond, skb, slave->dev);
+	else
+		bond_tx_drop(bond_dev, skb);
+
+	return NETDEV_TX_OK;
+}
+
+/*------------------------- Device initialization ---------------------------*/
+
+/* Lookup the slave that corresponds to a qid */
+static inline int bond_slave_override(struct bonding *bond,
+				      struct sk_buff *skb)
+{
+	struct slave *slave = NULL;
+	struct list_head *iter;
+
+	if (!skb_rx_queue_recorded(skb))
+		return 1;
+
+	/* Find out if any slaves have the same mapping as this skb. */
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (slave->queue_id == skb_get_queue_mapping(skb)) {
+			if (bond_slave_is_up(slave) &&
+			    slave->link == BOND_LINK_UP) {
+				bond_dev_queue_xmit(bond, skb, slave->dev);
+				return 0;
+			}
+			/* If the slave isn't UP, use default transmit policy. */
+			break;
+		}
+	}
+
+	return 1;
+}
+
+
+static u16 bond_select_queue(struct net_device *dev, struct sk_buff *skb,
+			     struct net_device *sb_dev,
+			     select_queue_fallback_t fallback)
+{
+	/* This helper function exists to help dev_pick_tx get the correct
+	 * destination queue.  Using a helper function skips a call to
+	 * skb_tx_hash and will put the skbs in the queue we expect on their
+	 * way down to the bonding driver.
+	 */
+	u16 txq = skb_rx_queue_recorded(skb) ? skb_get_rx_queue(skb) : 0;
+
+	/* Save the original txq to restore before passing to the driver */
+	qdisc_skb_cb(skb)->slave_dev_queue_mapping = skb_get_queue_mapping(skb);
+
+	if (unlikely(txq >= dev->real_num_tx_queues)) {
+		do {
+			txq -= dev->real_num_tx_queues;
+		} while (txq >= dev->real_num_tx_queues);
+	}
+	return txq;
+}
+
+static netdev_tx_t __bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct bonding *bond = netdev_priv(dev);
+
+	if (bond_should_override_tx_queue(bond) &&
+	    !bond_slave_override(bond, skb))
+		return NETDEV_TX_OK;
+
+	switch (BOND_MODE(bond)) {
+	case BOND_MODE_ROUNDROBIN:
+		return bond_xmit_roundrobin(skb, dev);
+	case BOND_MODE_ACTIVEBACKUP:
+		return bond_xmit_activebackup(skb, dev);
+	case BOND_MODE_8023AD:
+	case BOND_MODE_XOR:
+		return bond_3ad_xor_xmit(skb, dev);
+	case BOND_MODE_BROADCAST:
+		return bond_xmit_broadcast(skb, dev);
+	case BOND_MODE_ALB:
+		return bond_alb_xmit(skb, dev);
+	case BOND_MODE_TLB:
+		return bond_tlb_xmit(skb, dev);
+	default:
+		/* Should never happen, mode already checked */
+		netdev_err(dev, "Unknown bonding mode %d\n", BOND_MODE(bond));
+		WARN_ON_ONCE(1);
+		bond_tx_drop(dev, skb);
+		return NETDEV_TX_OK;
+	}
+}
+
+static netdev_tx_t bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct bonding *bond = netdev_priv(dev);
+	netdev_tx_t ret = NETDEV_TX_OK;
+
+	/* If we risk deadlock from transmitting this in the
+	 * netpoll path, tell netpoll to queue the frame for later tx
+	 */
+	if (unlikely(is_netpoll_tx_blocked(dev)))
+		return NETDEV_TX_BUSY;
+
+	rcu_read_lock();
+	if (bond_has_slaves(bond))
+		ret = __bond_start_xmit(skb, dev);
+	else
+		bond_tx_drop(dev, skb);
+	rcu_read_unlock();
+
+	return ret;
+}
+
+static u32 bond_mode_bcast_speed(struct slave *slave, u32 speed)
+{
+	if (speed == 0 || speed == SPEED_UNKNOWN)
+		speed = slave->speed;
+	else
+		speed = min(speed, slave->speed);
+
+	return speed;
+}
+
+static int bond_ethtool_get_link_ksettings(struct net_device *bond_dev,
+					   struct ethtool_link_ksettings *cmd)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	struct slave *slave;
+	u32 speed = 0;
+
+	cmd->base.duplex = DUPLEX_UNKNOWN;
+	cmd->base.port = PORT_OTHER;
+
+	/* Since bond_slave_can_tx returns false for all inactive or down slaves, we
+	 * do not need to check mode.  Though link speed might not represent
+	 * the true receive or transmit bandwidth (not all modes are symmetric)
+	 * this is an accurate maximum.
+	 */
+	bond_for_each_slave(bond, slave, iter) {
+		if (bond_slave_can_tx(slave)) {
+			if (slave->speed != SPEED_UNKNOWN) {
+				if (BOND_MODE(bond) == BOND_MODE_BROADCAST)
+					speed = bond_mode_bcast_speed(slave,
+								      speed);
+				else
+					speed += slave->speed;
+			}
+			if (cmd->base.duplex == DUPLEX_UNKNOWN &&
+			    slave->duplex != DUPLEX_UNKNOWN)
+				cmd->base.duplex = slave->duplex;
+		}
+	}
+	cmd->base.speed = speed ? : SPEED_UNKNOWN;
+
+	return 0;
+}
+
+static void bond_ethtool_get_drvinfo(struct net_device *bond_dev,
+				     struct ethtool_drvinfo *drvinfo)
+{
+	strlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));
+	strlcpy(drvinfo->version, DRV_VERSION, sizeof(drvinfo->version));
+	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version), "%d",
+		 BOND_ABI_VERSION);
+}
+
+static const struct ethtool_ops bond_ethtool_ops = {
+	.get_drvinfo		= bond_ethtool_get_drvinfo,
+	.get_link		= ethtool_op_get_link,
+	.get_link_ksettings	= bond_ethtool_get_link_ksettings,
+};
+
+static const struct net_device_ops bond_netdev_ops = {
+	.ndo_init		= bond_init,
+	.ndo_uninit		= bond_uninit,
+	.ndo_open		= bond_open,
+	.ndo_stop		= bond_close,
+	.ndo_start_xmit		= bond_start_xmit,
+	.ndo_select_queue	= bond_select_queue,
+	.ndo_get_stats64	= bond_get_stats,
+	.ndo_do_ioctl		= bond_do_ioctl,
+	.ndo_change_rx_flags	= bond_change_rx_flags,
+	.ndo_set_rx_mode	= bond_set_rx_mode,
+	.ndo_change_mtu		= bond_change_mtu,
+	.ndo_set_mac_address	= bond_set_mac_address,
+	.ndo_neigh_setup	= bond_neigh_setup,
+	.ndo_vlan_rx_add_vid	= bond_vlan_rx_add_vid,
+	.ndo_vlan_rx_kill_vid	= bond_vlan_rx_kill_vid,
+	.ndo_get_lock_subclass  = bond_get_nest_level,
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	.ndo_netpoll_setup	= bond_netpoll_setup,
+	.ndo_netpoll_cleanup	= bond_netpoll_cleanup,
+	.ndo_poll_controller	= bond_poll_controller,
+#endif
+	.ndo_add_slave		= bond_enslave,
+	.ndo_del_slave		= bond_release,
+	.ndo_fix_features	= bond_fix_features,
+	.ndo_features_check	= passthru_features_check,
+};
+
+static const struct device_type bond_type = {
+	.name = "bond",
+};
+
+static void bond_destructor(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	if (bond->wq)
+		destroy_workqueue(bond->wq);
+}
+
+void bond_setup(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+
+	spin_lock_init(&bond->mode_lock);
+	spin_lock_init(&bond->stats_lock);
+	bond->params = bonding_defaults;
+
+	/* Initialize pointers */
+	bond->dev = bond_dev;
+
+	/* Initialize the device entry points */
+	ether_setup(bond_dev);
+	bond_dev->max_mtu = ETH_MAX_MTU;
+	bond_dev->netdev_ops = &bond_netdev_ops;
+	bond_dev->ethtool_ops = &bond_ethtool_ops;
+
+	bond_dev->needs_free_netdev = true;
+	bond_dev->priv_destructor = bond_destructor;
+
+	SET_NETDEV_DEVTYPE(bond_dev, &bond_type);
+
+	/* Initialize the device options */
+	bond_dev->flags |= IFF_MASTER;
+	bond_dev->priv_flags |= IFF_BONDING | IFF_UNICAST_FLT | IFF_NO_QUEUE;
+	bond_dev->priv_flags &= ~(IFF_XMIT_DST_RELEASE | IFF_TX_SKB_SHARING);
+
+	/* don't acquire bond device's netif_tx_lock when transmitting */
+	bond_dev->features |= NETIF_F_LLTX;
+
+	/* By default, we declare the bond to be fully
+	 * VLAN hardware accelerated capable. Special
+	 * care is taken in the various xmit functions
+	 * when there are slaves that are not hw accel
+	 * capable
+	 */
+
+	/* Don't allow bond devices to change network namespaces. */
+	bond_dev->features |= NETIF_F_NETNS_LOCAL;
+
+	bond_dev->hw_features = BOND_VLAN_FEATURES |
+				NETIF_F_HW_VLAN_CTAG_RX |
+				NETIF_F_HW_VLAN_CTAG_FILTER;
+
+	bond_dev->hw_features |= NETIF_F_GSO_ENCAP_ALL | NETIF_F_GSO_UDP_L4;
+	bond_dev->features |= bond_dev->hw_features;
+	bond_dev->features |= NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_STAG_TX;
+}
+
+/* Destroy a bonding device.
+ * Must be under rtnl_lock when this function is called.
+ */
+static void bond_uninit(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct list_head *iter;
+	struct slave *slave;
+	struct bond_up_slave *arr;
+
+	bond_netpoll_cleanup(bond_dev);
+
+	/* Release the bonded slaves */
+	bond_for_each_slave(bond, slave, iter)
+		__bond_release_one(bond_dev, slave->dev, true, true);
+	netdev_info(bond_dev, "Released all slaves\n");
+
+	arr = rtnl_dereference(bond->slave_arr);
+	if (arr) {
+		RCU_INIT_POINTER(bond->slave_arr, NULL);
+		kfree_rcu(arr, rcu);
+	}
+
+	list_del(&bond->bond_list);
+
+	bond_debug_unregister(bond);
+}
+
+/*------------------------- Module initialization ---------------------------*/
+
+static int bond_check_params(struct bond_params *params)
+{
+	int arp_validate_value, fail_over_mac_value, primary_reselect_value, i;
+	struct bond_opt_value newval;
+	const struct bond_opt_value *valptr;
+	int arp_all_targets_value = 0;
+	u16 ad_actor_sys_prio = 0;
+	u16 ad_user_port_key = 0;
+	__be32 arp_target[BOND_MAX_ARP_TARGETS] = { 0 };
+	int arp_ip_count;
+	int bond_mode	= BOND_MODE_ROUNDROBIN;
+	int xmit_hashtype = BOND_XMIT_POLICY_LAYER2;
+	int lacp_fast = 0;
+	int tlb_dynamic_lb;
+
+	/* Convert string parameters. */
+	if (mode) {
+		bond_opt_initstr(&newval, mode);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_MODE), &newval);
+		if (!valptr) {
+			pr_err("Error: Invalid bonding mode \"%s\"\n", mode);
+			return -EINVAL;
+		}
+		bond_mode = valptr->value;
+	}
+
+	if (xmit_hash_policy) {
+		if (bond_mode == BOND_MODE_ROUNDROBIN ||
+		    bond_mode == BOND_MODE_ACTIVEBACKUP ||
+		    bond_mode == BOND_MODE_BROADCAST) {
+			pr_info("xmit_hash_policy param is irrelevant in mode %s\n",
+				bond_mode_name(bond_mode));
+		} else {
+			bond_opt_initstr(&newval, xmit_hash_policy);
+			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_XMIT_HASH),
+						&newval);
+			if (!valptr) {
+				pr_err("Error: Invalid xmit_hash_policy \"%s\"\n",
+				       xmit_hash_policy);
+				return -EINVAL;
+			}
+			xmit_hashtype = valptr->value;
+		}
+	}
+
+	if (lacp_rate) {
+		if (bond_mode != BOND_MODE_8023AD) {
+			pr_info("lacp_rate param is irrelevant in mode %s\n",
+				bond_mode_name(bond_mode));
+		} else {
+			bond_opt_initstr(&newval, lacp_rate);
+			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_LACP_RATE),
+						&newval);
+			if (!valptr) {
+				pr_err("Error: Invalid lacp rate \"%s\"\n",
+				       lacp_rate);
+				return -EINVAL;
+			}
+			lacp_fast = valptr->value;
+		}
+	}
+
+	if (ad_select) {
+		bond_opt_initstr(&newval, ad_select);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_SELECT),
+					&newval);
+		if (!valptr) {
+			pr_err("Error: Invalid ad_select \"%s\"\n", ad_select);
+			return -EINVAL;
+		}
+		params->ad_select = valptr->value;
+		if (bond_mode != BOND_MODE_8023AD)
+			pr_warn("ad_select param only affects 802.3ad mode\n");
+	} else {
+		params->ad_select = BOND_AD_STABLE;
+	}
+
+	if (max_bonds < 0) {
+		pr_warn("Warning: max_bonds (%d) not in range %d-%d, so it was reset to BOND_DEFAULT_MAX_BONDS (%d)\n",
+			max_bonds, 0, INT_MAX, BOND_DEFAULT_MAX_BONDS);
+		max_bonds = BOND_DEFAULT_MAX_BONDS;
+	}
+
+	if (miimon < 0) {
+		pr_warn("Warning: miimon module parameter (%d), not in range 0-%d, so it was reset to 0\n",
+			miimon, INT_MAX);
+		miimon = 0;
+	}
+
+	if (updelay < 0) {
+		pr_warn("Warning: updelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
+			updelay, INT_MAX);
+		updelay = 0;
+	}
+
+	if (downdelay < 0) {
+		pr_warn("Warning: downdelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
+			downdelay, INT_MAX);
+		downdelay = 0;
+	}
+
+	if ((use_carrier != 0) && (use_carrier != 1)) {
+		pr_warn("Warning: use_carrier module parameter (%d), not of valid value (0/1), so it was set to 1\n",
+			use_carrier);
+		use_carrier = 1;
+	}
+
+	if (num_peer_notif < 0 || num_peer_notif > 255) {
+		pr_warn("Warning: num_grat_arp/num_unsol_na (%d) not in range 0-255 so it was reset to 1\n",
+			num_peer_notif);
+		num_peer_notif = 1;
+	}
+
+	/* reset values for 802.3ad/TLB/ALB */
+	if (!bond_mode_uses_arp(bond_mode)) {
+		if (!miimon) {
+			pr_warn("Warning: miimon must be specified, otherwise bonding will not detect link failure, speed and duplex which are essential for 802.3ad operation\n");
+			pr_warn("Forcing miimon to 100msec\n");
+			miimon = BOND_DEFAULT_MIIMON;
+		}
+	}
+
+	if (tx_queues < 1 || tx_queues > 255) {
+		pr_warn("Warning: tx_queues (%d) should be between 1 and 255, resetting to %d\n",
+			tx_queues, BOND_DEFAULT_TX_QUEUES);
+		tx_queues = BOND_DEFAULT_TX_QUEUES;
+	}
+
+	if ((all_slaves_active != 0) && (all_slaves_active != 1)) {
+		pr_warn("Warning: all_slaves_active module parameter (%d), not of valid value (0/1), so it was set to 0\n",
+			all_slaves_active);
+		all_slaves_active = 0;
+	}
+
+	if (resend_igmp < 0 || resend_igmp > 255) {
+		pr_warn("Warning: resend_igmp (%d) should be between 0 and 255, resetting to %d\n",
+			resend_igmp, BOND_DEFAULT_RESEND_IGMP);
+		resend_igmp = BOND_DEFAULT_RESEND_IGMP;
+	}
+
+	bond_opt_initval(&newval, packets_per_slave);
+	if (!bond_opt_parse(bond_opt_get(BOND_OPT_PACKETS_PER_SLAVE), &newval)) {
+		pr_warn("Warning: packets_per_slave (%d) should be between 0 and %u resetting to 1\n",
+			packets_per_slave, USHRT_MAX);
+		packets_per_slave = 1;
+	}
+
+	if (bond_mode == BOND_MODE_ALB) {
+		pr_notice("In ALB mode you might experience client disconnections upon reconnection of a link if the bonding module updelay parameter (%d msec) is incompatible with the forwarding delay time of the switch\n",
+			  updelay);
+	}
+
+	if (!miimon) {
+		if (updelay || downdelay) {
+			/* just warn the user the up/down delay will have
+			 * no effect since miimon is zero...
+			 */
+			pr_warn("Warning: miimon module parameter not set and updelay (%d) or downdelay (%d) module parameter is set; updelay and downdelay have no effect unless miimon is set\n",
+				updelay, downdelay);
+		}
+	} else {
+		/* don't allow arp monitoring */
+		if (arp_interval) {
+			pr_warn("Warning: miimon (%d) and arp_interval (%d) can't be used simultaneously, disabling ARP monitoring\n",
+				miimon, arp_interval);
+			arp_interval = 0;
+		}
+
+		if ((updelay % miimon) != 0) {
+			pr_warn("Warning: updelay (%d) is not a multiple of miimon (%d), updelay rounded to %d ms\n",
+				updelay, miimon, (updelay / miimon) * miimon);
+		}
+
+		updelay /= miimon;
+
+		if ((downdelay % miimon) != 0) {
+			pr_warn("Warning: downdelay (%d) is not a multiple of miimon (%d), downdelay rounded to %d ms\n",
+				downdelay, miimon,
+				(downdelay / miimon) * miimon);
+		}
+
+		downdelay /= miimon;
+	}
+
+	if (arp_interval < 0) {
+		pr_warn("Warning: arp_interval module parameter (%d), not in range 0-%d, so it was reset to 0\n",
+			arp_interval, INT_MAX);
+		arp_interval = 0;
+	}
+
+	for (arp_ip_count = 0, i = 0;
+	     (arp_ip_count < BOND_MAX_ARP_TARGETS) && arp_ip_target[i]; i++) {
+		__be32 ip;
+
+		/* not a complete check, but good enough to catch mistakes */
+		if (!in4_pton(arp_ip_target[i], -1, (u8 *)&ip, -1, NULL) ||
+		    !bond_is_ip_target_ok(ip)) {
+			pr_warn("Warning: bad arp_ip_target module parameter (%s), ARP monitoring will not be performed\n",
+				arp_ip_target[i]);
+			arp_interval = 0;
+		} else {
+			if (bond_get_targets_ip(arp_target, ip) == -1)
+				arp_target[arp_ip_count++] = ip;
+			else
+				pr_warn("Warning: duplicate address %pI4 in arp_ip_target, skipping\n",
+					&ip);
+		}
+	}
+
+	if (arp_interval && !arp_ip_count) {
+		/* don't allow arping if no arp_ip_target given... */
+		pr_warn("Warning: arp_interval module parameter (%d) specified without providing an arp_ip_target parameter, arp_interval was reset to 0\n",
+			arp_interval);
+		arp_interval = 0;
+	}
+
+	if (arp_validate) {
+		if (!arp_interval) {
+			pr_err("arp_validate requires arp_interval\n");
+			return -EINVAL;
+		}
+
+		bond_opt_initstr(&newval, arp_validate);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_VALIDATE),
+					&newval);
+		if (!valptr) {
+			pr_err("Error: invalid arp_validate \"%s\"\n",
+			       arp_validate);
+			return -EINVAL;
+		}
+		arp_validate_value = valptr->value;
+	} else {
+		arp_validate_value = 0;
+	}
+
+	if (arp_all_targets) {
+		bond_opt_initstr(&newval, arp_all_targets);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_ALL_TARGETS),
+					&newval);
+		if (!valptr) {
+			pr_err("Error: invalid arp_all_targets_value \"%s\"\n",
+			       arp_all_targets);
+			arp_all_targets_value = 0;
+		} else {
+			arp_all_targets_value = valptr->value;
+		}
+	}
+
+	if (miimon) {
+		pr_info("MII link monitoring set to %d ms\n", miimon);
+	} else if (arp_interval) {
+		valptr = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
+					  arp_validate_value);
+		pr_info("ARP monitoring set to %d ms, validate %s, with %d target(s):",
+			arp_interval, valptr->string, arp_ip_count);
+
+		for (i = 0; i < arp_ip_count; i++)
+			pr_cont(" %s", arp_ip_target[i]);
+
+		pr_cont("\n");
+
+	} else if (max_bonds) {
+		/* miimon and arp_interval not set, we need one so things
+		 * work as expected, see bonding.txt for details
+		 */
+		pr_debug("Warning: either miimon or arp_interval and arp_ip_target module parameters must be specified, otherwise bonding will not detect link failures! see bonding.txt for details\n");
+	}
+
+	if (primary && !bond_mode_uses_primary(bond_mode)) {
+		/* currently, using a primary only makes sense
+		 * in active backup, TLB or ALB modes
+		 */
+		pr_warn("Warning: %s primary device specified but has no effect in %s mode\n",
+			primary, bond_mode_name(bond_mode));
+		primary = NULL;
+	}
+
+	if (primary && primary_reselect) {
+		bond_opt_initstr(&newval, primary_reselect);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_PRIMARY_RESELECT),
+					&newval);
+		if (!valptr) {
+			pr_err("Error: Invalid primary_reselect \"%s\"\n",
+			       primary_reselect);
+			return -EINVAL;
+		}
+		primary_reselect_value = valptr->value;
+	} else {
+		primary_reselect_value = BOND_PRI_RESELECT_ALWAYS;
+	}
+
+	if (fail_over_mac) {
+		bond_opt_initstr(&newval, fail_over_mac);
+		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_FAIL_OVER_MAC),
+					&newval);
+		if (!valptr) {
+			pr_err("Error: invalid fail_over_mac \"%s\"\n",
+			       fail_over_mac);
+			return -EINVAL;
+		}
+		fail_over_mac_value = valptr->value;
+		if (bond_mode != BOND_MODE_ACTIVEBACKUP)
+			pr_warn("Warning: fail_over_mac only affects active-backup mode\n");
+	} else {
+		fail_over_mac_value = BOND_FOM_NONE;
+	}
+
+	bond_opt_initstr(&newval, "default");
+	valptr = bond_opt_parse(
+			bond_opt_get(BOND_OPT_AD_ACTOR_SYS_PRIO),
+				     &newval);
+	if (!valptr) {
+		pr_err("Error: No ad_actor_sys_prio default value");
+		return -EINVAL;
+	}
+	ad_actor_sys_prio = valptr->value;
+
+	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_USER_PORT_KEY),
+				&newval);
+	if (!valptr) {
+		pr_err("Error: No ad_user_port_key default value");
+		return -EINVAL;
+	}
+	ad_user_port_key = valptr->value;
+
+	bond_opt_initstr(&newval, "default");
+	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_TLB_DYNAMIC_LB), &newval);
+	if (!valptr) {
+		pr_err("Error: No tlb_dynamic_lb default value");
+		return -EINVAL;
+	}
+	tlb_dynamic_lb = valptr->value;
+
+	if (lp_interval == 0) {
+		pr_warn("Warning: ip_interval must be between 1 and %d, so it was reset to %d\n",
+			INT_MAX, BOND_ALB_DEFAULT_LP_INTERVAL);
+		lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
+	}
+
+	/* fill params struct with the proper values */
+	params->mode = bond_mode;
+	params->xmit_policy = xmit_hashtype;
+	params->miimon = miimon;
+	params->num_peer_notif = num_peer_notif;
+	params->arp_interval = arp_interval;
+	params->arp_validate = arp_validate_value;
+	params->arp_all_targets = arp_all_targets_value;
+	params->updelay = updelay;
+	params->downdelay = downdelay;
+	params->use_carrier = use_carrier;
+	params->lacp_fast = lacp_fast;
+	params->primary[0] = 0;
+	params->primary_reselect = primary_reselect_value;
+	params->fail_over_mac = fail_over_mac_value;
+	params->tx_queues = tx_queues;
+	params->all_slaves_active = all_slaves_active;
+	params->resend_igmp = resend_igmp;
+	params->min_links = min_links;
+	params->lp_interval = lp_interval;
+	params->packets_per_slave = packets_per_slave;
+	params->tlb_dynamic_lb = tlb_dynamic_lb;
+	params->ad_actor_sys_prio = ad_actor_sys_prio;
+	eth_zero_addr(params->ad_actor_system);
+	params->ad_user_port_key = ad_user_port_key;
+	if (packets_per_slave > 0) {
+		params->reciprocal_packets_per_slave =
+			reciprocal_value(packets_per_slave);
+	} else {
+		/* reciprocal_packets_per_slave is unused if
+		 * packets_per_slave is 0 or 1, just initialize it
+		 */
+		params->reciprocal_packets_per_slave =
+			(struct reciprocal_value) { 0 };
+	}
+
+	if (primary) {
+		strncpy(params->primary, primary, IFNAMSIZ);
+		params->primary[IFNAMSIZ - 1] = 0;
+	}
+
+	memcpy(params->arp_targets, arp_target, sizeof(arp_target));
+
+	return 0;
+}
+
+/* Called from registration process */
+static int bond_init(struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
+
+	netdev_dbg(bond_dev, "Begin bond_init\n");
+
+	bond->wq = alloc_ordered_workqueue(bond_dev->name, WQ_MEM_RECLAIM);
+	if (!bond->wq)
+		return -ENOMEM;
+
+	bond->nest_level = SINGLE_DEPTH_NESTING;
+	netdev_lockdep_set_classes(bond_dev);
+
+	list_add_tail(&bond->bond_list, &bn->dev_list);
+
+	bond_prepare_sysfs_group(bond);
+
+	bond_debug_register(bond);
+
+	/* Ensure valid dev_addr */
+	if (is_zero_ether_addr(bond_dev->dev_addr) &&
+	    bond_dev->addr_assign_type == NET_ADDR_PERM)
+		eth_hw_addr_random(bond_dev);
+
+	return 0;
+}
+
+unsigned int bond_get_num_tx_queues(void)
+{
+	return tx_queues;
+}
+
+/* Create a new bond based on the specified name and bonding parameters.
+ * If name is NULL, obtain a suitable "bond%d" name for us.
+ * Caller must NOT hold rtnl_lock; we need to release it here before we
+ * set up our sysfs entries.
+ */
+int bond_create(struct net *net, const char *name)
+{
+	struct net_device *bond_dev;
+	struct bonding *bond;
+	struct alb_bond_info *bond_info;
+	int res;
+
+	rtnl_lock();
+
+	bond_dev = alloc_netdev_mq(sizeof(struct bonding),
+				   name ? name : "bond%d", NET_NAME_UNKNOWN,
+				   bond_setup, tx_queues);
+	if (!bond_dev) {
+		pr_err("%s: eek! can't alloc netdev!\n", name);
+		rtnl_unlock();
+		return -ENOMEM;
+	}
+
+	/*
+	 * Initialize rx_hashtbl_used_head to RLB_NULL_INDEX.
+	 * It is set to 0 by default which is wrong.
+	 */
+	bond = netdev_priv(bond_dev);
+	bond_info = &(BOND_ALB_INFO(bond));
+	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
+
+	dev_net_set(bond_dev, net);
+	bond_dev->rtnl_link_ops = &bond_link_ops;
+
+	res = register_netdevice(bond_dev);
+	if (res < 0) {
+		free_netdev(bond_dev);
+		rtnl_unlock();
+
+		return res;
+	}
+
+	netif_carrier_off(bond_dev);
+
+	bond_work_init_all(bond);
+
+	rtnl_unlock();
+	return 0;
+}
+
+static int __net_init bond_net_init(struct net *net)
+{
+	struct bond_net *bn = net_generic(net, bond_net_id);
+
+	bn->net = net;
+	INIT_LIST_HEAD(&bn->dev_list);
+
+	bond_create_proc_dir(bn);
+	bond_create_sysfs(bn);
+
+	return 0;
+}
+
+static void __net_exit bond_net_exit(struct net *net)
+{
+	struct bond_net *bn = net_generic(net, bond_net_id);
+	struct bonding *bond, *tmp_bond;
+	LIST_HEAD(list);
+
+	bond_destroy_sysfs(bn);
+
+	/* Kill off any bonds created after unregistering bond rtnl ops */
+	rtnl_lock();
+	list_for_each_entry_safe(bond, tmp_bond, &bn->dev_list, bond_list)
+		unregister_netdevice_queue(bond->dev, &list);
+	unregister_netdevice_many(&list);
+	rtnl_unlock();
+
+	bond_destroy_proc_dir(bn);
+}
+
+static struct pernet_operations bond_net_ops = {
+	.init = bond_net_init,
+	.exit = bond_net_exit,
+	.id   = &bond_net_id,
+	.size = sizeof(struct bond_net),
+};
+
+static int __init bonding_init(void)
+{
+	int i;
+	int res;
+
+	pr_info("%s", bond_version);
+
+	res = bond_check_params(&bonding_defaults);
+	if (res)
+		goto out;
+
+	res = register_pernet_subsys(&bond_net_ops);
+	if (res)
+		goto out;
+
+	res = bond_netlink_init();
+	if (res)
+		goto err_link;
+
+	bond_create_debugfs();
+
+	for (i = 0; i < max_bonds; i++) {
+		res = bond_create(&init_net, NULL);
+		if (res)
+			goto err;
+	}
+
+	register_netdevice_notifier(&bond_netdev_notifier);
+	register_toe_bond_rr_select_cb(bond_xmit_roundrobin_select);
+	register_toe_bond_acb_select_cb(bond_xmit_activebackup_select);
+	register_toe_bond_8023AD_select_cb(bond_xmit_xor_select);
+	register_toe_bond_xor_select_cb(bond_xmit_xor_select);
+out:
+	return res;
+err:
+	bond_destroy_debugfs();
+	bond_netlink_fini();
+err_link:
+	unregister_pernet_subsys(&bond_net_ops);
+	goto out;
+
+}
+
+static void __exit bonding_exit(void)
+{
+	unregister_netdevice_notifier(&bond_netdev_notifier);
+
+	bond_destroy_debugfs();
+
+	bond_netlink_fini();
+	unregister_pernet_subsys(&bond_net_ops);
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	/* Make sure we don't have an imbalance on our netpoll blocking */
+	WARN_ON(atomic_read(&netpoll_block_tx));
+#endif
+}
+
+module_init(bonding_init);
+module_exit(bonding_exit);
+MODULE_LICENSE("GPL");
+MODULE_VERSION(DRV_VERSION);
+MODULE_DESCRIPTION(DRV_DESCRIPTION ", v" DRV_VERSION);
+MODULE_AUTHOR("Thomas Davis, tadavis@lbl.gov and many others");
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.164/bond_netlink.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.164/bond_netlink.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,708 @@
+/*
+ * drivers/net/bond/bond_netlink.c - Netlink interface for bonding
+ * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
+ * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#include <linux/module.h>
+#include <linux/errno.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/if_link.h>
+#include <linux/if_ether.h>
+#include <net/netlink.h>
+#include <net/rtnetlink.h>
+#include <net/bonding.h>
+
+static size_t bond_get_slave_size(const struct net_device *bond_dev,
+				  const struct net_device *slave_dev)
+{
+	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_STATE */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_MII_STATUS */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_SLAVE_LINK_FAILURE_COUNT */
+		nla_total_size(MAX_ADDR_LEN) +	/* IFLA_BOND_SLAVE_PERM_HWADDR */
+		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_QUEUE_ID */
+		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_AGGREGATOR_ID */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE */
+		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE */
+		0;
+}
+
+static int bond_fill_slave_info(struct sk_buff *skb,
+				const struct net_device *bond_dev,
+				const struct net_device *slave_dev)
+{
+	struct slave *slave = bond_slave_get_rtnl(slave_dev);
+
+	if (nla_put_u8(skb, IFLA_BOND_SLAVE_STATE, bond_slave_state(slave)))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_SLAVE_MII_STATUS, slave->link))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_SLAVE_LINK_FAILURE_COUNT,
+			slave->link_failure_count))
+		goto nla_put_failure;
+
+	if (nla_put(skb, IFLA_BOND_SLAVE_PERM_HWADDR,
+		    slave_dev->addr_len, slave->perm_hwaddr))
+		goto nla_put_failure;
+
+	if (nla_put_u16(skb, IFLA_BOND_SLAVE_QUEUE_ID, slave->queue_id))
+		goto nla_put_failure;
+
+	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
+		const struct aggregator *agg;
+		const struct port *ad_port;
+
+		ad_port = &SLAVE_AD_INFO(slave)->port;
+		agg = SLAVE_AD_INFO(slave)->port.aggregator;
+		if (agg) {
+			if (nla_put_u16(skb, IFLA_BOND_SLAVE_AD_AGGREGATOR_ID,
+					agg->aggregator_identifier))
+				goto nla_put_failure;
+			if (nla_put_u8(skb,
+				       IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE,
+				       ad_port->actor_oper_port_state))
+				goto nla_put_failure;
+			if (nla_put_u16(skb,
+					IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE,
+					ad_port->partner_oper.port_state))
+				goto nla_put_failure;
+		}
+	}
+
+	return 0;
+
+nla_put_failure:
+	return -EMSGSIZE;
+}
+
+static const struct nla_policy bond_policy[IFLA_BOND_MAX + 1] = {
+	[IFLA_BOND_MODE]		= { .type = NLA_U8 },
+	[IFLA_BOND_ACTIVE_SLAVE]	= { .type = NLA_U32 },
+	[IFLA_BOND_MIIMON]		= { .type = NLA_U32 },
+	[IFLA_BOND_UPDELAY]		= { .type = NLA_U32 },
+	[IFLA_BOND_DOWNDELAY]		= { .type = NLA_U32 },
+	[IFLA_BOND_USE_CARRIER]		= { .type = NLA_U8 },
+	[IFLA_BOND_ARP_INTERVAL]	= { .type = NLA_U32 },
+	[IFLA_BOND_ARP_IP_TARGET]	= { .type = NLA_NESTED },
+	[IFLA_BOND_ARP_VALIDATE]	= { .type = NLA_U32 },
+	[IFLA_BOND_ARP_ALL_TARGETS]	= { .type = NLA_U32 },
+	[IFLA_BOND_PRIMARY]		= { .type = NLA_U32 },
+	[IFLA_BOND_PRIMARY_RESELECT]	= { .type = NLA_U8 },
+	[IFLA_BOND_FAIL_OVER_MAC]	= { .type = NLA_U8 },
+	[IFLA_BOND_XMIT_HASH_POLICY]	= { .type = NLA_U8 },
+	[IFLA_BOND_RESEND_IGMP]		= { .type = NLA_U32 },
+	[IFLA_BOND_NUM_PEER_NOTIF]	= { .type = NLA_U8 },
+	[IFLA_BOND_ALL_SLAVES_ACTIVE]	= { .type = NLA_U8 },
+	[IFLA_BOND_MIN_LINKS]		= { .type = NLA_U32 },
+	[IFLA_BOND_LP_INTERVAL]		= { .type = NLA_U32 },
+	[IFLA_BOND_PACKETS_PER_SLAVE]	= { .type = NLA_U32 },
+	[IFLA_BOND_AD_LACP_RATE]	= { .type = NLA_U8 },
+	[IFLA_BOND_AD_SELECT]		= { .type = NLA_U8 },
+	[IFLA_BOND_AD_INFO]		= { .type = NLA_NESTED },
+	[IFLA_BOND_AD_ACTOR_SYS_PRIO]	= { .type = NLA_U16 },
+	[IFLA_BOND_AD_USER_PORT_KEY]	= { .type = NLA_U16 },
+	[IFLA_BOND_AD_ACTOR_SYSTEM]	= { .type = NLA_BINARY,
+					    .len  = ETH_ALEN },
+	[IFLA_BOND_TLB_DYNAMIC_LB]	= { .type = NLA_U8 },
+};
+
+static const struct nla_policy bond_slave_policy[IFLA_BOND_SLAVE_MAX + 1] = {
+	[IFLA_BOND_SLAVE_QUEUE_ID]	= { .type = NLA_U16 },
+};
+
+static int bond_validate(struct nlattr *tb[], struct nlattr *data[],
+			 struct netlink_ext_ack *extack)
+{
+	if (tb[IFLA_ADDRESS]) {
+		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN)
+			return -EINVAL;
+		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS])))
+			return -EADDRNOTAVAIL;
+	}
+	return 0;
+}
+
+static int bond_slave_changelink(struct net_device *bond_dev,
+				 struct net_device *slave_dev,
+				 struct nlattr *tb[], struct nlattr *data[],
+				 struct netlink_ext_ack *extack)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct bond_opt_value newval;
+	int err;
+
+	if (!data)
+		return 0;
+
+	if (data[IFLA_BOND_SLAVE_QUEUE_ID]) {
+		u16 queue_id = nla_get_u16(data[IFLA_BOND_SLAVE_QUEUE_ID]);
+		char queue_id_str[IFNAMSIZ + 7];
+
+		/* queue_id option setting expects slave_name:queue_id */
+		snprintf(queue_id_str, sizeof(queue_id_str), "%s:%u\n",
+			 slave_dev->name, queue_id);
+		bond_opt_initstr(&newval, queue_id_str);
+		err = __bond_opt_set(bond, BOND_OPT_QUEUE_ID, &newval);
+		if (err)
+			return err;
+	}
+
+	return 0;
+}
+
+static int bond_changelink(struct net_device *bond_dev, struct nlattr *tb[],
+			   struct nlattr *data[],
+			   struct netlink_ext_ack *extack)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	struct bond_opt_value newval;
+	int miimon = 0;
+	int err;
+
+	if (!data)
+		return 0;
+
+	if (data[IFLA_BOND_MODE]) {
+		int mode = nla_get_u8(data[IFLA_BOND_MODE]);
+
+		bond_opt_initval(&newval, mode);
+		err = __bond_opt_set(bond, BOND_OPT_MODE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ACTIVE_SLAVE]) {
+		int ifindex = nla_get_u32(data[IFLA_BOND_ACTIVE_SLAVE]);
+		struct net_device *slave_dev;
+		char *active_slave = "";
+
+		if (ifindex != 0) {
+			slave_dev = __dev_get_by_index(dev_net(bond_dev),
+						       ifindex);
+			if (!slave_dev)
+				return -ENODEV;
+			active_slave = slave_dev->name;
+		}
+		bond_opt_initstr(&newval, active_slave);
+		err = __bond_opt_set(bond, BOND_OPT_ACTIVE_SLAVE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_MIIMON]) {
+		miimon = nla_get_u32(data[IFLA_BOND_MIIMON]);
+
+		bond_opt_initval(&newval, miimon);
+		err = __bond_opt_set(bond, BOND_OPT_MIIMON, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_UPDELAY]) {
+		int updelay = nla_get_u32(data[IFLA_BOND_UPDELAY]);
+
+		bond_opt_initval(&newval, updelay);
+		err = __bond_opt_set(bond, BOND_OPT_UPDELAY, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_DOWNDELAY]) {
+		int downdelay = nla_get_u32(data[IFLA_BOND_DOWNDELAY]);
+
+		bond_opt_initval(&newval, downdelay);
+		err = __bond_opt_set(bond, BOND_OPT_DOWNDELAY, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_USE_CARRIER]) {
+		int use_carrier = nla_get_u8(data[IFLA_BOND_USE_CARRIER]);
+
+		bond_opt_initval(&newval, use_carrier);
+		err = __bond_opt_set(bond, BOND_OPT_USE_CARRIER, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ARP_INTERVAL]) {
+		int arp_interval = nla_get_u32(data[IFLA_BOND_ARP_INTERVAL]);
+
+		if (arp_interval && miimon) {
+			netdev_err(bond->dev, "ARP monitoring cannot be used with MII monitoring\n");
+			return -EINVAL;
+		}
+
+		bond_opt_initval(&newval, arp_interval);
+		err = __bond_opt_set(bond, BOND_OPT_ARP_INTERVAL, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ARP_IP_TARGET]) {
+		struct nlattr *attr;
+		int i = 0, rem;
+
+		bond_option_arp_ip_targets_clear(bond);
+		nla_for_each_nested(attr, data[IFLA_BOND_ARP_IP_TARGET], rem) {
+			__be32 target;
+
+			if (nla_len(attr) < sizeof(target))
+				return -EINVAL;
+
+			target = nla_get_be32(attr);
+
+			bond_opt_initval(&newval, (__force u64)target);
+			err = __bond_opt_set(bond, BOND_OPT_ARP_TARGETS,
+					     &newval);
+			if (err)
+				break;
+			i++;
+		}
+		if (i == 0 && bond->params.arp_interval)
+			netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ARP_VALIDATE]) {
+		int arp_validate = nla_get_u32(data[IFLA_BOND_ARP_VALIDATE]);
+
+		if (arp_validate && miimon) {
+			netdev_err(bond->dev, "ARP validating cannot be used with MII monitoring\n");
+			return -EINVAL;
+		}
+
+		bond_opt_initval(&newval, arp_validate);
+		err = __bond_opt_set(bond, BOND_OPT_ARP_VALIDATE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ARP_ALL_TARGETS]) {
+		int arp_all_targets =
+			nla_get_u32(data[IFLA_BOND_ARP_ALL_TARGETS]);
+
+		bond_opt_initval(&newval, arp_all_targets);
+		err = __bond_opt_set(bond, BOND_OPT_ARP_ALL_TARGETS, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_PRIMARY]) {
+		int ifindex = nla_get_u32(data[IFLA_BOND_PRIMARY]);
+		struct net_device *dev;
+		char *primary = "";
+
+		dev = __dev_get_by_index(dev_net(bond_dev), ifindex);
+		if (dev)
+			primary = dev->name;
+
+		bond_opt_initstr(&newval, primary);
+		err = __bond_opt_set(bond, BOND_OPT_PRIMARY, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_PRIMARY_RESELECT]) {
+		int primary_reselect =
+			nla_get_u8(data[IFLA_BOND_PRIMARY_RESELECT]);
+
+		bond_opt_initval(&newval, primary_reselect);
+		err = __bond_opt_set(bond, BOND_OPT_PRIMARY_RESELECT, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_FAIL_OVER_MAC]) {
+		int fail_over_mac =
+			nla_get_u8(data[IFLA_BOND_FAIL_OVER_MAC]);
+
+		bond_opt_initval(&newval, fail_over_mac);
+		err = __bond_opt_set(bond, BOND_OPT_FAIL_OVER_MAC, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_XMIT_HASH_POLICY]) {
+		int xmit_hash_policy =
+			nla_get_u8(data[IFLA_BOND_XMIT_HASH_POLICY]);
+
+		bond_opt_initval(&newval, xmit_hash_policy);
+		err = __bond_opt_set(bond, BOND_OPT_XMIT_HASH, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_RESEND_IGMP]) {
+		int resend_igmp =
+			nla_get_u32(data[IFLA_BOND_RESEND_IGMP]);
+
+		bond_opt_initval(&newval, resend_igmp);
+		err = __bond_opt_set(bond, BOND_OPT_RESEND_IGMP, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_NUM_PEER_NOTIF]) {
+		int num_peer_notif =
+			nla_get_u8(data[IFLA_BOND_NUM_PEER_NOTIF]);
+
+		bond_opt_initval(&newval, num_peer_notif);
+		err = __bond_opt_set(bond, BOND_OPT_NUM_PEER_NOTIF, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_ALL_SLAVES_ACTIVE]) {
+		int all_slaves_active =
+			nla_get_u8(data[IFLA_BOND_ALL_SLAVES_ACTIVE]);
+
+		bond_opt_initval(&newval, all_slaves_active);
+		err = __bond_opt_set(bond, BOND_OPT_ALL_SLAVES_ACTIVE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_MIN_LINKS]) {
+		int min_links =
+			nla_get_u32(data[IFLA_BOND_MIN_LINKS]);
+
+		bond_opt_initval(&newval, min_links);
+		err = __bond_opt_set(bond, BOND_OPT_MINLINKS, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_LP_INTERVAL]) {
+		int lp_interval =
+			nla_get_u32(data[IFLA_BOND_LP_INTERVAL]);
+
+		bond_opt_initval(&newval, lp_interval);
+		err = __bond_opt_set(bond, BOND_OPT_LP_INTERVAL, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_PACKETS_PER_SLAVE]) {
+		int packets_per_slave =
+			nla_get_u32(data[IFLA_BOND_PACKETS_PER_SLAVE]);
+
+		bond_opt_initval(&newval, packets_per_slave);
+		err = __bond_opt_set(bond, BOND_OPT_PACKETS_PER_SLAVE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_AD_LACP_RATE]) {
+		int lacp_rate =
+			nla_get_u8(data[IFLA_BOND_AD_LACP_RATE]);
+
+		bond_opt_initval(&newval, lacp_rate);
+		err = __bond_opt_set(bond, BOND_OPT_LACP_RATE, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_AD_SELECT]) {
+		int ad_select =
+			nla_get_u8(data[IFLA_BOND_AD_SELECT]);
+
+		bond_opt_initval(&newval, ad_select);
+		err = __bond_opt_set(bond, BOND_OPT_AD_SELECT, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_AD_ACTOR_SYS_PRIO]) {
+		int actor_sys_prio =
+			nla_get_u16(data[IFLA_BOND_AD_ACTOR_SYS_PRIO]);
+
+		bond_opt_initval(&newval, actor_sys_prio);
+		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYS_PRIO, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_AD_USER_PORT_KEY]) {
+		int port_key =
+			nla_get_u16(data[IFLA_BOND_AD_USER_PORT_KEY]);
+
+		bond_opt_initval(&newval, port_key);
+		err = __bond_opt_set(bond, BOND_OPT_AD_USER_PORT_KEY, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_AD_ACTOR_SYSTEM]) {
+		if (nla_len(data[IFLA_BOND_AD_ACTOR_SYSTEM]) != ETH_ALEN)
+			return -EINVAL;
+
+		bond_opt_initval(&newval,
+				 nla_get_u64(data[IFLA_BOND_AD_ACTOR_SYSTEM]));
+		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYSTEM, &newval);
+		if (err)
+			return err;
+	}
+	if (data[IFLA_BOND_TLB_DYNAMIC_LB]) {
+		int dynamic_lb = nla_get_u8(data[IFLA_BOND_TLB_DYNAMIC_LB]);
+
+		bond_opt_initval(&newval, dynamic_lb);
+		err = __bond_opt_set(bond, BOND_OPT_TLB_DYNAMIC_LB, &newval);
+		if (err)
+			return err;
+	}
+
+	return 0;
+}
+
+static int bond_newlink(struct net *src_net, struct net_device *bond_dev,
+			struct nlattr *tb[], struct nlattr *data[],
+			struct netlink_ext_ack *extack)
+{
+	int err;
+
+	err = bond_changelink(bond_dev, tb, data, extack);
+	if (err < 0)
+		return err;
+
+	err = register_netdevice(bond_dev);
+	if (!err) {
+		struct bonding *bond = netdev_priv(bond_dev);
+
+		netif_carrier_off(bond_dev);
+		bond_work_init_all(bond);
+	}
+
+	return err;
+}
+
+static size_t bond_get_size(const struct net_device *bond_dev)
+{
+	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_MODE */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ACTIVE_SLAVE */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIIMON */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_UPDELAY */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_DOWNDELAY */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_USE_CARRIER */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_INTERVAL */
+						/* IFLA_BOND_ARP_IP_TARGET */
+		nla_total_size(sizeof(struct nlattr)) +
+		nla_total_size(sizeof(u32)) * BOND_MAX_ARP_TARGETS +
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_VALIDATE */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_ALL_TARGETS */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PRIMARY */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_PRIMARY_RESELECT */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_FAIL_OVER_MAC */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_XMIT_HASH_POLICY */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_RESEND_IGMP */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_NUM_PEER_NOTIF */
+		nla_total_size(sizeof(u8)) +   /* IFLA_BOND_ALL_SLAVES_ACTIVE */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIN_LINKS */
+		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_LP_INTERVAL */
+		nla_total_size(sizeof(u32)) +  /* IFLA_BOND_PACKETS_PER_SLAVE */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_LACP_RATE */
+		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_SELECT */
+		nla_total_size(sizeof(struct nlattr)) + /* IFLA_BOND_AD_INFO */
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_AGGREGATOR */
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_NUM_PORTS */
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_ACTOR_KEY */
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_PARTNER_KEY*/
+		nla_total_size(ETH_ALEN) +    /* IFLA_BOND_AD_INFO_PARTNER_MAC*/
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_ACTOR_SYS_PRIO */
+		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_USER_PORT_KEY */
+		nla_total_size(ETH_ALEN) + /* IFLA_BOND_AD_ACTOR_SYSTEM */
+		nla_total_size(sizeof(u8)) + /* IFLA_BOND_TLB_DYNAMIC_LB */
+		0;
+}
+
+static int bond_option_active_slave_get_ifindex(struct bonding *bond)
+{
+	const struct net_device *slave;
+	int ifindex;
+
+	rcu_read_lock();
+	slave = bond_option_active_slave_get_rcu(bond);
+	ifindex = slave ? slave->ifindex : 0;
+	rcu_read_unlock();
+	return ifindex;
+}
+
+static int bond_fill_info(struct sk_buff *skb,
+			  const struct net_device *bond_dev)
+{
+	struct bonding *bond = netdev_priv(bond_dev);
+	unsigned int packets_per_slave;
+	int ifindex, i, targets_added;
+	struct nlattr *targets;
+	struct slave *primary;
+
+	if (nla_put_u8(skb, IFLA_BOND_MODE, BOND_MODE(bond)))
+		goto nla_put_failure;
+
+	ifindex = bond_option_active_slave_get_ifindex(bond);
+	if (ifindex && nla_put_u32(skb, IFLA_BOND_ACTIVE_SLAVE, ifindex))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_MIIMON, bond->params.miimon))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_UPDELAY,
+			bond->params.updelay * bond->params.miimon))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_DOWNDELAY,
+			bond->params.downdelay * bond->params.miimon))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_USE_CARRIER, bond->params.use_carrier))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_ARP_INTERVAL, bond->params.arp_interval))
+		goto nla_put_failure;
+
+	targets = nla_nest_start(skb, IFLA_BOND_ARP_IP_TARGET);
+	if (!targets)
+		goto nla_put_failure;
+
+	targets_added = 0;
+	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
+		if (bond->params.arp_targets[i]) {
+			if (nla_put_be32(skb, i, bond->params.arp_targets[i]))
+				goto nla_put_failure;
+			targets_added = 1;
+		}
+	}
+
+	if (targets_added)
+		nla_nest_end(skb, targets);
+	else
+		nla_nest_cancel(skb, targets);
+
+	if (nla_put_u32(skb, IFLA_BOND_ARP_VALIDATE, bond->params.arp_validate))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_ARP_ALL_TARGETS,
+			bond->params.arp_all_targets))
+		goto nla_put_failure;
+
+	primary = rtnl_dereference(bond->primary_slave);
+	if (primary &&
+	    nla_put_u32(skb, IFLA_BOND_PRIMARY, primary->dev->ifindex))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_PRIMARY_RESELECT,
+		       bond->params.primary_reselect))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_FAIL_OVER_MAC,
+		       bond->params.fail_over_mac))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_XMIT_HASH_POLICY,
+		       bond->params.xmit_policy))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_RESEND_IGMP,
+		        bond->params.resend_igmp))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_NUM_PEER_NOTIF,
+		       bond->params.num_peer_notif))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_ALL_SLAVES_ACTIVE,
+		       bond->params.all_slaves_active))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_MIN_LINKS,
+			bond->params.min_links))
+		goto nla_put_failure;
+
+	if (nla_put_u32(skb, IFLA_BOND_LP_INTERVAL,
+			bond->params.lp_interval))
+		goto nla_put_failure;
+
+	packets_per_slave = bond->params.packets_per_slave;
+	if (nla_put_u32(skb, IFLA_BOND_PACKETS_PER_SLAVE,
+			packets_per_slave))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_AD_LACP_RATE,
+		       bond->params.lacp_fast))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_AD_SELECT,
+		       bond->params.ad_select))
+		goto nla_put_failure;
+
+	if (nla_put_u8(skb, IFLA_BOND_TLB_DYNAMIC_LB,
+		       bond->params.tlb_dynamic_lb))
+		goto nla_put_failure;
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		struct ad_info info;
+
+		if (capable(CAP_NET_ADMIN)) {
+			if (nla_put_u16(skb, IFLA_BOND_AD_ACTOR_SYS_PRIO,
+					bond->params.ad_actor_sys_prio))
+				goto nla_put_failure;
+
+			if (nla_put_u16(skb, IFLA_BOND_AD_USER_PORT_KEY,
+					bond->params.ad_user_port_key))
+				goto nla_put_failure;
+
+			if (nla_put(skb, IFLA_BOND_AD_ACTOR_SYSTEM,
+				    ETH_ALEN, &bond->params.ad_actor_system))
+				goto nla_put_failure;
+		}
+		if (!bond_3ad_get_active_agg_info(bond, &info)) {
+			struct nlattr *nest;
+
+			nest = nla_nest_start(skb, IFLA_BOND_AD_INFO);
+			if (!nest)
+				goto nla_put_failure;
+
+			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_AGGREGATOR,
+					info.aggregator_id))
+				goto nla_put_failure;
+			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_NUM_PORTS,
+					info.ports))
+				goto nla_put_failure;
+			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_ACTOR_KEY,
+					info.actor_key))
+				goto nla_put_failure;
+			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_PARTNER_KEY,
+					info.partner_key))
+				goto nla_put_failure;
+			if (nla_put(skb, IFLA_BOND_AD_INFO_PARTNER_MAC,
+				    sizeof(info.partner_system),
+				    &info.partner_system))
+				goto nla_put_failure;
+
+			nla_nest_end(skb, nest);
+		}
+	}
+
+	return 0;
+
+nla_put_failure:
+	return -EMSGSIZE;
+}
+
+struct rtnl_link_ops bond_link_ops __read_mostly = {
+	.kind			= "bond",
+	.priv_size		= sizeof(struct bonding),
+	.setup			= bond_setup,
+	.maxtype		= IFLA_BOND_MAX,
+	.policy			= bond_policy,
+	.validate		= bond_validate,
+	.newlink		= bond_newlink,
+	.changelink		= bond_changelink,
+	.get_size		= bond_get_size,
+	.fill_info		= bond_fill_info,
+	.get_num_tx_queues	= bond_get_num_tx_queues,
+	.get_num_rx_queues	= bond_get_num_tx_queues, /* Use the same number
+							     as for TX queues */
+	.slave_maxtype		= IFLA_BOND_SLAVE_MAX,
+	.slave_policy		= bond_slave_policy,
+	.slave_changelink	= bond_slave_changelink,
+	.get_slave_size		= bond_get_slave_size,
+	.fill_slave_info	= bond_fill_slave_info,
+};
+
+int __init bond_netlink_init(void)
+{
+	return rtnl_link_register(&bond_link_ops);
+}
+
+void bond_netlink_fini(void)
+{
+	rtnl_link_unregister(&bond_link_ops);
+}
+
+MODULE_ALIAS_RTNL_LINK("bond");
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.164/bond_options.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.164/bond_options.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,1464 @@
+/*
+ * drivers/net/bond/bond_options.c - bonding options
+ * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
+ * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#include <linux/errno.h>
+#include <linux/if.h>
+#include <linux/netdevice.h>
+#include <linux/spinlock.h>
+#include <linux/rcupdate.h>
+#include <linux/ctype.h>
+#include <linux/inet.h>
+#include <linux/sched/signal.h>
+
+#include <net/bonding.h>
+
+static int bond_option_active_slave_set(struct bonding *bond,
+					const struct bond_opt_value *newval);
+static int bond_option_miimon_set(struct bonding *bond,
+				  const struct bond_opt_value *newval);
+static int bond_option_updelay_set(struct bonding *bond,
+				   const struct bond_opt_value *newval);
+static int bond_option_downdelay_set(struct bonding *bond,
+				     const struct bond_opt_value *newval);
+static int bond_option_use_carrier_set(struct bonding *bond,
+				       const struct bond_opt_value *newval);
+static int bond_option_arp_interval_set(struct bonding *bond,
+					const struct bond_opt_value *newval);
+static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target);
+static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target);
+static int bond_option_arp_ip_targets_set(struct bonding *bond,
+					  const struct bond_opt_value *newval);
+static int bond_option_arp_validate_set(struct bonding *bond,
+					const struct bond_opt_value *newval);
+static int bond_option_arp_all_targets_set(struct bonding *bond,
+					   const struct bond_opt_value *newval);
+static int bond_option_primary_set(struct bonding *bond,
+				   const struct bond_opt_value *newval);
+static int bond_option_primary_reselect_set(struct bonding *bond,
+					    const struct bond_opt_value *newval);
+static int bond_option_fail_over_mac_set(struct bonding *bond,
+					 const struct bond_opt_value *newval);
+static int bond_option_xmit_hash_policy_set(struct bonding *bond,
+					    const struct bond_opt_value *newval);
+static int bond_option_resend_igmp_set(struct bonding *bond,
+				       const struct bond_opt_value *newval);
+static int bond_option_num_peer_notif_set(struct bonding *bond,
+					  const struct bond_opt_value *newval);
+static int bond_option_all_slaves_active_set(struct bonding *bond,
+					     const struct bond_opt_value *newval);
+static int bond_option_min_links_set(struct bonding *bond,
+				     const struct bond_opt_value *newval);
+static int bond_option_lp_interval_set(struct bonding *bond,
+				       const struct bond_opt_value *newval);
+static int bond_option_pps_set(struct bonding *bond,
+			       const struct bond_opt_value *newval);
+static int bond_option_lacp_rate_set(struct bonding *bond,
+				     const struct bond_opt_value *newval);
+static int bond_option_ad_select_set(struct bonding *bond,
+				     const struct bond_opt_value *newval);
+static int bond_option_queue_id_set(struct bonding *bond,
+				    const struct bond_opt_value *newval);
+static int bond_option_mode_set(struct bonding *bond,
+				const struct bond_opt_value *newval);
+static int bond_option_slaves_set(struct bonding *bond,
+				  const struct bond_opt_value *newval);
+static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
+				  const struct bond_opt_value *newval);
+static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
+					     const struct bond_opt_value *newval);
+static int bond_option_ad_actor_system_set(struct bonding *bond,
+					   const struct bond_opt_value *newval);
+static int bond_option_ad_user_port_key_set(struct bonding *bond,
+					    const struct bond_opt_value *newval);
+
+
+static const struct bond_opt_value bond_mode_tbl[] = {
+	{ "balance-rr",    BOND_MODE_ROUNDROBIN,   BOND_VALFLAG_DEFAULT},
+	{ "active-backup", BOND_MODE_ACTIVEBACKUP, 0},
+	{ "balance-xor",   BOND_MODE_XOR,          0},
+	{ "broadcast",     BOND_MODE_BROADCAST,    0},
+	{ "802.3ad",       BOND_MODE_8023AD,       0},
+	{ "balance-tlb",   BOND_MODE_TLB,          0},
+	{ "balance-alb",   BOND_MODE_ALB,          0},
+	{ NULL,            -1,                     0},
+};
+
+static const struct bond_opt_value bond_pps_tbl[] = {
+	{ "default", 1,         BOND_VALFLAG_DEFAULT},
+	{ "maxval",  USHRT_MAX, BOND_VALFLAG_MAX},
+	{ NULL,      -1,        0},
+};
+
+static const struct bond_opt_value bond_xmit_hashtype_tbl[] = {
+	{ "layer2",   BOND_XMIT_POLICY_LAYER2, BOND_VALFLAG_DEFAULT},
+	{ "layer3+4", BOND_XMIT_POLICY_LAYER34, 0},
+	{ "layer2+3", BOND_XMIT_POLICY_LAYER23, 0},
+	{ "encap2+3", BOND_XMIT_POLICY_ENCAP23, 0},
+	{ "encap3+4", BOND_XMIT_POLICY_ENCAP34, 0},
+	{ NULL,       -1,                       0},
+};
+
+static const struct bond_opt_value bond_arp_validate_tbl[] = {
+	{ "none",		BOND_ARP_VALIDATE_NONE,		BOND_VALFLAG_DEFAULT},
+	{ "active",		BOND_ARP_VALIDATE_ACTIVE,	0},
+	{ "backup",		BOND_ARP_VALIDATE_BACKUP,	0},
+	{ "all",		BOND_ARP_VALIDATE_ALL,		0},
+	{ "filter",		BOND_ARP_FILTER,		0},
+	{ "filter_active",	BOND_ARP_FILTER_ACTIVE,		0},
+	{ "filter_backup",	BOND_ARP_FILTER_BACKUP,		0},
+	{ NULL,			-1,				0},
+};
+
+static const struct bond_opt_value bond_arp_all_targets_tbl[] = {
+	{ "any", BOND_ARP_TARGETS_ANY, BOND_VALFLAG_DEFAULT},
+	{ "all", BOND_ARP_TARGETS_ALL, 0},
+	{ NULL,  -1,                   0},
+};
+
+static const struct bond_opt_value bond_fail_over_mac_tbl[] = {
+	{ "none",   BOND_FOM_NONE,   BOND_VALFLAG_DEFAULT},
+	{ "active", BOND_FOM_ACTIVE, 0},
+	{ "follow", BOND_FOM_FOLLOW, 0},
+	{ NULL,     -1,              0},
+};
+
+static const struct bond_opt_value bond_intmax_tbl[] = {
+	{ "off",     0,       BOND_VALFLAG_DEFAULT},
+	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
+	{ NULL,      -1,      0}
+};
+
+static const struct bond_opt_value bond_lacp_rate_tbl[] = {
+	{ "slow", AD_LACP_SLOW, 0},
+	{ "fast", AD_LACP_FAST, 0},
+	{ NULL,   -1,           0},
+};
+
+static const struct bond_opt_value bond_ad_select_tbl[] = {
+	{ "stable",    BOND_AD_STABLE,    BOND_VALFLAG_DEFAULT},
+	{ "bandwidth", BOND_AD_BANDWIDTH, 0},
+	{ "count",     BOND_AD_COUNT,     0},
+	{ NULL,        -1,                0},
+};
+
+static const struct bond_opt_value bond_num_peer_notif_tbl[] = {
+	{ "off",     0,   0},
+	{ "maxval",  255, BOND_VALFLAG_MAX},
+	{ "default", 1,   BOND_VALFLAG_DEFAULT},
+	{ NULL,      -1,  0}
+};
+
+static const struct bond_opt_value bond_primary_reselect_tbl[] = {
+	{ "always",  BOND_PRI_RESELECT_ALWAYS,  BOND_VALFLAG_DEFAULT},
+	{ "better",  BOND_PRI_RESELECT_BETTER,  0},
+	{ "failure", BOND_PRI_RESELECT_FAILURE, 0},
+	{ NULL,      -1},
+};
+
+static const struct bond_opt_value bond_use_carrier_tbl[] = {
+	{ "off", 0,  0},
+	{ "on",  1,  BOND_VALFLAG_DEFAULT},
+	{ NULL,  -1, 0}
+};
+
+static const struct bond_opt_value bond_all_slaves_active_tbl[] = {
+	{ "off", 0,  BOND_VALFLAG_DEFAULT},
+	{ "on",  1,  0},
+	{ NULL,  -1, 0}
+};
+
+static const struct bond_opt_value bond_resend_igmp_tbl[] = {
+	{ "off",     0,   0},
+	{ "maxval",  255, BOND_VALFLAG_MAX},
+	{ "default", 1,   BOND_VALFLAG_DEFAULT},
+	{ NULL,      -1,  0}
+};
+
+static const struct bond_opt_value bond_lp_interval_tbl[] = {
+	{ "minval",  1,       BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
+	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
+	{ NULL,      -1,      0},
+};
+
+static const struct bond_opt_value bond_tlb_dynamic_lb_tbl[] = {
+	{ "off", 0,  0},
+	{ "on",  1,  BOND_VALFLAG_DEFAULT},
+	{ NULL,  -1, 0}
+};
+
+static const struct bond_opt_value bond_ad_actor_sys_prio_tbl[] = {
+	{ "minval",  1,     BOND_VALFLAG_MIN},
+	{ "maxval",  65535, BOND_VALFLAG_MAX | BOND_VALFLAG_DEFAULT},
+	{ NULL,      -1,    0},
+};
+
+static const struct bond_opt_value bond_ad_user_port_key_tbl[] = {
+	{ "minval",  0,     BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
+	{ "maxval",  1023,  BOND_VALFLAG_MAX},
+	{ NULL,      -1,    0},
+};
+
+static const struct bond_option bond_opts[BOND_OPT_LAST] = {
+	[BOND_OPT_MODE] = {
+		.id = BOND_OPT_MODE,
+		.name = "mode",
+		.desc = "bond device mode",
+		.flags = BOND_OPTFLAG_NOSLAVES | BOND_OPTFLAG_IFDOWN,
+		.values = bond_mode_tbl,
+		.set = bond_option_mode_set
+	},
+	[BOND_OPT_PACKETS_PER_SLAVE] = {
+		.id = BOND_OPT_PACKETS_PER_SLAVE,
+		.name = "packets_per_slave",
+		.desc = "Packets to send per slave in RR mode",
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ROUNDROBIN)),
+		.values = bond_pps_tbl,
+		.set = bond_option_pps_set
+	},
+	[BOND_OPT_XMIT_HASH] = {
+		.id = BOND_OPT_XMIT_HASH,
+		.name = "xmit_hash_policy",
+		.desc = "balance-xor, 802.3ad, and tlb hashing method",
+		.values = bond_xmit_hashtype_tbl,
+		.set = bond_option_xmit_hash_policy_set
+	},
+	[BOND_OPT_ARP_VALIDATE] = {
+		.id = BOND_OPT_ARP_VALIDATE,
+		.name = "arp_validate",
+		.desc = "validate src/dst of ARP probes",
+		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
+			       BIT(BOND_MODE_ALB),
+		.values = bond_arp_validate_tbl,
+		.set = bond_option_arp_validate_set
+	},
+	[BOND_OPT_ARP_ALL_TARGETS] = {
+		.id = BOND_OPT_ARP_ALL_TARGETS,
+		.name = "arp_all_targets",
+		.desc = "fail on any/all arp targets timeout",
+		.values = bond_arp_all_targets_tbl,
+		.set = bond_option_arp_all_targets_set
+	},
+	[BOND_OPT_FAIL_OVER_MAC] = {
+		.id = BOND_OPT_FAIL_OVER_MAC,
+		.name = "fail_over_mac",
+		.desc = "For active-backup, do not set all slaves to the same MAC",
+		.flags = BOND_OPTFLAG_NOSLAVES,
+		.values = bond_fail_over_mac_tbl,
+		.set = bond_option_fail_over_mac_set
+	},
+	[BOND_OPT_ARP_INTERVAL] = {
+		.id = BOND_OPT_ARP_INTERVAL,
+		.name = "arp_interval",
+		.desc = "arp interval in milliseconds",
+		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
+			       BIT(BOND_MODE_ALB),
+		.values = bond_intmax_tbl,
+		.set = bond_option_arp_interval_set
+	},
+	[BOND_OPT_ARP_TARGETS] = {
+		.id = BOND_OPT_ARP_TARGETS,
+		.name = "arp_ip_target",
+		.desc = "arp targets in n.n.n.n form",
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.set = bond_option_arp_ip_targets_set
+	},
+	[BOND_OPT_DOWNDELAY] = {
+		.id = BOND_OPT_DOWNDELAY,
+		.name = "downdelay",
+		.desc = "Delay before considering link down, in milliseconds",
+		.values = bond_intmax_tbl,
+		.set = bond_option_downdelay_set
+	},
+	[BOND_OPT_UPDELAY] = {
+		.id = BOND_OPT_UPDELAY,
+		.name = "updelay",
+		.desc = "Delay before considering link up, in milliseconds",
+		.values = bond_intmax_tbl,
+		.set = bond_option_updelay_set
+	},
+	[BOND_OPT_LACP_RATE] = {
+		.id = BOND_OPT_LACP_RATE,
+		.name = "lacp_rate",
+		.desc = "LACPDU tx rate to request from 802.3ad partner",
+		.flags = BOND_OPTFLAG_IFDOWN,
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
+		.values = bond_lacp_rate_tbl,
+		.set = bond_option_lacp_rate_set
+	},
+	[BOND_OPT_MINLINKS] = {
+		.id = BOND_OPT_MINLINKS,
+		.name = "min_links",
+		.desc = "Minimum number of available links before turning on carrier",
+		.values = bond_intmax_tbl,
+		.set = bond_option_min_links_set
+	},
+	[BOND_OPT_AD_SELECT] = {
+		.id = BOND_OPT_AD_SELECT,
+		.name = "ad_select",
+		.desc = "802.3ad aggregation selection logic",
+		.flags = BOND_OPTFLAG_IFDOWN,
+		.values = bond_ad_select_tbl,
+		.set = bond_option_ad_select_set
+	},
+	[BOND_OPT_NUM_PEER_NOTIF] = {
+		.id = BOND_OPT_NUM_PEER_NOTIF,
+		.name = "num_unsol_na",
+		.desc = "Number of peer notifications to send on failover event",
+		.values = bond_num_peer_notif_tbl,
+		.set = bond_option_num_peer_notif_set
+	},
+	[BOND_OPT_MIIMON] = {
+		.id = BOND_OPT_MIIMON,
+		.name = "miimon",
+		.desc = "Link check interval in milliseconds",
+		.values = bond_intmax_tbl,
+		.set = bond_option_miimon_set
+	},
+	[BOND_OPT_PRIMARY] = {
+		.id = BOND_OPT_PRIMARY,
+		.name = "primary",
+		.desc = "Primary network device to use",
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
+						BIT(BOND_MODE_TLB) |
+						BIT(BOND_MODE_ALB)),
+		.set = bond_option_primary_set
+	},
+	[BOND_OPT_PRIMARY_RESELECT] = {
+		.id = BOND_OPT_PRIMARY_RESELECT,
+		.name = "primary_reselect",
+		.desc = "Reselect primary slave once it comes up",
+		.values = bond_primary_reselect_tbl,
+		.set = bond_option_primary_reselect_set
+	},
+	[BOND_OPT_USE_CARRIER] = {
+		.id = BOND_OPT_USE_CARRIER,
+		.name = "use_carrier",
+		.desc = "Use netif_carrier_ok (vs MII ioctls) in miimon",
+		.values = bond_use_carrier_tbl,
+		.set = bond_option_use_carrier_set
+	},
+	[BOND_OPT_ACTIVE_SLAVE] = {
+		.id = BOND_OPT_ACTIVE_SLAVE,
+		.name = "active_slave",
+		.desc = "Currently active slave",
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
+						BIT(BOND_MODE_TLB) |
+						BIT(BOND_MODE_ALB)),
+		.set = bond_option_active_slave_set
+	},
+	[BOND_OPT_QUEUE_ID] = {
+		.id = BOND_OPT_QUEUE_ID,
+		.name = "queue_id",
+		.desc = "Set queue id of a slave",
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.set = bond_option_queue_id_set
+	},
+	[BOND_OPT_ALL_SLAVES_ACTIVE] = {
+		.id = BOND_OPT_ALL_SLAVES_ACTIVE,
+		.name = "all_slaves_active",
+		.desc = "Keep all frames received on an interface by setting active flag for all slaves",
+		.values = bond_all_slaves_active_tbl,
+		.set = bond_option_all_slaves_active_set
+	},
+	[BOND_OPT_RESEND_IGMP] = {
+		.id = BOND_OPT_RESEND_IGMP,
+		.name = "resend_igmp",
+		.desc = "Number of IGMP membership reports to send on link failure",
+		.values = bond_resend_igmp_tbl,
+		.set = bond_option_resend_igmp_set
+	},
+	[BOND_OPT_LP_INTERVAL] = {
+		.id = BOND_OPT_LP_INTERVAL,
+		.name = "lp_interval",
+		.desc = "The number of seconds between instances where the bonding driver sends learning packets to each slave's peer switch",
+		.values = bond_lp_interval_tbl,
+		.set = bond_option_lp_interval_set
+	},
+	[BOND_OPT_SLAVES] = {
+		.id = BOND_OPT_SLAVES,
+		.name = "slaves",
+		.desc = "Slave membership management",
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.set = bond_option_slaves_set
+	},
+	[BOND_OPT_TLB_DYNAMIC_LB] = {
+		.id = BOND_OPT_TLB_DYNAMIC_LB,
+		.name = "tlb_dynamic_lb",
+		.desc = "Enable dynamic flow shuffling",
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_TLB) | BIT(BOND_MODE_ALB)),
+		.values = bond_tlb_dynamic_lb_tbl,
+		.flags = BOND_OPTFLAG_IFDOWN,
+		.set = bond_option_tlb_dynamic_lb_set,
+	},
+	[BOND_OPT_AD_ACTOR_SYS_PRIO] = {
+		.id = BOND_OPT_AD_ACTOR_SYS_PRIO,
+		.name = "ad_actor_sys_prio",
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
+		.values = bond_ad_actor_sys_prio_tbl,
+		.set = bond_option_ad_actor_sys_prio_set,
+	},
+	[BOND_OPT_AD_ACTOR_SYSTEM] = {
+		.id = BOND_OPT_AD_ACTOR_SYSTEM,
+		.name = "ad_actor_system",
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
+		.flags = BOND_OPTFLAG_RAWVAL,
+		.set = bond_option_ad_actor_system_set,
+	},
+	[BOND_OPT_AD_USER_PORT_KEY] = {
+		.id = BOND_OPT_AD_USER_PORT_KEY,
+		.name = "ad_user_port_key",
+		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
+		.flags = BOND_OPTFLAG_IFDOWN,
+		.values = bond_ad_user_port_key_tbl,
+		.set = bond_option_ad_user_port_key_set,
+	},
+	[BOND_OPT_NUM_PEER_NOTIF_ALIAS] = {
+		.id = BOND_OPT_NUM_PEER_NOTIF_ALIAS,
+		.name = "num_grat_arp",
+		.desc = "Number of peer notifications to send on failover event",
+		.values = bond_num_peer_notif_tbl,
+		.set = bond_option_num_peer_notif_set
+	}
+};
+
+/* Searches for an option by name */
+const struct bond_option *bond_opt_get_by_name(const char *name)
+{
+	const struct bond_option *opt;
+	int option;
+
+	for (option = 0; option < BOND_OPT_LAST; option++) {
+		opt = bond_opt_get(option);
+		if (opt && !strcmp(opt->name, name))
+			return opt;
+	}
+
+	return NULL;
+}
+
+/* Searches for a value in opt's values[] table */
+const struct bond_opt_value *bond_opt_get_val(unsigned int option, u64 val)
+{
+	const struct bond_option *opt;
+	int i;
+
+	opt = bond_opt_get(option);
+	if (WARN_ON(!opt))
+		return NULL;
+	for (i = 0; opt->values && opt->values[i].string; i++)
+		if (opt->values[i].value == val)
+			return &opt->values[i];
+
+	return NULL;
+}
+
+/* Searches for a value in opt's values[] table which matches the flagmask */
+static const struct bond_opt_value *bond_opt_get_flags(const struct bond_option *opt,
+						       u32 flagmask)
+{
+	int i;
+
+	for (i = 0; opt->values && opt->values[i].string; i++)
+		if (opt->values[i].flags & flagmask)
+			return &opt->values[i];
+
+	return NULL;
+}
+
+/* If maxval is missing then there's no range to check. In case minval is
+ * missing then it's considered to be 0.
+ */
+static bool bond_opt_check_range(const struct bond_option *opt, u64 val)
+{
+	const struct bond_opt_value *minval, *maxval;
+
+	minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
+	maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
+	if (!maxval || (minval && val < minval->value) || val > maxval->value)
+		return false;
+
+	return true;
+}
+
+/**
+ * bond_opt_parse - parse option value
+ * @opt: the option to parse against
+ * @val: value to parse
+ *
+ * This function tries to extract the value from @val and check if it's
+ * a possible match for the option and returns NULL if a match isn't found,
+ * or the struct_opt_value that matched. It also strips the new line from
+ * @val->string if it's present.
+ */
+const struct bond_opt_value *bond_opt_parse(const struct bond_option *opt,
+					    struct bond_opt_value *val)
+{
+	char *p, valstr[BOND_OPT_MAX_NAMELEN + 1] = { 0, };
+	const struct bond_opt_value *tbl;
+	const struct bond_opt_value *ret = NULL;
+	bool checkval;
+	int i, rv;
+
+	/* No parsing if the option wants a raw val */
+	if (opt->flags & BOND_OPTFLAG_RAWVAL)
+		return val;
+
+	tbl = opt->values;
+	if (!tbl)
+		goto out;
+
+	/* ULLONG_MAX is used to bypass string processing */
+	checkval = val->value != ULLONG_MAX;
+	if (!checkval) {
+		if (!val->string)
+			goto out;
+		p = strchr(val->string, '\n');
+		if (p)
+			*p = '\0';
+		for (p = val->string; *p; p++)
+			if (!(isdigit(*p) || isspace(*p)))
+				break;
+		/* The following code extracts the string to match or the value
+		 * and sets checkval appropriately
+		 */
+		if (*p) {
+			rv = sscanf(val->string, "%32s", valstr);
+		} else {
+			rv = sscanf(val->string, "%llu", &val->value);
+			checkval = true;
+		}
+		if (!rv)
+			goto out;
+	}
+
+	for (i = 0; tbl[i].string; i++) {
+		/* Check for exact match */
+		if (checkval) {
+			if (val->value == tbl[i].value)
+				ret = &tbl[i];
+		} else {
+			if (!strcmp(valstr, "default") &&
+			    (tbl[i].flags & BOND_VALFLAG_DEFAULT))
+				ret = &tbl[i];
+
+			if (!strcmp(valstr, tbl[i].string))
+				ret = &tbl[i];
+		}
+		/* Found an exact match */
+		if (ret)
+			goto out;
+	}
+	/* Possible range match */
+	if (checkval && bond_opt_check_range(opt, val->value))
+		ret = val;
+out:
+	return ret;
+}
+
+/* Check opt's dependencies against bond mode and currently set options */
+static int bond_opt_check_deps(struct bonding *bond,
+			       const struct bond_option *opt)
+{
+	struct bond_params *params = &bond->params;
+
+	if (test_bit(params->mode, &opt->unsuppmodes))
+		return -EACCES;
+	if ((opt->flags & BOND_OPTFLAG_NOSLAVES) && bond_has_slaves(bond))
+		return -ENOTEMPTY;
+	if ((opt->flags & BOND_OPTFLAG_IFDOWN) && (bond->dev->flags & IFF_UP))
+		return -EBUSY;
+
+	return 0;
+}
+
+static void bond_opt_dep_print(struct bonding *bond,
+			       const struct bond_option *opt)
+{
+	const struct bond_opt_value *modeval;
+	struct bond_params *params;
+
+	params = &bond->params;
+	modeval = bond_opt_get_val(BOND_OPT_MODE, params->mode);
+	if (test_bit(params->mode, &opt->unsuppmodes))
+		netdev_err(bond->dev, "option %s: mode dependency failed, not supported in mode %s(%llu)\n",
+			   opt->name, modeval->string, modeval->value);
+}
+
+static void bond_opt_error_interpret(struct bonding *bond,
+				     const struct bond_option *opt,
+				     int error, const struct bond_opt_value *val)
+{
+	const struct bond_opt_value *minval, *maxval;
+	char *p;
+
+	switch (error) {
+	case -EINVAL:
+		if (val) {
+			if (val->string) {
+				/* sometimes RAWVAL opts may have new lines */
+				p = strchr(val->string, '\n');
+				if (p)
+					*p = '\0';
+				netdev_err(bond->dev, "option %s: invalid value (%s)\n",
+					   opt->name, val->string);
+			} else {
+				netdev_err(bond->dev, "option %s: invalid value (%llu)\n",
+					   opt->name, val->value);
+			}
+		}
+		minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
+		maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
+		if (!maxval)
+			break;
+		netdev_err(bond->dev, "option %s: allowed values %llu - %llu\n",
+			   opt->name, minval ? minval->value : 0, maxval->value);
+		break;
+	case -EACCES:
+		bond_opt_dep_print(bond, opt);
+		break;
+	case -ENOTEMPTY:
+		netdev_err(bond->dev, "option %s: unable to set because the bond device has slaves\n",
+			   opt->name);
+		break;
+	case -EBUSY:
+		netdev_err(bond->dev, "option %s: unable to set because the bond device is up\n",
+			   opt->name);
+		break;
+	default:
+		break;
+	}
+}
+
+/**
+ * __bond_opt_set - set a bonding option
+ * @bond: target bond device
+ * @option: option to set
+ * @val: value to set it to
+ *
+ * This function is used to change the bond's option value, it can be
+ * used for both enabling/changing an option and for disabling it. RTNL lock
+ * must be obtained before calling this function.
+ */
+int __bond_opt_set(struct bonding *bond,
+		   unsigned int option, struct bond_opt_value *val)
+{
+	const struct bond_opt_value *retval = NULL;
+	const struct bond_option *opt;
+	int ret = -ENOENT;
+
+	ASSERT_RTNL();
+
+	opt = bond_opt_get(option);
+	if (WARN_ON(!val) || WARN_ON(!opt))
+		goto out;
+	ret = bond_opt_check_deps(bond, opt);
+	if (ret)
+		goto out;
+	retval = bond_opt_parse(opt, val);
+	if (!retval) {
+		ret = -EINVAL;
+		goto out;
+	}
+	ret = opt->set(bond, retval);
+out:
+	if (ret)
+		bond_opt_error_interpret(bond, opt, ret, val);
+
+	return ret;
+}
+/**
+ * __bond_opt_set_notify - set a bonding option
+ * @bond: target bond device
+ * @option: option to set
+ * @val: value to set it to
+ *
+ * This function is used to change the bond's option value and trigger
+ * a notification to user sapce. It can be used for both enabling/changing
+ * an option and for disabling it. RTNL lock must be obtained before calling
+ * this function.
+ */
+int __bond_opt_set_notify(struct bonding *bond,
+			  unsigned int option, struct bond_opt_value *val)
+{
+	int ret = -ENOENT;
+
+	ASSERT_RTNL();
+
+	ret = __bond_opt_set(bond, option, val);
+
+	if (!ret && (bond->dev->reg_state == NETREG_REGISTERED))
+		call_netdevice_notifiers(NETDEV_CHANGEINFODATA, bond->dev);
+
+	return ret;
+}
+
+/**
+ * bond_opt_tryset_rtnl - try to acquire rtnl and call __bond_opt_set
+ * @bond: target bond device
+ * @option: option to set
+ * @buf: value to set it to
+ *
+ * This function tries to acquire RTNL without blocking and if successful
+ * calls __bond_opt_set. It is mainly used for sysfs option manipulation.
+ */
+int bond_opt_tryset_rtnl(struct bonding *bond, unsigned int option, char *buf)
+{
+	struct bond_opt_value optval;
+	int ret;
+
+	if (!rtnl_trylock())
+		return restart_syscall();
+	bond_opt_initstr(&optval, buf);
+	ret = __bond_opt_set_notify(bond, option, &optval);
+	rtnl_unlock();
+
+	return ret;
+}
+
+/**
+ * bond_opt_get - get a pointer to an option
+ * @option: option for which to return a pointer
+ *
+ * This function checks if option is valid and if so returns a pointer
+ * to its entry in the bond_opts[] option array.
+ */
+const struct bond_option *bond_opt_get(unsigned int option)
+{
+	if (!BOND_OPT_VALID(option))
+		return NULL;
+
+	return &bond_opts[option];
+}
+
+static int bond_option_mode_set(struct bonding *bond,
+				const struct bond_opt_value *newval)
+{
+	if (!bond_mode_uses_arp(newval->value)) {
+		if (bond->params.arp_interval) {
+			netdev_dbg(bond->dev, "%s mode is incompatible with arp monitoring, start mii monitoring\n",
+				   newval->string);
+			/* disable arp monitoring */
+			bond->params.arp_interval = 0;
+		}
+
+		if (!bond->params.miimon) {
+			/* set miimon to default value */
+			bond->params.miimon = BOND_DEFAULT_MIIMON;
+			netdev_dbg(bond->dev, "Setting MII monitoring interval to %d\n",
+				   bond->params.miimon);
+		}
+	}
+
+	if (newval->value == BOND_MODE_ALB)
+		bond->params.tlb_dynamic_lb = 1;
+
+	/* don't cache arp_validate between modes */
+	bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
+	bond->params.mode = newval->value;
+
+	return 0;
+}
+
+static int bond_option_active_slave_set(struct bonding *bond,
+					const struct bond_opt_value *newval)
+{
+	char ifname[IFNAMSIZ] = { 0, };
+	struct net_device *slave_dev;
+	int ret = 0;
+
+	sscanf(newval->string, "%15s", ifname); /* IFNAMSIZ */
+	if (!strlen(ifname) || newval->string[0] == '\n') {
+		slave_dev = NULL;
+	} else {
+		slave_dev = __dev_get_by_name(dev_net(bond->dev), ifname);
+		if (!slave_dev)
+			return -ENODEV;
+	}
+
+	if (slave_dev) {
+		if (!netif_is_bond_slave(slave_dev)) {
+			netdev_err(bond->dev, "Device %s is not bonding slave\n",
+				   slave_dev->name);
+			return -EINVAL;
+		}
+
+		if (bond->dev != netdev_master_upper_dev_get(slave_dev)) {
+			netdev_err(bond->dev, "Device %s is not our slave\n",
+				   slave_dev->name);
+			return -EINVAL;
+		}
+	}
+
+	block_netpoll_tx();
+	/* check to see if we are clearing active */
+	if (!slave_dev) {
+		netdev_dbg(bond->dev, "Clearing current active slave\n");
+		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
+		bond_select_active_slave(bond);
+	} else {
+		struct slave *old_active = rtnl_dereference(bond->curr_active_slave);
+		struct slave *new_active = bond_slave_get_rtnl(slave_dev);
+
+		BUG_ON(!new_active);
+
+		if (new_active == old_active) {
+			/* do nothing */
+			netdev_dbg(bond->dev, "%s is already the current active slave\n",
+				   new_active->dev->name);
+		} else {
+			if (old_active && (new_active->link == BOND_LINK_UP) &&
+			    bond_slave_is_up(new_active)) {
+				netdev_dbg(bond->dev, "Setting %s as active slave\n",
+					   new_active->dev->name);
+				bond_change_active_slave(bond, new_active);
+			} else {
+				netdev_err(bond->dev, "Could not set %s as active slave; either %s is down or the link is down\n",
+					   new_active->dev->name,
+					   new_active->dev->name);
+				ret = -EINVAL;
+			}
+		}
+	}
+	unblock_netpoll_tx();
+
+	return ret;
+}
+
+/* There are two tricky bits here.  First, if MII monitoring is activated, then
+ * we must disable ARP monitoring.  Second, if the timer isn't running, we must
+ * start it.
+ */
+static int bond_option_miimon_set(struct bonding *bond,
+				  const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting MII monitoring interval to %llu\n",
+		   newval->value);
+	bond->params.miimon = newval->value;
+	if (bond->params.updelay)
+		netdev_dbg(bond->dev, "Note: Updating updelay (to %d) since it is a multiple of the miimon value\n",
+			   bond->params.updelay * bond->params.miimon);
+	if (bond->params.downdelay)
+		netdev_dbg(bond->dev, "Note: Updating downdelay (to %d) since it is a multiple of the miimon value\n",
+			   bond->params.downdelay * bond->params.miimon);
+	if (newval->value && bond->params.arp_interval) {
+		netdev_dbg(bond->dev, "MII monitoring cannot be used with ARP monitoring - disabling ARP monitoring...\n");
+		bond->params.arp_interval = 0;
+		if (bond->params.arp_validate)
+			bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
+	}
+	if (bond->dev->flags & IFF_UP) {
+		/* If the interface is up, we may need to fire off
+		 * the MII timer. If the interface is down, the
+		 * timer will get fired off when the open function
+		 * is called.
+		 */
+		if (!newval->value) {
+			cancel_delayed_work_sync(&bond->mii_work);
+		} else {
+			cancel_delayed_work_sync(&bond->arp_work);
+			queue_delayed_work(bond->wq, &bond->mii_work, 0);
+		}
+	}
+
+	return 0;
+}
+
+/* Set up and down delays. These must be multiples of the
+ * MII monitoring value, and are stored internally as the multiplier.
+ * Thus, we must translate to MS for the real world.
+ */
+static int bond_option_updelay_set(struct bonding *bond,
+				   const struct bond_opt_value *newval)
+{
+	int value = newval->value;
+
+	if (!bond->params.miimon) {
+		netdev_err(bond->dev, "Unable to set up delay as MII monitoring is disabled\n");
+		return -EPERM;
+	}
+	if ((value % bond->params.miimon) != 0) {
+		netdev_warn(bond->dev, "up delay (%d) is not a multiple of miimon (%d), updelay rounded to %d ms\n",
+			    value, bond->params.miimon,
+			    (value / bond->params.miimon) *
+			    bond->params.miimon);
+	}
+	bond->params.updelay = value / bond->params.miimon;
+	netdev_dbg(bond->dev, "Setting up delay to %d\n",
+		   bond->params.updelay * bond->params.miimon);
+
+	return 0;
+}
+
+static int bond_option_downdelay_set(struct bonding *bond,
+				     const struct bond_opt_value *newval)
+{
+	int value = newval->value;
+
+	if (!bond->params.miimon) {
+		netdev_err(bond->dev, "Unable to set down delay as MII monitoring is disabled\n");
+		return -EPERM;
+	}
+	if ((value % bond->params.miimon) != 0) {
+		netdev_warn(bond->dev, "down delay (%d) is not a multiple of miimon (%d), delay rounded to %d ms\n",
+			    value, bond->params.miimon,
+			    (value / bond->params.miimon) *
+			    bond->params.miimon);
+	}
+	bond->params.downdelay = value / bond->params.miimon;
+	netdev_dbg(bond->dev, "Setting down delay to %d\n",
+		   bond->params.downdelay * bond->params.miimon);
+
+	return 0;
+}
+
+static int bond_option_use_carrier_set(struct bonding *bond,
+				       const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting use_carrier to %llu\n",
+		   newval->value);
+	bond->params.use_carrier = newval->value;
+
+	return 0;
+}
+
+/* There are two tricky bits here.  First, if ARP monitoring is activated, then
+ * we must disable MII monitoring.  Second, if the ARP timer isn't running,
+ * we must start it.
+ */
+static int bond_option_arp_interval_set(struct bonding *bond,
+					const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting ARP monitoring interval to %llu\n",
+		   newval->value);
+	bond->params.arp_interval = newval->value;
+	if (newval->value) {
+		if (bond->params.miimon) {
+			netdev_dbg(bond->dev, "ARP monitoring cannot be used with MII monitoring. Disabling MII monitoring\n");
+			bond->params.miimon = 0;
+		}
+		if (!bond->params.arp_targets[0])
+			netdev_dbg(bond->dev, "ARP monitoring has been set up, but no ARP targets have been specified\n");
+	}
+	if (bond->dev->flags & IFF_UP) {
+		/* If the interface is up, we may need to fire off
+		 * the ARP timer.  If the interface is down, the
+		 * timer will get fired off when the open function
+		 * is called.
+		 */
+		if (!newval->value) {
+			if (bond->params.arp_validate)
+				bond->recv_probe = NULL;
+			cancel_delayed_work_sync(&bond->arp_work);
+		} else {
+			/* arp_validate can be set only in active-backup mode */
+			bond->recv_probe = bond_arp_rcv;
+			cancel_delayed_work_sync(&bond->mii_work);
+			queue_delayed_work(bond->wq, &bond->arp_work, 0);
+		}
+	}
+
+	return 0;
+}
+
+static void _bond_options_arp_ip_target_set(struct bonding *bond, int slot,
+					    __be32 target,
+					    unsigned long last_rx)
+{
+	__be32 *targets = bond->params.arp_targets;
+	struct list_head *iter;
+	struct slave *slave;
+
+	if (slot >= 0 && slot < BOND_MAX_ARP_TARGETS) {
+		bond_for_each_slave(bond, slave, iter)
+			slave->target_last_arp_rx[slot] = last_rx;
+		targets[slot] = target;
+	}
+}
+
+static int _bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
+{
+	__be32 *targets = bond->params.arp_targets;
+	int ind;
+
+	if (!bond_is_ip_target_ok(target)) {
+		netdev_err(bond->dev, "invalid ARP target %pI4 specified for addition\n",
+			   &target);
+		return -EINVAL;
+	}
+
+	if (bond_get_targets_ip(targets, target) != -1) { /* dup */
+		netdev_err(bond->dev, "ARP target %pI4 is already present\n",
+			   &target);
+		return -EINVAL;
+	}
+
+	ind = bond_get_targets_ip(targets, 0); /* first free slot */
+	if (ind == -1) {
+		netdev_err(bond->dev, "ARP target table is full!\n");
+		return -EINVAL;
+	}
+
+	netdev_dbg(bond->dev, "Adding ARP target %pI4\n", &target);
+
+	_bond_options_arp_ip_target_set(bond, ind, target, jiffies);
+
+	return 0;
+}
+
+static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
+{
+	return _bond_option_arp_ip_target_add(bond, target);
+}
+
+static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target)
+{
+	__be32 *targets = bond->params.arp_targets;
+	struct list_head *iter;
+	struct slave *slave;
+	unsigned long *targets_rx;
+	int ind, i;
+
+	if (!bond_is_ip_target_ok(target)) {
+		netdev_err(bond->dev, "invalid ARP target %pI4 specified for removal\n",
+			   &target);
+		return -EINVAL;
+	}
+
+	ind = bond_get_targets_ip(targets, target);
+	if (ind == -1) {
+		netdev_err(bond->dev, "unable to remove nonexistent ARP target %pI4\n",
+			   &target);
+		return -EINVAL;
+	}
+
+	if (ind == 0 && !targets[1] && bond->params.arp_interval)
+		netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
+
+	netdev_dbg(bond->dev, "Removing ARP target %pI4\n", &target);
+
+	bond_for_each_slave(bond, slave, iter) {
+		targets_rx = slave->target_last_arp_rx;
+		for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
+			targets_rx[i] = targets_rx[i+1];
+		targets_rx[i] = 0;
+	}
+	for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
+		targets[i] = targets[i+1];
+	targets[i] = 0;
+
+	return 0;
+}
+
+void bond_option_arp_ip_targets_clear(struct bonding *bond)
+{
+	int i;
+
+	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
+		_bond_options_arp_ip_target_set(bond, i, 0, 0);
+}
+
+static int bond_option_arp_ip_targets_set(struct bonding *bond,
+					  const struct bond_opt_value *newval)
+{
+	int ret = -EPERM;
+	__be32 target;
+
+	if (newval->string) {
+		if (!in4_pton(newval->string+1, -1, (u8 *)&target, -1, NULL)) {
+			netdev_err(bond->dev, "invalid ARP target %pI4 specified\n",
+				   &target);
+			return ret;
+		}
+		if (newval->string[0] == '+')
+			ret = bond_option_arp_ip_target_add(bond, target);
+		else if (newval->string[0] == '-')
+			ret = bond_option_arp_ip_target_rem(bond, target);
+		else
+			netdev_err(bond->dev, "no command found in arp_ip_targets file - use +<addr> or -<addr>\n");
+	} else {
+		target = newval->value;
+		ret = bond_option_arp_ip_target_add(bond, target);
+	}
+
+	return ret;
+}
+
+static int bond_option_arp_validate_set(struct bonding *bond,
+					const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting arp_validate to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.arp_validate = newval->value;
+
+	return 0;
+}
+
+static int bond_option_arp_all_targets_set(struct bonding *bond,
+					   const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting arp_all_targets to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.arp_all_targets = newval->value;
+
+	return 0;
+}
+
+static int bond_option_primary_set(struct bonding *bond,
+				   const struct bond_opt_value *newval)
+{
+	char *p, *primary = newval->string;
+	struct list_head *iter;
+	struct slave *slave;
+
+	block_netpoll_tx();
+
+	p = strchr(primary, '\n');
+	if (p)
+		*p = '\0';
+	/* check to see if we are clearing primary */
+	if (!strlen(primary)) {
+		netdev_dbg(bond->dev, "Setting primary slave to None\n");
+		RCU_INIT_POINTER(bond->primary_slave, NULL);
+		memset(bond->params.primary, 0, sizeof(bond->params.primary));
+		bond_select_active_slave(bond);
+		goto out;
+	}
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (strncmp(slave->dev->name, primary, IFNAMSIZ) == 0) {
+			netdev_dbg(bond->dev, "Setting %s as primary slave\n",
+				   slave->dev->name);
+			rcu_assign_pointer(bond->primary_slave, slave);
+			strcpy(bond->params.primary, slave->dev->name);
+			bond->force_primary = true;
+			bond_select_active_slave(bond);
+			goto out;
+		}
+	}
+
+	if (rtnl_dereference(bond->primary_slave)) {
+		netdev_dbg(bond->dev, "Setting primary slave to None\n");
+		RCU_INIT_POINTER(bond->primary_slave, NULL);
+		bond_select_active_slave(bond);
+	}
+	strncpy(bond->params.primary, primary, IFNAMSIZ);
+	bond->params.primary[IFNAMSIZ - 1] = 0;
+
+	netdev_dbg(bond->dev, "Recording %s as primary, but it has not been enslaved to %s yet\n",
+		   primary, bond->dev->name);
+
+out:
+	unblock_netpoll_tx();
+
+	return 0;
+}
+
+static int bond_option_primary_reselect_set(struct bonding *bond,
+					    const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting primary_reselect to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.primary_reselect = newval->value;
+
+	block_netpoll_tx();
+	bond_select_active_slave(bond);
+	unblock_netpoll_tx();
+
+	return 0;
+}
+
+static int bond_option_fail_over_mac_set(struct bonding *bond,
+					 const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting fail_over_mac to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.fail_over_mac = newval->value;
+
+	return 0;
+}
+
+static int bond_option_xmit_hash_policy_set(struct bonding *bond,
+					    const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting xmit hash policy to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.xmit_policy = newval->value;
+
+	return 0;
+}
+
+static int bond_option_resend_igmp_set(struct bonding *bond,
+				       const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting resend_igmp to %llu\n",
+		   newval->value);
+	bond->params.resend_igmp = newval->value;
+
+	return 0;
+}
+
+static int bond_option_num_peer_notif_set(struct bonding *bond,
+				   const struct bond_opt_value *newval)
+{
+	bond->params.num_peer_notif = newval->value;
+
+	return 0;
+}
+
+static int bond_option_all_slaves_active_set(struct bonding *bond,
+					     const struct bond_opt_value *newval)
+{
+	struct list_head *iter;
+	struct slave *slave;
+
+	if (newval->value == bond->params.all_slaves_active)
+		return 0;
+	bond->params.all_slaves_active = newval->value;
+	bond_for_each_slave(bond, slave, iter) {
+		if (!bond_is_active_slave(slave)) {
+			if (newval->value)
+				slave->inactive = 0;
+			else
+				slave->inactive = 1;
+		}
+	}
+
+	return 0;
+}
+
+static int bond_option_min_links_set(struct bonding *bond,
+				     const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting min links value to %llu\n",
+		   newval->value);
+	bond->params.min_links = newval->value;
+	bond_set_carrier(bond);
+
+	return 0;
+}
+
+static int bond_option_lp_interval_set(struct bonding *bond,
+				       const struct bond_opt_value *newval)
+{
+	bond->params.lp_interval = newval->value;
+
+	return 0;
+}
+
+static int bond_option_pps_set(struct bonding *bond,
+			       const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting packets per slave to %llu\n",
+		   newval->value);
+	bond->params.packets_per_slave = newval->value;
+	if (newval->value > 0) {
+		bond->params.reciprocal_packets_per_slave =
+			reciprocal_value(newval->value);
+	} else {
+		/* reciprocal_packets_per_slave is unused if
+		 * packets_per_slave is 0 or 1, just initialize it
+		 */
+		bond->params.reciprocal_packets_per_slave =
+			(struct reciprocal_value) { 0 };
+	}
+
+	return 0;
+}
+
+static int bond_option_lacp_rate_set(struct bonding *bond,
+				     const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting LACP rate to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.lacp_fast = newval->value;
+	bond_3ad_update_lacp_rate(bond);
+
+	return 0;
+}
+
+static int bond_option_ad_select_set(struct bonding *bond,
+				     const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting ad_select to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.ad_select = newval->value;
+
+	return 0;
+}
+
+static int bond_option_queue_id_set(struct bonding *bond,
+				    const struct bond_opt_value *newval)
+{
+	struct slave *slave, *update_slave;
+	struct net_device *sdev;
+	struct list_head *iter;
+	char *delim;
+	int ret = 0;
+	u16 qid;
+
+	/* delim will point to queue id if successful */
+	delim = strchr(newval->string, ':');
+	if (!delim)
+		goto err_no_cmd;
+
+	/* Terminate string that points to device name and bump it
+	 * up one, so we can read the queue id there.
+	 */
+	*delim = '\0';
+	if (sscanf(++delim, "%hd\n", &qid) != 1)
+		goto err_no_cmd;
+
+	/* Check buffer length, valid ifname and queue id */
+	if (!dev_valid_name(newval->string) ||
+	    qid > bond->dev->real_num_tx_queues)
+		goto err_no_cmd;
+
+	/* Get the pointer to that interface if it exists */
+	sdev = __dev_get_by_name(dev_net(bond->dev), newval->string);
+	if (!sdev)
+		goto err_no_cmd;
+
+	/* Search for thes slave and check for duplicate qids */
+	update_slave = NULL;
+	bond_for_each_slave(bond, slave, iter) {
+		if (sdev == slave->dev)
+			/* We don't need to check the matching
+			 * slave for dups, since we're overwriting it
+			 */
+			update_slave = slave;
+		else if (qid && qid == slave->queue_id) {
+			goto err_no_cmd;
+		}
+	}
+
+	if (!update_slave)
+		goto err_no_cmd;
+
+	/* Actually set the qids for the slave */
+	update_slave->queue_id = qid;
+
+out:
+	return ret;
+
+err_no_cmd:
+	netdev_dbg(bond->dev, "invalid input for queue_id set\n");
+	ret = -EPERM;
+	goto out;
+
+}
+
+static int bond_option_slaves_set(struct bonding *bond,
+				  const struct bond_opt_value *newval)
+{
+	char command[IFNAMSIZ + 1] = { 0, };
+	struct net_device *dev;
+	char *ifname;
+	int ret;
+
+	sscanf(newval->string, "%16s", command); /* IFNAMSIZ*/
+	ifname = command + 1;
+	if ((strlen(command) <= 1) ||
+	    !dev_valid_name(ifname))
+		goto err_no_cmd;
+
+	dev = __dev_get_by_name(dev_net(bond->dev), ifname);
+	if (!dev) {
+		netdev_dbg(bond->dev, "interface %s does not exist!\n",
+			   ifname);
+		ret = -ENODEV;
+		goto out;
+	}
+
+	switch (command[0]) {
+	case '+':
+		netdev_dbg(bond->dev, "Adding slave %s\n", dev->name);
+		ret = bond_enslave(bond->dev, dev, NULL);
+		break;
+
+	case '-':
+		netdev_dbg(bond->dev, "Removing slave %s\n", dev->name);
+		ret = bond_release(bond->dev, dev);
+		break;
+
+	default:
+		goto err_no_cmd;
+	}
+
+out:
+	return ret;
+
+err_no_cmd:
+	netdev_err(bond->dev, "no command found in slaves file - use +ifname or -ifname\n");
+	ret = -EPERM;
+	goto out;
+}
+
+static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
+					  const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting dynamic-lb to %s (%llu)\n",
+		   newval->string, newval->value);
+	bond->params.tlb_dynamic_lb = newval->value;
+
+	return 0;
+}
+
+static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
+					     const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting ad_actor_sys_prio to %llu\n",
+		   newval->value);
+
+	bond->params.ad_actor_sys_prio = newval->value;
+	bond_3ad_update_ad_actor_settings(bond);
+
+	return 0;
+}
+
+static int bond_option_ad_actor_system_set(struct bonding *bond,
+					   const struct bond_opt_value *newval)
+{
+	u8 macaddr[ETH_ALEN];
+	u8 *mac;
+
+	if (newval->string) {
+		if (!mac_pton(newval->string, macaddr))
+			goto err;
+		mac = macaddr;
+	} else {
+		mac = (u8 *)&newval->value;
+	}
+
+	if (!is_valid_ether_addr(mac))
+		goto err;
+
+	netdev_dbg(bond->dev, "Setting ad_actor_system to %pM\n", mac);
+	ether_addr_copy(bond->params.ad_actor_system, mac);
+	bond_3ad_update_ad_actor_settings(bond);
+
+	return 0;
+
+err:
+	netdev_err(bond->dev, "Invalid MAC address.\n");
+	return -EINVAL;
+}
+
+static int bond_option_ad_user_port_key_set(struct bonding *bond,
+					    const struct bond_opt_value *newval)
+{
+	netdev_dbg(bond->dev, "Setting ad_user_port_key to %llu\n",
+		   newval->value);
+
+	bond->params.ad_user_port_key = newval->value;
+	return 0;
+}
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.164/bond_procfs.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.164/bond_procfs.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,310 @@
+// SPDX-License-Identifier: GPL-2.0
+#include <linux/proc_fs.h>
+#include <linux/export.h>
+#include <net/net_namespace.h>
+#include <net/netns/generic.h>
+#include <net/bonding.h>
+
+#include "bonding_priv.h"
+
+static void *bond_info_seq_start(struct seq_file *seq, loff_t *pos)
+	__acquires(RCU)
+{
+	struct bonding *bond = PDE_DATA(file_inode(seq->file));
+	struct list_head *iter;
+	struct slave *slave;
+	loff_t off = 0;
+
+	rcu_read_lock();
+
+	if (*pos == 0)
+		return SEQ_START_TOKEN;
+
+	bond_for_each_slave_rcu(bond, slave, iter)
+		if (++off == *pos)
+			return slave;
+
+	return NULL;
+}
+
+static void *bond_info_seq_next(struct seq_file *seq, void *v, loff_t *pos)
+{
+	struct bonding *bond = PDE_DATA(file_inode(seq->file));
+	struct list_head *iter;
+	struct slave *slave;
+	bool found = false;
+
+	++*pos;
+	if (v == SEQ_START_TOKEN)
+		return bond_first_slave_rcu(bond);
+
+	bond_for_each_slave_rcu(bond, slave, iter) {
+		if (found)
+			return slave;
+		if (slave == v)
+			found = true;
+	}
+
+	return NULL;
+}
+
+static void bond_info_seq_stop(struct seq_file *seq, void *v)
+	__releases(RCU)
+{
+	rcu_read_unlock();
+}
+
+static void bond_info_show_master(struct seq_file *seq)
+{
+	struct bonding *bond = PDE_DATA(file_inode(seq->file));
+	const struct bond_opt_value *optval;
+	struct slave *curr, *primary;
+	int i;
+
+	curr = rcu_dereference(bond->curr_active_slave);
+
+	seq_printf(seq, "Bonding Mode: %s",
+		   bond_mode_name(BOND_MODE(bond)));
+
+	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
+	    bond->params.fail_over_mac) {
+		optval = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
+					  bond->params.fail_over_mac);
+		seq_printf(seq, " (fail_over_mac %s)", optval->string);
+	}
+
+	seq_printf(seq, "\n");
+
+	if (bond_mode_uses_xmit_hash(bond)) {
+		optval = bond_opt_get_val(BOND_OPT_XMIT_HASH,
+					  bond->params.xmit_policy);
+		seq_printf(seq, "Transmit Hash Policy: %s (%d)\n",
+			   optval->string, bond->params.xmit_policy);
+	}
+
+	if (bond_uses_primary(bond)) {
+		primary = rcu_dereference(bond->primary_slave);
+		seq_printf(seq, "Primary Slave: %s",
+			   primary ? primary->dev->name : "None");
+		if (primary) {
+			optval = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
+						  bond->params.primary_reselect);
+			seq_printf(seq, " (primary_reselect %s)",
+				   optval->string);
+		}
+
+		seq_printf(seq, "\nCurrently Active Slave: %s\n",
+			   (curr) ? curr->dev->name : "None");
+	}
+
+	seq_printf(seq, "MII Status: %s\n", netif_carrier_ok(bond->dev) ?
+		   "up" : "down");
+	seq_printf(seq, "MII Polling Interval (ms): %d\n", bond->params.miimon);
+	seq_printf(seq, "Up Delay (ms): %d\n",
+		   bond->params.updelay * bond->params.miimon);
+	seq_printf(seq, "Down Delay (ms): %d\n",
+		   bond->params.downdelay * bond->params.miimon);
+
+
+	/* ARP information */
+	if (bond->params.arp_interval > 0) {
+		int printed = 0;
+		seq_printf(seq, "ARP Polling Interval (ms): %d\n",
+				bond->params.arp_interval);
+
+		seq_printf(seq, "ARP IP target/s (n.n.n.n form):");
+
+		for (i = 0; (i < BOND_MAX_ARP_TARGETS); i++) {
+			if (!bond->params.arp_targets[i])
+				break;
+			if (printed)
+				seq_printf(seq, ",");
+			seq_printf(seq, " %pI4", &bond->params.arp_targets[i]);
+			printed = 1;
+		}
+		seq_printf(seq, "\n");
+	}
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		struct ad_info ad_info;
+
+		seq_puts(seq, "\n802.3ad info\n");
+		seq_printf(seq, "LACP rate: %s\n",
+			   (bond->params.lacp_fast) ? "fast" : "slow");
+		seq_printf(seq, "Min links: %d\n", bond->params.min_links);
+		optval = bond_opt_get_val(BOND_OPT_AD_SELECT,
+					  bond->params.ad_select);
+		seq_printf(seq, "Aggregator selection policy (ad_select): %s\n",
+			   optval->string);
+		if (capable(CAP_NET_ADMIN)) {
+			seq_printf(seq, "System priority: %d\n",
+				   BOND_AD_INFO(bond).system.sys_priority);
+			seq_printf(seq, "System MAC address: %pM\n",
+				   &BOND_AD_INFO(bond).system.sys_mac_addr);
+
+			if (__bond_3ad_get_active_agg_info(bond, &ad_info)) {
+				seq_printf(seq,
+					   "bond %s has no active aggregator\n",
+					   bond->dev->name);
+			} else {
+				seq_printf(seq, "Active Aggregator Info:\n");
+
+				seq_printf(seq, "\tAggregator ID: %d\n",
+					   ad_info.aggregator_id);
+				seq_printf(seq, "\tNumber of ports: %d\n",
+					   ad_info.ports);
+				seq_printf(seq, "\tActor Key: %d\n",
+					   ad_info.actor_key);
+				seq_printf(seq, "\tPartner Key: %d\n",
+					   ad_info.partner_key);
+				seq_printf(seq, "\tPartner Mac Address: %pM\n",
+					   ad_info.partner_system);
+			}
+		}
+	}
+}
+
+static void bond_info_show_slave(struct seq_file *seq,
+				 const struct slave *slave)
+{
+	struct bonding *bond = PDE_DATA(file_inode(seq->file));
+
+	seq_printf(seq, "\nSlave Interface: %s\n", slave->dev->name);
+	seq_printf(seq, "MII Status: %s\n", bond_slave_link_status(slave->link));
+	if (slave->speed == SPEED_UNKNOWN)
+		seq_printf(seq, "Speed: %s\n", "Unknown");
+	else
+		seq_printf(seq, "Speed: %d Mbps\n", slave->speed);
+
+	if (slave->duplex == DUPLEX_UNKNOWN)
+		seq_printf(seq, "Duplex: %s\n", "Unknown");
+	else
+		seq_printf(seq, "Duplex: %s\n", slave->duplex ? "full" : "half");
+
+	seq_printf(seq, "Link Failure Count: %u\n",
+		   slave->link_failure_count);
+
+	seq_printf(seq, "Permanent HW addr: %*phC\n",
+		   slave->dev->addr_len, slave->perm_hwaddr);
+	seq_printf(seq, "Slave queue ID: %d\n", slave->queue_id);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		const struct port *port = &SLAVE_AD_INFO(slave)->port;
+		const struct aggregator *agg = port->aggregator;
+
+		if (agg) {
+			seq_printf(seq, "Aggregator ID: %d\n",
+				   agg->aggregator_identifier);
+			seq_printf(seq, "Actor Churn State: %s\n",
+				   bond_3ad_churn_desc(port->sm_churn_actor_state));
+			seq_printf(seq, "Partner Churn State: %s\n",
+				   bond_3ad_churn_desc(port->sm_churn_partner_state));
+			seq_printf(seq, "Actor Churned Count: %d\n",
+				   port->churn_actor_count);
+			seq_printf(seq, "Partner Churned Count: %d\n",
+				   port->churn_partner_count);
+
+			if (capable(CAP_NET_ADMIN)) {
+				seq_puts(seq, "details actor lacp pdu:\n");
+				seq_printf(seq, "    system priority: %d\n",
+					   port->actor_system_priority);
+				seq_printf(seq, "    system mac address: %pM\n",
+					   &port->actor_system);
+				seq_printf(seq, "    port key: %d\n",
+					   port->actor_oper_port_key);
+				seq_printf(seq, "    port priority: %d\n",
+					   port->actor_port_priority);
+				seq_printf(seq, "    port number: %d\n",
+					   port->actor_port_number);
+				seq_printf(seq, "    port state: %d\n",
+					   port->actor_oper_port_state);
+
+				seq_puts(seq, "details partner lacp pdu:\n");
+				seq_printf(seq, "    system priority: %d\n",
+					   port->partner_oper.system_priority);
+				seq_printf(seq, "    system mac address: %pM\n",
+					   &port->partner_oper.system);
+				seq_printf(seq, "    oper key: %d\n",
+					   port->partner_oper.key);
+				seq_printf(seq, "    port priority: %d\n",
+					   port->partner_oper.port_priority);
+				seq_printf(seq, "    port number: %d\n",
+					   port->partner_oper.port_number);
+				seq_printf(seq, "    port state: %d\n",
+					   port->partner_oper.port_state);
+			}
+		} else {
+			seq_puts(seq, "Aggregator ID: N/A\n");
+		}
+	}
+}
+
+static int bond_info_seq_show(struct seq_file *seq, void *v)
+{
+	if (v == SEQ_START_TOKEN) {
+		seq_printf(seq, "%s\n", bond_version);
+		bond_info_show_master(seq);
+	} else
+		bond_info_show_slave(seq, v);
+
+	return 0;
+}
+
+static const struct seq_operations bond_info_seq_ops = {
+	.start = bond_info_seq_start,
+	.next  = bond_info_seq_next,
+	.stop  = bond_info_seq_stop,
+	.show  = bond_info_seq_show,
+};
+
+void bond_create_proc_entry(struct bonding *bond)
+{
+	struct net_device *bond_dev = bond->dev;
+	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
+
+	if (bn->proc_dir) {
+		bond->proc_entry = proc_create_seq_data(bond_dev->name, 0444,
+				bn->proc_dir, &bond_info_seq_ops, bond);
+		if (bond->proc_entry == NULL)
+			netdev_warn(bond_dev, "Cannot create /proc/net/%s/%s\n",
+				    DRV_NAME, bond_dev->name);
+		else
+			memcpy(bond->proc_file_name, bond_dev->name, IFNAMSIZ);
+	}
+}
+
+void bond_remove_proc_entry(struct bonding *bond)
+{
+	struct net_device *bond_dev = bond->dev;
+	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
+
+	if (bn->proc_dir && bond->proc_entry) {
+		remove_proc_entry(bond->proc_file_name, bn->proc_dir);
+		memset(bond->proc_file_name, 0, IFNAMSIZ);
+		bond->proc_entry = NULL;
+	}
+}
+
+/* Create the bonding directory under /proc/net, if doesn't exist yet.
+ * Caller must hold rtnl_lock.
+ */
+void __net_init bond_create_proc_dir(struct bond_net *bn)
+{
+	if (!bn->proc_dir) {
+		bn->proc_dir = proc_mkdir(DRV_NAME, bn->net->proc_net);
+		if (!bn->proc_dir)
+			pr_warn("Warning: Cannot create /proc/net/%s\n",
+				DRV_NAME);
+	}
+}
+
+/* Destroy the bonding directory under /proc/net, if empty.
+ * Caller must hold rtnl_lock.
+ */
+void __net_exit bond_destroy_proc_dir(struct bond_net *bn)
+{
+	if (bn->proc_dir) {
+		remove_proc_entry(DRV_NAME, bn->net->proc_net);
+		bn->proc_dir = NULL;
+	}
+}
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.164/bond_sysfs.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.164/bond_sysfs.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,819 @@
+/*
+ * Copyright(c) 2004-2005 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, see <http://www.gnu.org/licenses/>.
+ *
+ * The full GNU General Public License is included in this distribution in the
+ * file called LICENSE.
+ *
+ */
+
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/sched/signal.h>
+#include <linux/fs.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/netdevice.h>
+#include <linux/inetdevice.h>
+#include <linux/in.h>
+#include <linux/sysfs.h>
+#include <linux/ctype.h>
+#include <linux/inet.h>
+#include <linux/rtnetlink.h>
+#include <linux/etherdevice.h>
+#include <net/net_namespace.h>
+#include <net/netns/generic.h>
+#include <linux/nsproxy.h>
+
+#include <net/bonding.h>
+
+#define to_bond(cd)	((struct bonding *)(netdev_priv(to_net_dev(cd))))
+
+/* "show" function for the bond_masters attribute.
+ * The class parameter is ignored.
+ */
+static ssize_t bonding_show_bonds(struct class *cls,
+				  struct class_attribute *attr,
+				  char *buf)
+{
+	struct bond_net *bn =
+		container_of(attr, struct bond_net, class_attr_bonding_masters);
+	int res = 0;
+	struct bonding *bond;
+
+	rtnl_lock();
+
+	list_for_each_entry(bond, &bn->dev_list, bond_list) {
+		if (res > (PAGE_SIZE - IFNAMSIZ)) {
+			/* not enough space for another interface name */
+			if ((PAGE_SIZE - res) > 10)
+				res = PAGE_SIZE - 10;
+			res += sprintf(buf + res, "++more++ ");
+			break;
+		}
+		res += sprintf(buf + res, "%s ", bond->dev->name);
+	}
+	if (res)
+		buf[res-1] = '\n'; /* eat the leftover space */
+
+	rtnl_unlock();
+	return res;
+}
+
+static struct net_device *bond_get_by_name(struct bond_net *bn, const char *ifname)
+{
+	struct bonding *bond;
+
+	list_for_each_entry(bond, &bn->dev_list, bond_list) {
+		if (strncmp(bond->dev->name, ifname, IFNAMSIZ) == 0)
+			return bond->dev;
+	}
+	return NULL;
+}
+
+/* "store" function for the bond_masters attribute.  This is what
+ * creates and deletes entire bonds.
+ *
+ * The class parameter is ignored.
+ */
+static ssize_t bonding_store_bonds(struct class *cls,
+				   struct class_attribute *attr,
+				   const char *buffer, size_t count)
+{
+	struct bond_net *bn =
+		container_of(attr, struct bond_net, class_attr_bonding_masters);
+	char command[IFNAMSIZ + 1] = {0, };
+	char *ifname;
+	int rv, res = count;
+
+	sscanf(buffer, "%16s", command); /* IFNAMSIZ*/
+	ifname = command + 1;
+	if ((strlen(command) <= 1) ||
+	    !dev_valid_name(ifname))
+		goto err_no_cmd;
+
+	if (command[0] == '+') {
+		pr_info("%s is being created...\n", ifname);
+		rv = bond_create(bn->net, ifname);
+		if (rv) {
+			if (rv == -EEXIST)
+				pr_info("%s already exists\n", ifname);
+			else
+				pr_info("%s creation failed\n", ifname);
+			res = rv;
+		}
+	} else if (command[0] == '-') {
+		struct net_device *bond_dev;
+
+		rtnl_lock();
+		bond_dev = bond_get_by_name(bn, ifname);
+		if (bond_dev) {
+			pr_info("%s is being deleted...\n", ifname);
+			unregister_netdevice(bond_dev);
+		} else {
+			pr_err("unable to delete non-existent %s\n", ifname);
+			res = -ENODEV;
+		}
+		rtnl_unlock();
+	} else
+		goto err_no_cmd;
+
+	/* Always return either count or an error.  If you return 0, you'll
+	 * get called forever, which is bad.
+	 */
+	return res;
+
+err_no_cmd:
+	pr_err("no command found in bonding_masters - use +ifname or -ifname\n");
+	return -EPERM;
+}
+
+/* class attribute for bond_masters file.  This ends up in /sys/class/net */
+static const struct class_attribute class_attr_bonding_masters = {
+	.attr = {
+		.name = "bonding_masters",
+		.mode = 0644,
+	},
+	.show = bonding_show_bonds,
+	.store = bonding_store_bonds,
+};
+
+/* Generic "store" method for bonding sysfs option setting */
+static ssize_t bonding_sysfs_store_option(struct device *d,
+					  struct device_attribute *attr,
+					  const char *buffer, size_t count)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_option *opt;
+	char *buffer_clone;
+	int ret;
+
+	opt = bond_opt_get_by_name(attr->attr.name);
+	if (WARN_ON(!opt))
+		return -ENOENT;
+	buffer_clone = kstrndup(buffer, count, GFP_KERNEL);
+	if (!buffer_clone)
+		return -ENOMEM;
+	ret = bond_opt_tryset_rtnl(bond, opt->id, buffer_clone);
+	if (!ret)
+		ret = count;
+	kfree(buffer_clone);
+
+	return ret;
+}
+
+/* Show the slaves in the current bond. */
+static ssize_t bonding_show_slaves(struct device *d,
+				   struct device_attribute *attr, char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	struct list_head *iter;
+	struct slave *slave;
+	int res = 0;
+
+	if (!rtnl_trylock())
+		return restart_syscall();
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (res > (PAGE_SIZE - IFNAMSIZ)) {
+			/* not enough space for another interface name */
+			if ((PAGE_SIZE - res) > 10)
+				res = PAGE_SIZE - 10;
+			res += sprintf(buf + res, "++more++ ");
+			break;
+		}
+		res += sprintf(buf + res, "%s ", slave->dev->name);
+	}
+
+	rtnl_unlock();
+
+	if (res)
+		buf[res-1] = '\n'; /* eat the leftover space */
+
+	return res;
+}
+static DEVICE_ATTR(slaves, 0644, bonding_show_slaves,
+		   bonding_sysfs_store_option);
+
+/* Show the bonding mode. */
+static ssize_t bonding_show_mode(struct device *d,
+				 struct device_attribute *attr, char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_MODE, BOND_MODE(bond));
+
+	return sprintf(buf, "%s %d\n", val->string, BOND_MODE(bond));
+}
+static DEVICE_ATTR(mode, 0644, bonding_show_mode, bonding_sysfs_store_option);
+
+/* Show the bonding transmit hash method. */
+static ssize_t bonding_show_xmit_hash(struct device *d,
+				      struct device_attribute *attr,
+				      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_XMIT_HASH, bond->params.xmit_policy);
+
+	return sprintf(buf, "%s %d\n", val->string, bond->params.xmit_policy);
+}
+static DEVICE_ATTR(xmit_hash_policy, 0644,
+		   bonding_show_xmit_hash, bonding_sysfs_store_option);
+
+/* Show arp_validate. */
+static ssize_t bonding_show_arp_validate(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
+			       bond->params.arp_validate);
+
+	return sprintf(buf, "%s %d\n", val->string, bond->params.arp_validate);
+}
+static DEVICE_ATTR(arp_validate, 0644, bonding_show_arp_validate,
+		   bonding_sysfs_store_option);
+
+/* Show arp_all_targets. */
+static ssize_t bonding_show_arp_all_targets(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_ARP_ALL_TARGETS,
+			       bond->params.arp_all_targets);
+	return sprintf(buf, "%s %d\n",
+		       val->string, bond->params.arp_all_targets);
+}
+static DEVICE_ATTR(arp_all_targets, 0644,
+		   bonding_show_arp_all_targets, bonding_sysfs_store_option);
+
+/* Show fail_over_mac. */
+static ssize_t bonding_show_fail_over_mac(struct device *d,
+					  struct device_attribute *attr,
+					  char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
+			       bond->params.fail_over_mac);
+
+	return sprintf(buf, "%s %d\n", val->string, bond->params.fail_over_mac);
+}
+static DEVICE_ATTR(fail_over_mac, 0644,
+		   bonding_show_fail_over_mac, bonding_sysfs_store_option);
+
+/* Show the arp timer interval. */
+static ssize_t bonding_show_arp_interval(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.arp_interval);
+}
+static DEVICE_ATTR(arp_interval, 0644,
+		   bonding_show_arp_interval, bonding_sysfs_store_option);
+
+/* Show the arp targets. */
+static ssize_t bonding_show_arp_targets(struct device *d,
+					struct device_attribute *attr,
+					char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	int i, res = 0;
+
+	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
+		if (bond->params.arp_targets[i])
+			res += sprintf(buf + res, "%pI4 ",
+				       &bond->params.arp_targets[i]);
+	}
+	if (res)
+		buf[res-1] = '\n'; /* eat the leftover space */
+
+	return res;
+}
+static DEVICE_ATTR(arp_ip_target, 0644,
+		   bonding_show_arp_targets, bonding_sysfs_store_option);
+
+/* Show the up and down delays. */
+static ssize_t bonding_show_downdelay(struct device *d,
+				      struct device_attribute *attr,
+				      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.downdelay * bond->params.miimon);
+}
+static DEVICE_ATTR(downdelay, 0644,
+		   bonding_show_downdelay, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_updelay(struct device *d,
+				    struct device_attribute *attr,
+				    char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.updelay * bond->params.miimon);
+
+}
+static DEVICE_ATTR(updelay, 0644,
+		   bonding_show_updelay, bonding_sysfs_store_option);
+
+/* Show the LACP interval. */
+static ssize_t bonding_show_lacp(struct device *d,
+				 struct device_attribute *attr,
+				 char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_LACP_RATE, bond->params.lacp_fast);
+
+	return sprintf(buf, "%s %d\n", val->string, bond->params.lacp_fast);
+}
+static DEVICE_ATTR(lacp_rate, 0644,
+		   bonding_show_lacp, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_min_links(struct device *d,
+				      struct device_attribute *attr,
+				      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%u\n", bond->params.min_links);
+}
+static DEVICE_ATTR(min_links, 0644,
+		   bonding_show_min_links, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_ad_select(struct device *d,
+				      struct device_attribute *attr,
+				      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_AD_SELECT, bond->params.ad_select);
+
+	return sprintf(buf, "%s %d\n", val->string, bond->params.ad_select);
+}
+static DEVICE_ATTR(ad_select, 0644,
+		   bonding_show_ad_select, bonding_sysfs_store_option);
+
+/* Show the number of peer notifications to send after a failover event. */
+static ssize_t bonding_show_num_peer_notif(struct device *d,
+					   struct device_attribute *attr,
+					   char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	return sprintf(buf, "%d\n", bond->params.num_peer_notif);
+}
+static DEVICE_ATTR(num_grat_arp, 0644,
+		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
+static DEVICE_ATTR(num_unsol_na, 0644,
+		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
+
+/* Show the MII monitor interval. */
+static ssize_t bonding_show_miimon(struct device *d,
+				   struct device_attribute *attr,
+				   char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.miimon);
+}
+static DEVICE_ATTR(miimon, 0644,
+		   bonding_show_miimon, bonding_sysfs_store_option);
+
+/* Show the primary slave. */
+static ssize_t bonding_show_primary(struct device *d,
+				    struct device_attribute *attr,
+				    char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	struct slave *primary;
+	int count = 0;
+
+	rcu_read_lock();
+	primary = rcu_dereference(bond->primary_slave);
+	if (primary)
+		count = sprintf(buf, "%s\n", primary->dev->name);
+	rcu_read_unlock();
+
+	return count;
+}
+static DEVICE_ATTR(primary, 0644,
+		   bonding_show_primary, bonding_sysfs_store_option);
+
+/* Show the primary_reselect flag. */
+static ssize_t bonding_show_primary_reselect(struct device *d,
+					     struct device_attribute *attr,
+					     char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	const struct bond_opt_value *val;
+
+	val = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
+			       bond->params.primary_reselect);
+
+	return sprintf(buf, "%s %d\n",
+		       val->string, bond->params.primary_reselect);
+}
+static DEVICE_ATTR(primary_reselect, 0644,
+		   bonding_show_primary_reselect, bonding_sysfs_store_option);
+
+/* Show the use_carrier flag. */
+static ssize_t bonding_show_carrier(struct device *d,
+				    struct device_attribute *attr,
+				    char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.use_carrier);
+}
+static DEVICE_ATTR(use_carrier, 0644,
+		   bonding_show_carrier, bonding_sysfs_store_option);
+
+
+/* Show currently active_slave. */
+static ssize_t bonding_show_active_slave(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	struct net_device *slave_dev;
+	int count = 0;
+
+	rcu_read_lock();
+	slave_dev = bond_option_active_slave_get_rcu(bond);
+	if (slave_dev)
+		count = sprintf(buf, "%s\n", slave_dev->name);
+	rcu_read_unlock();
+
+	return count;
+}
+static DEVICE_ATTR(active_slave, 0644,
+		   bonding_show_active_slave, bonding_sysfs_store_option);
+
+/* Show link status of the bond interface. */
+static ssize_t bonding_show_mii_status(struct device *d,
+				       struct device_attribute *attr,
+				       char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	bool active = netif_carrier_ok(bond->dev);
+
+	return sprintf(buf, "%s\n", active ? "up" : "down");
+}
+static DEVICE_ATTR(mii_status, 0444, bonding_show_mii_status, NULL);
+
+/* Show current 802.3ad aggregator ID. */
+static ssize_t bonding_show_ad_aggregator(struct device *d,
+					  struct device_attribute *attr,
+					  char *buf)
+{
+	int count = 0;
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		struct ad_info ad_info;
+		count = sprintf(buf, "%d\n",
+				bond_3ad_get_active_agg_info(bond, &ad_info)
+				?  0 : ad_info.aggregator_id);
+	}
+
+	return count;
+}
+static DEVICE_ATTR(ad_aggregator, 0444, bonding_show_ad_aggregator, NULL);
+
+
+/* Show number of active 802.3ad ports. */
+static ssize_t bonding_show_ad_num_ports(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	int count = 0;
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
+		struct ad_info ad_info;
+		count = sprintf(buf, "%d\n",
+				bond_3ad_get_active_agg_info(bond, &ad_info)
+				?  0 : ad_info.ports);
+	}
+
+	return count;
+}
+static DEVICE_ATTR(ad_num_ports, 0444, bonding_show_ad_num_ports, NULL);
+
+
+/* Show current 802.3ad actor key. */
+static ssize_t bonding_show_ad_actor_key(struct device *d,
+					 struct device_attribute *attr,
+					 char *buf)
+{
+	int count = 0;
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
+		struct ad_info ad_info;
+		count = sprintf(buf, "%d\n",
+				bond_3ad_get_active_agg_info(bond, &ad_info)
+				?  0 : ad_info.actor_key);
+	}
+
+	return count;
+}
+static DEVICE_ATTR(ad_actor_key, 0444, bonding_show_ad_actor_key, NULL);
+
+
+/* Show current 802.3ad partner key. */
+static ssize_t bonding_show_ad_partner_key(struct device *d,
+					   struct device_attribute *attr,
+					   char *buf)
+{
+	int count = 0;
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
+		struct ad_info ad_info;
+		count = sprintf(buf, "%d\n",
+				bond_3ad_get_active_agg_info(bond, &ad_info)
+				?  0 : ad_info.partner_key);
+	}
+
+	return count;
+}
+static DEVICE_ATTR(ad_partner_key, 0444, bonding_show_ad_partner_key, NULL);
+
+
+/* Show current 802.3ad partner mac. */
+static ssize_t bonding_show_ad_partner_mac(struct device *d,
+					   struct device_attribute *attr,
+					   char *buf)
+{
+	int count = 0;
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
+		struct ad_info ad_info;
+		if (!bond_3ad_get_active_agg_info(bond, &ad_info))
+			count = sprintf(buf, "%pM\n", ad_info.partner_system);
+	}
+
+	return count;
+}
+static DEVICE_ATTR(ad_partner_mac, 0444, bonding_show_ad_partner_mac, NULL);
+
+/* Show the queue_ids of the slaves in the current bond. */
+static ssize_t bonding_show_queue_id(struct device *d,
+				     struct device_attribute *attr,
+				     char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	struct list_head *iter;
+	struct slave *slave;
+	int res = 0;
+
+	if (!rtnl_trylock())
+		return restart_syscall();
+
+	bond_for_each_slave(bond, slave, iter) {
+		if (res > (PAGE_SIZE - IFNAMSIZ - 6)) {
+			/* not enough space for another interface_name:queue_id pair */
+			if ((PAGE_SIZE - res) > 10)
+				res = PAGE_SIZE - 10;
+			res += sprintf(buf + res, "++more++ ");
+			break;
+		}
+		res += sprintf(buf + res, "%s:%d ",
+			       slave->dev->name, slave->queue_id);
+	}
+	if (res)
+		buf[res-1] = '\n'; /* eat the leftover space */
+
+	rtnl_unlock();
+
+	return res;
+}
+static DEVICE_ATTR(queue_id, 0644, bonding_show_queue_id,
+		   bonding_sysfs_store_option);
+
+
+/* Show the all_slaves_active flag. */
+static ssize_t bonding_show_slaves_active(struct device *d,
+					  struct device_attribute *attr,
+					  char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.all_slaves_active);
+}
+static DEVICE_ATTR(all_slaves_active, 0644,
+		   bonding_show_slaves_active, bonding_sysfs_store_option);
+
+/* Show the number of IGMP membership reports to send on link failure */
+static ssize_t bonding_show_resend_igmp(struct device *d,
+					struct device_attribute *attr,
+					char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.resend_igmp);
+}
+static DEVICE_ATTR(resend_igmp, 0644,
+		   bonding_show_resend_igmp, bonding_sysfs_store_option);
+
+
+static ssize_t bonding_show_lp_interval(struct device *d,
+					struct device_attribute *attr,
+					char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	return sprintf(buf, "%d\n", bond->params.lp_interval);
+}
+static DEVICE_ATTR(lp_interval, 0644,
+		   bonding_show_lp_interval, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_tlb_dynamic_lb(struct device *d,
+					   struct device_attribute *attr,
+					   char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	return sprintf(buf, "%d\n", bond->params.tlb_dynamic_lb);
+}
+static DEVICE_ATTR(tlb_dynamic_lb, 0644,
+		   bonding_show_tlb_dynamic_lb, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_packets_per_slave(struct device *d,
+					      struct device_attribute *attr,
+					      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+	unsigned int packets_per_slave = bond->params.packets_per_slave;
+
+	return sprintf(buf, "%u\n", packets_per_slave);
+}
+static DEVICE_ATTR(packets_per_slave, 0644,
+		   bonding_show_packets_per_slave, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_ad_actor_sys_prio(struct device *d,
+					      struct device_attribute *attr,
+					      char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
+		return sprintf(buf, "%hu\n", bond->params.ad_actor_sys_prio);
+
+	return 0;
+}
+static DEVICE_ATTR(ad_actor_sys_prio, 0644,
+		   bonding_show_ad_actor_sys_prio, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_ad_actor_system(struct device *d,
+					    struct device_attribute *attr,
+					    char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
+		return sprintf(buf, "%pM\n", bond->params.ad_actor_system);
+
+	return 0;
+}
+
+static DEVICE_ATTR(ad_actor_system, 0644,
+		   bonding_show_ad_actor_system, bonding_sysfs_store_option);
+
+static ssize_t bonding_show_ad_user_port_key(struct device *d,
+					     struct device_attribute *attr,
+					     char *buf)
+{
+	struct bonding *bond = to_bond(d);
+
+	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
+		return sprintf(buf, "%hu\n", bond->params.ad_user_port_key);
+
+	return 0;
+}
+static DEVICE_ATTR(ad_user_port_key, 0644,
+		   bonding_show_ad_user_port_key, bonding_sysfs_store_option);
+
+static struct attribute *per_bond_attrs[] = {
+	&dev_attr_slaves.attr,
+	&dev_attr_mode.attr,
+	&dev_attr_fail_over_mac.attr,
+	&dev_attr_arp_validate.attr,
+	&dev_attr_arp_all_targets.attr,
+	&dev_attr_arp_interval.attr,
+	&dev_attr_arp_ip_target.attr,
+	&dev_attr_downdelay.attr,
+	&dev_attr_updelay.attr,
+	&dev_attr_lacp_rate.attr,
+	&dev_attr_ad_select.attr,
+	&dev_attr_xmit_hash_policy.attr,
+	&dev_attr_num_grat_arp.attr,
+	&dev_attr_num_unsol_na.attr,
+	&dev_attr_miimon.attr,
+	&dev_attr_primary.attr,
+	&dev_attr_primary_reselect.attr,
+	&dev_attr_use_carrier.attr,
+	&dev_attr_active_slave.attr,
+	&dev_attr_mii_status.attr,
+	&dev_attr_ad_aggregator.attr,
+	&dev_attr_ad_num_ports.attr,
+	&dev_attr_ad_actor_key.attr,
+	&dev_attr_ad_partner_key.attr,
+	&dev_attr_ad_partner_mac.attr,
+	&dev_attr_queue_id.attr,
+	&dev_attr_all_slaves_active.attr,
+	&dev_attr_resend_igmp.attr,
+	&dev_attr_min_links.attr,
+	&dev_attr_lp_interval.attr,
+	&dev_attr_packets_per_slave.attr,
+	&dev_attr_tlb_dynamic_lb.attr,
+	&dev_attr_ad_actor_sys_prio.attr,
+	&dev_attr_ad_actor_system.attr,
+	&dev_attr_ad_user_port_key.attr,
+	NULL,
+};
+
+static const struct attribute_group bonding_group = {
+	.name = "bonding",
+	.attrs = per_bond_attrs,
+};
+
+/* Initialize sysfs.  This sets up the bonding_masters file in
+ * /sys/class/net.
+ */
+int bond_create_sysfs(struct bond_net *bn)
+{
+	int ret;
+
+	bn->class_attr_bonding_masters = class_attr_bonding_masters;
+	sysfs_attr_init(&bn->class_attr_bonding_masters.attr);
+
+	ret = netdev_class_create_file_ns(&bn->class_attr_bonding_masters,
+					  bn->net);
+	/* Permit multiple loads of the module by ignoring failures to
+	 * create the bonding_masters sysfs file.  Bonding devices
+	 * created by second or subsequent loads of the module will
+	 * not be listed in, or controllable by, bonding_masters, but
+	 * will have the usual "bonding" sysfs directory.
+	 *
+	 * This is done to preserve backwards compatibility for
+	 * initscripts/sysconfig, which load bonding multiple times to
+	 * configure multiple bonding devices.
+	 */
+	if (ret == -EEXIST) {
+		/* Is someone being kinky and naming a device bonding_master? */
+		if (__dev_get_by_name(bn->net,
+				      class_attr_bonding_masters.attr.name))
+			pr_err("network device named %s already exists in sysfs\n",
+			       class_attr_bonding_masters.attr.name);
+		ret = 0;
+	}
+
+	return ret;
+
+}
+
+/* Remove /sys/class/net/bonding_masters. */
+void bond_destroy_sysfs(struct bond_net *bn)
+{
+	netdev_class_remove_file_ns(&bn->class_attr_bonding_masters, bn->net);
+}
+
+/* Initialize sysfs for each bond.  This sets up and registers
+ * the 'bondctl' directory for each individual bond under /sys/class/net.
+ */
+void bond_prepare_sysfs_group(struct bonding *bond)
+{
+	bond->dev->sysfs_groups[0] = &bonding_group;
+}
+
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.164/bond_sysfs_slave.c
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.164/bond_sysfs_slave.c	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,164 @@
+/*	Sysfs attributes of bond slaves
+ *
+ *      Copyright (c) 2014 Scott Feldman <sfeldma@cumulusnetworks.com>
+ *
+ *	This program is free software; you can redistribute it and/or
+ *	modify it under the terms of the GNU General Public License
+ *	as published by the Free Software Foundation; either version
+ *	2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+
+#include <net/bonding.h>
+
+struct slave_attribute {
+	struct attribute attr;
+	ssize_t (*show)(struct slave *, char *);
+};
+
+#define SLAVE_ATTR(_name, _mode, _show)				\
+const struct slave_attribute slave_attr_##_name = {		\
+	.attr = {.name = __stringify(_name),			\
+		 .mode = _mode },				\
+	.show	= _show,					\
+};
+#define SLAVE_ATTR_RO(_name)					\
+	SLAVE_ATTR(_name, 0444, _name##_show)
+
+static ssize_t state_show(struct slave *slave, char *buf)
+{
+	switch (bond_slave_state(slave)) {
+	case BOND_STATE_ACTIVE:
+		return sprintf(buf, "active\n");
+	case BOND_STATE_BACKUP:
+		return sprintf(buf, "backup\n");
+	default:
+		return sprintf(buf, "UNKNOWN\n");
+	}
+}
+static SLAVE_ATTR_RO(state);
+
+static ssize_t mii_status_show(struct slave *slave, char *buf)
+{
+	return sprintf(buf, "%s\n", bond_slave_link_status(slave->link));
+}
+static SLAVE_ATTR_RO(mii_status);
+
+static ssize_t link_failure_count_show(struct slave *slave, char *buf)
+{
+	return sprintf(buf, "%d\n", slave->link_failure_count);
+}
+static SLAVE_ATTR_RO(link_failure_count);
+
+static ssize_t perm_hwaddr_show(struct slave *slave, char *buf)
+{
+	return sprintf(buf, "%*phC\n",
+		       slave->dev->addr_len,
+		       slave->perm_hwaddr);
+}
+static SLAVE_ATTR_RO(perm_hwaddr);
+
+static ssize_t queue_id_show(struct slave *slave, char *buf)
+{
+	return sprintf(buf, "%d\n", slave->queue_id);
+}
+static SLAVE_ATTR_RO(queue_id);
+
+static ssize_t ad_aggregator_id_show(struct slave *slave, char *buf)
+{
+	const struct aggregator *agg;
+
+	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
+		agg = SLAVE_AD_INFO(slave)->port.aggregator;
+		if (agg)
+			return sprintf(buf, "%d\n",
+				       agg->aggregator_identifier);
+	}
+
+	return sprintf(buf, "N/A\n");
+}
+static SLAVE_ATTR_RO(ad_aggregator_id);
+
+static ssize_t ad_actor_oper_port_state_show(struct slave *slave, char *buf)
+{
+	const struct port *ad_port;
+
+	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
+		ad_port = &SLAVE_AD_INFO(slave)->port;
+		if (ad_port->aggregator)
+			return sprintf(buf, "%u\n",
+				       ad_port->actor_oper_port_state);
+	}
+
+	return sprintf(buf, "N/A\n");
+}
+static SLAVE_ATTR_RO(ad_actor_oper_port_state);
+
+static ssize_t ad_partner_oper_port_state_show(struct slave *slave, char *buf)
+{
+	const struct port *ad_port;
+
+	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
+		ad_port = &SLAVE_AD_INFO(slave)->port;
+		if (ad_port->aggregator)
+			return sprintf(buf, "%u\n",
+				       ad_port->partner_oper.port_state);
+	}
+
+	return sprintf(buf, "N/A\n");
+}
+static SLAVE_ATTR_RO(ad_partner_oper_port_state);
+
+static const struct slave_attribute *slave_attrs[] = {
+	&slave_attr_state,
+	&slave_attr_mii_status,
+	&slave_attr_link_failure_count,
+	&slave_attr_perm_hwaddr,
+	&slave_attr_queue_id,
+	&slave_attr_ad_aggregator_id,
+	&slave_attr_ad_actor_oper_port_state,
+	&slave_attr_ad_partner_oper_port_state,
+	NULL
+};
+
+#define to_slave_attr(_at) container_of(_at, struct slave_attribute, attr)
+
+static ssize_t slave_show(struct kobject *kobj,
+			  struct attribute *attr, char *buf)
+{
+	struct slave_attribute *slave_attr = to_slave_attr(attr);
+	struct slave *slave = to_slave(kobj);
+
+	return slave_attr->show(slave, buf);
+}
+
+const struct sysfs_ops slave_sysfs_ops = {
+	.show = slave_show,
+};
+
+int bond_sysfs_slave_add(struct slave *slave)
+{
+	const struct slave_attribute **a;
+	int err;
+
+	for (a = slave_attrs; *a; ++a) {
+		err = sysfs_create_file(&slave->kobj, &((*a)->attr));
+		if (err) {
+			kobject_put(&slave->kobj);
+			return err;
+		}
+	}
+
+	return 0;
+}
+
+void bond_sysfs_slave_del(struct slave *slave)
+{
+	const struct slave_attribute **a;
+
+	for (a = slave_attrs; *a; ++a)
+		sysfs_remove_file(&slave->kobj, &((*a)->attr));
+}
diff -r 30 src/network/bonding/BONDING_KDIRS/4.19.164/bonding_priv.h
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/src/network/bonding/BONDING_KDIRS/4.19.164/bonding_priv.h	Tue May 18 15:02:47 2021 +0530
@@ -0,0 +1,25 @@
+/*
+ * Bond several ethernet interfaces into a Cisco, running 'Etherchannel'.
+ *
+ * Portions are (c) Copyright 1995 Simon "Guru Aleph-Null" Janes
+ * NCM: Network and Communications Management, Inc.
+ *
+ * BUT, I'm the one who modified it for ethernet, so:
+ * (c) Copyright 1999, Thomas Davis, tadavis@lbl.gov
+ *
+ *	This software may be used and distributed according to the terms
+ *	of the GNU Public License, incorporated herein by reference.
+ *
+ */
+
+#ifndef _BONDING_PRIV_H
+#define _BONDING_PRIV_H
+
+#define DRV_VERSION	"3.7.1-chelsio"
+#define DRV_RELDATE	"April 27, 2011"
+#define DRV_NAME	"bonding"
+#define DRV_DESCRIPTION	"Ethernet Channel Bonding Driver with Offload"
+
+#define bond_version DRV_DESCRIPTION ": v" DRV_VERSION " (" DRV_RELDATE ")\n"
+
+#endif
diff -r 30 src/network/bonding/BONDING_KDIRS/4.2.0/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/4.2.0/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/bonding/BONDING_KDIRS/4.2.0/bond_main.c	Tue May 18 15:02:47 2021 +0530
@@ -1810,6 +1810,8 @@
 		return -EINVAL;
 	}
 
+	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
+
 	bond_sysfs_slave_del(slave);
 
 	/* recompute stats just before removing the slave */
@@ -1821,8 +1823,6 @@
 	 */
 	netdev_rx_handler_unregister(slave_dev);
 
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
 	if (BOND_MODE(bond) == BOND_MODE_8023AD)
 		bond_3ad_unbind_slave(slave);
 
diff -r 30 src/network/bonding/BONDING_KDIRS/4.8.0/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/4.8.0/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/bonding/BONDING_KDIRS/4.8.0/bond_main.c	Tue May 18 15:02:47 2021 +0530
@@ -1849,6 +1849,8 @@
 		return -EINVAL;
 	}
 
+	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
+
 	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
 
 	bond_sysfs_slave_del(slave);
@@ -1862,8 +1864,6 @@
 	 */
 	netdev_rx_handler_unregister(slave_dev);
 
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
 	if (BOND_MODE(bond) == BOND_MODE_8023AD)
 		bond_3ad_unbind_slave(slave);
 
diff -r 30 src/network/bonding/BONDING_KDIRS/4.9.0/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/4.9.0/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/bonding/BONDING_KDIRS/4.9.0/bond_main.c	Tue May 18 15:02:47 2021 +0530
@@ -1850,6 +1850,8 @@
 		return -EINVAL;
 	}
 
+	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
+
 	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
 
 	bond_sysfs_slave_del(slave);
@@ -1863,8 +1865,6 @@
 	 */
 	netdev_rx_handler_unregister(slave_dev);
 
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
 	if (BOND_MODE(bond) == BOND_MODE_8023AD)
 		bond_3ad_unbind_slave(slave);
 
diff -r 30 src/network/bonding/BONDING_KDIRS/5.10.0/bond_3ad.c
--- a/src/network/bonding/BONDING_KDIRS/5.10.0/bond_3ad.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,2758 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
- */
-
-#include <linux/skbuff.h>
-#include <linux/if_ether.h>
-#include <linux/netdevice.h>
-#include <linux/spinlock.h>
-#include <linux/ethtool.h>
-#include <linux/etherdevice.h>
-#include <linux/if_bonding.h>
-#include <linux/pkt_sched.h>
-#include <linux/toedev.h>
-#include <net/net_namespace.h>
-#include <net/bonding.h>
-#include <net/bond_3ad.h>
-#include <net/netlink.h>
-
-/* General definitions */
-#define AD_SHORT_TIMEOUT           1
-#define AD_LONG_TIMEOUT            0
-#define AD_STANDBY                 0x2
-#define AD_MAX_TX_IN_SECOND        3
-#define AD_COLLECTOR_MAX_DELAY     0
-
-/* Timer definitions (43.4.4 in the 802.3ad standard) */
-#define AD_FAST_PERIODIC_TIME      1
-#define AD_SLOW_PERIODIC_TIME      30
-#define AD_SHORT_TIMEOUT_TIME      (3*AD_FAST_PERIODIC_TIME)
-#define AD_LONG_TIMEOUT_TIME       (3*AD_SLOW_PERIODIC_TIME)
-#define AD_CHURN_DETECTION_TIME    60
-#define AD_AGGREGATE_WAIT_TIME     2
-
-/* Port Variables definitions used by the State Machines (43.4.7 in the
- * 802.3ad standard)
- */
-#define AD_PORT_BEGIN           0x1
-#define AD_PORT_LACP_ENABLED    0x2
-#define AD_PORT_ACTOR_CHURN     0x4
-#define AD_PORT_PARTNER_CHURN   0x8
-#define AD_PORT_READY           0x10
-#define AD_PORT_READY_N         0x20
-#define AD_PORT_MATCHED         0x40
-#define AD_PORT_STANDBY         0x80
-#define AD_PORT_SELECTED        0x100
-#define AD_PORT_MOVED           0x200
-#define AD_PORT_CHURNED         (AD_PORT_ACTOR_CHURN | AD_PORT_PARTNER_CHURN)
-
-/* Port Key definitions
- * key is determined according to the link speed, duplex and
- * user key (which is yet not supported)
- *           --------------------------------------------------------------
- * Port key  | User key (10 bits)           | Speed (5 bits)      | Duplex|
- *           --------------------------------------------------------------
- *           |15                           6|5                   1|0
- */
-#define  AD_DUPLEX_KEY_MASKS    0x1
-#define  AD_SPEED_KEY_MASKS     0x3E
-#define  AD_USER_KEY_MASKS      0xFFC0
-
-enum ad_link_speed_type {
-	AD_LINK_SPEED_1MBPS = 1,
-	AD_LINK_SPEED_10MBPS,
-	AD_LINK_SPEED_100MBPS,
-	AD_LINK_SPEED_1000MBPS,
-	AD_LINK_SPEED_2500MBPS,
-	AD_LINK_SPEED_5000MBPS,
-	AD_LINK_SPEED_10000MBPS,
-	AD_LINK_SPEED_14000MBPS,
-	AD_LINK_SPEED_20000MBPS,
-	AD_LINK_SPEED_25000MBPS,
-	AD_LINK_SPEED_40000MBPS,
-	AD_LINK_SPEED_50000MBPS,
-	AD_LINK_SPEED_56000MBPS,
-	AD_LINK_SPEED_100000MBPS,
-};
-
-/* compare MAC addresses */
-#define MAC_ADDRESS_EQUAL(A, B)	\
-	ether_addr_equal_64bits((const u8 *)A, (const u8 *)B)
-
-static const u8 null_mac_addr[ETH_ALEN + 2] __long_aligned = {
-	0, 0, 0, 0, 0, 0
-};
-static u16 ad_ticks_per_sec;
-static const int ad_delta_in_ticks = (AD_TIMER_INTERVAL * HZ) / 1000;
-
-static const u8 lacpdu_mcast_addr[ETH_ALEN + 2] __long_aligned =
-	MULTICAST_LACPDU_ADDR;
-
-/* ================= main 802.3ad protocol functions ================== */
-static int ad_lacpdu_send(struct port *port);
-static int ad_marker_send(struct port *port, struct bond_marker *marker);
-static void ad_mux_machine(struct port *port, bool *update_slave_arr);
-static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port);
-static void ad_tx_machine(struct port *port);
-static void ad_periodic_machine(struct port *port);
-static void ad_port_selection_logic(struct port *port, bool *update_slave_arr);
-static void ad_agg_selection_logic(struct aggregator *aggregator,
-				   bool *update_slave_arr);
-static void ad_clear_agg(struct aggregator *aggregator);
-static void ad_initialize_agg(struct aggregator *aggregator);
-static void ad_initialize_port(struct port *port, int lacp_fast);
-static void ad_enable_collecting_distributing(struct port *port,
-					      bool *update_slave_arr);
-static void ad_disable_collecting_distributing(struct port *port,
-					       bool *update_slave_arr);
-static void ad_marker_info_received(struct bond_marker *marker_info,
-				    struct port *port);
-static void ad_marker_response_received(struct bond_marker *marker,
-					struct port *port);
-static void ad_update_actor_keys(struct port *port, bool reset);
-
-
-/* ================= api to bonding and kernel code ================== */
-
-/**
- * __get_bond_by_port - get the port's bonding struct
- * @port: the port we're looking at
- *
- * Return @port's bonding struct, or %NULL if it can't be found.
- */
-static inline struct bonding *__get_bond_by_port(struct port *port)
-{
-	if (port->slave == NULL)
-		return NULL;
-
-	return bond_get_bond_by_slave(port->slave);
-}
-
-/**
- * __get_first_agg - get the first aggregator in the bond
- * @port: the port we're looking at
- *
- * Return the aggregator of the first slave in @bond, or %NULL if it can't be
- * found.
- * The caller must hold RCU or RTNL lock.
- */
-static inline struct aggregator *__get_first_agg(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-	struct slave *first_slave;
-	struct aggregator *agg;
-
-	/* If there's no bond for this port, or bond has no slaves */
-	if (bond == NULL)
-		return NULL;
-
-	rcu_read_lock();
-	first_slave = bond_first_slave_rcu(bond);
-	agg = first_slave ? &(SLAVE_AD_INFO(first_slave)->aggregator) : NULL;
-	rcu_read_unlock();
-
-	return agg;
-}
-
-/**
- * __agg_has_partner - see if we have a partner
- * @agg: the agregator we're looking at
- *
- * Return nonzero if aggregator has a partner (denoted by a non-zero ether
- * address for the partner). Return 0 if not.
- */
-static inline int __agg_has_partner(struct aggregator *agg)
-{
-	return !is_zero_ether_addr(agg->partner_system.mac_addr_value);
-}
-
-/**
- * __disable_port - disable the port's slave
- * @port: the port we're looking at
- */
-static inline void __disable_port(struct port *port)
-{
-	bond_set_slave_inactive_flags(port->slave, BOND_SLAVE_NOTIFY_LATER);
-}
-
-/**
- * __enable_port - enable the port's slave, if it's up
- * @port: the port we're looking at
- */
-static inline void __enable_port(struct port *port)
-{
-	struct slave *slave = port->slave;
-
-	if ((slave->link == BOND_LINK_UP) && bond_slave_is_up(slave)) {
-		bond_set_slave_active_flags(slave, BOND_SLAVE_NOTIFY_LATER);
-		toe_failover(netdev_master_upper_dev_get_rcu(port->slave->dev),
-			     port->slave->dev, TOE_LINK_UP, NULL);
-	}
-}
-
-/**
- * __port_is_enabled - check if the port's slave is in active state
- * @port: the port we're looking at
- */
-static inline int __port_is_enabled(struct port *port)
-{
-	return bond_is_active_slave(port->slave);
-}
-
-/**
- * __get_agg_selection_mode - get the aggregator selection mode
- * @port: the port we're looking at
- *
- * Get the aggregator selection mode. Can be %STABLE, %BANDWIDTH or %COUNT.
- */
-static inline u32 __get_agg_selection_mode(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-
-	if (bond == NULL)
-		return BOND_AD_STABLE;
-
-	return bond->params.ad_select;
-}
-
-/**
- * __check_agg_selection_timer - check if the selection timer has expired
- * @port: the port we're looking at
- */
-static inline int __check_agg_selection_timer(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-
-	if (bond == NULL)
-		return 0;
-
-	return BOND_AD_INFO(bond).agg_select_timer ? 1 : 0;
-}
-
-/**
- * __get_link_speed - get a port's speed
- * @port: the port we're looking at
- *
- * Return @port's speed in 802.3ad enum format. i.e. one of:
- *     0,
- *     %AD_LINK_SPEED_10MBPS,
- *     %AD_LINK_SPEED_100MBPS,
- *     %AD_LINK_SPEED_1000MBPS,
- *     %AD_LINK_SPEED_2500MBPS,
- *     %AD_LINK_SPEED_5000MBPS,
- *     %AD_LINK_SPEED_10000MBPS
- *     %AD_LINK_SPEED_14000MBPS,
- *     %AD_LINK_SPEED_20000MBPS
- *     %AD_LINK_SPEED_25000MBPS
- *     %AD_LINK_SPEED_40000MBPS
- *     %AD_LINK_SPEED_50000MBPS
- *     %AD_LINK_SPEED_56000MBPS
- *     %AD_LINK_SPEED_100000MBPS
- */
-static u16 __get_link_speed(struct port *port)
-{
-	struct slave *slave = port->slave;
-	u16 speed;
-
-	/* this if covers only a special case: when the configuration starts
-	 * with link down, it sets the speed to 0.
-	 * This is done in spite of the fact that the e100 driver reports 0
-	 * to be compatible with MVT in the future.
-	 */
-	if (slave->link != BOND_LINK_UP)
-		speed = 0;
-	else {
-		switch (slave->speed) {
-		case SPEED_10:
-			speed = AD_LINK_SPEED_10MBPS;
-			break;
-
-		case SPEED_100:
-			speed = AD_LINK_SPEED_100MBPS;
-			break;
-
-		case SPEED_1000:
-			speed = AD_LINK_SPEED_1000MBPS;
-			break;
-
-		case SPEED_2500:
-			speed = AD_LINK_SPEED_2500MBPS;
-			break;
-
-		case SPEED_5000:
-			speed = AD_LINK_SPEED_5000MBPS;
-			break;
-
-		case SPEED_10000:
-			speed = AD_LINK_SPEED_10000MBPS;
-			break;
-
-		case SPEED_14000:
-			speed = AD_LINK_SPEED_14000MBPS;
-			break;
-
-		case SPEED_20000:
-			speed = AD_LINK_SPEED_20000MBPS;
-			break;
-
-		case SPEED_25000:
-			speed = AD_LINK_SPEED_25000MBPS;
-			break;
-
-		case SPEED_40000:
-			speed = AD_LINK_SPEED_40000MBPS;
-			break;
-
-		case SPEED_50000:
-			speed = AD_LINK_SPEED_50000MBPS;
-			break;
-
-		case SPEED_56000:
-			speed = AD_LINK_SPEED_56000MBPS;
-			break;
-
-		case SPEED_100000:
-			speed = AD_LINK_SPEED_100000MBPS;
-			break;
-
-		default:
-			/* unknown speed value from ethtool. shouldn't happen */
-			if (slave->speed != SPEED_UNKNOWN)
-				pr_warn_once("%s: (slave %s): unknown ethtool speed (%d) for port %d (set it to 0)\n",
-					     slave->bond->dev->name,
-					     slave->dev->name, slave->speed,
-					     port->actor_port_number);
-			speed = 0;
-			break;
-		}
-	}
-
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d Received link speed %d update from adapter\n",
-		  port->actor_port_number, speed);
-	return speed;
-}
-
-/**
- * __get_duplex - get a port's duplex
- * @port: the port we're looking at
- *
- * Return @port's duplex in 802.3ad bitmask format. i.e.:
- *     0x01 if in full duplex
- *     0x00 otherwise
- */
-static u8 __get_duplex(struct port *port)
-{
-	struct slave *slave = port->slave;
-	u8 retval = 0x0;
-
-	/* handling a special case: when the configuration starts with
-	 * link down, it sets the duplex to 0.
-	 */
-	if (slave->link == BOND_LINK_UP) {
-		switch (slave->duplex) {
-		case DUPLEX_FULL:
-			retval = 0x1;
-			slave_dbg(slave->bond->dev, slave->dev, "Port %d Received status full duplex update from adapter\n",
-				  port->actor_port_number);
-			break;
-		case DUPLEX_HALF:
-		default:
-			retval = 0x0;
-			slave_dbg(slave->bond->dev, slave->dev, "Port %d Received status NOT full duplex update from adapter\n",
-				  port->actor_port_number);
-			break;
-		}
-	}
-	return retval;
-}
-
-static void __ad_actor_update_port(struct port *port)
-{
-	const struct bonding *bond = bond_get_bond_by_slave(port->slave);
-
-	port->actor_system = BOND_AD_INFO(bond).system.sys_mac_addr;
-	port->actor_system_priority = BOND_AD_INFO(bond).system.sys_priority;
-}
-
-/* Conversions */
-
-/**
- * __ad_timer_to_ticks - convert a given timer type to AD module ticks
- * @timer_type:	which timer to operate
- * @par: timer parameter. see below
- *
- * If @timer_type is %current_while_timer, @par indicates long/short timer.
- * If @timer_type is %periodic_timer, @par is one of %FAST_PERIODIC_TIME,
- *						     %SLOW_PERIODIC_TIME.
- */
-static u16 __ad_timer_to_ticks(u16 timer_type, u16 par)
-{
-	u16 retval = 0; /* to silence the compiler */
-
-	switch (timer_type) {
-	case AD_CURRENT_WHILE_TIMER:	/* for rx machine usage */
-		if (par)
-			retval = (AD_SHORT_TIMEOUT_TIME*ad_ticks_per_sec);
-		else
-			retval = (AD_LONG_TIMEOUT_TIME*ad_ticks_per_sec);
-		break;
-	case AD_ACTOR_CHURN_TIMER:	/* for local churn machine */
-		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
-		break;
-	case AD_PERIODIC_TIMER:		/* for periodic machine */
-		retval = (par*ad_ticks_per_sec); /* long timeout */
-		break;
-	case AD_PARTNER_CHURN_TIMER:	/* for remote churn machine */
-		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
-		break;
-	case AD_WAIT_WHILE_TIMER:	/* for selection machine */
-		retval = (AD_AGGREGATE_WAIT_TIME*ad_ticks_per_sec);
-		break;
-	}
-
-	return retval;
-}
-
-
-/* ================= ad_rx_machine helper functions ================== */
-
-/**
- * __choose_matched - update a port's matched variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Update the value of the matched variable, using parameter values from a
- * newly received lacpdu. Parameter values for the partner carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the actor. Matched is set to TRUE if all of these parameters
- * match and the PDU parameter partner_state.aggregation has the same value as
- * actor_oper_port_state.aggregation and lacp will actively maintain the link
- * in the aggregation. Matched is also set to TRUE if the value of
- * actor_state.aggregation in the received PDU is set to FALSE, i.e., indicates
- * an individual link and lacp will actively maintain the link. Otherwise,
- * matched is set to FALSE. LACP is considered to be actively maintaining the
- * link if either the PDU's actor_state.lacp_activity variable is TRUE or both
- * the actor's actor_oper_port_state.lacp_activity and the PDU's
- * partner_state.lacp_activity variables are TRUE.
- *
- * Note: the AD_PORT_MATCHED "variable" is not specified by 802.3ad; it is
- * used here to implement the language from 802.3ad 43.4.9 that requires
- * recordPDU to "match" the LACPDU parameters to the stored values.
- */
-static void __choose_matched(struct lacpdu *lacpdu, struct port *port)
-{
-	/* check if all parameters are alike
-	 * or this is individual link(aggregation == FALSE)
-	 * then update the state machine Matched variable.
-	 */
-	if (((ntohs(lacpdu->partner_port) == port->actor_port_number) &&
-	     (ntohs(lacpdu->partner_port_priority) == port->actor_port_priority) &&
-	     MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) &&
-	     (ntohs(lacpdu->partner_system_priority) == port->actor_system_priority) &&
-	     (ntohs(lacpdu->partner_key) == port->actor_oper_port_key) &&
-	     ((lacpdu->partner_state & LACP_STATE_AGGREGATION) == (port->actor_oper_port_state & LACP_STATE_AGGREGATION))) ||
-	    ((lacpdu->actor_state & LACP_STATE_AGGREGATION) == 0)
-		) {
-		port->sm_vars |= AD_PORT_MATCHED;
-	} else {
-		port->sm_vars &= ~AD_PORT_MATCHED;
-	}
-}
-
-/**
- * __record_pdu - record parameters from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Record the parameter values for the Actor carried in a received lacpdu as
- * the current partner operational parameter values and sets
- * actor_oper_port_state.defaulted to FALSE.
- */
-static void __record_pdu(struct lacpdu *lacpdu, struct port *port)
-{
-	if (lacpdu && port) {
-		struct port_params *partner = &port->partner_oper;
-
-		__choose_matched(lacpdu, port);
-		/* record the new parameter values for the partner
-		 * operational
-		 */
-		partner->port_number = ntohs(lacpdu->actor_port);
-		partner->port_priority = ntohs(lacpdu->actor_port_priority);
-		partner->system = lacpdu->actor_system;
-		partner->system_priority = ntohs(lacpdu->actor_system_priority);
-		partner->key = ntohs(lacpdu->actor_key);
-		partner->port_state = lacpdu->actor_state;
-
-		/* set actor_oper_port_state.defaulted to FALSE */
-		port->actor_oper_port_state &= ~LACP_STATE_DEFAULTED;
-
-		/* set the partner sync. to on if the partner is sync,
-		 * and the port is matched
-		 */
-		if ((port->sm_vars & AD_PORT_MATCHED) &&
-		    (lacpdu->actor_state & LACP_STATE_SYNCHRONIZATION)) {
-			partner->port_state |= LACP_STATE_SYNCHRONIZATION;
-			slave_dbg(port->slave->bond->dev, port->slave->dev,
-				  "partner sync=1\n");
-		} else {
-			partner->port_state &= ~LACP_STATE_SYNCHRONIZATION;
-			slave_dbg(port->slave->bond->dev, port->slave->dev,
-				  "partner sync=0\n");
-		}
-	}
-}
-
-/**
- * __record_default - record default parameters
- * @port: the port we're looking at
- *
- * This function records the default parameter values for the partner carried
- * in the Partner Admin parameters as the current partner operational parameter
- * values and sets actor_oper_port_state.defaulted to TRUE.
- */
-static void __record_default(struct port *port)
-{
-	if (port) {
-		/* record the partner admin parameters */
-		memcpy(&port->partner_oper, &port->partner_admin,
-		       sizeof(struct port_params));
-
-		/* set actor_oper_port_state.defaulted to true */
-		port->actor_oper_port_state |= LACP_STATE_DEFAULTED;
-	}
-}
-
-/**
- * __update_selected - update a port's Selected variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Update the value of the selected variable, using parameter values from a
- * newly received lacpdu. The parameter values for the Actor carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the ports partner. If one or more of the comparisons shows that
- * the value(s) received in the PDU differ from the current operational values,
- * then selected is set to FALSE and actor_oper_port_state.synchronization is
- * set to out_of_sync. Otherwise, selected remains unchanged.
- */
-static void __update_selected(struct lacpdu *lacpdu, struct port *port)
-{
-	if (lacpdu && port) {
-		const struct port_params *partner = &port->partner_oper;
-
-		/* check if any parameter is different then
-		 * update the state machine selected variable.
-		 */
-		if (ntohs(lacpdu->actor_port) != partner->port_number ||
-		    ntohs(lacpdu->actor_port_priority) != partner->port_priority ||
-		    !MAC_ADDRESS_EQUAL(&lacpdu->actor_system, &partner->system) ||
-		    ntohs(lacpdu->actor_system_priority) != partner->system_priority ||
-		    ntohs(lacpdu->actor_key) != partner->key ||
-		    (lacpdu->actor_state & LACP_STATE_AGGREGATION) != (partner->port_state & LACP_STATE_AGGREGATION)) {
-			port->sm_vars &= ~AD_PORT_SELECTED;
-		}
-	}
-}
-
-/**
- * __update_default_selected - update a port's Selected variable from Partner
- * @port: the port we're looking at
- *
- * This function updates the value of the selected variable, using the partner
- * administrative parameter values. The administrative values are compared with
- * the corresponding operational parameter values for the partner. If one or
- * more of the comparisons shows that the administrative value(s) differ from
- * the current operational values, then Selected is set to FALSE and
- * actor_oper_port_state.synchronization is set to OUT_OF_SYNC. Otherwise,
- * Selected remains unchanged.
- */
-static void __update_default_selected(struct port *port)
-{
-	if (port) {
-		const struct port_params *admin = &port->partner_admin;
-		const struct port_params *oper = &port->partner_oper;
-
-		/* check if any parameter is different then
-		 * update the state machine selected variable.
-		 */
-		if (admin->port_number != oper->port_number ||
-		    admin->port_priority != oper->port_priority ||
-		    !MAC_ADDRESS_EQUAL(&admin->system, &oper->system) ||
-		    admin->system_priority != oper->system_priority ||
-		    admin->key != oper->key ||
-		    (admin->port_state & LACP_STATE_AGGREGATION)
-			!= (oper->port_state & LACP_STATE_AGGREGATION)) {
-			port->sm_vars &= ~AD_PORT_SELECTED;
-		}
-	}
-}
-
-/**
- * __update_ntt - update a port's ntt variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Updates the value of the ntt variable, using parameter values from a newly
- * received lacpdu. The parameter values for the partner carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the Actor. If one or more of the comparisons shows that the
- * value(s) received in the PDU differ from the current operational values,
- * then ntt is set to TRUE. Otherwise, ntt remains unchanged.
- */
-static void __update_ntt(struct lacpdu *lacpdu, struct port *port)
-{
-	/* validate lacpdu and port */
-	if (lacpdu && port) {
-		/* check if any parameter is different then
-		 * update the port->ntt.
-		 */
-		if ((ntohs(lacpdu->partner_port) != port->actor_port_number) ||
-		    (ntohs(lacpdu->partner_port_priority) != port->actor_port_priority) ||
-		    !MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) ||
-		    (ntohs(lacpdu->partner_system_priority) != port->actor_system_priority) ||
-		    (ntohs(lacpdu->partner_key) != port->actor_oper_port_key) ||
-		    ((lacpdu->partner_state & LACP_STATE_LACP_ACTIVITY) != (port->actor_oper_port_state & LACP_STATE_LACP_ACTIVITY)) ||
-		    ((lacpdu->partner_state & LACP_STATE_LACP_TIMEOUT) != (port->actor_oper_port_state & LACP_STATE_LACP_TIMEOUT)) ||
-		    ((lacpdu->partner_state & LACP_STATE_SYNCHRONIZATION) != (port->actor_oper_port_state & LACP_STATE_SYNCHRONIZATION)) ||
-		    ((lacpdu->partner_state & LACP_STATE_AGGREGATION) != (port->actor_oper_port_state & LACP_STATE_AGGREGATION))
-		   ) {
-			port->ntt = true;
-		}
-	}
-}
-
-/**
- * __agg_ports_are_ready - check if all ports in an aggregator are ready
- * @aggregator: the aggregator we're looking at
- *
- */
-static int __agg_ports_are_ready(struct aggregator *aggregator)
-{
-	struct port *port;
-	int retval = 1;
-
-	if (aggregator) {
-		/* scan all ports in this aggregator to verfy if they are
-		 * all ready.
-		 */
-		for (port = aggregator->lag_ports;
-		     port;
-		     port = port->next_port_in_aggregator) {
-			if (!(port->sm_vars & AD_PORT_READY_N)) {
-				retval = 0;
-				break;
-			}
-		}
-	}
-
-	return retval;
-}
-
-/**
- * __set_agg_ports_ready - set value of Ready bit in all ports of an aggregator
- * @aggregator: the aggregator we're looking at
- * @val: Should the ports' ready bit be set on or off
- *
- */
-static void __set_agg_ports_ready(struct aggregator *aggregator, int val)
-{
-	struct port *port;
-
-	for (port = aggregator->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (val)
-			port->sm_vars |= AD_PORT_READY;
-		else
-			port->sm_vars &= ~AD_PORT_READY;
-	}
-}
-
-static int __agg_active_ports(struct aggregator *agg)
-{
-	struct port *port;
-	int active = 0;
-
-	for (port = agg->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (port->is_enabled)
-			active++;
-	}
-
-	return active;
-}
-
-/**
- * __get_agg_bandwidth - get the total bandwidth of an aggregator
- * @aggregator: the aggregator we're looking at
- *
- */
-static u32 __get_agg_bandwidth(struct aggregator *aggregator)
-{
-	int nports = __agg_active_ports(aggregator);
-	u32 bandwidth = 0;
-
-	if (nports) {
-		switch (__get_link_speed(aggregator->lag_ports)) {
-		case AD_LINK_SPEED_1MBPS:
-			bandwidth = nports;
-			break;
-		case AD_LINK_SPEED_10MBPS:
-			bandwidth = nports * 10;
-			break;
-		case AD_LINK_SPEED_100MBPS:
-			bandwidth = nports * 100;
-			break;
-		case AD_LINK_SPEED_1000MBPS:
-			bandwidth = nports * 1000;
-			break;
-		case AD_LINK_SPEED_2500MBPS:
-			bandwidth = nports * 2500;
-			break;
-		case AD_LINK_SPEED_5000MBPS:
-			bandwidth = nports * 5000;
-			break;
-		case AD_LINK_SPEED_10000MBPS:
-			bandwidth = nports * 10000;
-			break;
-		case AD_LINK_SPEED_14000MBPS:
-			bandwidth = nports * 14000;
-			break;
-		case AD_LINK_SPEED_20000MBPS:
-			bandwidth = nports * 20000;
-			break;
-		case AD_LINK_SPEED_25000MBPS:
-			bandwidth = nports * 25000;
-			break;
-		case AD_LINK_SPEED_40000MBPS:
-			bandwidth = nports * 40000;
-			break;
-		case AD_LINK_SPEED_50000MBPS:
-			bandwidth = nports * 50000;
-			break;
-		case AD_LINK_SPEED_56000MBPS:
-			bandwidth = nports * 56000;
-			break;
-		case AD_LINK_SPEED_100000MBPS:
-			bandwidth = nports * 100000;
-			break;
-		default:
-			bandwidth = 0; /* to silence the compiler */
-		}
-	}
-	return bandwidth;
-}
-
-/**
- * __get_active_agg - get the current active aggregator
- * @aggregator: the aggregator we're looking at
- *
- * Caller must hold RCU lock.
- */
-static struct aggregator *__get_active_agg(struct aggregator *aggregator)
-{
-	struct bonding *bond = aggregator->slave->bond;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave_rcu(bond, slave, iter)
-		if (SLAVE_AD_INFO(slave)->aggregator.is_active)
-			return &(SLAVE_AD_INFO(slave)->aggregator);
-
-	return NULL;
-}
-
-/**
- * __update_lacpdu_from_port - update a port's lacpdu fields
- * @port: the port we're looking at
- */
-static inline void __update_lacpdu_from_port(struct port *port)
-{
-	struct lacpdu *lacpdu = &port->lacpdu;
-	const struct port_params *partner = &port->partner_oper;
-
-	/* update current actual Actor parameters
-	 * lacpdu->subtype                   initialized
-	 * lacpdu->version_number            initialized
-	 * lacpdu->tlv_type_actor_info       initialized
-	 * lacpdu->actor_information_length  initialized
-	 */
-
-	lacpdu->actor_system_priority = htons(port->actor_system_priority);
-	lacpdu->actor_system = port->actor_system;
-	lacpdu->actor_key = htons(port->actor_oper_port_key);
-	lacpdu->actor_port_priority = htons(port->actor_port_priority);
-	lacpdu->actor_port = htons(port->actor_port_number);
-	lacpdu->actor_state = port->actor_oper_port_state;
-	slave_dbg(port->slave->bond->dev, port->slave->dev,
-		  "update lacpdu: actor port state %x\n",
-		  port->actor_oper_port_state);
-
-	/* lacpdu->reserved_3_1              initialized
-	 * lacpdu->tlv_type_partner_info     initialized
-	 * lacpdu->partner_information_length initialized
-	 */
-
-	lacpdu->partner_system_priority = htons(partner->system_priority);
-	lacpdu->partner_system = partner->system;
-	lacpdu->partner_key = htons(partner->key);
-	lacpdu->partner_port_priority = htons(partner->port_priority);
-	lacpdu->partner_port = htons(partner->port_number);
-	lacpdu->partner_state = partner->port_state;
-
-	/* lacpdu->reserved_3_2              initialized
-	 * lacpdu->tlv_type_collector_info   initialized
-	 * lacpdu->collector_information_length initialized
-	 * collector_max_delay                initialized
-	 * reserved_12[12]                   initialized
-	 * tlv_type_terminator               initialized
-	 * terminator_length                 initialized
-	 * reserved_50[50]                   initialized
-	 */
-}
-
-/* ================= main 802.3ad protocol code ========================= */
-
-/**
- * ad_lacpdu_send - send out a lacpdu packet on a given port
- * @port: the port we're looking at
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-static int ad_lacpdu_send(struct port *port)
-{
-	struct slave *slave = port->slave;
-	struct sk_buff *skb;
-	struct lacpdu_header *lacpdu_header;
-	int length = sizeof(struct lacpdu_header);
-
-	skb = dev_alloc_skb(length);
-	if (!skb)
-		return -ENOMEM;
-
-	atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_tx);
-	atomic64_inc(&BOND_AD_INFO(slave->bond).stats.lacpdu_tx);
-
-	skb->dev = slave->dev;
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = PKT_TYPE_LACPDU;
-	skb->priority = TC_PRIO_CONTROL;
-
-	lacpdu_header = skb_put(skb, length);
-
-	ether_addr_copy(lacpdu_header->hdr.h_dest, lacpdu_mcast_addr);
-	/* Note: source address is set to be the member's PERMANENT address,
-	 * because we use it to identify loopback lacpdus in receive.
-	 */
-	ether_addr_copy(lacpdu_header->hdr.h_source, slave->perm_hwaddr);
-	lacpdu_header->hdr.h_proto = PKT_TYPE_LACPDU;
-
-	lacpdu_header->lacpdu = port->lacpdu;
-
-	dev_queue_xmit(skb);
-
-	return 0;
-}
-
-/**
- * ad_marker_send - send marker information/response on a given port
- * @port: the port we're looking at
- * @marker: marker data to send
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-static int ad_marker_send(struct port *port, struct bond_marker *marker)
-{
-	struct slave *slave = port->slave;
-	struct sk_buff *skb;
-	struct bond_marker_header *marker_header;
-	int length = sizeof(struct bond_marker_header);
-
-	skb = dev_alloc_skb(length + 16);
-	if (!skb)
-		return -ENOMEM;
-
-	switch (marker->tlv_type) {
-	case AD_MARKER_INFORMATION_SUBTYPE:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.marker_tx);
-		atomic64_inc(&BOND_AD_INFO(slave->bond).stats.marker_tx);
-		break;
-	case AD_MARKER_RESPONSE_SUBTYPE:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.marker_resp_tx);
-		atomic64_inc(&BOND_AD_INFO(slave->bond).stats.marker_resp_tx);
-		break;
-	}
-
-	skb_reserve(skb, 16);
-
-	skb->dev = slave->dev;
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = PKT_TYPE_LACPDU;
-
-	marker_header = skb_put(skb, length);
-
-	ether_addr_copy(marker_header->hdr.h_dest, lacpdu_mcast_addr);
-	/* Note: source address is set to be the member's PERMANENT address,
-	 * because we use it to identify loopback MARKERs in receive.
-	 */
-	ether_addr_copy(marker_header->hdr.h_source, slave->perm_hwaddr);
-	marker_header->hdr.h_proto = PKT_TYPE_LACPDU;
-
-	marker_header->marker = *marker;
-
-	dev_queue_xmit(skb);
-
-	return 0;
-}
-
-/**
- * ad_mux_machine - handle a port's mux state machine
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- */
-static void ad_mux_machine(struct port *port, bool *update_slave_arr)
-{
-	mux_states_t last_state;
-
-	/* keep current State Machine state to compare later if it was
-	 * changed
-	 */
-	last_state = port->sm_mux_state;
-
-	if (port->sm_vars & AD_PORT_BEGIN) {
-		port->sm_mux_state = AD_MUX_DETACHED;
-	} else {
-		switch (port->sm_mux_state) {
-		case AD_MUX_DETACHED:
-			if ((port->sm_vars & AD_PORT_SELECTED)
-			    || (port->sm_vars & AD_PORT_STANDBY))
-				/* if SELECTED or STANDBY */
-				port->sm_mux_state = AD_MUX_WAITING;
-			break;
-		case AD_MUX_WAITING:
-			/* if SELECTED == FALSE return to DETACH state */
-			if (!(port->sm_vars & AD_PORT_SELECTED)) {
-				port->sm_vars &= ~AD_PORT_READY_N;
-				/* in order to withhold the Selection Logic to
-				 * check all ports READY_N value every callback
-				 * cycle to update ready variable, we check
-				 * READY_N and update READY here
-				 */
-				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-				port->sm_mux_state = AD_MUX_DETACHED;
-				break;
-			}
-
-			/* check if the wait_while_timer expired */
-			if (port->sm_mux_timer_counter
-			    && !(--port->sm_mux_timer_counter))
-				port->sm_vars |= AD_PORT_READY_N;
-
-			/* in order to withhold the selection logic to check
-			 * all ports READY_N value every callback cycle to
-			 * update ready variable, we check READY_N and update
-			 * READY here
-			 */
-			__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-
-			/* if the wait_while_timer expired, and the port is
-			 * in READY state, move to ATTACHED state
-			 */
-			if ((port->sm_vars & AD_PORT_READY)
-			    && !port->sm_mux_timer_counter)
-				port->sm_mux_state = AD_MUX_ATTACHED;
-			break;
-		case AD_MUX_ATTACHED:
-			/* check also if agg_select_timer expired (so the
-			 * edable port will take place only after this timer)
-			 */
-			if ((port->sm_vars & AD_PORT_SELECTED) &&
-			    (port->partner_oper.port_state & LACP_STATE_SYNCHRONIZATION) &&
-			    !__check_agg_selection_timer(port)) {
-				if (port->aggregator->is_active)
-					port->sm_mux_state =
-					    AD_MUX_COLLECTING_DISTRIBUTING;
-			} else if (!(port->sm_vars & AD_PORT_SELECTED) ||
-				   (port->sm_vars & AD_PORT_STANDBY)) {
-				/* if UNSELECTED or STANDBY */
-				port->sm_vars &= ~AD_PORT_READY_N;
-				/* in order to withhold the selection logic to
-				 * check all ports READY_N value every callback
-				 * cycle to update ready variable, we check
-				 * READY_N and update READY here
-				 */
-				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-				port->sm_mux_state = AD_MUX_DETACHED;
-			} else if (port->aggregator->is_active) {
-				port->actor_oper_port_state |=
-				    LACP_STATE_SYNCHRONIZATION;
-			}
-			break;
-		case AD_MUX_COLLECTING_DISTRIBUTING:
-			if (!(port->sm_vars & AD_PORT_SELECTED) ||
-			    (port->sm_vars & AD_PORT_STANDBY) ||
-			    !(port->partner_oper.port_state & LACP_STATE_SYNCHRONIZATION) ||
-			    !(port->actor_oper_port_state & LACP_STATE_SYNCHRONIZATION)) {
-				port->sm_mux_state = AD_MUX_ATTACHED;
-			} else {
-				/* if port state hasn't changed make
-				 * sure that a collecting distributing
-				 * port in an active aggregator is enabled
-				 */
-				if (port->aggregator &&
-				    port->aggregator->is_active &&
-				    !__port_is_enabled(port)) {
-
-					__enable_port(port);
-				}
-			}
-			break;
-		default:
-			break;
-		}
-	}
-
-	/* check if the state machine was changed */
-	if (port->sm_mux_state != last_state) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Mux Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number,
-			  last_state,
-			  port->sm_mux_state);
-		switch (port->sm_mux_state) {
-		case AD_MUX_DETACHED:
-			port->actor_oper_port_state &= ~LACP_STATE_SYNCHRONIZATION;
-			ad_disable_collecting_distributing(port,
-							   update_slave_arr);
-			port->actor_oper_port_state &= ~LACP_STATE_COLLECTING;
-			port->actor_oper_port_state &= ~LACP_STATE_DISTRIBUTING;
-			port->ntt = true;
-			break;
-		case AD_MUX_WAITING:
-			port->sm_mux_timer_counter = __ad_timer_to_ticks(AD_WAIT_WHILE_TIMER, 0);
-			break;
-		case AD_MUX_ATTACHED:
-			if (port->aggregator->is_active)
-				port->actor_oper_port_state |=
-				    LACP_STATE_SYNCHRONIZATION;
-			else
-				port->actor_oper_port_state &=
-				    ~LACP_STATE_SYNCHRONIZATION;
-			port->actor_oper_port_state &= ~LACP_STATE_COLLECTING;
-			port->actor_oper_port_state &= ~LACP_STATE_DISTRIBUTING;
-			ad_disable_collecting_distributing(port,
-							   update_slave_arr);
-			port->ntt = true;
-			break;
-		case AD_MUX_COLLECTING_DISTRIBUTING:
-			port->actor_oper_port_state |= LACP_STATE_COLLECTING;
-			port->actor_oper_port_state |= LACP_STATE_DISTRIBUTING;
-			port->actor_oper_port_state |= LACP_STATE_SYNCHRONIZATION;
-			ad_enable_collecting_distributing(port,
-							  update_slave_arr);
-			port->ntt = true;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_rx_machine - handle a port's rx State Machine
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * If lacpdu arrived, stop previous timer (if exists) and set the next state as
- * CURRENT. If timer expired set the state machine in the proper state.
- * In other cases, this function checks if we need to switch to other state.
- */
-static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port)
-{
-	rx_states_t last_state;
-
-	/* keep current State Machine state to compare later if it was
-	 * changed
-	 */
-	last_state = port->sm_rx_state;
-
-	if (lacpdu) {
-		atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.lacpdu_rx);
-		atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.lacpdu_rx);
-	}
-	/* check if state machine should change state */
-
-	/* first, check if port was reinitialized */
-	if (port->sm_vars & AD_PORT_BEGIN) {
-		port->sm_rx_state = AD_RX_INITIALIZE;
-		port->sm_vars |= AD_PORT_CHURNED;
-	/* check if port is not enabled */
-	} else if (!(port->sm_vars & AD_PORT_BEGIN) && !port->is_enabled)
-		port->sm_rx_state = AD_RX_PORT_DISABLED;
-	/* check if new lacpdu arrived */
-	else if (lacpdu && ((port->sm_rx_state == AD_RX_EXPIRED) ||
-		 (port->sm_rx_state == AD_RX_DEFAULTED) ||
-		 (port->sm_rx_state == AD_RX_CURRENT))) {
-		if (port->sm_rx_state != AD_RX_CURRENT)
-			port->sm_vars |= AD_PORT_CHURNED;
-		port->sm_rx_timer_counter = 0;
-		port->sm_rx_state = AD_RX_CURRENT;
-	} else {
-		/* if timer is on, and if it is expired */
-		if (port->sm_rx_timer_counter &&
-		    !(--port->sm_rx_timer_counter)) {
-			switch (port->sm_rx_state) {
-			case AD_RX_EXPIRED:
-				port->sm_rx_state = AD_RX_DEFAULTED;
-				break;
-			case AD_RX_CURRENT:
-				port->sm_rx_state = AD_RX_EXPIRED;
-				break;
-			default:
-				break;
-			}
-		} else {
-			/* if no lacpdu arrived and no timer is on */
-			switch (port->sm_rx_state) {
-			case AD_RX_PORT_DISABLED:
-				if (port->is_enabled &&
-				    (port->sm_vars & AD_PORT_LACP_ENABLED))
-					port->sm_rx_state = AD_RX_EXPIRED;
-				else if (port->is_enabled
-					 && ((port->sm_vars
-					      & AD_PORT_LACP_ENABLED) == 0))
-					port->sm_rx_state = AD_RX_LACP_DISABLED;
-				break;
-			default:
-				break;
-
-			}
-		}
-	}
-
-	/* check if the State machine was changed or new lacpdu arrived */
-	if ((port->sm_rx_state != last_state) || (lacpdu)) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Rx Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number,
-			  last_state,
-			  port->sm_rx_state);
-		switch (port->sm_rx_state) {
-		case AD_RX_INITIALIZE:
-			if (!(port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS))
-				port->sm_vars &= ~AD_PORT_LACP_ENABLED;
-			else
-				port->sm_vars |= AD_PORT_LACP_ENABLED;
-			port->sm_vars &= ~AD_PORT_SELECTED;
-			__record_default(port);
-			port->actor_oper_port_state &= ~LACP_STATE_EXPIRED;
-			port->sm_rx_state = AD_RX_PORT_DISABLED;
-
-			fallthrough;
-		case AD_RX_PORT_DISABLED:
-			port->sm_vars &= ~AD_PORT_MATCHED;
-			break;
-		case AD_RX_LACP_DISABLED:
-			port->sm_vars &= ~AD_PORT_SELECTED;
-			__record_default(port);
-			port->partner_oper.port_state &= ~LACP_STATE_AGGREGATION;
-			port->sm_vars |= AD_PORT_MATCHED;
-			port->actor_oper_port_state &= ~LACP_STATE_EXPIRED;
-			break;
-		case AD_RX_EXPIRED:
-			/* Reset of the Synchronization flag (Standard 43.4.12)
-			 * This reset cause to disable this port in the
-			 * COLLECTING_DISTRIBUTING state of the mux machine in
-			 * case of EXPIRED even if LINK_DOWN didn't arrive for
-			 * the port.
-			 */
-			port->partner_oper.port_state &= ~LACP_STATE_SYNCHRONIZATION;
-			port->sm_vars &= ~AD_PORT_MATCHED;
-			port->partner_oper.port_state |= LACP_STATE_LACP_TIMEOUT;
-			port->partner_oper.port_state |= LACP_STATE_LACP_ACTIVITY;
-			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(AD_SHORT_TIMEOUT));
-			port->actor_oper_port_state |= LACP_STATE_EXPIRED;
-			port->sm_vars |= AD_PORT_CHURNED;
-			break;
-		case AD_RX_DEFAULTED:
-			__update_default_selected(port);
-			__record_default(port);
-			port->sm_vars |= AD_PORT_MATCHED;
-			port->actor_oper_port_state &= ~LACP_STATE_EXPIRED;
-			break;
-		case AD_RX_CURRENT:
-			/* detect loopback situation */
-			if (MAC_ADDRESS_EQUAL(&(lacpdu->actor_system),
-					      &(port->actor_system))) {
-				slave_err(port->slave->bond->dev, port->slave->dev, "An illegal loopback occurred on slave\n"
-					  "Check the configuration to verify that all adapters are connected to 802.3ad compliant switch ports\n");
-				return;
-			}
-			__update_selected(lacpdu, port);
-			__update_ntt(lacpdu, port);
-			__record_pdu(lacpdu, port);
-			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(port->actor_oper_port_state & LACP_STATE_LACP_TIMEOUT));
-			port->actor_oper_port_state &= ~LACP_STATE_EXPIRED;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_churn_machine - handle port churn's state machine
- * @port: the port we're looking at
- *
- */
-static void ad_churn_machine(struct port *port)
-{
-	if (port->sm_vars & AD_PORT_CHURNED) {
-		port->sm_vars &= ~AD_PORT_CHURNED;
-		port->sm_churn_actor_state = AD_CHURN_MONITOR;
-		port->sm_churn_partner_state = AD_CHURN_MONITOR;
-		port->sm_churn_actor_timer_counter =
-			__ad_timer_to_ticks(AD_ACTOR_CHURN_TIMER, 0);
-		port->sm_churn_partner_timer_counter =
-			 __ad_timer_to_ticks(AD_PARTNER_CHURN_TIMER, 0);
-		return;
-	}
-	if (port->sm_churn_actor_timer_counter &&
-	    !(--port->sm_churn_actor_timer_counter) &&
-	    port->sm_churn_actor_state == AD_CHURN_MONITOR) {
-		if (port->actor_oper_port_state & LACP_STATE_SYNCHRONIZATION) {
-			port->sm_churn_actor_state = AD_NO_CHURN;
-		} else {
-			port->churn_actor_count++;
-			port->sm_churn_actor_state = AD_CHURN;
-		}
-	}
-	if (port->sm_churn_partner_timer_counter &&
-	    !(--port->sm_churn_partner_timer_counter) &&
-	    port->sm_churn_partner_state == AD_CHURN_MONITOR) {
-		if (port->partner_oper.port_state & LACP_STATE_SYNCHRONIZATION) {
-			port->sm_churn_partner_state = AD_NO_CHURN;
-		} else {
-			port->churn_partner_count++;
-			port->sm_churn_partner_state = AD_CHURN;
-		}
-	}
-}
-
-/**
- * ad_tx_machine - handle a port's tx state machine
- * @port: the port we're looking at
- */
-static void ad_tx_machine(struct port *port)
-{
-	/* check if tx timer expired, to verify that we do not send more than
-	 * 3 packets per second
-	 */
-	if (port->sm_tx_timer_counter && !(--port->sm_tx_timer_counter)) {
-		/* check if there is something to send */
-		if (port->ntt && (port->sm_vars & AD_PORT_LACP_ENABLED)) {
-			__update_lacpdu_from_port(port);
-
-			if (ad_lacpdu_send(port) >= 0) {
-				slave_dbg(port->slave->bond->dev,
-					  port->slave->dev,
-					  "Sent LACPDU on port %d\n",
-					  port->actor_port_number);
-
-				/* mark ntt as false, so it will not be sent
-				 * again until demanded
-				 */
-				port->ntt = false;
-			}
-		}
-		/* restart tx timer(to verify that we will not exceed
-		 * AD_MAX_TX_IN_SECOND
-		 */
-		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
-	}
-}
-
-/**
- * ad_periodic_machine - handle a port's periodic state machine
- * @port: the port we're looking at
- *
- * Turn ntt flag on priodically to perform periodic transmission of lacpdu's.
- */
-static void ad_periodic_machine(struct port *port)
-{
-	periodic_states_t last_state;
-
-	/* keep current state machine state to compare later if it was changed */
-	last_state = port->sm_periodic_state;
-
-	/* check if port was reinitialized */
-	if (((port->sm_vars & AD_PORT_BEGIN) || !(port->sm_vars & AD_PORT_LACP_ENABLED) || !port->is_enabled) ||
-	    (!(port->actor_oper_port_state & LACP_STATE_LACP_ACTIVITY) && !(port->partner_oper.port_state & LACP_STATE_LACP_ACTIVITY))
-	   ) {
-		port->sm_periodic_state = AD_NO_PERIODIC;
-	}
-	/* check if state machine should change state */
-	else if (port->sm_periodic_timer_counter) {
-		/* check if periodic state machine expired */
-		if (!(--port->sm_periodic_timer_counter)) {
-			/* if expired then do tx */
-			port->sm_periodic_state = AD_PERIODIC_TX;
-		} else {
-			/* If not expired, check if there is some new timeout
-			 * parameter from the partner state
-			 */
-			switch (port->sm_periodic_state) {
-			case AD_FAST_PERIODIC:
-				if (!(port->partner_oper.port_state
-				      & LACP_STATE_LACP_TIMEOUT))
-					port->sm_periodic_state = AD_SLOW_PERIODIC;
-				break;
-			case AD_SLOW_PERIODIC:
-				if ((port->partner_oper.port_state & LACP_STATE_LACP_TIMEOUT)) {
-					port->sm_periodic_timer_counter = 0;
-					port->sm_periodic_state = AD_PERIODIC_TX;
-				}
-				break;
-			default:
-				break;
-			}
-		}
-	} else {
-		switch (port->sm_periodic_state) {
-		case AD_NO_PERIODIC:
-			port->sm_periodic_state = AD_FAST_PERIODIC;
-			break;
-		case AD_PERIODIC_TX:
-			if (!(port->partner_oper.port_state &
-			    LACP_STATE_LACP_TIMEOUT))
-				port->sm_periodic_state = AD_SLOW_PERIODIC;
-			else
-				port->sm_periodic_state = AD_FAST_PERIODIC;
-			break;
-		default:
-			break;
-		}
-	}
-
-	/* check if the state machine was changed */
-	if (port->sm_periodic_state != last_state) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Periodic Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number, last_state,
-			  port->sm_periodic_state);
-		switch (port->sm_periodic_state) {
-		case AD_NO_PERIODIC:
-			port->sm_periodic_timer_counter = 0;
-			break;
-		case AD_FAST_PERIODIC:
-			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
-			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_FAST_PERIODIC_TIME))-1;
-			break;
-		case AD_SLOW_PERIODIC:
-			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
-			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_SLOW_PERIODIC_TIME))-1;
-			break;
-		case AD_PERIODIC_TX:
-			port->ntt = true;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_port_selection_logic - select aggregation groups
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * Select aggregation groups, and assign each port for it's aggregetor. The
- * selection logic is called in the inititalization (after all the handshkes),
- * and after every lacpdu receive (if selected is off).
- */
-static void ad_port_selection_logic(struct port *port, bool *update_slave_arr)
-{
-	struct aggregator *aggregator, *free_aggregator = NULL, *temp_aggregator;
-	struct port *last_port = NULL, *curr_port;
-	struct list_head *iter;
-	struct bonding *bond;
-	struct slave *slave;
-	int found = 0;
-
-	/* if the port is already Selected, do nothing */
-	if (port->sm_vars & AD_PORT_SELECTED)
-		return;
-
-	bond = __get_bond_by_port(port);
-
-	/* if the port is connected to other aggregator, detach it */
-	if (port->aggregator) {
-		/* detach the port from its former aggregator */
-		temp_aggregator = port->aggregator;
-		for (curr_port = temp_aggregator->lag_ports; curr_port;
-		     last_port = curr_port,
-		     curr_port = curr_port->next_port_in_aggregator) {
-			if (curr_port == port) {
-				temp_aggregator->num_of_ports--;
-				/* if it is the first port attached to the
-				 * aggregator
-				 */
-				if (!last_port) {
-					temp_aggregator->lag_ports =
-						port->next_port_in_aggregator;
-				} else {
-					/* not the first port attached to the
-					 * aggregator
-					 */
-					last_port->next_port_in_aggregator =
-						port->next_port_in_aggregator;
-				}
-
-				/* clear the port's relations to this
-				 * aggregator
-				 */
-				port->aggregator = NULL;
-				port->next_port_in_aggregator = NULL;
-				port->actor_port_aggregator_identifier = 0;
-
-				slave_dbg(bond->dev, port->slave->dev, "Port %d left LAG %d\n",
-					  port->actor_port_number,
-					  temp_aggregator->aggregator_identifier);
-				/* if the aggregator is empty, clear its
-				 * parameters, and set it ready to be attached
-				 */
-				if (!temp_aggregator->lag_ports)
-					ad_clear_agg(temp_aggregator);
-				break;
-			}
-		}
-		if (!curr_port) {
-			/* meaning: the port was related to an aggregator
-			 * but was not on the aggregator port list
-			 */
-			net_warn_ratelimited("%s: (slave %s): Warning: Port %d was related to aggregator %d but was not on its port list\n",
-					     port->slave->bond->dev->name,
-					     port->slave->dev->name,
-					     port->actor_port_number,
-					     port->aggregator->aggregator_identifier);
-		}
-	}
-	/* search on all aggregators for a suitable aggregator for this port */
-	bond_for_each_slave(bond, slave, iter) {
-		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		/* keep a free aggregator for later use(if needed) */
-		if (!aggregator->lag_ports) {
-			if (!free_aggregator)
-				free_aggregator = aggregator;
-			continue;
-		}
-		/* check if current aggregator suits us */
-		if (((aggregator->actor_oper_aggregator_key == port->actor_oper_port_key) && /* if all parameters match AND */
-		     MAC_ADDRESS_EQUAL(&(aggregator->partner_system), &(port->partner_oper.system)) &&
-		     (aggregator->partner_system_priority == port->partner_oper.system_priority) &&
-		     (aggregator->partner_oper_aggregator_key == port->partner_oper.key)
-		    ) &&
-		    ((!MAC_ADDRESS_EQUAL(&(port->partner_oper.system), &(null_mac_addr)) && /* partner answers */
-		      !aggregator->is_individual)  /* but is not individual OR */
-		    )
-		   ) {
-			/* attach to the founded aggregator */
-			port->aggregator = aggregator;
-			port->actor_port_aggregator_identifier =
-				port->aggregator->aggregator_identifier;
-			port->next_port_in_aggregator = aggregator->lag_ports;
-			port->aggregator->num_of_ports++;
-			aggregator->lag_ports = port;
-			slave_dbg(bond->dev, slave->dev, "Port %d joined LAG %d (existing LAG)\n",
-				  port->actor_port_number,
-				  port->aggregator->aggregator_identifier);
-
-			/* mark this port as selected */
-			port->sm_vars |= AD_PORT_SELECTED;
-			found = 1;
-			break;
-		}
-	}
-
-	/* the port couldn't find an aggregator - attach it to a new
-	 * aggregator
-	 */
-	if (!found) {
-		if (free_aggregator) {
-			/* assign port a new aggregator */
-			port->aggregator = free_aggregator;
-			port->actor_port_aggregator_identifier =
-				port->aggregator->aggregator_identifier;
-
-			/* update the new aggregator's parameters
-			 * if port was responsed from the end-user
-			 */
-			if (port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS)
-				/* if port is full duplex */
-				port->aggregator->is_individual = false;
-			else
-				port->aggregator->is_individual = true;
-
-			port->aggregator->actor_admin_aggregator_key =
-				port->actor_admin_port_key;
-			port->aggregator->actor_oper_aggregator_key =
-				port->actor_oper_port_key;
-			port->aggregator->partner_system =
-				port->partner_oper.system;
-			port->aggregator->partner_system_priority =
-				port->partner_oper.system_priority;
-			port->aggregator->partner_oper_aggregator_key = port->partner_oper.key;
-			port->aggregator->receive_state = 1;
-			port->aggregator->transmit_state = 1;
-			port->aggregator->lag_ports = port;
-			port->aggregator->num_of_ports++;
-
-			/* mark this port as selected */
-			port->sm_vars |= AD_PORT_SELECTED;
-
-			slave_dbg(bond->dev, port->slave->dev, "Port %d joined LAG %d (new LAG)\n",
-				  port->actor_port_number,
-				  port->aggregator->aggregator_identifier);
-		} else {
-			slave_err(bond->dev, port->slave->dev,
-				  "Port %d did not find a suitable aggregator\n",
-				  port->actor_port_number);
-		}
-	}
-	/* if all aggregator's ports are READY_N == TRUE, set ready=TRUE
-	 * in all aggregator's ports, else set ready=FALSE in all
-	 * aggregator's ports
-	 */
-	__set_agg_ports_ready(port->aggregator,
-			      __agg_ports_are_ready(port->aggregator));
-
-	aggregator = __get_first_agg(port);
-	ad_agg_selection_logic(aggregator, update_slave_arr);
-
-	if (!port->aggregator->is_active)
-		port->actor_oper_port_state &= ~LACP_STATE_SYNCHRONIZATION;
-}
-
-/* Decide if "agg" is a better choice for the new active aggregator that
- * the current best, according to the ad_select policy.
- */
-static struct aggregator *ad_agg_selection_test(struct aggregator *best,
-						struct aggregator *curr)
-{
-	/* 0. If no best, select current.
-	 *
-	 * 1. If the current agg is not individual, and the best is
-	 *    individual, select current.
-	 *
-	 * 2. If current agg is individual and the best is not, keep best.
-	 *
-	 * 3. Therefore, current and best are both individual or both not
-	 *    individual, so:
-	 *
-	 * 3a. If current agg partner replied, and best agg partner did not,
-	 *     select current.
-	 *
-	 * 3b. If current agg partner did not reply and best agg partner
-	 *     did reply, keep best.
-	 *
-	 * 4.  Therefore, current and best both have partner replies or
-	 *     both do not, so perform selection policy:
-	 *
-	 * BOND_AD_COUNT: Select by count of ports.  If count is equal,
-	 *     select by bandwidth.
-	 *
-	 * BOND_AD_STABLE, BOND_AD_BANDWIDTH: Select by bandwidth.
-	 */
-	if (!best)
-		return curr;
-
-	if (!curr->is_individual && best->is_individual)
-		return curr;
-
-	if (curr->is_individual && !best->is_individual)
-		return best;
-
-	if (__agg_has_partner(curr) && !__agg_has_partner(best))
-		return curr;
-
-	if (!__agg_has_partner(curr) && __agg_has_partner(best))
-		return best;
-
-	switch (__get_agg_selection_mode(curr->lag_ports)) {
-	case BOND_AD_COUNT:
-		if (__agg_active_ports(curr) > __agg_active_ports(best))
-			return curr;
-
-		if (__agg_active_ports(curr) < __agg_active_ports(best))
-			return best;
-
-		fallthrough;
-	case BOND_AD_STABLE:
-	case BOND_AD_BANDWIDTH:
-		if (__get_agg_bandwidth(curr) > __get_agg_bandwidth(best))
-			return curr;
-
-		break;
-
-	default:
-		net_warn_ratelimited("%s: (slave %s): Impossible agg select mode %d\n",
-				     curr->slave->bond->dev->name,
-				     curr->slave->dev->name,
-				     __get_agg_selection_mode(curr->lag_ports));
-		break;
-	}
-
-	return best;
-}
-
-static int agg_device_up(const struct aggregator *agg)
-{
-	struct port *port = agg->lag_ports;
-
-	if (!port)
-		return 0;
-
-	for (port = agg->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (netif_running(port->slave->dev) &&
-		    netif_carrier_ok(port->slave->dev))
-			return 1;
-	}
-
-	return 0;
-}
-
-/**
- * ad_agg_selection_logic - select an aggregation group for a team
- * @agg: the aggregator we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * It is assumed that only one aggregator may be selected for a team.
- *
- * The logic of this function is to select the aggregator according to
- * the ad_select policy:
- *
- * BOND_AD_STABLE: select the aggregator with the most ports attached to
- * it, and to reselect the active aggregator only if the previous
- * aggregator has no more ports related to it.
- *
- * BOND_AD_BANDWIDTH: select the aggregator with the highest total
- * bandwidth, and reselect whenever a link state change takes place or the
- * set of slaves in the bond changes.
- *
- * BOND_AD_COUNT: select the aggregator with largest number of ports
- * (slaves), and reselect whenever a link state change takes place or the
- * set of slaves in the bond changes.
- *
- * FIXME: this function MUST be called with the first agg in the bond, or
- * __get_active_agg() won't work correctly. This function should be better
- * called with the bond itself, and retrieve the first agg from it.
- */
-static void ad_agg_selection_logic(struct aggregator *agg,
-				   bool *update_slave_arr)
-{
-	struct aggregator *best, *active, *origin;
-	struct bonding *bond = agg->slave->bond;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-
-	rcu_read_lock();
-	origin = agg;
-	active = __get_active_agg(agg);
-	best = (active && agg_device_up(active)) ? active : NULL;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		agg = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		agg->is_active = 0;
-
-		if (__agg_active_ports(agg) && agg_device_up(agg))
-			best = ad_agg_selection_test(best, agg);
-	}
-
-	if (best &&
-	    __get_agg_selection_mode(best->lag_ports) == BOND_AD_STABLE) {
-		/* For the STABLE policy, don't replace the old active
-		 * aggregator if it's still active (it has an answering
-		 * partner) or if both the best and active don't have an
-		 * answering partner.
-		 */
-		if (active && active->lag_ports &&
-		    __agg_active_ports(active) &&
-		    (__agg_has_partner(active) ||
-		     (!__agg_has_partner(active) &&
-		     !__agg_has_partner(best)))) {
-			if (!(!active->actor_oper_aggregator_key &&
-			      best->actor_oper_aggregator_key)) {
-				best = NULL;
-				active->is_active = 1;
-			}
-		}
-	}
-
-	if (best && (best == active)) {
-		best = NULL;
-		active->is_active = 1;
-	}
-
-	/* if there is new best aggregator, activate it */
-	if (best) {
-		netdev_dbg(bond->dev, "(slave %s): best Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier, best->num_of_ports,
-			   best->actor_oper_aggregator_key,
-			   best->partner_oper_aggregator_key,
-			   best->is_individual, best->is_active);
-		netdev_dbg(bond->dev, "(slave %s): best ports %p slave %p\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->lag_ports, best->slave);
-
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			agg = &(SLAVE_AD_INFO(slave)->aggregator);
-
-			slave_dbg(bond->dev, slave->dev, "Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-				  agg->aggregator_identifier, agg->num_of_ports,
-				  agg->actor_oper_aggregator_key,
-				  agg->partner_oper_aggregator_key,
-				  agg->is_individual, agg->is_active);
-		}
-
-		/* check if any partner replies */
-		if (best->is_individual)
-			net_warn_ratelimited("%s: Warning: No 802.3ad response from the link partner for any adapters in the bond\n",
-					     bond->dev->name);
-
-		best->is_active = 1;
-		netdev_dbg(bond->dev, "(slave %s): LAG %d chosen as the active LAG\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier);
-		netdev_dbg(bond->dev, "(slave %s): Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier, best->num_of_ports,
-			   best->actor_oper_aggregator_key,
-			   best->partner_oper_aggregator_key,
-			   best->is_individual, best->is_active);
-
-		/* disable the ports that were related to the former
-		 * active_aggregator
-		 */
-		if (active) {
-			for (port = active->lag_ports; port;
-			     port = port->next_port_in_aggregator) {
-				__disable_port(port);
-			}
-		}
-		/* Slave array needs update. */
-		*update_slave_arr = true;
-	}
-
-	/* if the selected aggregator is of join individuals
-	 * (partner_system is NULL), enable their ports
-	 */
-	active = __get_active_agg(origin);
-
-	if (active) {
-		if (!__agg_has_partner(active)) {
-			for (port = active->lag_ports; port;
-			     port = port->next_port_in_aggregator) {
-				__enable_port(port);
-			}
-		}
-	}
-
-	rcu_read_unlock();
-
-	bond_3ad_set_carrier(bond);
-}
-
-/**
- * ad_clear_agg - clear a given aggregator's parameters
- * @aggregator: the aggregator we're looking at
- */
-static void ad_clear_agg(struct aggregator *aggregator)
-{
-	if (aggregator) {
-		aggregator->is_individual = false;
-		aggregator->actor_admin_aggregator_key = 0;
-		aggregator->actor_oper_aggregator_key = 0;
-		eth_zero_addr(aggregator->partner_system.mac_addr_value);
-		aggregator->partner_system_priority = 0;
-		aggregator->partner_oper_aggregator_key = 0;
-		aggregator->receive_state = 0;
-		aggregator->transmit_state = 0;
-		aggregator->lag_ports = NULL;
-		aggregator->is_active = 0;
-		aggregator->num_of_ports = 0;
-		pr_debug("%s: LAG %d was cleared\n",
-			 aggregator->slave ?
-			 aggregator->slave->dev->name : "NULL",
-			 aggregator->aggregator_identifier);
-	}
-}
-
-/**
- * ad_initialize_agg - initialize a given aggregator's parameters
- * @aggregator: the aggregator we're looking at
- */
-static void ad_initialize_agg(struct aggregator *aggregator)
-{
-	if (aggregator) {
-		ad_clear_agg(aggregator);
-
-		eth_zero_addr(aggregator->aggregator_mac_address.mac_addr_value);
-		aggregator->aggregator_identifier = 0;
-		aggregator->slave = NULL;
-	}
-}
-
-/**
- * ad_initialize_port - initialize a given port's parameters
- * @port: the port we're looking at
- * @lacp_fast: boolean. whether fast periodic should be used
- */
-static void ad_initialize_port(struct port *port, int lacp_fast)
-{
-	static const struct port_params tmpl = {
-		.system_priority = 0xffff,
-		.key             = 1,
-		.port_number     = 1,
-		.port_priority   = 0xff,
-		.port_state      = 1,
-	};
-	static const struct lacpdu lacpdu = {
-		.subtype		= 0x01,
-		.version_number = 0x01,
-		.tlv_type_actor_info = 0x01,
-		.actor_information_length = 0x14,
-		.tlv_type_partner_info = 0x02,
-		.partner_information_length = 0x14,
-		.tlv_type_collector_info = 0x03,
-		.collector_information_length = 0x10,
-		.collector_max_delay = htons(AD_COLLECTOR_MAX_DELAY),
-	};
-
-	if (port) {
-		port->actor_port_priority = 0xff;
-		port->actor_port_aggregator_identifier = 0;
-		port->ntt = false;
-		port->actor_admin_port_state = LACP_STATE_AGGREGATION |
-					       LACP_STATE_LACP_ACTIVITY;
-		port->actor_oper_port_state  = LACP_STATE_AGGREGATION |
-					       LACP_STATE_LACP_ACTIVITY;
-
-		if (lacp_fast)
-			port->actor_oper_port_state |= LACP_STATE_LACP_TIMEOUT;
-
-		memcpy(&port->partner_admin, &tmpl, sizeof(tmpl));
-		memcpy(&port->partner_oper, &tmpl, sizeof(tmpl));
-
-		port->is_enabled = true;
-		/* private parameters */
-		port->sm_vars = AD_PORT_BEGIN | AD_PORT_LACP_ENABLED;
-		port->sm_rx_state = 0;
-		port->sm_rx_timer_counter = 0;
-		port->sm_periodic_state = 0;
-		port->sm_periodic_timer_counter = 0;
-		port->sm_mux_state = 0;
-		port->sm_mux_timer_counter = 0;
-		port->sm_tx_state = 0;
-		port->aggregator = NULL;
-		port->next_port_in_aggregator = NULL;
-		port->transaction_id = 0;
-
-		port->sm_churn_actor_timer_counter = 0;
-		port->sm_churn_actor_state = 0;
-		port->churn_actor_count = 0;
-		port->sm_churn_partner_timer_counter = 0;
-		port->sm_churn_partner_state = 0;
-		port->churn_partner_count = 0;
-
-		memcpy(&port->lacpdu, &lacpdu, sizeof(lacpdu));
-	}
-}
-
-/**
- * ad_enable_collecting_distributing - enable a port's transmit/receive
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * Enable @port if it's in an active aggregator
- */
-static void ad_enable_collecting_distributing(struct port *port,
-					      bool *update_slave_arr)
-{
-	if (port->aggregator->is_active) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Enabling port %d (LAG %d)\n",
-			  port->actor_port_number,
-			  port->aggregator->aggregator_identifier);
-		__enable_port(port);
-		/* Slave array needs update */
-		*update_slave_arr = true;
-	}
-}
-
-/**
- * ad_disable_collecting_distributing - disable a port's transmit/receive
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- */
-static void ad_disable_collecting_distributing(struct port *port,
-					       bool *update_slave_arr)
-{
-	if (port->aggregator &&
-	    !MAC_ADDRESS_EQUAL(&(port->aggregator->partner_system),
-			       &(null_mac_addr))) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Disabling port %d (LAG %d)\n",
-			  port->actor_port_number,
-			  port->aggregator->aggregator_identifier);
-		__disable_port(port);
-		/* Slave array needs an update */
-		*update_slave_arr = true;
-	}
-}
-
-/**
- * ad_marker_info_received - handle receive of a Marker information frame
- * @marker_info: Marker info received
- * @port: the port we're looking at
- */
-static void ad_marker_info_received(struct bond_marker *marker_info,
-				    struct port *port)
-{
-	struct bond_marker marker;
-
-	atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.marker_rx);
-	atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.marker_rx);
-
-	/* copy the received marker data to the response marker */
-	memcpy(&marker, marker_info, sizeof(struct bond_marker));
-	/* change the marker subtype to marker response */
-	marker.tlv_type = AD_MARKER_RESPONSE_SUBTYPE;
-
-	/* send the marker response */
-	if (ad_marker_send(port, &marker) >= 0)
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Sent Marker Response on port %d\n",
-			  port->actor_port_number);
-}
-
-/**
- * ad_marker_response_received - handle receive of a marker response frame
- * @marker: marker PDU received
- * @port: the port we're looking at
- *
- * This function does nothing since we decided not to implement send and handle
- * response for marker PDU's, in this stage, but only to respond to marker
- * information.
- */
-static void ad_marker_response_received(struct bond_marker *marker,
-					struct port *port)
-{
-	atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.marker_resp_rx);
-	atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.marker_resp_rx);
-
-	/* DO NOTHING, SINCE WE DECIDED NOT TO IMPLEMENT THIS FEATURE FOR NOW */
-}
-
-/* ========= AD exported functions to the main bonding code ========= */
-
-/* Check aggregators status in team every T seconds */
-#define AD_AGGREGATOR_SELECTION_TIMER  8
-
-/**
- * bond_3ad_initiate_agg_selection - initate aggregator selection
- * @bond: bonding struct
- * @timeout: timeout value to set
- *
- * Set the aggregation selection timer, to initiate an agg selection in
- * the very near future.  Called during first initialization, and during
- * any down to up transitions of the bond.
- */
-void bond_3ad_initiate_agg_selection(struct bonding *bond, int timeout)
-{
-	BOND_AD_INFO(bond).agg_select_timer = timeout;
-}
-
-/**
- * bond_3ad_initialize - initialize a bond's 802.3ad parameters and structures
- * @bond: bonding struct to work on
- * @tick_resolution: tick duration (millisecond resolution)
- *
- * Can be called only after the mac address of the bond is set.
- */
-void bond_3ad_initialize(struct bonding *bond, u16 tick_resolution)
-{
-	/* check that the bond is not initialized yet */
-	if (!MAC_ADDRESS_EQUAL(&(BOND_AD_INFO(bond).system.sys_mac_addr),
-				bond->dev->dev_addr)) {
-
-		BOND_AD_INFO(bond).aggregator_identifier = 0;
-
-		BOND_AD_INFO(bond).system.sys_priority =
-			bond->params.ad_actor_sys_prio;
-		if (is_zero_ether_addr(bond->params.ad_actor_system))
-			BOND_AD_INFO(bond).system.sys_mac_addr =
-			    *((struct mac_addr *)bond->dev->dev_addr);
-		else
-			BOND_AD_INFO(bond).system.sys_mac_addr =
-			    *((struct mac_addr *)bond->params.ad_actor_system);
-
-		/* initialize how many times this module is called in one
-		 * second (should be about every 100ms)
-		 */
-		ad_ticks_per_sec = tick_resolution;
-
-		bond_3ad_initiate_agg_selection(bond,
-						AD_AGGREGATOR_SELECTION_TIMER *
-						ad_ticks_per_sec);
-	}
-}
-
-/**
- * bond_3ad_bind_slave - initialize a slave's port
- * @slave: slave struct to work on
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-void bond_3ad_bind_slave(struct slave *slave)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-	struct port *port;
-	struct aggregator *aggregator;
-
-	/* check that the slave has not been initialized yet. */
-	if (SLAVE_AD_INFO(slave)->port.slave != slave) {
-
-		/* port initialization */
-		port = &(SLAVE_AD_INFO(slave)->port);
-
-		ad_initialize_port(port, bond->params.lacp_fast);
-
-		port->slave = slave;
-		port->actor_port_number = SLAVE_AD_INFO(slave)->id;
-		/* key is determined according to the link speed, duplex and
-		 * user key
-		 */
-		port->actor_admin_port_key = bond->params.ad_user_port_key << 6;
-		ad_update_actor_keys(port, false);
-		/* actor system is the bond's system */
-		__ad_actor_update_port(port);
-		/* tx timer(to verify that no more than MAX_TX_IN_SECOND
-		 * lacpdu's are sent in one second)
-		 */
-		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
-
-		__disable_port(port);
-
-		/* aggregator initialization */
-		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		ad_initialize_agg(aggregator);
-
-		aggregator->aggregator_mac_address = *((struct mac_addr *)bond->dev->dev_addr);
-		aggregator->aggregator_identifier = ++BOND_AD_INFO(bond).aggregator_identifier;
-		aggregator->slave = slave;
-		aggregator->is_active = 0;
-		aggregator->num_of_ports = 0;
-	}
-}
-
-/**
- * bond_3ad_unbind_slave - deinitialize a slave's port
- * @slave: slave struct to work on
- *
- * Search for the aggregator that is related to this port, remove the
- * aggregator and assign another aggregator for other port related to it
- * (if any), and remove the port.
- */
-void bond_3ad_unbind_slave(struct slave *slave)
-{
-	struct port *port, *prev_port, *temp_port;
-	struct aggregator *aggregator, *new_aggregator, *temp_aggregator;
-	int select_new_active_agg = 0;
-	struct bonding *bond = slave->bond;
-	struct slave *slave_iter;
-	struct list_head *iter;
-	bool dummy_slave_update; /* Ignore this value as caller updates array */
-
-	/* Sync against bond_3ad_state_machine_handler() */
-	spin_lock_bh(&bond->mode_lock);
-	aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(bond->dev, slave->dev, "Trying to unbind an uninitialized port\n");
-		goto out;
-	}
-
-	slave_dbg(bond->dev, slave->dev, "Unbinding Link Aggregation Group %d\n",
-		  aggregator->aggregator_identifier);
-
-	/* Tell the partner that this port is not suitable for aggregation */
-	port->actor_oper_port_state &= ~LACP_STATE_SYNCHRONIZATION;
-	port->actor_oper_port_state &= ~LACP_STATE_COLLECTING;
-	port->actor_oper_port_state &= ~LACP_STATE_DISTRIBUTING;
-	port->actor_oper_port_state &= ~LACP_STATE_AGGREGATION;
-	__update_lacpdu_from_port(port);
-	ad_lacpdu_send(port);
-
-	/* check if this aggregator is occupied */
-	if (aggregator->lag_ports) {
-		/* check if there are other ports related to this aggregator
-		 * except the port related to this slave(thats ensure us that
-		 * there is a reason to search for new aggregator, and that we
-		 * will find one
-		 */
-		if ((aggregator->lag_ports != port) ||
-		    (aggregator->lag_ports->next_port_in_aggregator)) {
-			/* find new aggregator for the related port(s) */
-			bond_for_each_slave(bond, slave_iter, iter) {
-				new_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
-				/* if the new aggregator is empty, or it is
-				 * connected to our port only
-				 */
-				if (!new_aggregator->lag_ports ||
-				    ((new_aggregator->lag_ports == port) &&
-				     !new_aggregator->lag_ports->next_port_in_aggregator))
-					break;
-			}
-			if (!slave_iter)
-				new_aggregator = NULL;
-
-			/* if new aggregator found, copy the aggregator's
-			 * parameters and connect the related lag_ports to the
-			 * new aggregator
-			 */
-			if ((new_aggregator) && ((!new_aggregator->lag_ports) || ((new_aggregator->lag_ports == port) && !new_aggregator->lag_ports->next_port_in_aggregator))) {
-				slave_dbg(bond->dev, slave->dev, "Some port(s) related to LAG %d - replacing with LAG %d\n",
-					  aggregator->aggregator_identifier,
-					  new_aggregator->aggregator_identifier);
-
-				if ((new_aggregator->lag_ports == port) &&
-				    new_aggregator->is_active) {
-					slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-					select_new_active_agg = 1;
-				}
-
-				new_aggregator->is_individual = aggregator->is_individual;
-				new_aggregator->actor_admin_aggregator_key = aggregator->actor_admin_aggregator_key;
-				new_aggregator->actor_oper_aggregator_key = aggregator->actor_oper_aggregator_key;
-				new_aggregator->partner_system = aggregator->partner_system;
-				new_aggregator->partner_system_priority = aggregator->partner_system_priority;
-				new_aggregator->partner_oper_aggregator_key = aggregator->partner_oper_aggregator_key;
-				new_aggregator->receive_state = aggregator->receive_state;
-				new_aggregator->transmit_state = aggregator->transmit_state;
-				new_aggregator->lag_ports = aggregator->lag_ports;
-				new_aggregator->is_active = aggregator->is_active;
-				new_aggregator->num_of_ports = aggregator->num_of_ports;
-
-				/* update the information that is written on
-				 * the ports about the aggregator
-				 */
-				for (temp_port = aggregator->lag_ports; temp_port;
-				     temp_port = temp_port->next_port_in_aggregator) {
-					temp_port->aggregator = new_aggregator;
-					temp_port->actor_port_aggregator_identifier = new_aggregator->aggregator_identifier;
-				}
-
-				ad_clear_agg(aggregator);
-
-				if (select_new_active_agg)
-					ad_agg_selection_logic(__get_first_agg(port),
-							       &dummy_slave_update);
-			} else {
-				slave_warn(bond->dev, slave->dev, "unbinding aggregator, and could not find a new aggregator for its ports\n");
-			}
-		} else {
-			/* in case that the only port related to this
-			 * aggregator is the one we want to remove
-			 */
-			select_new_active_agg = aggregator->is_active;
-			ad_clear_agg(aggregator);
-			if (select_new_active_agg) {
-				slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-				/* select new active aggregator */
-				temp_aggregator = __get_first_agg(port);
-				if (temp_aggregator)
-					ad_agg_selection_logic(temp_aggregator,
-							       &dummy_slave_update);
-			}
-		}
-	}
-
-	slave_dbg(bond->dev, slave->dev, "Unbinding port %d\n", port->actor_port_number);
-
-	/* find the aggregator that this port is connected to */
-	bond_for_each_slave(bond, slave_iter, iter) {
-		temp_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
-		prev_port = NULL;
-		/* search the port in the aggregator's related ports */
-		for (temp_port = temp_aggregator->lag_ports; temp_port;
-		     prev_port = temp_port,
-		     temp_port = temp_port->next_port_in_aggregator) {
-			if (temp_port == port) {
-				/* the aggregator found - detach the port from
-				 * this aggregator
-				 */
-				if (prev_port)
-					prev_port->next_port_in_aggregator = temp_port->next_port_in_aggregator;
-				else
-					temp_aggregator->lag_ports = temp_port->next_port_in_aggregator;
-				temp_aggregator->num_of_ports--;
-				if (__agg_active_ports(temp_aggregator) == 0) {
-					select_new_active_agg = temp_aggregator->is_active;
-					ad_clear_agg(temp_aggregator);
-					if (select_new_active_agg) {
-						slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-						/* select new active aggregator */
-						ad_agg_selection_logic(__get_first_agg(port),
-							               &dummy_slave_update);
-					}
-				}
-				break;
-			}
-		}
-	}
-	port->slave = NULL;
-
-out:
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/**
- * bond_3ad_update_ad_actor_settings - reflect change of actor settings to ports
- * @bond: bonding struct to work on
- *
- * If an ad_actor setting gets changed we need to update the individual port
- * settings so the bond device will use the new values when it gets upped.
- */
-void bond_3ad_update_ad_actor_settings(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	ASSERT_RTNL();
-
-	BOND_AD_INFO(bond).system.sys_priority = bond->params.ad_actor_sys_prio;
-	if (is_zero_ether_addr(bond->params.ad_actor_system))
-		BOND_AD_INFO(bond).system.sys_mac_addr =
-		    *((struct mac_addr *)bond->dev->dev_addr);
-	else
-		BOND_AD_INFO(bond).system.sys_mac_addr =
-		    *((struct mac_addr *)bond->params.ad_actor_system);
-
-	spin_lock_bh(&bond->mode_lock);
-	bond_for_each_slave(bond, slave, iter) {
-		struct port *port = &(SLAVE_AD_INFO(slave))->port;
-
-		__ad_actor_update_port(port);
-		port->ntt = true;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/**
- * bond_3ad_state_machine_handler - handle state machines timeout
- * @work: work context to fetch bonding struct to work on from
- *
- * The state machine handling concept in this module is to check every tick
- * which state machine should operate any function. The execution order is
- * round robin, so when we have an interaction between state machines, the
- * reply of one to each other might be delayed until next tick.
- *
- * This function also complete the initialization when the agg_select_timer
- * times out, and it selects an aggregator for the ports that are yet not
- * related to any aggregator, and selects the active aggregator for a bond.
- */
-void bond_3ad_state_machine_handler(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    ad_work.work);
-	struct aggregator *aggregator;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
-	bool update_slave_arr = false;
-
-	/* Lock to protect data accessed by all (e.g., port->sm_vars) and
-	 * against running with bond_3ad_unbind_slave. ad_rx_machine may run
-	 * concurrently due to incoming LACPDU as well.
-	 */
-	spin_lock_bh(&bond->mode_lock);
-	rcu_read_lock();
-
-	/* check if there are any slaves */
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	/* check if agg_select_timer timer after initialize is timed out */
-	if (BOND_AD_INFO(bond).agg_select_timer &&
-	    !(--BOND_AD_INFO(bond).agg_select_timer)) {
-		slave = bond_first_slave_rcu(bond);
-		port = slave ? &(SLAVE_AD_INFO(slave)->port) : NULL;
-
-		/* select the active aggregator for the bond */
-		if (port) {
-			if (!port->slave) {
-				net_warn_ratelimited("%s: Warning: bond's first port is uninitialized\n",
-						     bond->dev->name);
-				goto re_arm;
-			}
-
-			aggregator = __get_first_agg(port);
-			ad_agg_selection_logic(aggregator, &update_slave_arr);
-		}
-		bond_3ad_set_carrier(bond);
-	}
-
-	/* for each port run the state machines */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (!port->slave) {
-			net_warn_ratelimited("%s: Warning: Found an uninitialized port\n",
-					    bond->dev->name);
-			goto re_arm;
-		}
-
-		ad_rx_machine(NULL, port);
-		ad_periodic_machine(port);
-		ad_port_selection_logic(port, &update_slave_arr);
-		ad_mux_machine(port, &update_slave_arr);
-		ad_tx_machine(port);
-		ad_churn_machine(port);
-
-		/* turn off the BEGIN bit, since we already handled it */
-		if (port->sm_vars & AD_PORT_BEGIN)
-			port->sm_vars &= ~AD_PORT_BEGIN;
-	}
-
-re_arm:
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->should_notify) {
-			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
-			break;
-		}
-	}
-	rcu_read_unlock();
-	spin_unlock_bh(&bond->mode_lock);
-
-	if (update_slave_arr)
-		bond_slave_arr_work_rearm(bond, 0);
-
-	if (should_notify_rtnl && rtnl_trylock()) {
-		bond_slave_state_notify(bond);
-		rtnl_unlock();
-	}
-	queue_delayed_work(bond->wq, &bond->ad_work, ad_delta_in_ticks);
-}
-
-/**
- * bond_3ad_rx_indication - handle a received frame
- * @lacpdu: received lacpdu
- * @slave: slave struct to work on
- *
- * It is assumed that frames that were sent on this NIC don't returned as new
- * received frames (loopback). Since only the payload is given to this
- * function, it check for loopback.
- */
-static int bond_3ad_rx_indication(struct lacpdu *lacpdu, struct slave *slave)
-{
-	struct bonding *bond = slave->bond;
-	int ret = RX_HANDLER_ANOTHER;
-	struct bond_marker *marker;
-	struct port *port;
-	atomic64_t *stat;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-	if (!port->slave) {
-		net_warn_ratelimited("%s: Warning: port of slave %s is uninitialized\n",
-				     slave->dev->name, slave->bond->dev->name);
-		return ret;
-	}
-
-	switch (lacpdu->subtype) {
-	case AD_TYPE_LACPDU:
-		ret = RX_HANDLER_CONSUMED;
-		slave_dbg(slave->bond->dev, slave->dev,
-			  "Received LACPDU on port %d\n",
-			  port->actor_port_number);
-		/* Protect against concurrent state machines */
-		spin_lock(&slave->bond->mode_lock);
-		ad_rx_machine(lacpdu, port);
-		spin_unlock(&slave->bond->mode_lock);
-		break;
-	case AD_TYPE_MARKER:
-		ret = RX_HANDLER_CONSUMED;
-		/* No need to convert fields to Little Endian since we
-		 * don't use the marker's fields.
-		 */
-		marker = (struct bond_marker *)lacpdu;
-		switch (marker->tlv_type) {
-		case AD_MARKER_INFORMATION_SUBTYPE:
-			slave_dbg(slave->bond->dev, slave->dev, "Received Marker Information on port %d\n",
-				  port->actor_port_number);
-			ad_marker_info_received(marker, port);
-			break;
-		case AD_MARKER_RESPONSE_SUBTYPE:
-			slave_dbg(slave->bond->dev, slave->dev, "Received Marker Response on port %d\n",
-				  port->actor_port_number);
-			ad_marker_response_received(marker, port);
-			break;
-		default:
-			slave_dbg(slave->bond->dev, slave->dev, "Received an unknown Marker subtype on port %d\n",
-				  port->actor_port_number);
-			stat = &SLAVE_AD_INFO(slave)->stats.marker_unknown_rx;
-			atomic64_inc(stat);
-			stat = &BOND_AD_INFO(bond).stats.marker_unknown_rx;
-			atomic64_inc(stat);
-		}
-		break;
-	default:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_unknown_rx);
-		atomic64_inc(&BOND_AD_INFO(bond).stats.lacpdu_unknown_rx);
-	}
-
-	return ret;
-}
-
-/**
- * ad_update_actor_keys - Update the oper / admin keys for a port based on
- * its current speed and duplex settings.
- *
- * @port: the port we'are looking at
- * @reset: Boolean to just reset the speed and the duplex part of the key
- *
- * The logic to change the oper / admin keys is:
- * (a) A full duplex port can participate in LACP with partner.
- * (b) When the speed is changed, LACP need to be reinitiated.
- */
-static void ad_update_actor_keys(struct port *port, bool reset)
-{
-	u8 duplex = 0;
-	u16 ospeed = 0, speed = 0;
-	u16 old_oper_key = port->actor_oper_port_key;
-
-	port->actor_admin_port_key &= ~(AD_SPEED_KEY_MASKS|AD_DUPLEX_KEY_MASKS);
-	if (!reset) {
-		speed = __get_link_speed(port);
-		ospeed = (old_oper_key & AD_SPEED_KEY_MASKS) >> 1;
-		duplex = __get_duplex(port);
-		port->actor_admin_port_key |= (speed << 1) | duplex;
-	}
-	port->actor_oper_port_key = port->actor_admin_port_key;
-
-	if (old_oper_key != port->actor_oper_port_key) {
-		/* Only 'duplex' port participates in LACP */
-		if (duplex)
-			port->sm_vars |= AD_PORT_LACP_ENABLED;
-		else
-			port->sm_vars &= ~AD_PORT_LACP_ENABLED;
-
-		if (!reset) {
-			if (!speed) {
-				slave_err(port->slave->bond->dev,
-					  port->slave->dev,
-					  "speed changed to 0 on port %d\n",
-					  port->actor_port_number);
-			} else if (duplex && ospeed != speed) {
-				/* Speed change restarts LACP state-machine */
-				port->sm_vars |= AD_PORT_BEGIN;
-			}
-		}
-	}
-}
-
-/**
- * bond_3ad_adapter_speed_duplex_changed - handle a slave's speed / duplex
- * change indication
- *
- * @slave: slave struct to work on
- *
- * Handle reselection of aggregator (if needed) for this port.
- */
-void bond_3ad_adapter_speed_duplex_changed(struct slave *slave)
-{
-	struct port *port;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(slave->bond->dev, slave->dev,
-			   "speed/duplex changed for uninitialized port\n");
-		return;
-	}
-
-	spin_lock_bh(&slave->bond->mode_lock);
-	ad_update_actor_keys(port, false);
-	spin_unlock_bh(&slave->bond->mode_lock);
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d changed speed/duplex\n",
-		  port->actor_port_number);
-}
-
-/**
- * bond_3ad_handle_link_change - handle a slave's link status change indication
- * @slave: slave struct to work on
- * @link: whether the link is now up or down
- *
- * Handle reselection of aggregator (if needed) for this port.
- */
-void bond_3ad_handle_link_change(struct slave *slave, char link)
-{
-	struct aggregator *agg;
-	struct port *port;
-	bool dummy;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(slave->bond->dev, slave->dev, "link status changed for uninitialized port\n");
-		return;
-	}
-
-	spin_lock_bh(&slave->bond->mode_lock);
-	/* on link down we are zeroing duplex and speed since
-	 * some of the adaptors(ce1000.lan) report full duplex/speed
-	 * instead of N/A(duplex) / 0(speed).
-	 *
-	 * on link up we are forcing recheck on the duplex and speed since
-	 * some of he adaptors(ce1000.lan) report.
-	 */
-	if (link == BOND_LINK_UP) {
-		port->is_enabled = true;
-		ad_update_actor_keys(port, false);
-	} else {
-		/* link has failed */
-		port->is_enabled = false;
-		ad_update_actor_keys(port, true);
-		toe_failover(netdev_master_upper_dev_get(slave->dev),
-			     slave->dev, TOE_LINK_DOWN, NULL);
-	}
-	agg = __get_first_agg(port);
-	ad_agg_selection_logic(agg, &dummy);
-
-	spin_unlock_bh(&slave->bond->mode_lock);
-
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d changed link status to %s\n",
-		  port->actor_port_number,
-		  link == BOND_LINK_UP ? "UP" : "DOWN");
-
-	/* RTNL is held and mode_lock is released so it's safe
-	 * to update slave_array here.
-	 */
-	bond_update_slave_arr(slave->bond, NULL);
-}
-
-/**
- * bond_3ad_set_carrier - set link state for bonding master
- * @bond: bonding structure
- *
- * if we have an active aggregator, we're up, if not, we're down.
- * Presumes that we cannot have an active aggregator if there are
- * no slaves with link up.
- *
- * This behavior complies with IEEE 802.3 section 43.3.9.
- *
- * Called by bond_set_carrier(). Return zero if carrier state does not
- * change, nonzero if it does.
- */
-int bond_3ad_set_carrier(struct bonding *bond)
-{
-	struct aggregator *active;
-	struct slave *first_slave;
-	int ret = 1;
-
-	rcu_read_lock();
-	first_slave = bond_first_slave_rcu(bond);
-	if (!first_slave) {
-		ret = 0;
-		goto out;
-	}
-	active = __get_active_agg(&(SLAVE_AD_INFO(first_slave)->aggregator));
-	if (active) {
-		/* are enough slaves available to consider link up? */
-		if (__agg_active_ports(active) < bond->params.min_links) {
-			if (netif_carrier_ok(bond->dev)) {
-				netif_carrier_off(bond->dev);
-				goto out;
-			}
-		} else if (!netif_carrier_ok(bond->dev)) {
-			netif_carrier_on(bond->dev);
-			goto out;
-		}
-	} else if (netif_carrier_ok(bond->dev)) {
-		netif_carrier_off(bond->dev);
-	}
-out:
-	rcu_read_unlock();
-	return ret;
-}
-
-/**
- * __bond_3ad_get_active_agg_info - get information of the active aggregator
- * @bond: bonding struct to work on
- * @ad_info: ad_info struct to fill with the bond's info
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-int __bond_3ad_get_active_agg_info(struct bonding *bond,
-				   struct ad_info *ad_info)
-{
-	struct aggregator *aggregator = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (port->aggregator && port->aggregator->is_active) {
-			aggregator = port->aggregator;
-			break;
-		}
-	}
-
-	if (!aggregator)
-		return -1;
-
-	ad_info->aggregator_id = aggregator->aggregator_identifier;
-	ad_info->ports = __agg_active_ports(aggregator);
-	ad_info->actor_key = aggregator->actor_oper_aggregator_key;
-	ad_info->partner_key = aggregator->partner_oper_aggregator_key;
-	ether_addr_copy(ad_info->partner_system,
-			aggregator->partner_system.mac_addr_value);
-	return 0;
-}
-
-int bond_3ad_get_active_agg_info(struct bonding *bond, struct ad_info *ad_info)
-{
-	int ret;
-
-	rcu_read_lock();
-	ret = __bond_3ad_get_active_agg_info(bond, ad_info);
-	rcu_read_unlock();
-
-	return ret;
-}
-
-int bond_3ad_lacpdu_recv(const struct sk_buff *skb, struct bonding *bond,
-			 struct slave *slave)
-{
-	struct lacpdu *lacpdu, _lacpdu;
-
-	if (skb->protocol != PKT_TYPE_LACPDU)
-		return RX_HANDLER_ANOTHER;
-
-	if (!MAC_ADDRESS_EQUAL(eth_hdr(skb)->h_dest, lacpdu_mcast_addr))
-		return RX_HANDLER_ANOTHER;
-
-	lacpdu = skb_header_pointer(skb, 0, sizeof(_lacpdu), &_lacpdu);
-	if (!lacpdu) {
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_illegal_rx);
-		atomic64_inc(&BOND_AD_INFO(bond).stats.lacpdu_illegal_rx);
-		return RX_HANDLER_ANOTHER;
-	}
-
-	return bond_3ad_rx_indication(lacpdu, slave);
-}
-
-/**
- * bond_3ad_update_lacp_rate - change the lacp rate
- * @bond: bonding struct
- *
- * When modify lacp_rate parameter via sysfs,
- * update actor_oper_port_state of each port.
- *
- * Hold bond->mode_lock,
- * so we can modify port->actor_oper_port_state,
- * no matter bond is up or down.
- */
-void bond_3ad_update_lacp_rate(struct bonding *bond)
-{
-	struct port *port = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	int lacp_fast;
-
-	lacp_fast = bond->params.lacp_fast;
-	spin_lock_bh(&bond->mode_lock);
-	bond_for_each_slave(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (lacp_fast)
-			port->actor_oper_port_state |= LACP_STATE_LACP_TIMEOUT;
-		else
-			port->actor_oper_port_state &= ~LACP_STATE_LACP_TIMEOUT;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-size_t bond_3ad_stats_size(void)
-{
-	return nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_TX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_UNKNOWN_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_ILLEGAL_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_TX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RESP_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RESP_TX */
-	       nla_total_size_64bit(sizeof(u64)); /* BOND_3AD_STAT_MARKER_UNKNOWN_RX */
-}
-
-int bond_3ad_stats_fill(struct sk_buff *skb, struct bond_3ad_stats *stats)
-{
-	u64 val;
-
-	val = atomic64_read(&stats->lacpdu_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_unknown_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_UNKNOWN_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_illegal_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_ILLEGAL_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-
-	val = atomic64_read(&stats->marker_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_resp_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RESP_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_resp_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RESP_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_unknown_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_UNKNOWN_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-
-	return 0;
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.10.0/bond_alb.c
--- a/src/network/bonding/BONDING_KDIRS/5.10.0/bond_alb.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1828 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
- */
-
-#include <linux/skbuff.h>
-#include <linux/netdevice.h>
-#include <linux/etherdevice.h>
-#include <linux/pkt_sched.h>
-#include <linux/spinlock.h>
-#include <linux/slab.h>
-#include <linux/timer.h>
-#include <linux/ip.h>
-#include <linux/ipv6.h>
-#include <linux/if_arp.h>
-#include <linux/if_ether.h>
-#include <linux/if_bonding.h>
-#include <linux/if_vlan.h>
-#include <linux/in.h>
-#include <net/ipx.h>
-#include <net/arp.h>
-#include <net/ipv6.h>
-#include <asm/byteorder.h>
-#include <net/bonding.h>
-#include <net/bond_alb.h>
-
-static const u8 mac_v6_allmcast[ETH_ALEN + 2] __long_aligned = {
-	0x33, 0x33, 0x00, 0x00, 0x00, 0x01
-};
-static const int alb_delta_in_ticks = HZ / ALB_TIMER_TICKS_PER_SEC;
-
-#pragma pack(1)
-struct learning_pkt {
-	u8 mac_dst[ETH_ALEN];
-	u8 mac_src[ETH_ALEN];
-	__be16 type;
-	u8 padding[ETH_ZLEN - ETH_HLEN];
-};
-
-struct arp_pkt {
-	__be16  hw_addr_space;
-	__be16  prot_addr_space;
-	u8      hw_addr_len;
-	u8      prot_addr_len;
-	__be16  op_code;
-	u8      mac_src[ETH_ALEN];	/* sender hardware address */
-	__be32  ip_src;			/* sender IP address */
-	u8      mac_dst[ETH_ALEN];	/* target hardware address */
-	__be32  ip_dst;			/* target IP address */
-};
-#pragma pack()
-
-/* Forward declaration */
-static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
-				      bool strict_match);
-static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp);
-static void rlb_src_unlink(struct bonding *bond, u32 index);
-static void rlb_src_link(struct bonding *bond, u32 ip_src_hash,
-			 u32 ip_dst_hash);
-
-static inline u8 _simple_hash(const u8 *hash_start, int hash_size)
-{
-	int i;
-	u8 hash = 0;
-
-	for (i = 0; i < hash_size; i++)
-		hash ^= hash_start[i];
-
-	return hash;
-}
-
-/*********************** tlb specific functions ***************************/
-
-static inline void tlb_init_table_entry(struct tlb_client_info *entry, int save_load)
-{
-	if (save_load) {
-		entry->load_history = 1 + entry->tx_bytes /
-				      BOND_TLB_REBALANCE_INTERVAL;
-		entry->tx_bytes = 0;
-	}
-
-	entry->tx_slave = NULL;
-	entry->next = TLB_NULL_INDEX;
-	entry->prev = TLB_NULL_INDEX;
-}
-
-static inline void tlb_init_slave(struct slave *slave)
-{
-	SLAVE_TLB_INFO(slave).load = 0;
-	SLAVE_TLB_INFO(slave).head = TLB_NULL_INDEX;
-}
-
-static void __tlb_clear_slave(struct bonding *bond, struct slave *slave,
-			 int save_load)
-{
-	struct tlb_client_info *tx_hash_table;
-	u32 index;
-
-	/* clear slave from tx_hashtbl */
-	tx_hash_table = BOND_ALB_INFO(bond).tx_hashtbl;
-
-	/* skip this if we've already freed the tx hash table */
-	if (tx_hash_table) {
-		index = SLAVE_TLB_INFO(slave).head;
-		while (index != TLB_NULL_INDEX) {
-			u32 next_index = tx_hash_table[index].next;
-			tlb_init_table_entry(&tx_hash_table[index], save_load);
-			index = next_index;
-		}
-	}
-
-	tlb_init_slave(slave);
-}
-
-static void tlb_clear_slave(struct bonding *bond, struct slave *slave,
-			 int save_load)
-{
-	spin_lock_bh(&bond->mode_lock);
-	__tlb_clear_slave(bond, slave, save_load);
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* Must be called before starting the monitor timer */
-static int tlb_initialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	int size = TLB_HASH_TABLE_SIZE * sizeof(struct tlb_client_info);
-	struct tlb_client_info *new_hashtbl;
-	int i;
-
-	new_hashtbl = kzalloc(size, GFP_KERNEL);
-	if (!new_hashtbl)
-		return -ENOMEM;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	bond_info->tx_hashtbl = new_hashtbl;
-
-	for (i = 0; i < TLB_HASH_TABLE_SIZE; i++)
-		tlb_init_table_entry(&bond_info->tx_hashtbl[i], 0);
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	return 0;
-}
-
-/* Must be called only after all slaves have been released */
-static void tlb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	spin_lock_bh(&bond->mode_lock);
-
-	kfree(bond_info->tx_hashtbl);
-	bond_info->tx_hashtbl = NULL;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static long long compute_gap(struct slave *slave)
-{
-	return (s64) (slave->speed << 20) - /* Convert to Megabit per sec */
-	       (s64) (SLAVE_TLB_INFO(slave).load << 3); /* Bytes to bits */
-}
-
-static struct slave *tlb_get_least_loaded_slave(struct bonding *bond)
-{
-	struct slave *slave, *least_loaded;
-	struct list_head *iter;
-	long long max_gap;
-
-	least_loaded = NULL;
-	max_gap = LLONG_MIN;
-
-	/* Find the slave with the largest gap */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (bond_slave_can_tx(slave)) {
-			long long gap = compute_gap(slave);
-
-			if (max_gap < gap) {
-				least_loaded = slave;
-				max_gap = gap;
-			}
-		}
-	}
-
-	return least_loaded;
-}
-
-static struct slave *__tlb_choose_channel(struct bonding *bond, u32 hash_index,
-						u32 skb_len)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct tlb_client_info *hash_table;
-	struct slave *assigned_slave;
-
-	hash_table = bond_info->tx_hashtbl;
-	assigned_slave = hash_table[hash_index].tx_slave;
-	if (!assigned_slave) {
-		assigned_slave = tlb_get_least_loaded_slave(bond);
-
-		if (assigned_slave) {
-			struct tlb_slave_info *slave_info =
-				&(SLAVE_TLB_INFO(assigned_slave));
-			u32 next_index = slave_info->head;
-
-			hash_table[hash_index].tx_slave = assigned_slave;
-			hash_table[hash_index].next = next_index;
-			hash_table[hash_index].prev = TLB_NULL_INDEX;
-
-			if (next_index != TLB_NULL_INDEX)
-				hash_table[next_index].prev = hash_index;
-
-			slave_info->head = hash_index;
-			slave_info->load +=
-				hash_table[hash_index].load_history;
-		}
-	}
-
-	if (assigned_slave)
-		hash_table[hash_index].tx_bytes += skb_len;
-
-	return assigned_slave;
-}
-
-static struct slave *tlb_choose_channel(struct bonding *bond, u32 hash_index,
-					u32 skb_len)
-{
-	struct slave *tx_slave;
-
-	/* We don't need to disable softirq here, becase
-	 * tlb_choose_channel() is only called by bond_alb_xmit()
-	 * which already has softirq disabled.
-	 */
-	spin_lock(&bond->mode_lock);
-	tx_slave = __tlb_choose_channel(bond, hash_index, skb_len);
-	spin_unlock(&bond->mode_lock);
-
-	return tx_slave;
-}
-
-/*********************** rlb specific functions ***************************/
-
-/* when an ARP REPLY is received from a client update its info
- * in the rx_hashtbl
- */
-static void rlb_update_entry_from_arp(struct bonding *bond, struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
-	client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-	if ((client_info->assigned) &&
-	    (client_info->ip_src == arp->ip_dst) &&
-	    (client_info->ip_dst == arp->ip_src) &&
-	    (!ether_addr_equal_64bits(client_info->mac_dst, arp->mac_src))) {
-		/* update the clients MAC address */
-		ether_addr_copy(client_info->mac_dst, arp->mac_src);
-		client_info->ntt = 1;
-		bond_info->rx_ntt = 1;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static int rlb_arp_recv(const struct sk_buff *skb, struct bonding *bond,
-			struct slave *slave)
-{
-	struct arp_pkt *arp, _arp;
-
-	if (skb->protocol != cpu_to_be16(ETH_P_ARP))
-		goto out;
-
-	arp = skb_header_pointer(skb, 0, sizeof(_arp), &_arp);
-	if (!arp)
-		goto out;
-
-	/* We received an ARP from arp->ip_src.
-	 * We might have used this IP address previously (on the bonding host
-	 * itself or on a system that is bridged together with the bond).
-	 * However, if arp->mac_src is different than what is stored in
-	 * rx_hashtbl, some other host is now using the IP and we must prevent
-	 * sending out client updates with this IP address and the old MAC
-	 * address.
-	 * Clean up all hash table entries that have this address as ip_src but
-	 * have a different mac_src.
-	 */
-	rlb_purge_src_ip(bond, arp);
-
-	if (arp->op_code == htons(ARPOP_REPLY)) {
-		/* update rx hash table for this ARP */
-		rlb_update_entry_from_arp(bond, arp);
-		slave_dbg(bond->dev, slave->dev, "Server received an ARP Reply from client\n");
-	}
-out:
-	return RX_HANDLER_ANOTHER;
-}
-
-/* Caller must hold rcu_read_lock() */
-static struct slave *__rlb_next_rx_slave(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *before = NULL, *rx_slave = NULL, *slave;
-	struct list_head *iter;
-	bool found = false;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!bond_slave_can_tx(slave))
-			continue;
-		if (!found) {
-			if (!before || before->speed < slave->speed)
-				before = slave;
-		} else {
-			if (!rx_slave || rx_slave->speed < slave->speed)
-				rx_slave = slave;
-		}
-		if (slave == bond_info->rx_slave)
-			found = true;
-	}
-	/* we didn't find anything after the current or we have something
-	 * better before and up to the current slave
-	 */
-	if (!rx_slave || (before && rx_slave->speed < before->speed))
-		rx_slave = before;
-
-	if (rx_slave)
-		bond_info->rx_slave = rx_slave;
-
-	return rx_slave;
-}
-
-/* Caller must hold RTNL, rcu_read_lock is obtained only to silence checkers */
-static struct slave *rlb_next_rx_slave(struct bonding *bond)
-{
-	struct slave *rx_slave;
-
-	ASSERT_RTNL();
-
-	rcu_read_lock();
-	rx_slave = __rlb_next_rx_slave(bond);
-	rcu_read_unlock();
-
-	return rx_slave;
-}
-
-/* teach the switch the mac of a disabled slave
- * on the primary for fault tolerance
- *
- * Caller must hold RTNL
- */
-static void rlb_teach_disabled_mac_on_primary(struct bonding *bond, u8 addr[])
-{
-	struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-	if (!curr_active)
-		return;
-
-	if (!bond->alb_info.primary_is_promisc) {
-		if (!dev_set_promiscuity(curr_active->dev, 1))
-			bond->alb_info.primary_is_promisc = 1;
-		else
-			bond->alb_info.primary_is_promisc = 0;
-	}
-
-	bond->alb_info.rlb_promisc_timeout_counter = 0;
-
-	alb_send_learning_packets(curr_active, addr, true);
-}
-
-/* slave being removed should not be active at this point
- *
- * Caller must hold rtnl.
- */
-static void rlb_clear_slave(struct bonding *bond, struct slave *slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *rx_hash_table;
-	u32 index, next_index;
-
-	/* clear slave from rx_hashtbl */
-	spin_lock_bh(&bond->mode_lock);
-
-	rx_hash_table = bond_info->rx_hashtbl;
-	index = bond_info->rx_hashtbl_used_head;
-	for (; index != RLB_NULL_INDEX; index = next_index) {
-		next_index = rx_hash_table[index].used_next;
-		if (rx_hash_table[index].slave == slave) {
-			struct slave *assigned_slave = rlb_next_rx_slave(bond);
-
-			if (assigned_slave) {
-				rx_hash_table[index].slave = assigned_slave;
-				if (is_valid_ether_addr(rx_hash_table[index].mac_dst)) {
-					bond_info->rx_hashtbl[index].ntt = 1;
-					bond_info->rx_ntt = 1;
-					/* A slave has been removed from the
-					 * table because it is either disabled
-					 * or being released. We must retry the
-					 * update to avoid clients from not
-					 * being updated & disconnecting when
-					 * there is stress
-					 */
-					bond_info->rlb_update_retry_counter =
-						RLB_UPDATE_RETRY;
-				}
-			} else {  /* there is no active slave */
-				rx_hash_table[index].slave = NULL;
-			}
-		}
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	if (slave != rtnl_dereference(bond->curr_active_slave))
-		rlb_teach_disabled_mac_on_primary(bond, slave->dev->dev_addr);
-}
-
-static void rlb_update_client(struct rlb_client_info *client_info)
-{
-	int i;
-
-	if (!client_info->slave || !is_valid_ether_addr(client_info->mac_dst))
-		return;
-
-	for (i = 0; i < RLB_ARP_BURST_SIZE; i++) {
-		struct sk_buff *skb;
-
-		skb = arp_create(ARPOP_REPLY, ETH_P_ARP,
-				 client_info->ip_dst,
-				 client_info->slave->dev,
-				 client_info->ip_src,
-				 client_info->mac_dst,
-				 client_info->slave->dev->dev_addr,
-				 client_info->mac_dst);
-		if (!skb) {
-			slave_err(client_info->slave->bond->dev,
-				  client_info->slave->dev,
-				  "failed to create an ARP packet\n");
-			continue;
-		}
-
-		skb->dev = client_info->slave->dev;
-
-		if (client_info->vlan_id) {
-			__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),
-					       client_info->vlan_id);
-		}
-
-		arp_xmit(skb);
-	}
-}
-
-/* sends ARP REPLIES that update the clients that need updating */
-static void rlb_update_rx_clients(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		if (client_info->ntt) {
-			rlb_update_client(client_info);
-			if (bond_info->rlb_update_retry_counter == 0)
-				client_info->ntt = 0;
-		}
-	}
-
-	/* do not update the entries again until this counter is zero so that
-	 * not to confuse the clients.
-	 */
-	bond_info->rlb_update_delay_counter = RLB_UPDATE_DELAY;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* The slave was assigned a new mac address - update the clients */
-static void rlb_req_update_slave_clients(struct bonding *bond, struct slave *slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	int ntt = 0;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-		if ((client_info->slave == slave) &&
-		    is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			ntt = 1;
-		}
-	}
-
-	/* update the team's flag only after the whole iteration */
-	if (ntt) {
-		bond_info->rx_ntt = 1;
-		/* fasten the change */
-		bond_info->rlb_update_retry_counter = RLB_UPDATE_RETRY;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* mark all clients using src_ip to be updated */
-static void rlb_req_update_subnet_clients(struct bonding *bond, __be32 src_ip)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-		if (!client_info->slave) {
-			netdev_err(bond->dev, "found a client with no channel in the client's hash table\n");
-			continue;
-		}
-		/* update all clients using this src_ip, that are not assigned
-		 * to the team's address (curr_active_slave) and have a known
-		 * unicast mac address.
-		 */
-		if ((client_info->ip_src == src_ip) &&
-		    !ether_addr_equal_64bits(client_info->slave->dev->dev_addr,
-					     bond->dev->dev_addr) &&
-		    is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			bond_info->rx_ntt = 1;
-		}
-	}
-
-	spin_unlock(&bond->mode_lock);
-}
-
-static struct slave *rlb_choose_channel(struct sk_buff *skb,
-					struct bonding *bond,
-					const struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *assigned_slave, *curr_active_slave;
-	struct rlb_client_info *client_info;
-	u32 hash_index = 0;
-
-	spin_lock(&bond->mode_lock);
-
-	curr_active_slave = rcu_dereference(bond->curr_active_slave);
-
-	hash_index = _simple_hash((u8 *)&arp->ip_dst, sizeof(arp->ip_dst));
-	client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-	if (client_info->assigned) {
-		if ((client_info->ip_src == arp->ip_src) &&
-		    (client_info->ip_dst == arp->ip_dst)) {
-			/* the entry is already assigned to this client */
-			if (!is_broadcast_ether_addr(arp->mac_dst)) {
-				/* update mac address from arp */
-				ether_addr_copy(client_info->mac_dst, arp->mac_dst);
-			}
-			ether_addr_copy(client_info->mac_src, arp->mac_src);
-
-			assigned_slave = client_info->slave;
-			if (assigned_slave) {
-				spin_unlock(&bond->mode_lock);
-				return assigned_slave;
-			}
-		} else {
-			/* the entry is already assigned to some other client,
-			 * move the old client to primary (curr_active_slave) so
-			 * that the new client can be assigned to this entry.
-			 */
-			if (curr_active_slave &&
-			    client_info->slave != curr_active_slave) {
-				client_info->slave = curr_active_slave;
-				rlb_update_client(client_info);
-			}
-		}
-	}
-	/* assign a new slave */
-	assigned_slave = __rlb_next_rx_slave(bond);
-
-	if (assigned_slave) {
-		if (!(client_info->assigned &&
-		      client_info->ip_src == arp->ip_src)) {
-			/* ip_src is going to be updated,
-			 * fix the src hash list
-			 */
-			u32 hash_src = _simple_hash((u8 *)&arp->ip_src,
-						    sizeof(arp->ip_src));
-			rlb_src_unlink(bond, hash_index);
-			rlb_src_link(bond, hash_src, hash_index);
-		}
-
-		client_info->ip_src = arp->ip_src;
-		client_info->ip_dst = arp->ip_dst;
-		/* arp->mac_dst is broadcast for arp reqeusts.
-		 * will be updated with clients actual unicast mac address
-		 * upon receiving an arp reply.
-		 */
-		ether_addr_copy(client_info->mac_dst, arp->mac_dst);
-		ether_addr_copy(client_info->mac_src, arp->mac_src);
-		client_info->slave = assigned_slave;
-
-		if (is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			bond->alb_info.rx_ntt = 1;
-		} else {
-			client_info->ntt = 0;
-		}
-
-		if (vlan_get_tag(skb, &client_info->vlan_id))
-			client_info->vlan_id = 0;
-
-		if (!client_info->assigned) {
-			u32 prev_tbl_head = bond_info->rx_hashtbl_used_head;
-			bond_info->rx_hashtbl_used_head = hash_index;
-			client_info->used_next = prev_tbl_head;
-			if (prev_tbl_head != RLB_NULL_INDEX) {
-				bond_info->rx_hashtbl[prev_tbl_head].used_prev =
-					hash_index;
-			}
-			client_info->assigned = 1;
-		}
-	}
-
-	spin_unlock(&bond->mode_lock);
-
-	return assigned_slave;
-}
-
-/* chooses (and returns) transmit channel for arp reply
- * does not choose channel for other arp types since they are
- * sent on the curr_active_slave
- */
-static struct slave *rlb_arp_xmit(struct sk_buff *skb, struct bonding *bond)
-{
-	struct slave *tx_slave = NULL;
-	struct arp_pkt *arp;
-
-	if (!pskb_network_may_pull(skb, sizeof(*arp)))
-		return NULL;
-	arp = (struct arp_pkt *)skb_network_header(skb);
-
-	/* Don't modify or load balance ARPs that do not originate locally
-	 * (e.g.,arrive via a bridge).
-	 */
-	if (!bond_slave_has_mac_rx(bond, arp->mac_src))
-		return NULL;
-
-	if (arp->op_code == htons(ARPOP_REPLY)) {
-		/* the arp must be sent on the selected rx channel */
-		tx_slave = rlb_choose_channel(skb, bond, arp);
-		if (tx_slave)
-			bond_hw_addr_copy(arp->mac_src, tx_slave->dev->dev_addr,
-					  tx_slave->dev->addr_len);
-		netdev_dbg(bond->dev, "(slave %s): Server sent ARP Reply packet\n",
-			   tx_slave ? tx_slave->dev->name : "NULL");
-	} else if (arp->op_code == htons(ARPOP_REQUEST)) {
-		/* Create an entry in the rx_hashtbl for this client as a
-		 * place holder.
-		 * When the arp reply is received the entry will be updated
-		 * with the correct unicast address of the client.
-		 */
-		tx_slave = rlb_choose_channel(skb, bond, arp);
-
-		/* The ARP reply packets must be delayed so that
-		 * they can cancel out the influence of the ARP request.
-		 */
-		bond->alb_info.rlb_update_delay_counter = RLB_UPDATE_DELAY;
-
-		/* arp requests are broadcast and are sent on the primary
-		 * the arp request will collapse all clients on the subnet to
-		 * the primary slave. We must register these clients to be
-		 * updated with their assigned mac.
-		 */
-		rlb_req_update_subnet_clients(bond, arp->ip_src);
-		netdev_dbg(bond->dev, "(slave %s): Server sent ARP Request packet\n",
-			   tx_slave ? tx_slave->dev->name : "NULL");
-	}
-
-	return tx_slave;
-}
-
-static void rlb_rebalance(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *assigned_slave;
-	struct rlb_client_info *client_info;
-	int ntt;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	ntt = 0;
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		assigned_slave = __rlb_next_rx_slave(bond);
-		if (assigned_slave && (client_info->slave != assigned_slave)) {
-			client_info->slave = assigned_slave;
-			if (!is_zero_ether_addr(client_info->mac_dst)) {
-				client_info->ntt = 1;
-				ntt = 1;
-			}
-		}
-	}
-
-	/* update the team's flag only after the whole iteration */
-	if (ntt)
-		bond_info->rx_ntt = 1;
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* Caller must hold mode_lock */
-static void rlb_init_table_entry_dst(struct rlb_client_info *entry)
-{
-	entry->used_next = RLB_NULL_INDEX;
-	entry->used_prev = RLB_NULL_INDEX;
-	entry->assigned = 0;
-	entry->slave = NULL;
-	entry->vlan_id = 0;
-}
-static void rlb_init_table_entry_src(struct rlb_client_info *entry)
-{
-	entry->src_first = RLB_NULL_INDEX;
-	entry->src_prev = RLB_NULL_INDEX;
-	entry->src_next = RLB_NULL_INDEX;
-}
-
-static void rlb_init_table_entry(struct rlb_client_info *entry)
-{
-	memset(entry, 0, sizeof(struct rlb_client_info));
-	rlb_init_table_entry_dst(entry);
-	rlb_init_table_entry_src(entry);
-}
-
-static void rlb_delete_table_entry_dst(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next_index = bond_info->rx_hashtbl[index].used_next;
-	u32 prev_index = bond_info->rx_hashtbl[index].used_prev;
-
-	if (index == bond_info->rx_hashtbl_used_head)
-		bond_info->rx_hashtbl_used_head = next_index;
-	if (prev_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[prev_index].used_next = next_index;
-	if (next_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next_index].used_prev = prev_index;
-}
-
-/* unlink a rlb hash table entry from the src list */
-static void rlb_src_unlink(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next_index = bond_info->rx_hashtbl[index].src_next;
-	u32 prev_index = bond_info->rx_hashtbl[index].src_prev;
-
-	bond_info->rx_hashtbl[index].src_next = RLB_NULL_INDEX;
-	bond_info->rx_hashtbl[index].src_prev = RLB_NULL_INDEX;
-
-	if (next_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next_index].src_prev = prev_index;
-
-	if (prev_index == RLB_NULL_INDEX)
-		return;
-
-	/* is prev_index pointing to the head of this list? */
-	if (bond_info->rx_hashtbl[prev_index].src_first == index)
-		bond_info->rx_hashtbl[prev_index].src_first = next_index;
-	else
-		bond_info->rx_hashtbl[prev_index].src_next = next_index;
-
-}
-
-static void rlb_delete_table_entry(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
-
-	rlb_delete_table_entry_dst(bond, index);
-	rlb_init_table_entry_dst(entry);
-
-	rlb_src_unlink(bond, index);
-}
-
-/* add the rx_hashtbl[ip_dst_hash] entry to the list
- * of entries with identical ip_src_hash
- */
-static void rlb_src_link(struct bonding *bond, u32 ip_src_hash, u32 ip_dst_hash)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next;
-
-	bond_info->rx_hashtbl[ip_dst_hash].src_prev = ip_src_hash;
-	next = bond_info->rx_hashtbl[ip_src_hash].src_first;
-	bond_info->rx_hashtbl[ip_dst_hash].src_next = next;
-	if (next != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next].src_prev = ip_dst_hash;
-	bond_info->rx_hashtbl[ip_src_hash].src_first = ip_dst_hash;
-}
-
-/* deletes all rx_hashtbl entries with arp->ip_src if their mac_src does
- * not match arp->mac_src
- */
-static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 ip_src_hash = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
-	u32 index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	index = bond_info->rx_hashtbl[ip_src_hash].src_first;
-	while (index != RLB_NULL_INDEX) {
-		struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
-		u32 next_index = entry->src_next;
-		if (entry->ip_src == arp->ip_src &&
-		    !ether_addr_equal_64bits(arp->mac_src, entry->mac_src))
-				rlb_delete_table_entry(bond, index);
-		index = next_index;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static int rlb_initialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info	*new_hashtbl;
-	int size = RLB_HASH_TABLE_SIZE * sizeof(struct rlb_client_info);
-	int i;
-
-	new_hashtbl = kmalloc(size, GFP_KERNEL);
-	if (!new_hashtbl)
-		return -1;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	bond_info->rx_hashtbl = new_hashtbl;
-
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	for (i = 0; i < RLB_HASH_TABLE_SIZE; i++)
-		rlb_init_table_entry(bond_info->rx_hashtbl + i);
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	/* register to receive ARPs */
-	bond->recv_probe = rlb_arp_recv;
-
-	return 0;
-}
-
-static void rlb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	spin_lock_bh(&bond->mode_lock);
-
-	kfree(bond_info->rx_hashtbl);
-	bond_info->rx_hashtbl = NULL;
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static void rlb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 curr_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	curr_index = bond_info->rx_hashtbl_used_head;
-	while (curr_index != RLB_NULL_INDEX) {
-		struct rlb_client_info *curr = &(bond_info->rx_hashtbl[curr_index]);
-		u32 next_index = bond_info->rx_hashtbl[curr_index].used_next;
-
-		if (curr->vlan_id == vlan_id)
-			rlb_delete_table_entry(bond, curr_index);
-
-		curr_index = next_index;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/*********************** tlb/rlb shared functions *********************/
-
-static void alb_send_lp_vid(struct slave *slave, u8 mac_addr[],
-			    __be16 vlan_proto, u16 vid)
-{
-	struct learning_pkt pkt;
-	struct sk_buff *skb;
-	int size = sizeof(struct learning_pkt);
-
-	memset(&pkt, 0, size);
-	ether_addr_copy(pkt.mac_dst, mac_addr);
-	ether_addr_copy(pkt.mac_src, mac_addr);
-	pkt.type = cpu_to_be16(ETH_P_LOOPBACK);
-
-	skb = dev_alloc_skb(size);
-	if (!skb)
-		return;
-
-	skb_put_data(skb, &pkt, size);
-
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = pkt.type;
-	skb->priority = TC_PRIO_CONTROL;
-	skb->dev = slave->dev;
-
-	slave_dbg(slave->bond->dev, slave->dev,
-		  "Send learning packet: mac %pM vlan %d\n", mac_addr, vid);
-
-	if (vid)
-		__vlan_hwaccel_put_tag(skb, vlan_proto, vid);
-
-	dev_queue_xmit(skb);
-}
-
-struct alb_walk_data {
-	struct bonding *bond;
-	struct slave *slave;
-	u8 *mac_addr;
-	bool strict_match;
-};
-
-static int alb_upper_dev_walk(struct net_device *upper,
-			      struct netdev_nested_priv *priv)
-{
-	struct alb_walk_data *data = (struct alb_walk_data *)priv->data;
-	bool strict_match = data->strict_match;
-	struct bonding *bond = data->bond;
-	struct slave *slave = data->slave;
-	u8 *mac_addr = data->mac_addr;
-	struct bond_vlan_tag *tags;
-
-	if (is_vlan_dev(upper) &&
-	    bond->dev->lower_level == upper->lower_level - 1) {
-		if (upper->addr_assign_type == NET_ADDR_STOLEN) {
-			alb_send_lp_vid(slave, mac_addr,
-					vlan_dev_vlan_proto(upper),
-					vlan_dev_vlan_id(upper));
-		} else {
-			alb_send_lp_vid(slave, upper->dev_addr,
-					vlan_dev_vlan_proto(upper),
-					vlan_dev_vlan_id(upper));
-		}
-	}
-
-	/* If this is a macvlan device, then only send updates
-	 * when strict_match is turned off.
-	 */
-	if (netif_is_macvlan(upper) && !strict_match) {
-		tags = bond_verify_device_path(bond->dev, upper, 0);
-		if (IS_ERR_OR_NULL(tags))
-			BUG();
-		alb_send_lp_vid(slave, upper->dev_addr,
-				tags[0].vlan_proto, tags[0].vlan_id);
-		kfree(tags);
-	}
-
-	return 0;
-}
-
-static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
-				      bool strict_match)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-	struct netdev_nested_priv priv;
-	struct alb_walk_data data = {
-		.strict_match = strict_match,
-		.mac_addr = mac_addr,
-		.slave = slave,
-		.bond = bond,
-	};
-
-	priv.data = (void *)&data;
-	/* send untagged */
-	alb_send_lp_vid(slave, mac_addr, 0, 0);
-
-	/* loop through all devices and see if we need to send a packet
-	 * for that device.
-	 */
-	rcu_read_lock();
-	netdev_walk_all_upper_dev_rcu(bond->dev, alb_upper_dev_walk, &priv);
-	rcu_read_unlock();
-}
-
-static int alb_set_slave_mac_addr(struct slave *slave, u8 addr[],
-				  unsigned int len)
-{
-	struct net_device *dev = slave->dev;
-	struct sockaddr_storage ss;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_TLB) {
-		memcpy(dev->dev_addr, addr, len);
-		return 0;
-	}
-
-	/* for rlb each slave must have a unique hw mac addresses so that
-	 * each slave will receive packets destined to a different mac
-	 */
-	memcpy(ss.__data, addr, len);
-	ss.ss_family = dev->type;
-	if (dev_set_mac_address(dev, (struct sockaddr *)&ss, NULL)) {
-		slave_err(slave->bond->dev, dev, "dev_set_mac_address on slave failed! ALB mode requires that the base driver support setting the hw address also when the network device's interface is open\n");
-		return -EOPNOTSUPP;
-	}
-	return 0;
-}
-
-/* Swap MAC addresses between two slaves.
- *
- * Called with RTNL held, and no other locks.
- */
-static void alb_swap_mac_addr(struct slave *slave1, struct slave *slave2)
-{
-	u8 tmp_mac_addr[MAX_ADDR_LEN];
-
-	bond_hw_addr_copy(tmp_mac_addr, slave1->dev->dev_addr,
-			  slave1->dev->addr_len);
-	alb_set_slave_mac_addr(slave1, slave2->dev->dev_addr,
-			       slave2->dev->addr_len);
-	alb_set_slave_mac_addr(slave2, tmp_mac_addr,
-			       slave1->dev->addr_len);
-
-}
-
-/* Send learning packets after MAC address swap.
- *
- * Called with RTNL and no other locks
- */
-static void alb_fasten_mac_swap(struct bonding *bond, struct slave *slave1,
-				struct slave *slave2)
-{
-	int slaves_state_differ = (bond_slave_can_tx(slave1) != bond_slave_can_tx(slave2));
-	struct slave *disabled_slave = NULL;
-
-	ASSERT_RTNL();
-
-	/* fasten the change in the switch */
-	if (bond_slave_can_tx(slave1)) {
-		alb_send_learning_packets(slave1, slave1->dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform the clients that the mac address
-			 * has changed
-			 */
-			rlb_req_update_slave_clients(bond, slave1);
-		}
-	} else {
-		disabled_slave = slave1;
-	}
-
-	if (bond_slave_can_tx(slave2)) {
-		alb_send_learning_packets(slave2, slave2->dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform the clients that the mac address
-			 * has changed
-			 */
-			rlb_req_update_slave_clients(bond, slave2);
-		}
-	} else {
-		disabled_slave = slave2;
-	}
-
-	if (bond->alb_info.rlb_enabled && slaves_state_differ) {
-		/* A disabled slave was assigned an active mac addr */
-		rlb_teach_disabled_mac_on_primary(bond,
-						  disabled_slave->dev->dev_addr);
-	}
-}
-
-/**
- * alb_change_hw_addr_on_detach
- * @bond: bonding we're working on
- * @slave: the slave that was just detached
- *
- * We assume that @slave was already detached from the slave list.
- *
- * If @slave's permanent hw address is different both from its current
- * address and from @bond's address, then somewhere in the bond there's
- * a slave that has @slave's permanet address as its current address.
- * We'll make sure that that slave no longer uses @slave's permanent address.
- *
- * Caller must hold RTNL and no other locks
- */
-static void alb_change_hw_addr_on_detach(struct bonding *bond, struct slave *slave)
-{
-	int perm_curr_diff;
-	int perm_bond_diff;
-	struct slave *found_slave;
-
-	perm_curr_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
-						  slave->dev->dev_addr);
-	perm_bond_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
-						  bond->dev->dev_addr);
-
-	if (perm_curr_diff && perm_bond_diff) {
-		found_slave = bond_slave_has_mac(bond, slave->perm_hwaddr);
-
-		if (found_slave) {
-			alb_swap_mac_addr(slave, found_slave);
-			alb_fasten_mac_swap(bond, slave, found_slave);
-		}
-	}
-}
-
-/**
- * alb_handle_addr_collision_on_attach
- * @bond: bonding we're working on
- * @slave: the slave that was just attached
- *
- * checks uniqueness of slave's mac address and handles the case the
- * new slave uses the bonds mac address.
- *
- * If the permanent hw address of @slave is @bond's hw address, we need to
- * find a different hw address to give @slave, that isn't in use by any other
- * slave in the bond. This address must be, of course, one of the permanent
- * addresses of the other slaves.
- *
- * We go over the slave list, and for each slave there we compare its
- * permanent hw address with the current address of all the other slaves.
- * If no match was found, then we've found a slave with a permanent address
- * that isn't used by any other slave in the bond, so we can assign it to
- * @slave.
- *
- * assumption: this function is called before @slave is attached to the
- *	       bond slave list.
- */
-static int alb_handle_addr_collision_on_attach(struct bonding *bond, struct slave *slave)
-{
-	struct slave *has_bond_addr = rcu_access_pointer(bond->curr_active_slave);
-	struct slave *tmp_slave1, *free_mac_slave = NULL;
-	struct list_head *iter;
-
-	if (!bond_has_slaves(bond)) {
-		/* this is the first slave */
-		return 0;
-	}
-
-	/* if slave's mac address differs from bond's mac address
-	 * check uniqueness of slave's mac address against the other
-	 * slaves in the bond.
-	 */
-	if (!ether_addr_equal_64bits(slave->perm_hwaddr, bond->dev->dev_addr)) {
-		if (!bond_slave_has_mac(bond, slave->dev->dev_addr))
-			return 0;
-
-		/* Try setting slave mac to bond address and fall-through
-		 * to code handling that situation below...
-		 */
-		alb_set_slave_mac_addr(slave, bond->dev->dev_addr,
-				       bond->dev->addr_len);
-	}
-
-	/* The slave's address is equal to the address of the bond.
-	 * Search for a spare address in the bond for this slave.
-	 */
-	bond_for_each_slave(bond, tmp_slave1, iter) {
-		if (!bond_slave_has_mac(bond, tmp_slave1->perm_hwaddr)) {
-			/* no slave has tmp_slave1's perm addr
-			 * as its curr addr
-			 */
-			free_mac_slave = tmp_slave1;
-			break;
-		}
-
-		if (!has_bond_addr) {
-			if (ether_addr_equal_64bits(tmp_slave1->dev->dev_addr,
-						    bond->dev->dev_addr)) {
-
-				has_bond_addr = tmp_slave1;
-			}
-		}
-	}
-
-	if (free_mac_slave) {
-		alb_set_slave_mac_addr(slave, free_mac_slave->perm_hwaddr,
-				       free_mac_slave->dev->addr_len);
-
-		slave_warn(bond->dev, slave->dev, "the slave hw address is in use by the bond; giving it the hw address of %s\n",
-			   free_mac_slave->dev->name);
-
-	} else if (has_bond_addr) {
-		slave_err(bond->dev, slave->dev, "the slave hw address is in use by the bond; couldn't find a slave with a free hw address to give it (this should not have happened)\n");
-		return -EFAULT;
-	}
-
-	return 0;
-}
-
-/**
- * alb_set_mac_address
- * @bond: bonding we're working on
- * @addr: MAC address to set
- *
- * In TLB mode all slaves are configured to the bond's hw address, but set
- * their dev_addr field to different addresses (based on their permanent hw
- * addresses).
- *
- * For each slave, this function sets the interface to the new address and then
- * changes its dev_addr field to its previous value.
- *
- * Unwinding assumes bond's mac address has not yet changed.
- */
-static int alb_set_mac_address(struct bonding *bond, void *addr)
-{
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	struct sockaddr_storage ss;
-	char tmp_addr[MAX_ADDR_LEN];
-	int res;
-
-	if (bond->alb_info.rlb_enabled)
-		return 0;
-
-	bond_for_each_slave(bond, slave, iter) {
-		/* save net_device's current hw address */
-		bond_hw_addr_copy(tmp_addr, slave->dev->dev_addr,
-				  slave->dev->addr_len);
-
-		res = dev_set_mac_address(slave->dev, addr, NULL);
-
-		/* restore net_device's hw address */
-		bond_hw_addr_copy(slave->dev->dev_addr, tmp_addr,
-				  slave->dev->addr_len);
-
-		if (res)
-			goto unwind;
-	}
-
-	return 0;
-
-unwind:
-	memcpy(ss.__data, bond->dev->dev_addr, bond->dev->addr_len);
-	ss.ss_family = bond->dev->type;
-
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		if (rollback_slave == slave)
-			break;
-		bond_hw_addr_copy(tmp_addr, rollback_slave->dev->dev_addr,
-				  rollback_slave->dev->addr_len);
-		dev_set_mac_address(rollback_slave->dev,
-				    (struct sockaddr *)&ss, NULL);
-		bond_hw_addr_copy(rollback_slave->dev->dev_addr, tmp_addr,
-				  rollback_slave->dev->addr_len);
-	}
-
-	return res;
-}
-
-/************************ exported alb funcions ************************/
-
-int bond_alb_initialize(struct bonding *bond, int rlb_enabled)
-{
-	int res;
-
-	res = tlb_initialize(bond);
-	if (res)
-		return res;
-
-	if (rlb_enabled) {
-		bond->alb_info.rlb_enabled = 1;
-		res = rlb_initialize(bond);
-		if (res) {
-			tlb_deinitialize(bond);
-			return res;
-		}
-	} else {
-		bond->alb_info.rlb_enabled = 0;
-	}
-
-	return 0;
-}
-
-void bond_alb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	tlb_deinitialize(bond);
-
-	if (bond_info->rlb_enabled)
-		rlb_deinitialize(bond);
-}
-
-static netdev_tx_t bond_do_alb_xmit(struct sk_buff *skb, struct bonding *bond,
-				    struct slave *tx_slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct ethhdr *eth_data = eth_hdr(skb);
-
-	if (!tx_slave) {
-		/* unbalanced or unassigned, send through primary */
-		tx_slave = rcu_dereference(bond->curr_active_slave);
-		if (bond->params.tlb_dynamic_lb)
-			bond_info->unbalanced_load += skb->len;
-	}
-
-	if (tx_slave && bond_slave_can_tx(tx_slave)) {
-		if (tx_slave != rcu_access_pointer(bond->curr_active_slave)) {
-			ether_addr_copy(eth_data->h_source,
-					tx_slave->dev->dev_addr);
-		}
-
-		return bond_dev_queue_xmit(bond, skb, tx_slave->dev);
-	}
-
-	if (tx_slave && bond->params.tlb_dynamic_lb) {
-		spin_lock(&bond->mode_lock);
-		__tlb_clear_slave(bond, tx_slave, 0);
-		spin_unlock(&bond->mode_lock);
-	}
-
-	/* no suitable interface, frame not sent */
-	return bond_tx_drop(bond->dev, skb);
-}
-
-struct slave *bond_xmit_tlb_slave_get(struct bonding *bond,
-				      struct sk_buff *skb)
-{
-	struct slave *tx_slave = NULL;
-	struct ethhdr *eth_data;
-	u32 hash_index;
-
-	skb_reset_mac_header(skb);
-	eth_data = eth_hdr(skb);
-
-	/* Do not TX balance any multicast or broadcast */
-	if (!is_multicast_ether_addr(eth_data->h_dest)) {
-		switch (skb->protocol) {
-		case htons(ETH_P_IP):
-		case htons(ETH_P_IPX):
-		    /* In case of IPX, it will falback to L2 hash */
-		case htons(ETH_P_IPV6):
-			hash_index = bond_xmit_hash(bond, skb);
-			if (bond->params.tlb_dynamic_lb) {
-				tx_slave = tlb_choose_channel(bond,
-							      hash_index & 0xFF,
-							      skb->len);
-			} else {
-				struct bond_up_slave *slaves;
-				unsigned int count;
-
-				slaves = rcu_dereference(bond->usable_slaves);
-				count = slaves ? READ_ONCE(slaves->count) : 0;
-				if (likely(count))
-					tx_slave = slaves->arr[hash_index %
-							       count];
-			}
-			break;
-		}
-	}
-	return tx_slave;
-}
-
-netdev_tx_t bond_tlb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *tx_slave;
-
-	tx_slave = bond_xmit_tlb_slave_get(bond, skb);
-	return bond_do_alb_xmit(skb, bond, tx_slave);
-}
-
-struct slave *bond_xmit_alb_slave_get(struct bonding *bond,
-				      struct sk_buff *skb)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	static const __be32 ip_bcast = htonl(0xffffffff);
-	struct slave *tx_slave = NULL;
-	const u8 *hash_start = NULL;
-	bool do_tx_balance = true;
-	struct ethhdr *eth_data;
-	u32 hash_index = 0;
-	int hash_size = 0;
-
-	skb_reset_mac_header(skb);
-	eth_data = eth_hdr(skb);
-
-	switch (ntohs(skb->protocol)) {
-	case ETH_P_IP: {
-		const struct iphdr *iph;
-
-		if (is_broadcast_ether_addr(eth_data->h_dest) ||
-		    !pskb_network_may_pull(skb, sizeof(*iph))) {
-			do_tx_balance = false;
-			break;
-		}
-		iph = ip_hdr(skb);
-		if (iph->daddr == ip_bcast || iph->protocol == IPPROTO_IGMP) {
-			do_tx_balance = false;
-			break;
-		}
-		hash_start = (char *)&(iph->daddr);
-		hash_size = sizeof(iph->daddr);
-		break;
-	}
-	case ETH_P_IPV6: {
-		const struct ipv6hdr *ip6hdr;
-
-		/* IPv6 doesn't really use broadcast mac address, but leave
-		 * that here just in case.
-		 */
-		if (is_broadcast_ether_addr(eth_data->h_dest)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		/* IPv6 uses all-nodes multicast as an equivalent to
-		 * broadcasts in IPv4.
-		 */
-		if (ether_addr_equal_64bits(eth_data->h_dest, mac_v6_allmcast)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		if (!pskb_network_may_pull(skb, sizeof(*ip6hdr))) {
-			do_tx_balance = false;
-			break;
-		}
-		/* Additionally, DAD probes should not be tx-balanced as that
-		 * will lead to false positives for duplicate addresses and
-		 * prevent address configuration from working.
-		 */
-		ip6hdr = ipv6_hdr(skb);
-		if (ipv6_addr_any(&ip6hdr->saddr)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		hash_start = (char *)&ip6hdr->daddr;
-		hash_size = sizeof(ip6hdr->daddr);
-		break;
-	}
-	case ETH_P_IPX: {
-		const struct ipxhdr *ipxhdr;
-
-		if (pskb_network_may_pull(skb, sizeof(*ipxhdr))) {
-			do_tx_balance = false;
-			break;
-		}
-		ipxhdr = (struct ipxhdr *)skb_network_header(skb);
-
-		if (ipxhdr->ipx_checksum != IPX_NO_CHECKSUM) {
-			/* something is wrong with this packet */
-			do_tx_balance = false;
-			break;
-		}
-
-		if (ipxhdr->ipx_type != IPX_TYPE_NCP) {
-			/* The only protocol worth balancing in
-			 * this family since it has an "ARP" like
-			 * mechanism
-			 */
-			do_tx_balance = false;
-			break;
-		}
-
-		eth_data = eth_hdr(skb);
-		hash_start = (char *)eth_data->h_dest;
-		hash_size = ETH_ALEN;
-		break;
-	}
-	case ETH_P_ARP:
-		do_tx_balance = false;
-		if (bond_info->rlb_enabled)
-			tx_slave = rlb_arp_xmit(skb, bond);
-		break;
-	default:
-		do_tx_balance = false;
-		break;
-	}
-
-	if (do_tx_balance) {
-		if (bond->params.tlb_dynamic_lb) {
-			hash_index = _simple_hash(hash_start, hash_size);
-			tx_slave = tlb_choose_channel(bond, hash_index, skb->len);
-		} else {
-			/*
-			 * do_tx_balance means we are free to select the tx_slave
-			 * So we do exactly what tlb would do for hash selection
-			 */
-
-			struct bond_up_slave *slaves;
-			unsigned int count;
-
-			slaves = rcu_dereference(bond->usable_slaves);
-			count = slaves ? READ_ONCE(slaves->count) : 0;
-			if (likely(count))
-				tx_slave = slaves->arr[bond_xmit_hash(bond, skb) %
-						       count];
-		}
-	}
-	return tx_slave;
-}
-
-netdev_tx_t bond_alb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *tx_slave = NULL;
-
-	tx_slave = bond_xmit_alb_slave_get(bond, skb);
-	return bond_do_alb_xmit(skb, bond, tx_slave);
-}
-
-void bond_alb_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    alb_work.work);
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (!bond_has_slaves(bond)) {
-		bond_info->tx_rebalance_counter = 0;
-		bond_info->lp_counter = 0;
-		goto re_arm;
-	}
-
-	rcu_read_lock();
-
-	bond_info->tx_rebalance_counter++;
-	bond_info->lp_counter++;
-
-	/* send learning packets */
-	if (bond_info->lp_counter >= BOND_ALB_LP_TICKS(bond)) {
-		bool strict_match;
-
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			/* If updating current_active, use all currently
-			 * user mac addreses (!strict_match).  Otherwise, only
-			 * use mac of the slave device.
-			 * In RLB mode, we always use strict matches.
-			 */
-			strict_match = (slave != rcu_access_pointer(bond->curr_active_slave) ||
-					bond_info->rlb_enabled);
-			alb_send_learning_packets(slave, slave->dev->dev_addr,
-						  strict_match);
-		}
-		bond_info->lp_counter = 0;
-	}
-
-	/* rebalance tx traffic */
-	if (bond_info->tx_rebalance_counter >= BOND_TLB_REBALANCE_TICKS) {
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			tlb_clear_slave(bond, slave, 1);
-			if (slave == rcu_access_pointer(bond->curr_active_slave)) {
-				SLAVE_TLB_INFO(slave).load =
-					bond_info->unbalanced_load /
-						BOND_TLB_REBALANCE_INTERVAL;
-				bond_info->unbalanced_load = 0;
-			}
-		}
-		bond_info->tx_rebalance_counter = 0;
-	}
-
-	if (bond_info->rlb_enabled) {
-		if (bond_info->primary_is_promisc &&
-		    (++bond_info->rlb_promisc_timeout_counter >= RLB_PROMISC_TIMEOUT)) {
-
-			/* dev_set_promiscuity requires rtnl and
-			 * nothing else.  Avoid race with bond_close.
-			 */
-			rcu_read_unlock();
-			if (!rtnl_trylock())
-				goto re_arm;
-
-			bond_info->rlb_promisc_timeout_counter = 0;
-
-			/* If the primary was set to promiscuous mode
-			 * because a slave was disabled then
-			 * it can now leave promiscuous mode.
-			 */
-			dev_set_promiscuity(rtnl_dereference(bond->curr_active_slave)->dev,
-					    -1);
-			bond_info->primary_is_promisc = 0;
-
-			rtnl_unlock();
-			rcu_read_lock();
-		}
-
-		if (bond_info->rlb_rebalance) {
-			bond_info->rlb_rebalance = 0;
-			rlb_rebalance(bond);
-		}
-
-		/* check if clients need updating */
-		if (bond_info->rx_ntt) {
-			if (bond_info->rlb_update_delay_counter) {
-				--bond_info->rlb_update_delay_counter;
-			} else {
-				rlb_update_rx_clients(bond);
-				if (bond_info->rlb_update_retry_counter)
-					--bond_info->rlb_update_retry_counter;
-				else
-					bond_info->rx_ntt = 0;
-			}
-		}
-	}
-	rcu_read_unlock();
-re_arm:
-	queue_delayed_work(bond->wq, &bond->alb_work, alb_delta_in_ticks);
-}
-
-/* assumption: called before the slave is attached to the bond
- * and not locked by the bond lock
- */
-int bond_alb_init_slave(struct bonding *bond, struct slave *slave)
-{
-	int res;
-
-	res = alb_set_slave_mac_addr(slave, slave->perm_hwaddr,
-				     slave->dev->addr_len);
-	if (res)
-		return res;
-
-	res = alb_handle_addr_collision_on_attach(bond, slave);
-	if (res)
-		return res;
-
-	tlb_init_slave(slave);
-
-	/* order a rebalance ASAP */
-	bond->alb_info.tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
-
-	if (bond->alb_info.rlb_enabled)
-		bond->alb_info.rlb_rebalance = 1;
-
-	return 0;
-}
-
-/* Remove slave from tlb and rlb hash tables, and fix up MAC addresses
- * if necessary.
- *
- * Caller must hold RTNL and no other locks
- */
-void bond_alb_deinit_slave(struct bonding *bond, struct slave *slave)
-{
-	if (bond_has_slaves(bond))
-		alb_change_hw_addr_on_detach(bond, slave);
-
-	tlb_clear_slave(bond, slave, 0);
-
-	if (bond->alb_info.rlb_enabled) {
-		bond->alb_info.rx_slave = NULL;
-		rlb_clear_slave(bond, slave);
-	}
-
-}
-
-void bond_alb_handle_link_change(struct bonding *bond, struct slave *slave, char link)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	if (link == BOND_LINK_DOWN) {
-		tlb_clear_slave(bond, slave, 0);
-		if (bond->alb_info.rlb_enabled)
-			rlb_clear_slave(bond, slave);
-	} else if (link == BOND_LINK_UP) {
-		/* order a rebalance ASAP */
-		bond_info->tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
-		if (bond->alb_info.rlb_enabled) {
-			bond->alb_info.rlb_rebalance = 1;
-			/* If the updelay module parameter is smaller than the
-			 * forwarding delay of the switch the rebalance will
-			 * not work because the rebalance arp replies will
-			 * not be forwarded to the clients..
-			 */
-		}
-	}
-
-	if (bond_is_nondyn_tlb(bond)) {
-		if (bond_update_slave_arr(bond, NULL))
-			pr_err("Failed to build slave-array for TLB mode.\n");
-	}
-}
-
-/**
- * bond_alb_handle_active_change - assign new curr_active_slave
- * @bond: our bonding struct
- * @new_slave: new slave to assign
- *
- * Set the bond->curr_active_slave to @new_slave and handle
- * mac address swapping and promiscuity changes as needed.
- *
- * Caller must hold RTNL
- */
-void bond_alb_handle_active_change(struct bonding *bond, struct slave *new_slave)
-{
-	struct slave *swap_slave;
-	struct slave *curr_active;
-
-	curr_active = rtnl_dereference(bond->curr_active_slave);
-	if (curr_active == new_slave)
-		return;
-
-	if (curr_active && bond->alb_info.primary_is_promisc) {
-		dev_set_promiscuity(curr_active->dev, -1);
-		bond->alb_info.primary_is_promisc = 0;
-		bond->alb_info.rlb_promisc_timeout_counter = 0;
-	}
-
-	swap_slave = curr_active;
-	rcu_assign_pointer(bond->curr_active_slave, new_slave);
-
-	if (!new_slave || !bond_has_slaves(bond))
-		return;
-
-	/* set the new curr_active_slave to the bonds mac address
-	 * i.e. swap mac addresses of old curr_active_slave and new curr_active_slave
-	 */
-	if (!swap_slave)
-		swap_slave = bond_slave_has_mac(bond, bond->dev->dev_addr);
-
-	/* Arrange for swap_slave and new_slave to temporarily be
-	 * ignored so we can mess with their MAC addresses without
-	 * fear of interference from transmit activity.
-	 */
-	if (swap_slave)
-		tlb_clear_slave(bond, swap_slave, 1);
-	tlb_clear_slave(bond, new_slave, 1);
-
-	/* in TLB mode, the slave might flip down/up with the old dev_addr,
-	 * and thus filter bond->dev_addr's packets, so force bond's mac
-	 */
-	if (BOND_MODE(bond) == BOND_MODE_TLB) {
-		struct sockaddr_storage ss;
-		u8 tmp_addr[MAX_ADDR_LEN];
-
-		bond_hw_addr_copy(tmp_addr, new_slave->dev->dev_addr,
-				  new_slave->dev->addr_len);
-
-		bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
-				  bond->dev->addr_len);
-		ss.ss_family = bond->dev->type;
-		/* we don't care if it can't change its mac, best effort */
-		dev_set_mac_address(new_slave->dev, (struct sockaddr *)&ss,
-				    NULL);
-
-		bond_hw_addr_copy(new_slave->dev->dev_addr, tmp_addr,
-				  new_slave->dev->addr_len);
-	}
-
-	/* curr_active_slave must be set before calling alb_swap_mac_addr */
-	if (swap_slave) {
-		/* swap mac address */
-		alb_swap_mac_addr(swap_slave, new_slave);
-		alb_fasten_mac_swap(bond, swap_slave, new_slave);
-	} else {
-		/* set the new_slave to the bond mac address */
-		alb_set_slave_mac_addr(new_slave, bond->dev->dev_addr,
-				       bond->dev->addr_len);
-		alb_send_learning_packets(new_slave, bond->dev->dev_addr,
-					  false);
-	}
-}
-
-/* Called with RTNL */
-int bond_alb_set_mac_address(struct net_device *bond_dev, void *addr)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct sockaddr_storage *ss = addr;
-	struct slave *curr_active;
-	struct slave *swap_slave;
-	int res;
-
-	if (!is_valid_ether_addr(ss->__data))
-		return -EADDRNOTAVAIL;
-
-	res = alb_set_mac_address(bond, addr);
-	if (res)
-		return res;
-
-	bond_hw_addr_copy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
-
-	/* If there is no curr_active_slave there is nothing else to do.
-	 * Otherwise we'll need to pass the new address to it and handle
-	 * duplications.
-	 */
-	curr_active = rtnl_dereference(bond->curr_active_slave);
-	if (!curr_active)
-		return 0;
-
-	swap_slave = bond_slave_has_mac(bond, bond_dev->dev_addr);
-
-	if (swap_slave) {
-		alb_swap_mac_addr(swap_slave, curr_active);
-		alb_fasten_mac_swap(bond, swap_slave, curr_active);
-	} else {
-		alb_set_slave_mac_addr(curr_active, bond_dev->dev_addr,
-				       bond_dev->addr_len);
-
-		alb_send_learning_packets(curr_active,
-					  bond_dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform clients mac address has changed */
-			rlb_req_update_slave_clients(bond, curr_active);
-		}
-	}
-
-	return 0;
-}
-
-void bond_alb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
-{
-	if (bond->alb_info.rlb_enabled)
-		rlb_clear_vlan(bond, vlan_id);
-}
-
diff -r 30 src/network/bonding/BONDING_KDIRS/5.10.0/bond_debugfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.10.0/bond_debugfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,125 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/device.h>
-#include <linux/netdevice.h>
-
-#include <net/bonding.h>
-#include <net/bond_alb.h>
-
-#if defined(CONFIG_DEBUG_FS) && !defined(CONFIG_NET_NS)
-
-#include <linux/debugfs.h>
-#include <linux/seq_file.h>
-
-static struct dentry *bonding_debug_root;
-
-/* Show RLB hash table */
-static int bond_debug_rlb_hash_show(struct seq_file *m, void *v)
-{
-	struct bonding *bond = m->private;
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	if (BOND_MODE(bond) != BOND_MODE_ALB)
-		return 0;
-
-	seq_printf(m, "SourceIP        DestinationIP   "
-			"Destination MAC   DEV\n");
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		seq_printf(m, "%-15pI4 %-15pI4 %-17pM %s\n",
-			&client_info->ip_src,
-			&client_info->ip_dst,
-			&client_info->mac_dst,
-			client_info->slave->dev->name);
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	return 0;
-}
-DEFINE_SHOW_ATTRIBUTE(bond_debug_rlb_hash);
-
-void bond_debug_register(struct bonding *bond)
-{
-	if (!bonding_debug_root)
-		return;
-
-	bond->debug_dir =
-		debugfs_create_dir(bond->dev->name, bonding_debug_root);
-
-	debugfs_create_file("rlb_hash_table", 0400, bond->debug_dir,
-				bond, &bond_debug_rlb_hash_fops);
-}
-
-void bond_debug_unregister(struct bonding *bond)
-{
-	if (!bonding_debug_root)
-		return;
-
-	debugfs_remove_recursive(bond->debug_dir);
-}
-
-void bond_debug_reregister(struct bonding *bond)
-{
-	struct dentry *d;
-
-	if (!bonding_debug_root)
-		return;
-
-	d = debugfs_rename(bonding_debug_root, bond->debug_dir,
-			   bonding_debug_root, bond->dev->name);
-	if (d) {
-		bond->debug_dir = d;
-	} else {
-		netdev_warn(bond->dev, "failed to reregister, so just unregister old one\n");
-		bond_debug_unregister(bond);
-	}
-}
-
-void bond_create_debugfs(void)
-{
-	bonding_debug_root = debugfs_create_dir("bonding", NULL);
-
-	if (!bonding_debug_root) {
-		pr_warn("Warning: Cannot create bonding directory in debugfs\n");
-	}
-}
-
-void bond_destroy_debugfs(void)
-{
-	debugfs_remove_recursive(bonding_debug_root);
-	bonding_debug_root = NULL;
-}
-
-
-#else /* !CONFIG_DEBUG_FS */
-
-void bond_debug_register(struct bonding *bond)
-{
-}
-
-void bond_debug_unregister(struct bonding *bond)
-{
-}
-
-void bond_debug_reregister(struct bonding *bond)
-{
-}
-
-void bond_create_debugfs(void)
-{
-}
-
-void bond_destroy_debugfs(void)
-{
-}
-
-#endif /* CONFIG_DEBUG_FS */
diff -r 30 src/network/bonding/BONDING_KDIRS/5.10.0/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/5.10.0/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,5475 +0,0 @@
-/*
- * originally based on the dummy device.
- *
- * Copyright 1999, Thomas Davis, tadavis@lbl.gov.
- * Licensed under the GPL. Based on dummy.c, and eql.c devices.
- *
- * bonding.c: an Ethernet Bonding driver
- *
- * This is useful to talk to a Cisco EtherChannel compatible equipment:
- *	Cisco 5500
- *	Sun Trunking (Solaris)
- *	Alteon AceDirector Trunks
- *	Linux Bonding
- *	and probably many L2 switches ...
- *
- * How it works:
- *    ifconfig bond0 ipaddress netmask up
- *      will setup a network device, with an ip address.  No mac address
- *	will be assigned at this time.  The hw mac address will come from
- *	the first slave bonded to the channel.  All slaves will then use
- *	this hw mac address.
- *
- *    ifconfig bond0 down
- *         will release all slaves, marking them as down.
- *
- *    ifenslave bond0 eth0
- *	will attach eth0 to bond0 as a slave.  eth0 hw mac address will either
- *	a: be used as initial mac address
- *	b: if a hw mac address already is there, eth0's hw mac address
- *	   will then be set from bond0.
- *
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/types.h>
-#include <linux/fcntl.h>
-#include <linux/interrupt.h>
-#include <linux/ptrace.h>
-#include <linux/ioport.h>
-#include <linux/in.h>
-#include <net/ip.h>
-#include <linux/ip.h>
-#include <linux/icmp.h>
-#include <linux/icmpv6.h>
-#include <linux/tcp.h>
-#include <linux/udp.h>
-#include <linux/slab.h>
-#include <linux/string.h>
-#include <linux/init.h>
-#include <linux/timer.h>
-#include <linux/socket.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/bitops.h>
-#include <linux/io.h>
-#include <asm/dma.h>
-#include <linux/uaccess.h>
-#include <linux/errno.h>
-#include <linux/netdevice.h>
-#include <linux/inetdevice.h>
-#include <linux/igmp.h>
-#include <linux/etherdevice.h>
-#include <linux/skbuff.h>
-#include <net/sock.h>
-#include <linux/rtnetlink.h>
-#include <linux/smp.h>
-#include <linux/if_ether.h>
-#include <net/arp.h>
-#include <linux/mii.h>
-#include <linux/ethtool.h>
-#include <linux/if_vlan.h>
-#include <linux/if_bonding.h>
-#include <linux/jiffies.h>
-#include <linux/preempt.h>
-#include <net/route.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <net/pkt_sched.h>
-#include <linux/rculist.h>
-#include <linux/toedev.h>
-#include <net/flow_dissector.h>
-#include <net/xfrm.h>
-#include <net/bonding.h>
-#include <net/bond_3ad.h>
-#include <net/bond_alb.h>
-
-#include "bonding_priv.h"
-
-/*---------------------------- Module parameters ----------------------------*/
-
-/* monitor all links that often (in milliseconds). <=0 disables monitoring */
-
-static int max_bonds	= BOND_DEFAULT_MAX_BONDS;
-static int tx_queues	= BOND_DEFAULT_TX_QUEUES;
-static int num_peer_notif = 1;
-static int miimon;
-static int updelay;
-static int downdelay;
-static int use_carrier	= 1;
-static char *mode;
-static char *primary;
-static char *primary_reselect;
-static char *lacp_rate;
-static int min_links;
-static char *ad_select;
-static char *xmit_hash_policy;
-static int arp_interval;
-static char *arp_ip_target[BOND_MAX_ARP_TARGETS];
-static char *arp_validate;
-static char *arp_all_targets;
-static char *fail_over_mac;
-static int all_slaves_active;
-static struct bond_params bonding_defaults;
-static int resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-static int packets_per_slave = 1;
-static int lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-
-module_param(max_bonds, int, 0);
-MODULE_PARM_DESC(max_bonds, "Max number of bonded devices");
-module_param(tx_queues, int, 0);
-MODULE_PARM_DESC(tx_queues, "Max number of transmit queues (default = 16)");
-module_param_named(num_grat_arp, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_grat_arp, "Number of peer notifications to send on "
-			       "failover event (alias of num_unsol_na)");
-module_param_named(num_unsol_na, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_unsol_na, "Number of peer notifications to send on "
-			       "failover event (alias of num_grat_arp)");
-module_param(miimon, int, 0);
-MODULE_PARM_DESC(miimon, "Link check interval in milliseconds");
-module_param(updelay, int, 0);
-MODULE_PARM_DESC(updelay, "Delay before considering link up, in milliseconds");
-module_param(downdelay, int, 0);
-MODULE_PARM_DESC(downdelay, "Delay before considering link down, "
-			    "in milliseconds");
-module_param(use_carrier, int, 0);
-MODULE_PARM_DESC(use_carrier, "Use netif_carrier_ok (vs MII ioctls) in miimon; "
-			      "0 for off, 1 for on (default)");
-module_param(mode, charp, 0);
-MODULE_PARM_DESC(mode, "Mode of operation; 0 for balance-rr, "
-		       "1 for active-backup, 2 for balance-xor, "
-		       "3 for broadcast, 4 for 802.3ad, 5 for balance-tlb, "
-		       "6 for balance-alb");
-module_param(primary, charp, 0);
-MODULE_PARM_DESC(primary, "Primary network device to use");
-module_param(primary_reselect, charp, 0);
-MODULE_PARM_DESC(primary_reselect, "Reselect primary slave "
-				   "once it comes up; "
-				   "0 for always (default), "
-				   "1 for only if speed of primary is "
-				   "better, "
-				   "2 for only on active slave "
-				   "failure");
-module_param(lacp_rate, charp, 0);
-MODULE_PARM_DESC(lacp_rate, "LACPDU tx rate to request from 802.3ad partner; "
-			    "0 for slow, 1 for fast");
-module_param(ad_select, charp, 0);
-MODULE_PARM_DESC(ad_select, "802.3ad aggregation selection logic; "
-			    "0 for stable (default), 1 for bandwidth, "
-			    "2 for count");
-module_param(min_links, int, 0);
-MODULE_PARM_DESC(min_links, "Minimum number of available links before turning on carrier");
-
-module_param(xmit_hash_policy, charp, 0);
-MODULE_PARM_DESC(xmit_hash_policy, "balance-alb, balance-tlb, balance-xor, 802.3ad hashing method; "
-				   "0 for layer 2 (default), 1 for layer 3+4, "
-				   "2 for layer 2+3, 3 for encap layer 2+3, "
-				   "4 for encap layer 3+4");
-module_param(arp_interval, int, 0);
-MODULE_PARM_DESC(arp_interval, "arp interval in milliseconds");
-module_param_array(arp_ip_target, charp, NULL, 0);
-MODULE_PARM_DESC(arp_ip_target, "arp targets in n.n.n.n form");
-module_param(arp_validate, charp, 0);
-MODULE_PARM_DESC(arp_validate, "validate src/dst of ARP probes; "
-			       "0 for none (default), 1 for active, "
-			       "2 for backup, 3 for all");
-module_param(arp_all_targets, charp, 0);
-MODULE_PARM_DESC(arp_all_targets, "fail on any/all arp targets timeout; 0 for any (default), 1 for all");
-module_param(fail_over_mac, charp, 0);
-MODULE_PARM_DESC(fail_over_mac, "For active-backup, do not set all slaves to "
-				"the same MAC; 0 for none (default), "
-				"1 for active, 2 for follow");
-module_param(all_slaves_active, int, 0);
-MODULE_PARM_DESC(all_slaves_active, "Keep all frames received on an interface "
-				     "by setting active flag for all slaves; "
-				     "0 for never (default), 1 for always.");
-module_param(resend_igmp, int, 0);
-MODULE_PARM_DESC(resend_igmp, "Number of IGMP membership reports to send on "
-			      "link failure");
-module_param(packets_per_slave, int, 0);
-MODULE_PARM_DESC(packets_per_slave, "Packets to send per slave in balance-rr "
-				    "mode; 0 for a random slave, 1 packet per "
-				    "slave (default), >1 packets per slave.");
-module_param(lp_interval, uint, 0);
-MODULE_PARM_DESC(lp_interval, "The number of seconds between instances where "
-			      "the bonding driver sends learning packets to "
-			      "each slaves peer switch. The default is 1.");
-
-/*----------------------------- Global variables ----------------------------*/
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-atomic_t netpoll_block_tx = ATOMIC_INIT(0);
-#endif
-
-unsigned int bond_net_id __read_mostly;
-
-static const struct flow_dissector_key flow_keys_bonding_keys[] = {
-	{
-		.key_id = FLOW_DISSECTOR_KEY_CONTROL,
-		.offset = offsetof(struct flow_keys, control),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_BASIC,
-		.offset = offsetof(struct flow_keys, basic),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_IPV4_ADDRS,
-		.offset = offsetof(struct flow_keys, addrs.v4addrs),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_IPV6_ADDRS,
-		.offset = offsetof(struct flow_keys, addrs.v6addrs),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_TIPC,
-		.offset = offsetof(struct flow_keys, addrs.tipckey),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_PORTS,
-		.offset = offsetof(struct flow_keys, ports),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_ICMP,
-		.offset = offsetof(struct flow_keys, icmp),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_VLAN,
-		.offset = offsetof(struct flow_keys, vlan),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_FLOW_LABEL,
-		.offset = offsetof(struct flow_keys, tags),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_GRE_KEYID,
-		.offset = offsetof(struct flow_keys, keyid),
-	},
-};
-
-static struct flow_dissector flow_keys_bonding __read_mostly;
-
-/*-------------------------- Forward declarations ---------------------------*/
-
-static int bond_init(struct net_device *bond_dev);
-static void bond_uninit(struct net_device *bond_dev);
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats);
-static void bond_slave_arr_handler(struct work_struct *work);
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod);
-static void bond_netdev_notify_work(struct work_struct *work);
-
-/*---------------------------- General routines -----------------------------*/
-
-const char *bond_mode_name(int mode)
-{
-	static const char *names[] = {
-		[BOND_MODE_ROUNDROBIN] = "load balancing (round-robin)",
-		[BOND_MODE_ACTIVEBACKUP] = "fault-tolerance (active-backup)",
-		[BOND_MODE_XOR] = "load balancing (xor)",
-		[BOND_MODE_BROADCAST] = "fault-tolerance (broadcast)",
-		[BOND_MODE_8023AD] = "IEEE 802.3ad Dynamic link aggregation",
-		[BOND_MODE_TLB] = "transmit load balancing",
-		[BOND_MODE_ALB] = "adaptive load balancing",
-	};
-
-	if (mode < BOND_MODE_ROUNDROBIN || mode > BOND_MODE_ALB)
-		return "unknown";
-
-	return names[mode];
-}
-
-/**
- * bond_dev_queue_xmit - Prepare skb for xmit.
- *
- * @bond: bond device that got this skb for tx.
- * @skb: hw accel VLAN tagged skb to transmit
- * @slave_dev: slave that is supposed to xmit this skbuff
- */
-netdev_tx_t bond_dev_queue_xmit(struct bonding *bond, struct sk_buff *skb,
-			struct net_device *slave_dev)
-{
-	skb->dev = slave_dev;
-
-	BUILD_BUG_ON(sizeof(skb->queue_mapping) !=
-		     sizeof(qdisc_skb_cb(skb)->slave_dev_queue_mapping));
-	skb_set_queue_mapping(skb, qdisc_skb_cb(skb)->slave_dev_queue_mapping);
-
-	if (unlikely(netpoll_tx_running(bond->dev)))
-		return bond_netpoll_send_skb(bond_get_slave_by_dev(bond, slave_dev), skb);
-
-	return dev_queue_xmit(skb);
-}
-
-/*---------------------------------- VLAN -----------------------------------*/
-
-/* In the following 2 functions, bond_vlan_rx_add_vid and bond_vlan_rx_kill_vid,
- * We don't protect the slave list iteration with a lock because:
- * a. This operation is performed in IOCTL context,
- * b. The operation is protected by the RTNL semaphore in the 8021q code,
- * c. Holding a lock with BH disabled while directly calling a base driver
- *    entry point is generally a BAD idea.
- *
- * The design of synchronization/protection for this operation in the 8021q
- * module is good for one or more VLAN devices over a single physical device
- * and cannot be extended for a teaming solution like bonding, so there is a
- * potential race condition here where a net device from the vlan group might
- * be referenced (either by a base driver or the 8021q code) while it is being
- * removed from the system. However, it turns out we're not making matters
- * worse, and if it works for regular VLAN usage it will work here too.
-*/
-
-/**
- * bond_vlan_rx_add_vid - Propagates adding an id to slaves
- * @bond_dev: bonding net device that got called
- * @proto: network protocol ID
- * @vid: vlan id being added
- */
-static int bond_vlan_rx_add_vid(struct net_device *bond_dev,
-				__be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res;
-
-	bond_for_each_slave(bond, slave, iter) {
-		res = vlan_vid_add(slave->dev, proto, vid);
-		if (res)
-			goto unwind;
-	}
-
-	return 0;
-
-unwind:
-	/* unwind to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		if (rollback_slave == slave)
-			break;
-
-		vlan_vid_del(rollback_slave->dev, proto, vid);
-	}
-
-	return res;
-}
-
-/**
- * bond_vlan_rx_kill_vid - Propagates deleting an id to slaves
- * @bond_dev: bonding net device that got called
- * @proto: network protocol ID
- * @vid: vlan id being removed
- */
-static int bond_vlan_rx_kill_vid(struct net_device *bond_dev,
-				 __be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		vlan_vid_del(slave->dev, proto, vid);
-
-	if (bond_is_lb(bond))
-		bond_alb_clear_vlan(bond, vid);
-
-	return 0;
-}
-
-/*---------------------------------- XFRM -----------------------------------*/
-
-#ifdef CONFIG_XFRM_OFFLOAD
-/**
- * bond_ipsec_add_sa - program device with a security association
- * @xs: pointer to transformer state struct
- **/
-static int bond_ipsec_add_sa(struct xfrm_state *xs)
-{
-	struct net_device *bond_dev = xs->xso.dev;
-	struct bonding *bond;
-	struct slave *slave;
-
-	if (!bond_dev)
-		return -EINVAL;
-
-	bond = netdev_priv(bond_dev);
-	slave = rcu_dereference(bond->curr_active_slave);
-	xs->xso.real_dev = slave->dev;
-	bond->xs = xs;
-
-	if (!(slave->dev->xfrmdev_ops
-	      && slave->dev->xfrmdev_ops->xdo_dev_state_add)) {
-		slave_warn(bond_dev, slave->dev, "Slave does not support ipsec offload\n");
-		return -EINVAL;
-	}
-
-	return slave->dev->xfrmdev_ops->xdo_dev_state_add(xs);
-}
-
-/**
- * bond_ipsec_del_sa - clear out this specific SA
- * @xs: pointer to transformer state struct
- **/
-static void bond_ipsec_del_sa(struct xfrm_state *xs)
-{
-	struct net_device *bond_dev = xs->xso.dev;
-	struct bonding *bond;
-	struct slave *slave;
-
-	if (!bond_dev)
-		return;
-
-	bond = netdev_priv(bond_dev);
-	slave = rcu_dereference(bond->curr_active_slave);
-
-	if (!slave)
-		return;
-
-	xs->xso.real_dev = slave->dev;
-
-	if (!(slave->dev->xfrmdev_ops
-	      && slave->dev->xfrmdev_ops->xdo_dev_state_delete)) {
-		slave_warn(bond_dev, slave->dev, "%s: no slave xdo_dev_state_delete\n", __func__);
-		return;
-	}
-
-	slave->dev->xfrmdev_ops->xdo_dev_state_delete(xs);
-}
-
-/**
- * bond_ipsec_offload_ok - can this packet use the xfrm hw offload
- * @skb: current data packet
- * @xs: pointer to transformer state struct
- **/
-static bool bond_ipsec_offload_ok(struct sk_buff *skb, struct xfrm_state *xs)
-{
-	struct net_device *bond_dev = xs->xso.dev;
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *curr_active = rcu_dereference(bond->curr_active_slave);
-	struct net_device *slave_dev = curr_active->dev;
-
-	if (BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP)
-		return true;
-
-	if (!(slave_dev->xfrmdev_ops
-	      && slave_dev->xfrmdev_ops->xdo_dev_offload_ok)) {
-		slave_warn(bond_dev, slave_dev, "%s: no slave xdo_dev_offload_ok\n", __func__);
-		return false;
-	}
-
-	xs->xso.real_dev = slave_dev;
-	return slave_dev->xfrmdev_ops->xdo_dev_offload_ok(skb, xs);
-}
-
-static const struct xfrmdev_ops bond_xfrmdev_ops = {
-	.xdo_dev_state_add = bond_ipsec_add_sa,
-	.xdo_dev_state_delete = bond_ipsec_del_sa,
-	.xdo_dev_offload_ok = bond_ipsec_offload_ok,
-};
-#endif /* CONFIG_XFRM_OFFLOAD */
-
-/*------------------------------- Link status -------------------------------*/
-
-/* Set the carrier state for the master according to the state of its
- * slaves.  If any slaves are up, the master is up.  In 802.3ad mode,
- * do special 802.3ad magic.
- *
- * Returns zero if carrier state does not change, nonzero if it does.
- */
-int bond_set_carrier(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (!bond_has_slaves(bond))
-		goto down;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		return bond_3ad_set_carrier(bond);
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP) {
-			if (!netif_carrier_ok(bond->dev)) {
-				netif_carrier_on(bond->dev);
-				return 1;
-			}
-			return 0;
-		}
-	}
-
-down:
-	if (netif_carrier_ok(bond->dev)) {
-		netif_carrier_off(bond->dev);
-		return 1;
-	}
-	return 0;
-}
-
-/* Get link speed and duplex from the slave's base driver
- * using ethtool. If for some reason the call fails or the
- * values are invalid, set speed and duplex to -1,
- * and return. Return 1 if speed or duplex settings are
- * UNKNOWN; 0 otherwise.
- */
-static int bond_update_speed_duplex(struct slave *slave)
-{
-	struct net_device *slave_dev = slave->dev;
-	struct ethtool_link_ksettings ecmd;
-	int res;
-
-	slave->speed = SPEED_UNKNOWN;
-	slave->duplex = DUPLEX_UNKNOWN;
-
-	res = __ethtool_get_link_ksettings(slave_dev, &ecmd);
-	if (res < 0)
-		return 1;
-	if (ecmd.base.speed == 0 || ecmd.base.speed == ((__u32)-1))
-		return 1;
-	switch (ecmd.base.duplex) {
-	case DUPLEX_FULL:
-	case DUPLEX_HALF:
-		break;
-	default:
-		return 1;
-	}
-
-	slave->speed = ecmd.base.speed;
-	slave->duplex = ecmd.base.duplex;
-
-	return 0;
-}
-
-const char *bond_slave_link_status(s8 link)
-{
-	switch (link) {
-	case BOND_LINK_UP:
-		return "up";
-	case BOND_LINK_FAIL:
-		return "going down";
-	case BOND_LINK_DOWN:
-		return "down";
-	case BOND_LINK_BACK:
-		return "going back";
-	default:
-		return "unknown";
-	}
-}
-
-/* if <dev> supports MII link status reporting, check its link status.
- *
- * We either do MII/ETHTOOL ioctls, or check netif_carrier_ok(),
- * depending upon the setting of the use_carrier parameter.
- *
- * Return either BMSR_LSTATUS, meaning that the link is up (or we
- * can't tell and just pretend it is), or 0, meaning that the link is
- * down.
- *
- * If reporting is non-zero, instead of faking link up, return -1 if
- * both ETHTOOL and MII ioctls fail (meaning the device does not
- * support them).  If use_carrier is set, return whatever it says.
- * It'd be nice if there was a good way to tell if a driver supports
- * netif_carrier, but there really isn't.
- */
-static int bond_check_dev_link(struct bonding *bond,
-			       struct net_device *slave_dev, int reporting)
-{
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	int (*ioctl)(struct net_device *, struct ifreq *, int);
-	struct ifreq ifr;
-	struct mii_ioctl_data *mii;
-
-	if (!reporting && !netif_running(slave_dev))
-		return 0;
-
-	if (bond->params.use_carrier)
-		return netif_carrier_ok(slave_dev) ? BMSR_LSTATUS : 0;
-
-	/* Try to get link status using Ethtool first. */
-	if (slave_dev->ethtool_ops->get_link)
-		return slave_dev->ethtool_ops->get_link(slave_dev) ?
-			BMSR_LSTATUS : 0;
-
-	/* Ethtool can't be used, fallback to MII ioctls. */
-	ioctl = slave_ops->ndo_do_ioctl;
-	if (ioctl) {
-		/* TODO: set pointer to correct ioctl on a per team member
-		 *       bases to make this more efficient. that is, once
-		 *       we determine the correct ioctl, we will always
-		 *       call it and not the others for that team
-		 *       member.
-		 */
-
-		/* We cannot assume that SIOCGMIIPHY will also read a
-		 * register; not all network drivers (e.g., e100)
-		 * support that.
-		 */
-
-		/* Yes, the mii is overlaid on the ifreq.ifr_ifru */
-		strncpy(ifr.ifr_name, slave_dev->name, IFNAMSIZ);
-		mii = if_mii(&ifr);
-		if (ioctl(slave_dev, &ifr, SIOCGMIIPHY) == 0) {
-			mii->reg_num = MII_BMSR;
-			if (ioctl(slave_dev, &ifr, SIOCGMIIREG) == 0)
-				return mii->val_out & BMSR_LSTATUS;
-		}
-	}
-
-	/* If reporting, report that either there's no dev->do_ioctl,
-	 * or both SIOCGMIIREG and get_link failed (meaning that we
-	 * cannot report link status).  If not reporting, pretend
-	 * we're ok.
-	 */
-	return reporting ? -1 : BMSR_LSTATUS;
-}
-
-/*----------------------------- Multicast list ------------------------------*/
-
-/* Push the promiscuity flag down to appropriate slaves */
-static int bond_set_promiscuity(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_promiscuity(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_promiscuity(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Push the allmulti flag down to all slaves */
-static int bond_set_allmulti(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_allmulti(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_allmulti(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Retrieve the list of registered multicast addresses for the bonding
- * device and retransmit an IGMP JOIN request to the current active
- * slave.
- */
-static void bond_resend_igmp_join_requests_delayed(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mcast_work.work);
-
-	if (!rtnl_trylock()) {
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-		return;
-	}
-	call_netdevice_notifiers(NETDEV_RESEND_IGMP, bond->dev);
-
-	if (bond->igmp_retrans > 1) {
-		bond->igmp_retrans--;
-		queue_delayed_work(bond->wq, &bond->mcast_work, HZ/5);
-	}
-	rtnl_unlock();
-}
-
-/* Flush bond's hardware addresses from slave */
-static void bond_hw_addr_flush(struct net_device *bond_dev,
-			       struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	dev_uc_unsync(slave_dev, bond_dev);
-	dev_mc_unsync(slave_dev, bond_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		/* del lacpdu mc addr from mc list */
-		u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-		dev_mc_del(slave_dev, lacpdu_multicast);
-	}
-}
-
-/*--------------------------- Active slave change ---------------------------*/
-
-/* Update the hardware address list and promisc/allmulti for the new and
- * old active slaves (if any).  Modes that are not using primary keep all
- * slaves up date at all times; only the modes that use primary need to call
- * this function to swap these settings during a failover.
- */
-static void bond_hw_addr_swap(struct bonding *bond, struct slave *new_active,
-			      struct slave *old_active)
-{
-	if (old_active) {
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(old_active->dev, -1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(old_active->dev, -1);
-
-		bond_hw_addr_flush(bond->dev, old_active->dev);
-	}
-
-	if (new_active) {
-		/* FIXME: Signal errors upstream. */
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(new_active->dev, 1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(new_active->dev, 1);
-
-		netif_addr_lock_bh(bond->dev);
-		dev_uc_sync(new_active->dev, bond->dev);
-		dev_mc_sync(new_active->dev, bond->dev);
-		netif_addr_unlock_bh(bond->dev);
-	}
-}
-
-/**
- * bond_set_dev_addr - clone slave's address to bond
- * @bond_dev: bond net device
- * @slave_dev: slave net device
- *
- * Should be called with RTNL held.
- */
-static int bond_set_dev_addr(struct net_device *bond_dev,
-			     struct net_device *slave_dev)
-{
-	int err;
-
-	slave_dbg(bond_dev, slave_dev, "bond_dev=%p slave_dev=%p slave_dev->addr_len=%d\n",
-		  bond_dev, slave_dev, slave_dev->addr_len);
-	err = dev_pre_changeaddr_notify(bond_dev, slave_dev->dev_addr, NULL);
-	if (err)
-		return err;
-
-	memcpy(bond_dev->dev_addr, slave_dev->dev_addr, slave_dev->addr_len);
-	bond_dev->addr_assign_type = NET_ADDR_STOLEN;
-	call_netdevice_notifiers(NETDEV_CHANGEADDR, bond_dev);
-	return 0;
-}
-
-static struct slave *bond_get_old_active(struct bonding *bond,
-					 struct slave *new_active)
-{
-	struct slave *slave;
-	struct list_head *iter;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave == new_active)
-			continue;
-
-		if (ether_addr_equal(bond->dev->dev_addr, slave->dev->dev_addr))
-			return slave;
-	}
-
-	return NULL;
-}
-
-/* bond_do_fail_over_mac
- *
- * Perform special MAC address swapping for fail_over_mac settings
- *
- * Called with RTNL
- */
-static void bond_do_fail_over_mac(struct bonding *bond,
-				  struct slave *new_active,
-				  struct slave *old_active)
-{
-	u8 tmp_mac[MAX_ADDR_LEN];
-	struct sockaddr_storage ss;
-	int rv;
-
-	switch (bond->params.fail_over_mac) {
-	case BOND_FOM_ACTIVE:
-		if (new_active) {
-			rv = bond_set_dev_addr(bond->dev, new_active->dev);
-			if (rv)
-				slave_err(bond->dev, new_active->dev, "Error %d setting bond MAC from slave\n",
-					  -rv);
-		}
-		break;
-	case BOND_FOM_FOLLOW:
-		/* if new_active && old_active, swap them
-		 * if just old_active, do nothing (going to no active slave)
-		 * if just new_active, set new_active to bond's MAC
-		 */
-		if (!new_active)
-			return;
-
-		if (!old_active)
-			old_active = bond_get_old_active(bond, new_active);
-
-		if (old_active) {
-			bond_hw_addr_copy(tmp_mac, new_active->dev->dev_addr,
-					  new_active->dev->addr_len);
-			bond_hw_addr_copy(ss.__data,
-					  old_active->dev->dev_addr,
-					  old_active->dev->addr_len);
-			ss.ss_family = new_active->dev->type;
-		} else {
-			bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
-					  bond->dev->addr_len);
-			ss.ss_family = bond->dev->type;
-		}
-
-		rv = dev_set_mac_address(new_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv) {
-			slave_err(bond->dev, new_active->dev, "Error %d setting MAC of new active slave\n",
-				  -rv);
-			goto out;
-		}
-
-		if (!old_active)
-			goto out;
-
-		bond_hw_addr_copy(ss.__data, tmp_mac,
-				  new_active->dev->addr_len);
-		ss.ss_family = old_active->dev->type;
-
-		rv = dev_set_mac_address(old_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv)
-			slave_err(bond->dev, old_active->dev, "Error %d setting MAC of old active slave\n",
-				  -rv);
-out:
-		break;
-	default:
-		netdev_err(bond->dev, "bond_do_fail_over_mac impossible: bad policy %d\n",
-			   bond->params.fail_over_mac);
-		break;
-	}
-
-}
-
-static struct slave *bond_choose_primary_or_current(struct bonding *bond)
-{
-	struct slave *prim = rtnl_dereference(bond->primary_slave);
-	struct slave *curr = rtnl_dereference(bond->curr_active_slave);
-
-	if (!prim || prim->link != BOND_LINK_UP) {
-		if (!curr || curr->link != BOND_LINK_UP)
-			return NULL;
-		return curr;
-	}
-
-	if (bond->force_primary) {
-		bond->force_primary = false;
-		return prim;
-	}
-
-	if (!curr || curr->link != BOND_LINK_UP)
-		return prim;
-
-	/* At this point, prim and curr are both up */
-	switch (bond->params.primary_reselect) {
-	case BOND_PRI_RESELECT_ALWAYS:
-		return prim;
-	case BOND_PRI_RESELECT_BETTER:
-		if (prim->speed < curr->speed)
-			return curr;
-		if (prim->speed == curr->speed && prim->duplex <= curr->duplex)
-			return curr;
-		return prim;
-	case BOND_PRI_RESELECT_FAILURE:
-		return curr;
-	default:
-		netdev_err(bond->dev, "impossible primary_reselect %d\n",
-			   bond->params.primary_reselect);
-		return curr;
-	}
-}
-
-/**
- * bond_find_best_slave - select the best available slave to be the active one
- * @bond: our bonding struct
- */
-static struct slave *bond_find_best_slave(struct bonding *bond)
-{
-	struct slave *slave, *bestslave = NULL;
-	struct list_head *iter;
-	int mintime = bond->params.updelay;
-
-	slave = bond_choose_primary_or_current(bond);
-	if (slave)
-		return slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP)
-			return slave;
-		if (slave->link == BOND_LINK_BACK && bond_slave_is_up(slave) &&
-		    slave->delay < mintime) {
-			mintime = slave->delay;
-			bestslave = slave;
-		}
-	}
-
-	return bestslave;
-}
-
-static bool bond_should_notify_peers(struct bonding *bond)
-{
-	struct slave *slave;
-
-	rcu_read_lock();
-	slave = rcu_dereference(bond->curr_active_slave);
-	rcu_read_unlock();
-
-	netdev_dbg(bond->dev, "bond_should_notify_peers: slave %s\n",
-		   slave ? slave->dev->name : "NULL");
-
-	if (!slave || !bond->send_peer_notif ||
-	    bond->send_peer_notif %
-	    max(1, bond->params.peer_notif_delay) != 0 ||
-	    !netif_carrier_ok(bond->dev) ||
-	    test_bit(__LINK_STATE_LINKWATCH_PENDING, &slave->dev->state))
-		return false;
-
-	return true;
-}
-
-/**
- * change_active_interface - change the active slave into the specified one
- * @bond: our bonding struct
- * @new_active: the new slave to make the active one
- *
- * Set the new slave to the bond's settings and unset them on the old
- * curr_active_slave.
- * Setting include flags, mc-list, promiscuity, allmulti, etc.
- *
- * If @new's link state is %BOND_LINK_BACK we'll set it to %BOND_LINK_UP,
- * because it is apparently the best available slave we have, even though its
- * updelay hasn't timed out yet.
- *
- * Caller must hold RTNL.
- */
-void bond_change_active_slave(struct bonding *bond, struct slave *new_active)
-{
-	struct slave *old_active;
-
-	ASSERT_RTNL();
-
-	old_active = rtnl_dereference(bond->curr_active_slave);
-
-	if (old_active == new_active)
-		return;
-
-#ifdef CONFIG_XFRM_OFFLOAD
-	if (old_active && bond->xs)
-		bond_ipsec_del_sa(bond->xs);
-#endif /* CONFIG_XFRM_OFFLOAD */
-
-	if (new_active) {
-		new_active->last_link_up = jiffies;
-
-		if (new_active->link == BOND_LINK_BACK) {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one %d ms earlier\n",
-					   (bond->params.updelay - new_active->delay) * bond->params.miimon);
-			}
-
-			new_active->delay = 0;
-			bond_set_slave_link_state(new_active, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_3ad_handle_link_change(new_active, BOND_LINK_UP);
-
-			if (bond_is_lb(bond))
-				bond_alb_handle_link_change(bond, new_active, BOND_LINK_UP);
-		} else {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one\n");
-			}
-		}
-	}
-
-	if (bond_uses_primary(bond))
-		bond_hw_addr_swap(bond, new_active, old_active);
-
-	if (bond_is_lb(bond)) {
-		bond_alb_handle_active_change(bond, new_active);
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-		if (new_active)
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		rcu_assign_pointer(bond->curr_active_slave, new_active);
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP) {
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-		if (new_active) {
-			bool should_notify_peers = false;
-
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-
-			if (bond->params.fail_over_mac)
-				bond_do_fail_over_mac(bond, new_active,
-						      old_active);
-
-			if (netif_running(bond->dev)) {
-				bond->send_peer_notif =
-					bond->params.num_peer_notif *
-					max(1, bond->params.peer_notif_delay);
-				should_notify_peers =
-					bond_should_notify_peers(bond);
-			}
-
-			call_netdevice_notifiers(NETDEV_BONDING_FAILOVER, bond->dev);
-			if (should_notify_peers) {
-				bond->send_peer_notif--;
-				call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-							 bond->dev);
-			}
-		}
-	}
-
-#ifdef CONFIG_XFRM_OFFLOAD
-	if (new_active && bond->xs) {
-		xfrm_dev_state_flush(dev_net(bond->dev), bond->dev, true);
-		bond_ipsec_add_sa(bond->xs);
-	}
-#endif /* CONFIG_XFRM_OFFLOAD */
-
-	/* resend IGMP joins since active slave has changed or
-	 * all were sent on curr_active_slave.
-	 * resend only if bond is brought up with the affected
-	 * bonding modes and the retransmission is enabled
-	 */
-	if (netif_running(bond->dev) && (bond->params.resend_igmp > 0) &&
-	    ((bond_uses_primary(bond) && new_active) ||
-	     BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)) {
-		bond->igmp_retrans = bond->params.resend_igmp;
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-	}
-}
-
-/**
- * bond_select_active_slave - select a new active slave, if needed
- * @bond: our bonding struct
- *
- * This functions should be called when one of the following occurs:
- * - The old curr_active_slave has been released or lost its link.
- * - The primary_slave has got its link back.
- * - A slave has got its link back and there's no old curr_active_slave.
- *
- * Caller must hold RTNL.
- */
-void bond_select_active_slave(struct bonding *bond)
-{
-	struct slave *best_slave;
-	int rv;
-
-	ASSERT_RTNL();
-
-	best_slave = bond_find_best_slave(bond);
-	if (best_slave != rtnl_dereference(bond->curr_active_slave)) {
-		struct slave *last_slave = bond->curr_active_slave;
-
-		bond_change_active_slave(bond, best_slave);
-		toe_failover(bond->dev,
-			     bond->curr_active_slave ?
-			     bond->curr_active_slave->dev : NULL,
-			     TOE_ACTIVE_SLAVE,
-			     last_slave ? last_slave->dev : NULL);
-
-		rv = bond_set_carrier(bond);
-		if (!rv)
-			return;
-
-		if (netif_carrier_ok(bond->dev))
-			netdev_info(bond->dev, "active interface up!\n");
-		else
-			netdev_info(bond->dev, "now running without any active interface!\n");
-	}
-}
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	struct netpoll *np;
-	int err = 0;
-
-	np = kzalloc(sizeof(*np), GFP_KERNEL);
-	err = -ENOMEM;
-	if (!np)
-		goto out;
-
-	err = __netpoll_setup(np, slave->dev);
-	if (err) {
-		kfree(np);
-		goto out;
-	}
-	slave->np = np;
-out:
-	return err;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-	struct netpoll *np = slave->np;
-
-	if (!np)
-		return;
-
-	slave->np = NULL;
-
-	__netpoll_free(np);
-}
-
-static void bond_poll_controller(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-	struct ad_info ad_info;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		if (bond_3ad_get_active_agg_info(bond, &ad_info))
-			return;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!bond_slave_is_up(slave))
-			continue;
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg =
-			    SLAVE_AD_INFO(slave)->port.aggregator;
-
-			if (agg &&
-			    agg->aggregator_identifier != ad_info.aggregator_id)
-				continue;
-		}
-
-		netpoll_poll_dev(slave->dev);
-	}
-}
-
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		if (bond_slave_is_up(slave))
-			slave_disable_netpoll(slave);
-}
-
-static int bond_netpoll_setup(struct net_device *dev, struct netpoll_info *ni)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	struct slave *slave;
-	int err = 0;
-
-	bond_for_each_slave(bond, slave, iter) {
-		err = slave_enable_netpoll(slave);
-		if (err) {
-			bond_netpoll_cleanup(dev);
-			break;
-		}
-	}
-	return err;
-}
-#else
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	return 0;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-}
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-}
-#endif
-
-/*---------------------------------- IOCTL ----------------------------------*/
-
-static netdev_features_t bond_fix_features(struct net_device *dev,
-					   netdev_features_t features)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	netdev_features_t mask;
-	struct slave *slave;
-
-	mask = features;
-
-	features &= ~NETIF_F_ONE_FOR_ALL;
-	features |= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		features = netdev_increment_features(features,
-						     slave->dev->features,
-						     mask);
-	}
-	features = netdev_add_tso_features(features, mask);
-
-	return features;
-}
-
-#define BOND_VLAN_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_FRAGLIST | NETIF_F_ALL_TSO | \
-				 NETIF_F_HIGHDMA | NETIF_F_LRO)
-
-#define BOND_ENC_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_RXCSUM | NETIF_F_ALL_TSO)
-
-#define BOND_MPLS_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_ALL_TSO)
-
-
-static void bond_compute_features(struct bonding *bond)
-{
-	unsigned int dst_release_flag = IFF_XMIT_DST_RELEASE |
-					IFF_XMIT_DST_RELEASE_PERM;
-	netdev_features_t vlan_features = BOND_VLAN_FEATURES;
-	netdev_features_t enc_features  = BOND_ENC_FEATURES;
-#ifdef CONFIG_XFRM_OFFLOAD
-	netdev_features_t xfrm_features  = BOND_XFRM_FEATURES;
-#endif /* CONFIG_XFRM_OFFLOAD */
-	netdev_features_t mpls_features  = BOND_MPLS_FEATURES;
-	struct net_device *bond_dev = bond->dev;
-	struct list_head *iter;
-	struct slave *slave;
-	unsigned short max_hard_header_len = ETH_HLEN;
-	unsigned int gso_max_size = GSO_MAX_SIZE;
-	u16 gso_max_segs = GSO_MAX_SEGS;
-
-	if (!bond_has_slaves(bond))
-		goto done;
-	vlan_features &= NETIF_F_ALL_FOR_ALL;
-	mpls_features &= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		vlan_features = netdev_increment_features(vlan_features,
-			slave->dev->vlan_features, BOND_VLAN_FEATURES);
-
-		enc_features = netdev_increment_features(enc_features,
-							 slave->dev->hw_enc_features,
-							 BOND_ENC_FEATURES);
-
-#ifdef CONFIG_XFRM_OFFLOAD
-		xfrm_features = netdev_increment_features(xfrm_features,
-							  slave->dev->hw_enc_features,
-							  BOND_XFRM_FEATURES);
-#endif /* CONFIG_XFRM_OFFLOAD */
-
-		mpls_features = netdev_increment_features(mpls_features,
-							  slave->dev->mpls_features,
-							  BOND_MPLS_FEATURES);
-
-		dst_release_flag &= slave->dev->priv_flags;
-		if (slave->dev->hard_header_len > max_hard_header_len)
-			max_hard_header_len = slave->dev->hard_header_len;
-
-		gso_max_size = min(gso_max_size, slave->dev->gso_max_size);
-		gso_max_segs = min(gso_max_segs, slave->dev->gso_max_segs);
-	}
-	bond_dev->hard_header_len = max_hard_header_len;
-
-done:
-	bond_dev->vlan_features = vlan_features;
-	bond_dev->hw_enc_features = enc_features | NETIF_F_GSO_ENCAP_ALL |
-				    NETIF_F_HW_VLAN_CTAG_TX |
-				    NETIF_F_HW_VLAN_STAG_TX |
-				    NETIF_F_GSO_UDP_L4;
-#ifdef CONFIG_XFRM_OFFLOAD
-	bond_dev->hw_enc_features |= xfrm_features;
-#endif /* CONFIG_XFRM_OFFLOAD */
-	bond_dev->mpls_features = mpls_features;
-	bond_dev->gso_max_segs = gso_max_segs;
-	netif_set_gso_max_size(bond_dev, gso_max_size);
-
-	bond_dev->priv_flags &= ~IFF_XMIT_DST_RELEASE;
-	if ((bond_dev->priv_flags & IFF_XMIT_DST_RELEASE_PERM) &&
-	    dst_release_flag == (IFF_XMIT_DST_RELEASE | IFF_XMIT_DST_RELEASE_PERM))
-		bond_dev->priv_flags |= IFF_XMIT_DST_RELEASE;
-
-	netdev_change_features(bond_dev);
-}
-
-static void bond_setup_by_slave(struct net_device *bond_dev,
-				struct net_device *slave_dev)
-{
-	bond_dev->header_ops	    = slave_dev->header_ops;
-
-	bond_dev->type		    = slave_dev->type;
-	bond_dev->hard_header_len   = slave_dev->hard_header_len;
-	bond_dev->needed_headroom   = slave_dev->needed_headroom;
-	bond_dev->addr_len	    = slave_dev->addr_len;
-
-	memcpy(bond_dev->broadcast, slave_dev->broadcast,
-		slave_dev->addr_len);
-}
-
-/* On bonding slaves other than the currently active slave, suppress
- * duplicates except for alb non-mcast/bcast.
- */
-static bool bond_should_deliver_exact_match(struct sk_buff *skb,
-					    struct slave *slave,
-					    struct bonding *bond)
-{
-	if (bond_is_slave_inactive(slave)) {
-		if (BOND_MODE(bond) == BOND_MODE_ALB &&
-		    skb->pkt_type != PACKET_BROADCAST &&
-		    skb->pkt_type != PACKET_MULTICAST)
-			return false;
-		return true;
-	}
-	return false;
-}
-
-static rx_handler_result_t bond_handle_frame(struct sk_buff **pskb)
-{
-	struct sk_buff *skb = *pskb;
-	struct slave *slave;
-	struct bonding *bond;
-	int (*recv_probe)(const struct sk_buff *, struct bonding *,
-			  struct slave *);
-	int ret = RX_HANDLER_ANOTHER;
-
-	skb = skb_share_check(skb, GFP_ATOMIC);
-	if (unlikely(!skb))
-		return RX_HANDLER_CONSUMED;
-
-	*pskb = skb;
-
-	slave = bond_slave_get_rcu(skb->dev);
-	bond = slave->bond;
-
-	recv_probe = READ_ONCE(bond->recv_probe);
-	if (recv_probe) {
-		ret = recv_probe(skb, bond, slave);
-		if (ret == RX_HANDLER_CONSUMED) {
-			consume_skb(skb);
-			return ret;
-		}
-	}
-
-	/*
-	 * For packets determined by bond_should_deliver_exact_match() call to
-	 * be suppressed we want to make an exception for link-local packets.
-	 * This is necessary for e.g. LLDP daemons to be able to monitor
-	 * inactive slave links without being forced to bind to them
-	 * explicitly.
-	 *
-	 * At the same time, packets that are passed to the bonding master
-	 * (including link-local ones) can have their originating interface
-	 * determined via PACKET_ORIGDEV socket option.
-	 */
-	if (bond_should_deliver_exact_match(skb, slave, bond)) {
-		if (is_link_local_ether_addr(eth_hdr(skb)->h_dest))
-			return RX_HANDLER_PASS;
-		return RX_HANDLER_EXACT;
-	}
-
-	skb->dev = bond->dev;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB &&
-	    netif_is_bridge_port(bond->dev) &&
-	    skb->pkt_type == PACKET_HOST) {
-
-		if (unlikely(skb_cow_head(skb,
-					  skb->data - skb_mac_header(skb)))) {
-			kfree_skb(skb);
-			return RX_HANDLER_CONSUMED;
-		}
-		bond_hw_addr_copy(eth_hdr(skb)->h_dest, bond->dev->dev_addr,
-				  bond->dev->addr_len);
-	}
-
-	return ret;
-}
-
-static enum netdev_lag_tx_type bond_lag_tx_type(struct bonding *bond)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return NETDEV_LAG_TX_TYPE_ROUNDROBIN;
-	case BOND_MODE_ACTIVEBACKUP:
-		return NETDEV_LAG_TX_TYPE_ACTIVEBACKUP;
-	case BOND_MODE_BROADCAST:
-		return NETDEV_LAG_TX_TYPE_BROADCAST;
-	case BOND_MODE_XOR:
-	case BOND_MODE_8023AD:
-		return NETDEV_LAG_TX_TYPE_HASH;
-	default:
-		return NETDEV_LAG_TX_TYPE_UNKNOWN;
-	}
-}
-
-static enum netdev_lag_hash bond_lag_hash_type(struct bonding *bond,
-					       enum netdev_lag_tx_type type)
-{
-	if (type != NETDEV_LAG_TX_TYPE_HASH)
-		return NETDEV_LAG_HASH_NONE;
-
-	switch (bond->params.xmit_policy) {
-	case BOND_XMIT_POLICY_LAYER2:
-		return NETDEV_LAG_HASH_L2;
-	case BOND_XMIT_POLICY_LAYER34:
-		return NETDEV_LAG_HASH_L34;
-	case BOND_XMIT_POLICY_LAYER23:
-		return NETDEV_LAG_HASH_L23;
-	case BOND_XMIT_POLICY_ENCAP23:
-		return NETDEV_LAG_HASH_E23;
-	case BOND_XMIT_POLICY_ENCAP34:
-		return NETDEV_LAG_HASH_E34;
-	default:
-		return NETDEV_LAG_HASH_UNKNOWN;
-	}
-}
-
-static int bond_master_upper_dev_link(struct bonding *bond, struct slave *slave,
-				      struct netlink_ext_ack *extack)
-{
-	struct netdev_lag_upper_info lag_upper_info;
-	enum netdev_lag_tx_type type;
-
-	type = bond_lag_tx_type(bond);
-	lag_upper_info.tx_type = type;
-	lag_upper_info.hash_type = bond_lag_hash_type(bond, type);
-
-	return netdev_master_upper_dev_link(slave->dev, bond->dev, slave,
-					    &lag_upper_info, extack);
-}
-
-static void bond_upper_dev_unlink(struct bonding *bond, struct slave *slave)
-{
-	netdev_upper_dev_unlink(slave->dev, bond->dev);
-	slave->dev->flags &= ~IFF_SLAVE;
-}
-
-static void slave_kobj_release(struct kobject *kobj)
-{
-	struct slave *slave = to_slave(kobj);
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-
-	cancel_delayed_work_sync(&slave->notify_work);
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		kfree(SLAVE_AD_INFO(slave));
-
-	kfree(slave);
-}
-
-static struct kobj_type slave_ktype = {
-	.release = slave_kobj_release,
-#ifdef CONFIG_SYSFS
-	.sysfs_ops = &slave_sysfs_ops,
-#endif
-};
-
-static int bond_kobj_init(struct slave *slave)
-{
-	int err;
-
-	err = kobject_init_and_add(&slave->kobj, &slave_ktype,
-				   &(slave->dev->dev.kobj), "bonding_slave");
-	if (err)
-		kobject_put(&slave->kobj);
-
-	return err;
-}
-
-static struct slave *bond_alloc_slave(struct bonding *bond,
-				      struct net_device *slave_dev)
-{
-	struct slave *slave = NULL;
-
-	slave = kzalloc(sizeof(*slave), GFP_KERNEL);
-	if (!slave)
-		return NULL;
-
-	slave->bond = bond;
-	slave->dev = slave_dev;
-
-	if (bond_kobj_init(slave))
-		return NULL;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		SLAVE_AD_INFO(slave) = kzalloc(sizeof(struct ad_slave_info),
-					       GFP_KERNEL);
-		if (!SLAVE_AD_INFO(slave)) {
-			kobject_put(&slave->kobj);
-			return NULL;
-		}
-	}
-	INIT_DELAYED_WORK(&slave->notify_work, bond_netdev_notify_work);
-
-	return slave;
-}
-
-static void bond_fill_ifbond(struct bonding *bond, struct ifbond *info)
-{
-	info->bond_mode = BOND_MODE(bond);
-	info->miimon = bond->params.miimon;
-	info->num_slaves = bond->slave_cnt;
-}
-
-static void bond_fill_ifslave(struct slave *slave, struct ifslave *info)
-{
-	strcpy(info->slave_name, slave->dev->name);
-	info->link = slave->link;
-	info->state = bond_slave_state(slave);
-	info->link_failure_count = slave->link_failure_count;
-}
-
-static void bond_netdev_notify_work(struct work_struct *_work)
-{
-	struct slave *slave = container_of(_work, struct slave,
-					   notify_work.work);
-
-	if (rtnl_trylock()) {
-		struct netdev_bonding_info binfo;
-
-		bond_fill_ifslave(slave, &binfo.slave);
-		bond_fill_ifbond(slave->bond, &binfo.master);
-		netdev_bonding_info_change(slave->dev, &binfo);
-		rtnl_unlock();
-	} else {
-		queue_delayed_work(slave->bond->wq, &slave->notify_work, 1);
-	}
-}
-
-void bond_queue_slave_event(struct slave *slave)
-{
-	queue_delayed_work(slave->bond->wq, &slave->notify_work, 0);
-}
-
-void bond_lower_state_changed(struct slave *slave)
-{
-	struct netdev_lag_lower_state_info info;
-
-	info.link_up = slave->link == BOND_LINK_UP ||
-		       slave->link == BOND_LINK_FAIL;
-	info.tx_enabled = bond_is_active_slave(slave);
-	netdev_lower_state_changed(slave->dev, &info);
-}
-
-/* enslave device <slave> to bond device <master> */
-int bond_enslave(struct net_device *bond_dev, struct net_device *slave_dev,
-		 struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	struct slave *new_slave = NULL, *prev_slave;
-	struct sockaddr_storage ss;
-	int link_reporting;
-	int res = 0, i;
-
-	if (!bond->params.use_carrier &&
-	    slave_dev->ethtool_ops->get_link == NULL &&
-	    slave_ops->ndo_do_ioctl == NULL) {
-		slave_warn(bond_dev, slave_dev, "no link monitoring support\n");
-	}
-
-	/* already in-use? */
-	if (netdev_is_rx_handler_busy(slave_dev)) {
-		NL_SET_ERR_MSG(extack, "Device is in use and cannot be enslaved");
-		slave_err(bond_dev, slave_dev,
-			  "Error: Device is in use and cannot be enslaved\n");
-		return -EBUSY;
-	}
-
-	if (bond_dev == slave_dev) {
-		NL_SET_ERR_MSG(extack, "Cannot enslave bond to itself.");
-		netdev_err(bond_dev, "cannot enslave bond to itself.\n");
-		return -EPERM;
-	}
-
-	/* vlan challenged mutual exclusion */
-	/* no need to lock since we're protected by rtnl_lock */
-	if (slave_dev->features & NETIF_F_VLAN_CHALLENGED) {
-		slave_dbg(bond_dev, slave_dev, "is NETIF_F_VLAN_CHALLENGED\n");
-		if (vlan_uses_dev(bond_dev)) {
-			NL_SET_ERR_MSG(extack, "Can not enslave VLAN challenged device to VLAN enabled bond");
-			slave_err(bond_dev, slave_dev, "Error: cannot enslave VLAN challenged slave on VLAN enabled bond\n");
-			return -EPERM;
-		} else {
-			slave_warn(bond_dev, slave_dev, "enslaved VLAN challenged slave. Adding VLANs will be blocked as long as it is part of bond.\n");
-		}
-	} else {
-		slave_dbg(bond_dev, slave_dev, "is !NETIF_F_VLAN_CHALLENGED\n");
-	}
-
-	if (slave_dev->features & NETIF_F_HW_ESP)
-		slave_dbg(bond_dev, slave_dev, "is esp-hw-offload capable\n");
-
-	/* Old ifenslave binaries are no longer supported.  These can
-	 * be identified with moderate accuracy by the state of the slave:
-	 * the current ifenslave will set the interface down prior to
-	 * enslaving it; the old ifenslave will not.
-	 */
-	if (slave_dev->flags & IFF_UP) {
-		NL_SET_ERR_MSG(extack, "Device can not be enslaved while up");
-		slave_err(bond_dev, slave_dev, "slave is up - this may be due to an out of date ifenslave\n");
-		return -EPERM;
-	}
-
-	/* set bonding device ether type by slave - bonding netdevices are
-	 * created with ether_setup, so when the slave type is not ARPHRD_ETHER
-	 * there is a need to override some of the type dependent attribs/funcs.
-	 *
-	 * bond ether type mutual exclusion - don't allow slaves of dissimilar
-	 * ether type (eg ARPHRD_ETHER and ARPHRD_INFINIBAND) share the same bond
-	 */
-	if (!bond_has_slaves(bond)) {
-		if (bond_dev->type != slave_dev->type) {
-			slave_dbg(bond_dev, slave_dev, "change device type from %d to %d\n",
-				  bond_dev->type, slave_dev->type);
-
-			res = call_netdevice_notifiers(NETDEV_PRE_TYPE_CHANGE,
-						       bond_dev);
-			res = notifier_to_errno(res);
-			if (res) {
-				slave_err(bond_dev, slave_dev, "refused to change device type\n");
-				return -EBUSY;
-			}
-
-			/* Flush unicast and multicast addresses */
-			dev_uc_flush(bond_dev);
-			dev_mc_flush(bond_dev);
-
-			if (slave_dev->type != ARPHRD_ETHER)
-				bond_setup_by_slave(bond_dev, slave_dev);
-			else {
-				ether_setup(bond_dev);
-				bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-			}
-
-			call_netdevice_notifiers(NETDEV_POST_TYPE_CHANGE,
-						 bond_dev);
-		}
-	} else if (bond_dev->type != slave_dev->type) {
-		NL_SET_ERR_MSG(extack, "Device type is different from other slaves");
-		slave_err(bond_dev, slave_dev, "ether type (%d) is different from other slaves (%d), can not enslave it\n",
-			  slave_dev->type, bond_dev->type);
-		return -EINVAL;
-	}
-
-	if (slave_dev->type == ARPHRD_INFINIBAND &&
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		NL_SET_ERR_MSG(extack, "Only active-backup mode is supported for infiniband slaves");
-		slave_warn(bond_dev, slave_dev, "Type (%d) supports only active-backup mode\n",
-			   slave_dev->type);
-		res = -EOPNOTSUPP;
-		goto err_undo_flags;
-	}
-
-	if (!slave_ops->ndo_set_mac_address ||
-	    slave_dev->type == ARPHRD_INFINIBAND) {
-		slave_warn(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address\n");
-		if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
-		    bond->params.fail_over_mac != BOND_FOM_ACTIVE) {
-			if (!bond_has_slaves(bond)) {
-				bond->params.fail_over_mac = BOND_FOM_ACTIVE;
-				slave_warn(bond_dev, slave_dev, "Setting fail_over_mac to active for active-backup mode\n");
-			} else {
-				NL_SET_ERR_MSG(extack, "Slave device does not support setting the MAC address, but fail_over_mac is not set to active");
-				slave_err(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address, but fail_over_mac is not set to active\n");
-				res = -EOPNOTSUPP;
-				goto err_undo_flags;
-			}
-		}
-	}
-
-	call_netdevice_notifiers(NETDEV_JOIN, slave_dev);
-
-	/* If this is the first slave, then we need to set the master's hardware
-	 * address to be the same as the slave's.
-	 */
-	if (!bond_has_slaves(bond) &&
-	    bond->dev->addr_assign_type == NET_ADDR_RANDOM) {
-		res = bond_set_dev_addr(bond->dev, slave_dev);
-		if (res)
-			goto err_undo_flags;
-	}
-
-	new_slave = bond_alloc_slave(bond, slave_dev);
-	if (!new_slave) {
-		res = -ENOMEM;
-		goto err_undo_flags;
-	}
-
-	/* Set the new_slave's queue_id to be zero.  Queue ID mapping
-	 * is set via sysfs or module option if desired.
-	 */
-	new_slave->queue_id = 0;
-
-	/* Save slave's original mtu and then set it to match the bond */
-	new_slave->original_mtu = slave_dev->mtu;
-	res = dev_set_mtu(slave_dev, bond->dev->mtu);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Error %d calling dev_set_mtu\n", res);
-		goto err_free;
-	}
-
-	/* Save slave's original ("permanent") mac address for modes
-	 * that need it, and for restoring it upon release, and then
-	 * set it to the master's address
-	 */
-	bond_hw_addr_copy(new_slave->perm_hwaddr, slave_dev->dev_addr,
-			  slave_dev->addr_len);
-
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* Set slave to master's mac address.  The application already
-		 * set the master's mac address to that of the first slave
-		 */
-		memcpy(ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		res = dev_set_mac_address(slave_dev, (struct sockaddr *)&ss,
-					  extack);
-		if (res) {
-			slave_err(bond_dev, slave_dev, "Error %d calling set_mac_address\n", res);
-			goto err_restore_mtu;
-		}
-	}
-
-	/* set slave flag before open to prevent IPv6 addrconf */
-	slave_dev->flags |= IFF_SLAVE;
-
-	/* open the slave since the application closed it */
-	res = dev_open(slave_dev, extack);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Opening slave failed\n");
-		goto err_restore_mac;
-	}
-
-	slave_dev->priv_flags |= IFF_BONDING;
-	/* initialize slave stats */
-	dev_get_stats(new_slave->dev, &new_slave->slave_stats);
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_init_slave() must be called before all other stages since
-		 * it might fail and we do not want to have to undo everything
-		 */
-		res = bond_alb_init_slave(bond, new_slave);
-		if (res)
-			goto err_close;
-	}
-
-	res = vlan_vids_add_by_dev(slave_dev, bond_dev);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Couldn't add bond vlan ids\n");
-		goto err_close;
-	}
-
-	prev_slave = bond_last_slave(bond);
-
-	new_slave->delay = 0;
-	new_slave->link_failure_count = 0;
-
-	if (bond_update_speed_duplex(new_slave) &&
-	    bond_needs_speed_duplex(bond))
-		new_slave->link = BOND_LINK_DOWN;
-
-	new_slave->last_rx = jiffies -
-		(msecs_to_jiffies(bond->params.arp_interval) + 1);
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
-		new_slave->target_last_arp_rx[i] = new_slave->last_rx;
-
-	if (bond->params.miimon && !bond->params.use_carrier) {
-		link_reporting = bond_check_dev_link(bond, slave_dev, 1);
-
-		if ((link_reporting == -1) && !bond->params.arp_interval) {
-			/* miimon is set but a bonded network driver
-			 * does not support ETHTOOL/MII and
-			 * arp_interval is not set.  Note: if
-			 * use_carrier is enabled, we will never go
-			 * here (because netif_carrier is always
-			 * supported); thus, we don't need to change
-			 * the messages for netif_carrier.
-			 */
-			slave_warn(bond_dev, slave_dev, "MII and ETHTOOL support not available for slave, and arp_interval/arp_ip_target module parameters not specified, thus bonding will not detect link failures! see bonding.txt for details\n");
-		} else if (link_reporting == -1) {
-			/* unable get link status using mii/ethtool */
-			slave_warn(bond_dev, slave_dev, "can't get link status from slave; the network driver associated with this interface does not support MII or ETHTOOL link status reporting, thus miimon has no effect on this interface\n");
-		}
-	}
-
-	/* check for initial state */
-	new_slave->link = BOND_LINK_NOCHANGE;
-	if (bond->params.miimon) {
-		if (bond_check_dev_link(bond, slave_dev, 0) == BMSR_LSTATUS) {
-			if (bond->params.updelay) {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_BACK,
-							  BOND_SLAVE_NOTIFY_NOW);
-				new_slave->delay = bond->params.updelay;
-			} else {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-			}
-		} else {
-			bond_set_slave_link_state(new_slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-		}
-	} else if (bond->params.arp_interval) {
-		bond_set_slave_link_state(new_slave,
-					  (netif_carrier_ok(slave_dev) ?
-					  BOND_LINK_UP : BOND_LINK_DOWN),
-					  BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		bond_set_slave_link_state(new_slave, BOND_LINK_UP,
-					  BOND_SLAVE_NOTIFY_NOW);
-	}
-
-	if (new_slave->link != BOND_LINK_DOWN)
-		new_slave->last_link_up = jiffies;
-	slave_dbg(bond_dev, slave_dev, "Initial state of slave is BOND_LINK_%s\n",
-		  new_slave->link == BOND_LINK_DOWN ? "DOWN" :
-		  (new_slave->link == BOND_LINK_UP ? "UP" : "BACK"));
-
-	if (bond_uses_primary(bond) && bond->params.primary[0]) {
-		/* if there is a primary slave, remember it */
-		if (strcmp(bond->params.primary, new_slave->dev->name) == 0) {
-			rcu_assign_pointer(bond->primary_slave, new_slave);
-			bond->force_primary = true;
-		}
-	}
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ACTIVEBACKUP:
-		bond_set_slave_inactive_flags(new_slave,
-					      BOND_SLAVE_NOTIFY_NOW);
-		break;
-	case BOND_MODE_8023AD:
-		/* in 802.3ad mode, the internal mechanism
-		 * will activate the slaves in the selected
-		 * aggregator
-		 */
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		/* if this is the first slave */
-		if (!prev_slave) {
-			SLAVE_AD_INFO(new_slave)->id = 1;
-			/* Initialize AD with the number of times that the AD timer is called in 1 second
-			 * can be called only after the mac address of the bond is set
-			 */
-			bond_3ad_initialize(bond, 1000/AD_TIMER_INTERVAL);
-		} else {
-			SLAVE_AD_INFO(new_slave)->id =
-				SLAVE_AD_INFO(prev_slave)->id + 1;
-		}
-
-		bond_3ad_bind_slave(new_slave);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_set_active_slave(new_slave);
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		break;
-	default:
-		slave_dbg(bond_dev, slave_dev, "This slave is always active in trunk mode\n");
-
-		/* always active in trunk mode */
-		bond_set_active_slave(new_slave);
-
-		/* In trunking mode there is little meaning to curr_active_slave
-		 * anyway (it holds no special properties of the bond device),
-		 * so we can change it without calling change_active_interface()
-		 */
-		if (!rcu_access_pointer(bond->curr_active_slave) &&
-		    new_slave->link == BOND_LINK_UP)
-			rcu_assign_pointer(bond->curr_active_slave, new_slave);
-
-		break;
-	} /* switch(bond_mode) */
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	if (bond->dev->npinfo) {
-		if (slave_enable_netpoll(new_slave)) {
-			slave_info(bond_dev, slave_dev, "master_dev is using netpoll, but new slave device does not support netpoll\n");
-			res = -EBUSY;
-			goto err_detach;
-		}
-	}
-#endif
-
-	if (!(bond_dev->features & NETIF_F_LRO))
-		dev_disable_lro(slave_dev);
-
-	res = netdev_rx_handler_register(slave_dev, bond_handle_frame,
-					 new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling netdev_rx_handler_register\n", res);
-		goto err_detach;
-	}
-
-	res = bond_master_upper_dev_link(bond, new_slave, extack);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_master_upper_dev_link\n", res);
-		goto err_unregister;
-	}
-
-	res = bond_sysfs_slave_add(new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_sysfs_slave_add\n", res);
-		goto err_upper_unlink;
-	}
-
-	/* If the mode uses primary, then the following is handled by
-	 * bond_change_active_slave().
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* set promiscuity level to new slave */
-		if (bond_dev->flags & IFF_PROMISC) {
-			res = dev_set_promiscuity(slave_dev, 1);
-			if (res)
-				goto err_sysfs_del;
-		}
-
-		/* set allmulti level to new slave */
-		if (bond_dev->flags & IFF_ALLMULTI) {
-			res = dev_set_allmulti(slave_dev, 1);
-			if (res) {
-				if (bond_dev->flags & IFF_PROMISC)
-					dev_set_promiscuity(slave_dev, -1);
-				goto err_sysfs_del;
-			}
-		}
-
-		netif_addr_lock_bh(bond_dev);
-		dev_mc_sync_multiple(slave_dev, bond_dev);
-		dev_uc_sync_multiple(slave_dev, bond_dev);
-		netif_addr_unlock_bh(bond_dev);
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			/* add lacpdu mc addr to mc list */
-			u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-			dev_mc_add(slave_dev, lacpdu_multicast);
-		}
-	}
-
-	bond->slave_cnt++;
-	bond_compute_features(bond);
-	bond_set_carrier(bond);
-
-	if (bond_uses_primary(bond)) {
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-
-	slave_info(bond_dev, slave_dev, "Enslaving as %s interface with %s link\n",
-		   bond_is_active_slave(new_slave) ? "an active" : "a backup",
-		   new_slave->link != BOND_LINK_DOWN ? "an up" : "a down");
-
-	/* enslave is successful */
-	bond_queue_slave_event(new_slave);
-	return 0;
-
-/* Undo stages on error */
-err_sysfs_del:
-	bond_sysfs_slave_del(new_slave);
-
-err_upper_unlink:
-	bond_upper_dev_unlink(bond, new_slave);
-
-err_unregister:
-	netdev_rx_handler_unregister(slave_dev);
-
-err_detach:
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-	if (rcu_access_pointer(bond->primary_slave) == new_slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-	if (rcu_access_pointer(bond->curr_active_slave) == new_slave) {
-		block_netpoll_tx();
-		bond_change_active_slave(bond, NULL);
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-	/* either primary_slave or curr_active_slave might've changed */
-	synchronize_rcu();
-	slave_disable_netpoll(new_slave);
-
-err_close:
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-	dev_close(slave_dev);
-
-err_restore_mac:
-	slave_dev->flags &= ~IFF_SLAVE;
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* XXX TODO - fom follow mode needs to change master's
-		 * MAC if this slave's MAC is in use by the bond, or at
-		 * least print a warning.
-		 */
-		bond_hw_addr_copy(ss.__data, new_slave->perm_hwaddr,
-				  new_slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-err_restore_mtu:
-	dev_set_mtu(slave_dev, new_slave->original_mtu);
-
-err_free:
-	kobject_put(&new_slave->kobj);
-
-err_undo_flags:
-	/* Enslave of first slave has failed and we need to fix master's mac */
-	if (!bond_has_slaves(bond)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr,
-					    slave_dev->dev_addr))
-			eth_hw_addr_random(bond_dev);
-		if (bond_dev->type != ARPHRD_ETHER) {
-			dev_close(bond_dev);
-			ether_setup(bond_dev);
-			bond_dev->flags |= IFF_MASTER;
-			bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-		}
-	}
-
-	return res;
-}
-
-/* Try to release the slave device <slave> from the bond device <master>
- * It is legal to access curr_active_slave without a lock because all the function
- * is RTNL-locked. If "all" is true it means that the function is being called
- * while destroying a bond interface and all slaves are being released.
- *
- * The rules for slave state should be:
- *   for Active/Backup:
- *     Active stays on all backups go down
- *   for Bonded connections:
- *     The first up interface should be left on and all others downed.
- */
-static int __bond_release_one(struct net_device *bond_dev,
-			      struct net_device *slave_dev,
-			      bool all, bool unregister)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *oldcurrent;
-	struct sockaddr_storage ss;
-	int old_flags = bond_dev->flags;
-	netdev_features_t old_features = bond_dev->features;
-
-	/* slave is not a slave or master is not master of this slave */
-	if (!(slave_dev->flags & IFF_SLAVE) ||
-	    !netdev_has_upper_dev(slave_dev, bond_dev)) {
-		slave_dbg(bond_dev, slave_dev, "cannot release slave\n");
-		return -EINVAL;
-	}
-
-	block_netpoll_tx();
-
-	slave = bond_get_slave_by_dev(bond, slave_dev);
-	if (!slave) {
-		/* not a slave of this bond */
-		slave_info(bond_dev, slave_dev, "interface not enslaved\n");
-		unblock_netpoll_tx();
-		return -EINVAL;
-	}
-
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
-	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
-
-	bond_sysfs_slave_del(slave);
-
-	/* recompute stats just before removing the slave */
-	bond_get_stats(bond->dev, &bond->bond_stats);
-
-	bond_upper_dev_unlink(bond, slave);
-	/* unregister rx_handler early so bond_handle_frame wouldn't be called
-	 * for this slave anymore.
-	 */
-	netdev_rx_handler_unregister(slave_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		bond_3ad_unbind_slave(slave);
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, slave);
-
-	slave_info(bond_dev, slave_dev, "Releasing %s interface\n",
-		    bond_is_active_slave(slave) ? "active" : "backup");
-
-	oldcurrent = rcu_access_pointer(bond->curr_active_slave);
-
-	RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-
-	if (!all && (!bond->params.fail_over_mac ||
-		     BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr, slave->perm_hwaddr) &&
-		    bond_has_slaves(bond))
-			slave_warn(bond_dev, slave_dev, "the permanent HWaddr of slave - %pM - is still in use by bond - set the HWaddr of slave to a different address to avoid conflicts\n",
-				   slave->perm_hwaddr);
-	}
-
-	if (rtnl_dereference(bond->primary_slave) == slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-
-	if (oldcurrent == slave)
-		bond_change_active_slave(bond, NULL);
-
-	if (bond_is_lb(bond)) {
-		/* Must be called only after the slave has been
-		 * detached from the list and the curr_active_slave
-		 * has been cleared (if our_slave == old_current),
-		 * but before a new active slave is selected.
-		 */
-		bond_alb_deinit_slave(bond, slave);
-	}
-
-	if (all) {
-		toe_failover(bond_dev, NULL, TOE_RELEASE_ALL, NULL);
-		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
-	} else if (oldcurrent == slave) {
-		/* Note that we hold RTNL over this sequence, so there
-		 * is no concern that another slave add/remove event
-		 * will interfere.
-		 */
-		bond_select_active_slave(bond);
-	}
-
-	if (!bond_has_slaves(bond)) {
-		bond_set_carrier(bond);
-		eth_hw_addr_random(bond_dev);
-	}
-
-	unblock_netpoll_tx();
-	synchronize_rcu();
-	bond->slave_cnt--;
-
-	if (!bond_has_slaves(bond)) {
-		call_netdevice_notifiers(NETDEV_CHANGEADDR, bond->dev);
-		call_netdevice_notifiers(NETDEV_RELEASE, bond->dev);
-	}
-
-	bond_compute_features(bond);
-	if (!(bond_dev->features & NETIF_F_VLAN_CHALLENGED) &&
-	    (old_features & NETIF_F_VLAN_CHALLENGED))
-		slave_info(bond_dev, slave_dev, "last VLAN challenged slave left bond - VLAN blocking is removed\n");
-
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-
-	/* If the mode uses primary, then this case was handled above by
-	 * bond_change_active_slave(..., NULL)
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* unset promiscuity level from slave
-		 * NOTE: The NETDEV_CHANGEADDR call above may change the value
-		 * of the IFF_PROMISC flag in the bond_dev, but we need the
-		 * value of that flag before that change, as that was the value
-		 * when this slave was attached, so we cache at the start of the
-		 * function and use it here. Same goes for ALLMULTI below
-		 */
-		if (old_flags & IFF_PROMISC)
-			dev_set_promiscuity(slave_dev, -1);
-
-		/* unset allmulti level from slave */
-		if (old_flags & IFF_ALLMULTI)
-			dev_set_allmulti(slave_dev, -1);
-
-		bond_hw_addr_flush(bond_dev, slave_dev);
-	}
-
-	slave_disable_netpoll(slave);
-
-	/* close slave before restoring its mac address */
-	dev_close(slave_dev);
-
-	if (bond->params.fail_over_mac != BOND_FOM_ACTIVE ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* restore original ("permanent") mac address */
-		bond_hw_addr_copy(ss.__data, slave->perm_hwaddr,
-				  slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-	if (unregister)
-		__dev_set_mtu(slave_dev, slave->original_mtu);
-	else
-		dev_set_mtu(slave_dev, slave->original_mtu);
-
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-
-	kobject_put(&slave->kobj);
-
-	return 0;
-}
-
-/* A wrapper used because of ndo_del_link */
-int bond_release(struct net_device *bond_dev, struct net_device *slave_dev)
-{
-	return __bond_release_one(bond_dev, slave_dev, false, false);
-}
-
-/* First release a slave and then destroy the bond if no more slaves are left.
- * Must be under rtnl_lock when this function is called.
- */
-static int bond_release_and_destroy(struct net_device *bond_dev,
-				    struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	int ret;
-
-	ret = __bond_release_one(bond_dev, slave_dev, false, true);
-	if (ret == 0 && !bond_has_slaves(bond) &&
-	    bond_dev->reg_state != NETREG_UNREGISTERING) {
-		bond_dev->priv_flags |= IFF_DISABLE_NETPOLL;
-		netdev_info(bond_dev, "Destroying bond\n");
-		bond_remove_proc_entry(bond);
-		unregister_netdevice(bond_dev);
-	}
-	return ret;
-}
-
-static void bond_info_query(struct net_device *bond_dev, struct ifbond *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	bond_fill_ifbond(bond, info);
-}
-
-static int bond_slave_info_query(struct net_device *bond_dev, struct ifslave *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	int i = 0, res = -ENODEV;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (i++ == (int)info->slave_id) {
-			res = 0;
-			bond_fill_ifslave(slave, info);
-			break;
-		}
-	}
-
-	return res;
-}
-
-/*-------------------------------- Monitoring -------------------------------*/
-
-/* called with rcu_read_lock() */
-static int bond_miimon_inspect(struct bonding *bond)
-{
-	int link_state, commit = 0;
-	struct list_head *iter;
-	struct slave *slave;
-	bool ignore_updelay;
-
-	ignore_updelay = !rcu_dereference(bond->curr_active_slave);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		link_state = bond_check_dev_link(bond, slave->dev, 0);
-
-		switch (slave->link) {
-		case BOND_LINK_UP:
-			if (link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_FAIL);
-			commit++;
-			slave->delay = bond->params.downdelay;
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status down for %sinterface, disabling it in %d ms\n",
-					   (BOND_MODE(bond) ==
-					    BOND_MODE_ACTIVEBACKUP) ?
-					    (bond_is_active_slave(slave) ?
-					     "active " : "backup ") : "",
-					   bond->params.downdelay * bond->params.miimon);
-			}
-			fallthrough;
-		case BOND_LINK_FAIL:
-			if (link_state) {
-				/* recovered before downdelay expired */
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave->last_link_up = jiffies;
-				slave_info(bond->dev, slave->dev, "link status up again after %d ms\n",
-					   (bond->params.downdelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				commit++;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-
-		case BOND_LINK_DOWN:
-			if (!link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_BACK);
-			commit++;
-			slave->delay = bond->params.updelay;
-
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status up, enabling it in %d ms\n",
-					   ignore_updelay ? 0 :
-					   bond->params.updelay *
-					   bond->params.miimon);
-			}
-			fallthrough;
-		case BOND_LINK_BACK:
-			if (!link_state) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_info(bond->dev, slave->dev, "link status down again after %d ms\n",
-					   (bond->params.updelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (ignore_updelay)
-				slave->delay = 0;
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-				ignore_updelay = false;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-		}
-	}
-
-	return commit;
-}
-
-static void bond_miimon_link_change(struct bonding *bond,
-				    struct slave *slave,
-				    char link)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_8023AD:
-		bond_3ad_handle_link_change(slave, link);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_alb_handle_link_change(bond, slave, link);
-		break;
-	case BOND_MODE_XOR:
-		bond_update_slave_arr(bond, NULL);
-		break;
-	}
-}
-
-static void bond_miimon_commit(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave, *primary;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			/* For 802.3ad mode, check current slave speed and
-			 * duplex again in case its port was disabled after
-			 * invalid speed/duplex reporting but recovered before
-			 * link monitoring could make a decision on the actual
-			 * link status
-			 */
-			if (BOND_MODE(bond) == BOND_MODE_8023AD &&
-			    slave->link == BOND_LINK_UP)
-				bond_3ad_adapter_speed_duplex_changed(slave);
-			continue;
-
-		case BOND_LINK_UP:
-			if (bond_update_speed_duplex(slave) &&
-			    bond_needs_speed_duplex(bond)) {
-				slave->link = BOND_LINK_DOWN;
-				if (net_ratelimit())
-					slave_warn(bond->dev, slave->dev,
-						   "failed to get link speed/duplex\n");
-				continue;
-			}
-			bond_set_slave_link_state(slave, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-			slave->last_link_up = jiffies;
-
-			primary = rtnl_dereference(bond->primary_slave);
-			if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-				/* prevent it from being the active one */
-				bond_set_backup_slave(slave);
-			} else if (BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-				/* make it immediately active */
-				bond_set_active_slave(slave);
-			}
-
-			slave_info(bond->dev, slave->dev, "link status definitely up, %u Mbps %s duplex\n",
-				   slave->speed == SPEED_UNKNOWN ? 0 : slave->speed,
-				   slave->duplex ? "full" : "half");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_UP);
-
-			if (BOND_MODE(bond) == BOND_MODE_XOR ||
-			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
-				toe_failover(netdev_master_upper_dev_get(slave->dev),
-					     slave->dev, TOE_LINK_UP, NULL);
-			if (!bond->curr_active_slave || slave == primary)
-				goto do_failover;
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP ||
-			    BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_DOWN);
-
-			if (BOND_MODE(bond) == BOND_MODE_XOR ||
-			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
-				toe_failover(netdev_master_upper_dev_get(slave->dev),
-					     slave->dev, TOE_LINK_DOWN, NULL);
-			if (slave == rcu_access_pointer(bond->curr_active_slave))
-				goto do_failover;
-
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev, "invalid new link %d on slave\n",
-				  slave->link_new_state);
-			bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* bond_mii_monitor
- *
- * Really a wrapper that splits the mii monitor into two phases: an
- * inspection, then (if inspection indicates something needs to be done)
- * an acquisition of appropriate locks followed by a commit phase to
- * implement whatever link state changes are indicated.
- */
-static void bond_mii_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mii_work.work);
-	bool should_notify_peers = false;
-	bool commit;
-	unsigned long delay;
-	struct slave *slave;
-	struct list_head *iter;
-
-	delay = msecs_to_jiffies(bond->params.miimon);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-	should_notify_peers = bond_should_notify_peers(bond);
-	commit = !!bond_miimon_inspect(bond);
-	if (bond->send_peer_notif) {
-		rcu_read_unlock();
-		if (rtnl_trylock()) {
-			bond->send_peer_notif--;
-			rtnl_unlock();
-		}
-	} else {
-		rcu_read_unlock();
-	}
-
-	if (commit) {
-		/* Race avoidance with bond_close cancel of workqueue */
-		if (!rtnl_trylock()) {
-			delay = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_for_each_slave(bond, slave, iter) {
-			bond_commit_link_state(slave, BOND_SLAVE_NOTIFY_LATER);
-		}
-		bond_miimon_commit(bond);
-
-		rtnl_unlock();	/* might sleep, hold no other locks */
-	}
-
-re_arm:
-	if (bond->params.miimon)
-		queue_delayed_work(bond->wq, &bond->mii_work, delay);
-
-	if (should_notify_peers) {
-		if (!rtnl_trylock())
-			return;
-		call_netdevice_notifiers(NETDEV_NOTIFY_PEERS, bond->dev);
-		rtnl_unlock();
-	}
-}
-
-static int bond_upper_dev_walk(struct net_device *upper,
-			       struct netdev_nested_priv *priv)
-{
-	__be32 ip = *(__be32 *)priv->data;
-
-	return ip == bond_confirm_addr(upper, 0, ip);
-}
-
-static bool bond_has_this_ip(struct bonding *bond, __be32 ip)
-{
-	struct netdev_nested_priv priv = {
-		.data = (void *)&ip,
-	};
-	bool ret = false;
-
-	if (ip == bond_confirm_addr(bond->dev, 0, ip))
-		return true;
-
-	rcu_read_lock();
-	if (netdev_walk_all_upper_dev_rcu(bond->dev, bond_upper_dev_walk, &priv))
-		ret = true;
-	rcu_read_unlock();
-
-	return ret;
-}
-
-/* We go to the (large) trouble of VLAN tagging ARP frames because
- * switches in VLAN mode (especially if ports are configured as
- * "native" to a VLAN) might not pass non-tagged frames.
- */
-static void bond_arp_send(struct slave *slave, int arp_op, __be32 dest_ip,
-			  __be32 src_ip, struct bond_vlan_tag *tags)
-{
-	struct sk_buff *skb;
-	struct bond_vlan_tag *outer_tag = tags;
-	struct net_device *slave_dev = slave->dev;
-	struct net_device *bond_dev = slave->bond->dev;
-
-	slave_dbg(bond_dev, slave_dev, "arp %d on slave: dst %pI4 src %pI4\n",
-		  arp_op, &dest_ip, &src_ip);
-
-	skb = arp_create(arp_op, ETH_P_ARP, dest_ip, slave_dev, src_ip,
-			 NULL, slave_dev->dev_addr, NULL);
-
-	if (!skb) {
-		net_err_ratelimited("ARP packet allocation failed\n");
-		return;
-	}
-
-	if (!tags || tags->vlan_proto == VLAN_N_VID)
-		goto xmit;
-
-	tags++;
-
-	/* Go through all the tags backwards and add them to the packet */
-	while (tags->vlan_proto != VLAN_N_VID) {
-		if (!tags->vlan_id) {
-			tags++;
-			continue;
-		}
-
-		slave_dbg(bond_dev, slave_dev, "inner tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), tags->vlan_id);
-		skb = vlan_insert_tag_set_proto(skb, tags->vlan_proto,
-						tags->vlan_id);
-		if (!skb) {
-			net_err_ratelimited("failed to insert inner VLAN tag\n");
-			return;
-		}
-
-		tags++;
-	}
-	/* Set the outer tag */
-	if (outer_tag->vlan_id) {
-		slave_dbg(bond_dev, slave_dev, "outer tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), outer_tag->vlan_id);
-		__vlan_hwaccel_put_tag(skb, outer_tag->vlan_proto,
-				       outer_tag->vlan_id);
-	}
-
-xmit:
-	arp_xmit(skb);
-}
-
-/* Validate the device path between the @start_dev and the @end_dev.
- * The path is valid if the @end_dev is reachable through device
- * stacking.
- * When the path is validated, collect any vlan information in the
- * path.
- */
-struct bond_vlan_tag *bond_verify_device_path(struct net_device *start_dev,
-					      struct net_device *end_dev,
-					      int level)
-{
-	struct bond_vlan_tag *tags;
-	struct net_device *upper;
-	struct list_head  *iter;
-
-	if (start_dev == end_dev) {
-		tags = kcalloc(level + 1, sizeof(*tags), GFP_ATOMIC);
-		if (!tags)
-			return ERR_PTR(-ENOMEM);
-		tags[level].vlan_proto = VLAN_N_VID;
-		return tags;
-	}
-
-	netdev_for_each_upper_dev_rcu(start_dev, upper, iter) {
-		tags = bond_verify_device_path(upper, end_dev, level + 1);
-		if (IS_ERR_OR_NULL(tags)) {
-			if (IS_ERR(tags))
-				return tags;
-			continue;
-		}
-		if (is_vlan_dev(upper)) {
-			tags[level].vlan_proto = vlan_dev_vlan_proto(upper);
-			tags[level].vlan_id = vlan_dev_vlan_id(upper);
-		}
-
-		return tags;
-	}
-
-	return NULL;
-}
-
-static void bond_arp_send_all(struct bonding *bond, struct slave *slave)
-{
-	struct rtable *rt;
-	struct bond_vlan_tag *tags;
-	__be32 *targets = bond->params.arp_targets, addr;
-	int i;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS && targets[i]; i++) {
-		slave_dbg(bond->dev, slave->dev, "%s: target %pI4\n",
-			  __func__, &targets[i]);
-		tags = NULL;
-
-		/* Find out through which dev should the packet go */
-		rt = ip_route_output(dev_net(bond->dev), targets[i], 0,
-				     RTO_ONLINK, 0);
-		if (IS_ERR(rt)) {
-			/* there's no route to target - try to send arp
-			 * probe to generate any traffic (arp_validate=0)
-			 */
-			if (bond->params.arp_validate)
-				net_warn_ratelimited("%s: no route to arp_ip_target %pI4 and arp_validate is set\n",
-						     bond->dev->name,
-						     &targets[i]);
-			bond_arp_send(slave, ARPOP_REQUEST, targets[i],
-				      0, tags);
-			continue;
-		}
-
-		/* bond device itself */
-		if (rt->dst.dev == bond->dev)
-			goto found;
-
-		rcu_read_lock();
-		tags = bond_verify_device_path(bond->dev, rt->dst.dev, 0);
-		rcu_read_unlock();
-
-		if (!IS_ERR_OR_NULL(tags))
-			goto found;
-
-		/* Not our device - skip */
-		slave_dbg(bond->dev, slave->dev, "no path to arp_ip_target %pI4 via rt.dev %s\n",
-			   &targets[i], rt->dst.dev ? rt->dst.dev->name : "NULL");
-
-		ip_rt_put(rt);
-		continue;
-
-found:
-		addr = bond_confirm_addr(rt->dst.dev, targets[i], 0);
-		ip_rt_put(rt);
-		bond_arp_send(slave, ARPOP_REQUEST, targets[i], addr, tags);
-		kfree(tags);
-	}
-}
-
-static void bond_validate_arp(struct bonding *bond, struct slave *slave, __be32 sip, __be32 tip)
-{
-	int i;
-
-	if (!sip || !bond_has_this_ip(bond, tip)) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 tip %pI4 not found\n",
-			   __func__, &sip, &tip);
-		return;
-	}
-
-	i = bond_get_targets_ip(bond->params.arp_targets, sip);
-	if (i == -1) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 not found in targets\n",
-			   __func__, &sip);
-		return;
-	}
-	slave->last_rx = jiffies;
-	slave->target_last_arp_rx[i] = jiffies;
-}
-
-int bond_arp_rcv(const struct sk_buff *skb, struct bonding *bond,
-		 struct slave *slave)
-{
-	struct arphdr *arp = (struct arphdr *)skb->data;
-	struct slave *curr_active_slave, *curr_arp_slave;
-	unsigned char *arp_ptr;
-	__be32 sip, tip;
-	int is_arp = skb->protocol == __cpu_to_be16(ETH_P_ARP);
-	unsigned int alen;
-
-	if (!slave_do_arp_validate(bond, slave)) {
-		if ((slave_do_arp_validate_only(bond) && is_arp) ||
-		    !slave_do_arp_validate_only(bond))
-			slave->last_rx = jiffies;
-		return RX_HANDLER_ANOTHER;
-	} else if (!is_arp) {
-		return RX_HANDLER_ANOTHER;
-	}
-
-	alen = arp_hdr_len(bond->dev);
-
-	slave_dbg(bond->dev, slave->dev, "%s: skb->dev %s\n",
-		   __func__, skb->dev->name);
-
-	if (alen > skb_headlen(skb)) {
-		arp = kmalloc(alen, GFP_ATOMIC);
-		if (!arp)
-			goto out_unlock;
-		if (skb_copy_bits(skb, 0, arp, alen) < 0)
-			goto out_unlock;
-	}
-
-	if (arp->ar_hln != bond->dev->addr_len ||
-	    skb->pkt_type == PACKET_OTHERHOST ||
-	    skb->pkt_type == PACKET_LOOPBACK ||
-	    arp->ar_hrd != htons(ARPHRD_ETHER) ||
-	    arp->ar_pro != htons(ETH_P_IP) ||
-	    arp->ar_pln != 4)
-		goto out_unlock;
-
-	arp_ptr = (unsigned char *)(arp + 1);
-	arp_ptr += bond->dev->addr_len;
-	memcpy(&sip, arp_ptr, 4);
-	arp_ptr += 4 + bond->dev->addr_len;
-	memcpy(&tip, arp_ptr, 4);
-
-	slave_dbg(bond->dev, slave->dev, "%s: %s/%d av %d sv %d sip %pI4 tip %pI4\n",
-		  __func__, slave->dev->name, bond_slave_state(slave),
-		  bond->params.arp_validate, slave_do_arp_validate(bond, slave),
-		  &sip, &tip);
-
-	curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	curr_arp_slave = rcu_dereference(bond->current_arp_slave);
-
-	/* We 'trust' the received ARP enough to validate it if:
-	 *
-	 * (a) the slave receiving the ARP is active (which includes the
-	 * current ARP slave, if any), or
-	 *
-	 * (b) the receiving slave isn't active, but there is a currently
-	 * active slave and it received valid arp reply(s) after it became
-	 * the currently active slave, or
-	 *
-	 * (c) there is an ARP slave that sent an ARP during the prior ARP
-	 * interval, and we receive an ARP reply on any slave.  We accept
-	 * these because switch FDB update delays may deliver the ARP
-	 * reply to a slave other than the sender of the ARP request.
-	 *
-	 * Note: for (b), backup slaves are receiving the broadcast ARP
-	 * request, not a reply.  This request passes from the sending
-	 * slave through the L2 switch(es) to the receiving slave.  Since
-	 * this is checking the request, sip/tip are swapped for
-	 * validation.
-	 *
-	 * This is done to avoid endless looping when we can't reach the
-	 * arp_ip_target and fool ourselves with our own arp requests.
-	 */
-	if (bond_is_active_slave(slave))
-		bond_validate_arp(bond, slave, sip, tip);
-	else if (curr_active_slave &&
-		 time_after(slave_last_rx(bond, curr_active_slave),
-			    curr_active_slave->last_link_up))
-		bond_validate_arp(bond, slave, tip, sip);
-	else if (curr_arp_slave && (arp->ar_op == htons(ARPOP_REPLY)) &&
-		 bond_time_in_interval(bond,
-				       dev_trans_start(curr_arp_slave->dev), 1))
-		bond_validate_arp(bond, slave, sip, tip);
-
-out_unlock:
-	if (arp != (struct arphdr *)skb->data)
-		kfree(arp);
-	return RX_HANDLER_ANOTHER;
-}
-
-/* function to verify if we're in the arp_interval timeslice, returns true if
- * (last_act - arp_interval) <= jiffies <= (last_act + mod * arp_interval +
- * arp_interval/2) . the arp_interval/2 is needed for really fast networks.
- */
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod)
-{
-	int delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	return time_in_range(jiffies,
-			     last_act - delta_in_ticks,
-			     last_act + mod * delta_in_ticks + delta_in_ticks/2);
-}
-
-/* This function is called regularly to monitor each slave's link
- * ensuring that traffic is being sent and received when arp monitoring
- * is used in load-balancing mode. if the adapter has been dormant, then an
- * arp is transmitted to generate traffic. see activebackup_arp_monitor for
- * arp monitoring in active backup mode.
- */
-static void bond_loadbalance_arp_mon(struct bonding *bond)
-{
-	struct slave *slave, *oldcurrent;
-	struct list_head *iter;
-	int do_failover = 0, slave_state_changed = 0;
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	oldcurrent = rcu_dereference(bond->curr_active_slave);
-	/* see if any of the previous devices are up now (i.e. they have
-	 * xmt and rcv traffic). the curr_active_slave does not come into
-	 * the picture unless it is null. also, slave->last_link_up is not
-	 * needed here because we send an arp on each slave and give a slave
-	 * as long as it needs to get the tx/rx within the delta.
-	 * TODO: what about up/down delay in arp mode? it wasn't here before
-	 *       so it can wait
-	 */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		unsigned long trans_start = dev_trans_start(slave->dev);
-
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, trans_start, 1) &&
-			    bond_time_in_interval(bond, slave->last_rx, 1)) {
-
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave_state_changed = 1;
-
-				/* primary_slave has no meaning in round-robin
-				 * mode. the window of a slave being up and
-				 * curr_active_slave being null after enslaving
-				 * is closed.
-				 */
-				if (!oldcurrent) {
-					slave_info(bond->dev, slave->dev, "link status definitely up\n");
-					do_failover = 1;
-				} else {
-					slave_info(bond->dev, slave->dev, "interface is now up\n");
-				}
-			}
-		} else {
-			/* slave->link == BOND_LINK_UP */
-
-			/* not all switches will respond to an arp request
-			 * when the source ip is 0, so don't take the link down
-			 * if we don't know our ip yet
-			 */
-			if (!bond_time_in_interval(bond, trans_start, 2) ||
-			    !bond_time_in_interval(bond, slave->last_rx, 2)) {
-
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_state_changed = 1;
-
-				if (slave->link_failure_count < UINT_MAX)
-					slave->link_failure_count++;
-
-				slave_info(bond->dev, slave->dev, "interface is now down\n");
-
-				if (slave == oldcurrent)
-					do_failover = 1;
-			}
-		}
-
-		/* note: if switch is in round-robin mode, all links
-		 * must tx arp to ensure all links rx an arp - otherwise
-		 * links may oscillate or not come up at all; if switch is
-		 * in something like xor mode, there is nothing we can
-		 * do - all replies will be rx'ed on same link causing slaves
-		 * to be unstable during low/no traffic periods
-		 */
-		if (bond_slave_is_up(slave))
-			bond_arp_send_all(bond, slave);
-	}
-
-	rcu_read_unlock();
-
-	if (do_failover || slave_state_changed) {
-		if (!rtnl_trylock())
-			goto re_arm;
-
-		bond_for_each_slave(bond, slave, iter) {
-			if (slave->link_new_state != BOND_LINK_NOCHANGE)
-				slave->link = slave->link_new_state;
-		}
-
-		if (slave_state_changed) {
-			bond_slave_state_change(bond);
-			if (BOND_MODE(bond) == BOND_MODE_XOR)
-				bond_update_slave_arr(bond, NULL);
-		}
-		if (do_failover) {
-			block_netpoll_tx();
-			bond_select_active_slave(bond);
-			unblock_netpoll_tx();
-		}
-		rtnl_unlock();
-	}
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work,
-				   msecs_to_jiffies(bond->params.arp_interval));
-}
-
-/* Called to inspect slaves for active-backup mode ARP monitor link state
- * changes.  Sets proposed link state in slaves to specify what action
- * should take place for the slave.  Returns 0 if no changes are found, >0
- * if changes to link states must be committed.
- *
- * Called with rcu_read_lock held.
- */
-static int bond_ab_arp_inspect(struct bonding *bond)
-{
-	unsigned long trans_start, last_rx;
-	struct list_head *iter;
-	struct slave *slave;
-	int commit = 0;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-		last_rx = slave_last_rx(bond, slave);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, last_rx, 1)) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-			} else if (slave->link == BOND_LINK_BACK) {
-				bond_propose_link_state(slave, BOND_LINK_FAIL);
-				commit++;
-			}
-			continue;
-		}
-
-		/* Give slaves 2*delta after being enslaved or made
-		 * active.  This avoids bouncing, as the last receive
-		 * times need a full ARP monitor cycle to be updated.
-		 */
-		if (bond_time_in_interval(bond, slave->last_link_up, 2))
-			continue;
-
-		/* Backup slave is down if:
-		 * - No current_arp_slave AND
-		 * - more than 3*delta since last receive AND
-		 * - the bond has an IP address
-		 *
-		 * Note: a non-null current_arp_slave indicates
-		 * the curr_active_slave went down and we are
-		 * searching for a new one; under this condition
-		 * we only take the curr_active_slave down - this
-		 * gives each slave a chance to tx/rx traffic
-		 * before being taken out
-		 */
-		if (!bond_is_active_slave(slave) &&
-		    !rcu_access_pointer(bond->current_arp_slave) &&
-		    !bond_time_in_interval(bond, last_rx, 3)) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-
-		/* Active slave is down if:
-		 * - more than 2*delta since transmitting OR
-		 * - (more than 2*delta since receive AND
-		 *    the bond has an IP address)
-		 */
-		trans_start = dev_trans_start(slave->dev);
-		if (bond_is_active_slave(slave) &&
-		    (!bond_time_in_interval(bond, trans_start, 2) ||
-		     !bond_time_in_interval(bond, last_rx, 2))) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-	}
-
-	return commit;
-}
-
-/* Called to commit link state changes noted by inspection step of
- * active-backup mode ARP monitor.
- *
- * Called with RTNL hold.
- */
-static void bond_ab_arp_commit(struct bonding *bond)
-{
-	unsigned long trans_start;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			continue;
-
-		case BOND_LINK_UP:
-			trans_start = dev_trans_start(slave->dev);
-			if (rtnl_dereference(bond->curr_active_slave) != slave ||
-			    (!rtnl_dereference(bond->curr_active_slave) &&
-			     bond_time_in_interval(bond, trans_start, 1))) {
-				struct slave *current_arp_slave;
-
-				current_arp_slave = rtnl_dereference(bond->current_arp_slave);
-				bond_set_slave_link_state(slave, BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-				if (current_arp_slave) {
-					bond_set_slave_inactive_flags(
-						current_arp_slave,
-						BOND_SLAVE_NOTIFY_NOW);
-					RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				}
-
-				slave_info(bond->dev, slave->dev, "link status definitely up\n");
-
-				if (!rtnl_dereference(bond->curr_active_slave) ||
-				    slave == rtnl_dereference(bond->primary_slave))
-					goto do_failover;
-
-			}
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			if (slave == rtnl_dereference(bond->curr_active_slave)) {
-				RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				goto do_failover;
-			}
-
-			continue;
-
-		case BOND_LINK_FAIL:
-			bond_set_slave_link_state(slave, BOND_LINK_FAIL,
-						  BOND_SLAVE_NOTIFY_NOW);
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-			/* A slave has just been enslaved and has become
-			 * the current active slave.
-			 */
-			if (rtnl_dereference(bond->curr_active_slave))
-				RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev,
-				  "impossible: link_new_state %d on slave\n",
-				  slave->link_new_state);
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* Send ARP probes for active-backup mode ARP monitor.
- *
- * Called with rcu_read_lock held.
- */
-static bool bond_ab_arp_probe(struct bonding *bond)
-{
-	struct slave *slave, *before = NULL, *new_slave = NULL,
-		     *curr_arp_slave = rcu_dereference(bond->current_arp_slave),
-		     *curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	struct list_head *iter;
-	bool found = false;
-	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
-
-	if (curr_arp_slave && curr_active_slave)
-		netdev_info(bond->dev, "PROBE: c_arp %s && cas %s BAD\n",
-			    curr_arp_slave->dev->name,
-			    curr_active_slave->dev->name);
-
-	if (curr_active_slave) {
-		bond_arp_send_all(bond, curr_active_slave);
-		return should_notify_rtnl;
-	}
-
-	/* if we don't have a curr_active_slave, search for the next available
-	 * backup slave from the current_arp_slave and make it the candidate
-	 * for becoming the curr_active_slave
-	 */
-
-	if (!curr_arp_slave) {
-		curr_arp_slave = bond_first_slave_rcu(bond);
-		if (!curr_arp_slave)
-			return should_notify_rtnl;
-	}
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!found && !before && bond_slave_is_up(slave))
-			before = slave;
-
-		if (found && !new_slave && bond_slave_is_up(slave))
-			new_slave = slave;
-		/* if the link state is up at this point, we
-		 * mark it down - this can happen if we have
-		 * simultaneous link failures and
-		 * reselect_active_interface doesn't make this
-		 * one the current slave so it is still marked
-		 * up when it is actually down
-		 */
-		if (!bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_LATER);
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_LATER);
-
-			slave_info(bond->dev, slave->dev, "backup interface is now down\n");
-		}
-		if (slave == curr_arp_slave)
-			found = true;
-	}
-
-	if (!new_slave && before)
-		new_slave = before;
-
-	if (!new_slave)
-		goto check_state;
-
-	bond_set_slave_link_state(new_slave, BOND_LINK_BACK,
-				  BOND_SLAVE_NOTIFY_LATER);
-	bond_set_slave_active_flags(new_slave, BOND_SLAVE_NOTIFY_LATER);
-	bond_arp_send_all(bond, new_slave);
-	new_slave->last_link_up = jiffies;
-	rcu_assign_pointer(bond->current_arp_slave, new_slave);
-
-check_state:
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->should_notify || slave->should_notify_link) {
-			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
-			break;
-		}
-	}
-	return should_notify_rtnl;
-}
-
-static void bond_activebackup_arp_mon(struct bonding *bond)
-{
-	bool should_notify_peers = false;
-	bool should_notify_rtnl = false;
-	int delta_in_ticks;
-
-	delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	should_notify_peers = bond_should_notify_peers(bond);
-
-	if (bond_ab_arp_inspect(bond)) {
-		rcu_read_unlock();
-
-		/* Race avoidance with bond_close flush of workqueue */
-		if (!rtnl_trylock()) {
-			delta_in_ticks = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_ab_arp_commit(bond);
-
-		rtnl_unlock();
-		rcu_read_lock();
-	}
-
-	should_notify_rtnl = bond_ab_arp_probe(bond);
-	rcu_read_unlock();
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work, delta_in_ticks);
-
-	if (should_notify_peers || should_notify_rtnl) {
-		if (!rtnl_trylock())
-			return;
-
-		if (should_notify_peers)
-			call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-						 bond->dev);
-		if (should_notify_rtnl) {
-			bond_slave_state_notify(bond);
-			bond_slave_link_notify(bond);
-		}
-
-		rtnl_unlock();
-	}
-}
-
-static void bond_arp_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    arp_work.work);
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		bond_activebackup_arp_mon(bond);
-	else
-		bond_loadbalance_arp_mon(bond);
-}
-
-/*-------------------------- netdev event handling --------------------------*/
-
-/* Change device name */
-static int bond_event_changename(struct bonding *bond)
-{
-	bond_remove_proc_entry(bond);
-	bond_create_proc_entry(bond);
-
-	bond_debug_reregister(bond);
-
-	return NOTIFY_DONE;
-}
-
-static int bond_master_netdev_event(unsigned long event,
-				    struct net_device *bond_dev)
-{
-	struct bonding *event_bond = netdev_priv(bond_dev);
-
-	netdev_dbg(bond_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_CHANGENAME:
-		return bond_event_changename(event_bond);
-	case NETDEV_UNREGISTER:
-		bond_remove_proc_entry(event_bond);
-		break;
-	case NETDEV_REGISTER:
-		bond_create_proc_entry(event_bond);
-		break;
-	case NETDEV_DOWN: {
-		struct slave *slave = bond_first_slave(event_bond);
-
-		toe_failover(bond_dev, slave ? slave->dev : NULL,
-			     TOE_BOND_DOWN, NULL);
-		break;
-	}
-	case NETDEV_UP: {
-		struct slave *slave = bond_first_slave(event_bond);
-
-		toe_failover(bond_dev, slave ? slave->dev : NULL,
-			     TOE_BOND_UP, NULL);
-		break;
-	}
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-static int bond_slave_netdev_event(unsigned long event,
-				   struct net_device *slave_dev)
-{
-	struct slave *slave = bond_slave_get_rtnl(slave_dev), *primary;
-	struct bonding *bond;
-	struct net_device *bond_dev;
-
-	/* A netdev event can be generated while enslaving a device
-	 * before netdev_rx_handler_register is called in which case
-	 * slave will be NULL
-	 */
-	if (!slave) {
-		netdev_dbg(slave_dev, "%s called on NULL slave\n", __func__);
-		return NOTIFY_DONE;
-	}
-
-	bond_dev = slave->bond->dev;
-	bond = slave->bond;
-	primary = rtnl_dereference(bond->primary_slave);
-
-	slave_dbg(bond_dev, slave_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_UNREGISTER:
-		if (bond_dev->type != ARPHRD_ETHER)
-			bond_release_and_destroy(bond_dev, slave_dev);
-		else
-			__bond_release_one(bond_dev, slave_dev, false, true);
-		break;
-	case NETDEV_UP:
-	case NETDEV_CHANGE:
-		/* For 802.3ad mode only:
-		 * Getting invalid Speed/Duplex values here will put slave
-		 * in weird state. Mark it as link-fail if the link was
-		 * previously up or link-down if it hasn't yet come up, and
-		 * let link-monitoring (miimon) set it right when correct
-		 * speeds/duplex are available.
-		 */
-		if (bond_update_speed_duplex(slave) &&
-		    BOND_MODE(bond) == BOND_MODE_8023AD) {
-			if (slave->last_link_up)
-				slave->link = BOND_LINK_FAIL;
-			else
-				slave->link = BOND_LINK_DOWN;
-		}
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD)
-			bond_3ad_adapter_speed_duplex_changed(slave);
-		fallthrough;
-	case NETDEV_DOWN:
-		/* Refresh slave-array if applicable!
-		 * If the setup does not use miimon or arpmon (mode-specific!),
-		 * then these events will not cause the slave-array to be
-		 * refreshed. This will cause xmit to use a slave that is not
-		 * usable. Avoid such situation by refeshing the array at these
-		 * events. If these (miimon/arpmon) parameters are configured
-		 * then array gets refreshed twice and that should be fine!
-		 */
-		if (bond_mode_can_use_xmit_hash(bond))
-			bond_update_slave_arr(bond, NULL);
-		break;
-	case NETDEV_CHANGEMTU:
-		/* TODO: Should slaves be allowed to
-		 * independently alter their MTU?  For
-		 * an active-backup bond, slaves need
-		 * not be the same type of device, so
-		 * MTUs may vary.  For other modes,
-		 * slaves arguably should have the
-		 * same MTUs. To do this, we'd need to
-		 * take over the slave's change_mtu
-		 * function for the duration of their
-		 * servitude.
-		 */
-		break;
-	case NETDEV_CHANGENAME:
-		/* we don't care if we don't have primary set */
-		if (!bond_uses_primary(bond) ||
-		    !bond->params.primary[0])
-			break;
-
-		if (slave == primary) {
-			/* slave's name changed - he's no longer primary */
-			RCU_INIT_POINTER(bond->primary_slave, NULL);
-		} else if (!strcmp(slave_dev->name, bond->params.primary)) {
-			/* we have a new primary slave */
-			rcu_assign_pointer(bond->primary_slave, slave);
-		} else { /* we didn't change primary - exit */
-			break;
-		}
-
-		netdev_info(bond->dev, "Primary slave changed to %s, reselecting active slave\n",
-			    primary ? slave_dev->name : "none");
-
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-		break;
-	case NETDEV_FEAT_CHANGE:
-		bond_compute_features(bond);
-		break;
-	case NETDEV_RESEND_IGMP:
-		/* Propagate to master device */
-		call_netdevice_notifiers(event, slave->bond->dev);
-		break;
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-/* bond_netdev_event: handle netdev notifier chain events.
- *
- * This function receives events for the netdev chain.  The caller (an
- * ioctl handler calling blocking_notifier_call_chain) holds the necessary
- * locks for us to safely manipulate the slave devices (RTNL lock,
- * dev_probe_lock).
- */
-static int bond_netdev_event(struct notifier_block *this,
-			     unsigned long event, void *ptr)
-{
-	struct net_device *event_dev = netdev_notifier_info_to_dev(ptr);
-
-	netdev_dbg(event_dev, "%s received %s\n",
-		   __func__, netdev_cmd_to_name(event));
-
-	if (!(event_dev->priv_flags & IFF_BONDING))
-		return NOTIFY_DONE;
-
-	if (event_dev->flags & IFF_MASTER) {
-		int ret;
-
-		ret = bond_master_netdev_event(event, event_dev);
-		if (ret != NOTIFY_DONE)
-			return ret;
-	}
-
-	if (event_dev->flags & IFF_SLAVE)
-		return bond_slave_netdev_event(event, event_dev);
-
-	return NOTIFY_DONE;
-}
-
-static struct notifier_block bond_netdev_notifier = {
-	.notifier_call = bond_netdev_event,
-};
-
-/*---------------------------- Hashing Policies -----------------------------*/
-
-/* L2 hash helper */
-static inline u32 bond_eth_hash(struct sk_buff *skb)
-{
-	struct ethhdr *ep, hdr_tmp;
-
-	ep = skb_header_pointer(skb, 0, sizeof(hdr_tmp), &hdr_tmp);
-	if (ep)
-		return ep->h_dest[5] ^ ep->h_source[5] ^ ep->h_proto;
-	return 0;
-}
-
-static bool bond_flow_ip(struct sk_buff *skb, struct flow_keys *fk,
-			 int *noff, int *proto, bool l34)
-{
-	const struct ipv6hdr *iph6;
-	const struct iphdr *iph;
-
-	if (skb->protocol == htons(ETH_P_IP)) {
-		if (unlikely(!pskb_may_pull(skb, *noff + sizeof(*iph))))
-			return false;
-		iph = (const struct iphdr *)(skb->data + *noff);
-		iph_to_flow_copy_v4addrs(fk, iph);
-		*noff += iph->ihl << 2;
-		if (!ip_is_fragment(iph))
-			*proto = iph->protocol;
-	} else if (skb->protocol == htons(ETH_P_IPV6)) {
-		if (unlikely(!pskb_may_pull(skb, *noff + sizeof(*iph6))))
-			return false;
-		iph6 = (const struct ipv6hdr *)(skb->data + *noff);
-		iph_to_flow_copy_v6addrs(fk, iph6);
-		*noff += sizeof(*iph6);
-		*proto = iph6->nexthdr;
-	} else {
-		return false;
-	}
-
-	if (l34 && *proto >= 0)
-		fk->ports.ports = skb_flow_get_ports(skb, *noff, *proto);
-
-	return true;
-}
-
-/* Extract the appropriate headers based on bond's xmit policy */
-static bool bond_flow_dissect(struct bonding *bond, struct sk_buff *skb,
-			      struct flow_keys *fk)
-{
-	bool l34 = bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER34;
-	int noff, proto = -1;
-
-	if (bond->params.xmit_policy > BOND_XMIT_POLICY_LAYER23) {
-		memset(fk, 0, sizeof(*fk));
-		return __skb_flow_dissect(NULL, skb, &flow_keys_bonding,
-					  fk, NULL, 0, 0, 0, 0);
-	}
-
-	fk->ports.ports = 0;
-	memset(&fk->icmp, 0, sizeof(fk->icmp));
-	noff = skb_network_offset(skb);
-	if (!bond_flow_ip(skb, fk, &noff, &proto, l34))
-		return false;
-
-	/* ICMP error packets contains at least 8 bytes of the header
-	 * of the packet which generated the error. Use this information
-	 * to correlate ICMP error packets within the same flow which
-	 * generated the error.
-	 */
-	if (proto == IPPROTO_ICMP || proto == IPPROTO_ICMPV6) {
-		skb_flow_get_icmp_tci(skb, &fk->icmp, skb->data,
-				      skb_transport_offset(skb),
-				      skb_headlen(skb));
-		if (proto == IPPROTO_ICMP) {
-			if (!icmp_is_err(fk->icmp.type))
-				return true;
-
-			noff += sizeof(struct icmphdr);
-		} else if (proto == IPPROTO_ICMPV6) {
-			if (!icmpv6_is_err(fk->icmp.type))
-				return true;
-
-			noff += sizeof(struct icmp6hdr);
-		}
-		return bond_flow_ip(skb, fk, &noff, &proto, l34);
-	}
-
-	return true;
-}
-
-/**
- * bond_xmit_hash - generate a hash value based on the xmit policy
- * @bond: bonding device
- * @skb: buffer to use for headers
- *
- * This function will extract the necessary headers from the skb buffer and use
- * them to generate a hash based on the xmit_policy set in the bonding device
- */
-u32 bond_xmit_hash(struct bonding *bond, struct sk_buff *skb)
-{
-	struct flow_keys flow;
-	u32 hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP34 &&
-	    skb->l4_hash)
-		return skb->hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER2 ||
-	    !bond_flow_dissect(bond, skb, &flow))
-		return bond_eth_hash(skb);
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER23 ||
-	    bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP23) {
-		hash = bond_eth_hash(skb);
-	} else {
-		if (flow.icmp.id)
-			memcpy(&hash, &flow.icmp, sizeof(hash));
-		else
-			memcpy(&hash, &flow.ports.ports, sizeof(hash));
-	}
-	hash ^= (__force u32)flow_get_u32_dst(&flow) ^
-		(__force u32)flow_get_u32_src(&flow);
-	hash ^= (hash >> 16);
-	hash ^= (hash >> 8);
-
-	return hash >> 1;
-}
-
-/*-------------------------- Device entry points ----------------------------*/
-
-void bond_work_init_all(struct bonding *bond)
-{
-	INIT_DELAYED_WORK(&bond->mcast_work,
-			  bond_resend_igmp_join_requests_delayed);
-	INIT_DELAYED_WORK(&bond->alb_work, bond_alb_monitor);
-	INIT_DELAYED_WORK(&bond->mii_work, bond_mii_monitor);
-	INIT_DELAYED_WORK(&bond->arp_work, bond_arp_monitor);
-	INIT_DELAYED_WORK(&bond->ad_work, bond_3ad_state_machine_handler);
-	INIT_DELAYED_WORK(&bond->slave_arr_work, bond_slave_arr_handler);
-}
-
-static void bond_work_cancel_all(struct bonding *bond)
-{
-	cancel_delayed_work_sync(&bond->mii_work);
-	cancel_delayed_work_sync(&bond->arp_work);
-	cancel_delayed_work_sync(&bond->alb_work);
-	cancel_delayed_work_sync(&bond->ad_work);
-	cancel_delayed_work_sync(&bond->mcast_work);
-	cancel_delayed_work_sync(&bond->slave_arr_work);
-}
-
-static int bond_open(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	/* reset slave->backup and slave->inactive */
-	if (bond_has_slaves(bond)) {
-		bond_for_each_slave(bond, slave, iter) {
-			if (bond_uses_primary(bond) &&
-			    slave != rcu_access_pointer(bond->curr_active_slave)) {
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-			} else if (BOND_MODE(bond) != BOND_MODE_8023AD) {
-				bond_set_slave_active_flags(slave,
-							    BOND_SLAVE_NOTIFY_NOW);
-			}
-		}
-	}
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_initialize must be called before the timer
-		 * is started.
-		 */
-		if (bond_alb_initialize(bond, (BOND_MODE(bond) == BOND_MODE_ALB)))
-			return -ENOMEM;
-		if (bond->params.tlb_dynamic_lb || BOND_MODE(bond) == BOND_MODE_ALB)
-			queue_delayed_work(bond->wq, &bond->alb_work, 0);
-	}
-
-	if (bond->params.miimon)  /* link check interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->mii_work, 0);
-
-	if (bond->params.arp_interval) {  /* arp interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->arp_work, 0);
-		bond->recv_probe = bond_arp_rcv;
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		queue_delayed_work(bond->wq, &bond->ad_work, 0);
-		/* register to receive LACPDUs */
-		bond->recv_probe = bond_3ad_lacpdu_recv;
-		bond_3ad_initiate_agg_selection(bond, 1);
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-	return 0;
-}
-
-static int bond_close(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	bond_work_cancel_all(bond);
-	bond->send_peer_notif = 0;
-	if (bond_is_lb(bond))
-		bond_alb_deinitialize(bond);
-	bond->recv_probe = NULL;
-
-	return 0;
-}
-
-/* fold stats, assuming all rtnl_link_stats64 fields are u64, but
- * that some drivers can provide 32bit values only.
- */
-static void bond_fold_stats(struct rtnl_link_stats64 *_res,
-			    const struct rtnl_link_stats64 *_new,
-			    const struct rtnl_link_stats64 *_old)
-{
-	const u64 *new = (const u64 *)_new;
-	const u64 *old = (const u64 *)_old;
-	u64 *res = (u64 *)_res;
-	int i;
-
-	for (i = 0; i < sizeof(*_res) / sizeof(u64); i++) {
-		u64 nv = new[i];
-		u64 ov = old[i];
-		s64 delta = nv - ov;
-
-		/* detects if this particular field is 32bit only */
-		if (((nv | ov) >> 32) == 0)
-			delta = (s64)(s32)((u32)nv - (u32)ov);
-
-		/* filter anomalies, some drivers reset their stats
-		 * at down/up events.
-		 */
-		if (delta > 0)
-			res[i] += delta;
-	}
-}
-
-#ifdef CONFIG_LOCKDEP
-static int bond_get_lowest_level_rcu(struct net_device *dev)
-{
-	struct net_device *ldev, *next, *now, *dev_stack[MAX_NEST_DEV + 1];
-	struct list_head *niter, *iter, *iter_stack[MAX_NEST_DEV + 1];
-	int cur = 0, max = 0;
-
-	now = dev;
-	iter = &dev->adj_list.lower;
-
-	while (1) {
-		next = NULL;
-		while (1) {
-			ldev = netdev_next_lower_dev_rcu(now, &iter);
-			if (!ldev)
-				break;
-
-			next = ldev;
-			niter = &ldev->adj_list.lower;
-			dev_stack[cur] = now;
-			iter_stack[cur++] = iter;
-			if (max <= cur)
-				max = cur;
-			break;
-		}
-
-		if (!next) {
-			if (!cur)
-				return max;
-			next = dev_stack[--cur];
-			niter = iter_stack[cur];
-		}
-
-		now = next;
-		iter = niter;
-	}
-
-	return max;
-}
-#endif
-
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct rtnl_link_stats64 temp;
-	struct list_head *iter;
-	struct slave *slave;
-	int nest_level = 0;
-
-
-	rcu_read_lock();
-#ifdef CONFIG_LOCKDEP
-	nest_level = bond_get_lowest_level_rcu(bond_dev);
-#endif
-
-	spin_lock_nested(&bond->stats_lock, nest_level);
-	memcpy(stats, &bond->bond_stats, sizeof(*stats));
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		const struct rtnl_link_stats64 *new =
-			dev_get_stats(slave->dev, &temp);
-
-		bond_fold_stats(stats, new, &slave->slave_stats);
-
-		/* save off the slave stats for the next run */
-		memcpy(&slave->slave_stats, new, sizeof(*new));
-	}
-
-	memcpy(&bond->bond_stats, stats, sizeof(*stats));
-	spin_unlock(&bond->stats_lock);
-	rcu_read_unlock();
-}
-
-static int bond_do_ioctl(struct net_device *bond_dev, struct ifreq *ifr, int cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct ifbond k_binfo;
-	struct ifbond __user *u_binfo = NULL;
-	struct ifslave k_sinfo;
-	struct ifslave __user *u_sinfo = NULL;
-	struct mii_ioctl_data *mii = NULL;
-	struct bond_opt_value newval;
-	struct net *net;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond_ioctl: cmd=%d\n", cmd);
-
-	switch (cmd) {
-	case SIOCGMIIPHY:
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		mii->phy_id = 0;
-		fallthrough;
-	case SIOCGMIIREG:
-		/* We do this again just in case we were called by SIOCGMIIREG
-		 * instead of SIOCGMIIPHY.
-		 */
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		if (mii->reg_num == 1) {
-			mii->val_out = 0;
-			if (netif_carrier_ok(bond->dev))
-				mii->val_out = BMSR_LSTATUS;
-		}
-
-		return 0;
-	case BOND_INFO_QUERY_OLD:
-	case SIOCBONDINFOQUERY:
-		u_binfo = (struct ifbond __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_binfo, u_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		bond_info_query(bond_dev, &k_binfo);
-		if (copy_to_user(u_binfo, &k_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		return 0;
-	case BOND_SLAVE_INFO_QUERY_OLD:
-	case SIOCBONDSLAVEINFOQUERY:
-		u_sinfo = (struct ifslave __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_sinfo, u_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		res = bond_slave_info_query(bond_dev, &k_sinfo);
-		if (res == 0 &&
-		    copy_to_user(u_sinfo, &k_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		return res;
-	default:
-		break;
-	}
-
-	net = dev_net(bond_dev);
-
-	if (!ns_capable(net->user_ns, CAP_NET_ADMIN))
-		return -EPERM;
-
-	slave_dev = __dev_get_by_name(net, ifr->ifr_slave);
-
-	slave_dbg(bond_dev, slave_dev, "slave_dev=%p:\n", slave_dev);
-
-	if (!slave_dev)
-		return -ENODEV;
-
-	switch (cmd) {
-	case BOND_ENSLAVE_OLD:
-	case SIOCBONDENSLAVE:
-		res = bond_enslave(bond_dev, slave_dev, NULL);
-		break;
-	case BOND_RELEASE_OLD:
-	case SIOCBONDRELEASE:
-		res = bond_release(bond_dev, slave_dev);
-		break;
-	case BOND_SETHWADDR_OLD:
-	case SIOCBONDSETHWADDR:
-		res = bond_set_dev_addr(bond_dev, slave_dev);
-		break;
-	case BOND_CHANGE_ACTIVE_OLD:
-	case SIOCBONDCHANGEACTIVE:
-		bond_opt_initstr(&newval, slave_dev->name);
-		res = __bond_opt_set_notify(bond, BOND_OPT_ACTIVE_SLAVE,
-					    &newval);
-		break;
-	default:
-		res = -EOPNOTSUPP;
-	}
-
-	return res;
-}
-
-static void bond_change_rx_flags(struct net_device *bond_dev, int change)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	if (change & IFF_PROMISC)
-		bond_set_promiscuity(bond,
-				     bond_dev->flags & IFF_PROMISC ? 1 : -1);
-
-	if (change & IFF_ALLMULTI)
-		bond_set_allmulti(bond,
-				  bond_dev->flags & IFF_ALLMULTI ? 1 : -1);
-}
-
-static void bond_set_rx_mode(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	rcu_read_lock();
-	if (bond_uses_primary(bond)) {
-		slave = rcu_dereference(bond->curr_active_slave);
-		if (slave) {
-			dev_uc_sync(slave->dev, bond_dev);
-			dev_mc_sync(slave->dev, bond_dev);
-		}
-	} else {
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			dev_uc_sync_multiple(slave->dev, bond_dev);
-			dev_mc_sync_multiple(slave->dev, bond_dev);
-		}
-	}
-	rcu_read_unlock();
-}
-
-static int bond_neigh_init(struct neighbour *n)
-{
-	struct bonding *bond = netdev_priv(n->dev);
-	const struct net_device_ops *slave_ops;
-	struct neigh_parms parms;
-	struct slave *slave;
-	int ret = 0;
-
-	rcu_read_lock();
-	slave = bond_first_slave_rcu(bond);
-	if (!slave)
-		goto out;
-	slave_ops = slave->dev->netdev_ops;
-	if (!slave_ops->ndo_neigh_setup)
-		goto out;
-
-	/* TODO: find another way [1] to implement this.
-	 * Passing a zeroed structure is fragile,
-	 * but at least we do not pass garbage.
-	 *
-	 * [1] One way would be that ndo_neigh_setup() never touch
-	 *     struct neigh_parms, but propagate the new neigh_setup()
-	 *     back to ___neigh_create() / neigh_parms_alloc()
-	 */
-	memset(&parms, 0, sizeof(parms));
-	ret = slave_ops->ndo_neigh_setup(slave->dev, &parms);
-
-	if (ret)
-		goto out;
-
-	if (parms.neigh_setup)
-		ret = parms.neigh_setup(n);
-out:
-	rcu_read_unlock();
-	return ret;
-}
-
-/* The bonding ndo_neigh_setup is called at init time beofre any
- * slave exists. So we must declare proxy setup function which will
- * be used at run time to resolve the actual slave neigh param setup.
- *
- * It's also called by master devices (such as vlans) to setup their
- * underlying devices. In that case - do nothing, we're already set up from
- * our init.
- */
-static int bond_neigh_setup(struct net_device *dev,
-			    struct neigh_parms *parms)
-{
-	/* modify only our neigh_parms */
-	if (parms->dev == dev)
-		parms->neigh_setup = bond_neigh_init;
-
-	return 0;
-}
-
-/* Change the MTU of all of a master's slaves to match the master */
-static int bond_change_mtu(struct net_device *bond_dev, int new_mtu)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond=%p, new_mtu=%d\n", bond, new_mtu);
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "s %p c_m %p\n",
-			   slave, slave->dev->netdev_ops->ndo_change_mtu);
-
-		res = dev_set_mtu(slave->dev, new_mtu);
-
-		if (res) {
-			/* If we failed to set the slave's mtu to the new value
-			 * we must abort the operation even in ACTIVE_BACKUP
-			 * mode, because if we allow the backup slaves to have
-			 * different mtu values than the active slave we'll
-			 * need to change their mtu when doing a failover. That
-			 * means changing their mtu from timer context, which
-			 * is probably not a good idea.
-			 */
-			slave_dbg(bond_dev, slave->dev, "err %d setting mtu to %d\n",
-				  res, new_mtu);
-			goto unwind;
-		}
-	}
-
-	bond_dev->mtu = new_mtu;
-
-	return 0;
-
-unwind:
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mtu(rollback_slave->dev, bond_dev->mtu);
-		if (tmp_res)
-			slave_dbg(bond_dev, rollback_slave->dev, "unwind err %d\n",
-				  tmp_res);
-	}
-
-	return res;
-}
-
-/* Change HW address
- *
- * Note that many devices must be down to change the HW address, and
- * downing the master releases all slaves.  We can make bonds full of
- * bonding devices to test this, however.
- */
-static int bond_set_mac_address(struct net_device *bond_dev, void *addr)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct sockaddr_storage *ss = addr, tmp_ss;
-	struct list_head *iter;
-	int res = 0;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB)
-		return bond_alb_set_mac_address(bond_dev, addr);
-
-
-	netdev_dbg(bond_dev, "%s: bond=%p\n", __func__, bond);
-
-	/* If fail_over_mac is enabled, do nothing and return success.
-	 * Returning an error causes ifenslave to fail.
-	 */
-	if (bond->params.fail_over_mac &&
-	    BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		return 0;
-
-	if (!is_valid_ether_addr(ss->__data))
-		return -EADDRNOTAVAIL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "%s: slave=%p\n",
-			  __func__, slave);
-		res = dev_set_mac_address(slave->dev, addr, NULL);
-		if (res) {
-			/* TODO: consider downing the slave
-			 * and retry ?
-			 * User should expect communications
-			 * breakage anyway until ARP finish
-			 * updating, so...
-			 */
-			slave_dbg(bond_dev, slave->dev, "%s: err %d\n",
-				  __func__, res);
-			goto unwind;
-		}
-	}
-
-	/* success */
-	memcpy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
-	return 0;
-
-unwind:
-	memcpy(tmp_ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-	tmp_ss.ss_family = bond_dev->type;
-
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mac_address(rollback_slave->dev,
-					      (struct sockaddr *)&tmp_ss, NULL);
-		if (tmp_res) {
-			slave_dbg(bond_dev, rollback_slave->dev, "%s: unwind err %d\n",
-				   __func__, tmp_res);
-		}
-	}
-
-	return res;
-}
-
-static struct net_device *bond_xmit_slave_id_select(struct bonding *bond, int slave_id)
-{
-	struct net_device *slave_dev = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	int i = slave_id;
-
-	/* Here we start from the slave with slave_id */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0) {
-			if (bond_slave_can_tx(slave)) {
-				slave_dev = slave->dev;
-				return slave_dev;
-			}
-		}
-	}
-
-	/* Here we start from the first slave up to slave_id */
-	i = slave_id;
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0)
-			break;
-		if (bond_slave_can_tx(slave)) {
-			slave_dev = slave->dev;
-			return slave_dev;
-		}
-	}
-	return slave_dev;
-}
-
-/**
- * bond_get_slave_by_id - get xmit slave with slave_id
- * @bond: bonding device that is transmitting
- * @slave_id: slave id up to slave_cnt-1 through which to transmit
- *
- * This function tries to get slave with slave_id but in case
- * it fails, it tries to find the first available slave for transmission.
- */
-static struct slave *bond_get_slave_by_id(struct bonding *bond,
-					  int slave_id)
-{
-	struct list_head *iter;
-	struct slave *slave;
-	int i = slave_id;
-
-	/* Here we start from the slave with slave_id */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0) {
-			if (bond_slave_can_tx(slave))
-				return slave;
-		}
-	}
-
-	/* Here we start from the first slave up to slave_id */
-	i = slave_id;
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0)
-			break;
-		if (bond_slave_can_tx(slave))
-			return slave;
-	}
-	/* no slave that can tx has been found */
-	return NULL;
-}
-
-/**
- * bond_rr_gen_slave_id - generate slave id based on packets_per_slave
- * @bond: bonding device to use
- *
- * Based on the value of the bonding device's packets_per_slave parameter
- * this function generates a slave id, which is usually used as the next
- * slave to transmit through.
- */
-static u32 bond_rr_gen_slave_id(struct bonding *bond)
-{
-	u32 slave_id;
-	struct reciprocal_value reciprocal_packets_per_slave;
-	int packets_per_slave = bond->params.packets_per_slave;
-
-	switch (packets_per_slave) {
-	case 0:
-		slave_id = prandom_u32();
-		break;
-	case 1:
-		slave_id = bond->rr_tx_counter;
-		break;
-	default:
-		reciprocal_packets_per_slave =
-			bond->params.reciprocal_packets_per_slave;
-		slave_id = reciprocal_divide(bond->rr_tx_counter,
-					     reciprocal_packets_per_slave);
-		break;
-	}
-	bond->rr_tx_counter++;
-
-	return slave_id;
-}
-
-static struct slave *bond_xmit_roundrobin_slave_get(struct bonding *bond,
-						    struct sk_buff *skb)
-{
-	struct slave *slave;
-	int slave_cnt;
-	u32 slave_id;
-
-	/* Start with the curr_active_slave that joined the bond as the
-	 * default for sending IGMP traffic.  For failover purposes one
-	 * needs to maintain some consistency for the interface that will
-	 * send the join/membership reports.  The curr_active_slave found
-	 * will send all of this type of traffic.
-	 */
-	if (skb->protocol == htons(ETH_P_IP)) {
-		int noff = skb_network_offset(skb);
-		struct iphdr *iph;
-
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
-			goto non_igmp;
-
-		iph = ip_hdr(skb);
-		if (iph->protocol == IPPROTO_IGMP) {
-			slave = rcu_dereference(bond->curr_active_slave);
-			if (slave)
-				return slave;
-			return bond_get_slave_by_id(bond, 0);
-		}
-	}
-
-non_igmp:
-	slave_cnt = READ_ONCE(bond->slave_cnt);
-	if (likely(slave_cnt)) {
-		slave_id = bond_rr_gen_slave_id(bond) % slave_cnt;
-		return bond_get_slave_by_id(bond, slave_id);
-	}
-	return NULL;
-}
-
-static struct net_device *bond_xmit_roundrobin_select(int slave_id,
-						      struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	return bond_xmit_slave_id_select(bond, slave_id);
-}
-
-static netdev_tx_t bond_xmit_roundrobin(struct sk_buff *skb,
-					struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-
-	slave = bond_xmit_roundrobin_slave_get(bond, skb);
-	if (likely(slave))
-		return bond_dev_queue_xmit(bond, skb, slave->dev);
-
-	return bond_tx_drop(bond_dev, skb);
-}
-
-static struct slave *bond_xmit_activebackup_slave_get(struct bonding *bond,
-						      struct sk_buff *skb)
-{
-	return rcu_dereference(bond->curr_active_slave);
-}
-
-static struct net_device *bond_xmit_activebackup_select(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct slave *slave;
-
-	slave = rcu_dereference(bond->curr_active_slave);
-	if (slave)
-		slave_dev = slave->dev;
-
-	return slave_dev;
-}
-
-/* In active-backup mode, we know that bond->curr_active_slave is always valid if
- * the bond has a usable interface.
- */
-static netdev_tx_t bond_xmit_activebackup(struct sk_buff *skb,
-					  struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-
-	slave = bond_xmit_activebackup_slave_get(bond, skb);
-	if (slave)
-		return bond_dev_queue_xmit(bond, skb, slave->dev);
-
-	return bond_tx_drop(bond_dev, skb);
-}
-
-/* Use this to update slave_array when (a) it's not appropriate to update
- * slave_array right away (note that update_slave_array() may sleep)
- * and / or (b) RTNL is not held.
- */
-void bond_slave_arr_work_rearm(struct bonding *bond, unsigned long delay)
-{
-	queue_delayed_work(bond->wq, &bond->slave_arr_work, delay);
-}
-
-/* Slave array work handler. Holds only RTNL */
-static void bond_slave_arr_handler(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    slave_arr_work.work);
-	int ret;
-
-	if (!rtnl_trylock())
-		goto err;
-
-	ret = bond_update_slave_arr(bond, NULL);
-	rtnl_unlock();
-	if (ret) {
-		pr_warn_ratelimited("Failed to update slave array from WT\n");
-		goto err;
-	}
-	return;
-
-err:
-	bond_slave_arr_work_rearm(bond, 1);
-}
-
-static void bond_skip_slave(struct bond_up_slave *slaves,
-			    struct slave *skipslave)
-{
-	int idx;
-
-	/* Rare situation where caller has asked to skip a specific
-	 * slave but allocation failed (most likely!). BTW this is
-	 * only possible when the call is initiated from
-	 * __bond_release_one(). In this situation; overwrite the
-	 * skipslave entry in the array with the last entry from the
-	 * array to avoid a situation where the xmit path may choose
-	 * this to-be-skipped slave to send a packet out.
-	 */
-	for (idx = 0; slaves && idx < slaves->count; idx++) {
-		if (skipslave == slaves->arr[idx]) {
-			slaves->arr[idx] =
-				slaves->arr[slaves->count - 1];
-			slaves->count--;
-			break;
-		}
-	}
-}
-
-static void bond_set_slave_arr(struct bonding *bond,
-			       struct bond_up_slave *usable_slaves,
-			       struct bond_up_slave *all_slaves)
-{
-	struct bond_up_slave *usable, *all;
-
-	usable = rtnl_dereference(bond->usable_slaves);
-	rcu_assign_pointer(bond->usable_slaves, usable_slaves);
-	kfree_rcu(usable, rcu);
-
-	all = rtnl_dereference(bond->all_slaves);
-	rcu_assign_pointer(bond->all_slaves, all_slaves);
-	kfree_rcu(all, rcu);
-}
-
-static void bond_reset_slave_arr(struct bonding *bond)
-{
-	struct bond_up_slave *usable, *all;
-
-	usable = rtnl_dereference(bond->usable_slaves);
-	if (usable) {
-		RCU_INIT_POINTER(bond->usable_slaves, NULL);
-		kfree_rcu(usable, rcu);
-	}
-
-	all = rtnl_dereference(bond->all_slaves);
-	if (all) {
-		RCU_INIT_POINTER(bond->all_slaves, NULL);
-		kfree_rcu(all, rcu);
-	}
-}
-
-/* Build the usable slaves array in control path for modes that use xmit-hash
- * to determine the slave interface -
- * (a) BOND_MODE_8023AD
- * (b) BOND_MODE_XOR
- * (c) (BOND_MODE_TLB || BOND_MODE_ALB) && tlb_dynamic_lb == 0
- *
- * The caller is expected to hold RTNL only and NO other lock!
- */
-int bond_update_slave_arr(struct bonding *bond, struct slave *skipslave)
-{
-	struct bond_up_slave *usable_slaves = NULL, *all_slaves = NULL;
-	struct slave *slave;
-	struct list_head *iter;
-	int agg_id = 0;
-	int ret = 0;
-
-#ifdef CONFIG_LOCKDEP
-	WARN_ON(lockdep_is_held(&bond->mode_lock));
-#endif
-
-	usable_slaves = kzalloc(struct_size(usable_slaves, arr,
-					    bond->slave_cnt), GFP_KERNEL);
-	all_slaves = kzalloc(struct_size(all_slaves, arr,
-					 bond->slave_cnt), GFP_KERNEL);
-	if (!usable_slaves || !all_slaves) {
-		ret = -ENOMEM;
-		goto out;
-	}
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-
-		if (bond_3ad_get_active_agg_info(bond, &ad_info)) {
-			pr_debug("bond_3ad_get_active_agg_info failed\n");
-			/* No active aggragator means it's not safe to use
-			 * the previous array.
-			 */
-			bond_reset_slave_arr(bond);
-			goto out;
-		}
-		agg_id = ad_info.aggregator_id;
-	}
-	bond_for_each_slave(bond, slave, iter) {
-		if (skipslave == slave)
-			continue;
-
-		all_slaves->arr[all_slaves->count++] = slave;
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg;
-
-			agg = SLAVE_AD_INFO(slave)->port.aggregator;
-			if (!agg || agg->aggregator_identifier != agg_id)
-				continue;
-		}
-		if (!bond_slave_can_tx(slave))
-			continue;
-
-		slave_dbg(bond->dev, slave->dev, "Adding slave to tx hash array[%d]\n",
-			  usable_slaves->count);
-
-		usable_slaves->arr[usable_slaves->count++] = slave;
-	}
-
-	bond_set_slave_arr(bond, usable_slaves, all_slaves);
-	return ret;
-out:
-	if (ret != 0 && skipslave) {
-		bond_skip_slave(rtnl_dereference(bond->all_slaves),
-				skipslave);
-		bond_skip_slave(rtnl_dereference(bond->usable_slaves),
-				skipslave);
-	}
-	kfree_rcu(all_slaves, rcu);
-	kfree_rcu(usable_slaves, rcu);
-
-	return ret;
-}
-
-static struct slave *bond_xmit_3ad_xor_slave_get(struct bonding *bond,
-						 struct sk_buff *skb,
-						 struct bond_up_slave *slaves)
-{
-	struct slave *slave;
-	unsigned int count;
-	u32 hash;
-
-	hash = bond_xmit_hash(bond, skb);
-	count = slaves ? READ_ONCE(slaves->count) : 0;
-	if (unlikely(!count))
-		return NULL;
-
-	slave = slaves->arr[hash % count];
-	return slave;
-}
-
-static struct net_device *bond_xmit_xor_select(int slave_id,
-					       struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct bond_up_slave *slaves;
-	struct slave *slave;
-	unsigned int count;
-
-	slaves = rcu_dereference(bond->usable_slaves);
-	count = slaves ? READ_ONCE(slaves->count) : 0;
-	if (likely(count)) {
-		slave = slaves->arr[slave_id];
-		if (slave)
-			slave_dev = slave->dev;
-	}
-	return slave_dev;
-}
-
-/* Use this Xmit function for 3AD as well as XOR modes. The current
- * usable slave array is formed in the control path. The xmit function
- * just calculates hash and sends the packet out.
- */
-static netdev_tx_t bond_3ad_xor_xmit(struct sk_buff *skb,
-				     struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct bond_up_slave *slaves;
-	struct slave *slave;
-
-	slaves = rcu_dereference(bond->usable_slaves);
-	slave = bond_xmit_3ad_xor_slave_get(bond, skb, slaves);
-	if (likely(slave))
-		return bond_dev_queue_xmit(bond, skb, slave->dev);
-
-	return bond_tx_drop(dev, skb);
-}
-
-/* in broadcast mode, we send everything to all usable interfaces. */
-static netdev_tx_t bond_xmit_broadcast(struct sk_buff *skb,
-				       struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (bond_is_last_slave(bond, slave))
-			break;
-		if (bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
-
-			if (!skb2) {
-				net_err_ratelimited("%s: Error: %s: skb_clone() failed\n",
-						    bond_dev->name, __func__);
-				continue;
-			}
-			bond_dev_queue_xmit(bond, skb2, slave->dev);
-		}
-	}
-	if (slave && bond_slave_is_up(slave) && slave->link == BOND_LINK_UP)
-		return bond_dev_queue_xmit(bond, skb, slave->dev);
-
-	return bond_tx_drop(bond_dev, skb);
-}
-
-/*------------------------- Device initialization ---------------------------*/
-
-/* Lookup the slave that corresponds to a qid */
-static inline int bond_slave_override(struct bonding *bond,
-				      struct sk_buff *skb)
-{
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	if (!skb_rx_queue_recorded(skb))
-		return 1;
-
-	/* Find out if any slaves have the same mapping as this skb. */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->queue_id == skb_get_queue_mapping(skb)) {
-			if (bond_slave_is_up(slave) &&
-			    slave->link == BOND_LINK_UP) {
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-				return 0;
-			}
-			/* If the slave isn't UP, use default transmit policy. */
-			break;
-		}
-	}
-
-	return 1;
-}
-
-
-static u16 bond_select_queue(struct net_device *dev, struct sk_buff *skb,
-			     struct net_device *sb_dev)
-{
-	/* This helper function exists to help dev_pick_tx get the correct
-	 * destination queue.  Using a helper function skips a call to
-	 * skb_tx_hash and will put the skbs in the queue we expect on their
-	 * way down to the bonding driver.
-	 */
-	u16 txq = skb_rx_queue_recorded(skb) ? skb_get_rx_queue(skb) : 0;
-
-	/* Save the original txq to restore before passing to the driver */
-	qdisc_skb_cb(skb)->slave_dev_queue_mapping = skb_get_queue_mapping(skb);
-
-	if (unlikely(txq >= dev->real_num_tx_queues)) {
-		do {
-			txq -= dev->real_num_tx_queues;
-		} while (txq >= dev->real_num_tx_queues);
-	}
-	return txq;
-}
-
-static struct net_device *bond_xmit_get_slave(struct net_device *master_dev,
-					      struct sk_buff *skb,
-					      bool all_slaves)
-{
-	struct bonding *bond = netdev_priv(master_dev);
-	struct bond_up_slave *slaves;
-	struct slave *slave = NULL;
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		slave = bond_xmit_roundrobin_slave_get(bond, skb);
-		break;
-	case BOND_MODE_ACTIVEBACKUP:
-		slave = bond_xmit_activebackup_slave_get(bond, skb);
-		break;
-	case BOND_MODE_8023AD:
-	case BOND_MODE_XOR:
-		if (all_slaves)
-			slaves = rcu_dereference(bond->all_slaves);
-		else
-			slaves = rcu_dereference(bond->usable_slaves);
-		slave = bond_xmit_3ad_xor_slave_get(bond, skb, slaves);
-		break;
-	case BOND_MODE_BROADCAST:
-		break;
-	case BOND_MODE_ALB:
-		slave = bond_xmit_alb_slave_get(bond, skb);
-		break;
-	case BOND_MODE_TLB:
-		slave = bond_xmit_tlb_slave_get(bond, skb);
-		break;
-	default:
-		/* Should never happen, mode already checked */
-		WARN_ONCE(true, "Unknown bonding mode");
-		break;
-	}
-
-	if (slave)
-		return slave->dev;
-	return NULL;
-}
-
-static netdev_tx_t __bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-
-	if (bond_should_override_tx_queue(bond) &&
-	    !bond_slave_override(bond, skb))
-		return NETDEV_TX_OK;
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return bond_xmit_roundrobin(skb, dev);
-	case BOND_MODE_ACTIVEBACKUP:
-		return bond_xmit_activebackup(skb, dev);
-	case BOND_MODE_8023AD:
-	case BOND_MODE_XOR:
-		return bond_3ad_xor_xmit(skb, dev);
-	case BOND_MODE_BROADCAST:
-		return bond_xmit_broadcast(skb, dev);
-	case BOND_MODE_ALB:
-		return bond_alb_xmit(skb, dev);
-	case BOND_MODE_TLB:
-		return bond_tlb_xmit(skb, dev);
-	default:
-		/* Should never happen, mode already checked */
-		netdev_err(dev, "Unknown bonding mode %d\n", BOND_MODE(bond));
-		WARN_ON_ONCE(1);
-		return bond_tx_drop(dev, skb);
-	}
-}
-
-static netdev_tx_t bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	netdev_tx_t ret = NETDEV_TX_OK;
-
-	/* If we risk deadlock from transmitting this in the
-	 * netpoll path, tell netpoll to queue the frame for later tx
-	 */
-	if (unlikely(is_netpoll_tx_blocked(dev)))
-		return NETDEV_TX_BUSY;
-
-	rcu_read_lock();
-	if (bond_has_slaves(bond))
-		ret = __bond_start_xmit(skb, dev);
-	else
-		ret = bond_tx_drop(dev, skb);
-	rcu_read_unlock();
-
-	return ret;
-}
-
-static u32 bond_mode_bcast_speed(struct slave *slave, u32 speed)
-{
-	if (speed == 0 || speed == SPEED_UNKNOWN)
-		speed = slave->speed;
-	else
-		speed = min(speed, slave->speed);
-
-	return speed;
-}
-
-static int bond_ethtool_get_link_ksettings(struct net_device *bond_dev,
-					   struct ethtool_link_ksettings *cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-	u32 speed = 0;
-
-	cmd->base.duplex = DUPLEX_UNKNOWN;
-	cmd->base.port = PORT_OTHER;
-
-	/* Since bond_slave_can_tx returns false for all inactive or down slaves, we
-	 * do not need to check mode.  Though link speed might not represent
-	 * the true receive or transmit bandwidth (not all modes are symmetric)
-	 * this is an accurate maximum.
-	 */
-	bond_for_each_slave(bond, slave, iter) {
-		if (bond_slave_can_tx(slave)) {
-			if (slave->speed != SPEED_UNKNOWN) {
-				if (BOND_MODE(bond) == BOND_MODE_BROADCAST)
-					speed = bond_mode_bcast_speed(slave,
-								      speed);
-				else
-					speed += slave->speed;
-			}
-			if (cmd->base.duplex == DUPLEX_UNKNOWN &&
-			    slave->duplex != DUPLEX_UNKNOWN)
-				cmd->base.duplex = slave->duplex;
-		}
-	}
-	cmd->base.speed = speed ? : SPEED_UNKNOWN;
-
-	return 0;
-}
-
-static void bond_ethtool_get_drvinfo(struct net_device *bond_dev,
-				     struct ethtool_drvinfo *drvinfo)
-{
-	strlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));
-	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version), "%d",
-		 BOND_ABI_VERSION);
-}
-
-static const struct ethtool_ops bond_ethtool_ops = {
-	.get_drvinfo		= bond_ethtool_get_drvinfo,
-	.get_link		= ethtool_op_get_link,
-	.get_link_ksettings	= bond_ethtool_get_link_ksettings,
-};
-
-static const struct net_device_ops bond_netdev_ops = {
-	.ndo_init		= bond_init,
-	.ndo_uninit		= bond_uninit,
-	.ndo_open		= bond_open,
-	.ndo_stop		= bond_close,
-	.ndo_start_xmit		= bond_start_xmit,
-	.ndo_select_queue	= bond_select_queue,
-	.ndo_get_stats64	= bond_get_stats,
-	.ndo_do_ioctl		= bond_do_ioctl,
-	.ndo_change_rx_flags	= bond_change_rx_flags,
-	.ndo_set_rx_mode	= bond_set_rx_mode,
-	.ndo_change_mtu		= bond_change_mtu,
-	.ndo_set_mac_address	= bond_set_mac_address,
-	.ndo_neigh_setup	= bond_neigh_setup,
-	.ndo_vlan_rx_add_vid	= bond_vlan_rx_add_vid,
-	.ndo_vlan_rx_kill_vid	= bond_vlan_rx_kill_vid,
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	.ndo_netpoll_setup	= bond_netpoll_setup,
-	.ndo_netpoll_cleanup	= bond_netpoll_cleanup,
-	.ndo_poll_controller	= bond_poll_controller,
-#endif
-	.ndo_add_slave		= bond_enslave,
-	.ndo_del_slave		= bond_release,
-	.ndo_fix_features	= bond_fix_features,
-	.ndo_features_check	= passthru_features_check,
-	.ndo_get_xmit_slave	= bond_xmit_get_slave,
-};
-
-static const struct device_type bond_type = {
-	.name = "bond",
-};
-
-static void bond_destructor(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	if (bond->wq)
-		destroy_workqueue(bond->wq);
-}
-
-void bond_setup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	spin_lock_init(&bond->mode_lock);
-	bond->params = bonding_defaults;
-
-	/* Initialize pointers */
-	bond->dev = bond_dev;
-
-	/* Initialize the device entry points */
-	ether_setup(bond_dev);
-	bond_dev->max_mtu = ETH_MAX_MTU;
-	bond_dev->netdev_ops = &bond_netdev_ops;
-	bond_dev->ethtool_ops = &bond_ethtool_ops;
-
-	bond_dev->needs_free_netdev = true;
-	bond_dev->priv_destructor = bond_destructor;
-
-	SET_NETDEV_DEVTYPE(bond_dev, &bond_type);
-
-	/* Initialize the device options */
-	bond_dev->flags |= IFF_MASTER;
-	bond_dev->priv_flags |= IFF_BONDING | IFF_UNICAST_FLT | IFF_NO_QUEUE;
-	bond_dev->priv_flags &= ~(IFF_XMIT_DST_RELEASE | IFF_TX_SKB_SHARING);
-
-#ifdef CONFIG_XFRM_OFFLOAD
-	/* set up xfrm device ops (only supported in active-backup right now) */
-	bond_dev->xfrmdev_ops = &bond_xfrmdev_ops;
-	bond->xs = NULL;
-#endif /* CONFIG_XFRM_OFFLOAD */
-
-	/* don't acquire bond device's netif_tx_lock when transmitting */
-	bond_dev->features |= NETIF_F_LLTX;
-
-	/* By default, we declare the bond to be fully
-	 * VLAN hardware accelerated capable. Special
-	 * care is taken in the various xmit functions
-	 * when there are slaves that are not hw accel
-	 * capable
-	 */
-
-	/* Don't allow bond devices to change network namespaces. */
-	bond_dev->features |= NETIF_F_NETNS_LOCAL;
-
-	bond_dev->hw_features = BOND_VLAN_FEATURES |
-				NETIF_F_HW_VLAN_CTAG_RX |
-				NETIF_F_HW_VLAN_CTAG_FILTER;
-
-	bond_dev->hw_features |= NETIF_F_GSO_ENCAP_ALL | NETIF_F_GSO_UDP_L4;
-#ifdef CONFIG_XFRM_OFFLOAD
-	bond_dev->hw_features |= BOND_XFRM_FEATURES;
-#endif /* CONFIG_XFRM_OFFLOAD */
-	bond_dev->features |= bond_dev->hw_features;
-	bond_dev->features |= NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_STAG_TX;
-#ifdef CONFIG_XFRM_OFFLOAD
-	/* Disable XFRM features if this isn't an active-backup config */
-	if (BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP)
-		bond_dev->features &= ~BOND_XFRM_FEATURES;
-#endif /* CONFIG_XFRM_OFFLOAD */
-}
-
-/* Destroy a bonding device.
- * Must be under rtnl_lock when this function is called.
- */
-static void bond_uninit(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_up_slave *usable, *all;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_netpoll_cleanup(bond_dev);
-
-	/* Release the bonded slaves */
-	bond_for_each_slave(bond, slave, iter)
-		__bond_release_one(bond_dev, slave->dev, true, true);
-	netdev_info(bond_dev, "Released all slaves\n");
-
-	usable = rtnl_dereference(bond->usable_slaves);
-	if (usable) {
-		RCU_INIT_POINTER(bond->usable_slaves, NULL);
-		kfree_rcu(usable, rcu);
-	}
-
-	all = rtnl_dereference(bond->all_slaves);
-	if (all) {
-		RCU_INIT_POINTER(bond->all_slaves, NULL);
-		kfree_rcu(all, rcu);
-	}
-
-	list_del(&bond->bond_list);
-
-	bond_debug_unregister(bond);
-}
-
-/*------------------------- Module initialization ---------------------------*/
-
-static int bond_check_params(struct bond_params *params)
-{
-	int arp_validate_value, fail_over_mac_value, primary_reselect_value, i;
-	struct bond_opt_value newval;
-	const struct bond_opt_value *valptr;
-	int arp_all_targets_value = 0;
-	u16 ad_actor_sys_prio = 0;
-	u16 ad_user_port_key = 0;
-	__be32 arp_target[BOND_MAX_ARP_TARGETS] = { 0 };
-	int arp_ip_count;
-	int bond_mode	= BOND_MODE_ROUNDROBIN;
-	int xmit_hashtype = BOND_XMIT_POLICY_LAYER2;
-	int lacp_fast = 0;
-	int tlb_dynamic_lb;
-
-	/* Convert string parameters. */
-	if (mode) {
-		bond_opt_initstr(&newval, mode);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_MODE), &newval);
-		if (!valptr) {
-			pr_err("Error: Invalid bonding mode \"%s\"\n", mode);
-			return -EINVAL;
-		}
-		bond_mode = valptr->value;
-	}
-
-	if (xmit_hash_policy) {
-		if (bond_mode == BOND_MODE_ROUNDROBIN ||
-		    bond_mode == BOND_MODE_ACTIVEBACKUP ||
-		    bond_mode == BOND_MODE_BROADCAST) {
-			pr_info("xmit_hash_policy param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, xmit_hash_policy);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_XMIT_HASH),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid xmit_hash_policy \"%s\"\n",
-				       xmit_hash_policy);
-				return -EINVAL;
-			}
-			xmit_hashtype = valptr->value;
-		}
-	}
-
-	if (lacp_rate) {
-		if (bond_mode != BOND_MODE_8023AD) {
-			pr_info("lacp_rate param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, lacp_rate);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_LACP_RATE),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid lacp rate \"%s\"\n",
-				       lacp_rate);
-				return -EINVAL;
-			}
-			lacp_fast = valptr->value;
-		}
-	}
-
-	if (ad_select) {
-		bond_opt_initstr(&newval, ad_select);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_SELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid ad_select \"%s\"\n", ad_select);
-			return -EINVAL;
-		}
-		params->ad_select = valptr->value;
-		if (bond_mode != BOND_MODE_8023AD)
-			pr_warn("ad_select param only affects 802.3ad mode\n");
-	} else {
-		params->ad_select = BOND_AD_STABLE;
-	}
-
-	if (max_bonds < 0) {
-		pr_warn("Warning: max_bonds (%d) not in range %d-%d, so it was reset to BOND_DEFAULT_MAX_BONDS (%d)\n",
-			max_bonds, 0, INT_MAX, BOND_DEFAULT_MAX_BONDS);
-		max_bonds = BOND_DEFAULT_MAX_BONDS;
-	}
-
-	if (miimon < 0) {
-		pr_warn("Warning: miimon module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			miimon, INT_MAX);
-		miimon = 0;
-	}
-
-	if (updelay < 0) {
-		pr_warn("Warning: updelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			updelay, INT_MAX);
-		updelay = 0;
-	}
-
-	if (downdelay < 0) {
-		pr_warn("Warning: downdelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			downdelay, INT_MAX);
-		downdelay = 0;
-	}
-
-	if ((use_carrier != 0) && (use_carrier != 1)) {
-		pr_warn("Warning: use_carrier module parameter (%d), not of valid value (0/1), so it was set to 1\n",
-			use_carrier);
-		use_carrier = 1;
-	}
-
-	if (num_peer_notif < 0 || num_peer_notif > 255) {
-		pr_warn("Warning: num_grat_arp/num_unsol_na (%d) not in range 0-255 so it was reset to 1\n",
-			num_peer_notif);
-		num_peer_notif = 1;
-	}
-
-	/* reset values for 802.3ad/TLB/ALB */
-	if (!bond_mode_uses_arp(bond_mode)) {
-		if (!miimon) {
-			pr_warn("Warning: miimon must be specified, otherwise bonding will not detect link failure, speed and duplex which are essential for 802.3ad operation\n");
-			pr_warn("Forcing miimon to 100msec\n");
-			miimon = BOND_DEFAULT_MIIMON;
-		}
-	}
-
-	if (tx_queues < 1 || tx_queues > 255) {
-		pr_warn("Warning: tx_queues (%d) should be between 1 and 255, resetting to %d\n",
-			tx_queues, BOND_DEFAULT_TX_QUEUES);
-		tx_queues = BOND_DEFAULT_TX_QUEUES;
-	}
-
-	if ((all_slaves_active != 0) && (all_slaves_active != 1)) {
-		pr_warn("Warning: all_slaves_active module parameter (%d), not of valid value (0/1), so it was set to 0\n",
-			all_slaves_active);
-		all_slaves_active = 0;
-	}
-
-	if (resend_igmp < 0 || resend_igmp > 255) {
-		pr_warn("Warning: resend_igmp (%d) should be between 0 and 255, resetting to %d\n",
-			resend_igmp, BOND_DEFAULT_RESEND_IGMP);
-		resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-	}
-
-	bond_opt_initval(&newval, packets_per_slave);
-	if (!bond_opt_parse(bond_opt_get(BOND_OPT_PACKETS_PER_SLAVE), &newval)) {
-		pr_warn("Warning: packets_per_slave (%d) should be between 0 and %u resetting to 1\n",
-			packets_per_slave, USHRT_MAX);
-		packets_per_slave = 1;
-	}
-
-	if (bond_mode == BOND_MODE_ALB) {
-		pr_notice("In ALB mode you might experience client disconnections upon reconnection of a link if the bonding module updelay parameter (%d msec) is incompatible with the forwarding delay time of the switch\n",
-			  updelay);
-	}
-
-	if (!miimon) {
-		if (updelay || downdelay) {
-			/* just warn the user the up/down delay will have
-			 * no effect since miimon is zero...
-			 */
-			pr_warn("Warning: miimon module parameter not set and updelay (%d) or downdelay (%d) module parameter is set; updelay and downdelay have no effect unless miimon is set\n",
-				updelay, downdelay);
-		}
-	} else {
-		/* don't allow arp monitoring */
-		if (arp_interval) {
-			pr_warn("Warning: miimon (%d) and arp_interval (%d) can't be used simultaneously, disabling ARP monitoring\n",
-				miimon, arp_interval);
-			arp_interval = 0;
-		}
-
-		if ((updelay % miimon) != 0) {
-			pr_warn("Warning: updelay (%d) is not a multiple of miimon (%d), updelay rounded to %d ms\n",
-				updelay, miimon, (updelay / miimon) * miimon);
-		}
-
-		updelay /= miimon;
-
-		if ((downdelay % miimon) != 0) {
-			pr_warn("Warning: downdelay (%d) is not a multiple of miimon (%d), downdelay rounded to %d ms\n",
-				downdelay, miimon,
-				(downdelay / miimon) * miimon);
-		}
-
-		downdelay /= miimon;
-	}
-
-	if (arp_interval < 0) {
-		pr_warn("Warning: arp_interval module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			arp_interval, INT_MAX);
-		arp_interval = 0;
-	}
-
-	for (arp_ip_count = 0, i = 0;
-	     (arp_ip_count < BOND_MAX_ARP_TARGETS) && arp_ip_target[i]; i++) {
-		__be32 ip;
-
-		/* not a complete check, but good enough to catch mistakes */
-		if (!in4_pton(arp_ip_target[i], -1, (u8 *)&ip, -1, NULL) ||
-		    !bond_is_ip_target_ok(ip)) {
-			pr_warn("Warning: bad arp_ip_target module parameter (%s), ARP monitoring will not be performed\n",
-				arp_ip_target[i]);
-			arp_interval = 0;
-		} else {
-			if (bond_get_targets_ip(arp_target, ip) == -1)
-				arp_target[arp_ip_count++] = ip;
-			else
-				pr_warn("Warning: duplicate address %pI4 in arp_ip_target, skipping\n",
-					&ip);
-		}
-	}
-
-	if (arp_interval && !arp_ip_count) {
-		/* don't allow arping if no arp_ip_target given... */
-		pr_warn("Warning: arp_interval module parameter (%d) specified without providing an arp_ip_target parameter, arp_interval was reset to 0\n",
-			arp_interval);
-		arp_interval = 0;
-	}
-
-	if (arp_validate) {
-		if (!arp_interval) {
-			pr_err("arp_validate requires arp_interval\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initstr(&newval, arp_validate);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_VALIDATE),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_validate \"%s\"\n",
-			       arp_validate);
-			return -EINVAL;
-		}
-		arp_validate_value = valptr->value;
-	} else {
-		arp_validate_value = 0;
-	}
-
-	if (arp_all_targets) {
-		bond_opt_initstr(&newval, arp_all_targets);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_ALL_TARGETS),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_all_targets_value \"%s\"\n",
-			       arp_all_targets);
-			arp_all_targets_value = 0;
-		} else {
-			arp_all_targets_value = valptr->value;
-		}
-	}
-
-	if (miimon) {
-		pr_info("MII link monitoring set to %d ms\n", miimon);
-	} else if (arp_interval) {
-		valptr = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
-					  arp_validate_value);
-		pr_info("ARP monitoring set to %d ms, validate %s, with %d target(s):",
-			arp_interval, valptr->string, arp_ip_count);
-
-		for (i = 0; i < arp_ip_count; i++)
-			pr_cont(" %s", arp_ip_target[i]);
-
-		pr_cont("\n");
-
-	} else if (max_bonds) {
-		/* miimon and arp_interval not set, we need one so things
-		 * work as expected, see bonding.txt for details
-		 */
-		pr_debug("Warning: either miimon or arp_interval and arp_ip_target module parameters must be specified, otherwise bonding will not detect link failures! see bonding.txt for details\n");
-	}
-
-	if (primary && !bond_mode_uses_primary(bond_mode)) {
-		/* currently, using a primary only makes sense
-		 * in active backup, TLB or ALB modes
-		 */
-		pr_warn("Warning: %s primary device specified but has no effect in %s mode\n",
-			primary, bond_mode_name(bond_mode));
-		primary = NULL;
-	}
-
-	if (primary && primary_reselect) {
-		bond_opt_initstr(&newval, primary_reselect);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_PRIMARY_RESELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid primary_reselect \"%s\"\n",
-			       primary_reselect);
-			return -EINVAL;
-		}
-		primary_reselect_value = valptr->value;
-	} else {
-		primary_reselect_value = BOND_PRI_RESELECT_ALWAYS;
-	}
-
-	if (fail_over_mac) {
-		bond_opt_initstr(&newval, fail_over_mac);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_FAIL_OVER_MAC),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid fail_over_mac \"%s\"\n",
-			       fail_over_mac);
-			return -EINVAL;
-		}
-		fail_over_mac_value = valptr->value;
-		if (bond_mode != BOND_MODE_ACTIVEBACKUP)
-			pr_warn("Warning: fail_over_mac only affects active-backup mode\n");
-	} else {
-		fail_over_mac_value = BOND_FOM_NONE;
-	}
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(
-			bond_opt_get(BOND_OPT_AD_ACTOR_SYS_PRIO),
-				     &newval);
-	if (!valptr) {
-		pr_err("Error: No ad_actor_sys_prio default value");
-		return -EINVAL;
-	}
-	ad_actor_sys_prio = valptr->value;
-
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_USER_PORT_KEY),
-				&newval);
-	if (!valptr) {
-		pr_err("Error: No ad_user_port_key default value");
-		return -EINVAL;
-	}
-	ad_user_port_key = valptr->value;
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_TLB_DYNAMIC_LB), &newval);
-	if (!valptr) {
-		pr_err("Error: No tlb_dynamic_lb default value");
-		return -EINVAL;
-	}
-	tlb_dynamic_lb = valptr->value;
-
-	if (lp_interval == 0) {
-		pr_warn("Warning: ip_interval must be between 1 and %d, so it was reset to %d\n",
-			INT_MAX, BOND_ALB_DEFAULT_LP_INTERVAL);
-		lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-	}
-
-	/* fill params struct with the proper values */
-	params->mode = bond_mode;
-	params->xmit_policy = xmit_hashtype;
-	params->miimon = miimon;
-	params->num_peer_notif = num_peer_notif;
-	params->arp_interval = arp_interval;
-	params->arp_validate = arp_validate_value;
-	params->arp_all_targets = arp_all_targets_value;
-	params->updelay = updelay;
-	params->downdelay = downdelay;
-	params->peer_notif_delay = 0;
-	params->use_carrier = use_carrier;
-	params->lacp_fast = lacp_fast;
-	params->primary[0] = 0;
-	params->primary_reselect = primary_reselect_value;
-	params->fail_over_mac = fail_over_mac_value;
-	params->tx_queues = tx_queues;
-	params->all_slaves_active = all_slaves_active;
-	params->resend_igmp = resend_igmp;
-	params->min_links = min_links;
-	params->lp_interval = lp_interval;
-	params->packets_per_slave = packets_per_slave;
-	params->tlb_dynamic_lb = tlb_dynamic_lb;
-	params->ad_actor_sys_prio = ad_actor_sys_prio;
-	eth_zero_addr(params->ad_actor_system);
-	params->ad_user_port_key = ad_user_port_key;
-	if (packets_per_slave > 0) {
-		params->reciprocal_packets_per_slave =
-			reciprocal_value(packets_per_slave);
-	} else {
-		/* reciprocal_packets_per_slave is unused if
-		 * packets_per_slave is 0 or 1, just initialize it
-		 */
-		params->reciprocal_packets_per_slave =
-			(struct reciprocal_value) { 0 };
-	}
-
-	if (primary) {
-		strncpy(params->primary, primary, IFNAMSIZ);
-		params->primary[IFNAMSIZ - 1] = 0;
-	}
-
-	memcpy(params->arp_targets, arp_target, sizeof(arp_target));
-
-	return 0;
-}
-
-/* Called from registration process */
-static int bond_init(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	netdev_dbg(bond_dev, "Begin bond_init\n");
-
-	bond->wq = alloc_ordered_workqueue(bond_dev->name, WQ_MEM_RECLAIM);
-	if (!bond->wq)
-		return -ENOMEM;
-
-	spin_lock_init(&bond->stats_lock);
-	netdev_lockdep_set_classes(bond_dev);
-
-	list_add_tail(&bond->bond_list, &bn->dev_list);
-
-	bond_prepare_sysfs_group(bond);
-
-	bond_debug_register(bond);
-
-	/* Ensure valid dev_addr */
-	if (is_zero_ether_addr(bond_dev->dev_addr) &&
-	    bond_dev->addr_assign_type == NET_ADDR_PERM)
-		eth_hw_addr_random(bond_dev);
-
-	return 0;
-}
-
-unsigned int bond_get_num_tx_queues(void)
-{
-	return tx_queues;
-}
-
-/* Create a new bond based on the specified name and bonding parameters.
- * If name is NULL, obtain a suitable "bond%d" name for us.
- * Caller must NOT hold rtnl_lock; we need to release it here before we
- * set up our sysfs entries.
- */
-int bond_create(struct net *net, const char *name)
-{
-	struct net_device *bond_dev;
-	struct bonding *bond;
-	struct alb_bond_info *bond_info;
-	int res;
-
-	rtnl_lock();
-
-	bond_dev = alloc_netdev_mq(sizeof(struct bonding),
-				   name ? name : "bond%d", NET_NAME_UNKNOWN,
-				   bond_setup, tx_queues);
-	if (!bond_dev) {
-		pr_err("%s: eek! can't alloc netdev!\n", name);
-		rtnl_unlock();
-		return -ENOMEM;
-	}
-
-	/*
-	 * Initialize rx_hashtbl_used_head to RLB_NULL_INDEX.
-	 * It is set to 0 by default which is wrong.
-	 */
-	bond = netdev_priv(bond_dev);
-	bond_info = &(BOND_ALB_INFO(bond));
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	dev_net_set(bond_dev, net);
-	bond_dev->rtnl_link_ops = &bond_link_ops;
-
-	res = register_netdevice(bond_dev);
-	if (res < 0) {
-		free_netdev(bond_dev);
-		rtnl_unlock();
-
-		return res;
-	}
-
-	netif_carrier_off(bond_dev);
-
-	bond_work_init_all(bond);
-
-	rtnl_unlock();
-	return 0;
-}
-
-static int __net_init bond_net_init(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-
-	bn->net = net;
-	INIT_LIST_HEAD(&bn->dev_list);
-
-	bond_create_proc_dir(bn);
-	bond_create_sysfs(bn);
-
-	return 0;
-}
-
-static void __net_exit bond_net_exit(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-	struct bonding *bond, *tmp_bond;
-	LIST_HEAD(list);
-
-	bond_destroy_sysfs(bn);
-
-	/* Kill off any bonds created after unregistering bond rtnl ops */
-	rtnl_lock();
-	list_for_each_entry_safe(bond, tmp_bond, &bn->dev_list, bond_list)
-		unregister_netdevice_queue(bond->dev, &list);
-	unregister_netdevice_many(&list);
-	rtnl_unlock();
-
-	bond_destroy_proc_dir(bn);
-}
-
-static struct pernet_operations bond_net_ops = {
-	.init = bond_net_init,
-	.exit = bond_net_exit,
-	.id   = &bond_net_id,
-	.size = sizeof(struct bond_net),
-};
-
-static int __init bonding_init(void)
-{
-	int i;
-	int res;
-
-	res = bond_check_params(&bonding_defaults);
-	if (res)
-		goto out;
-
-	res = register_pernet_subsys(&bond_net_ops);
-	if (res)
-		goto out;
-
-	res = bond_netlink_init();
-	if (res)
-		goto err_link;
-
-	bond_create_debugfs();
-
-	for (i = 0; i < max_bonds; i++) {
-		res = bond_create(&init_net, NULL);
-		if (res)
-			goto err;
-	}
-
-	skb_flow_dissector_init(&flow_keys_bonding,
-				flow_keys_bonding_keys,
-				ARRAY_SIZE(flow_keys_bonding_keys));
-
-	register_netdevice_notifier(&bond_netdev_notifier);
-
-	register_toe_bond_rr_select_cb(bond_xmit_roundrobin_select);
-	register_toe_bond_acb_select_cb(bond_xmit_activebackup_select);
-	register_toe_bond_8023AD_select_cb(bond_xmit_xor_select);
-	register_toe_bond_xor_select_cb(bond_xmit_xor_select);
-out:
-	return res;
-err:
-	bond_destroy_debugfs();
-	bond_netlink_fini();
-err_link:
-	unregister_pernet_subsys(&bond_net_ops);
-	goto out;
-
-}
-
-static void __exit bonding_exit(void)
-{
-	unregister_netdevice_notifier(&bond_netdev_notifier);
-
-	bond_destroy_debugfs();
-
-	bond_netlink_fini();
-	unregister_pernet_subsys(&bond_net_ops);
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	/* Make sure we don't have an imbalance on our netpoll blocking */
-	WARN_ON(atomic_read(&netpoll_block_tx));
-#endif
-}
-
-module_init(bonding_init);
-module_exit(bonding_exit);
-MODULE_LICENSE("GPL");
-MODULE_DESCRIPTION(DRV_DESCRIPTION);
-MODULE_AUTHOR("Thomas Davis, tadavis@lbl.gov and many others");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.10.0/bond_netlink.c
--- a/src/network/bonding/BONDING_KDIRS/5.10.0/bond_netlink.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,785 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * drivers/net/bond/bond_netlink.c - Netlink interface for bonding
- * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
- * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/module.h>
-#include <linux/errno.h>
-#include <linux/netdevice.h>
-#include <linux/etherdevice.h>
-#include <linux/if_link.h>
-#include <linux/if_ether.h>
-#include <net/netlink.h>
-#include <net/rtnetlink.h>
-#include <net/bonding.h>
-
-static size_t bond_get_slave_size(const struct net_device *bond_dev,
-				  const struct net_device *slave_dev)
-{
-	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_STATE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_MII_STATUS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_SLAVE_LINK_FAILURE_COUNT */
-		nla_total_size(MAX_ADDR_LEN) +	/* IFLA_BOND_SLAVE_PERM_HWADDR */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_QUEUE_ID */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_AGGREGATOR_ID */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE */
-		0;
-}
-
-static int bond_fill_slave_info(struct sk_buff *skb,
-				const struct net_device *bond_dev,
-				const struct net_device *slave_dev)
-{
-	struct slave *slave = bond_slave_get_rtnl(slave_dev);
-
-	if (nla_put_u8(skb, IFLA_BOND_SLAVE_STATE, bond_slave_state(slave)))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_SLAVE_MII_STATUS, slave->link))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_SLAVE_LINK_FAILURE_COUNT,
-			slave->link_failure_count))
-		goto nla_put_failure;
-
-	if (nla_put(skb, IFLA_BOND_SLAVE_PERM_HWADDR,
-		    slave_dev->addr_len, slave->perm_hwaddr))
-		goto nla_put_failure;
-
-	if (nla_put_u16(skb, IFLA_BOND_SLAVE_QUEUE_ID, slave->queue_id))
-		goto nla_put_failure;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		const struct aggregator *agg;
-		const struct port *ad_port;
-
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		agg = SLAVE_AD_INFO(slave)->port.aggregator;
-		if (agg) {
-			if (nla_put_u16(skb, IFLA_BOND_SLAVE_AD_AGGREGATOR_ID,
-					agg->aggregator_identifier))
-				goto nla_put_failure;
-			if (nla_put_u8(skb,
-				       IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE,
-				       ad_port->actor_oper_port_state))
-				goto nla_put_failure;
-			if (nla_put_u16(skb,
-					IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE,
-					ad_port->partner_oper.port_state))
-				goto nla_put_failure;
-		}
-	}
-
-	return 0;
-
-nla_put_failure:
-	return -EMSGSIZE;
-}
-
-static const struct nla_policy bond_policy[IFLA_BOND_MAX + 1] = {
-	[IFLA_BOND_MODE]		= { .type = NLA_U8 },
-	[IFLA_BOND_ACTIVE_SLAVE]	= { .type = NLA_U32 },
-	[IFLA_BOND_MIIMON]		= { .type = NLA_U32 },
-	[IFLA_BOND_UPDELAY]		= { .type = NLA_U32 },
-	[IFLA_BOND_DOWNDELAY]		= { .type = NLA_U32 },
-	[IFLA_BOND_USE_CARRIER]		= { .type = NLA_U8 },
-	[IFLA_BOND_ARP_INTERVAL]	= { .type = NLA_U32 },
-	[IFLA_BOND_ARP_IP_TARGET]	= { .type = NLA_NESTED },
-	[IFLA_BOND_ARP_VALIDATE]	= { .type = NLA_U32 },
-	[IFLA_BOND_ARP_ALL_TARGETS]	= { .type = NLA_U32 },
-	[IFLA_BOND_PRIMARY]		= { .type = NLA_U32 },
-	[IFLA_BOND_PRIMARY_RESELECT]	= { .type = NLA_U8 },
-	[IFLA_BOND_FAIL_OVER_MAC]	= { .type = NLA_U8 },
-	[IFLA_BOND_XMIT_HASH_POLICY]	= { .type = NLA_U8 },
-	[IFLA_BOND_RESEND_IGMP]		= { .type = NLA_U32 },
-	[IFLA_BOND_NUM_PEER_NOTIF]	= { .type = NLA_U8 },
-	[IFLA_BOND_ALL_SLAVES_ACTIVE]	= { .type = NLA_U8 },
-	[IFLA_BOND_MIN_LINKS]		= { .type = NLA_U32 },
-	[IFLA_BOND_LP_INTERVAL]		= { .type = NLA_U32 },
-	[IFLA_BOND_PACKETS_PER_SLAVE]	= { .type = NLA_U32 },
-	[IFLA_BOND_AD_LACP_RATE]	= { .type = NLA_U8 },
-	[IFLA_BOND_AD_SELECT]		= { .type = NLA_U8 },
-	[IFLA_BOND_AD_INFO]		= { .type = NLA_NESTED },
-	[IFLA_BOND_AD_ACTOR_SYS_PRIO]	= { .type = NLA_U16 },
-	[IFLA_BOND_AD_USER_PORT_KEY]	= { .type = NLA_U16 },
-	[IFLA_BOND_AD_ACTOR_SYSTEM]	= { .type = NLA_BINARY,
-					    .len  = ETH_ALEN },
-	[IFLA_BOND_TLB_DYNAMIC_LB]	= { .type = NLA_U8 },
-	[IFLA_BOND_PEER_NOTIF_DELAY]    = { .type = NLA_U32 },
-};
-
-static const struct nla_policy bond_slave_policy[IFLA_BOND_SLAVE_MAX + 1] = {
-	[IFLA_BOND_SLAVE_QUEUE_ID]	= { .type = NLA_U16 },
-};
-
-static int bond_validate(struct nlattr *tb[], struct nlattr *data[],
-			 struct netlink_ext_ack *extack)
-{
-	if (tb[IFLA_ADDRESS]) {
-		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN)
-			return -EINVAL;
-		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS])))
-			return -EADDRNOTAVAIL;
-	}
-	return 0;
-}
-
-static int bond_slave_changelink(struct net_device *bond_dev,
-				 struct net_device *slave_dev,
-				 struct nlattr *tb[], struct nlattr *data[],
-				 struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_opt_value newval;
-	int err;
-
-	if (!data)
-		return 0;
-
-	if (data[IFLA_BOND_SLAVE_QUEUE_ID]) {
-		u16 queue_id = nla_get_u16(data[IFLA_BOND_SLAVE_QUEUE_ID]);
-		char queue_id_str[IFNAMSIZ + 7];
-
-		/* queue_id option setting expects slave_name:queue_id */
-		snprintf(queue_id_str, sizeof(queue_id_str), "%s:%u\n",
-			 slave_dev->name, queue_id);
-		bond_opt_initstr(&newval, queue_id_str);
-		err = __bond_opt_set(bond, BOND_OPT_QUEUE_ID, &newval);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int bond_changelink(struct net_device *bond_dev, struct nlattr *tb[],
-			   struct nlattr *data[],
-			   struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_opt_value newval;
-	int miimon = 0;
-	int err;
-
-	if (!data)
-		return 0;
-
-	if (data[IFLA_BOND_MODE]) {
-		int mode = nla_get_u8(data[IFLA_BOND_MODE]);
-
-		bond_opt_initval(&newval, mode);
-		err = __bond_opt_set(bond, BOND_OPT_MODE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ACTIVE_SLAVE]) {
-		int ifindex = nla_get_u32(data[IFLA_BOND_ACTIVE_SLAVE]);
-		struct net_device *slave_dev;
-		char *active_slave = "";
-
-		if (ifindex != 0) {
-			slave_dev = __dev_get_by_index(dev_net(bond_dev),
-						       ifindex);
-			if (!slave_dev)
-				return -ENODEV;
-			active_slave = slave_dev->name;
-		}
-		bond_opt_initstr(&newval, active_slave);
-		err = __bond_opt_set(bond, BOND_OPT_ACTIVE_SLAVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_MIIMON]) {
-		miimon = nla_get_u32(data[IFLA_BOND_MIIMON]);
-
-		bond_opt_initval(&newval, miimon);
-		err = __bond_opt_set(bond, BOND_OPT_MIIMON, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_UPDELAY]) {
-		int updelay = nla_get_u32(data[IFLA_BOND_UPDELAY]);
-
-		bond_opt_initval(&newval, updelay);
-		err = __bond_opt_set(bond, BOND_OPT_UPDELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_DOWNDELAY]) {
-		int downdelay = nla_get_u32(data[IFLA_BOND_DOWNDELAY]);
-
-		bond_opt_initval(&newval, downdelay);
-		err = __bond_opt_set(bond, BOND_OPT_DOWNDELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PEER_NOTIF_DELAY]) {
-		int delay = nla_get_u32(data[IFLA_BOND_PEER_NOTIF_DELAY]);
-
-		bond_opt_initval(&newval, delay);
-		err = __bond_opt_set(bond, BOND_OPT_PEER_NOTIF_DELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_USE_CARRIER]) {
-		int use_carrier = nla_get_u8(data[IFLA_BOND_USE_CARRIER]);
-
-		bond_opt_initval(&newval, use_carrier);
-		err = __bond_opt_set(bond, BOND_OPT_USE_CARRIER, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_INTERVAL]) {
-		int arp_interval = nla_get_u32(data[IFLA_BOND_ARP_INTERVAL]);
-
-		if (arp_interval && miimon) {
-			netdev_err(bond->dev, "ARP monitoring cannot be used with MII monitoring\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initval(&newval, arp_interval);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_INTERVAL, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_IP_TARGET]) {
-		struct nlattr *attr;
-		int i = 0, rem;
-
-		bond_option_arp_ip_targets_clear(bond);
-		nla_for_each_nested(attr, data[IFLA_BOND_ARP_IP_TARGET], rem) {
-			__be32 target;
-
-			if (nla_len(attr) < sizeof(target))
-				return -EINVAL;
-
-			target = nla_get_be32(attr);
-
-			bond_opt_initval(&newval, (__force u64)target);
-			err = __bond_opt_set(bond, BOND_OPT_ARP_TARGETS,
-					     &newval);
-			if (err)
-				break;
-			i++;
-		}
-		if (i == 0 && bond->params.arp_interval)
-			netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_VALIDATE]) {
-		int arp_validate = nla_get_u32(data[IFLA_BOND_ARP_VALIDATE]);
-
-		if (arp_validate && miimon) {
-			netdev_err(bond->dev, "ARP validating cannot be used with MII monitoring\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initval(&newval, arp_validate);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_VALIDATE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_ALL_TARGETS]) {
-		int arp_all_targets =
-			nla_get_u32(data[IFLA_BOND_ARP_ALL_TARGETS]);
-
-		bond_opt_initval(&newval, arp_all_targets);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_ALL_TARGETS, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PRIMARY]) {
-		int ifindex = nla_get_u32(data[IFLA_BOND_PRIMARY]);
-		struct net_device *dev;
-		char *primary = "";
-
-		dev = __dev_get_by_index(dev_net(bond_dev), ifindex);
-		if (dev)
-			primary = dev->name;
-
-		bond_opt_initstr(&newval, primary);
-		err = __bond_opt_set(bond, BOND_OPT_PRIMARY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PRIMARY_RESELECT]) {
-		int primary_reselect =
-			nla_get_u8(data[IFLA_BOND_PRIMARY_RESELECT]);
-
-		bond_opt_initval(&newval, primary_reselect);
-		err = __bond_opt_set(bond, BOND_OPT_PRIMARY_RESELECT, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_FAIL_OVER_MAC]) {
-		int fail_over_mac =
-			nla_get_u8(data[IFLA_BOND_FAIL_OVER_MAC]);
-
-		bond_opt_initval(&newval, fail_over_mac);
-		err = __bond_opt_set(bond, BOND_OPT_FAIL_OVER_MAC, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_XMIT_HASH_POLICY]) {
-		int xmit_hash_policy =
-			nla_get_u8(data[IFLA_BOND_XMIT_HASH_POLICY]);
-
-		bond_opt_initval(&newval, xmit_hash_policy);
-		err = __bond_opt_set(bond, BOND_OPT_XMIT_HASH, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_RESEND_IGMP]) {
-		int resend_igmp =
-			nla_get_u32(data[IFLA_BOND_RESEND_IGMP]);
-
-		bond_opt_initval(&newval, resend_igmp);
-		err = __bond_opt_set(bond, BOND_OPT_RESEND_IGMP, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_NUM_PEER_NOTIF]) {
-		int num_peer_notif =
-			nla_get_u8(data[IFLA_BOND_NUM_PEER_NOTIF]);
-
-		bond_opt_initval(&newval, num_peer_notif);
-		err = __bond_opt_set(bond, BOND_OPT_NUM_PEER_NOTIF, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ALL_SLAVES_ACTIVE]) {
-		int all_slaves_active =
-			nla_get_u8(data[IFLA_BOND_ALL_SLAVES_ACTIVE]);
-
-		bond_opt_initval(&newval, all_slaves_active);
-		err = __bond_opt_set(bond, BOND_OPT_ALL_SLAVES_ACTIVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_MIN_LINKS]) {
-		int min_links =
-			nla_get_u32(data[IFLA_BOND_MIN_LINKS]);
-
-		bond_opt_initval(&newval, min_links);
-		err = __bond_opt_set(bond, BOND_OPT_MINLINKS, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_LP_INTERVAL]) {
-		int lp_interval =
-			nla_get_u32(data[IFLA_BOND_LP_INTERVAL]);
-
-		bond_opt_initval(&newval, lp_interval);
-		err = __bond_opt_set(bond, BOND_OPT_LP_INTERVAL, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PACKETS_PER_SLAVE]) {
-		int packets_per_slave =
-			nla_get_u32(data[IFLA_BOND_PACKETS_PER_SLAVE]);
-
-		bond_opt_initval(&newval, packets_per_slave);
-		err = __bond_opt_set(bond, BOND_OPT_PACKETS_PER_SLAVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_LACP_RATE]) {
-		int lacp_rate =
-			nla_get_u8(data[IFLA_BOND_AD_LACP_RATE]);
-
-		bond_opt_initval(&newval, lacp_rate);
-		err = __bond_opt_set(bond, BOND_OPT_LACP_RATE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_SELECT]) {
-		int ad_select =
-			nla_get_u8(data[IFLA_BOND_AD_SELECT]);
-
-		bond_opt_initval(&newval, ad_select);
-		err = __bond_opt_set(bond, BOND_OPT_AD_SELECT, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_ACTOR_SYS_PRIO]) {
-		int actor_sys_prio =
-			nla_get_u16(data[IFLA_BOND_AD_ACTOR_SYS_PRIO]);
-
-		bond_opt_initval(&newval, actor_sys_prio);
-		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYS_PRIO, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_USER_PORT_KEY]) {
-		int port_key =
-			nla_get_u16(data[IFLA_BOND_AD_USER_PORT_KEY]);
-
-		bond_opt_initval(&newval, port_key);
-		err = __bond_opt_set(bond, BOND_OPT_AD_USER_PORT_KEY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_ACTOR_SYSTEM]) {
-		if (nla_len(data[IFLA_BOND_AD_ACTOR_SYSTEM]) != ETH_ALEN)
-			return -EINVAL;
-
-		bond_opt_initval(&newval,
-				 nla_get_u64(data[IFLA_BOND_AD_ACTOR_SYSTEM]));
-		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYSTEM, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_TLB_DYNAMIC_LB]) {
-		int dynamic_lb = nla_get_u8(data[IFLA_BOND_TLB_DYNAMIC_LB]);
-
-		bond_opt_initval(&newval, dynamic_lb);
-		err = __bond_opt_set(bond, BOND_OPT_TLB_DYNAMIC_LB, &newval);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int bond_newlink(struct net *src_net, struct net_device *bond_dev,
-			struct nlattr *tb[], struct nlattr *data[],
-			struct netlink_ext_ack *extack)
-{
-	int err;
-
-	err = bond_changelink(bond_dev, tb, data, extack);
-	if (err < 0)
-		return err;
-
-	err = register_netdevice(bond_dev);
-	if (!err) {
-		struct bonding *bond = netdev_priv(bond_dev);
-
-		netif_carrier_off(bond_dev);
-		bond_work_init_all(bond);
-	}
-
-	return err;
-}
-
-static size_t bond_get_size(const struct net_device *bond_dev)
-{
-	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_MODE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ACTIVE_SLAVE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIIMON */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_UPDELAY */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_DOWNDELAY */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_USE_CARRIER */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_INTERVAL */
-						/* IFLA_BOND_ARP_IP_TARGET */
-		nla_total_size(sizeof(struct nlattr)) +
-		nla_total_size(sizeof(u32)) * BOND_MAX_ARP_TARGETS +
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_VALIDATE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_ALL_TARGETS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PRIMARY */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_PRIMARY_RESELECT */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_FAIL_OVER_MAC */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_XMIT_HASH_POLICY */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_RESEND_IGMP */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_NUM_PEER_NOTIF */
-		nla_total_size(sizeof(u8)) +   /* IFLA_BOND_ALL_SLAVES_ACTIVE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIN_LINKS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_LP_INTERVAL */
-		nla_total_size(sizeof(u32)) +  /* IFLA_BOND_PACKETS_PER_SLAVE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_LACP_RATE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_SELECT */
-		nla_total_size(sizeof(struct nlattr)) + /* IFLA_BOND_AD_INFO */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_AGGREGATOR */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_NUM_PORTS */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_ACTOR_KEY */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_PARTNER_KEY*/
-		nla_total_size(ETH_ALEN) +    /* IFLA_BOND_AD_INFO_PARTNER_MAC*/
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_ACTOR_SYS_PRIO */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_USER_PORT_KEY */
-		nla_total_size(ETH_ALEN) + /* IFLA_BOND_AD_ACTOR_SYSTEM */
-		nla_total_size(sizeof(u8)) + /* IFLA_BOND_TLB_DYNAMIC_LB */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PEER_NOTIF_DELAY */
-		0;
-}
-
-static int bond_option_active_slave_get_ifindex(struct bonding *bond)
-{
-	const struct net_device *slave;
-	int ifindex;
-
-	rcu_read_lock();
-	slave = bond_option_active_slave_get_rcu(bond);
-	ifindex = slave ? slave->ifindex : 0;
-	rcu_read_unlock();
-	return ifindex;
-}
-
-static int bond_fill_info(struct sk_buff *skb,
-			  const struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	unsigned int packets_per_slave;
-	int ifindex, i, targets_added;
-	struct nlattr *targets;
-	struct slave *primary;
-
-	if (nla_put_u8(skb, IFLA_BOND_MODE, BOND_MODE(bond)))
-		goto nla_put_failure;
-
-	ifindex = bond_option_active_slave_get_ifindex(bond);
-	if (ifindex && nla_put_u32(skb, IFLA_BOND_ACTIVE_SLAVE, ifindex))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_MIIMON, bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_UPDELAY,
-			bond->params.updelay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_DOWNDELAY,
-			bond->params.downdelay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_PEER_NOTIF_DELAY,
-			bond->params.peer_notif_delay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_USE_CARRIER, bond->params.use_carrier))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_INTERVAL, bond->params.arp_interval))
-		goto nla_put_failure;
-
-	targets = nla_nest_start_noflag(skb, IFLA_BOND_ARP_IP_TARGET);
-	if (!targets)
-		goto nla_put_failure;
-
-	targets_added = 0;
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
-		if (bond->params.arp_targets[i]) {
-			if (nla_put_be32(skb, i, bond->params.arp_targets[i]))
-				goto nla_put_failure;
-			targets_added = 1;
-		}
-	}
-
-	if (targets_added)
-		nla_nest_end(skb, targets);
-	else
-		nla_nest_cancel(skb, targets);
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_VALIDATE, bond->params.arp_validate))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_ALL_TARGETS,
-			bond->params.arp_all_targets))
-		goto nla_put_failure;
-
-	primary = rtnl_dereference(bond->primary_slave);
-	if (primary &&
-	    nla_put_u32(skb, IFLA_BOND_PRIMARY, primary->dev->ifindex))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_PRIMARY_RESELECT,
-		       bond->params.primary_reselect))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_FAIL_OVER_MAC,
-		       bond->params.fail_over_mac))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_XMIT_HASH_POLICY,
-		       bond->params.xmit_policy))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_RESEND_IGMP,
-		        bond->params.resend_igmp))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_NUM_PEER_NOTIF,
-		       bond->params.num_peer_notif))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_ALL_SLAVES_ACTIVE,
-		       bond->params.all_slaves_active))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_MIN_LINKS,
-			bond->params.min_links))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_LP_INTERVAL,
-			bond->params.lp_interval))
-		goto nla_put_failure;
-
-	packets_per_slave = bond->params.packets_per_slave;
-	if (nla_put_u32(skb, IFLA_BOND_PACKETS_PER_SLAVE,
-			packets_per_slave))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_AD_LACP_RATE,
-		       bond->params.lacp_fast))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_AD_SELECT,
-		       bond->params.ad_select))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_TLB_DYNAMIC_LB,
-		       bond->params.tlb_dynamic_lb))
-		goto nla_put_failure;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info info;
-
-		if (capable(CAP_NET_ADMIN)) {
-			if (nla_put_u16(skb, IFLA_BOND_AD_ACTOR_SYS_PRIO,
-					bond->params.ad_actor_sys_prio))
-				goto nla_put_failure;
-
-			if (nla_put_u16(skb, IFLA_BOND_AD_USER_PORT_KEY,
-					bond->params.ad_user_port_key))
-				goto nla_put_failure;
-
-			if (nla_put(skb, IFLA_BOND_AD_ACTOR_SYSTEM,
-				    ETH_ALEN, &bond->params.ad_actor_system))
-				goto nla_put_failure;
-		}
-		if (!bond_3ad_get_active_agg_info(bond, &info)) {
-			struct nlattr *nest;
-
-			nest = nla_nest_start_noflag(skb, IFLA_BOND_AD_INFO);
-			if (!nest)
-				goto nla_put_failure;
-
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_AGGREGATOR,
-					info.aggregator_id))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_NUM_PORTS,
-					info.ports))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_ACTOR_KEY,
-					info.actor_key))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_PARTNER_KEY,
-					info.partner_key))
-				goto nla_put_failure;
-			if (nla_put(skb, IFLA_BOND_AD_INFO_PARTNER_MAC,
-				    sizeof(info.partner_system),
-				    &info.partner_system))
-				goto nla_put_failure;
-
-			nla_nest_end(skb, nest);
-		}
-	}
-
-	return 0;
-
-nla_put_failure:
-	return -EMSGSIZE;
-}
-
-static size_t bond_get_linkxstats_size(const struct net_device *dev, int attr)
-{
-	switch (attr) {
-	case IFLA_STATS_LINK_XSTATS:
-	case IFLA_STATS_LINK_XSTATS_SLAVE:
-		break;
-	default:
-		return 0;
-	}
-
-	return bond_3ad_stats_size() + nla_total_size(0);
-}
-
-static int bond_fill_linkxstats(struct sk_buff *skb,
-				const struct net_device *dev,
-				int *prividx, int attr)
-{
-	struct nlattr *nla __maybe_unused;
-	struct slave *slave = NULL;
-	struct nlattr *nest, *nest2;
-	struct bonding *bond;
-
-	switch (attr) {
-	case IFLA_STATS_LINK_XSTATS:
-		bond = netdev_priv(dev);
-		break;
-	case IFLA_STATS_LINK_XSTATS_SLAVE:
-		slave = bond_slave_get_rtnl(dev);
-		if (!slave)
-			return 0;
-		bond = slave->bond;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	nest = nla_nest_start_noflag(skb, LINK_XSTATS_TYPE_BOND);
-	if (!nest)
-		return -EMSGSIZE;
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct bond_3ad_stats *stats;
-
-		if (slave)
-			stats = &SLAVE_AD_INFO(slave)->stats;
-		else
-			stats = &BOND_AD_INFO(bond).stats;
-
-		nest2 = nla_nest_start_noflag(skb, BOND_XSTATS_3AD);
-		if (!nest2) {
-			nla_nest_end(skb, nest);
-			return -EMSGSIZE;
-		}
-
-		if (bond_3ad_stats_fill(skb, stats)) {
-			nla_nest_cancel(skb, nest2);
-			nla_nest_end(skb, nest);
-			return -EMSGSIZE;
-		}
-		nla_nest_end(skb, nest2);
-	}
-	nla_nest_end(skb, nest);
-
-	return 0;
-}
-
-struct rtnl_link_ops bond_link_ops __read_mostly = {
-	.kind			= "bond",
-	.priv_size		= sizeof(struct bonding),
-	.setup			= bond_setup,
-	.maxtype		= IFLA_BOND_MAX,
-	.policy			= bond_policy,
-	.validate		= bond_validate,
-	.newlink		= bond_newlink,
-	.changelink		= bond_changelink,
-	.get_size		= bond_get_size,
-	.fill_info		= bond_fill_info,
-	.get_num_tx_queues	= bond_get_num_tx_queues,
-	.get_num_rx_queues	= bond_get_num_tx_queues, /* Use the same number
-							     as for TX queues */
-	.fill_linkxstats        = bond_fill_linkxstats,
-	.get_linkxstats_size    = bond_get_linkxstats_size,
-	.slave_maxtype		= IFLA_BOND_SLAVE_MAX,
-	.slave_policy		= bond_slave_policy,
-	.slave_changelink	= bond_slave_changelink,
-	.get_slave_size		= bond_get_slave_size,
-	.fill_slave_info	= bond_fill_slave_info,
-};
-
-int __init bond_netlink_init(void)
-{
-	return rtnl_link_register(&bond_link_ops);
-}
-
-void bond_netlink_fini(void)
-{
-	rtnl_link_unregister(&bond_link_ops);
-}
-
-MODULE_ALIAS_RTNL_LINK("bond");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.10.0/bond_options.c
--- a/src/network/bonding/BONDING_KDIRS/5.10.0/bond_options.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1491 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * drivers/net/bond/bond_options.c - bonding options
- * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
- * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/errno.h>
-#include <linux/if.h>
-#include <linux/netdevice.h>
-#include <linux/spinlock.h>
-#include <linux/rcupdate.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/sched/signal.h>
-
-#include <net/bonding.h>
-
-static int bond_option_active_slave_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_miimon_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_updelay_set(struct bonding *bond,
-				   const struct bond_opt_value *newval);
-static int bond_option_downdelay_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_peer_notif_delay_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_use_carrier_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_arp_interval_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target);
-static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target);
-static int bond_option_arp_ip_targets_set(struct bonding *bond,
-					  const struct bond_opt_value *newval);
-static int bond_option_arp_validate_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_arp_all_targets_set(struct bonding *bond,
-					   const struct bond_opt_value *newval);
-static int bond_option_primary_set(struct bonding *bond,
-				   const struct bond_opt_value *newval);
-static int bond_option_primary_reselect_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_fail_over_mac_set(struct bonding *bond,
-					 const struct bond_opt_value *newval);
-static int bond_option_xmit_hash_policy_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_resend_igmp_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_num_peer_notif_set(struct bonding *bond,
-					  const struct bond_opt_value *newval);
-static int bond_option_all_slaves_active_set(struct bonding *bond,
-					     const struct bond_opt_value *newval);
-static int bond_option_min_links_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_lp_interval_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_pps_set(struct bonding *bond,
-			       const struct bond_opt_value *newval);
-static int bond_option_lacp_rate_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_ad_select_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_queue_id_set(struct bonding *bond,
-				    const struct bond_opt_value *newval);
-static int bond_option_mode_set(struct bonding *bond,
-				const struct bond_opt_value *newval);
-static int bond_option_slaves_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
-					     const struct bond_opt_value *newval);
-static int bond_option_ad_actor_system_set(struct bonding *bond,
-					   const struct bond_opt_value *newval);
-static int bond_option_ad_user_port_key_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-
-
-static const struct bond_opt_value bond_mode_tbl[] = {
-	{ "balance-rr",    BOND_MODE_ROUNDROBIN,   BOND_VALFLAG_DEFAULT},
-	{ "active-backup", BOND_MODE_ACTIVEBACKUP, 0},
-	{ "balance-xor",   BOND_MODE_XOR,          0},
-	{ "broadcast",     BOND_MODE_BROADCAST,    0},
-	{ "802.3ad",       BOND_MODE_8023AD,       0},
-	{ "balance-tlb",   BOND_MODE_TLB,          0},
-	{ "balance-alb",   BOND_MODE_ALB,          0},
-	{ NULL,            -1,                     0},
-};
-
-static const struct bond_opt_value bond_pps_tbl[] = {
-	{ "default", 1,         BOND_VALFLAG_DEFAULT},
-	{ "maxval",  USHRT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,        0},
-};
-
-static const struct bond_opt_value bond_xmit_hashtype_tbl[] = {
-	{ "layer2",   BOND_XMIT_POLICY_LAYER2, BOND_VALFLAG_DEFAULT},
-	{ "layer3+4", BOND_XMIT_POLICY_LAYER34, 0},
-	{ "layer2+3", BOND_XMIT_POLICY_LAYER23, 0},
-	{ "encap2+3", BOND_XMIT_POLICY_ENCAP23, 0},
-	{ "encap3+4", BOND_XMIT_POLICY_ENCAP34, 0},
-	{ NULL,       -1,                       0},
-};
-
-static const struct bond_opt_value bond_arp_validate_tbl[] = {
-	{ "none",		BOND_ARP_VALIDATE_NONE,		BOND_VALFLAG_DEFAULT},
-	{ "active",		BOND_ARP_VALIDATE_ACTIVE,	0},
-	{ "backup",		BOND_ARP_VALIDATE_BACKUP,	0},
-	{ "all",		BOND_ARP_VALIDATE_ALL,		0},
-	{ "filter",		BOND_ARP_FILTER,		0},
-	{ "filter_active",	BOND_ARP_FILTER_ACTIVE,		0},
-	{ "filter_backup",	BOND_ARP_FILTER_BACKUP,		0},
-	{ NULL,			-1,				0},
-};
-
-static const struct bond_opt_value bond_arp_all_targets_tbl[] = {
-	{ "any", BOND_ARP_TARGETS_ANY, BOND_VALFLAG_DEFAULT},
-	{ "all", BOND_ARP_TARGETS_ALL, 0},
-	{ NULL,  -1,                   0},
-};
-
-static const struct bond_opt_value bond_fail_over_mac_tbl[] = {
-	{ "none",   BOND_FOM_NONE,   BOND_VALFLAG_DEFAULT},
-	{ "active", BOND_FOM_ACTIVE, 0},
-	{ "follow", BOND_FOM_FOLLOW, 0},
-	{ NULL,     -1,              0},
-};
-
-static const struct bond_opt_value bond_intmax_tbl[] = {
-	{ "off",     0,       BOND_VALFLAG_DEFAULT},
-	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,      0}
-};
-
-static const struct bond_opt_value bond_lacp_rate_tbl[] = {
-	{ "slow", AD_LACP_SLOW, 0},
-	{ "fast", AD_LACP_FAST, 0},
-	{ NULL,   -1,           0},
-};
-
-static const struct bond_opt_value bond_ad_select_tbl[] = {
-	{ "stable",    BOND_AD_STABLE,    BOND_VALFLAG_DEFAULT},
-	{ "bandwidth", BOND_AD_BANDWIDTH, 0},
-	{ "count",     BOND_AD_COUNT,     0},
-	{ NULL,        -1,                0},
-};
-
-static const struct bond_opt_value bond_num_peer_notif_tbl[] = {
-	{ "off",     0,   0},
-	{ "maxval",  255, BOND_VALFLAG_MAX},
-	{ "default", 1,   BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,  0}
-};
-
-static const struct bond_opt_value bond_primary_reselect_tbl[] = {
-	{ "always",  BOND_PRI_RESELECT_ALWAYS,  BOND_VALFLAG_DEFAULT},
-	{ "better",  BOND_PRI_RESELECT_BETTER,  0},
-	{ "failure", BOND_PRI_RESELECT_FAILURE, 0},
-	{ NULL,      -1},
-};
-
-static const struct bond_opt_value bond_use_carrier_tbl[] = {
-	{ "off", 0,  0},
-	{ "on",  1,  BOND_VALFLAG_DEFAULT},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_all_slaves_active_tbl[] = {
-	{ "off", 0,  BOND_VALFLAG_DEFAULT},
-	{ "on",  1,  0},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_resend_igmp_tbl[] = {
-	{ "off",     0,   0},
-	{ "maxval",  255, BOND_VALFLAG_MAX},
-	{ "default", 1,   BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,  0}
-};
-
-static const struct bond_opt_value bond_lp_interval_tbl[] = {
-	{ "minval",  1,       BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
-	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,      0},
-};
-
-static const struct bond_opt_value bond_tlb_dynamic_lb_tbl[] = {
-	{ "off", 0,  0},
-	{ "on",  1,  BOND_VALFLAG_DEFAULT},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_ad_actor_sys_prio_tbl[] = {
-	{ "minval",  1,     BOND_VALFLAG_MIN},
-	{ "maxval",  65535, BOND_VALFLAG_MAX | BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,    0},
-};
-
-static const struct bond_opt_value bond_ad_user_port_key_tbl[] = {
-	{ "minval",  0,     BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
-	{ "maxval",  1023,  BOND_VALFLAG_MAX},
-	{ NULL,      -1,    0},
-};
-
-static const struct bond_option bond_opts[BOND_OPT_LAST] = {
-	[BOND_OPT_MODE] = {
-		.id = BOND_OPT_MODE,
-		.name = "mode",
-		.desc = "bond device mode",
-		.flags = BOND_OPTFLAG_NOSLAVES | BOND_OPTFLAG_IFDOWN,
-		.values = bond_mode_tbl,
-		.set = bond_option_mode_set
-	},
-	[BOND_OPT_PACKETS_PER_SLAVE] = {
-		.id = BOND_OPT_PACKETS_PER_SLAVE,
-		.name = "packets_per_slave",
-		.desc = "Packets to send per slave in RR mode",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ROUNDROBIN)),
-		.values = bond_pps_tbl,
-		.set = bond_option_pps_set
-	},
-	[BOND_OPT_XMIT_HASH] = {
-		.id = BOND_OPT_XMIT_HASH,
-		.name = "xmit_hash_policy",
-		.desc = "balance-xor, 802.3ad, and tlb hashing method",
-		.values = bond_xmit_hashtype_tbl,
-		.set = bond_option_xmit_hash_policy_set
-	},
-	[BOND_OPT_ARP_VALIDATE] = {
-		.id = BOND_OPT_ARP_VALIDATE,
-		.name = "arp_validate",
-		.desc = "validate src/dst of ARP probes",
-		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
-			       BIT(BOND_MODE_ALB),
-		.values = bond_arp_validate_tbl,
-		.set = bond_option_arp_validate_set
-	},
-	[BOND_OPT_ARP_ALL_TARGETS] = {
-		.id = BOND_OPT_ARP_ALL_TARGETS,
-		.name = "arp_all_targets",
-		.desc = "fail on any/all arp targets timeout",
-		.values = bond_arp_all_targets_tbl,
-		.set = bond_option_arp_all_targets_set
-	},
-	[BOND_OPT_FAIL_OVER_MAC] = {
-		.id = BOND_OPT_FAIL_OVER_MAC,
-		.name = "fail_over_mac",
-		.desc = "For active-backup, do not set all slaves to the same MAC",
-		.flags = BOND_OPTFLAG_NOSLAVES,
-		.values = bond_fail_over_mac_tbl,
-		.set = bond_option_fail_over_mac_set
-	},
-	[BOND_OPT_ARP_INTERVAL] = {
-		.id = BOND_OPT_ARP_INTERVAL,
-		.name = "arp_interval",
-		.desc = "arp interval in milliseconds",
-		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
-			       BIT(BOND_MODE_ALB),
-		.values = bond_intmax_tbl,
-		.set = bond_option_arp_interval_set
-	},
-	[BOND_OPT_ARP_TARGETS] = {
-		.id = BOND_OPT_ARP_TARGETS,
-		.name = "arp_ip_target",
-		.desc = "arp targets in n.n.n.n form",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_arp_ip_targets_set
-	},
-	[BOND_OPT_DOWNDELAY] = {
-		.id = BOND_OPT_DOWNDELAY,
-		.name = "downdelay",
-		.desc = "Delay before considering link down, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_downdelay_set
-	},
-	[BOND_OPT_UPDELAY] = {
-		.id = BOND_OPT_UPDELAY,
-		.name = "updelay",
-		.desc = "Delay before considering link up, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_updelay_set
-	},
-	[BOND_OPT_LACP_RATE] = {
-		.id = BOND_OPT_LACP_RATE,
-		.name = "lacp_rate",
-		.desc = "LACPDU tx rate to request from 802.3ad partner",
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.values = bond_lacp_rate_tbl,
-		.set = bond_option_lacp_rate_set
-	},
-	[BOND_OPT_MINLINKS] = {
-		.id = BOND_OPT_MINLINKS,
-		.name = "min_links",
-		.desc = "Minimum number of available links before turning on carrier",
-		.values = bond_intmax_tbl,
-		.set = bond_option_min_links_set
-	},
-	[BOND_OPT_AD_SELECT] = {
-		.id = BOND_OPT_AD_SELECT,
-		.name = "ad_select",
-		.desc = "802.3ad aggregation selection logic",
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.values = bond_ad_select_tbl,
-		.set = bond_option_ad_select_set
-	},
-	[BOND_OPT_NUM_PEER_NOTIF] = {
-		.id = BOND_OPT_NUM_PEER_NOTIF,
-		.name = "num_unsol_na",
-		.desc = "Number of peer notifications to send on failover event",
-		.values = bond_num_peer_notif_tbl,
-		.set = bond_option_num_peer_notif_set
-	},
-	[BOND_OPT_MIIMON] = {
-		.id = BOND_OPT_MIIMON,
-		.name = "miimon",
-		.desc = "Link check interval in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_miimon_set
-	},
-	[BOND_OPT_PRIMARY] = {
-		.id = BOND_OPT_PRIMARY,
-		.name = "primary",
-		.desc = "Primary network device to use",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
-						BIT(BOND_MODE_TLB) |
-						BIT(BOND_MODE_ALB)),
-		.set = bond_option_primary_set
-	},
-	[BOND_OPT_PRIMARY_RESELECT] = {
-		.id = BOND_OPT_PRIMARY_RESELECT,
-		.name = "primary_reselect",
-		.desc = "Reselect primary slave once it comes up",
-		.values = bond_primary_reselect_tbl,
-		.set = bond_option_primary_reselect_set
-	},
-	[BOND_OPT_USE_CARRIER] = {
-		.id = BOND_OPT_USE_CARRIER,
-		.name = "use_carrier",
-		.desc = "Use netif_carrier_ok (vs MII ioctls) in miimon",
-		.values = bond_use_carrier_tbl,
-		.set = bond_option_use_carrier_set
-	},
-	[BOND_OPT_ACTIVE_SLAVE] = {
-		.id = BOND_OPT_ACTIVE_SLAVE,
-		.name = "active_slave",
-		.desc = "Currently active slave",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
-						BIT(BOND_MODE_TLB) |
-						BIT(BOND_MODE_ALB)),
-		.set = bond_option_active_slave_set
-	},
-	[BOND_OPT_QUEUE_ID] = {
-		.id = BOND_OPT_QUEUE_ID,
-		.name = "queue_id",
-		.desc = "Set queue id of a slave",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_queue_id_set
-	},
-	[BOND_OPT_ALL_SLAVES_ACTIVE] = {
-		.id = BOND_OPT_ALL_SLAVES_ACTIVE,
-		.name = "all_slaves_active",
-		.desc = "Keep all frames received on an interface by setting active flag for all slaves",
-		.values = bond_all_slaves_active_tbl,
-		.set = bond_option_all_slaves_active_set
-	},
-	[BOND_OPT_RESEND_IGMP] = {
-		.id = BOND_OPT_RESEND_IGMP,
-		.name = "resend_igmp",
-		.desc = "Number of IGMP membership reports to send on link failure",
-		.values = bond_resend_igmp_tbl,
-		.set = bond_option_resend_igmp_set
-	},
-	[BOND_OPT_LP_INTERVAL] = {
-		.id = BOND_OPT_LP_INTERVAL,
-		.name = "lp_interval",
-		.desc = "The number of seconds between instances where the bonding driver sends learning packets to each slave's peer switch",
-		.values = bond_lp_interval_tbl,
-		.set = bond_option_lp_interval_set
-	},
-	[BOND_OPT_SLAVES] = {
-		.id = BOND_OPT_SLAVES,
-		.name = "slaves",
-		.desc = "Slave membership management",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_slaves_set
-	},
-	[BOND_OPT_TLB_DYNAMIC_LB] = {
-		.id = BOND_OPT_TLB_DYNAMIC_LB,
-		.name = "tlb_dynamic_lb",
-		.desc = "Enable dynamic flow shuffling",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_TLB) | BIT(BOND_MODE_ALB)),
-		.values = bond_tlb_dynamic_lb_tbl,
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.set = bond_option_tlb_dynamic_lb_set,
-	},
-	[BOND_OPT_AD_ACTOR_SYS_PRIO] = {
-		.id = BOND_OPT_AD_ACTOR_SYS_PRIO,
-		.name = "ad_actor_sys_prio",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.values = bond_ad_actor_sys_prio_tbl,
-		.set = bond_option_ad_actor_sys_prio_set,
-	},
-	[BOND_OPT_AD_ACTOR_SYSTEM] = {
-		.id = BOND_OPT_AD_ACTOR_SYSTEM,
-		.name = "ad_actor_system",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_ad_actor_system_set,
-	},
-	[BOND_OPT_AD_USER_PORT_KEY] = {
-		.id = BOND_OPT_AD_USER_PORT_KEY,
-		.name = "ad_user_port_key",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.values = bond_ad_user_port_key_tbl,
-		.set = bond_option_ad_user_port_key_set,
-	},
-	[BOND_OPT_NUM_PEER_NOTIF_ALIAS] = {
-		.id = BOND_OPT_NUM_PEER_NOTIF_ALIAS,
-		.name = "num_grat_arp",
-		.desc = "Number of peer notifications to send on failover event",
-		.values = bond_num_peer_notif_tbl,
-		.set = bond_option_num_peer_notif_set
-	},
-	[BOND_OPT_PEER_NOTIF_DELAY] = {
-		.id = BOND_OPT_PEER_NOTIF_DELAY,
-		.name = "peer_notif_delay",
-		.desc = "Delay between each peer notification on failover event, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_peer_notif_delay_set
-	}
-};
-
-/* Searches for an option by name */
-const struct bond_option *bond_opt_get_by_name(const char *name)
-{
-	const struct bond_option *opt;
-	int option;
-
-	for (option = 0; option < BOND_OPT_LAST; option++) {
-		opt = bond_opt_get(option);
-		if (opt && !strcmp(opt->name, name))
-			return opt;
-	}
-
-	return NULL;
-}
-
-/* Searches for a value in opt's values[] table */
-const struct bond_opt_value *bond_opt_get_val(unsigned int option, u64 val)
-{
-	const struct bond_option *opt;
-	int i;
-
-	opt = bond_opt_get(option);
-	if (WARN_ON(!opt))
-		return NULL;
-	for (i = 0; opt->values && opt->values[i].string; i++)
-		if (opt->values[i].value == val)
-			return &opt->values[i];
-
-	return NULL;
-}
-
-/* Searches for a value in opt's values[] table which matches the flagmask */
-static const struct bond_opt_value *bond_opt_get_flags(const struct bond_option *opt,
-						       u32 flagmask)
-{
-	int i;
-
-	for (i = 0; opt->values && opt->values[i].string; i++)
-		if (opt->values[i].flags & flagmask)
-			return &opt->values[i];
-
-	return NULL;
-}
-
-/* If maxval is missing then there's no range to check. In case minval is
- * missing then it's considered to be 0.
- */
-static bool bond_opt_check_range(const struct bond_option *opt, u64 val)
-{
-	const struct bond_opt_value *minval, *maxval;
-
-	minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
-	maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
-	if (!maxval || (minval && val < minval->value) || val > maxval->value)
-		return false;
-
-	return true;
-}
-
-/**
- * bond_opt_parse - parse option value
- * @opt: the option to parse against
- * @val: value to parse
- *
- * This function tries to extract the value from @val and check if it's
- * a possible match for the option and returns NULL if a match isn't found,
- * or the struct_opt_value that matched. It also strips the new line from
- * @val->string if it's present.
- */
-const struct bond_opt_value *bond_opt_parse(const struct bond_option *opt,
-					    struct bond_opt_value *val)
-{
-	char *p, valstr[BOND_OPT_MAX_NAMELEN + 1] = { 0, };
-	const struct bond_opt_value *tbl;
-	const struct bond_opt_value *ret = NULL;
-	bool checkval;
-	int i, rv;
-
-	/* No parsing if the option wants a raw val */
-	if (opt->flags & BOND_OPTFLAG_RAWVAL)
-		return val;
-
-	tbl = opt->values;
-	if (!tbl)
-		goto out;
-
-	/* ULLONG_MAX is used to bypass string processing */
-	checkval = val->value != ULLONG_MAX;
-	if (!checkval) {
-		if (!val->string)
-			goto out;
-		p = strchr(val->string, '\n');
-		if (p)
-			*p = '\0';
-		for (p = val->string; *p; p++)
-			if (!(isdigit(*p) || isspace(*p)))
-				break;
-		/* The following code extracts the string to match or the value
-		 * and sets checkval appropriately
-		 */
-		if (*p) {
-			rv = sscanf(val->string, "%32s", valstr);
-		} else {
-			rv = sscanf(val->string, "%llu", &val->value);
-			checkval = true;
-		}
-		if (!rv)
-			goto out;
-	}
-
-	for (i = 0; tbl[i].string; i++) {
-		/* Check for exact match */
-		if (checkval) {
-			if (val->value == tbl[i].value)
-				ret = &tbl[i];
-		} else {
-			if (!strcmp(valstr, "default") &&
-			    (tbl[i].flags & BOND_VALFLAG_DEFAULT))
-				ret = &tbl[i];
-
-			if (!strcmp(valstr, tbl[i].string))
-				ret = &tbl[i];
-		}
-		/* Found an exact match */
-		if (ret)
-			goto out;
-	}
-	/* Possible range match */
-	if (checkval && bond_opt_check_range(opt, val->value))
-		ret = val;
-out:
-	return ret;
-}
-
-/* Check opt's dependencies against bond mode and currently set options */
-static int bond_opt_check_deps(struct bonding *bond,
-			       const struct bond_option *opt)
-{
-	struct bond_params *params = &bond->params;
-
-	if (test_bit(params->mode, &opt->unsuppmodes))
-		return -EACCES;
-	if ((opt->flags & BOND_OPTFLAG_NOSLAVES) && bond_has_slaves(bond))
-		return -ENOTEMPTY;
-	if ((opt->flags & BOND_OPTFLAG_IFDOWN) && (bond->dev->flags & IFF_UP))
-		return -EBUSY;
-
-	return 0;
-}
-
-static void bond_opt_dep_print(struct bonding *bond,
-			       const struct bond_option *opt)
-{
-	const struct bond_opt_value *modeval;
-	struct bond_params *params;
-
-	params = &bond->params;
-	modeval = bond_opt_get_val(BOND_OPT_MODE, params->mode);
-	if (test_bit(params->mode, &opt->unsuppmodes))
-		netdev_err(bond->dev, "option %s: mode dependency failed, not supported in mode %s(%llu)\n",
-			   opt->name, modeval->string, modeval->value);
-}
-
-static void bond_opt_error_interpret(struct bonding *bond,
-				     const struct bond_option *opt,
-				     int error, const struct bond_opt_value *val)
-{
-	const struct bond_opt_value *minval, *maxval;
-	char *p;
-
-	switch (error) {
-	case -EINVAL:
-		if (val) {
-			if (val->string) {
-				/* sometimes RAWVAL opts may have new lines */
-				p = strchr(val->string, '\n');
-				if (p)
-					*p = '\0';
-				netdev_err(bond->dev, "option %s: invalid value (%s)\n",
-					   opt->name, val->string);
-			} else {
-				netdev_err(bond->dev, "option %s: invalid value (%llu)\n",
-					   opt->name, val->value);
-			}
-		}
-		minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
-		maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
-		if (!maxval)
-			break;
-		netdev_err(bond->dev, "option %s: allowed values %llu - %llu\n",
-			   opt->name, minval ? minval->value : 0, maxval->value);
-		break;
-	case -EACCES:
-		bond_opt_dep_print(bond, opt);
-		break;
-	case -ENOTEMPTY:
-		netdev_err(bond->dev, "option %s: unable to set because the bond device has slaves\n",
-			   opt->name);
-		break;
-	case -EBUSY:
-		netdev_err(bond->dev, "option %s: unable to set because the bond device is up\n",
-			   opt->name);
-		break;
-	default:
-		break;
-	}
-}
-
-/**
- * __bond_opt_set - set a bonding option
- * @bond: target bond device
- * @option: option to set
- * @val: value to set it to
- *
- * This function is used to change the bond's option value, it can be
- * used for both enabling/changing an option and for disabling it. RTNL lock
- * must be obtained before calling this function.
- */
-int __bond_opt_set(struct bonding *bond,
-		   unsigned int option, struct bond_opt_value *val)
-{
-	const struct bond_opt_value *retval = NULL;
-	const struct bond_option *opt;
-	int ret = -ENOENT;
-
-	ASSERT_RTNL();
-
-	opt = bond_opt_get(option);
-	if (WARN_ON(!val) || WARN_ON(!opt))
-		goto out;
-	ret = bond_opt_check_deps(bond, opt);
-	if (ret)
-		goto out;
-	retval = bond_opt_parse(opt, val);
-	if (!retval) {
-		ret = -EINVAL;
-		goto out;
-	}
-	ret = opt->set(bond, retval);
-out:
-	if (ret)
-		bond_opt_error_interpret(bond, opt, ret, val);
-
-	return ret;
-}
-/**
- * __bond_opt_set_notify - set a bonding option
- * @bond: target bond device
- * @option: option to set
- * @val: value to set it to
- *
- * This function is used to change the bond's option value and trigger
- * a notification to user sapce. It can be used for both enabling/changing
- * an option and for disabling it. RTNL lock must be obtained before calling
- * this function.
- */
-int __bond_opt_set_notify(struct bonding *bond,
-			  unsigned int option, struct bond_opt_value *val)
-{
-	int ret = -ENOENT;
-
-	ASSERT_RTNL();
-
-	ret = __bond_opt_set(bond, option, val);
-
-	if (!ret && (bond->dev->reg_state == NETREG_REGISTERED))
-		call_netdevice_notifiers(NETDEV_CHANGEINFODATA, bond->dev);
-
-	return ret;
-}
-
-/**
- * bond_opt_tryset_rtnl - try to acquire rtnl and call __bond_opt_set
- * @bond: target bond device
- * @option: option to set
- * @buf: value to set it to
- *
- * This function tries to acquire RTNL without blocking and if successful
- * calls __bond_opt_set. It is mainly used for sysfs option manipulation.
- */
-int bond_opt_tryset_rtnl(struct bonding *bond, unsigned int option, char *buf)
-{
-	struct bond_opt_value optval;
-	int ret;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-	bond_opt_initstr(&optval, buf);
-	ret = __bond_opt_set_notify(bond, option, &optval);
-	rtnl_unlock();
-
-	return ret;
-}
-
-/**
- * bond_opt_get - get a pointer to an option
- * @option: option for which to return a pointer
- *
- * This function checks if option is valid and if so returns a pointer
- * to its entry in the bond_opts[] option array.
- */
-const struct bond_option *bond_opt_get(unsigned int option)
-{
-	if (!BOND_OPT_VALID(option))
-		return NULL;
-
-	return &bond_opts[option];
-}
-
-static void bond_set_xfrm_features(struct net_device *bond_dev, u64 mode)
-{
-	if (!IS_ENABLED(CONFIG_XFRM_OFFLOAD))
-		return;
-
-	if (mode == BOND_MODE_ACTIVEBACKUP)
-		bond_dev->wanted_features |= BOND_XFRM_FEATURES;
-	else
-		bond_dev->wanted_features &= ~BOND_XFRM_FEATURES;
-
-	netdev_update_features(bond_dev);
-}
-
-static int bond_option_mode_set(struct bonding *bond,
-				const struct bond_opt_value *newval)
-{
-	if (!bond_mode_uses_arp(newval->value)) {
-		if (bond->params.arp_interval) {
-			netdev_dbg(bond->dev, "%s mode is incompatible with arp monitoring, start mii monitoring\n",
-				   newval->string);
-			/* disable arp monitoring */
-			bond->params.arp_interval = 0;
-		}
-
-		if (!bond->params.miimon) {
-			/* set miimon to default value */
-			bond->params.miimon = BOND_DEFAULT_MIIMON;
-			netdev_dbg(bond->dev, "Setting MII monitoring interval to %d\n",
-				   bond->params.miimon);
-		}
-	}
-
-	if (newval->value == BOND_MODE_ALB)
-		bond->params.tlb_dynamic_lb = 1;
-
-	if (bond->dev->reg_state == NETREG_REGISTERED)
-		bond_set_xfrm_features(bond->dev, newval->value);
-
-	/* don't cache arp_validate between modes */
-	bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
-	bond->params.mode = newval->value;
-
-	return 0;
-}
-
-static int bond_option_active_slave_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	char ifname[IFNAMSIZ] = { 0, };
-	struct net_device *slave_dev;
-	int ret = 0;
-
-	sscanf(newval->string, "%15s", ifname); /* IFNAMSIZ */
-	if (!strlen(ifname) || newval->string[0] == '\n') {
-		slave_dev = NULL;
-	} else {
-		slave_dev = __dev_get_by_name(dev_net(bond->dev), ifname);
-		if (!slave_dev)
-			return -ENODEV;
-	}
-
-	if (slave_dev) {
-		if (!netif_is_bond_slave(slave_dev)) {
-			slave_err(bond->dev, slave_dev, "Device is not bonding slave\n");
-			return -EINVAL;
-		}
-
-		if (bond->dev != netdev_master_upper_dev_get(slave_dev)) {
-			slave_err(bond->dev, slave_dev, "Device is not our slave\n");
-			return -EINVAL;
-		}
-	}
-
-	block_netpoll_tx();
-	/* check to see if we are clearing active */
-	if (!slave_dev) {
-		netdev_dbg(bond->dev, "Clearing current active slave\n");
-		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
-		bond_select_active_slave(bond);
-	} else {
-		struct slave *old_active = rtnl_dereference(bond->curr_active_slave);
-		struct slave *new_active = bond_slave_get_rtnl(slave_dev);
-
-		BUG_ON(!new_active);
-
-		if (new_active == old_active) {
-			/* do nothing */
-			slave_dbg(bond->dev, new_active->dev, "is already the current active slave\n");
-		} else {
-			if (old_active && (new_active->link == BOND_LINK_UP) &&
-			    bond_slave_is_up(new_active)) {
-				slave_dbg(bond->dev, new_active->dev, "Setting as active slave\n");
-				bond_change_active_slave(bond, new_active);
-			} else {
-				slave_err(bond->dev, new_active->dev, "Could not set as active slave; either %s is down or the link is down\n",
-					  new_active->dev->name);
-				ret = -EINVAL;
-			}
-		}
-	}
-	unblock_netpoll_tx();
-
-	return ret;
-}
-
-/* There are two tricky bits here.  First, if MII monitoring is activated, then
- * we must disable ARP monitoring.  Second, if the timer isn't running, we must
- * start it.
- */
-static int bond_option_miimon_set(struct bonding *bond,
-				  const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting MII monitoring interval to %llu\n",
-		   newval->value);
-	bond->params.miimon = newval->value;
-	if (bond->params.updelay)
-		netdev_dbg(bond->dev, "Note: Updating updelay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.updelay * bond->params.miimon);
-	if (bond->params.downdelay)
-		netdev_dbg(bond->dev, "Note: Updating downdelay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.downdelay * bond->params.miimon);
-	if (bond->params.peer_notif_delay)
-		netdev_dbg(bond->dev, "Note: Updating peer_notif_delay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.peer_notif_delay * bond->params.miimon);
-	if (newval->value && bond->params.arp_interval) {
-		netdev_dbg(bond->dev, "MII monitoring cannot be used with ARP monitoring - disabling ARP monitoring...\n");
-		bond->params.arp_interval = 0;
-		if (bond->params.arp_validate)
-			bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
-	}
-	if (bond->dev->flags & IFF_UP) {
-		/* If the interface is up, we may need to fire off
-		 * the MII timer. If the interface is down, the
-		 * timer will get fired off when the open function
-		 * is called.
-		 */
-		if (!newval->value) {
-			cancel_delayed_work_sync(&bond->mii_work);
-		} else {
-			cancel_delayed_work_sync(&bond->arp_work);
-			queue_delayed_work(bond->wq, &bond->mii_work, 0);
-		}
-	}
-
-	return 0;
-}
-
-/* Set up, down and peer notification delays. These must be multiples
- * of the MII monitoring value, and are stored internally as the
- * multiplier. Thus, we must translate to MS for the real world.
- */
-static int _bond_option_delay_set(struct bonding *bond,
-				  const struct bond_opt_value *newval,
-				  const char *name,
-				  int *target)
-{
-	int value = newval->value;
-
-	if (!bond->params.miimon) {
-		netdev_err(bond->dev, "Unable to set %s as MII monitoring is disabled\n",
-			   name);
-		return -EPERM;
-	}
-	if ((value % bond->params.miimon) != 0) {
-		netdev_warn(bond->dev,
-			    "%s (%d) is not a multiple of miimon (%d), value rounded to %d ms\n",
-			    name,
-			    value, bond->params.miimon,
-			    (value / bond->params.miimon) *
-			    bond->params.miimon);
-	}
-	*target = value / bond->params.miimon;
-	netdev_dbg(bond->dev, "Setting %s to %d\n",
-		   name,
-		   *target * bond->params.miimon);
-
-	return 0;
-}
-
-static int bond_option_updelay_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	return _bond_option_delay_set(bond, newval, "up delay",
-				      &bond->params.updelay);
-}
-
-static int bond_option_downdelay_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	return _bond_option_delay_set(bond, newval, "down delay",
-				      &bond->params.downdelay);
-}
-
-static int bond_option_peer_notif_delay_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	int ret = _bond_option_delay_set(bond, newval,
-					 "peer notification delay",
-					 &bond->params.peer_notif_delay);
-	return ret;
-}
-
-static int bond_option_use_carrier_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting use_carrier to %llu\n",
-		   newval->value);
-	bond->params.use_carrier = newval->value;
-
-	return 0;
-}
-
-/* There are two tricky bits here.  First, if ARP monitoring is activated, then
- * we must disable MII monitoring.  Second, if the ARP timer isn't running,
- * we must start it.
- */
-static int bond_option_arp_interval_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ARP monitoring interval to %llu\n",
-		   newval->value);
-	bond->params.arp_interval = newval->value;
-	if (newval->value) {
-		if (bond->params.miimon) {
-			netdev_dbg(bond->dev, "ARP monitoring cannot be used with MII monitoring. Disabling MII monitoring\n");
-			bond->params.miimon = 0;
-		}
-		if (!bond->params.arp_targets[0])
-			netdev_dbg(bond->dev, "ARP monitoring has been set up, but no ARP targets have been specified\n");
-	}
-	if (bond->dev->flags & IFF_UP) {
-		/* If the interface is up, we may need to fire off
-		 * the ARP timer.  If the interface is down, the
-		 * timer will get fired off when the open function
-		 * is called.
-		 */
-		if (!newval->value) {
-			if (bond->params.arp_validate)
-				bond->recv_probe = NULL;
-			cancel_delayed_work_sync(&bond->arp_work);
-		} else {
-			/* arp_validate can be set only in active-backup mode */
-			bond->recv_probe = bond_arp_rcv;
-			cancel_delayed_work_sync(&bond->mii_work);
-			queue_delayed_work(bond->wq, &bond->arp_work, 0);
-		}
-	}
-
-	return 0;
-}
-
-static void _bond_options_arp_ip_target_set(struct bonding *bond, int slot,
-					    __be32 target,
-					    unsigned long last_rx)
-{
-	__be32 *targets = bond->params.arp_targets;
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (slot >= 0 && slot < BOND_MAX_ARP_TARGETS) {
-		bond_for_each_slave(bond, slave, iter)
-			slave->target_last_arp_rx[slot] = last_rx;
-		targets[slot] = target;
-	}
-}
-
-static int _bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
-{
-	__be32 *targets = bond->params.arp_targets;
-	int ind;
-
-	if (!bond_is_ip_target_ok(target)) {
-		netdev_err(bond->dev, "invalid ARP target %pI4 specified for addition\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	if (bond_get_targets_ip(targets, target) != -1) { /* dup */
-		netdev_err(bond->dev, "ARP target %pI4 is already present\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	ind = bond_get_targets_ip(targets, 0); /* first free slot */
-	if (ind == -1) {
-		netdev_err(bond->dev, "ARP target table is full!\n");
-		return -EINVAL;
-	}
-
-	netdev_dbg(bond->dev, "Adding ARP target %pI4\n", &target);
-
-	_bond_options_arp_ip_target_set(bond, ind, target, jiffies);
-
-	return 0;
-}
-
-static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
-{
-	return _bond_option_arp_ip_target_add(bond, target);
-}
-
-static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target)
-{
-	__be32 *targets = bond->params.arp_targets;
-	struct list_head *iter;
-	struct slave *slave;
-	unsigned long *targets_rx;
-	int ind, i;
-
-	if (!bond_is_ip_target_ok(target)) {
-		netdev_err(bond->dev, "invalid ARP target %pI4 specified for removal\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	ind = bond_get_targets_ip(targets, target);
-	if (ind == -1) {
-		netdev_err(bond->dev, "unable to remove nonexistent ARP target %pI4\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	if (ind == 0 && !targets[1] && bond->params.arp_interval)
-		netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
-
-	netdev_dbg(bond->dev, "Removing ARP target %pI4\n", &target);
-
-	bond_for_each_slave(bond, slave, iter) {
-		targets_rx = slave->target_last_arp_rx;
-		for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
-			targets_rx[i] = targets_rx[i+1];
-		targets_rx[i] = 0;
-	}
-	for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
-		targets[i] = targets[i+1];
-	targets[i] = 0;
-
-	return 0;
-}
-
-void bond_option_arp_ip_targets_clear(struct bonding *bond)
-{
-	int i;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
-		_bond_options_arp_ip_target_set(bond, i, 0, 0);
-}
-
-static int bond_option_arp_ip_targets_set(struct bonding *bond,
-					  const struct bond_opt_value *newval)
-{
-	int ret = -EPERM;
-	__be32 target;
-
-	if (newval->string) {
-		if (!in4_pton(newval->string+1, -1, (u8 *)&target, -1, NULL)) {
-			netdev_err(bond->dev, "invalid ARP target %pI4 specified\n",
-				   &target);
-			return ret;
-		}
-		if (newval->string[0] == '+')
-			ret = bond_option_arp_ip_target_add(bond, target);
-		else if (newval->string[0] == '-')
-			ret = bond_option_arp_ip_target_rem(bond, target);
-		else
-			netdev_err(bond->dev, "no command found in arp_ip_targets file - use +<addr> or -<addr>\n");
-	} else {
-		target = newval->value;
-		ret = bond_option_arp_ip_target_add(bond, target);
-	}
-
-	return ret;
-}
-
-static int bond_option_arp_validate_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting arp_validate to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.arp_validate = newval->value;
-
-	return 0;
-}
-
-static int bond_option_arp_all_targets_set(struct bonding *bond,
-					   const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting arp_all_targets to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.arp_all_targets = newval->value;
-
-	return 0;
-}
-
-static int bond_option_primary_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	char *p, *primary = newval->string;
-	struct list_head *iter;
-	struct slave *slave;
-
-	block_netpoll_tx();
-
-	p = strchr(primary, '\n');
-	if (p)
-		*p = '\0';
-	/* check to see if we are clearing primary */
-	if (!strlen(primary)) {
-		netdev_dbg(bond->dev, "Setting primary slave to None\n");
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-		memset(bond->params.primary, 0, sizeof(bond->params.primary));
-		bond_select_active_slave(bond);
-		goto out;
-	}
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (strncmp(slave->dev->name, primary, IFNAMSIZ) == 0) {
-			slave_dbg(bond->dev, slave->dev, "Setting as primary slave\n");
-			rcu_assign_pointer(bond->primary_slave, slave);
-			strcpy(bond->params.primary, slave->dev->name);
-			bond->force_primary = true;
-			bond_select_active_slave(bond);
-			goto out;
-		}
-	}
-
-	if (rtnl_dereference(bond->primary_slave)) {
-		netdev_dbg(bond->dev, "Setting primary slave to None\n");
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-		bond_select_active_slave(bond);
-	}
-	strncpy(bond->params.primary, primary, IFNAMSIZ);
-	bond->params.primary[IFNAMSIZ - 1] = 0;
-
-	netdev_dbg(bond->dev, "Recording %s as primary, but it has not been enslaved yet\n",
-		   primary);
-
-out:
-	unblock_netpoll_tx();
-
-	return 0;
-}
-
-static int bond_option_primary_reselect_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting primary_reselect to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.primary_reselect = newval->value;
-
-	block_netpoll_tx();
-	bond_select_active_slave(bond);
-	unblock_netpoll_tx();
-
-	return 0;
-}
-
-static int bond_option_fail_over_mac_set(struct bonding *bond,
-					 const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting fail_over_mac to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.fail_over_mac = newval->value;
-
-	return 0;
-}
-
-static int bond_option_xmit_hash_policy_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting xmit hash policy to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.xmit_policy = newval->value;
-
-	return 0;
-}
-
-static int bond_option_resend_igmp_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting resend_igmp to %llu\n",
-		   newval->value);
-	bond->params.resend_igmp = newval->value;
-
-	return 0;
-}
-
-static int bond_option_num_peer_notif_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	bond->params.num_peer_notif = newval->value;
-
-	return 0;
-}
-
-static int bond_option_all_slaves_active_set(struct bonding *bond,
-					     const struct bond_opt_value *newval)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (newval->value == bond->params.all_slaves_active)
-		return 0;
-	bond->params.all_slaves_active = newval->value;
-	bond_for_each_slave(bond, slave, iter) {
-		if (!bond_is_active_slave(slave)) {
-			if (newval->value)
-				slave->inactive = 0;
-			else
-				slave->inactive = 1;
-		}
-	}
-
-	return 0;
-}
-
-static int bond_option_min_links_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting min links value to %llu\n",
-		   newval->value);
-	bond->params.min_links = newval->value;
-	bond_set_carrier(bond);
-
-	return 0;
-}
-
-static int bond_option_lp_interval_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	bond->params.lp_interval = newval->value;
-
-	return 0;
-}
-
-static int bond_option_pps_set(struct bonding *bond,
-			       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting packets per slave to %llu\n",
-		   newval->value);
-	bond->params.packets_per_slave = newval->value;
-	if (newval->value > 0) {
-		bond->params.reciprocal_packets_per_slave =
-			reciprocal_value(newval->value);
-	} else {
-		/* reciprocal_packets_per_slave is unused if
-		 * packets_per_slave is 0 or 1, just initialize it
-		 */
-		bond->params.reciprocal_packets_per_slave =
-			(struct reciprocal_value) { 0 };
-	}
-
-	return 0;
-}
-
-static int bond_option_lacp_rate_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting LACP rate to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.lacp_fast = newval->value;
-	bond_3ad_update_lacp_rate(bond);
-
-	return 0;
-}
-
-static int bond_option_ad_select_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_select to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.ad_select = newval->value;
-
-	return 0;
-}
-
-static int bond_option_queue_id_set(struct bonding *bond,
-				    const struct bond_opt_value *newval)
-{
-	struct slave *slave, *update_slave;
-	struct net_device *sdev;
-	struct list_head *iter;
-	char *delim;
-	int ret = 0;
-	u16 qid;
-
-	/* delim will point to queue id if successful */
-	delim = strchr(newval->string, ':');
-	if (!delim)
-		goto err_no_cmd;
-
-	/* Terminate string that points to device name and bump it
-	 * up one, so we can read the queue id there.
-	 */
-	*delim = '\0';
-	if (sscanf(++delim, "%hd\n", &qid) != 1)
-		goto err_no_cmd;
-
-	/* Check buffer length, valid ifname and queue id */
-	if (!dev_valid_name(newval->string) ||
-	    qid > bond->dev->real_num_tx_queues)
-		goto err_no_cmd;
-
-	/* Get the pointer to that interface if it exists */
-	sdev = __dev_get_by_name(dev_net(bond->dev), newval->string);
-	if (!sdev)
-		goto err_no_cmd;
-
-	/* Search for thes slave and check for duplicate qids */
-	update_slave = NULL;
-	bond_for_each_slave(bond, slave, iter) {
-		if (sdev == slave->dev)
-			/* We don't need to check the matching
-			 * slave for dups, since we're overwriting it
-			 */
-			update_slave = slave;
-		else if (qid && qid == slave->queue_id) {
-			goto err_no_cmd;
-		}
-	}
-
-	if (!update_slave)
-		goto err_no_cmd;
-
-	/* Actually set the qids for the slave */
-	update_slave->queue_id = qid;
-
-out:
-	return ret;
-
-err_no_cmd:
-	netdev_dbg(bond->dev, "invalid input for queue_id set\n");
-	ret = -EPERM;
-	goto out;
-
-}
-
-static int bond_option_slaves_set(struct bonding *bond,
-				  const struct bond_opt_value *newval)
-{
-	char command[IFNAMSIZ + 1] = { 0, };
-	struct net_device *dev;
-	char *ifname;
-	int ret;
-
-	sscanf(newval->string, "%16s", command); /* IFNAMSIZ*/
-	ifname = command + 1;
-	if ((strlen(command) <= 1) ||
-	    (command[0] != '+' && command[0] != '-') ||
-	    !dev_valid_name(ifname))
-		goto err_no_cmd;
-
-	dev = __dev_get_by_name(dev_net(bond->dev), ifname);
-	if (!dev) {
-		netdev_dbg(bond->dev, "interface %s does not exist!\n",
-			   ifname);
-		ret = -ENODEV;
-		goto out;
-	}
-
-	switch (command[0]) {
-	case '+':
-		slave_dbg(bond->dev, dev, "Enslaving interface\n");
-		ret = bond_enslave(bond->dev, dev, NULL);
-		break;
-
-	case '-':
-		slave_dbg(bond->dev, dev, "Releasing interface\n");
-		ret = bond_release(bond->dev, dev);
-		break;
-
-	default:
-		/* should not run here. */
-		goto err_no_cmd;
-	}
-
-out:
-	return ret;
-
-err_no_cmd:
-	netdev_err(bond->dev, "no command found in slaves file - use +ifname or -ifname\n");
-	ret = -EPERM;
-	goto out;
-}
-
-static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
-					  const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting dynamic-lb to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.tlb_dynamic_lb = newval->value;
-
-	return 0;
-}
-
-static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
-					     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_actor_sys_prio to %llu\n",
-		   newval->value);
-
-	bond->params.ad_actor_sys_prio = newval->value;
-	bond_3ad_update_ad_actor_settings(bond);
-
-	return 0;
-}
-
-static int bond_option_ad_actor_system_set(struct bonding *bond,
-					   const struct bond_opt_value *newval)
-{
-	u8 macaddr[ETH_ALEN];
-	u8 *mac;
-
-	if (newval->string) {
-		if (!mac_pton(newval->string, macaddr))
-			goto err;
-		mac = macaddr;
-	} else {
-		mac = (u8 *)&newval->value;
-	}
-
-	if (!is_valid_ether_addr(mac))
-		goto err;
-
-	netdev_dbg(bond->dev, "Setting ad_actor_system to %pM\n", mac);
-	ether_addr_copy(bond->params.ad_actor_system, mac);
-	bond_3ad_update_ad_actor_settings(bond);
-
-	return 0;
-
-err:
-	netdev_err(bond->dev, "Invalid ad_actor_system MAC address.\n");
-	return -EINVAL;
-}
-
-static int bond_option_ad_user_port_key_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_user_port_key to %llu\n",
-		   newval->value);
-
-	bond->params.ad_user_port_key = newval->value;
-	return 0;
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.10.0/bond_procfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.10.0/bond_procfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,312 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-#include <linux/proc_fs.h>
-#include <linux/export.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <net/bonding.h>
-
-#include "bonding_priv.h"
-
-static void *bond_info_seq_start(struct seq_file *seq, loff_t *pos)
-	__acquires(RCU)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	struct list_head *iter;
-	struct slave *slave;
-	loff_t off = 0;
-
-	rcu_read_lock();
-
-	if (*pos == 0)
-		return SEQ_START_TOKEN;
-
-	bond_for_each_slave_rcu(bond, slave, iter)
-		if (++off == *pos)
-			return slave;
-
-	return NULL;
-}
-
-static void *bond_info_seq_next(struct seq_file *seq, void *v, loff_t *pos)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	struct list_head *iter;
-	struct slave *slave;
-	bool found = false;
-
-	++*pos;
-	if (v == SEQ_START_TOKEN)
-		return bond_first_slave_rcu(bond);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (found)
-			return slave;
-		if (slave == v)
-			found = true;
-	}
-
-	return NULL;
-}
-
-static void bond_info_seq_stop(struct seq_file *seq, void *v)
-	__releases(RCU)
-{
-	rcu_read_unlock();
-}
-
-static void bond_info_show_master(struct seq_file *seq)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	const struct bond_opt_value *optval;
-	struct slave *curr, *primary;
-	int i;
-
-	curr = rcu_dereference(bond->curr_active_slave);
-
-	seq_printf(seq, "Bonding Mode: %s",
-		   bond_mode_name(BOND_MODE(bond)));
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
-	    bond->params.fail_over_mac) {
-		optval = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
-					  bond->params.fail_over_mac);
-		seq_printf(seq, " (fail_over_mac %s)", optval->string);
-	}
-
-	seq_printf(seq, "\n");
-
-	if (bond_mode_uses_xmit_hash(bond)) {
-		optval = bond_opt_get_val(BOND_OPT_XMIT_HASH,
-					  bond->params.xmit_policy);
-		seq_printf(seq, "Transmit Hash Policy: %s (%d)\n",
-			   optval->string, bond->params.xmit_policy);
-	}
-
-	if (bond_uses_primary(bond)) {
-		primary = rcu_dereference(bond->primary_slave);
-		seq_printf(seq, "Primary Slave: %s",
-			   primary ? primary->dev->name : "None");
-		if (primary) {
-			optval = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
-						  bond->params.primary_reselect);
-			seq_printf(seq, " (primary_reselect %s)",
-				   optval->string);
-		}
-
-		seq_printf(seq, "\nCurrently Active Slave: %s\n",
-			   (curr) ? curr->dev->name : "None");
-	}
-
-	seq_printf(seq, "MII Status: %s\n", netif_carrier_ok(bond->dev) ?
-		   "up" : "down");
-	seq_printf(seq, "MII Polling Interval (ms): %d\n", bond->params.miimon);
-	seq_printf(seq, "Up Delay (ms): %d\n",
-		   bond->params.updelay * bond->params.miimon);
-	seq_printf(seq, "Down Delay (ms): %d\n",
-		   bond->params.downdelay * bond->params.miimon);
-	seq_printf(seq, "Peer Notification Delay (ms): %d\n",
-		   bond->params.peer_notif_delay * bond->params.miimon);
-
-
-	/* ARP information */
-	if (bond->params.arp_interval > 0) {
-		int printed = 0;
-		seq_printf(seq, "ARP Polling Interval (ms): %d\n",
-				bond->params.arp_interval);
-
-		seq_printf(seq, "ARP IP target/s (n.n.n.n form):");
-
-		for (i = 0; (i < BOND_MAX_ARP_TARGETS); i++) {
-			if (!bond->params.arp_targets[i])
-				break;
-			if (printed)
-				seq_printf(seq, ",");
-			seq_printf(seq, " %pI4", &bond->params.arp_targets[i]);
-			printed = 1;
-		}
-		seq_printf(seq, "\n");
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-
-		seq_puts(seq, "\n802.3ad info\n");
-		seq_printf(seq, "LACP rate: %s\n",
-			   (bond->params.lacp_fast) ? "fast" : "slow");
-		seq_printf(seq, "Min links: %d\n", bond->params.min_links);
-		optval = bond_opt_get_val(BOND_OPT_AD_SELECT,
-					  bond->params.ad_select);
-		seq_printf(seq, "Aggregator selection policy (ad_select): %s\n",
-			   optval->string);
-		if (capable(CAP_NET_ADMIN)) {
-			seq_printf(seq, "System priority: %d\n",
-				   BOND_AD_INFO(bond).system.sys_priority);
-			seq_printf(seq, "System MAC address: %pM\n",
-				   &BOND_AD_INFO(bond).system.sys_mac_addr);
-
-			if (__bond_3ad_get_active_agg_info(bond, &ad_info)) {
-				seq_printf(seq,
-					   "bond %s has no active aggregator\n",
-					   bond->dev->name);
-			} else {
-				seq_printf(seq, "Active Aggregator Info:\n");
-
-				seq_printf(seq, "\tAggregator ID: %d\n",
-					   ad_info.aggregator_id);
-				seq_printf(seq, "\tNumber of ports: %d\n",
-					   ad_info.ports);
-				seq_printf(seq, "\tActor Key: %d\n",
-					   ad_info.actor_key);
-				seq_printf(seq, "\tPartner Key: %d\n",
-					   ad_info.partner_key);
-				seq_printf(seq, "\tPartner Mac Address: %pM\n",
-					   ad_info.partner_system);
-			}
-		}
-	}
-}
-
-static void bond_info_show_slave(struct seq_file *seq,
-				 const struct slave *slave)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-
-	seq_printf(seq, "\nSlave Interface: %s\n", slave->dev->name);
-	seq_printf(seq, "MII Status: %s\n", bond_slave_link_status(slave->link));
-	if (slave->speed == SPEED_UNKNOWN)
-		seq_printf(seq, "Speed: %s\n", "Unknown");
-	else
-		seq_printf(seq, "Speed: %d Mbps\n", slave->speed);
-
-	if (slave->duplex == DUPLEX_UNKNOWN)
-		seq_printf(seq, "Duplex: %s\n", "Unknown");
-	else
-		seq_printf(seq, "Duplex: %s\n", slave->duplex ? "full" : "half");
-
-	seq_printf(seq, "Link Failure Count: %u\n",
-		   slave->link_failure_count);
-
-	seq_printf(seq, "Permanent HW addr: %*phC\n",
-		   slave->dev->addr_len, slave->perm_hwaddr);
-	seq_printf(seq, "Slave queue ID: %d\n", slave->queue_id);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		const struct port *port = &SLAVE_AD_INFO(slave)->port;
-		const struct aggregator *agg = port->aggregator;
-
-		if (agg) {
-			seq_printf(seq, "Aggregator ID: %d\n",
-				   agg->aggregator_identifier);
-			seq_printf(seq, "Actor Churn State: %s\n",
-				   bond_3ad_churn_desc(port->sm_churn_actor_state));
-			seq_printf(seq, "Partner Churn State: %s\n",
-				   bond_3ad_churn_desc(port->sm_churn_partner_state));
-			seq_printf(seq, "Actor Churned Count: %d\n",
-				   port->churn_actor_count);
-			seq_printf(seq, "Partner Churned Count: %d\n",
-				   port->churn_partner_count);
-
-			if (capable(CAP_NET_ADMIN)) {
-				seq_puts(seq, "details actor lacp pdu:\n");
-				seq_printf(seq, "    system priority: %d\n",
-					   port->actor_system_priority);
-				seq_printf(seq, "    system mac address: %pM\n",
-					   &port->actor_system);
-				seq_printf(seq, "    port key: %d\n",
-					   port->actor_oper_port_key);
-				seq_printf(seq, "    port priority: %d\n",
-					   port->actor_port_priority);
-				seq_printf(seq, "    port number: %d\n",
-					   port->actor_port_number);
-				seq_printf(seq, "    port state: %d\n",
-					   port->actor_oper_port_state);
-
-				seq_puts(seq, "details partner lacp pdu:\n");
-				seq_printf(seq, "    system priority: %d\n",
-					   port->partner_oper.system_priority);
-				seq_printf(seq, "    system mac address: %pM\n",
-					   &port->partner_oper.system);
-				seq_printf(seq, "    oper key: %d\n",
-					   port->partner_oper.key);
-				seq_printf(seq, "    port priority: %d\n",
-					   port->partner_oper.port_priority);
-				seq_printf(seq, "    port number: %d\n",
-					   port->partner_oper.port_number);
-				seq_printf(seq, "    port state: %d\n",
-					   port->partner_oper.port_state);
-			}
-		} else {
-			seq_puts(seq, "Aggregator ID: N/A\n");
-		}
-	}
-}
-
-static int bond_info_seq_show(struct seq_file *seq, void *v)
-{
-	if (v == SEQ_START_TOKEN) {
-		seq_printf(seq, "%s\n", bond_version);
-		bond_info_show_master(seq);
-	} else
-		bond_info_show_slave(seq, v);
-
-	return 0;
-}
-
-static const struct seq_operations bond_info_seq_ops = {
-	.start = bond_info_seq_start,
-	.next  = bond_info_seq_next,
-	.stop  = bond_info_seq_stop,
-	.show  = bond_info_seq_show,
-};
-
-void bond_create_proc_entry(struct bonding *bond)
-{
-	struct net_device *bond_dev = bond->dev;
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	if (bn->proc_dir) {
-		bond->proc_entry = proc_create_seq_data(bond_dev->name, 0444,
-				bn->proc_dir, &bond_info_seq_ops, bond);
-		if (bond->proc_entry == NULL)
-			netdev_warn(bond_dev, "Cannot create /proc/net/%s/%s\n",
-				    DRV_NAME, bond_dev->name);
-		else
-			memcpy(bond->proc_file_name, bond_dev->name, IFNAMSIZ);
-	}
-}
-
-void bond_remove_proc_entry(struct bonding *bond)
-{
-	struct net_device *bond_dev = bond->dev;
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	if (bn->proc_dir && bond->proc_entry) {
-		remove_proc_entry(bond->proc_file_name, bn->proc_dir);
-		memset(bond->proc_file_name, 0, IFNAMSIZ);
-		bond->proc_entry = NULL;
-	}
-}
-
-/* Create the bonding directory under /proc/net, if doesn't exist yet.
- * Caller must hold rtnl_lock.
- */
-void __net_init bond_create_proc_dir(struct bond_net *bn)
-{
-	if (!bn->proc_dir) {
-		bn->proc_dir = proc_mkdir(DRV_NAME, bn->net->proc_net);
-		if (!bn->proc_dir)
-			pr_warn("Warning: Cannot create /proc/net/%s\n",
-				DRV_NAME);
-	}
-}
-
-/* Destroy the bonding directory under /proc/net, if empty.
- * Caller must hold rtnl_lock.
- */
-void __net_exit bond_destroy_proc_dir(struct bond_net *bn)
-{
-	if (bn->proc_dir) {
-		remove_proc_entry(DRV_NAME, bn->net->proc_net);
-		bn->proc_dir = NULL;
-	}
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.10.0/bond_sysfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.10.0/bond_sysfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,816 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 2004-2005 Intel Corporation. All rights reserved.
- */
-
-#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/device.h>
-#include <linux/sched/signal.h>
-#include <linux/fs.h>
-#include <linux/types.h>
-#include <linux/string.h>
-#include <linux/netdevice.h>
-#include <linux/inetdevice.h>
-#include <linux/in.h>
-#include <linux/sysfs.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/rtnetlink.h>
-#include <linux/etherdevice.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <linux/nsproxy.h>
-
-#include <net/bonding.h>
-
-#define to_bond(cd)	((struct bonding *)(netdev_priv(to_net_dev(cd))))
-
-/* "show" function for the bond_masters attribute.
- * The class parameter is ignored.
- */
-static ssize_t bonding_show_bonds(struct class *cls,
-				  struct class_attribute *attr,
-				  char *buf)
-{
-	struct bond_net *bn =
-		container_of(attr, struct bond_net, class_attr_bonding_masters);
-	int res = 0;
-	struct bonding *bond;
-
-	rtnl_lock();
-
-	list_for_each_entry(bond, &bn->dev_list, bond_list) {
-		if (res > (PAGE_SIZE - IFNAMSIZ)) {
-			/* not enough space for another interface name */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s ", bond->dev->name);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	rtnl_unlock();
-	return res;
-}
-
-static struct net_device *bond_get_by_name(struct bond_net *bn, const char *ifname)
-{
-	struct bonding *bond;
-
-	list_for_each_entry(bond, &bn->dev_list, bond_list) {
-		if (strncmp(bond->dev->name, ifname, IFNAMSIZ) == 0)
-			return bond->dev;
-	}
-	return NULL;
-}
-
-/* "store" function for the bond_masters attribute.  This is what
- * creates and deletes entire bonds.
- *
- * The class parameter is ignored.
- */
-static ssize_t bonding_store_bonds(struct class *cls,
-				   struct class_attribute *attr,
-				   const char *buffer, size_t count)
-{
-	struct bond_net *bn =
-		container_of(attr, struct bond_net, class_attr_bonding_masters);
-	char command[IFNAMSIZ + 1] = {0, };
-	char *ifname;
-	int rv, res = count;
-
-	sscanf(buffer, "%16s", command); /* IFNAMSIZ*/
-	ifname = command + 1;
-	if ((strlen(command) <= 1) ||
-	    !dev_valid_name(ifname))
-		goto err_no_cmd;
-
-	if (command[0] == '+') {
-		pr_info("%s is being created...\n", ifname);
-		rv = bond_create(bn->net, ifname);
-		if (rv) {
-			if (rv == -EEXIST)
-				pr_info("%s already exists\n", ifname);
-			else
-				pr_info("%s creation failed\n", ifname);
-			res = rv;
-		}
-	} else if (command[0] == '-') {
-		struct net_device *bond_dev;
-
-		rtnl_lock();
-		bond_dev = bond_get_by_name(bn, ifname);
-		if (bond_dev) {
-			pr_info("%s is being deleted...\n", ifname);
-			unregister_netdevice(bond_dev);
-		} else {
-			pr_err("unable to delete non-existent %s\n", ifname);
-			res = -ENODEV;
-		}
-		rtnl_unlock();
-	} else
-		goto err_no_cmd;
-
-	/* Always return either count or an error.  If you return 0, you'll
-	 * get called forever, which is bad.
-	 */
-	return res;
-
-err_no_cmd:
-	pr_err("no command found in bonding_masters - use +ifname or -ifname\n");
-	return -EPERM;
-}
-
-/* class attribute for bond_masters file.  This ends up in /sys/class/net */
-static const struct class_attribute class_attr_bonding_masters = {
-	.attr = {
-		.name = "bonding_masters",
-		.mode = 0644,
-	},
-	.show = bonding_show_bonds,
-	.store = bonding_store_bonds,
-};
-
-/* Generic "store" method for bonding sysfs option setting */
-static ssize_t bonding_sysfs_store_option(struct device *d,
-					  struct device_attribute *attr,
-					  const char *buffer, size_t count)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_option *opt;
-	char *buffer_clone;
-	int ret;
-
-	opt = bond_opt_get_by_name(attr->attr.name);
-	if (WARN_ON(!opt))
-		return -ENOENT;
-	buffer_clone = kstrndup(buffer, count, GFP_KERNEL);
-	if (!buffer_clone)
-		return -ENOMEM;
-	ret = bond_opt_tryset_rtnl(bond, opt->id, buffer_clone);
-	if (!ret)
-		ret = count;
-	kfree(buffer_clone);
-
-	return ret;
-}
-
-/* Show the slaves in the current bond. */
-static ssize_t bonding_show_slaves(struct device *d,
-				   struct device_attribute *attr, char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct list_head *iter;
-	struct slave *slave;
-	int res = 0;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (res > (PAGE_SIZE - IFNAMSIZ)) {
-			/* not enough space for another interface name */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s ", slave->dev->name);
-	}
-
-	rtnl_unlock();
-
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	return res;
-}
-static DEVICE_ATTR(slaves, 0644, bonding_show_slaves,
-		   bonding_sysfs_store_option);
-
-/* Show the bonding mode. */
-static ssize_t bonding_show_mode(struct device *d,
-				 struct device_attribute *attr, char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_MODE, BOND_MODE(bond));
-
-	return sprintf(buf, "%s %d\n", val->string, BOND_MODE(bond));
-}
-static DEVICE_ATTR(mode, 0644, bonding_show_mode, bonding_sysfs_store_option);
-
-/* Show the bonding transmit hash method. */
-static ssize_t bonding_show_xmit_hash(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_XMIT_HASH, bond->params.xmit_policy);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.xmit_policy);
-}
-static DEVICE_ATTR(xmit_hash_policy, 0644,
-		   bonding_show_xmit_hash, bonding_sysfs_store_option);
-
-/* Show arp_validate. */
-static ssize_t bonding_show_arp_validate(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
-			       bond->params.arp_validate);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.arp_validate);
-}
-static DEVICE_ATTR(arp_validate, 0644, bonding_show_arp_validate,
-		   bonding_sysfs_store_option);
-
-/* Show arp_all_targets. */
-static ssize_t bonding_show_arp_all_targets(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_ARP_ALL_TARGETS,
-			       bond->params.arp_all_targets);
-	return sprintf(buf, "%s %d\n",
-		       val->string, bond->params.arp_all_targets);
-}
-static DEVICE_ATTR(arp_all_targets, 0644,
-		   bonding_show_arp_all_targets, bonding_sysfs_store_option);
-
-/* Show fail_over_mac. */
-static ssize_t bonding_show_fail_over_mac(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
-			       bond->params.fail_over_mac);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.fail_over_mac);
-}
-static DEVICE_ATTR(fail_over_mac, 0644,
-		   bonding_show_fail_over_mac, bonding_sysfs_store_option);
-
-/* Show the arp timer interval. */
-static ssize_t bonding_show_arp_interval(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.arp_interval);
-}
-static DEVICE_ATTR(arp_interval, 0644,
-		   bonding_show_arp_interval, bonding_sysfs_store_option);
-
-/* Show the arp targets. */
-static ssize_t bonding_show_arp_targets(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	int i, res = 0;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
-		if (bond->params.arp_targets[i])
-			res += sprintf(buf + res, "%pI4 ",
-				       &bond->params.arp_targets[i]);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	return res;
-}
-static DEVICE_ATTR(arp_ip_target, 0644,
-		   bonding_show_arp_targets, bonding_sysfs_store_option);
-
-/* Show the up and down delays. */
-static ssize_t bonding_show_downdelay(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.downdelay * bond->params.miimon);
-}
-static DEVICE_ATTR(downdelay, 0644,
-		   bonding_show_downdelay, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_updelay(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.updelay * bond->params.miimon);
-
-}
-static DEVICE_ATTR(updelay, 0644,
-		   bonding_show_updelay, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_peer_notif_delay(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n",
-		       bond->params.peer_notif_delay * bond->params.miimon);
-}
-static DEVICE_ATTR(peer_notif_delay, 0644,
-		   bonding_show_peer_notif_delay, bonding_sysfs_store_option);
-
-/* Show the LACP interval. */
-static ssize_t bonding_show_lacp(struct device *d,
-				 struct device_attribute *attr,
-				 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_LACP_RATE, bond->params.lacp_fast);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.lacp_fast);
-}
-static DEVICE_ATTR(lacp_rate, 0644,
-		   bonding_show_lacp, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_min_links(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%u\n", bond->params.min_links);
-}
-static DEVICE_ATTR(min_links, 0644,
-		   bonding_show_min_links, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_select(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_AD_SELECT, bond->params.ad_select);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.ad_select);
-}
-static DEVICE_ATTR(ad_select, 0644,
-		   bonding_show_ad_select, bonding_sysfs_store_option);
-
-/* Show the number of peer notifications to send after a failover event. */
-static ssize_t bonding_show_num_peer_notif(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	return sprintf(buf, "%d\n", bond->params.num_peer_notif);
-}
-static DEVICE_ATTR(num_grat_arp, 0644,
-		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
-static DEVICE_ATTR(num_unsol_na, 0644,
-		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
-
-/* Show the MII monitor interval. */
-static ssize_t bonding_show_miimon(struct device *d,
-				   struct device_attribute *attr,
-				   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.miimon);
-}
-static DEVICE_ATTR(miimon, 0644,
-		   bonding_show_miimon, bonding_sysfs_store_option);
-
-/* Show the primary slave. */
-static ssize_t bonding_show_primary(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct slave *primary;
-	int count = 0;
-
-	rcu_read_lock();
-	primary = rcu_dereference(bond->primary_slave);
-	if (primary)
-		count = sprintf(buf, "%s\n", primary->dev->name);
-	rcu_read_unlock();
-
-	return count;
-}
-static DEVICE_ATTR(primary, 0644,
-		   bonding_show_primary, bonding_sysfs_store_option);
-
-/* Show the primary_reselect flag. */
-static ssize_t bonding_show_primary_reselect(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
-			       bond->params.primary_reselect);
-
-	return sprintf(buf, "%s %d\n",
-		       val->string, bond->params.primary_reselect);
-}
-static DEVICE_ATTR(primary_reselect, 0644,
-		   bonding_show_primary_reselect, bonding_sysfs_store_option);
-
-/* Show the use_carrier flag. */
-static ssize_t bonding_show_carrier(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.use_carrier);
-}
-static DEVICE_ATTR(use_carrier, 0644,
-		   bonding_show_carrier, bonding_sysfs_store_option);
-
-
-/* Show currently active_slave. */
-static ssize_t bonding_show_active_slave(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct net_device *slave_dev;
-	int count = 0;
-
-	rcu_read_lock();
-	slave_dev = bond_option_active_slave_get_rcu(bond);
-	if (slave_dev)
-		count = sprintf(buf, "%s\n", slave_dev->name);
-	rcu_read_unlock();
-
-	return count;
-}
-static DEVICE_ATTR(active_slave, 0644,
-		   bonding_show_active_slave, bonding_sysfs_store_option);
-
-/* Show link status of the bond interface. */
-static ssize_t bonding_show_mii_status(struct device *d,
-				       struct device_attribute *attr,
-				       char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	bool active = netif_carrier_ok(bond->dev);
-
-	return sprintf(buf, "%s\n", active ? "up" : "down");
-}
-static DEVICE_ATTR(mii_status, 0444, bonding_show_mii_status, NULL);
-
-/* Show current 802.3ad aggregator ID. */
-static ssize_t bonding_show_ad_aggregator(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.aggregator_id);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_aggregator, 0444, bonding_show_ad_aggregator, NULL);
-
-
-/* Show number of active 802.3ad ports. */
-static ssize_t bonding_show_ad_num_ports(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.ports);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_num_ports, 0444, bonding_show_ad_num_ports, NULL);
-
-
-/* Show current 802.3ad actor key. */
-static ssize_t bonding_show_ad_actor_key(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.actor_key);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_actor_key, 0444, bonding_show_ad_actor_key, NULL);
-
-
-/* Show current 802.3ad partner key. */
-static ssize_t bonding_show_ad_partner_key(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.partner_key);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_partner_key, 0444, bonding_show_ad_partner_key, NULL);
-
-
-/* Show current 802.3ad partner mac. */
-static ssize_t bonding_show_ad_partner_mac(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		if (!bond_3ad_get_active_agg_info(bond, &ad_info))
-			count = sprintf(buf, "%pM\n", ad_info.partner_system);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_partner_mac, 0444, bonding_show_ad_partner_mac, NULL);
-
-/* Show the queue_ids of the slaves in the current bond. */
-static ssize_t bonding_show_queue_id(struct device *d,
-				     struct device_attribute *attr,
-				     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct list_head *iter;
-	struct slave *slave;
-	int res = 0;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (res > (PAGE_SIZE - IFNAMSIZ - 6)) {
-			/* not enough space for another interface_name:queue_id pair */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s:%d ",
-			       slave->dev->name, slave->queue_id);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	rtnl_unlock();
-
-	return res;
-}
-static DEVICE_ATTR(queue_id, 0644, bonding_show_queue_id,
-		   bonding_sysfs_store_option);
-
-
-/* Show the all_slaves_active flag. */
-static ssize_t bonding_show_slaves_active(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.all_slaves_active);
-}
-static DEVICE_ATTR(all_slaves_active, 0644,
-		   bonding_show_slaves_active, bonding_sysfs_store_option);
-
-/* Show the number of IGMP membership reports to send on link failure */
-static ssize_t bonding_show_resend_igmp(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.resend_igmp);
-}
-static DEVICE_ATTR(resend_igmp, 0644,
-		   bonding_show_resend_igmp, bonding_sysfs_store_option);
-
-
-static ssize_t bonding_show_lp_interval(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.lp_interval);
-}
-static DEVICE_ATTR(lp_interval, 0644,
-		   bonding_show_lp_interval, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_tlb_dynamic_lb(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	return sprintf(buf, "%d\n", bond->params.tlb_dynamic_lb);
-}
-static DEVICE_ATTR(tlb_dynamic_lb, 0644,
-		   bonding_show_tlb_dynamic_lb, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_packets_per_slave(struct device *d,
-					      struct device_attribute *attr,
-					      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	unsigned int packets_per_slave = bond->params.packets_per_slave;
-
-	return sprintf(buf, "%u\n", packets_per_slave);
-}
-static DEVICE_ATTR(packets_per_slave, 0644,
-		   bonding_show_packets_per_slave, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_actor_sys_prio(struct device *d,
-					      struct device_attribute *attr,
-					      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%hu\n", bond->params.ad_actor_sys_prio);
-
-	return 0;
-}
-static DEVICE_ATTR(ad_actor_sys_prio, 0644,
-		   bonding_show_ad_actor_sys_prio, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_actor_system(struct device *d,
-					    struct device_attribute *attr,
-					    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%pM\n", bond->params.ad_actor_system);
-
-	return 0;
-}
-
-static DEVICE_ATTR(ad_actor_system, 0644,
-		   bonding_show_ad_actor_system, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_user_port_key(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%hu\n", bond->params.ad_user_port_key);
-
-	return 0;
-}
-static DEVICE_ATTR(ad_user_port_key, 0644,
-		   bonding_show_ad_user_port_key, bonding_sysfs_store_option);
-
-static struct attribute *per_bond_attrs[] = {
-	&dev_attr_slaves.attr,
-	&dev_attr_mode.attr,
-	&dev_attr_fail_over_mac.attr,
-	&dev_attr_arp_validate.attr,
-	&dev_attr_arp_all_targets.attr,
-	&dev_attr_arp_interval.attr,
-	&dev_attr_arp_ip_target.attr,
-	&dev_attr_downdelay.attr,
-	&dev_attr_updelay.attr,
-	&dev_attr_peer_notif_delay.attr,
-	&dev_attr_lacp_rate.attr,
-	&dev_attr_ad_select.attr,
-	&dev_attr_xmit_hash_policy.attr,
-	&dev_attr_num_grat_arp.attr,
-	&dev_attr_num_unsol_na.attr,
-	&dev_attr_miimon.attr,
-	&dev_attr_primary.attr,
-	&dev_attr_primary_reselect.attr,
-	&dev_attr_use_carrier.attr,
-	&dev_attr_active_slave.attr,
-	&dev_attr_mii_status.attr,
-	&dev_attr_ad_aggregator.attr,
-	&dev_attr_ad_num_ports.attr,
-	&dev_attr_ad_actor_key.attr,
-	&dev_attr_ad_partner_key.attr,
-	&dev_attr_ad_partner_mac.attr,
-	&dev_attr_queue_id.attr,
-	&dev_attr_all_slaves_active.attr,
-	&dev_attr_resend_igmp.attr,
-	&dev_attr_min_links.attr,
-	&dev_attr_lp_interval.attr,
-	&dev_attr_packets_per_slave.attr,
-	&dev_attr_tlb_dynamic_lb.attr,
-	&dev_attr_ad_actor_sys_prio.attr,
-	&dev_attr_ad_actor_system.attr,
-	&dev_attr_ad_user_port_key.attr,
-	NULL,
-};
-
-static const struct attribute_group bonding_group = {
-	.name = "bonding",
-	.attrs = per_bond_attrs,
-};
-
-/* Initialize sysfs.  This sets up the bonding_masters file in
- * /sys/class/net.
- */
-int bond_create_sysfs(struct bond_net *bn)
-{
-	int ret;
-
-	bn->class_attr_bonding_masters = class_attr_bonding_masters;
-	sysfs_attr_init(&bn->class_attr_bonding_masters.attr);
-
-	ret = netdev_class_create_file_ns(&bn->class_attr_bonding_masters,
-					  bn->net);
-	/* Permit multiple loads of the module by ignoring failures to
-	 * create the bonding_masters sysfs file.  Bonding devices
-	 * created by second or subsequent loads of the module will
-	 * not be listed in, or controllable by, bonding_masters, but
-	 * will have the usual "bonding" sysfs directory.
-	 *
-	 * This is done to preserve backwards compatibility for
-	 * initscripts/sysconfig, which load bonding multiple times to
-	 * configure multiple bonding devices.
-	 */
-	if (ret == -EEXIST) {
-		/* Is someone being kinky and naming a device bonding_master? */
-		if (__dev_get_by_name(bn->net,
-				      class_attr_bonding_masters.attr.name))
-			pr_err("network device named %s already exists in sysfs\n",
-			       class_attr_bonding_masters.attr.name);
-		ret = 0;
-	}
-
-	return ret;
-
-}
-
-/* Remove /sys/class/net/bonding_masters. */
-void bond_destroy_sysfs(struct bond_net *bn)
-{
-	netdev_class_remove_file_ns(&bn->class_attr_bonding_masters, bn->net);
-}
-
-/* Initialize sysfs for each bond.  This sets up and registers
- * the 'bondctl' directory for each individual bond under /sys/class/net.
- */
-void bond_prepare_sysfs_group(struct bonding *bond)
-{
-	bond->dev->sysfs_groups[0] = &bonding_group;
-}
-
diff -r 30 src/network/bonding/BONDING_KDIRS/5.10.0/bond_sysfs_slave.c
--- a/src/network/bonding/BONDING_KDIRS/5.10.0/bond_sysfs_slave.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,160 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*	Sysfs attributes of bond slaves
- *
- *      Copyright (c) 2014 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/capability.h>
-#include <linux/kernel.h>
-#include <linux/netdevice.h>
-
-#include <net/bonding.h>
-
-struct slave_attribute {
-	struct attribute attr;
-	ssize_t (*show)(struct slave *, char *);
-};
-
-#define SLAVE_ATTR(_name, _mode, _show)				\
-const struct slave_attribute slave_attr_##_name = {		\
-	.attr = {.name = __stringify(_name),			\
-		 .mode = _mode },				\
-	.show	= _show,					\
-};
-#define SLAVE_ATTR_RO(_name)					\
-	SLAVE_ATTR(_name, 0444, _name##_show)
-
-static ssize_t state_show(struct slave *slave, char *buf)
-{
-	switch (bond_slave_state(slave)) {
-	case BOND_STATE_ACTIVE:
-		return sprintf(buf, "active\n");
-	case BOND_STATE_BACKUP:
-		return sprintf(buf, "backup\n");
-	default:
-		return sprintf(buf, "UNKNOWN\n");
-	}
-}
-static SLAVE_ATTR_RO(state);
-
-static ssize_t mii_status_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%s\n", bond_slave_link_status(slave->link));
-}
-static SLAVE_ATTR_RO(mii_status);
-
-static ssize_t link_failure_count_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%d\n", slave->link_failure_count);
-}
-static SLAVE_ATTR_RO(link_failure_count);
-
-static ssize_t perm_hwaddr_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%*phC\n",
-		       slave->dev->addr_len,
-		       slave->perm_hwaddr);
-}
-static SLAVE_ATTR_RO(perm_hwaddr);
-
-static ssize_t queue_id_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%d\n", slave->queue_id);
-}
-static SLAVE_ATTR_RO(queue_id);
-
-static ssize_t ad_aggregator_id_show(struct slave *slave, char *buf)
-{
-	const struct aggregator *agg;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		agg = SLAVE_AD_INFO(slave)->port.aggregator;
-		if (agg)
-			return sprintf(buf, "%d\n",
-				       agg->aggregator_identifier);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_aggregator_id);
-
-static ssize_t ad_actor_oper_port_state_show(struct slave *slave, char *buf)
-{
-	const struct port *ad_port;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		if (ad_port->aggregator)
-			return sprintf(buf, "%u\n",
-				       ad_port->actor_oper_port_state);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_actor_oper_port_state);
-
-static ssize_t ad_partner_oper_port_state_show(struct slave *slave, char *buf)
-{
-	const struct port *ad_port;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		if (ad_port->aggregator)
-			return sprintf(buf, "%u\n",
-				       ad_port->partner_oper.port_state);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_partner_oper_port_state);
-
-static const struct slave_attribute *slave_attrs[] = {
-	&slave_attr_state,
-	&slave_attr_mii_status,
-	&slave_attr_link_failure_count,
-	&slave_attr_perm_hwaddr,
-	&slave_attr_queue_id,
-	&slave_attr_ad_aggregator_id,
-	&slave_attr_ad_actor_oper_port_state,
-	&slave_attr_ad_partner_oper_port_state,
-	NULL
-};
-
-#define to_slave_attr(_at) container_of(_at, struct slave_attribute, attr)
-
-static ssize_t slave_show(struct kobject *kobj,
-			  struct attribute *attr, char *buf)
-{
-	struct slave_attribute *slave_attr = to_slave_attr(attr);
-	struct slave *slave = to_slave(kobj);
-
-	return slave_attr->show(slave, buf);
-}
-
-const struct sysfs_ops slave_sysfs_ops = {
-	.show = slave_show,
-};
-
-int bond_sysfs_slave_add(struct slave *slave)
-{
-	const struct slave_attribute **a;
-	int err;
-
-	for (a = slave_attrs; *a; ++a) {
-		err = sysfs_create_file(&slave->kobj, &((*a)->attr));
-		if (err) {
-			kobject_put(&slave->kobj);
-			return err;
-		}
-	}
-
-	return 0;
-}
-
-void bond_sysfs_slave_del(struct slave *slave)
-{
-	const struct slave_attribute **a;
-
-	for (a = slave_attrs; *a; ++a)
-		sysfs_remove_file(&slave->kobj, &((*a)->attr));
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.10.0/bonding.mod.c
--- a/src/network/bonding/BONDING_KDIRS/5.10.0/bonding.mod.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,218 +0,0 @@
-#include <linux/module.h>
-#define INCLUDE_VERMAGIC
-#include <linux/build-salt.h>
-#include <linux/vermagic.h>
-#include <linux/compiler.h>
-
-BUILD_SALT;
-
-MODULE_INFO(vermagic, VERMAGIC_STRING);
-MODULE_INFO(name, KBUILD_MODNAME);
-
-__visible struct module __this_module
-__section(".gnu.linkonce.this_module") = {
-	.name = KBUILD_MODNAME,
-	.init = init_module,
-#ifdef CONFIG_MODULE_UNLOAD
-	.exit = cleanup_module,
-#endif
-	.arch = MODULE_ARCH_INIT,
-};
-
-MODULE_INFO(intree, "Y");
-
-#ifdef CONFIG_RETPOLINE
-MODULE_INFO(retpoline, "Y");
-#endif
-
-static const struct modversion_info ____versions[]
-__used __section("__versions") = {
-	{ 0xa6eb6c9f, "module_layout" },
-	{ 0x8b2513a4, "register_netdevice" },
-	{ 0x5952bb98, "dev_mc_sync_multiple" },
-	{ 0xfa319915, "kobject_put" },
-	{ 0x446a473b, "netdev_info" },
-	{ 0x9efec27a, "kmalloc_caches" },
-	{ 0xeb233a45, "__kmalloc" },
-	{ 0xb288a6aa, "dev_mc_unsync" },
-	{ 0x349cba85, "strchr" },
-	{ 0x94d50d61, "proc_create_seq_private" },
-	{ 0xa91cf8ef, "param_ops_int" },
-	{ 0xabeb9438, "skb_flow_dissector_init" },
-	{ 0x848ed455, "skb_flow_get_icmp_tci" },
-	{ 0x528093e0, "dev_disable_lro" },
-	{ 0x915100d3, "vlan_dev_vlan_id" },
-	{ 0x3cde9b04, "__skb_flow_dissect" },
-	{ 0x79aa04a2, "get_random_bytes" },
-	{ 0xfc6990e6, "seq_puts" },
-	{ 0x3d075b66, "netdev_rx_handler_register" },
-	{ 0xc7a4fbed, "rtnl_lock" },
-	{ 0xd0111f72, "vlan_uses_dev" },
-	{ 0xfa690589, "netdev_cmd_to_name" },
-	{ 0x93e57640, "netif_carrier_on" },
-	{ 0x4890c5e6, "dst_release" },
-	{ 0xc3690fc, "_raw_spin_lock_bh" },
-	{ 0x97137a55, "skb_clone" },
-	{ 0xffeedf6a, "delayed_work_timer_fn" },
-	{ 0x5ee16721, "flow_get_u32_src" },
-	{ 0xe0d389b2, "seq_printf" },
-	{ 0xd2da1048, "register_netdevice_notifier" },
-	{ 0x25f646f, "netif_carrier_off" },
-	{ 0x56470118, "__warn_printk" },
-	{ 0x70a0cc9f, "netdev_master_upper_dev_get" },
-	{ 0x9fc7e36c, "remove_proc_entry" },
-	{ 0x837b7b09, "__dynamic_pr_debug" },
-	{ 0xc29957c3, "__x86_indirect_thunk_rcx" },
-	{ 0x78c2e570, "dev_set_allmulti" },
-	{ 0x300d2eda, "vlan_vid_del" },
-	{ 0x735fec55, "netpoll_poll_dev" },
-	{ 0x1e22c48a, "call_netdevice_notifiers" },
-	{ 0x82b8cb7d, "__dev_kfree_skb_any" },
-	{ 0xc6f46339, "init_timer_key" },
-	{ 0x2d5f69b3, "rcu_read_unlock_strict" },
-	{ 0x9fa7184a, "cancel_delayed_work_sync" },
-	{ 0xb1900abb, "vlan_vid_add" },
-	{ 0xbaf22757, "kvfree_call_rcu" },
-	{ 0xa4b05da7, "__netpoll_setup" },
-	{ 0x4629334c, "__preempt_count" },
-	{ 0x363967c6, "vlan_vids_del_by_dev" },
-	{ 0x3c3ff9fd, "sprintf" },
-	{ 0x303ea4d1, "pv_ops" },
-	{ 0x539d1b09, "netdev_walk_all_upper_dev_rcu" },
-	{ 0x15ba50a6, "jiffies" },
-	{ 0xe1dea02c, "__dynamic_netdev_dbg" },
-	{ 0x9d0d6206, "unregister_netdevice_notifier" },
-	{ 0xb4d1cee0, "skb_trim" },
-	{ 0xe2d5255a, "strcmp" },
-	{ 0xba31c809, "vlan_vids_add_by_dev" },
-	{ 0x798090eb, "netdev_master_upper_dev_link" },
-	{ 0x6fde0d73, "dev_mc_add" },
-	{ 0x8e4846a5, "__netdev_alloc_skb" },
-	{ 0x1f09f2ed, "netdev_lower_get_next_private_rcu" },
-	{ 0x21ad40ad, "netdev_lower_state_changed" },
-	{ 0x96df09a8, "__pskb_pull_tail" },
-	{ 0x5066af52, "netdev_change_features" },
-	{ 0x6b10bee1, "_copy_to_user" },
-	{ 0xde742ecf, "PDE_DATA" },
-	{ 0xd1b5e121, "netdev_has_upper_dev" },
-	{ 0xf1db1704, "nla_memcpy" },
-	{ 0x192cfc65, "param_ops_charp" },
-	{ 0xa5d25a80, "dev_set_mac_address" },
-	{ 0x131788, "unregister_pernet_subsys" },
-	{ 0xbdcbf354, "proc_mkdir" },
-	{ 0x9fdecc31, "unregister_netdevice_many" },
-	{ 0x11089ac7, "_ctype" },
-	{ 0xe6bdc5f8, "current_task" },
-	{ 0x9959f6a7, "__ethtool_get_link_ksettings" },
-	{ 0x32e131e, "arp_create" },
-	{ 0xc5850110, "printk" },
-	{ 0xf6b416db, "ethtool_op_get_link" },
-	{ 0xbcab6ee6, "sscanf" },
-	{ 0xe1537255, "__list_del_entry_valid" },
-	{ 0xa965ca81, "reciprocal_value" },
-	{ 0xfba0a9d1, "ns_capable" },
-	{ 0x9240d1e2, "kobject_init_and_add" },
-	{ 0x62849ac7, "dev_valid_name" },
-	{ 0x4e6f8297, "netdev_class_remove_file_ns" },
-	{ 0xc29c65b0, "free_netdev" },
-	{ 0xe7b00dfb, "__x86_indirect_thunk_r13" },
-	{ 0x9166fada, "strncpy" },
-	{ 0x7f48895d, "dev_mc_del" },
-	{ 0xad9e797a, "nla_put" },
-	{ 0x1a77fbcf, "xfrm_dev_state_flush" },
-	{ 0x85b62c82, "netdev_upper_dev_unlink" },
-	{ 0x5a921311, "strncmp" },
-	{ 0x5a57d192, "skb_push" },
-	{ 0x652032cb, "mac_pton" },
-	{ 0x8c03d20c, "destroy_workqueue" },
-	{ 0x5dfe86f3, "dev_close" },
-	{ 0xf4f14de6, "rtnl_trylock" },
-	{ 0x726a43e9, "netdev_bonding_info_change" },
-	{ 0xf4d441a5, "dev_mc_flush" },
-	{ 0xfda9581f, "prandom_u32" },
-	{ 0x6091797f, "synchronize_rcu" },
-	{ 0xd897ed3e, "inet_confirm_addr" },
-	{ 0x3cb64603, "init_net" },
-	{ 0x90dfd0e4, "rtnl_link_unregister" },
-	{ 0xab34a7ab, "__dev_get_by_index" },
-	{ 0x68f31cbd, "__list_add_valid" },
-	{ 0x273fac16, "netdev_lower_dev_get_private" },
-	{ 0x9eacf8a5, "kstrndup" },
-	{ 0xc5de6193, "dev_open" },
-	{ 0x596801a6, "dev_uc_flush" },
-	{ 0xc6cbbc89, "capable" },
-	{ 0xb601be4c, "__x86_indirect_thunk_rdx" },
-	{ 0xa916b694, "strnlen" },
-	{ 0x88e5cd75, "netdev_upper_get_next_dev_rcu" },
-	{ 0x4a7cd981, "sysfs_remove_file_ns" },
-	{ 0xe46021ca, "_raw_spin_unlock_bh" },
-	{ 0xb2fcb56d, "queue_delayed_work_on" },
-	{ 0xc959d152, "__stack_chk_fail" },
-	{ 0xcaebe797, "vlan_dev_vlan_proto" },
-	{ 0x406304a6, "netdev_rx_handler_unregister" },
-	{ 0xb8b9f817, "kmalloc_order_trace" },
-	{ 0x1d24c881, "___ratelimit" },
-	{ 0xd4169d1d, "kfree_skb" },
-	{ 0xac5fcec0, "in4_pton" },
-	{ 0x3d321ac7, "passthru_features_check" },
-	{ 0xaadd04d4, "alloc_netdev_mqs" },
-	{ 0x2ea2c95c, "__x86_indirect_thunk_rax" },
-	{ 0x9facedc9, "arp_xmit" },
-	{ 0x94fd8520, "netdev_lower_get_next_private" },
-	{ 0xb7eded77, "register_pernet_subsys" },
-	{ 0xef0b0318, "pskb_expand_head" },
-	{ 0xbdfb6dbb, "__fentry__" },
-	{ 0x686a83cd, "netdev_err" },
-	{ 0xcbd4898c, "fortify_panic" },
-	{ 0xe9d98f28, "ether_setup" },
-	{ 0x10eb0d80, "dev_uc_unsync" },
-	{ 0x80a402f4, "__dev_get_by_name" },
-	{ 0x1e82893f, "kmem_cache_alloc_trace" },
-	{ 0xba8fbd64, "_raw_spin_lock" },
-	{ 0x7887b77a, "unregister_netdevice_queue" },
-	{ 0xff58c98d, "ip_route_output_flow" },
-	{ 0xf6ebc03b, "net_ratelimit" },
-	{ 0xb960a311, "netdev_warn" },
-	{ 0x523d501a, "__skb_flow_get_ports" },
-	{ 0x1f92a0c3, "dev_set_promiscuity" },
-	{ 0xa934bc4b, "flow_get_u32_dst" },
-	{ 0x37a0cba, "kfree" },
-	{ 0x78b4e074, "dev_uc_sync_multiple" },
-	{ 0x64df8f34, "param_array_ops" },
-	{ 0xbffa2d57, "dev_trans_start" },
-	{ 0x8da2cc51, "__dev_set_mtu" },
-	{ 0xcccec6e3, "rtnl_link_register" },
-	{ 0xe67dd70c, "netpoll_send_skb" },
-	{ 0x15fadcad, "dev_uc_sync" },
-	{ 0x9c363cc9, "netdev_lower_get_first_private_rcu" },
-	{ 0xa0dad88e, "netdev_adjacent_get_private" },
-	{ 0xf35b7feb, "nla_put_64bit" },
-	{ 0x3eb11a48, "__netpoll_free" },
-	{ 0x656e4a6e, "snprintf" },
-	{ 0xb0e602eb, "memmove" },
-	{ 0x59a938c6, "consume_skb" },
-	{ 0xa70acd68, "netdev_update_features" },
-	{ 0x85670f1d, "rtnl_is_locked" },
-	{ 0x7f02188f, "__msecs_to_jiffies" },
-	{ 0xda6518bd, "sysfs_create_file_ns" },
-	{ 0x3f028e35, "dev_queue_xmit" },
-	{ 0x61ba843b, "netdev_is_rx_handler_busy" },
-	{ 0xf44e583f, "skb_put" },
-	{ 0x13c49cc2, "_copy_from_user" },
-	{ 0x2ed1d098, "param_ops_uint" },
-	{ 0x5c0af9ac, "skb_copy_bits" },
-	{ 0x1484ea2b, "dev_mc_sync" },
-	{ 0xdf9208c0, "alloc_workqueue" },
-	{ 0xffc3c72b, "dev_pre_changeaddr_notify" },
-	{ 0x6e720ff2, "rtnl_unlock" },
-	{ 0x69668826, "netdev_increment_features" },
-	{ 0x4d11c7de, "dev_get_stats" },
-	{ 0x7f79943b, "netdev_class_create_file_ns" },
-	{ 0x7e7e33b9, "dev_set_mtu" },
-	{ 0xe914e41e, "strcpy" },
-};
-
-MODULE_INFO(depends, "");
-
-
-MODULE_INFO(srcversion, "7906E65FC44254C6FA04272");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.10.0/bonding_priv.h
--- a/src/network/bonding/BONDING_KDIRS/5.10.0/bonding_priv.h	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,25 +0,0 @@
-/*
- * Bond several ethernet interfaces into a Cisco, running 'Etherchannel'.
- *
- * Portions are (c) Copyright 1995 Simon "Guru Aleph-Null" Janes
- * NCM: Network and Communications Management, Inc.
- *
- * BUT, I'm the one who modified it for ethernet, so:
- * (c) Copyright 1999, Thomas Davis, tadavis@lbl.gov
- *
- *	This software may be used and distributed according to the terms
- *	of the GNU Public License, incorporated herein by reference.
- *
- */
-
-#ifndef _BONDING_PRIV_H
-#define _BONDING_PRIV_H
-#include <generated/utsrelease.h>
-
-#define DRV_VERSION     "3.7.1-chelsio"
-#define DRV_NAME	"bonding"
-#define DRV_DESCRIPTION	"Ethernet Channel Bonding Driver with Offload"
-
-#define bond_version DRV_DESCRIPTION ": v" UTS_RELEASE "\n"
-
-#endif
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bond_3ad.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bond_3ad.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,2767 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
- */
-
-#include <linux/skbuff.h>
-#include <linux/if_ether.h>
-#include <linux/netdevice.h>
-#include <linux/spinlock.h>
-#include <linux/ethtool.h>
-#include <linux/etherdevice.h>
-#include <linux/if_bonding.h>
-#include <linux/pkt_sched.h>
-#include <linux/toedev.h>
-#include <net/net_namespace.h>
-#include <net/bonding.h>
-#include <net/bond_3ad.h>
-#include <net/netlink.h>
-
-/* General definitions */
-#define AD_SHORT_TIMEOUT           1
-#define AD_LONG_TIMEOUT            0
-#define AD_STANDBY                 0x2
-#define AD_MAX_TX_IN_SECOND        3
-#define AD_COLLECTOR_MAX_DELAY     0
-
-/* Timer definitions (43.4.4 in the 802.3ad standard) */
-#define AD_FAST_PERIODIC_TIME      1
-#define AD_SLOW_PERIODIC_TIME      30
-#define AD_SHORT_TIMEOUT_TIME      (3*AD_FAST_PERIODIC_TIME)
-#define AD_LONG_TIMEOUT_TIME       (3*AD_SLOW_PERIODIC_TIME)
-#define AD_CHURN_DETECTION_TIME    60
-#define AD_AGGREGATE_WAIT_TIME     2
-
-/* Port state definitions (43.4.2.2 in the 802.3ad standard) */
-#define AD_STATE_LACP_ACTIVITY   0x1
-#define AD_STATE_LACP_TIMEOUT    0x2
-#define AD_STATE_AGGREGATION     0x4
-#define AD_STATE_SYNCHRONIZATION 0x8
-#define AD_STATE_COLLECTING      0x10
-#define AD_STATE_DISTRIBUTING    0x20
-#define AD_STATE_DEFAULTED       0x40
-#define AD_STATE_EXPIRED         0x80
-
-/* Port Variables definitions used by the State Machines (43.4.7 in the
- * 802.3ad standard)
- */
-#define AD_PORT_BEGIN           0x1
-#define AD_PORT_LACP_ENABLED    0x2
-#define AD_PORT_ACTOR_CHURN     0x4
-#define AD_PORT_PARTNER_CHURN   0x8
-#define AD_PORT_READY           0x10
-#define AD_PORT_READY_N         0x20
-#define AD_PORT_MATCHED         0x40
-#define AD_PORT_STANDBY         0x80
-#define AD_PORT_SELECTED        0x100
-#define AD_PORT_MOVED           0x200
-#define AD_PORT_CHURNED         (AD_PORT_ACTOR_CHURN | AD_PORT_PARTNER_CHURN)
-
-/* Port Key definitions
- * key is determined according to the link speed, duplex and
- * user key (which is yet not supported)
- *           --------------------------------------------------------------
- * Port key  | User key (10 bits)           | Speed (5 bits)      | Duplex|
- *           --------------------------------------------------------------
- *           |15                           6|5                   1|0
- */
-#define  AD_DUPLEX_KEY_MASKS    0x1
-#define  AD_SPEED_KEY_MASKS     0x3E
-#define  AD_USER_KEY_MASKS      0xFFC0
-
-enum ad_link_speed_type {
-	AD_LINK_SPEED_1MBPS = 1,
-	AD_LINK_SPEED_10MBPS,
-	AD_LINK_SPEED_100MBPS,
-	AD_LINK_SPEED_1000MBPS,
-	AD_LINK_SPEED_2500MBPS,
-	AD_LINK_SPEED_5000MBPS,
-	AD_LINK_SPEED_10000MBPS,
-	AD_LINK_SPEED_14000MBPS,
-	AD_LINK_SPEED_20000MBPS,
-	AD_LINK_SPEED_25000MBPS,
-	AD_LINK_SPEED_40000MBPS,
-	AD_LINK_SPEED_50000MBPS,
-	AD_LINK_SPEED_56000MBPS,
-	AD_LINK_SPEED_100000MBPS,
-};
-
-/* compare MAC addresses */
-#define MAC_ADDRESS_EQUAL(A, B)	\
-	ether_addr_equal_64bits((const u8 *)A, (const u8 *)B)
-
-static const u8 null_mac_addr[ETH_ALEN + 2] __long_aligned = {
-	0, 0, 0, 0, 0, 0
-};
-static u16 ad_ticks_per_sec;
-static const int ad_delta_in_ticks = (AD_TIMER_INTERVAL * HZ) / 1000;
-
-static const u8 lacpdu_mcast_addr[ETH_ALEN + 2] __long_aligned =
-	MULTICAST_LACPDU_ADDR;
-
-/* ================= main 802.3ad protocol functions ================== */
-static int ad_lacpdu_send(struct port *port);
-static int ad_marker_send(struct port *port, struct bond_marker *marker);
-static void ad_mux_machine(struct port *port, bool *update_slave_arr);
-static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port);
-static void ad_tx_machine(struct port *port);
-static void ad_periodic_machine(struct port *port);
-static void ad_port_selection_logic(struct port *port, bool *update_slave_arr);
-static void ad_agg_selection_logic(struct aggregator *aggregator,
-				   bool *update_slave_arr);
-static void ad_clear_agg(struct aggregator *aggregator);
-static void ad_initialize_agg(struct aggregator *aggregator);
-static void ad_initialize_port(struct port *port, int lacp_fast);
-static void ad_enable_collecting_distributing(struct port *port,
-					      bool *update_slave_arr);
-static void ad_disable_collecting_distributing(struct port *port,
-					       bool *update_slave_arr);
-static void ad_marker_info_received(struct bond_marker *marker_info,
-				    struct port *port);
-static void ad_marker_response_received(struct bond_marker *marker,
-					struct port *port);
-static void ad_update_actor_keys(struct port *port, bool reset);
-
-
-/* ================= api to bonding and kernel code ================== */
-
-/**
- * __get_bond_by_port - get the port's bonding struct
- * @port: the port we're looking at
- *
- * Return @port's bonding struct, or %NULL if it can't be found.
- */
-static inline struct bonding *__get_bond_by_port(struct port *port)
-{
-	if (port->slave == NULL)
-		return NULL;
-
-	return bond_get_bond_by_slave(port->slave);
-}
-
-/**
- * __get_first_agg - get the first aggregator in the bond
- * @bond: the bond we're looking at
- *
- * Return the aggregator of the first slave in @bond, or %NULL if it can't be
- * found.
- * The caller must hold RCU or RTNL lock.
- */
-static inline struct aggregator *__get_first_agg(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-	struct slave *first_slave;
-	struct aggregator *agg;
-
-	/* If there's no bond for this port, or bond has no slaves */
-	if (bond == NULL)
-		return NULL;
-
-	rcu_read_lock();
-	first_slave = bond_first_slave_rcu(bond);
-	agg = first_slave ? &(SLAVE_AD_INFO(first_slave)->aggregator) : NULL;
-	rcu_read_unlock();
-
-	return agg;
-}
-
-/**
- * __agg_has_partner - see if we have a partner
- * @agg: the agregator we're looking at
- *
- * Return nonzero if aggregator has a partner (denoted by a non-zero ether
- * address for the partner). Return 0 if not.
- */
-static inline int __agg_has_partner(struct aggregator *agg)
-{
-	return !is_zero_ether_addr(agg->partner_system.mac_addr_value);
-}
-
-/**
- * __disable_port - disable the port's slave
- * @port: the port we're looking at
- */
-static inline void __disable_port(struct port *port)
-{
-	bond_set_slave_inactive_flags(port->slave, BOND_SLAVE_NOTIFY_LATER);
-}
-
-/**
- * __enable_port - enable the port's slave, if it's up
- * @port: the port we're looking at
- */
-static inline void __enable_port(struct port *port)
-{
-	struct slave *slave = port->slave;
-
-	if ((slave->link == BOND_LINK_UP) && bond_slave_is_up(slave)) {
-		bond_set_slave_active_flags(slave, BOND_SLAVE_NOTIFY_LATER);
-		toe_failover(netdev_master_upper_dev_get_rcu(port->slave->dev),
-			     port->slave->dev, TOE_LINK_UP, NULL);
-	}
-}
-
-/**
- * __port_is_enabled - check if the port's slave is in active state
- * @port: the port we're looking at
- */
-static inline int __port_is_enabled(struct port *port)
-{
-	return bond_is_active_slave(port->slave);
-}
-
-/**
- * __get_agg_selection_mode - get the aggregator selection mode
- * @port: the port we're looking at
- *
- * Get the aggregator selection mode. Can be %STABLE, %BANDWIDTH or %COUNT.
- */
-static inline u32 __get_agg_selection_mode(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-
-	if (bond == NULL)
-		return BOND_AD_STABLE;
-
-	return bond->params.ad_select;
-}
-
-/**
- * __check_agg_selection_timer - check if the selection timer has expired
- * @port: the port we're looking at
- */
-static inline int __check_agg_selection_timer(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-
-	if (bond == NULL)
-		return 0;
-
-	return BOND_AD_INFO(bond).agg_select_timer ? 1 : 0;
-}
-
-/**
- * __get_link_speed - get a port's speed
- * @port: the port we're looking at
- *
- * Return @port's speed in 802.3ad enum format. i.e. one of:
- *     0,
- *     %AD_LINK_SPEED_10MBPS,
- *     %AD_LINK_SPEED_100MBPS,
- *     %AD_LINK_SPEED_1000MBPS,
- *     %AD_LINK_SPEED_2500MBPS,
- *     %AD_LINK_SPEED_5000MBPS,
- *     %AD_LINK_SPEED_10000MBPS
- *     %AD_LINK_SPEED_14000MBPS,
- *     %AD_LINK_SPEED_20000MBPS
- *     %AD_LINK_SPEED_25000MBPS
- *     %AD_LINK_SPEED_40000MBPS
- *     %AD_LINK_SPEED_50000MBPS
- *     %AD_LINK_SPEED_56000MBPS
- *     %AD_LINK_SPEED_100000MBPS
- */
-static u16 __get_link_speed(struct port *port)
-{
-	struct slave *slave = port->slave;
-	u16 speed;
-
-	/* this if covers only a special case: when the configuration starts
-	 * with link down, it sets the speed to 0.
-	 * This is done in spite of the fact that the e100 driver reports 0
-	 * to be compatible with MVT in the future.
-	 */
-	if (slave->link != BOND_LINK_UP)
-		speed = 0;
-	else {
-		switch (slave->speed) {
-		case SPEED_10:
-			speed = AD_LINK_SPEED_10MBPS;
-			break;
-
-		case SPEED_100:
-			speed = AD_LINK_SPEED_100MBPS;
-			break;
-
-		case SPEED_1000:
-			speed = AD_LINK_SPEED_1000MBPS;
-			break;
-
-		case SPEED_2500:
-			speed = AD_LINK_SPEED_2500MBPS;
-			break;
-
-		case SPEED_5000:
-			speed = AD_LINK_SPEED_5000MBPS;
-			break;
-
-		case SPEED_10000:
-			speed = AD_LINK_SPEED_10000MBPS;
-			break;
-
-		case SPEED_14000:
-			speed = AD_LINK_SPEED_14000MBPS;
-			break;
-
-		case SPEED_20000:
-			speed = AD_LINK_SPEED_20000MBPS;
-			break;
-
-		case SPEED_25000:
-			speed = AD_LINK_SPEED_25000MBPS;
-			break;
-
-		case SPEED_40000:
-			speed = AD_LINK_SPEED_40000MBPS;
-			break;
-
-		case SPEED_50000:
-			speed = AD_LINK_SPEED_50000MBPS;
-			break;
-
-		case SPEED_56000:
-			speed = AD_LINK_SPEED_56000MBPS;
-			break;
-
-		case SPEED_100000:
-			speed = AD_LINK_SPEED_100000MBPS;
-			break;
-
-		default:
-			/* unknown speed value from ethtool. shouldn't happen */
-			if (slave->speed != SPEED_UNKNOWN)
-				pr_warn_once("%s: (slave %s): unknown ethtool speed (%d) for port %d (set it to 0)\n",
-					     slave->bond->dev->name,
-					     slave->dev->name, slave->speed,
-					     port->actor_port_number);
-			speed = 0;
-			break;
-		}
-	}
-
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d Received link speed %d update from adapter\n",
-		  port->actor_port_number, speed);
-	return speed;
-}
-
-/**
- * __get_duplex - get a port's duplex
- * @port: the port we're looking at
- *
- * Return @port's duplex in 802.3ad bitmask format. i.e.:
- *     0x01 if in full duplex
- *     0x00 otherwise
- */
-static u8 __get_duplex(struct port *port)
-{
-	struct slave *slave = port->slave;
-	u8 retval = 0x0;
-
-	/* handling a special case: when the configuration starts with
-	 * link down, it sets the duplex to 0.
-	 */
-	if (slave->link == BOND_LINK_UP) {
-		switch (slave->duplex) {
-		case DUPLEX_FULL:
-			retval = 0x1;
-			slave_dbg(slave->bond->dev, slave->dev, "Port %d Received status full duplex update from adapter\n",
-				  port->actor_port_number);
-			break;
-		case DUPLEX_HALF:
-		default:
-			retval = 0x0;
-			slave_dbg(slave->bond->dev, slave->dev, "Port %d Received status NOT full duplex update from adapter\n",
-				  port->actor_port_number);
-			break;
-		}
-	}
-	return retval;
-}
-
-static void __ad_actor_update_port(struct port *port)
-{
-	const struct bonding *bond = bond_get_bond_by_slave(port->slave);
-
-	port->actor_system = BOND_AD_INFO(bond).system.sys_mac_addr;
-	port->actor_system_priority = BOND_AD_INFO(bond).system.sys_priority;
-}
-
-/* Conversions */
-
-/**
- * __ad_timer_to_ticks - convert a given timer type to AD module ticks
- * @timer_type:	which timer to operate
- * @par: timer parameter. see below
- *
- * If @timer_type is %current_while_timer, @par indicates long/short timer.
- * If @timer_type is %periodic_timer, @par is one of %FAST_PERIODIC_TIME,
- *						     %SLOW_PERIODIC_TIME.
- */
-static u16 __ad_timer_to_ticks(u16 timer_type, u16 par)
-{
-	u16 retval = 0; /* to silence the compiler */
-
-	switch (timer_type) {
-	case AD_CURRENT_WHILE_TIMER:	/* for rx machine usage */
-		if (par)
-			retval = (AD_SHORT_TIMEOUT_TIME*ad_ticks_per_sec);
-		else
-			retval = (AD_LONG_TIMEOUT_TIME*ad_ticks_per_sec);
-		break;
-	case AD_ACTOR_CHURN_TIMER:	/* for local churn machine */
-		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
-		break;
-	case AD_PERIODIC_TIMER:		/* for periodic machine */
-		retval = (par*ad_ticks_per_sec); /* long timeout */
-		break;
-	case AD_PARTNER_CHURN_TIMER:	/* for remote churn machine */
-		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
-		break;
-	case AD_WAIT_WHILE_TIMER:	/* for selection machine */
-		retval = (AD_AGGREGATE_WAIT_TIME*ad_ticks_per_sec);
-		break;
-	}
-
-	return retval;
-}
-
-
-/* ================= ad_rx_machine helper functions ================== */
-
-/**
- * __choose_matched - update a port's matched variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Update the value of the matched variable, using parameter values from a
- * newly received lacpdu. Parameter values for the partner carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the actor. Matched is set to TRUE if all of these parameters
- * match and the PDU parameter partner_state.aggregation has the same value as
- * actor_oper_port_state.aggregation and lacp will actively maintain the link
- * in the aggregation. Matched is also set to TRUE if the value of
- * actor_state.aggregation in the received PDU is set to FALSE, i.e., indicates
- * an individual link and lacp will actively maintain the link. Otherwise,
- * matched is set to FALSE. LACP is considered to be actively maintaining the
- * link if either the PDU's actor_state.lacp_activity variable is TRUE or both
- * the actor's actor_oper_port_state.lacp_activity and the PDU's
- * partner_state.lacp_activity variables are TRUE.
- *
- * Note: the AD_PORT_MATCHED "variable" is not specified by 802.3ad; it is
- * used here to implement the language from 802.3ad 43.4.9 that requires
- * recordPDU to "match" the LACPDU parameters to the stored values.
- */
-static void __choose_matched(struct lacpdu *lacpdu, struct port *port)
-{
-	/* check if all parameters are alike
-	 * or this is individual link(aggregation == FALSE)
-	 * then update the state machine Matched variable.
-	 */
-	if (((ntohs(lacpdu->partner_port) == port->actor_port_number) &&
-	     (ntohs(lacpdu->partner_port_priority) == port->actor_port_priority) &&
-	     MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) &&
-	     (ntohs(lacpdu->partner_system_priority) == port->actor_system_priority) &&
-	     (ntohs(lacpdu->partner_key) == port->actor_oper_port_key) &&
-	     ((lacpdu->partner_state & AD_STATE_AGGREGATION) == (port->actor_oper_port_state & AD_STATE_AGGREGATION))) ||
-	    ((lacpdu->actor_state & AD_STATE_AGGREGATION) == 0)
-		) {
-		port->sm_vars |= AD_PORT_MATCHED;
-	} else {
-		port->sm_vars &= ~AD_PORT_MATCHED;
-	}
-}
-
-/**
- * __record_pdu - record parameters from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Record the parameter values for the Actor carried in a received lacpdu as
- * the current partner operational parameter values and sets
- * actor_oper_port_state.defaulted to FALSE.
- */
-static void __record_pdu(struct lacpdu *lacpdu, struct port *port)
-{
-	if (lacpdu && port) {
-		struct port_params *partner = &port->partner_oper;
-
-		__choose_matched(lacpdu, port);
-		/* record the new parameter values for the partner
-		 * operational
-		 */
-		partner->port_number = ntohs(lacpdu->actor_port);
-		partner->port_priority = ntohs(lacpdu->actor_port_priority);
-		partner->system = lacpdu->actor_system;
-		partner->system_priority = ntohs(lacpdu->actor_system_priority);
-		partner->key = ntohs(lacpdu->actor_key);
-		partner->port_state = lacpdu->actor_state;
-
-		/* set actor_oper_port_state.defaulted to FALSE */
-		port->actor_oper_port_state &= ~AD_STATE_DEFAULTED;
-
-		/* set the partner sync. to on if the partner is sync,
-		 * and the port is matched
-		 */
-		if ((port->sm_vars & AD_PORT_MATCHED) &&
-		    (lacpdu->actor_state & AD_STATE_SYNCHRONIZATION)) {
-			partner->port_state |= AD_STATE_SYNCHRONIZATION;
-			slave_dbg(port->slave->bond->dev, port->slave->dev,
-				  "partner sync=1\n");
-		} else {
-			partner->port_state &= ~AD_STATE_SYNCHRONIZATION;
-			slave_dbg(port->slave->bond->dev, port->slave->dev,
-				  "partner sync=0\n");
-		}
-	}
-}
-
-/**
- * __record_default - record default parameters
- * @port: the port we're looking at
- *
- * This function records the default parameter values for the partner carried
- * in the Partner Admin parameters as the current partner operational parameter
- * values and sets actor_oper_port_state.defaulted to TRUE.
- */
-static void __record_default(struct port *port)
-{
-	if (port) {
-		/* record the partner admin parameters */
-		memcpy(&port->partner_oper, &port->partner_admin,
-		       sizeof(struct port_params));
-
-		/* set actor_oper_port_state.defaulted to true */
-		port->actor_oper_port_state |= AD_STATE_DEFAULTED;
-	}
-}
-
-/**
- * __update_selected - update a port's Selected variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Update the value of the selected variable, using parameter values from a
- * newly received lacpdu. The parameter values for the Actor carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the ports partner. If one or more of the comparisons shows that
- * the value(s) received in the PDU differ from the current operational values,
- * then selected is set to FALSE and actor_oper_port_state.synchronization is
- * set to out_of_sync. Otherwise, selected remains unchanged.
- */
-static void __update_selected(struct lacpdu *lacpdu, struct port *port)
-{
-	if (lacpdu && port) {
-		const struct port_params *partner = &port->partner_oper;
-
-		/* check if any parameter is different then
-		 * update the state machine selected variable.
-		 */
-		if (ntohs(lacpdu->actor_port) != partner->port_number ||
-		    ntohs(lacpdu->actor_port_priority) != partner->port_priority ||
-		    !MAC_ADDRESS_EQUAL(&lacpdu->actor_system, &partner->system) ||
-		    ntohs(lacpdu->actor_system_priority) != partner->system_priority ||
-		    ntohs(lacpdu->actor_key) != partner->key ||
-		    (lacpdu->actor_state & AD_STATE_AGGREGATION) != (partner->port_state & AD_STATE_AGGREGATION)) {
-			port->sm_vars &= ~AD_PORT_SELECTED;
-		}
-	}
-}
-
-/**
- * __update_default_selected - update a port's Selected variable from Partner
- * @port: the port we're looking at
- *
- * This function updates the value of the selected variable, using the partner
- * administrative parameter values. The administrative values are compared with
- * the corresponding operational parameter values for the partner. If one or
- * more of the comparisons shows that the administrative value(s) differ from
- * the current operational values, then Selected is set to FALSE and
- * actor_oper_port_state.synchronization is set to OUT_OF_SYNC. Otherwise,
- * Selected remains unchanged.
- */
-static void __update_default_selected(struct port *port)
-{
-	if (port) {
-		const struct port_params *admin = &port->partner_admin;
-		const struct port_params *oper = &port->partner_oper;
-
-		/* check if any parameter is different then
-		 * update the state machine selected variable.
-		 */
-		if (admin->port_number != oper->port_number ||
-		    admin->port_priority != oper->port_priority ||
-		    !MAC_ADDRESS_EQUAL(&admin->system, &oper->system) ||
-		    admin->system_priority != oper->system_priority ||
-		    admin->key != oper->key ||
-		    (admin->port_state & AD_STATE_AGGREGATION)
-			!= (oper->port_state & AD_STATE_AGGREGATION)) {
-			port->sm_vars &= ~AD_PORT_SELECTED;
-		}
-	}
-}
-
-/**
- * __update_ntt - update a port's ntt variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Updates the value of the ntt variable, using parameter values from a newly
- * received lacpdu. The parameter values for the partner carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the Actor. If one or more of the comparisons shows that the
- * value(s) received in the PDU differ from the current operational values,
- * then ntt is set to TRUE. Otherwise, ntt remains unchanged.
- */
-static void __update_ntt(struct lacpdu *lacpdu, struct port *port)
-{
-	/* validate lacpdu and port */
-	if (lacpdu && port) {
-		/* check if any parameter is different then
-		 * update the port->ntt.
-		 */
-		if ((ntohs(lacpdu->partner_port) != port->actor_port_number) ||
-		    (ntohs(lacpdu->partner_port_priority) != port->actor_port_priority) ||
-		    !MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) ||
-		    (ntohs(lacpdu->partner_system_priority) != port->actor_system_priority) ||
-		    (ntohs(lacpdu->partner_key) != port->actor_oper_port_key) ||
-		    ((lacpdu->partner_state & AD_STATE_LACP_ACTIVITY) != (port->actor_oper_port_state & AD_STATE_LACP_ACTIVITY)) ||
-		    ((lacpdu->partner_state & AD_STATE_LACP_TIMEOUT) != (port->actor_oper_port_state & AD_STATE_LACP_TIMEOUT)) ||
-		    ((lacpdu->partner_state & AD_STATE_SYNCHRONIZATION) != (port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION)) ||
-		    ((lacpdu->partner_state & AD_STATE_AGGREGATION) != (port->actor_oper_port_state & AD_STATE_AGGREGATION))
-		   ) {
-			port->ntt = true;
-		}
-	}
-}
-
-/**
- * __agg_ports_are_ready - check if all ports in an aggregator are ready
- * @aggregator: the aggregator we're looking at
- *
- */
-static int __agg_ports_are_ready(struct aggregator *aggregator)
-{
-	struct port *port;
-	int retval = 1;
-
-	if (aggregator) {
-		/* scan all ports in this aggregator to verfy if they are
-		 * all ready.
-		 */
-		for (port = aggregator->lag_ports;
-		     port;
-		     port = port->next_port_in_aggregator) {
-			if (!(port->sm_vars & AD_PORT_READY_N)) {
-				retval = 0;
-				break;
-			}
-		}
-	}
-
-	return retval;
-}
-
-/**
- * __set_agg_ports_ready - set value of Ready bit in all ports of an aggregator
- * @aggregator: the aggregator we're looking at
- * @val: Should the ports' ready bit be set on or off
- *
- */
-static void __set_agg_ports_ready(struct aggregator *aggregator, int val)
-{
-	struct port *port;
-
-	for (port = aggregator->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (val)
-			port->sm_vars |= AD_PORT_READY;
-		else
-			port->sm_vars &= ~AD_PORT_READY;
-	}
-}
-
-static int __agg_active_ports(struct aggregator *agg)
-{
-	struct port *port;
-	int active = 0;
-
-	for (port = agg->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (port->is_enabled)
-			active++;
-	}
-
-	return active;
-}
-
-/**
- * __get_agg_bandwidth - get the total bandwidth of an aggregator
- * @aggregator: the aggregator we're looking at
- *
- */
-static u32 __get_agg_bandwidth(struct aggregator *aggregator)
-{
-	int nports = __agg_active_ports(aggregator);
-	u32 bandwidth = 0;
-
-	if (nports) {
-		switch (__get_link_speed(aggregator->lag_ports)) {
-		case AD_LINK_SPEED_1MBPS:
-			bandwidth = nports;
-			break;
-		case AD_LINK_SPEED_10MBPS:
-			bandwidth = nports * 10;
-			break;
-		case AD_LINK_SPEED_100MBPS:
-			bandwidth = nports * 100;
-			break;
-		case AD_LINK_SPEED_1000MBPS:
-			bandwidth = nports * 1000;
-			break;
-		case AD_LINK_SPEED_2500MBPS:
-			bandwidth = nports * 2500;
-			break;
-		case AD_LINK_SPEED_5000MBPS:
-			bandwidth = nports * 5000;
-			break;
-		case AD_LINK_SPEED_10000MBPS:
-			bandwidth = nports * 10000;
-			break;
-		case AD_LINK_SPEED_14000MBPS:
-			bandwidth = nports * 14000;
-			break;
-		case AD_LINK_SPEED_20000MBPS:
-			bandwidth = nports * 20000;
-			break;
-		case AD_LINK_SPEED_25000MBPS:
-			bandwidth = nports * 25000;
-			break;
-		case AD_LINK_SPEED_40000MBPS:
-			bandwidth = nports * 40000;
-			break;
-		case AD_LINK_SPEED_50000MBPS:
-			bandwidth = nports * 50000;
-			break;
-		case AD_LINK_SPEED_56000MBPS:
-			bandwidth = nports * 56000;
-			break;
-		case AD_LINK_SPEED_100000MBPS:
-			bandwidth = nports * 100000;
-			break;
-		default:
-			bandwidth = 0; /* to silence the compiler */
-		}
-	}
-	return bandwidth;
-}
-
-/**
- * __get_active_agg - get the current active aggregator
- * @aggregator: the aggregator we're looking at
- *
- * Caller must hold RCU lock.
- */
-static struct aggregator *__get_active_agg(struct aggregator *aggregator)
-{
-	struct bonding *bond = aggregator->slave->bond;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave_rcu(bond, slave, iter)
-		if (SLAVE_AD_INFO(slave)->aggregator.is_active)
-			return &(SLAVE_AD_INFO(slave)->aggregator);
-
-	return NULL;
-}
-
-/**
- * __update_lacpdu_from_port - update a port's lacpdu fields
- * @port: the port we're looking at
- */
-static inline void __update_lacpdu_from_port(struct port *port)
-{
-	struct lacpdu *lacpdu = &port->lacpdu;
-	const struct port_params *partner = &port->partner_oper;
-
-	/* update current actual Actor parameters
-	 * lacpdu->subtype                   initialized
-	 * lacpdu->version_number            initialized
-	 * lacpdu->tlv_type_actor_info       initialized
-	 * lacpdu->actor_information_length  initialized
-	 */
-
-	lacpdu->actor_system_priority = htons(port->actor_system_priority);
-	lacpdu->actor_system = port->actor_system;
-	lacpdu->actor_key = htons(port->actor_oper_port_key);
-	lacpdu->actor_port_priority = htons(port->actor_port_priority);
-	lacpdu->actor_port = htons(port->actor_port_number);
-	lacpdu->actor_state = port->actor_oper_port_state;
-	slave_dbg(port->slave->bond->dev, port->slave->dev,
-		  "update lacpdu: actor port state %x\n",
-		  port->actor_oper_port_state);
-
-	/* lacpdu->reserved_3_1              initialized
-	 * lacpdu->tlv_type_partner_info     initialized
-	 * lacpdu->partner_information_length initialized
-	 */
-
-	lacpdu->partner_system_priority = htons(partner->system_priority);
-	lacpdu->partner_system = partner->system;
-	lacpdu->partner_key = htons(partner->key);
-	lacpdu->partner_port_priority = htons(partner->port_priority);
-	lacpdu->partner_port = htons(partner->port_number);
-	lacpdu->partner_state = partner->port_state;
-
-	/* lacpdu->reserved_3_2              initialized
-	 * lacpdu->tlv_type_collector_info   initialized
-	 * lacpdu->collector_information_length initialized
-	 * collector_max_delay                initialized
-	 * reserved_12[12]                   initialized
-	 * tlv_type_terminator               initialized
-	 * terminator_length                 initialized
-	 * reserved_50[50]                   initialized
-	 */
-}
-
-/* ================= main 802.3ad protocol code ========================= */
-
-/**
- * ad_lacpdu_send - send out a lacpdu packet on a given port
- * @port: the port we're looking at
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-static int ad_lacpdu_send(struct port *port)
-{
-	struct slave *slave = port->slave;
-	struct sk_buff *skb;
-	struct lacpdu_header *lacpdu_header;
-	int length = sizeof(struct lacpdu_header);
-
-	skb = dev_alloc_skb(length);
-	if (!skb)
-		return -ENOMEM;
-
-	atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_tx);
-	atomic64_inc(&BOND_AD_INFO(slave->bond).stats.lacpdu_tx);
-
-	skb->dev = slave->dev;
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = PKT_TYPE_LACPDU;
-	skb->priority = TC_PRIO_CONTROL;
-
-	lacpdu_header = skb_put(skb, length);
-
-	ether_addr_copy(lacpdu_header->hdr.h_dest, lacpdu_mcast_addr);
-	/* Note: source address is set to be the member's PERMANENT address,
-	 * because we use it to identify loopback lacpdus in receive.
-	 */
-	ether_addr_copy(lacpdu_header->hdr.h_source, slave->perm_hwaddr);
-	lacpdu_header->hdr.h_proto = PKT_TYPE_LACPDU;
-
-	lacpdu_header->lacpdu = port->lacpdu;
-
-	dev_queue_xmit(skb);
-
-	return 0;
-}
-
-/**
- * ad_marker_send - send marker information/response on a given port
- * @port: the port we're looking at
- * @marker: marker data to send
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-static int ad_marker_send(struct port *port, struct bond_marker *marker)
-{
-	struct slave *slave = port->slave;
-	struct sk_buff *skb;
-	struct bond_marker_header *marker_header;
-	int length = sizeof(struct bond_marker_header);
-
-	skb = dev_alloc_skb(length + 16);
-	if (!skb)
-		return -ENOMEM;
-
-	switch (marker->tlv_type) {
-	case AD_MARKER_INFORMATION_SUBTYPE:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.marker_tx);
-		atomic64_inc(&BOND_AD_INFO(slave->bond).stats.marker_tx);
-		break;
-	case AD_MARKER_RESPONSE_SUBTYPE:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.marker_resp_tx);
-		atomic64_inc(&BOND_AD_INFO(slave->bond).stats.marker_resp_tx);
-		break;
-	}
-
-	skb_reserve(skb, 16);
-
-	skb->dev = slave->dev;
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = PKT_TYPE_LACPDU;
-
-	marker_header = skb_put(skb, length);
-
-	ether_addr_copy(marker_header->hdr.h_dest, lacpdu_mcast_addr);
-	/* Note: source address is set to be the member's PERMANENT address,
-	 * because we use it to identify loopback MARKERs in receive.
-	 */
-	ether_addr_copy(marker_header->hdr.h_source, slave->perm_hwaddr);
-	marker_header->hdr.h_proto = PKT_TYPE_LACPDU;
-
-	marker_header->marker = *marker;
-
-	dev_queue_xmit(skb);
-
-	return 0;
-}
-
-/**
- * ad_mux_machine - handle a port's mux state machine
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- */
-static void ad_mux_machine(struct port *port, bool *update_slave_arr)
-{
-	mux_states_t last_state;
-
-	/* keep current State Machine state to compare later if it was
-	 * changed
-	 */
-	last_state = port->sm_mux_state;
-
-	if (port->sm_vars & AD_PORT_BEGIN) {
-		port->sm_mux_state = AD_MUX_DETACHED;
-	} else {
-		switch (port->sm_mux_state) {
-		case AD_MUX_DETACHED:
-			if ((port->sm_vars & AD_PORT_SELECTED)
-			    || (port->sm_vars & AD_PORT_STANDBY))
-				/* if SELECTED or STANDBY */
-				port->sm_mux_state = AD_MUX_WAITING;
-			break;
-		case AD_MUX_WAITING:
-			/* if SELECTED == FALSE return to DETACH state */
-			if (!(port->sm_vars & AD_PORT_SELECTED)) {
-				port->sm_vars &= ~AD_PORT_READY_N;
-				/* in order to withhold the Selection Logic to
-				 * check all ports READY_N value every callback
-				 * cycle to update ready variable, we check
-				 * READY_N and update READY here
-				 */
-				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-				port->sm_mux_state = AD_MUX_DETACHED;
-				break;
-			}
-
-			/* check if the wait_while_timer expired */
-			if (port->sm_mux_timer_counter
-			    && !(--port->sm_mux_timer_counter))
-				port->sm_vars |= AD_PORT_READY_N;
-
-			/* in order to withhold the selection logic to check
-			 * all ports READY_N value every callback cycle to
-			 * update ready variable, we check READY_N and update
-			 * READY here
-			 */
-			__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-
-			/* if the wait_while_timer expired, and the port is
-			 * in READY state, move to ATTACHED state
-			 */
-			if ((port->sm_vars & AD_PORT_READY)
-			    && !port->sm_mux_timer_counter)
-				port->sm_mux_state = AD_MUX_ATTACHED;
-			break;
-		case AD_MUX_ATTACHED:
-			/* check also if agg_select_timer expired (so the
-			 * edable port will take place only after this timer)
-			 */
-			if ((port->sm_vars & AD_PORT_SELECTED) &&
-			    (port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) &&
-			    !__check_agg_selection_timer(port)) {
-				if (port->aggregator->is_active)
-					port->sm_mux_state =
-					    AD_MUX_COLLECTING_DISTRIBUTING;
-			} else if (!(port->sm_vars & AD_PORT_SELECTED) ||
-				   (port->sm_vars & AD_PORT_STANDBY)) {
-				/* if UNSELECTED or STANDBY */
-				port->sm_vars &= ~AD_PORT_READY_N;
-				/* in order to withhold the selection logic to
-				 * check all ports READY_N value every callback
-				 * cycle to update ready variable, we check
-				 * READY_N and update READY here
-				 */
-				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-				port->sm_mux_state = AD_MUX_DETACHED;
-			} else if (port->aggregator->is_active) {
-				port->actor_oper_port_state |=
-				    AD_STATE_SYNCHRONIZATION;
-			}
-			break;
-		case AD_MUX_COLLECTING_DISTRIBUTING:
-			if (!(port->sm_vars & AD_PORT_SELECTED) ||
-			    (port->sm_vars & AD_PORT_STANDBY) ||
-			    !(port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) ||
-			    !(port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION)) {
-				port->sm_mux_state = AD_MUX_ATTACHED;
-			} else {
-				/* if port state hasn't changed make
-				 * sure that a collecting distributing
-				 * port in an active aggregator is enabled
-				 */
-				if (port->aggregator &&
-				    port->aggregator->is_active &&
-				    !__port_is_enabled(port)) {
-
-					__enable_port(port);
-				}
-			}
-			break;
-		default:
-			break;
-		}
-	}
-
-	/* check if the state machine was changed */
-	if (port->sm_mux_state != last_state) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Mux Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number,
-			  last_state,
-			  port->sm_mux_state);
-		switch (port->sm_mux_state) {
-		case AD_MUX_DETACHED:
-			port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
-			ad_disable_collecting_distributing(port,
-							   update_slave_arr);
-			port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
-			port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
-			port->ntt = true;
-			break;
-		case AD_MUX_WAITING:
-			port->sm_mux_timer_counter = __ad_timer_to_ticks(AD_WAIT_WHILE_TIMER, 0);
-			break;
-		case AD_MUX_ATTACHED:
-			if (port->aggregator->is_active)
-				port->actor_oper_port_state |=
-				    AD_STATE_SYNCHRONIZATION;
-			else
-				port->actor_oper_port_state &=
-				    ~AD_STATE_SYNCHRONIZATION;
-			port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
-			port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
-			ad_disable_collecting_distributing(port,
-							   update_slave_arr);
-			port->ntt = true;
-			break;
-		case AD_MUX_COLLECTING_DISTRIBUTING:
-			port->actor_oper_port_state |= AD_STATE_COLLECTING;
-			port->actor_oper_port_state |= AD_STATE_DISTRIBUTING;
-			port->actor_oper_port_state |= AD_STATE_SYNCHRONIZATION;
-			ad_enable_collecting_distributing(port,
-							  update_slave_arr);
-			port->ntt = true;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_rx_machine - handle a port's rx State Machine
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * If lacpdu arrived, stop previous timer (if exists) and set the next state as
- * CURRENT. If timer expired set the state machine in the proper state.
- * In other cases, this function checks if we need to switch to other state.
- */
-static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port)
-{
-	rx_states_t last_state;
-
-	/* keep current State Machine state to compare later if it was
-	 * changed
-	 */
-	last_state = port->sm_rx_state;
-
-	if (lacpdu) {
-		atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.lacpdu_rx);
-		atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.lacpdu_rx);
-	}
-	/* check if state machine should change state */
-
-	/* first, check if port was reinitialized */
-	if (port->sm_vars & AD_PORT_BEGIN) {
-		port->sm_rx_state = AD_RX_INITIALIZE;
-		port->sm_vars |= AD_PORT_CHURNED;
-	/* check if port is not enabled */
-	} else if (!(port->sm_vars & AD_PORT_BEGIN) && !port->is_enabled)
-		port->sm_rx_state = AD_RX_PORT_DISABLED;
-	/* check if new lacpdu arrived */
-	else if (lacpdu && ((port->sm_rx_state == AD_RX_EXPIRED) ||
-		 (port->sm_rx_state == AD_RX_DEFAULTED) ||
-		 (port->sm_rx_state == AD_RX_CURRENT))) {
-		if (port->sm_rx_state != AD_RX_CURRENT)
-			port->sm_vars |= AD_PORT_CHURNED;
-		port->sm_rx_timer_counter = 0;
-		port->sm_rx_state = AD_RX_CURRENT;
-	} else {
-		/* if timer is on, and if it is expired */
-		if (port->sm_rx_timer_counter &&
-		    !(--port->sm_rx_timer_counter)) {
-			switch (port->sm_rx_state) {
-			case AD_RX_EXPIRED:
-				port->sm_rx_state = AD_RX_DEFAULTED;
-				break;
-			case AD_RX_CURRENT:
-				port->sm_rx_state = AD_RX_EXPIRED;
-				break;
-			default:
-				break;
-			}
-		} else {
-			/* if no lacpdu arrived and no timer is on */
-			switch (port->sm_rx_state) {
-			case AD_RX_PORT_DISABLED:
-				if (port->is_enabled &&
-				    (port->sm_vars & AD_PORT_LACP_ENABLED))
-					port->sm_rx_state = AD_RX_EXPIRED;
-				else if (port->is_enabled
-					 && ((port->sm_vars
-					      & AD_PORT_LACP_ENABLED) == 0))
-					port->sm_rx_state = AD_RX_LACP_DISABLED;
-				break;
-			default:
-				break;
-
-			}
-		}
-	}
-
-	/* check if the State machine was changed or new lacpdu arrived */
-	if ((port->sm_rx_state != last_state) || (lacpdu)) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Rx Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number,
-			  last_state,
-			  port->sm_rx_state);
-		switch (port->sm_rx_state) {
-		case AD_RX_INITIALIZE:
-			if (!(port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS))
-				port->sm_vars &= ~AD_PORT_LACP_ENABLED;
-			else
-				port->sm_vars |= AD_PORT_LACP_ENABLED;
-			port->sm_vars &= ~AD_PORT_SELECTED;
-			__record_default(port);
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			port->sm_rx_state = AD_RX_PORT_DISABLED;
-
-			/* Fall Through */
-		case AD_RX_PORT_DISABLED:
-			port->sm_vars &= ~AD_PORT_MATCHED;
-			break;
-		case AD_RX_LACP_DISABLED:
-			port->sm_vars &= ~AD_PORT_SELECTED;
-			__record_default(port);
-			port->partner_oper.port_state &= ~AD_STATE_AGGREGATION;
-			port->sm_vars |= AD_PORT_MATCHED;
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			break;
-		case AD_RX_EXPIRED:
-			/* Reset of the Synchronization flag (Standard 43.4.12)
-			 * This reset cause to disable this port in the
-			 * COLLECTING_DISTRIBUTING state of the mux machine in
-			 * case of EXPIRED even if LINK_DOWN didn't arrive for
-			 * the port.
-			 */
-			port->partner_oper.port_state &= ~AD_STATE_SYNCHRONIZATION;
-			port->sm_vars &= ~AD_PORT_MATCHED;
-			port->partner_oper.port_state |= AD_STATE_LACP_TIMEOUT;
-			port->partner_oper.port_state |= AD_STATE_LACP_ACTIVITY;
-			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(AD_SHORT_TIMEOUT));
-			port->actor_oper_port_state |= AD_STATE_EXPIRED;
-			port->sm_vars |= AD_PORT_CHURNED;
-			break;
-		case AD_RX_DEFAULTED:
-			__update_default_selected(port);
-			__record_default(port);
-			port->sm_vars |= AD_PORT_MATCHED;
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			break;
-		case AD_RX_CURRENT:
-			/* detect loopback situation */
-			if (MAC_ADDRESS_EQUAL(&(lacpdu->actor_system),
-					      &(port->actor_system))) {
-				slave_err(port->slave->bond->dev, port->slave->dev, "An illegal loopback occurred on slave\n"
-					  "Check the configuration to verify that all adapters are connected to 802.3ad compliant switch ports\n");
-				return;
-			}
-			__update_selected(lacpdu, port);
-			__update_ntt(lacpdu, port);
-			__record_pdu(lacpdu, port);
-			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(port->actor_oper_port_state & AD_STATE_LACP_TIMEOUT));
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_churn_machine - handle port churn's state machine
- * @port: the port we're looking at
- *
- */
-static void ad_churn_machine(struct port *port)
-{
-	if (port->sm_vars & AD_PORT_CHURNED) {
-		port->sm_vars &= ~AD_PORT_CHURNED;
-		port->sm_churn_actor_state = AD_CHURN_MONITOR;
-		port->sm_churn_partner_state = AD_CHURN_MONITOR;
-		port->sm_churn_actor_timer_counter =
-			__ad_timer_to_ticks(AD_ACTOR_CHURN_TIMER, 0);
-		port->sm_churn_partner_timer_counter =
-			 __ad_timer_to_ticks(AD_PARTNER_CHURN_TIMER, 0);
-		return;
-	}
-	if (port->sm_churn_actor_timer_counter &&
-	    !(--port->sm_churn_actor_timer_counter) &&
-	    port->sm_churn_actor_state == AD_CHURN_MONITOR) {
-		if (port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION) {
-			port->sm_churn_actor_state = AD_NO_CHURN;
-		} else {
-			port->churn_actor_count++;
-			port->sm_churn_actor_state = AD_CHURN;
-		}
-	}
-	if (port->sm_churn_partner_timer_counter &&
-	    !(--port->sm_churn_partner_timer_counter) &&
-	    port->sm_churn_partner_state == AD_CHURN_MONITOR) {
-		if (port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) {
-			port->sm_churn_partner_state = AD_NO_CHURN;
-		} else {
-			port->churn_partner_count++;
-			port->sm_churn_partner_state = AD_CHURN;
-		}
-	}
-}
-
-/**
- * ad_tx_machine - handle a port's tx state machine
- * @port: the port we're looking at
- */
-static void ad_tx_machine(struct port *port)
-{
-	/* check if tx timer expired, to verify that we do not send more than
-	 * 3 packets per second
-	 */
-	if (port->sm_tx_timer_counter && !(--port->sm_tx_timer_counter)) {
-		/* check if there is something to send */
-		if (port->ntt && (port->sm_vars & AD_PORT_LACP_ENABLED)) {
-			__update_lacpdu_from_port(port);
-
-			if (ad_lacpdu_send(port) >= 0) {
-				slave_dbg(port->slave->bond->dev,
-					  port->slave->dev,
-					  "Sent LACPDU on port %d\n",
-					  port->actor_port_number);
-
-				/* mark ntt as false, so it will not be sent
-				 * again until demanded
-				 */
-				port->ntt = false;
-			}
-		}
-		/* restart tx timer(to verify that we will not exceed
-		 * AD_MAX_TX_IN_SECOND
-		 */
-		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
-	}
-}
-
-/**
- * ad_periodic_machine - handle a port's periodic state machine
- * @port: the port we're looking at
- *
- * Turn ntt flag on priodically to perform periodic transmission of lacpdu's.
- */
-static void ad_periodic_machine(struct port *port)
-{
-	periodic_states_t last_state;
-
-	/* keep current state machine state to compare later if it was changed */
-	last_state = port->sm_periodic_state;
-
-	/* check if port was reinitialized */
-	if (((port->sm_vars & AD_PORT_BEGIN) || !(port->sm_vars & AD_PORT_LACP_ENABLED) || !port->is_enabled) ||
-	    (!(port->actor_oper_port_state & AD_STATE_LACP_ACTIVITY) && !(port->partner_oper.port_state & AD_STATE_LACP_ACTIVITY))
-	   ) {
-		port->sm_periodic_state = AD_NO_PERIODIC;
-	}
-	/* check if state machine should change state */
-	else if (port->sm_periodic_timer_counter) {
-		/* check if periodic state machine expired */
-		if (!(--port->sm_periodic_timer_counter)) {
-			/* if expired then do tx */
-			port->sm_periodic_state = AD_PERIODIC_TX;
-		} else {
-			/* If not expired, check if there is some new timeout
-			 * parameter from the partner state
-			 */
-			switch (port->sm_periodic_state) {
-			case AD_FAST_PERIODIC:
-				if (!(port->partner_oper.port_state
-				      & AD_STATE_LACP_TIMEOUT))
-					port->sm_periodic_state = AD_SLOW_PERIODIC;
-				break;
-			case AD_SLOW_PERIODIC:
-				if ((port->partner_oper.port_state & AD_STATE_LACP_TIMEOUT)) {
-					port->sm_periodic_timer_counter = 0;
-					port->sm_periodic_state = AD_PERIODIC_TX;
-				}
-				break;
-			default:
-				break;
-			}
-		}
-	} else {
-		switch (port->sm_periodic_state) {
-		case AD_NO_PERIODIC:
-			port->sm_periodic_state = AD_FAST_PERIODIC;
-			break;
-		case AD_PERIODIC_TX:
-			if (!(port->partner_oper.port_state &
-			    AD_STATE_LACP_TIMEOUT))
-				port->sm_periodic_state = AD_SLOW_PERIODIC;
-			else
-				port->sm_periodic_state = AD_FAST_PERIODIC;
-			break;
-		default:
-			break;
-		}
-	}
-
-	/* check if the state machine was changed */
-	if (port->sm_periodic_state != last_state) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Periodic Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number, last_state,
-			  port->sm_periodic_state);
-		switch (port->sm_periodic_state) {
-		case AD_NO_PERIODIC:
-			port->sm_periodic_timer_counter = 0;
-			break;
-		case AD_FAST_PERIODIC:
-			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
-			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_FAST_PERIODIC_TIME))-1;
-			break;
-		case AD_SLOW_PERIODIC:
-			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
-			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_SLOW_PERIODIC_TIME))-1;
-			break;
-		case AD_PERIODIC_TX:
-			port->ntt = true;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_port_selection_logic - select aggregation groups
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * Select aggregation groups, and assign each port for it's aggregetor. The
- * selection logic is called in the inititalization (after all the handshkes),
- * and after every lacpdu receive (if selected is off).
- */
-static void ad_port_selection_logic(struct port *port, bool *update_slave_arr)
-{
-	struct aggregator *aggregator, *free_aggregator = NULL, *temp_aggregator;
-	struct port *last_port = NULL, *curr_port;
-	struct list_head *iter;
-	struct bonding *bond;
-	struct slave *slave;
-	int found = 0;
-
-	/* if the port is already Selected, do nothing */
-	if (port->sm_vars & AD_PORT_SELECTED)
-		return;
-
-	bond = __get_bond_by_port(port);
-
-	/* if the port is connected to other aggregator, detach it */
-	if (port->aggregator) {
-		/* detach the port from its former aggregator */
-		temp_aggregator = port->aggregator;
-		for (curr_port = temp_aggregator->lag_ports; curr_port;
-		     last_port = curr_port,
-		     curr_port = curr_port->next_port_in_aggregator) {
-			if (curr_port == port) {
-				temp_aggregator->num_of_ports--;
-				/* if it is the first port attached to the
-				 * aggregator
-				 */
-				if (!last_port) {
-					temp_aggregator->lag_ports =
-						port->next_port_in_aggregator;
-				} else {
-					/* not the first port attached to the
-					 * aggregator
-					 */
-					last_port->next_port_in_aggregator =
-						port->next_port_in_aggregator;
-				}
-
-				/* clear the port's relations to this
-				 * aggregator
-				 */
-				port->aggregator = NULL;
-				port->next_port_in_aggregator = NULL;
-				port->actor_port_aggregator_identifier = 0;
-
-				slave_dbg(bond->dev, port->slave->dev, "Port %d left LAG %d\n",
-					  port->actor_port_number,
-					  temp_aggregator->aggregator_identifier);
-				/* if the aggregator is empty, clear its
-				 * parameters, and set it ready to be attached
-				 */
-				if (!temp_aggregator->lag_ports)
-					ad_clear_agg(temp_aggregator);
-				break;
-			}
-		}
-		if (!curr_port) {
-			/* meaning: the port was related to an aggregator
-			 * but was not on the aggregator port list
-			 */
-			net_warn_ratelimited("%s: (slave %s): Warning: Port %d was related to aggregator %d but was not on its port list\n",
-					     port->slave->bond->dev->name,
-					     port->slave->dev->name,
-					     port->actor_port_number,
-					     port->aggregator->aggregator_identifier);
-		}
-	}
-	/* search on all aggregators for a suitable aggregator for this port */
-	bond_for_each_slave(bond, slave, iter) {
-		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		/* keep a free aggregator for later use(if needed) */
-		if (!aggregator->lag_ports) {
-			if (!free_aggregator)
-				free_aggregator = aggregator;
-			continue;
-		}
-		/* check if current aggregator suits us */
-		if (((aggregator->actor_oper_aggregator_key == port->actor_oper_port_key) && /* if all parameters match AND */
-		     MAC_ADDRESS_EQUAL(&(aggregator->partner_system), &(port->partner_oper.system)) &&
-		     (aggregator->partner_system_priority == port->partner_oper.system_priority) &&
-		     (aggregator->partner_oper_aggregator_key == port->partner_oper.key)
-		    ) &&
-		    ((!MAC_ADDRESS_EQUAL(&(port->partner_oper.system), &(null_mac_addr)) && /* partner answers */
-		      !aggregator->is_individual)  /* but is not individual OR */
-		    )
-		   ) {
-			/* attach to the founded aggregator */
-			port->aggregator = aggregator;
-			port->actor_port_aggregator_identifier =
-				port->aggregator->aggregator_identifier;
-			port->next_port_in_aggregator = aggregator->lag_ports;
-			port->aggregator->num_of_ports++;
-			aggregator->lag_ports = port;
-			slave_dbg(bond->dev, slave->dev, "Port %d joined LAG %d (existing LAG)\n",
-				  port->actor_port_number,
-				  port->aggregator->aggregator_identifier);
-
-			/* mark this port as selected */
-			port->sm_vars |= AD_PORT_SELECTED;
-			found = 1;
-			break;
-		}
-	}
-
-	/* the port couldn't find an aggregator - attach it to a new
-	 * aggregator
-	 */
-	if (!found) {
-		if (free_aggregator) {
-			/* assign port a new aggregator */
-			port->aggregator = free_aggregator;
-			port->actor_port_aggregator_identifier =
-				port->aggregator->aggregator_identifier;
-
-			/* update the new aggregator's parameters
-			 * if port was responsed from the end-user
-			 */
-			if (port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS)
-				/* if port is full duplex */
-				port->aggregator->is_individual = false;
-			else
-				port->aggregator->is_individual = true;
-
-			port->aggregator->actor_admin_aggregator_key =
-				port->actor_admin_port_key;
-			port->aggregator->actor_oper_aggregator_key =
-				port->actor_oper_port_key;
-			port->aggregator->partner_system =
-				port->partner_oper.system;
-			port->aggregator->partner_system_priority =
-				port->partner_oper.system_priority;
-			port->aggregator->partner_oper_aggregator_key = port->partner_oper.key;
-			port->aggregator->receive_state = 1;
-			port->aggregator->transmit_state = 1;
-			port->aggregator->lag_ports = port;
-			port->aggregator->num_of_ports++;
-
-			/* mark this port as selected */
-			port->sm_vars |= AD_PORT_SELECTED;
-
-			slave_dbg(bond->dev, port->slave->dev, "Port %d joined LAG %d (new LAG)\n",
-				  port->actor_port_number,
-				  port->aggregator->aggregator_identifier);
-		} else {
-			slave_err(bond->dev, port->slave->dev,
-				  "Port %d did not find a suitable aggregator\n",
-				  port->actor_port_number);
-		}
-	}
-	/* if all aggregator's ports are READY_N == TRUE, set ready=TRUE
-	 * in all aggregator's ports, else set ready=FALSE in all
-	 * aggregator's ports
-	 */
-	__set_agg_ports_ready(port->aggregator,
-			      __agg_ports_are_ready(port->aggregator));
-
-	aggregator = __get_first_agg(port);
-	ad_agg_selection_logic(aggregator, update_slave_arr);
-
-	if (!port->aggregator->is_active)
-		port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
-}
-
-/* Decide if "agg" is a better choice for the new active aggregator that
- * the current best, according to the ad_select policy.
- */
-static struct aggregator *ad_agg_selection_test(struct aggregator *best,
-						struct aggregator *curr)
-{
-	/* 0. If no best, select current.
-	 *
-	 * 1. If the current agg is not individual, and the best is
-	 *    individual, select current.
-	 *
-	 * 2. If current agg is individual and the best is not, keep best.
-	 *
-	 * 3. Therefore, current and best are both individual or both not
-	 *    individual, so:
-	 *
-	 * 3a. If current agg partner replied, and best agg partner did not,
-	 *     select current.
-	 *
-	 * 3b. If current agg partner did not reply and best agg partner
-	 *     did reply, keep best.
-	 *
-	 * 4.  Therefore, current and best both have partner replies or
-	 *     both do not, so perform selection policy:
-	 *
-	 * BOND_AD_COUNT: Select by count of ports.  If count is equal,
-	 *     select by bandwidth.
-	 *
-	 * BOND_AD_STABLE, BOND_AD_BANDWIDTH: Select by bandwidth.
-	 */
-	if (!best)
-		return curr;
-
-	if (!curr->is_individual && best->is_individual)
-		return curr;
-
-	if (curr->is_individual && !best->is_individual)
-		return best;
-
-	if (__agg_has_partner(curr) && !__agg_has_partner(best))
-		return curr;
-
-	if (!__agg_has_partner(curr) && __agg_has_partner(best))
-		return best;
-
-	switch (__get_agg_selection_mode(curr->lag_ports)) {
-	case BOND_AD_COUNT:
-		if (__agg_active_ports(curr) > __agg_active_ports(best))
-			return curr;
-
-		if (__agg_active_ports(curr) < __agg_active_ports(best))
-			return best;
-
-		/*FALLTHROUGH*/
-	case BOND_AD_STABLE:
-	case BOND_AD_BANDWIDTH:
-		if (__get_agg_bandwidth(curr) > __get_agg_bandwidth(best))
-			return curr;
-
-		break;
-
-	default:
-		net_warn_ratelimited("%s: (slave %s): Impossible agg select mode %d\n",
-				     curr->slave->bond->dev->name,
-				     curr->slave->dev->name,
-				     __get_agg_selection_mode(curr->lag_ports));
-		break;
-	}
-
-	return best;
-}
-
-static int agg_device_up(const struct aggregator *agg)
-{
-	struct port *port = agg->lag_ports;
-
-	if (!port)
-		return 0;
-
-	for (port = agg->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (netif_running(port->slave->dev) &&
-		    netif_carrier_ok(port->slave->dev))
-			return 1;
-	}
-
-	return 0;
-}
-
-/**
- * ad_agg_selection_logic - select an aggregation group for a team
- * @aggregator: the aggregator we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * It is assumed that only one aggregator may be selected for a team.
- *
- * The logic of this function is to select the aggregator according to
- * the ad_select policy:
- *
- * BOND_AD_STABLE: select the aggregator with the most ports attached to
- * it, and to reselect the active aggregator only if the previous
- * aggregator has no more ports related to it.
- *
- * BOND_AD_BANDWIDTH: select the aggregator with the highest total
- * bandwidth, and reselect whenever a link state change takes place or the
- * set of slaves in the bond changes.
- *
- * BOND_AD_COUNT: select the aggregator with largest number of ports
- * (slaves), and reselect whenever a link state change takes place or the
- * set of slaves in the bond changes.
- *
- * FIXME: this function MUST be called with the first agg in the bond, or
- * __get_active_agg() won't work correctly. This function should be better
- * called with the bond itself, and retrieve the first agg from it.
- */
-static void ad_agg_selection_logic(struct aggregator *agg,
-				   bool *update_slave_arr)
-{
-	struct aggregator *best, *active, *origin;
-	struct bonding *bond = agg->slave->bond;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-
-	rcu_read_lock();
-	origin = agg;
-	active = __get_active_agg(agg);
-	best = (active && agg_device_up(active)) ? active : NULL;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		agg = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		agg->is_active = 0;
-
-		if (__agg_active_ports(agg) && agg_device_up(agg))
-			best = ad_agg_selection_test(best, agg);
-	}
-
-	if (best &&
-	    __get_agg_selection_mode(best->lag_ports) == BOND_AD_STABLE) {
-		/* For the STABLE policy, don't replace the old active
-		 * aggregator if it's still active (it has an answering
-		 * partner) or if both the best and active don't have an
-		 * answering partner.
-		 */
-		if (active && active->lag_ports &&
-		    __agg_active_ports(active) &&
-		    (__agg_has_partner(active) ||
-		     (!__agg_has_partner(active) &&
-		     !__agg_has_partner(best)))) {
-			if (!(!active->actor_oper_aggregator_key &&
-			      best->actor_oper_aggregator_key)) {
-				best = NULL;
-				active->is_active = 1;
-			}
-		}
-	}
-
-	if (best && (best == active)) {
-		best = NULL;
-		active->is_active = 1;
-	}
-
-	/* if there is new best aggregator, activate it */
-	if (best) {
-		netdev_dbg(bond->dev, "(slave %s): best Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier, best->num_of_ports,
-			   best->actor_oper_aggregator_key,
-			   best->partner_oper_aggregator_key,
-			   best->is_individual, best->is_active);
-		netdev_dbg(bond->dev, "(slave %s): best ports %p slave %p\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->lag_ports, best->slave);
-
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			agg = &(SLAVE_AD_INFO(slave)->aggregator);
-
-			slave_dbg(bond->dev, slave->dev, "Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-				  agg->aggregator_identifier, agg->num_of_ports,
-				  agg->actor_oper_aggregator_key,
-				  agg->partner_oper_aggregator_key,
-				  agg->is_individual, agg->is_active);
-		}
-
-		/* check if any partner replies */
-		if (best->is_individual)
-			net_warn_ratelimited("%s: Warning: No 802.3ad response from the link partner for any adapters in the bond\n",
-					     bond->dev->name);
-
-		best->is_active = 1;
-		netdev_dbg(bond->dev, "(slave %s): LAG %d chosen as the active LAG\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier);
-		netdev_dbg(bond->dev, "(slave %s): Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier, best->num_of_ports,
-			   best->actor_oper_aggregator_key,
-			   best->partner_oper_aggregator_key,
-			   best->is_individual, best->is_active);
-
-		/* disable the ports that were related to the former
-		 * active_aggregator
-		 */
-		if (active) {
-			for (port = active->lag_ports; port;
-			     port = port->next_port_in_aggregator) {
-				__disable_port(port);
-			}
-		}
-		/* Slave array needs update. */
-		*update_slave_arr = true;
-	}
-
-	/* if the selected aggregator is of join individuals
-	 * (partner_system is NULL), enable their ports
-	 */
-	active = __get_active_agg(origin);
-
-	if (active) {
-		if (!__agg_has_partner(active)) {
-			for (port = active->lag_ports; port;
-			     port = port->next_port_in_aggregator) {
-				__enable_port(port);
-			}
-		}
-	}
-
-	rcu_read_unlock();
-
-	bond_3ad_set_carrier(bond);
-}
-
-/**
- * ad_clear_agg - clear a given aggregator's parameters
- * @aggregator: the aggregator we're looking at
- */
-static void ad_clear_agg(struct aggregator *aggregator)
-{
-	if (aggregator) {
-		aggregator->is_individual = false;
-		aggregator->actor_admin_aggregator_key = 0;
-		aggregator->actor_oper_aggregator_key = 0;
-		eth_zero_addr(aggregator->partner_system.mac_addr_value);
-		aggregator->partner_system_priority = 0;
-		aggregator->partner_oper_aggregator_key = 0;
-		aggregator->receive_state = 0;
-		aggregator->transmit_state = 0;
-		aggregator->lag_ports = NULL;
-		aggregator->is_active = 0;
-		aggregator->num_of_ports = 0;
-		pr_debug("%s: LAG %d was cleared\n",
-			 aggregator->slave ?
-			 aggregator->slave->dev->name : "NULL",
-			 aggregator->aggregator_identifier);
-	}
-}
-
-/**
- * ad_initialize_agg - initialize a given aggregator's parameters
- * @aggregator: the aggregator we're looking at
- */
-static void ad_initialize_agg(struct aggregator *aggregator)
-{
-	if (aggregator) {
-		ad_clear_agg(aggregator);
-
-		eth_zero_addr(aggregator->aggregator_mac_address.mac_addr_value);
-		aggregator->aggregator_identifier = 0;
-		aggregator->slave = NULL;
-	}
-}
-
-/**
- * ad_initialize_port - initialize a given port's parameters
- * @aggregator: the aggregator we're looking at
- * @lacp_fast: boolean. whether fast periodic should be used
- */
-static void ad_initialize_port(struct port *port, int lacp_fast)
-{
-	static const struct port_params tmpl = {
-		.system_priority = 0xffff,
-		.key             = 1,
-		.port_number     = 1,
-		.port_priority   = 0xff,
-		.port_state      = 1,
-	};
-	static const struct lacpdu lacpdu = {
-		.subtype		= 0x01,
-		.version_number = 0x01,
-		.tlv_type_actor_info = 0x01,
-		.actor_information_length = 0x14,
-		.tlv_type_partner_info = 0x02,
-		.partner_information_length = 0x14,
-		.tlv_type_collector_info = 0x03,
-		.collector_information_length = 0x10,
-		.collector_max_delay = htons(AD_COLLECTOR_MAX_DELAY),
-	};
-
-	if (port) {
-		port->actor_port_priority = 0xff;
-		port->actor_port_aggregator_identifier = 0;
-		port->ntt = false;
-		port->actor_admin_port_state = AD_STATE_AGGREGATION |
-					       AD_STATE_LACP_ACTIVITY;
-		port->actor_oper_port_state  = AD_STATE_AGGREGATION |
-					       AD_STATE_LACP_ACTIVITY;
-
-		if (lacp_fast)
-			port->actor_oper_port_state |= AD_STATE_LACP_TIMEOUT;
-
-		memcpy(&port->partner_admin, &tmpl, sizeof(tmpl));
-		memcpy(&port->partner_oper, &tmpl, sizeof(tmpl));
-
-		port->is_enabled = true;
-		/* private parameters */
-		port->sm_vars = AD_PORT_BEGIN | AD_PORT_LACP_ENABLED;
-		port->sm_rx_state = 0;
-		port->sm_rx_timer_counter = 0;
-		port->sm_periodic_state = 0;
-		port->sm_periodic_timer_counter = 0;
-		port->sm_mux_state = 0;
-		port->sm_mux_timer_counter = 0;
-		port->sm_tx_state = 0;
-		port->aggregator = NULL;
-		port->next_port_in_aggregator = NULL;
-		port->transaction_id = 0;
-
-		port->sm_churn_actor_timer_counter = 0;
-		port->sm_churn_actor_state = 0;
-		port->churn_actor_count = 0;
-		port->sm_churn_partner_timer_counter = 0;
-		port->sm_churn_partner_state = 0;
-		port->churn_partner_count = 0;
-
-		memcpy(&port->lacpdu, &lacpdu, sizeof(lacpdu));
-	}
-}
-
-/**
- * ad_enable_collecting_distributing - enable a port's transmit/receive
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * Enable @port if it's in an active aggregator
- */
-static void ad_enable_collecting_distributing(struct port *port,
-					      bool *update_slave_arr)
-{
-	if (port->aggregator->is_active) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Enabling port %d (LAG %d)\n",
-			  port->actor_port_number,
-			  port->aggregator->aggregator_identifier);
-		__enable_port(port);
-		/* Slave array needs update */
-		*update_slave_arr = true;
-	}
-}
-
-/**
- * ad_disable_collecting_distributing - disable a port's transmit/receive
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- */
-static void ad_disable_collecting_distributing(struct port *port,
-					       bool *update_slave_arr)
-{
-	if (port->aggregator &&
-	    !MAC_ADDRESS_EQUAL(&(port->aggregator->partner_system),
-			       &(null_mac_addr))) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Disabling port %d (LAG %d)\n",
-			  port->actor_port_number,
-			  port->aggregator->aggregator_identifier);
-		__disable_port(port);
-		/* Slave array needs an update */
-		*update_slave_arr = true;
-	}
-}
-
-/**
- * ad_marker_info_received - handle receive of a Marker information frame
- * @marker_info: Marker info received
- * @port: the port we're looking at
- */
-static void ad_marker_info_received(struct bond_marker *marker_info,
-				    struct port *port)
-{
-	struct bond_marker marker;
-
-	atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.marker_rx);
-	atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.marker_rx);
-
-	/* copy the received marker data to the response marker */
-	memcpy(&marker, marker_info, sizeof(struct bond_marker));
-	/* change the marker subtype to marker response */
-	marker.tlv_type = AD_MARKER_RESPONSE_SUBTYPE;
-
-	/* send the marker response */
-	if (ad_marker_send(port, &marker) >= 0)
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Sent Marker Response on port %d\n",
-			  port->actor_port_number);
-}
-
-/**
- * ad_marker_response_received - handle receive of a marker response frame
- * @marker: marker PDU received
- * @port: the port we're looking at
- *
- * This function does nothing since we decided not to implement send and handle
- * response for marker PDU's, in this stage, but only to respond to marker
- * information.
- */
-static void ad_marker_response_received(struct bond_marker *marker,
-					struct port *port)
-{
-	atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.marker_resp_rx);
-	atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.marker_resp_rx);
-
-	/* DO NOTHING, SINCE WE DECIDED NOT TO IMPLEMENT THIS FEATURE FOR NOW */
-}
-
-/* ========= AD exported functions to the main bonding code ========= */
-
-/* Check aggregators status in team every T seconds */
-#define AD_AGGREGATOR_SELECTION_TIMER  8
-
-/**
- * bond_3ad_initiate_agg_selection - initate aggregator selection
- * @bond: bonding struct
- *
- * Set the aggregation selection timer, to initiate an agg selection in
- * the very near future.  Called during first initialization, and during
- * any down to up transitions of the bond.
- */
-void bond_3ad_initiate_agg_selection(struct bonding *bond, int timeout)
-{
-	BOND_AD_INFO(bond).agg_select_timer = timeout;
-}
-
-/**
- * bond_3ad_initialize - initialize a bond's 802.3ad parameters and structures
- * @bond: bonding struct to work on
- * @tick_resolution: tick duration (millisecond resolution)
- *
- * Can be called only after the mac address of the bond is set.
- */
-void bond_3ad_initialize(struct bonding *bond, u16 tick_resolution)
-{
-	/* check that the bond is not initialized yet */
-	if (!MAC_ADDRESS_EQUAL(&(BOND_AD_INFO(bond).system.sys_mac_addr),
-				bond->dev->dev_addr)) {
-
-		BOND_AD_INFO(bond).aggregator_identifier = 0;
-
-		BOND_AD_INFO(bond).system.sys_priority =
-			bond->params.ad_actor_sys_prio;
-		if (is_zero_ether_addr(bond->params.ad_actor_system))
-			BOND_AD_INFO(bond).system.sys_mac_addr =
-			    *((struct mac_addr *)bond->dev->dev_addr);
-		else
-			BOND_AD_INFO(bond).system.sys_mac_addr =
-			    *((struct mac_addr *)bond->params.ad_actor_system);
-
-		/* initialize how many times this module is called in one
-		 * second (should be about every 100ms)
-		 */
-		ad_ticks_per_sec = tick_resolution;
-
-		bond_3ad_initiate_agg_selection(bond,
-						AD_AGGREGATOR_SELECTION_TIMER *
-						ad_ticks_per_sec);
-	}
-}
-
-/**
- * bond_3ad_bind_slave - initialize a slave's port
- * @slave: slave struct to work on
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-void bond_3ad_bind_slave(struct slave *slave)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-	struct port *port;
-	struct aggregator *aggregator;
-
-	/* check that the slave has not been initialized yet. */
-	if (SLAVE_AD_INFO(slave)->port.slave != slave) {
-
-		/* port initialization */
-		port = &(SLAVE_AD_INFO(slave)->port);
-
-		ad_initialize_port(port, bond->params.lacp_fast);
-
-		port->slave = slave;
-		port->actor_port_number = SLAVE_AD_INFO(slave)->id;
-		/* key is determined according to the link speed, duplex and
-		 * user key
-		 */
-		port->actor_admin_port_key = bond->params.ad_user_port_key << 6;
-		ad_update_actor_keys(port, false);
-		/* actor system is the bond's system */
-		__ad_actor_update_port(port);
-		/* tx timer(to verify that no more than MAX_TX_IN_SECOND
-		 * lacpdu's are sent in one second)
-		 */
-		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
-
-		__disable_port(port);
-
-		/* aggregator initialization */
-		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		ad_initialize_agg(aggregator);
-
-		aggregator->aggregator_mac_address = *((struct mac_addr *)bond->dev->dev_addr);
-		aggregator->aggregator_identifier = ++BOND_AD_INFO(bond).aggregator_identifier;
-		aggregator->slave = slave;
-		aggregator->is_active = 0;
-		aggregator->num_of_ports = 0;
-	}
-}
-
-/**
- * bond_3ad_unbind_slave - deinitialize a slave's port
- * @slave: slave struct to work on
- *
- * Search for the aggregator that is related to this port, remove the
- * aggregator and assign another aggregator for other port related to it
- * (if any), and remove the port.
- */
-void bond_3ad_unbind_slave(struct slave *slave)
-{
-	struct port *port, *prev_port, *temp_port;
-	struct aggregator *aggregator, *new_aggregator, *temp_aggregator;
-	int select_new_active_agg = 0;
-	struct bonding *bond = slave->bond;
-	struct slave *slave_iter;
-	struct list_head *iter;
-	bool dummy_slave_update; /* Ignore this value as caller updates array */
-
-	/* Sync against bond_3ad_state_machine_handler() */
-	spin_lock_bh(&bond->mode_lock);
-	aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(bond->dev, slave->dev, "Trying to unbind an uninitialized port\n");
-		goto out;
-	}
-
-	slave_dbg(bond->dev, slave->dev, "Unbinding Link Aggregation Group %d\n",
-		  aggregator->aggregator_identifier);
-
-	/* Tell the partner that this port is not suitable for aggregation */
-	port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
-	port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
-	port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
-	port->actor_oper_port_state &= ~AD_STATE_AGGREGATION;
-	__update_lacpdu_from_port(port);
-	ad_lacpdu_send(port);
-
-	/* check if this aggregator is occupied */
-	if (aggregator->lag_ports) {
-		/* check if there are other ports related to this aggregator
-		 * except the port related to this slave(thats ensure us that
-		 * there is a reason to search for new aggregator, and that we
-		 * will find one
-		 */
-		if ((aggregator->lag_ports != port) ||
-		    (aggregator->lag_ports->next_port_in_aggregator)) {
-			/* find new aggregator for the related port(s) */
-			bond_for_each_slave(bond, slave_iter, iter) {
-				new_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
-				/* if the new aggregator is empty, or it is
-				 * connected to our port only
-				 */
-				if (!new_aggregator->lag_ports ||
-				    ((new_aggregator->lag_ports == port) &&
-				     !new_aggregator->lag_ports->next_port_in_aggregator))
-					break;
-			}
-			if (!slave_iter)
-				new_aggregator = NULL;
-
-			/* if new aggregator found, copy the aggregator's
-			 * parameters and connect the related lag_ports to the
-			 * new aggregator
-			 */
-			if ((new_aggregator) && ((!new_aggregator->lag_ports) || ((new_aggregator->lag_ports == port) && !new_aggregator->lag_ports->next_port_in_aggregator))) {
-				slave_dbg(bond->dev, slave->dev, "Some port(s) related to LAG %d - replacing with LAG %d\n",
-					  aggregator->aggregator_identifier,
-					  new_aggregator->aggregator_identifier);
-
-				if ((new_aggregator->lag_ports == port) &&
-				    new_aggregator->is_active) {
-					slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-					select_new_active_agg = 1;
-				}
-
-				new_aggregator->is_individual = aggregator->is_individual;
-				new_aggregator->actor_admin_aggregator_key = aggregator->actor_admin_aggregator_key;
-				new_aggregator->actor_oper_aggregator_key = aggregator->actor_oper_aggregator_key;
-				new_aggregator->partner_system = aggregator->partner_system;
-				new_aggregator->partner_system_priority = aggregator->partner_system_priority;
-				new_aggregator->partner_oper_aggregator_key = aggregator->partner_oper_aggregator_key;
-				new_aggregator->receive_state = aggregator->receive_state;
-				new_aggregator->transmit_state = aggregator->transmit_state;
-				new_aggregator->lag_ports = aggregator->lag_ports;
-				new_aggregator->is_active = aggregator->is_active;
-				new_aggregator->num_of_ports = aggregator->num_of_ports;
-
-				/* update the information that is written on
-				 * the ports about the aggregator
-				 */
-				for (temp_port = aggregator->lag_ports; temp_port;
-				     temp_port = temp_port->next_port_in_aggregator) {
-					temp_port->aggregator = new_aggregator;
-					temp_port->actor_port_aggregator_identifier = new_aggregator->aggregator_identifier;
-				}
-
-				ad_clear_agg(aggregator);
-
-				if (select_new_active_agg)
-					ad_agg_selection_logic(__get_first_agg(port),
-							       &dummy_slave_update);
-			} else {
-				slave_warn(bond->dev, slave->dev, "unbinding aggregator, and could not find a new aggregator for its ports\n");
-			}
-		} else {
-			/* in case that the only port related to this
-			 * aggregator is the one we want to remove
-			 */
-			select_new_active_agg = aggregator->is_active;
-			ad_clear_agg(aggregator);
-			if (select_new_active_agg) {
-				slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-				/* select new active aggregator */
-				temp_aggregator = __get_first_agg(port);
-				if (temp_aggregator)
-					ad_agg_selection_logic(temp_aggregator,
-							       &dummy_slave_update);
-			}
-		}
-	}
-
-	slave_dbg(bond->dev, slave->dev, "Unbinding port %d\n", port->actor_port_number);
-
-	/* find the aggregator that this port is connected to */
-	bond_for_each_slave(bond, slave_iter, iter) {
-		temp_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
-		prev_port = NULL;
-		/* search the port in the aggregator's related ports */
-		for (temp_port = temp_aggregator->lag_ports; temp_port;
-		     prev_port = temp_port,
-		     temp_port = temp_port->next_port_in_aggregator) {
-			if (temp_port == port) {
-				/* the aggregator found - detach the port from
-				 * this aggregator
-				 */
-				if (prev_port)
-					prev_port->next_port_in_aggregator = temp_port->next_port_in_aggregator;
-				else
-					temp_aggregator->lag_ports = temp_port->next_port_in_aggregator;
-				temp_aggregator->num_of_ports--;
-				if (__agg_active_ports(temp_aggregator) == 0) {
-					select_new_active_agg = temp_aggregator->is_active;
-					ad_clear_agg(temp_aggregator);
-					if (select_new_active_agg) {
-						slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-						/* select new active aggregator */
-						ad_agg_selection_logic(__get_first_agg(port),
-							               &dummy_slave_update);
-					}
-				}
-				break;
-			}
-		}
-	}
-	port->slave = NULL;
-
-out:
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/**
- * bond_3ad_update_ad_actor_settings - reflect change of actor settings to ports
- * @bond: bonding struct to work on
- *
- * If an ad_actor setting gets changed we need to update the individual port
- * settings so the bond device will use the new values when it gets upped.
- */
-void bond_3ad_update_ad_actor_settings(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	ASSERT_RTNL();
-
-	BOND_AD_INFO(bond).system.sys_priority = bond->params.ad_actor_sys_prio;
-	if (is_zero_ether_addr(bond->params.ad_actor_system))
-		BOND_AD_INFO(bond).system.sys_mac_addr =
-		    *((struct mac_addr *)bond->dev->dev_addr);
-	else
-		BOND_AD_INFO(bond).system.sys_mac_addr =
-		    *((struct mac_addr *)bond->params.ad_actor_system);
-
-	spin_lock_bh(&bond->mode_lock);
-	bond_for_each_slave(bond, slave, iter) {
-		struct port *port = &(SLAVE_AD_INFO(slave))->port;
-
-		__ad_actor_update_port(port);
-		port->ntt = true;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/**
- * bond_3ad_state_machine_handler - handle state machines timeout
- * @bond: bonding struct to work on
- *
- * The state machine handling concept in this module is to check every tick
- * which state machine should operate any function. The execution order is
- * round robin, so when we have an interaction between state machines, the
- * reply of one to each other might be delayed until next tick.
- *
- * This function also complete the initialization when the agg_select_timer
- * times out, and it selects an aggregator for the ports that are yet not
- * related to any aggregator, and selects the active aggregator for a bond.
- */
-void bond_3ad_state_machine_handler(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    ad_work.work);
-	struct aggregator *aggregator;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
-	bool update_slave_arr = false;
-
-	/* Lock to protect data accessed by all (e.g., port->sm_vars) and
-	 * against running with bond_3ad_unbind_slave. ad_rx_machine may run
-	 * concurrently due to incoming LACPDU as well.
-	 */
-	spin_lock_bh(&bond->mode_lock);
-	rcu_read_lock();
-
-	/* check if there are any slaves */
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	/* check if agg_select_timer timer after initialize is timed out */
-	if (BOND_AD_INFO(bond).agg_select_timer &&
-	    !(--BOND_AD_INFO(bond).agg_select_timer)) {
-		slave = bond_first_slave_rcu(bond);
-		port = slave ? &(SLAVE_AD_INFO(slave)->port) : NULL;
-
-		/* select the active aggregator for the bond */
-		if (port) {
-			if (!port->slave) {
-				net_warn_ratelimited("%s: Warning: bond's first port is uninitialized\n",
-						     bond->dev->name);
-				goto re_arm;
-			}
-
-			aggregator = __get_first_agg(port);
-			ad_agg_selection_logic(aggregator, &update_slave_arr);
-		}
-		bond_3ad_set_carrier(bond);
-	}
-
-	/* for each port run the state machines */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (!port->slave) {
-			net_warn_ratelimited("%s: Warning: Found an uninitialized port\n",
-					    bond->dev->name);
-			goto re_arm;
-		}
-
-		ad_rx_machine(NULL, port);
-		ad_periodic_machine(port);
-		ad_port_selection_logic(port, &update_slave_arr);
-		ad_mux_machine(port, &update_slave_arr);
-		ad_tx_machine(port);
-		ad_churn_machine(port);
-
-		/* turn off the BEGIN bit, since we already handled it */
-		if (port->sm_vars & AD_PORT_BEGIN)
-			port->sm_vars &= ~AD_PORT_BEGIN;
-	}
-
-re_arm:
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->should_notify) {
-			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
-			break;
-		}
-	}
-	rcu_read_unlock();
-	spin_unlock_bh(&bond->mode_lock);
-
-	if (update_slave_arr)
-		bond_slave_arr_work_rearm(bond, 0);
-
-	if (should_notify_rtnl && rtnl_trylock()) {
-		bond_slave_state_notify(bond);
-		rtnl_unlock();
-	}
-	queue_delayed_work(bond->wq, &bond->ad_work, ad_delta_in_ticks);
-}
-
-/**
- * bond_3ad_rx_indication - handle a received frame
- * @lacpdu: received lacpdu
- * @slave: slave struct to work on
- *
- * It is assumed that frames that were sent on this NIC don't returned as new
- * received frames (loopback). Since only the payload is given to this
- * function, it check for loopback.
- */
-static int bond_3ad_rx_indication(struct lacpdu *lacpdu, struct slave *slave)
-{
-	struct bonding *bond = slave->bond;
-	int ret = RX_HANDLER_ANOTHER;
-	struct bond_marker *marker;
-	struct port *port;
-	atomic64_t *stat;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-	if (!port->slave) {
-		net_warn_ratelimited("%s: Warning: port of slave %s is uninitialized\n",
-				     slave->dev->name, slave->bond->dev->name);
-		return ret;
-	}
-
-	switch (lacpdu->subtype) {
-	case AD_TYPE_LACPDU:
-		ret = RX_HANDLER_CONSUMED;
-		slave_dbg(slave->bond->dev, slave->dev,
-			  "Received LACPDU on port %d\n",
-			  port->actor_port_number);
-		/* Protect against concurrent state machines */
-		spin_lock(&slave->bond->mode_lock);
-		ad_rx_machine(lacpdu, port);
-		spin_unlock(&slave->bond->mode_lock);
-		break;
-	case AD_TYPE_MARKER:
-		ret = RX_HANDLER_CONSUMED;
-		/* No need to convert fields to Little Endian since we
-		 * don't use the marker's fields.
-		 */
-		marker = (struct bond_marker *)lacpdu;
-		switch (marker->tlv_type) {
-		case AD_MARKER_INFORMATION_SUBTYPE:
-			slave_dbg(slave->bond->dev, slave->dev, "Received Marker Information on port %d\n",
-				  port->actor_port_number);
-			ad_marker_info_received(marker, port);
-			break;
-		case AD_MARKER_RESPONSE_SUBTYPE:
-			slave_dbg(slave->bond->dev, slave->dev, "Received Marker Response on port %d\n",
-				  port->actor_port_number);
-			ad_marker_response_received(marker, port);
-			break;
-		default:
-			slave_dbg(slave->bond->dev, slave->dev, "Received an unknown Marker subtype on port %d\n",
-				  port->actor_port_number);
-			stat = &SLAVE_AD_INFO(slave)->stats.marker_unknown_rx;
-			atomic64_inc(stat);
-			stat = &BOND_AD_INFO(bond).stats.marker_unknown_rx;
-			atomic64_inc(stat);
-		}
-		break;
-	default:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_unknown_rx);
-		atomic64_inc(&BOND_AD_INFO(bond).stats.lacpdu_unknown_rx);
-	}
-
-	return ret;
-}
-
-/**
- * ad_update_actor_keys - Update the oper / admin keys for a port based on
- * its current speed and duplex settings.
- *
- * @port: the port we'are looking at
- * @reset: Boolean to just reset the speed and the duplex part of the key
- *
- * The logic to change the oper / admin keys is:
- * (a) A full duplex port can participate in LACP with partner.
- * (b) When the speed is changed, LACP need to be reinitiated.
- */
-static void ad_update_actor_keys(struct port *port, bool reset)
-{
-	u8 duplex = 0;
-	u16 ospeed = 0, speed = 0;
-	u16 old_oper_key = port->actor_oper_port_key;
-
-	port->actor_admin_port_key &= ~(AD_SPEED_KEY_MASKS|AD_DUPLEX_KEY_MASKS);
-	if (!reset) {
-		speed = __get_link_speed(port);
-		ospeed = (old_oper_key & AD_SPEED_KEY_MASKS) >> 1;
-		duplex = __get_duplex(port);
-		port->actor_admin_port_key |= (speed << 1) | duplex;
-	}
-	port->actor_oper_port_key = port->actor_admin_port_key;
-
-	if (old_oper_key != port->actor_oper_port_key) {
-		/* Only 'duplex' port participates in LACP */
-		if (duplex)
-			port->sm_vars |= AD_PORT_LACP_ENABLED;
-		else
-			port->sm_vars &= ~AD_PORT_LACP_ENABLED;
-
-		if (!reset) {
-			if (!speed) {
-				slave_err(port->slave->bond->dev,
-					  port->slave->dev,
-					  "speed changed to 0 on port %d\n",
-					  port->actor_port_number);
-			} else if (duplex && ospeed != speed) {
-				/* Speed change restarts LACP state-machine */
-				port->sm_vars |= AD_PORT_BEGIN;
-			}
-		}
-	}
-}
-
-/**
- * bond_3ad_adapter_speed_duplex_changed - handle a slave's speed / duplex
- * change indication
- *
- * @slave: slave struct to work on
- *
- * Handle reselection of aggregator (if needed) for this port.
- */
-void bond_3ad_adapter_speed_duplex_changed(struct slave *slave)
-{
-	struct port *port;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(slave->bond->dev, slave->dev,
-			   "speed/duplex changed for uninitialized port\n");
-		return;
-	}
-
-	spin_lock_bh(&slave->bond->mode_lock);
-	ad_update_actor_keys(port, false);
-	spin_unlock_bh(&slave->bond->mode_lock);
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d changed speed/duplex\n",
-		  port->actor_port_number);
-}
-
-/**
- * bond_3ad_handle_link_change - handle a slave's link status change indication
- * @slave: slave struct to work on
- * @status: whether the link is now up or down
- *
- * Handle reselection of aggregator (if needed) for this port.
- */
-void bond_3ad_handle_link_change(struct slave *slave, char link)
-{
-	struct aggregator *agg;
-	struct port *port;
-	bool dummy;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(slave->bond->dev, slave->dev, "link status changed for uninitialized port\n");
-		return;
-	}
-
-	spin_lock_bh(&slave->bond->mode_lock);
-	/* on link down we are zeroing duplex and speed since
-	 * some of the adaptors(ce1000.lan) report full duplex/speed
-	 * instead of N/A(duplex) / 0(speed).
-	 *
-	 * on link up we are forcing recheck on the duplex and speed since
-	 * some of he adaptors(ce1000.lan) report.
-	 */
-	if (link == BOND_LINK_UP) {
-		port->is_enabled = true;
-		ad_update_actor_keys(port, false);
-	} else {
-		/* link has failed */
-		port->is_enabled = false;
-		ad_update_actor_keys(port, true);
-		toe_failover(netdev_master_upper_dev_get(slave->dev),
-			     slave->dev, TOE_LINK_DOWN, NULL);
-	}
-	agg = __get_first_agg(port);
-	ad_agg_selection_logic(agg, &dummy);
-
-	spin_unlock_bh(&slave->bond->mode_lock);
-
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d changed link status to %s\n",
-		  port->actor_port_number,
-		  link == BOND_LINK_UP ? "UP" : "DOWN");
-
-	/* RTNL is held and mode_lock is released so it's safe
-	 * to update slave_array here.
-	 */
-	bond_update_slave_arr(slave->bond, NULL);
-}
-
-/**
- * bond_3ad_set_carrier - set link state for bonding master
- * @bond - bonding structure
- *
- * if we have an active aggregator, we're up, if not, we're down.
- * Presumes that we cannot have an active aggregator if there are
- * no slaves with link up.
- *
- * This behavior complies with IEEE 802.3 section 43.3.9.
- *
- * Called by bond_set_carrier(). Return zero if carrier state does not
- * change, nonzero if it does.
- */
-int bond_3ad_set_carrier(struct bonding *bond)
-{
-	struct aggregator *active;
-	struct slave *first_slave;
-	int ret = 1;
-
-	rcu_read_lock();
-	first_slave = bond_first_slave_rcu(bond);
-	if (!first_slave) {
-		ret = 0;
-		goto out;
-	}
-	active = __get_active_agg(&(SLAVE_AD_INFO(first_slave)->aggregator));
-	if (active) {
-		/* are enough slaves available to consider link up? */
-		if (__agg_active_ports(active) < bond->params.min_links) {
-			if (netif_carrier_ok(bond->dev)) {
-				netif_carrier_off(bond->dev);
-				goto out;
-			}
-		} else if (!netif_carrier_ok(bond->dev)) {
-			netif_carrier_on(bond->dev);
-			goto out;
-		}
-	} else if (netif_carrier_ok(bond->dev)) {
-		netif_carrier_off(bond->dev);
-	}
-out:
-	rcu_read_unlock();
-	return ret;
-}
-
-/**
- * __bond_3ad_get_active_agg_info - get information of the active aggregator
- * @bond: bonding struct to work on
- * @ad_info: ad_info struct to fill with the bond's info
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-int __bond_3ad_get_active_agg_info(struct bonding *bond,
-				   struct ad_info *ad_info)
-{
-	struct aggregator *aggregator = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (port->aggregator && port->aggregator->is_active) {
-			aggregator = port->aggregator;
-			break;
-		}
-	}
-
-	if (!aggregator)
-		return -1;
-
-	ad_info->aggregator_id = aggregator->aggregator_identifier;
-	ad_info->ports = __agg_active_ports(aggregator);
-	ad_info->actor_key = aggregator->actor_oper_aggregator_key;
-	ad_info->partner_key = aggregator->partner_oper_aggregator_key;
-	ether_addr_copy(ad_info->partner_system,
-			aggregator->partner_system.mac_addr_value);
-	return 0;
-}
-
-int bond_3ad_get_active_agg_info(struct bonding *bond, struct ad_info *ad_info)
-{
-	int ret;
-
-	rcu_read_lock();
-	ret = __bond_3ad_get_active_agg_info(bond, ad_info);
-	rcu_read_unlock();
-
-	return ret;
-}
-
-int bond_3ad_lacpdu_recv(const struct sk_buff *skb, struct bonding *bond,
-			 struct slave *slave)
-{
-	struct lacpdu *lacpdu, _lacpdu;
-
-	if (skb->protocol != PKT_TYPE_LACPDU)
-		return RX_HANDLER_ANOTHER;
-
-	if (!MAC_ADDRESS_EQUAL(eth_hdr(skb)->h_dest, lacpdu_mcast_addr))
-		return RX_HANDLER_ANOTHER;
-
-	lacpdu = skb_header_pointer(skb, 0, sizeof(_lacpdu), &_lacpdu);
-	if (!lacpdu) {
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_illegal_rx);
-		atomic64_inc(&BOND_AD_INFO(bond).stats.lacpdu_illegal_rx);
-		return RX_HANDLER_ANOTHER;
-	}
-
-	return bond_3ad_rx_indication(lacpdu, slave);
-}
-
-/**
- * bond_3ad_update_lacp_rate - change the lacp rate
- * @bond - bonding struct
- *
- * When modify lacp_rate parameter via sysfs,
- * update actor_oper_port_state of each port.
- *
- * Hold bond->mode_lock,
- * so we can modify port->actor_oper_port_state,
- * no matter bond is up or down.
- */
-void bond_3ad_update_lacp_rate(struct bonding *bond)
-{
-	struct port *port = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	int lacp_fast;
-
-	lacp_fast = bond->params.lacp_fast;
-	spin_lock_bh(&bond->mode_lock);
-	bond_for_each_slave(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (lacp_fast)
-			port->actor_oper_port_state |= AD_STATE_LACP_TIMEOUT;
-		else
-			port->actor_oper_port_state &= ~AD_STATE_LACP_TIMEOUT;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-size_t bond_3ad_stats_size(void)
-{
-	return nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_TX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_UNKNOWN_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_ILLEGAL_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_TX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RESP_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RESP_TX */
-	       nla_total_size_64bit(sizeof(u64)); /* BOND_3AD_STAT_MARKER_UNKNOWN_RX */
-}
-
-int bond_3ad_stats_fill(struct sk_buff *skb, struct bond_3ad_stats *stats)
-{
-	u64 val;
-
-	val = atomic64_read(&stats->lacpdu_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_unknown_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_UNKNOWN_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_illegal_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_ILLEGAL_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-
-	val = atomic64_read(&stats->marker_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_resp_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RESP_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_resp_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RESP_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_unknown_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_UNKNOWN_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-
-	return 0;
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bond_alb.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bond_alb.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1791 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
- */
-
-#include <linux/skbuff.h>
-#include <linux/netdevice.h>
-#include <linux/etherdevice.h>
-#include <linux/pkt_sched.h>
-#include <linux/spinlock.h>
-#include <linux/slab.h>
-#include <linux/timer.h>
-#include <linux/ip.h>
-#include <linux/ipv6.h>
-#include <linux/if_arp.h>
-#include <linux/if_ether.h>
-#include <linux/if_bonding.h>
-#include <linux/if_vlan.h>
-#include <linux/in.h>
-#include <net/ipx.h>
-#include <net/arp.h>
-#include <net/ipv6.h>
-#include <asm/byteorder.h>
-#include <net/bonding.h>
-#include <net/bond_alb.h>
-
-static const u8 mac_v6_allmcast[ETH_ALEN + 2] __long_aligned = {
-	0x33, 0x33, 0x00, 0x00, 0x00, 0x01
-};
-static const int alb_delta_in_ticks = HZ / ALB_TIMER_TICKS_PER_SEC;
-
-#pragma pack(1)
-struct learning_pkt {
-	u8 mac_dst[ETH_ALEN];
-	u8 mac_src[ETH_ALEN];
-	__be16 type;
-	u8 padding[ETH_ZLEN - ETH_HLEN];
-};
-
-struct arp_pkt {
-	__be16  hw_addr_space;
-	__be16  prot_addr_space;
-	u8      hw_addr_len;
-	u8      prot_addr_len;
-	__be16  op_code;
-	u8      mac_src[ETH_ALEN];	/* sender hardware address */
-	__be32  ip_src;			/* sender IP address */
-	u8      mac_dst[ETH_ALEN];	/* target hardware address */
-	__be32  ip_dst;			/* target IP address */
-};
-#pragma pack()
-
-static inline struct arp_pkt *arp_pkt(const struct sk_buff *skb)
-{
-	return (struct arp_pkt *)skb_network_header(skb);
-}
-
-/* Forward declaration */
-static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
-				      bool strict_match);
-static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp);
-static void rlb_src_unlink(struct bonding *bond, u32 index);
-static void rlb_src_link(struct bonding *bond, u32 ip_src_hash,
-			 u32 ip_dst_hash);
-
-static inline u8 _simple_hash(const u8 *hash_start, int hash_size)
-{
-	int i;
-	u8 hash = 0;
-
-	for (i = 0; i < hash_size; i++)
-		hash ^= hash_start[i];
-
-	return hash;
-}
-
-/*********************** tlb specific functions ***************************/
-
-static inline void tlb_init_table_entry(struct tlb_client_info *entry, int save_load)
-{
-	if (save_load) {
-		entry->load_history = 1 + entry->tx_bytes /
-				      BOND_TLB_REBALANCE_INTERVAL;
-		entry->tx_bytes = 0;
-	}
-
-	entry->tx_slave = NULL;
-	entry->next = TLB_NULL_INDEX;
-	entry->prev = TLB_NULL_INDEX;
-}
-
-static inline void tlb_init_slave(struct slave *slave)
-{
-	SLAVE_TLB_INFO(slave).load = 0;
-	SLAVE_TLB_INFO(slave).head = TLB_NULL_INDEX;
-}
-
-static void __tlb_clear_slave(struct bonding *bond, struct slave *slave,
-			 int save_load)
-{
-	struct tlb_client_info *tx_hash_table;
-	u32 index;
-
-	/* clear slave from tx_hashtbl */
-	tx_hash_table = BOND_ALB_INFO(bond).tx_hashtbl;
-
-	/* skip this if we've already freed the tx hash table */
-	if (tx_hash_table) {
-		index = SLAVE_TLB_INFO(slave).head;
-		while (index != TLB_NULL_INDEX) {
-			u32 next_index = tx_hash_table[index].next;
-			tlb_init_table_entry(&tx_hash_table[index], save_load);
-			index = next_index;
-		}
-	}
-
-	tlb_init_slave(slave);
-}
-
-static void tlb_clear_slave(struct bonding *bond, struct slave *slave,
-			 int save_load)
-{
-	spin_lock_bh(&bond->mode_lock);
-	__tlb_clear_slave(bond, slave, save_load);
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* Must be called before starting the monitor timer */
-static int tlb_initialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	int size = TLB_HASH_TABLE_SIZE * sizeof(struct tlb_client_info);
-	struct tlb_client_info *new_hashtbl;
-	int i;
-
-	new_hashtbl = kzalloc(size, GFP_KERNEL);
-	if (!new_hashtbl)
-		return -ENOMEM;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	bond_info->tx_hashtbl = new_hashtbl;
-
-	for (i = 0; i < TLB_HASH_TABLE_SIZE; i++)
-		tlb_init_table_entry(&bond_info->tx_hashtbl[i], 0);
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	return 0;
-}
-
-/* Must be called only after all slaves have been released */
-static void tlb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	spin_lock_bh(&bond->mode_lock);
-
-	kfree(bond_info->tx_hashtbl);
-	bond_info->tx_hashtbl = NULL;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static long long compute_gap(struct slave *slave)
-{
-	return (s64) (slave->speed << 20) - /* Convert to Megabit per sec */
-	       (s64) (SLAVE_TLB_INFO(slave).load << 3); /* Bytes to bits */
-}
-
-static struct slave *tlb_get_least_loaded_slave(struct bonding *bond)
-{
-	struct slave *slave, *least_loaded;
-	struct list_head *iter;
-	long long max_gap;
-
-	least_loaded = NULL;
-	max_gap = LLONG_MIN;
-
-	/* Find the slave with the largest gap */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (bond_slave_can_tx(slave)) {
-			long long gap = compute_gap(slave);
-
-			if (max_gap < gap) {
-				least_loaded = slave;
-				max_gap = gap;
-			}
-		}
-	}
-
-	return least_loaded;
-}
-
-static struct slave *__tlb_choose_channel(struct bonding *bond, u32 hash_index,
-						u32 skb_len)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct tlb_client_info *hash_table;
-	struct slave *assigned_slave;
-
-	hash_table = bond_info->tx_hashtbl;
-	assigned_slave = hash_table[hash_index].tx_slave;
-	if (!assigned_slave) {
-		assigned_slave = tlb_get_least_loaded_slave(bond);
-
-		if (assigned_slave) {
-			struct tlb_slave_info *slave_info =
-				&(SLAVE_TLB_INFO(assigned_slave));
-			u32 next_index = slave_info->head;
-
-			hash_table[hash_index].tx_slave = assigned_slave;
-			hash_table[hash_index].next = next_index;
-			hash_table[hash_index].prev = TLB_NULL_INDEX;
-
-			if (next_index != TLB_NULL_INDEX)
-				hash_table[next_index].prev = hash_index;
-
-			slave_info->head = hash_index;
-			slave_info->load +=
-				hash_table[hash_index].load_history;
-		}
-	}
-
-	if (assigned_slave)
-		hash_table[hash_index].tx_bytes += skb_len;
-
-	return assigned_slave;
-}
-
-static struct slave *tlb_choose_channel(struct bonding *bond, u32 hash_index,
-					u32 skb_len)
-{
-	struct slave *tx_slave;
-
-	/* We don't need to disable softirq here, becase
-	 * tlb_choose_channel() is only called by bond_alb_xmit()
-	 * which already has softirq disabled.
-	 */
-	spin_lock(&bond->mode_lock);
-	tx_slave = __tlb_choose_channel(bond, hash_index, skb_len);
-	spin_unlock(&bond->mode_lock);
-
-	return tx_slave;
-}
-
-/*********************** rlb specific functions ***************************/
-
-/* when an ARP REPLY is received from a client update its info
- * in the rx_hashtbl
- */
-static void rlb_update_entry_from_arp(struct bonding *bond, struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
-	client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-	if ((client_info->assigned) &&
-	    (client_info->ip_src == arp->ip_dst) &&
-	    (client_info->ip_dst == arp->ip_src) &&
-	    (!ether_addr_equal_64bits(client_info->mac_dst, arp->mac_src))) {
-		/* update the clients MAC address */
-		ether_addr_copy(client_info->mac_dst, arp->mac_src);
-		client_info->ntt = 1;
-		bond_info->rx_ntt = 1;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static int rlb_arp_recv(const struct sk_buff *skb, struct bonding *bond,
-			struct slave *slave)
-{
-	struct arp_pkt *arp, _arp;
-
-	if (skb->protocol != cpu_to_be16(ETH_P_ARP))
-		goto out;
-
-	arp = skb_header_pointer(skb, 0, sizeof(_arp), &_arp);
-	if (!arp)
-		goto out;
-
-	/* We received an ARP from arp->ip_src.
-	 * We might have used this IP address previously (on the bonding host
-	 * itself or on a system that is bridged together with the bond).
-	 * However, if arp->mac_src is different than what is stored in
-	 * rx_hashtbl, some other host is now using the IP and we must prevent
-	 * sending out client updates with this IP address and the old MAC
-	 * address.
-	 * Clean up all hash table entries that have this address as ip_src but
-	 * have a different mac_src.
-	 */
-	rlb_purge_src_ip(bond, arp);
-
-	if (arp->op_code == htons(ARPOP_REPLY)) {
-		/* update rx hash table for this ARP */
-		rlb_update_entry_from_arp(bond, arp);
-		slave_dbg(bond->dev, slave->dev, "Server received an ARP Reply from client\n");
-	}
-out:
-	return RX_HANDLER_ANOTHER;
-}
-
-/* Caller must hold rcu_read_lock() */
-static struct slave *__rlb_next_rx_slave(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *before = NULL, *rx_slave = NULL, *slave;
-	struct list_head *iter;
-	bool found = false;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!bond_slave_can_tx(slave))
-			continue;
-		if (!found) {
-			if (!before || before->speed < slave->speed)
-				before = slave;
-		} else {
-			if (!rx_slave || rx_slave->speed < slave->speed)
-				rx_slave = slave;
-		}
-		if (slave == bond_info->rx_slave)
-			found = true;
-	}
-	/* we didn't find anything after the current or we have something
-	 * better before and up to the current slave
-	 */
-	if (!rx_slave || (before && rx_slave->speed < before->speed))
-		rx_slave = before;
-
-	if (rx_slave)
-		bond_info->rx_slave = rx_slave;
-
-	return rx_slave;
-}
-
-/* Caller must hold RTNL, rcu_read_lock is obtained only to silence checkers */
-static struct slave *rlb_next_rx_slave(struct bonding *bond)
-{
-	struct slave *rx_slave;
-
-	ASSERT_RTNL();
-
-	rcu_read_lock();
-	rx_slave = __rlb_next_rx_slave(bond);
-	rcu_read_unlock();
-
-	return rx_slave;
-}
-
-/* teach the switch the mac of a disabled slave
- * on the primary for fault tolerance
- *
- * Caller must hold RTNL
- */
-static void rlb_teach_disabled_mac_on_primary(struct bonding *bond, u8 addr[])
-{
-	struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-	if (!curr_active)
-		return;
-
-	if (!bond->alb_info.primary_is_promisc) {
-		if (!dev_set_promiscuity(curr_active->dev, 1))
-			bond->alb_info.primary_is_promisc = 1;
-		else
-			bond->alb_info.primary_is_promisc = 0;
-	}
-
-	bond->alb_info.rlb_promisc_timeout_counter = 0;
-
-	alb_send_learning_packets(curr_active, addr, true);
-}
-
-/* slave being removed should not be active at this point
- *
- * Caller must hold rtnl.
- */
-static void rlb_clear_slave(struct bonding *bond, struct slave *slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *rx_hash_table;
-	u32 index, next_index;
-
-	/* clear slave from rx_hashtbl */
-	spin_lock_bh(&bond->mode_lock);
-
-	rx_hash_table = bond_info->rx_hashtbl;
-	index = bond_info->rx_hashtbl_used_head;
-	for (; index != RLB_NULL_INDEX; index = next_index) {
-		next_index = rx_hash_table[index].used_next;
-		if (rx_hash_table[index].slave == slave) {
-			struct slave *assigned_slave = rlb_next_rx_slave(bond);
-
-			if (assigned_slave) {
-				rx_hash_table[index].slave = assigned_slave;
-				if (is_valid_ether_addr(rx_hash_table[index].mac_dst)) {
-					bond_info->rx_hashtbl[index].ntt = 1;
-					bond_info->rx_ntt = 1;
-					/* A slave has been removed from the
-					 * table because it is either disabled
-					 * or being released. We must retry the
-					 * update to avoid clients from not
-					 * being updated & disconnecting when
-					 * there is stress
-					 */
-					bond_info->rlb_update_retry_counter =
-						RLB_UPDATE_RETRY;
-				}
-			} else {  /* there is no active slave */
-				rx_hash_table[index].slave = NULL;
-			}
-		}
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	if (slave != rtnl_dereference(bond->curr_active_slave))
-		rlb_teach_disabled_mac_on_primary(bond, slave->dev->dev_addr);
-}
-
-static void rlb_update_client(struct rlb_client_info *client_info)
-{
-	int i;
-
-	if (!client_info->slave || !is_valid_ether_addr(client_info->mac_dst))
-		return;
-
-	for (i = 0; i < RLB_ARP_BURST_SIZE; i++) {
-		struct sk_buff *skb;
-
-		skb = arp_create(ARPOP_REPLY, ETH_P_ARP,
-				 client_info->ip_dst,
-				 client_info->slave->dev,
-				 client_info->ip_src,
-				 client_info->mac_dst,
-				 client_info->slave->dev->dev_addr,
-				 client_info->mac_dst);
-		if (!skb) {
-			slave_err(client_info->slave->bond->dev,
-				  client_info->slave->dev,
-				  "failed to create an ARP packet\n");
-			continue;
-		}
-
-		skb->dev = client_info->slave->dev;
-
-		if (client_info->vlan_id) {
-			__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),
-					       client_info->vlan_id);
-		}
-
-		arp_xmit(skb);
-	}
-}
-
-/* sends ARP REPLIES that update the clients that need updating */
-static void rlb_update_rx_clients(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		if (client_info->ntt) {
-			rlb_update_client(client_info);
-			if (bond_info->rlb_update_retry_counter == 0)
-				client_info->ntt = 0;
-		}
-	}
-
-	/* do not update the entries again until this counter is zero so that
-	 * not to confuse the clients.
-	 */
-	bond_info->rlb_update_delay_counter = RLB_UPDATE_DELAY;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* The slave was assigned a new mac address - update the clients */
-static void rlb_req_update_slave_clients(struct bonding *bond, struct slave *slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	int ntt = 0;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-		if ((client_info->slave == slave) &&
-		    is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			ntt = 1;
-		}
-	}
-
-	/* update the team's flag only after the whole iteration */
-	if (ntt) {
-		bond_info->rx_ntt = 1;
-		/* fasten the change */
-		bond_info->rlb_update_retry_counter = RLB_UPDATE_RETRY;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* mark all clients using src_ip to be updated */
-static void rlb_req_update_subnet_clients(struct bonding *bond, __be32 src_ip)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-		if (!client_info->slave) {
-			netdev_err(bond->dev, "found a client with no channel in the client's hash table\n");
-			continue;
-		}
-		/* update all clients using this src_ip, that are not assigned
-		 * to the team's address (curr_active_slave) and have a known
-		 * unicast mac address.
-		 */
-		if ((client_info->ip_src == src_ip) &&
-		    !ether_addr_equal_64bits(client_info->slave->dev->dev_addr,
-					     bond->dev->dev_addr) &&
-		    is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			bond_info->rx_ntt = 1;
-		}
-	}
-
-	spin_unlock(&bond->mode_lock);
-}
-
-static struct slave *rlb_choose_channel(struct sk_buff *skb, struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct arp_pkt *arp = arp_pkt(skb);
-	struct slave *assigned_slave, *curr_active_slave;
-	struct rlb_client_info *client_info;
-	u32 hash_index = 0;
-
-	spin_lock(&bond->mode_lock);
-
-	curr_active_slave = rcu_dereference(bond->curr_active_slave);
-
-	hash_index = _simple_hash((u8 *)&arp->ip_dst, sizeof(arp->ip_dst));
-	client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-	if (client_info->assigned) {
-		if ((client_info->ip_src == arp->ip_src) &&
-		    (client_info->ip_dst == arp->ip_dst)) {
-			/* the entry is already assigned to this client */
-			if (!is_broadcast_ether_addr(arp->mac_dst)) {
-				/* update mac address from arp */
-				ether_addr_copy(client_info->mac_dst, arp->mac_dst);
-			}
-			ether_addr_copy(client_info->mac_src, arp->mac_src);
-
-			assigned_slave = client_info->slave;
-			if (assigned_slave) {
-				spin_unlock(&bond->mode_lock);
-				return assigned_slave;
-			}
-		} else {
-			/* the entry is already assigned to some other client,
-			 * move the old client to primary (curr_active_slave) so
-			 * that the new client can be assigned to this entry.
-			 */
-			if (curr_active_slave &&
-			    client_info->slave != curr_active_slave) {
-				client_info->slave = curr_active_slave;
-				rlb_update_client(client_info);
-			}
-		}
-	}
-	/* assign a new slave */
-	assigned_slave = __rlb_next_rx_slave(bond);
-
-	if (assigned_slave) {
-		if (!(client_info->assigned &&
-		      client_info->ip_src == arp->ip_src)) {
-			/* ip_src is going to be updated,
-			 * fix the src hash list
-			 */
-			u32 hash_src = _simple_hash((u8 *)&arp->ip_src,
-						    sizeof(arp->ip_src));
-			rlb_src_unlink(bond, hash_index);
-			rlb_src_link(bond, hash_src, hash_index);
-		}
-
-		client_info->ip_src = arp->ip_src;
-		client_info->ip_dst = arp->ip_dst;
-		/* arp->mac_dst is broadcast for arp reqeusts.
-		 * will be updated with clients actual unicast mac address
-		 * upon receiving an arp reply.
-		 */
-		ether_addr_copy(client_info->mac_dst, arp->mac_dst);
-		ether_addr_copy(client_info->mac_src, arp->mac_src);
-		client_info->slave = assigned_slave;
-
-		if (is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			bond->alb_info.rx_ntt = 1;
-		} else {
-			client_info->ntt = 0;
-		}
-
-		if (vlan_get_tag(skb, &client_info->vlan_id))
-			client_info->vlan_id = 0;
-
-		if (!client_info->assigned) {
-			u32 prev_tbl_head = bond_info->rx_hashtbl_used_head;
-			bond_info->rx_hashtbl_used_head = hash_index;
-			client_info->used_next = prev_tbl_head;
-			if (prev_tbl_head != RLB_NULL_INDEX) {
-				bond_info->rx_hashtbl[prev_tbl_head].used_prev =
-					hash_index;
-			}
-			client_info->assigned = 1;
-		}
-	}
-
-	spin_unlock(&bond->mode_lock);
-
-	return assigned_slave;
-}
-
-/* chooses (and returns) transmit channel for arp reply
- * does not choose channel for other arp types since they are
- * sent on the curr_active_slave
- */
-static struct slave *rlb_arp_xmit(struct sk_buff *skb, struct bonding *bond)
-{
-	struct arp_pkt *arp = arp_pkt(skb);
-	struct slave *tx_slave = NULL;
-
-	/* Don't modify or load balance ARPs that do not originate locally
-	 * (e.g.,arrive via a bridge).
-	 */
-	if (!bond_slave_has_mac_rx(bond, arp->mac_src))
-		return NULL;
-
-	if (arp->op_code == htons(ARPOP_REPLY)) {
-		/* the arp must be sent on the selected rx channel */
-		tx_slave = rlb_choose_channel(skb, bond);
-		if (tx_slave)
-			bond_hw_addr_copy(arp->mac_src, tx_slave->dev->dev_addr,
-					  tx_slave->dev->addr_len);
-		netdev_dbg(bond->dev, "(slave %s): Server sent ARP Reply packet\n",
-			   tx_slave ? tx_slave->dev->name : "NULL");
-	} else if (arp->op_code == htons(ARPOP_REQUEST)) {
-		/* Create an entry in the rx_hashtbl for this client as a
-		 * place holder.
-		 * When the arp reply is received the entry will be updated
-		 * with the correct unicast address of the client.
-		 */
-		tx_slave = rlb_choose_channel(skb, bond);
-
-		/* The ARP reply packets must be delayed so that
-		 * they can cancel out the influence of the ARP request.
-		 */
-		bond->alb_info.rlb_update_delay_counter = RLB_UPDATE_DELAY;
-
-		/* arp requests are broadcast and are sent on the primary
-		 * the arp request will collapse all clients on the subnet to
-		 * the primary slave. We must register these clients to be
-		 * updated with their assigned mac.
-		 */
-		rlb_req_update_subnet_clients(bond, arp->ip_src);
-		netdev_dbg(bond->dev, "(slave %s): Server sent ARP Request packet\n",
-			   tx_slave ? tx_slave->dev->name : "NULL");
-	}
-
-	return tx_slave;
-}
-
-static void rlb_rebalance(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *assigned_slave;
-	struct rlb_client_info *client_info;
-	int ntt;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	ntt = 0;
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		assigned_slave = __rlb_next_rx_slave(bond);
-		if (assigned_slave && (client_info->slave != assigned_slave)) {
-			client_info->slave = assigned_slave;
-			if (!is_zero_ether_addr(client_info->mac_dst)) {
-				client_info->ntt = 1;
-				ntt = 1;
-			}
-		}
-	}
-
-	/* update the team's flag only after the whole iteration */
-	if (ntt)
-		bond_info->rx_ntt = 1;
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* Caller must hold mode_lock */
-static void rlb_init_table_entry_dst(struct rlb_client_info *entry)
-{
-	entry->used_next = RLB_NULL_INDEX;
-	entry->used_prev = RLB_NULL_INDEX;
-	entry->assigned = 0;
-	entry->slave = NULL;
-	entry->vlan_id = 0;
-}
-static void rlb_init_table_entry_src(struct rlb_client_info *entry)
-{
-	entry->src_first = RLB_NULL_INDEX;
-	entry->src_prev = RLB_NULL_INDEX;
-	entry->src_next = RLB_NULL_INDEX;
-}
-
-static void rlb_init_table_entry(struct rlb_client_info *entry)
-{
-	memset(entry, 0, sizeof(struct rlb_client_info));
-	rlb_init_table_entry_dst(entry);
-	rlb_init_table_entry_src(entry);
-}
-
-static void rlb_delete_table_entry_dst(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next_index = bond_info->rx_hashtbl[index].used_next;
-	u32 prev_index = bond_info->rx_hashtbl[index].used_prev;
-
-	if (index == bond_info->rx_hashtbl_used_head)
-		bond_info->rx_hashtbl_used_head = next_index;
-	if (prev_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[prev_index].used_next = next_index;
-	if (next_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next_index].used_prev = prev_index;
-}
-
-/* unlink a rlb hash table entry from the src list */
-static void rlb_src_unlink(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next_index = bond_info->rx_hashtbl[index].src_next;
-	u32 prev_index = bond_info->rx_hashtbl[index].src_prev;
-
-	bond_info->rx_hashtbl[index].src_next = RLB_NULL_INDEX;
-	bond_info->rx_hashtbl[index].src_prev = RLB_NULL_INDEX;
-
-	if (next_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next_index].src_prev = prev_index;
-
-	if (prev_index == RLB_NULL_INDEX)
-		return;
-
-	/* is prev_index pointing to the head of this list? */
-	if (bond_info->rx_hashtbl[prev_index].src_first == index)
-		bond_info->rx_hashtbl[prev_index].src_first = next_index;
-	else
-		bond_info->rx_hashtbl[prev_index].src_next = next_index;
-
-}
-
-static void rlb_delete_table_entry(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
-
-	rlb_delete_table_entry_dst(bond, index);
-	rlb_init_table_entry_dst(entry);
-
-	rlb_src_unlink(bond, index);
-}
-
-/* add the rx_hashtbl[ip_dst_hash] entry to the list
- * of entries with identical ip_src_hash
- */
-static void rlb_src_link(struct bonding *bond, u32 ip_src_hash, u32 ip_dst_hash)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next;
-
-	bond_info->rx_hashtbl[ip_dst_hash].src_prev = ip_src_hash;
-	next = bond_info->rx_hashtbl[ip_src_hash].src_first;
-	bond_info->rx_hashtbl[ip_dst_hash].src_next = next;
-	if (next != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next].src_prev = ip_dst_hash;
-	bond_info->rx_hashtbl[ip_src_hash].src_first = ip_dst_hash;
-}
-
-/* deletes all rx_hashtbl entries with arp->ip_src if their mac_src does
- * not match arp->mac_src
- */
-static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 ip_src_hash = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
-	u32 index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	index = bond_info->rx_hashtbl[ip_src_hash].src_first;
-	while (index != RLB_NULL_INDEX) {
-		struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
-		u32 next_index = entry->src_next;
-		if (entry->ip_src == arp->ip_src &&
-		    !ether_addr_equal_64bits(arp->mac_src, entry->mac_src))
-				rlb_delete_table_entry(bond, index);
-		index = next_index;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static int rlb_initialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info	*new_hashtbl;
-	int size = RLB_HASH_TABLE_SIZE * sizeof(struct rlb_client_info);
-	int i;
-
-	new_hashtbl = kmalloc(size, GFP_KERNEL);
-	if (!new_hashtbl)
-		return -1;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	bond_info->rx_hashtbl = new_hashtbl;
-
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	for (i = 0; i < RLB_HASH_TABLE_SIZE; i++)
-		rlb_init_table_entry(bond_info->rx_hashtbl + i);
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	/* register to receive ARPs */
-	bond->recv_probe = rlb_arp_recv;
-
-	return 0;
-}
-
-static void rlb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	spin_lock_bh(&bond->mode_lock);
-
-	kfree(bond_info->rx_hashtbl);
-	bond_info->rx_hashtbl = NULL;
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static void rlb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 curr_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	curr_index = bond_info->rx_hashtbl_used_head;
-	while (curr_index != RLB_NULL_INDEX) {
-		struct rlb_client_info *curr = &(bond_info->rx_hashtbl[curr_index]);
-		u32 next_index = bond_info->rx_hashtbl[curr_index].used_next;
-
-		if (curr->vlan_id == vlan_id)
-			rlb_delete_table_entry(bond, curr_index);
-
-		curr_index = next_index;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/*********************** tlb/rlb shared functions *********************/
-
-static void alb_send_lp_vid(struct slave *slave, u8 mac_addr[],
-			    __be16 vlan_proto, u16 vid)
-{
-	struct learning_pkt pkt;
-	struct sk_buff *skb;
-	int size = sizeof(struct learning_pkt);
-
-	memset(&pkt, 0, size);
-	ether_addr_copy(pkt.mac_dst, mac_addr);
-	ether_addr_copy(pkt.mac_src, mac_addr);
-	pkt.type = cpu_to_be16(ETH_P_LOOPBACK);
-
-	skb = dev_alloc_skb(size);
-	if (!skb)
-		return;
-
-	skb_put_data(skb, &pkt, size);
-
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = pkt.type;
-	skb->priority = TC_PRIO_CONTROL;
-	skb->dev = slave->dev;
-
-	slave_dbg(slave->bond->dev, slave->dev,
-		  "Send learning packet: mac %pM vlan %d\n", mac_addr, vid);
-
-	if (vid)
-		__vlan_hwaccel_put_tag(skb, vlan_proto, vid);
-
-	dev_queue_xmit(skb);
-}
-
-struct alb_walk_data {
-	struct bonding *bond;
-	struct slave *slave;
-	u8 *mac_addr;
-	bool strict_match;
-};
-
-static int alb_upper_dev_walk(struct net_device *upper, void *_data)
-{
-	struct alb_walk_data *data = _data;
-	bool strict_match = data->strict_match;
-	struct bonding *bond = data->bond;
-	struct slave *slave = data->slave;
-	u8 *mac_addr = data->mac_addr;
-	struct bond_vlan_tag *tags;
-
-	if (is_vlan_dev(upper) &&
-	    bond->dev->lower_level == upper->lower_level - 1) {
-		if (upper->addr_assign_type == NET_ADDR_STOLEN) {
-			alb_send_lp_vid(slave, mac_addr,
-					vlan_dev_vlan_proto(upper),
-					vlan_dev_vlan_id(upper));
-		} else {
-			alb_send_lp_vid(slave, upper->dev_addr,
-					vlan_dev_vlan_proto(upper),
-					vlan_dev_vlan_id(upper));
-		}
-	}
-
-	/* If this is a macvlan device, then only send updates
-	 * when strict_match is turned off.
-	 */
-	if (netif_is_macvlan(upper) && !strict_match) {
-		tags = bond_verify_device_path(bond->dev, upper, 0);
-		if (IS_ERR_OR_NULL(tags))
-			BUG();
-		alb_send_lp_vid(slave, upper->dev_addr,
-				tags[0].vlan_proto, tags[0].vlan_id);
-		kfree(tags);
-	}
-
-	return 0;
-}
-
-static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
-				      bool strict_match)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-	struct alb_walk_data data = {
-		.strict_match = strict_match,
-		.mac_addr = mac_addr,
-		.slave = slave,
-		.bond = bond,
-	};
-
-	/* send untagged */
-	alb_send_lp_vid(slave, mac_addr, 0, 0);
-
-	/* loop through all devices and see if we need to send a packet
-	 * for that device.
-	 */
-	rcu_read_lock();
-	netdev_walk_all_upper_dev_rcu(bond->dev, alb_upper_dev_walk, &data);
-	rcu_read_unlock();
-}
-
-static int alb_set_slave_mac_addr(struct slave *slave, u8 addr[],
-				  unsigned int len)
-{
-	struct net_device *dev = slave->dev;
-	struct sockaddr_storage ss;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_TLB) {
-		memcpy(dev->dev_addr, addr, len);
-		return 0;
-	}
-
-	/* for rlb each slave must have a unique hw mac addresses so that
-	 * each slave will receive packets destined to a different mac
-	 */
-	memcpy(ss.__data, addr, len);
-	ss.ss_family = dev->type;
-	if (dev_set_mac_address(dev, (struct sockaddr *)&ss, NULL)) {
-		slave_err(slave->bond->dev, dev, "dev_set_mac_address on slave failed! ALB mode requires that the base driver support setting the hw address also when the network device's interface is open\n");
-		return -EOPNOTSUPP;
-	}
-	return 0;
-}
-
-/* Swap MAC addresses between two slaves.
- *
- * Called with RTNL held, and no other locks.
- */
-static void alb_swap_mac_addr(struct slave *slave1, struct slave *slave2)
-{
-	u8 tmp_mac_addr[MAX_ADDR_LEN];
-
-	bond_hw_addr_copy(tmp_mac_addr, slave1->dev->dev_addr,
-			  slave1->dev->addr_len);
-	alb_set_slave_mac_addr(slave1, slave2->dev->dev_addr,
-			       slave2->dev->addr_len);
-	alb_set_slave_mac_addr(slave2, tmp_mac_addr,
-			       slave1->dev->addr_len);
-
-}
-
-/* Send learning packets after MAC address swap.
- *
- * Called with RTNL and no other locks
- */
-static void alb_fasten_mac_swap(struct bonding *bond, struct slave *slave1,
-				struct slave *slave2)
-{
-	int slaves_state_differ = (bond_slave_can_tx(slave1) != bond_slave_can_tx(slave2));
-	struct slave *disabled_slave = NULL;
-
-	ASSERT_RTNL();
-
-	/* fasten the change in the switch */
-	if (bond_slave_can_tx(slave1)) {
-		alb_send_learning_packets(slave1, slave1->dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform the clients that the mac address
-			 * has changed
-			 */
-			rlb_req_update_slave_clients(bond, slave1);
-		}
-	} else {
-		disabled_slave = slave1;
-	}
-
-	if (bond_slave_can_tx(slave2)) {
-		alb_send_learning_packets(slave2, slave2->dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform the clients that the mac address
-			 * has changed
-			 */
-			rlb_req_update_slave_clients(bond, slave2);
-		}
-	} else {
-		disabled_slave = slave2;
-	}
-
-	if (bond->alb_info.rlb_enabled && slaves_state_differ) {
-		/* A disabled slave was assigned an active mac addr */
-		rlb_teach_disabled_mac_on_primary(bond,
-						  disabled_slave->dev->dev_addr);
-	}
-}
-
-/**
- * alb_change_hw_addr_on_detach
- * @bond: bonding we're working on
- * @slave: the slave that was just detached
- *
- * We assume that @slave was already detached from the slave list.
- *
- * If @slave's permanent hw address is different both from its current
- * address and from @bond's address, then somewhere in the bond there's
- * a slave that has @slave's permanet address as its current address.
- * We'll make sure that that slave no longer uses @slave's permanent address.
- *
- * Caller must hold RTNL and no other locks
- */
-static void alb_change_hw_addr_on_detach(struct bonding *bond, struct slave *slave)
-{
-	int perm_curr_diff;
-	int perm_bond_diff;
-	struct slave *found_slave;
-
-	perm_curr_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
-						  slave->dev->dev_addr);
-	perm_bond_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
-						  bond->dev->dev_addr);
-
-	if (perm_curr_diff && perm_bond_diff) {
-		found_slave = bond_slave_has_mac(bond, slave->perm_hwaddr);
-
-		if (found_slave) {
-			alb_swap_mac_addr(slave, found_slave);
-			alb_fasten_mac_swap(bond, slave, found_slave);
-		}
-	}
-}
-
-/**
- * alb_handle_addr_collision_on_attach
- * @bond: bonding we're working on
- * @slave: the slave that was just attached
- *
- * checks uniqueness of slave's mac address and handles the case the
- * new slave uses the bonds mac address.
- *
- * If the permanent hw address of @slave is @bond's hw address, we need to
- * find a different hw address to give @slave, that isn't in use by any other
- * slave in the bond. This address must be, of course, one of the permanent
- * addresses of the other slaves.
- *
- * We go over the slave list, and for each slave there we compare its
- * permanent hw address with the current address of all the other slaves.
- * If no match was found, then we've found a slave with a permanent address
- * that isn't used by any other slave in the bond, so we can assign it to
- * @slave.
- *
- * assumption: this function is called before @slave is attached to the
- *	       bond slave list.
- */
-static int alb_handle_addr_collision_on_attach(struct bonding *bond, struct slave *slave)
-{
-	struct slave *has_bond_addr = rcu_access_pointer(bond->curr_active_slave);
-	struct slave *tmp_slave1, *free_mac_slave = NULL;
-	struct list_head *iter;
-
-	if (!bond_has_slaves(bond)) {
-		/* this is the first slave */
-		return 0;
-	}
-
-	/* if slave's mac address differs from bond's mac address
-	 * check uniqueness of slave's mac address against the other
-	 * slaves in the bond.
-	 */
-	if (!ether_addr_equal_64bits(slave->perm_hwaddr, bond->dev->dev_addr)) {
-		if (!bond_slave_has_mac(bond, slave->dev->dev_addr))
-			return 0;
-
-		/* Try setting slave mac to bond address and fall-through
-		 * to code handling that situation below...
-		 */
-		alb_set_slave_mac_addr(slave, bond->dev->dev_addr,
-				       bond->dev->addr_len);
-	}
-
-	/* The slave's address is equal to the address of the bond.
-	 * Search for a spare address in the bond for this slave.
-	 */
-	bond_for_each_slave(bond, tmp_slave1, iter) {
-		if (!bond_slave_has_mac(bond, tmp_slave1->perm_hwaddr)) {
-			/* no slave has tmp_slave1's perm addr
-			 * as its curr addr
-			 */
-			free_mac_slave = tmp_slave1;
-			break;
-		}
-
-		if (!has_bond_addr) {
-			if (ether_addr_equal_64bits(tmp_slave1->dev->dev_addr,
-						    bond->dev->dev_addr)) {
-
-				has_bond_addr = tmp_slave1;
-			}
-		}
-	}
-
-	if (free_mac_slave) {
-		alb_set_slave_mac_addr(slave, free_mac_slave->perm_hwaddr,
-				       free_mac_slave->dev->addr_len);
-
-		slave_warn(bond->dev, slave->dev, "the slave hw address is in use by the bond; giving it the hw address of %s\n",
-			   free_mac_slave->dev->name);
-
-	} else if (has_bond_addr) {
-		slave_err(bond->dev, slave->dev, "the slave hw address is in use by the bond; couldn't find a slave with a free hw address to give it (this should not have happened)\n");
-		return -EFAULT;
-	}
-
-	return 0;
-}
-
-/**
- * alb_set_mac_address
- * @bond:
- * @addr:
- *
- * In TLB mode all slaves are configured to the bond's hw address, but set
- * their dev_addr field to different addresses (based on their permanent hw
- * addresses).
- *
- * For each slave, this function sets the interface to the new address and then
- * changes its dev_addr field to its previous value.
- *
- * Unwinding assumes bond's mac address has not yet changed.
- */
-static int alb_set_mac_address(struct bonding *bond, void *addr)
-{
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	struct sockaddr_storage ss;
-	char tmp_addr[MAX_ADDR_LEN];
-	int res;
-
-	if (bond->alb_info.rlb_enabled)
-		return 0;
-
-	bond_for_each_slave(bond, slave, iter) {
-		/* save net_device's current hw address */
-		bond_hw_addr_copy(tmp_addr, slave->dev->dev_addr,
-				  slave->dev->addr_len);
-
-		res = dev_set_mac_address(slave->dev, addr, NULL);
-
-		/* restore net_device's hw address */
-		bond_hw_addr_copy(slave->dev->dev_addr, tmp_addr,
-				  slave->dev->addr_len);
-
-		if (res)
-			goto unwind;
-	}
-
-	return 0;
-
-unwind:
-	memcpy(ss.__data, bond->dev->dev_addr, bond->dev->addr_len);
-	ss.ss_family = bond->dev->type;
-
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		if (rollback_slave == slave)
-			break;
-		bond_hw_addr_copy(tmp_addr, rollback_slave->dev->dev_addr,
-				  rollback_slave->dev->addr_len);
-		dev_set_mac_address(rollback_slave->dev,
-				    (struct sockaddr *)&ss, NULL);
-		bond_hw_addr_copy(rollback_slave->dev->dev_addr, tmp_addr,
-				  rollback_slave->dev->addr_len);
-	}
-
-	return res;
-}
-
-/************************ exported alb funcions ************************/
-
-int bond_alb_initialize(struct bonding *bond, int rlb_enabled)
-{
-	int res;
-
-	res = tlb_initialize(bond);
-	if (res)
-		return res;
-
-	if (rlb_enabled) {
-		bond->alb_info.rlb_enabled = 1;
-		res = rlb_initialize(bond);
-		if (res) {
-			tlb_deinitialize(bond);
-			return res;
-		}
-	} else {
-		bond->alb_info.rlb_enabled = 0;
-	}
-
-	return 0;
-}
-
-void bond_alb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	tlb_deinitialize(bond);
-
-	if (bond_info->rlb_enabled)
-		rlb_deinitialize(bond);
-}
-
-static netdev_tx_t bond_do_alb_xmit(struct sk_buff *skb, struct bonding *bond,
-				    struct slave *tx_slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct ethhdr *eth_data = eth_hdr(skb);
-
-	if (!tx_slave) {
-		/* unbalanced or unassigned, send through primary */
-		tx_slave = rcu_dereference(bond->curr_active_slave);
-		if (bond->params.tlb_dynamic_lb)
-			bond_info->unbalanced_load += skb->len;
-	}
-
-	if (tx_slave && bond_slave_can_tx(tx_slave)) {
-		if (tx_slave != rcu_access_pointer(bond->curr_active_slave)) {
-			ether_addr_copy(eth_data->h_source,
-					tx_slave->dev->dev_addr);
-		}
-
-		bond_dev_queue_xmit(bond, skb, tx_slave->dev);
-		goto out;
-	}
-
-	if (tx_slave && bond->params.tlb_dynamic_lb) {
-		spin_lock(&bond->mode_lock);
-		__tlb_clear_slave(bond, tx_slave, 0);
-		spin_unlock(&bond->mode_lock);
-	}
-
-	/* no suitable interface, frame not sent */
-	bond_tx_drop(bond->dev, skb);
-out:
-	return NETDEV_TX_OK;
-}
-
-netdev_tx_t bond_tlb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct ethhdr *eth_data;
-	struct slave *tx_slave = NULL;
-	u32 hash_index;
-
-	skb_reset_mac_header(skb);
-	eth_data = eth_hdr(skb);
-
-	/* Do not TX balance any multicast or broadcast */
-	if (!is_multicast_ether_addr(eth_data->h_dest)) {
-		switch (skb->protocol) {
-		case htons(ETH_P_IP):
-		case htons(ETH_P_IPX):
-		    /* In case of IPX, it will falback to L2 hash */
-		case htons(ETH_P_IPV6):
-			hash_index = bond_xmit_hash(bond, skb);
-			if (bond->params.tlb_dynamic_lb) {
-				tx_slave = tlb_choose_channel(bond,
-							      hash_index & 0xFF,
-							      skb->len);
-			} else {
-				struct bond_up_slave *slaves;
-				unsigned int count;
-
-				slaves = rcu_dereference(bond->slave_arr);
-				count = slaves ? READ_ONCE(slaves->count) : 0;
-				if (likely(count))
-					tx_slave = slaves->arr[hash_index %
-							       count];
-			}
-			break;
-		}
-	}
-	return bond_do_alb_xmit(skb, bond, tx_slave);
-}
-
-netdev_tx_t bond_alb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct ethhdr *eth_data;
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *tx_slave = NULL;
-	static const __be32 ip_bcast = htonl(0xffffffff);
-	int hash_size = 0;
-	bool do_tx_balance = true;
-	u32 hash_index = 0;
-	const u8 *hash_start = NULL;
-	struct ipv6hdr *ip6hdr;
-
-	skb_reset_mac_header(skb);
-	eth_data = eth_hdr(skb);
-
-	switch (ntohs(skb->protocol)) {
-	case ETH_P_IP: {
-		const struct iphdr *iph = ip_hdr(skb);
-
-		if (is_broadcast_ether_addr(eth_data->h_dest) ||
-		    iph->daddr == ip_bcast ||
-		    iph->protocol == IPPROTO_IGMP) {
-			do_tx_balance = false;
-			break;
-		}
-		hash_start = (char *)&(iph->daddr);
-		hash_size = sizeof(iph->daddr);
-	}
-		break;
-	case ETH_P_IPV6:
-		/* IPv6 doesn't really use broadcast mac address, but leave
-		 * that here just in case.
-		 */
-		if (is_broadcast_ether_addr(eth_data->h_dest)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		/* IPv6 uses all-nodes multicast as an equivalent to
-		 * broadcasts in IPv4.
-		 */
-		if (ether_addr_equal_64bits(eth_data->h_dest, mac_v6_allmcast)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		/* Additianally, DAD probes should not be tx-balanced as that
-		 * will lead to false positives for duplicate addresses and
-		 * prevent address configuration from working.
-		 */
-		ip6hdr = ipv6_hdr(skb);
-		if (ipv6_addr_any(&ip6hdr->saddr)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		hash_start = (char *)&(ipv6_hdr(skb)->daddr);
-		hash_size = sizeof(ipv6_hdr(skb)->daddr);
-		break;
-	case ETH_P_IPX:
-		if (ipx_hdr(skb)->ipx_checksum != IPX_NO_CHECKSUM) {
-			/* something is wrong with this packet */
-			do_tx_balance = false;
-			break;
-		}
-
-		if (ipx_hdr(skb)->ipx_type != IPX_TYPE_NCP) {
-			/* The only protocol worth balancing in
-			 * this family since it has an "ARP" like
-			 * mechanism
-			 */
-			do_tx_balance = false;
-			break;
-		}
-
-		hash_start = (char *)eth_data->h_dest;
-		hash_size = ETH_ALEN;
-		break;
-	case ETH_P_ARP:
-		do_tx_balance = false;
-		if (bond_info->rlb_enabled)
-			tx_slave = rlb_arp_xmit(skb, bond);
-		break;
-	default:
-		do_tx_balance = false;
-		break;
-	}
-
-	if (do_tx_balance) {
-		if (bond->params.tlb_dynamic_lb) {
-			hash_index = _simple_hash(hash_start, hash_size);
-			tx_slave = tlb_choose_channel(bond, hash_index, skb->len);
-		} else {
-			/*
-			 * do_tx_balance means we are free to select the tx_slave
-			 * So we do exactly what tlb would do for hash selection
-			 */
-
-			struct bond_up_slave *slaves;
-			unsigned int count;
-
-			slaves = rcu_dereference(bond->slave_arr);
-			count = slaves ? READ_ONCE(slaves->count) : 0;
-			if (likely(count))
-				tx_slave = slaves->arr[bond_xmit_hash(bond, skb) %
-						       count];
-		}
-	}
-
-	return bond_do_alb_xmit(skb, bond, tx_slave);
-}
-
-void bond_alb_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    alb_work.work);
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (!bond_has_slaves(bond)) {
-		bond_info->tx_rebalance_counter = 0;
-		bond_info->lp_counter = 0;
-		goto re_arm;
-	}
-
-	rcu_read_lock();
-
-	bond_info->tx_rebalance_counter++;
-	bond_info->lp_counter++;
-
-	/* send learning packets */
-	if (bond_info->lp_counter >= BOND_ALB_LP_TICKS(bond)) {
-		bool strict_match;
-
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			/* If updating current_active, use all currently
-			 * user mac addreses (!strict_match).  Otherwise, only
-			 * use mac of the slave device.
-			 * In RLB mode, we always use strict matches.
-			 */
-			strict_match = (slave != rcu_access_pointer(bond->curr_active_slave) ||
-					bond_info->rlb_enabled);
-			alb_send_learning_packets(slave, slave->dev->dev_addr,
-						  strict_match);
-		}
-		bond_info->lp_counter = 0;
-	}
-
-	/* rebalance tx traffic */
-	if (bond_info->tx_rebalance_counter >= BOND_TLB_REBALANCE_TICKS) {
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			tlb_clear_slave(bond, slave, 1);
-			if (slave == rcu_access_pointer(bond->curr_active_slave)) {
-				SLAVE_TLB_INFO(slave).load =
-					bond_info->unbalanced_load /
-						BOND_TLB_REBALANCE_INTERVAL;
-				bond_info->unbalanced_load = 0;
-			}
-		}
-		bond_info->tx_rebalance_counter = 0;
-	}
-
-	if (bond_info->rlb_enabled) {
-		if (bond_info->primary_is_promisc &&
-		    (++bond_info->rlb_promisc_timeout_counter >= RLB_PROMISC_TIMEOUT)) {
-
-			/* dev_set_promiscuity requires rtnl and
-			 * nothing else.  Avoid race with bond_close.
-			 */
-			rcu_read_unlock();
-			if (!rtnl_trylock())
-				goto re_arm;
-
-			bond_info->rlb_promisc_timeout_counter = 0;
-
-			/* If the primary was set to promiscuous mode
-			 * because a slave was disabled then
-			 * it can now leave promiscuous mode.
-			 */
-			dev_set_promiscuity(rtnl_dereference(bond->curr_active_slave)->dev,
-					    -1);
-			bond_info->primary_is_promisc = 0;
-
-			rtnl_unlock();
-			rcu_read_lock();
-		}
-
-		if (bond_info->rlb_rebalance) {
-			bond_info->rlb_rebalance = 0;
-			rlb_rebalance(bond);
-		}
-
-		/* check if clients need updating */
-		if (bond_info->rx_ntt) {
-			if (bond_info->rlb_update_delay_counter) {
-				--bond_info->rlb_update_delay_counter;
-			} else {
-				rlb_update_rx_clients(bond);
-				if (bond_info->rlb_update_retry_counter)
-					--bond_info->rlb_update_retry_counter;
-				else
-					bond_info->rx_ntt = 0;
-			}
-		}
-	}
-	rcu_read_unlock();
-re_arm:
-	queue_delayed_work(bond->wq, &bond->alb_work, alb_delta_in_ticks);
-}
-
-/* assumption: called before the slave is attached to the bond
- * and not locked by the bond lock
- */
-int bond_alb_init_slave(struct bonding *bond, struct slave *slave)
-{
-	int res;
-
-	res = alb_set_slave_mac_addr(slave, slave->perm_hwaddr,
-				     slave->dev->addr_len);
-	if (res)
-		return res;
-
-	res = alb_handle_addr_collision_on_attach(bond, slave);
-	if (res)
-		return res;
-
-	tlb_init_slave(slave);
-
-	/* order a rebalance ASAP */
-	bond->alb_info.tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
-
-	if (bond->alb_info.rlb_enabled)
-		bond->alb_info.rlb_rebalance = 1;
-
-	return 0;
-}
-
-/* Remove slave from tlb and rlb hash tables, and fix up MAC addresses
- * if necessary.
- *
- * Caller must hold RTNL and no other locks
- */
-void bond_alb_deinit_slave(struct bonding *bond, struct slave *slave)
-{
-	if (bond_has_slaves(bond))
-		alb_change_hw_addr_on_detach(bond, slave);
-
-	tlb_clear_slave(bond, slave, 0);
-
-	if (bond->alb_info.rlb_enabled) {
-		bond->alb_info.rx_slave = NULL;
-		rlb_clear_slave(bond, slave);
-	}
-
-}
-
-void bond_alb_handle_link_change(struct bonding *bond, struct slave *slave, char link)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	if (link == BOND_LINK_DOWN) {
-		tlb_clear_slave(bond, slave, 0);
-		if (bond->alb_info.rlb_enabled)
-			rlb_clear_slave(bond, slave);
-	} else if (link == BOND_LINK_UP) {
-		/* order a rebalance ASAP */
-		bond_info->tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
-		if (bond->alb_info.rlb_enabled) {
-			bond->alb_info.rlb_rebalance = 1;
-			/* If the updelay module parameter is smaller than the
-			 * forwarding delay of the switch the rebalance will
-			 * not work because the rebalance arp replies will
-			 * not be forwarded to the clients..
-			 */
-		}
-	}
-
-	if (bond_is_nondyn_tlb(bond)) {
-		if (bond_update_slave_arr(bond, NULL))
-			pr_err("Failed to build slave-array for TLB mode.\n");
-	}
-}
-
-/**
- * bond_alb_handle_active_change - assign new curr_active_slave
- * @bond: our bonding struct
- * @new_slave: new slave to assign
- *
- * Set the bond->curr_active_slave to @new_slave and handle
- * mac address swapping and promiscuity changes as needed.
- *
- * Caller must hold RTNL
- */
-void bond_alb_handle_active_change(struct bonding *bond, struct slave *new_slave)
-{
-	struct slave *swap_slave;
-	struct slave *curr_active;
-
-	curr_active = rtnl_dereference(bond->curr_active_slave);
-	if (curr_active == new_slave)
-		return;
-
-	if (curr_active && bond->alb_info.primary_is_promisc) {
-		dev_set_promiscuity(curr_active->dev, -1);
-		bond->alb_info.primary_is_promisc = 0;
-		bond->alb_info.rlb_promisc_timeout_counter = 0;
-	}
-
-	swap_slave = curr_active;
-	rcu_assign_pointer(bond->curr_active_slave, new_slave);
-
-	if (!new_slave || !bond_has_slaves(bond))
-		return;
-
-	/* set the new curr_active_slave to the bonds mac address
-	 * i.e. swap mac addresses of old curr_active_slave and new curr_active_slave
-	 */
-	if (!swap_slave)
-		swap_slave = bond_slave_has_mac(bond, bond->dev->dev_addr);
-
-	/* Arrange for swap_slave and new_slave to temporarily be
-	 * ignored so we can mess with their MAC addresses without
-	 * fear of interference from transmit activity.
-	 */
-	if (swap_slave)
-		tlb_clear_slave(bond, swap_slave, 1);
-	tlb_clear_slave(bond, new_slave, 1);
-
-	/* in TLB mode, the slave might flip down/up with the old dev_addr,
-	 * and thus filter bond->dev_addr's packets, so force bond's mac
-	 */
-	if (BOND_MODE(bond) == BOND_MODE_TLB) {
-		struct sockaddr_storage ss;
-		u8 tmp_addr[MAX_ADDR_LEN];
-
-		bond_hw_addr_copy(tmp_addr, new_slave->dev->dev_addr,
-				  new_slave->dev->addr_len);
-
-		bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
-				  bond->dev->addr_len);
-		ss.ss_family = bond->dev->type;
-		/* we don't care if it can't change its mac, best effort */
-		dev_set_mac_address(new_slave->dev, (struct sockaddr *)&ss,
-				    NULL);
-
-		bond_hw_addr_copy(new_slave->dev->dev_addr, tmp_addr,
-				  new_slave->dev->addr_len);
-	}
-
-	/* curr_active_slave must be set before calling alb_swap_mac_addr */
-	if (swap_slave) {
-		/* swap mac address */
-		alb_swap_mac_addr(swap_slave, new_slave);
-		alb_fasten_mac_swap(bond, swap_slave, new_slave);
-	} else {
-		/* set the new_slave to the bond mac address */
-		alb_set_slave_mac_addr(new_slave, bond->dev->dev_addr,
-				       bond->dev->addr_len);
-		alb_send_learning_packets(new_slave, bond->dev->dev_addr,
-					  false);
-	}
-}
-
-/* Called with RTNL */
-int bond_alb_set_mac_address(struct net_device *bond_dev, void *addr)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct sockaddr_storage *ss = addr;
-	struct slave *curr_active;
-	struct slave *swap_slave;
-	int res;
-
-	if (!is_valid_ether_addr(ss->__data))
-		return -EADDRNOTAVAIL;
-
-	res = alb_set_mac_address(bond, addr);
-	if (res)
-		return res;
-
-	bond_hw_addr_copy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
-
-	/* If there is no curr_active_slave there is nothing else to do.
-	 * Otherwise we'll need to pass the new address to it and handle
-	 * duplications.
-	 */
-	curr_active = rtnl_dereference(bond->curr_active_slave);
-	if (!curr_active)
-		return 0;
-
-	swap_slave = bond_slave_has_mac(bond, bond_dev->dev_addr);
-
-	if (swap_slave) {
-		alb_swap_mac_addr(swap_slave, curr_active);
-		alb_fasten_mac_swap(bond, swap_slave, curr_active);
-	} else {
-		alb_set_slave_mac_addr(curr_active, bond_dev->dev_addr,
-				       bond_dev->addr_len);
-
-		alb_send_learning_packets(curr_active,
-					  bond_dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform clients mac address has changed */
-			rlb_req_update_slave_clients(bond, curr_active);
-		}
-	}
-
-	return 0;
-}
-
-void bond_alb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
-{
-	if (bond->alb_info.rlb_enabled)
-		rlb_clear_vlan(bond, vlan_id);
-}
-
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bond_debugfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bond_debugfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,125 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/device.h>
-#include <linux/netdevice.h>
-
-#include <net/bonding.h>
-#include <net/bond_alb.h>
-
-#if defined(CONFIG_DEBUG_FS) && !defined(CONFIG_NET_NS)
-
-#include <linux/debugfs.h>
-#include <linux/seq_file.h>
-
-static struct dentry *bonding_debug_root;
-
-/* Show RLB hash table */
-static int bond_debug_rlb_hash_show(struct seq_file *m, void *v)
-{
-	struct bonding *bond = m->private;
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	if (BOND_MODE(bond) != BOND_MODE_ALB)
-		return 0;
-
-	seq_printf(m, "SourceIP        DestinationIP   "
-			"Destination MAC   DEV\n");
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		seq_printf(m, "%-15pI4 %-15pI4 %-17pM %s\n",
-			&client_info->ip_src,
-			&client_info->ip_dst,
-			&client_info->mac_dst,
-			client_info->slave->dev->name);
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	return 0;
-}
-DEFINE_SHOW_ATTRIBUTE(bond_debug_rlb_hash);
-
-void bond_debug_register(struct bonding *bond)
-{
-	if (!bonding_debug_root)
-		return;
-
-	bond->debug_dir =
-		debugfs_create_dir(bond->dev->name, bonding_debug_root);
-
-	debugfs_create_file("rlb_hash_table", 0400, bond->debug_dir,
-				bond, &bond_debug_rlb_hash_fops);
-}
-
-void bond_debug_unregister(struct bonding *bond)
-{
-	if (!bonding_debug_root)
-		return;
-
-	debugfs_remove_recursive(bond->debug_dir);
-}
-
-void bond_debug_reregister(struct bonding *bond)
-{
-	struct dentry *d;
-
-	if (!bonding_debug_root)
-		return;
-
-	d = debugfs_rename(bonding_debug_root, bond->debug_dir,
-			   bonding_debug_root, bond->dev->name);
-	if (d) {
-		bond->debug_dir = d;
-	} else {
-		netdev_warn(bond->dev, "failed to reregister, so just unregister old one\n");
-		bond_debug_unregister(bond);
-	}
-}
-
-void bond_create_debugfs(void)
-{
-	bonding_debug_root = debugfs_create_dir("bonding", NULL);
-
-	if (!bonding_debug_root) {
-		pr_warn("Warning: Cannot create bonding directory in debugfs\n");
-	}
-}
-
-void bond_destroy_debugfs(void)
-{
-	debugfs_remove_recursive(bonding_debug_root);
-	bonding_debug_root = NULL;
-}
-
-
-#else /* !CONFIG_DEBUG_FS */
-
-void bond_debug_register(struct bonding *bond)
-{
-}
-
-void bond_debug_unregister(struct bonding *bond)
-{
-}
-
-void bond_debug_reregister(struct bonding *bond)
-{
-}
-
-void bond_create_debugfs(void)
-{
-}
-
-void bond_destroy_debugfs(void)
-{
-}
-
-#endif /* CONFIG_DEBUG_FS */
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,5037 +0,0 @@
-/*
- * originally based on the dummy device.
- *
- * Copyright 1999, Thomas Davis, tadavis@lbl.gov.
- * Licensed under the GPL. Based on dummy.c, and eql.c devices.
- *
- * bonding.c: an Ethernet Bonding driver
- *
- * This is useful to talk to a Cisco EtherChannel compatible equipment:
- *	Cisco 5500
- *	Sun Trunking (Solaris)
- *	Alteon AceDirector Trunks
- *	Linux Bonding
- *	and probably many L2 switches ...
- *
- * How it works:
- *    ifconfig bond0 ipaddress netmask up
- *      will setup a network device, with an ip address.  No mac address
- *	will be assigned at this time.  The hw mac address will come from
- *	the first slave bonded to the channel.  All slaves will then use
- *	this hw mac address.
- *
- *    ifconfig bond0 down
- *         will release all slaves, marking them as down.
- *
- *    ifenslave bond0 eth0
- *	will attach eth0 to bond0 as a slave.  eth0 hw mac address will either
- *	a: be used as initial mac address
- *	b: if a hw mac address already is there, eth0's hw mac address
- *	   will then be set from bond0.
- *
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/types.h>
-#include <linux/fcntl.h>
-#include <linux/interrupt.h>
-#include <linux/ptrace.h>
-#include <linux/ioport.h>
-#include <linux/in.h>
-#include <net/ip.h>
-#include <linux/ip.h>
-#include <linux/tcp.h>
-#include <linux/udp.h>
-#include <linux/slab.h>
-#include <linux/string.h>
-#include <linux/init.h>
-#include <linux/timer.h>
-#include <linux/socket.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/bitops.h>
-#include <linux/io.h>
-#include <asm/dma.h>
-#include <linux/uaccess.h>
-#include <linux/errno.h>
-#include <linux/netdevice.h>
-#include <linux/inetdevice.h>
-#include <linux/igmp.h>
-#include <linux/etherdevice.h>
-#include <linux/skbuff.h>
-#include <net/sock.h>
-#include <linux/rtnetlink.h>
-#include <linux/smp.h>
-#include <linux/if_ether.h>
-#include <net/arp.h>
-#include <linux/mii.h>
-#include <linux/ethtool.h>
-#include <linux/if_vlan.h>
-#include <linux/if_bonding.h>
-#include <linux/jiffies.h>
-#include <linux/preempt.h>
-#include <net/route.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <net/pkt_sched.h>
-#include <linux/rculist.h>
-#include <linux/toedev.h>
-#include <net/flow_dissector.h>
-#include <net/bonding.h>
-#include <net/bond_3ad.h>
-#include <net/bond_alb.h>
-
-#include "bonding_priv.h"
-
-/*---------------------------- Module parameters ----------------------------*/
-
-/* monitor all links that often (in milliseconds). <=0 disables monitoring */
-
-static int max_bonds	= BOND_DEFAULT_MAX_BONDS;
-static int tx_queues	= BOND_DEFAULT_TX_QUEUES;
-static int num_peer_notif = 1;
-static int miimon;
-static int updelay;
-static int downdelay;
-static int use_carrier	= 1;
-static char *mode;
-static char *primary;
-static char *primary_reselect;
-static char *lacp_rate;
-static int min_links;
-static char *ad_select;
-static char *xmit_hash_policy;
-static int arp_interval;
-static char *arp_ip_target[BOND_MAX_ARP_TARGETS];
-static char *arp_validate;
-static char *arp_all_targets;
-static char *fail_over_mac;
-static int all_slaves_active;
-static struct bond_params bonding_defaults;
-static int resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-static int packets_per_slave = 1;
-static int lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-
-module_param(max_bonds, int, 0);
-MODULE_PARM_DESC(max_bonds, "Max number of bonded devices");
-module_param(tx_queues, int, 0);
-MODULE_PARM_DESC(tx_queues, "Max number of transmit queues (default = 16)");
-module_param_named(num_grat_arp, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_grat_arp, "Number of peer notifications to send on "
-			       "failover event (alias of num_unsol_na)");
-module_param_named(num_unsol_na, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_unsol_na, "Number of peer notifications to send on "
-			       "failover event (alias of num_grat_arp)");
-module_param(miimon, int, 0);
-MODULE_PARM_DESC(miimon, "Link check interval in milliseconds");
-module_param(updelay, int, 0);
-MODULE_PARM_DESC(updelay, "Delay before considering link up, in milliseconds");
-module_param(downdelay, int, 0);
-MODULE_PARM_DESC(downdelay, "Delay before considering link down, "
-			    "in milliseconds");
-module_param(use_carrier, int, 0);
-MODULE_PARM_DESC(use_carrier, "Use netif_carrier_ok (vs MII ioctls) in miimon; "
-			      "0 for off, 1 for on (default)");
-module_param(mode, charp, 0);
-MODULE_PARM_DESC(mode, "Mode of operation; 0 for balance-rr, "
-		       "1 for active-backup, 2 for balance-xor, "
-		       "3 for broadcast, 4 for 802.3ad, 5 for balance-tlb, "
-		       "6 for balance-alb");
-module_param(primary, charp, 0);
-MODULE_PARM_DESC(primary, "Primary network device to use");
-module_param(primary_reselect, charp, 0);
-MODULE_PARM_DESC(primary_reselect, "Reselect primary slave "
-				   "once it comes up; "
-				   "0 for always (default), "
-				   "1 for only if speed of primary is "
-				   "better, "
-				   "2 for only on active slave "
-				   "failure");
-module_param(lacp_rate, charp, 0);
-MODULE_PARM_DESC(lacp_rate, "LACPDU tx rate to request from 802.3ad partner; "
-			    "0 for slow, 1 for fast");
-module_param(ad_select, charp, 0);
-MODULE_PARM_DESC(ad_select, "802.3ad aggregation selection logic; "
-			    "0 for stable (default), 1 for bandwidth, "
-			    "2 for count");
-module_param(min_links, int, 0);
-MODULE_PARM_DESC(min_links, "Minimum number of available links before turning on carrier");
-
-module_param(xmit_hash_policy, charp, 0);
-MODULE_PARM_DESC(xmit_hash_policy, "balance-alb, balance-tlb, balance-xor, 802.3ad hashing method; "
-				   "0 for layer 2 (default), 1 for layer 3+4, "
-				   "2 for layer 2+3, 3 for encap layer 2+3, "
-				   "4 for encap layer 3+4");
-module_param(arp_interval, int, 0);
-MODULE_PARM_DESC(arp_interval, "arp interval in milliseconds");
-module_param_array(arp_ip_target, charp, NULL, 0);
-MODULE_PARM_DESC(arp_ip_target, "arp targets in n.n.n.n form");
-module_param(arp_validate, charp, 0);
-MODULE_PARM_DESC(arp_validate, "validate src/dst of ARP probes; "
-			       "0 for none (default), 1 for active, "
-			       "2 for backup, 3 for all");
-module_param(arp_all_targets, charp, 0);
-MODULE_PARM_DESC(arp_all_targets, "fail on any/all arp targets timeout; 0 for any (default), 1 for all");
-module_param(fail_over_mac, charp, 0);
-MODULE_PARM_DESC(fail_over_mac, "For active-backup, do not set all slaves to "
-				"the same MAC; 0 for none (default), "
-				"1 for active, 2 for follow");
-module_param(all_slaves_active, int, 0);
-MODULE_PARM_DESC(all_slaves_active, "Keep all frames received on an interface "
-				     "by setting active flag for all slaves; "
-				     "0 for never (default), 1 for always.");
-module_param(resend_igmp, int, 0);
-MODULE_PARM_DESC(resend_igmp, "Number of IGMP membership reports to send on "
-			      "link failure");
-module_param(packets_per_slave, int, 0);
-MODULE_PARM_DESC(packets_per_slave, "Packets to send per slave in balance-rr "
-				    "mode; 0 for a random slave, 1 packet per "
-				    "slave (default), >1 packets per slave.");
-module_param(lp_interval, uint, 0);
-MODULE_PARM_DESC(lp_interval, "The number of seconds between instances where "
-			      "the bonding driver sends learning packets to "
-			      "each slaves peer switch. The default is 1.");
-
-/*----------------------------- Global variables ----------------------------*/
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-atomic_t netpoll_block_tx = ATOMIC_INIT(0);
-#endif
-
-unsigned int bond_net_id __read_mostly;
-
-/*-------------------------- Forward declarations ---------------------------*/
-
-static int bond_init(struct net_device *bond_dev);
-static void bond_uninit(struct net_device *bond_dev);
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats);
-static void bond_slave_arr_handler(struct work_struct *work);
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod);
-static void bond_netdev_notify_work(struct work_struct *work);
-
-/*---------------------------- General routines -----------------------------*/
-
-const char *bond_mode_name(int mode)
-{
-	static const char *names[] = {
-		[BOND_MODE_ROUNDROBIN] = "load balancing (round-robin)",
-		[BOND_MODE_ACTIVEBACKUP] = "fault-tolerance (active-backup)",
-		[BOND_MODE_XOR] = "load balancing (xor)",
-		[BOND_MODE_BROADCAST] = "fault-tolerance (broadcast)",
-		[BOND_MODE_8023AD] = "IEEE 802.3ad Dynamic link aggregation",
-		[BOND_MODE_TLB] = "transmit load balancing",
-		[BOND_MODE_ALB] = "adaptive load balancing",
-	};
-
-	if (mode < BOND_MODE_ROUNDROBIN || mode > BOND_MODE_ALB)
-		return "unknown";
-
-	return names[mode];
-}
-
-/*---------------------------------- VLAN -----------------------------------*/
-
-/**
- * bond_dev_queue_xmit - Prepare skb for xmit.
- *
- * @bond: bond device that got this skb for tx.
- * @skb: hw accel VLAN tagged skb to transmit
- * @slave_dev: slave that is supposed to xmit this skbuff
- */
-void bond_dev_queue_xmit(struct bonding *bond, struct sk_buff *skb,
-			struct net_device *slave_dev)
-{
-	skb->dev = slave_dev;
-
-	BUILD_BUG_ON(sizeof(skb->queue_mapping) !=
-		     sizeof(qdisc_skb_cb(skb)->slave_dev_queue_mapping));
-	skb_set_queue_mapping(skb, qdisc_skb_cb(skb)->slave_dev_queue_mapping);
-
-	if (unlikely(netpoll_tx_running(bond->dev)))
-		bond_netpoll_send_skb(bond_get_slave_by_dev(bond, slave_dev), skb);
-	else
-		dev_queue_xmit(skb);
-}
-
-/* In the following 2 functions, bond_vlan_rx_add_vid and bond_vlan_rx_kill_vid,
- * We don't protect the slave list iteration with a lock because:
- * a. This operation is performed in IOCTL context,
- * b. The operation is protected by the RTNL semaphore in the 8021q code,
- * c. Holding a lock with BH disabled while directly calling a base driver
- *    entry point is generally a BAD idea.
- *
- * The design of synchronization/protection for this operation in the 8021q
- * module is good for one or more VLAN devices over a single physical device
- * and cannot be extended for a teaming solution like bonding, so there is a
- * potential race condition here where a net device from the vlan group might
- * be referenced (either by a base driver or the 8021q code) while it is being
- * removed from the system. However, it turns out we're not making matters
- * worse, and if it works for regular VLAN usage it will work here too.
-*/
-
-/**
- * bond_vlan_rx_add_vid - Propagates adding an id to slaves
- * @bond_dev: bonding net device that got called
- * @vid: vlan id being added
- */
-static int bond_vlan_rx_add_vid(struct net_device *bond_dev,
-				__be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res;
-
-	bond_for_each_slave(bond, slave, iter) {
-		res = vlan_vid_add(slave->dev, proto, vid);
-		if (res)
-			goto unwind;
-	}
-
-	return 0;
-
-unwind:
-	/* unwind to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		if (rollback_slave == slave)
-			break;
-
-		vlan_vid_del(rollback_slave->dev, proto, vid);
-	}
-
-	return res;
-}
-
-/**
- * bond_vlan_rx_kill_vid - Propagates deleting an id to slaves
- * @bond_dev: bonding net device that got called
- * @vid: vlan id being removed
- */
-static int bond_vlan_rx_kill_vid(struct net_device *bond_dev,
-				 __be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		vlan_vid_del(slave->dev, proto, vid);
-
-	if (bond_is_lb(bond))
-		bond_alb_clear_vlan(bond, vid);
-
-	return 0;
-}
-
-/*------------------------------- Link status -------------------------------*/
-
-/* Set the carrier state for the master according to the state of its
- * slaves.  If any slaves are up, the master is up.  In 802.3ad mode,
- * do special 802.3ad magic.
- *
- * Returns zero if carrier state does not change, nonzero if it does.
- */
-int bond_set_carrier(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (!bond_has_slaves(bond))
-		goto down;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		return bond_3ad_set_carrier(bond);
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP) {
-			if (!netif_carrier_ok(bond->dev)) {
-				netif_carrier_on(bond->dev);
-				return 1;
-			}
-			return 0;
-		}
-	}
-
-down:
-	if (netif_carrier_ok(bond->dev)) {
-		netif_carrier_off(bond->dev);
-		return 1;
-	}
-	return 0;
-}
-
-/* Get link speed and duplex from the slave's base driver
- * using ethtool. If for some reason the call fails or the
- * values are invalid, set speed and duplex to -1,
- * and return. Return 1 if speed or duplex settings are
- * UNKNOWN; 0 otherwise.
- */
-static int bond_update_speed_duplex(struct slave *slave)
-{
-	struct net_device *slave_dev = slave->dev;
-	struct ethtool_link_ksettings ecmd;
-	int res;
-
-	slave->speed = SPEED_UNKNOWN;
-	slave->duplex = DUPLEX_UNKNOWN;
-
-	res = __ethtool_get_link_ksettings(slave_dev, &ecmd);
-	if (res < 0)
-		return 1;
-	if (ecmd.base.speed == 0 || ecmd.base.speed == ((__u32)-1))
-		return 1;
-	switch (ecmd.base.duplex) {
-	case DUPLEX_FULL:
-	case DUPLEX_HALF:
-		break;
-	default:
-		return 1;
-	}
-
-	slave->speed = ecmd.base.speed;
-	slave->duplex = ecmd.base.duplex;
-
-	return 0;
-}
-
-const char *bond_slave_link_status(s8 link)
-{
-	switch (link) {
-	case BOND_LINK_UP:
-		return "up";
-	case BOND_LINK_FAIL:
-		return "going down";
-	case BOND_LINK_DOWN:
-		return "down";
-	case BOND_LINK_BACK:
-		return "going back";
-	default:
-		return "unknown";
-	}
-}
-
-/* if <dev> supports MII link status reporting, check its link status.
- *
- * We either do MII/ETHTOOL ioctls, or check netif_carrier_ok(),
- * depending upon the setting of the use_carrier parameter.
- *
- * Return either BMSR_LSTATUS, meaning that the link is up (or we
- * can't tell and just pretend it is), or 0, meaning that the link is
- * down.
- *
- * If reporting is non-zero, instead of faking link up, return -1 if
- * both ETHTOOL and MII ioctls fail (meaning the device does not
- * support them).  If use_carrier is set, return whatever it says.
- * It'd be nice if there was a good way to tell if a driver supports
- * netif_carrier, but there really isn't.
- */
-static int bond_check_dev_link(struct bonding *bond,
-			       struct net_device *slave_dev, int reporting)
-{
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	int (*ioctl)(struct net_device *, struct ifreq *, int);
-	struct ifreq ifr;
-	struct mii_ioctl_data *mii;
-
-	if (!reporting && !netif_running(slave_dev))
-		return 0;
-
-	if (bond->params.use_carrier)
-		return netif_carrier_ok(slave_dev) ? BMSR_LSTATUS : 0;
-
-	/* Try to get link status using Ethtool first. */
-	if (slave_dev->ethtool_ops->get_link)
-		return slave_dev->ethtool_ops->get_link(slave_dev) ?
-			BMSR_LSTATUS : 0;
-
-	/* Ethtool can't be used, fallback to MII ioctls. */
-	ioctl = slave_ops->ndo_do_ioctl;
-	if (ioctl) {
-		/* TODO: set pointer to correct ioctl on a per team member
-		 *       bases to make this more efficient. that is, once
-		 *       we determine the correct ioctl, we will always
-		 *       call it and not the others for that team
-		 *       member.
-		 */
-
-		/* We cannot assume that SIOCGMIIPHY will also read a
-		 * register; not all network drivers (e.g., e100)
-		 * support that.
-		 */
-
-		/* Yes, the mii is overlaid on the ifreq.ifr_ifru */
-		strncpy(ifr.ifr_name, slave_dev->name, IFNAMSIZ);
-		mii = if_mii(&ifr);
-		if (ioctl(slave_dev, &ifr, SIOCGMIIPHY) == 0) {
-			mii->reg_num = MII_BMSR;
-			if (ioctl(slave_dev, &ifr, SIOCGMIIREG) == 0)
-				return mii->val_out & BMSR_LSTATUS;
-		}
-	}
-
-	/* If reporting, report that either there's no dev->do_ioctl,
-	 * or both SIOCGMIIREG and get_link failed (meaning that we
-	 * cannot report link status).  If not reporting, pretend
-	 * we're ok.
-	 */
-	return reporting ? -1 : BMSR_LSTATUS;
-}
-
-/*----------------------------- Multicast list ------------------------------*/
-
-/* Push the promiscuity flag down to appropriate slaves */
-static int bond_set_promiscuity(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_promiscuity(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_promiscuity(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Push the allmulti flag down to all slaves */
-static int bond_set_allmulti(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_allmulti(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_allmulti(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Retrieve the list of registered multicast addresses for the bonding
- * device and retransmit an IGMP JOIN request to the current active
- * slave.
- */
-static void bond_resend_igmp_join_requests_delayed(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mcast_work.work);
-
-	if (!rtnl_trylock()) {
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-		return;
-	}
-	call_netdevice_notifiers(NETDEV_RESEND_IGMP, bond->dev);
-
-	if (bond->igmp_retrans > 1) {
-		bond->igmp_retrans--;
-		queue_delayed_work(bond->wq, &bond->mcast_work, HZ/5);
-	}
-	rtnl_unlock();
-}
-
-/* Flush bond's hardware addresses from slave */
-static void bond_hw_addr_flush(struct net_device *bond_dev,
-			       struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	dev_uc_unsync(slave_dev, bond_dev);
-	dev_mc_unsync(slave_dev, bond_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		/* del lacpdu mc addr from mc list */
-		u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-		dev_mc_del(slave_dev, lacpdu_multicast);
-	}
-}
-
-/*--------------------------- Active slave change ---------------------------*/
-
-/* Update the hardware address list and promisc/allmulti for the new and
- * old active slaves (if any).  Modes that are not using primary keep all
- * slaves up date at all times; only the modes that use primary need to call
- * this function to swap these settings during a failover.
- */
-static void bond_hw_addr_swap(struct bonding *bond, struct slave *new_active,
-			      struct slave *old_active)
-{
-	if (old_active) {
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(old_active->dev, -1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(old_active->dev, -1);
-
-		bond_hw_addr_flush(bond->dev, old_active->dev);
-	}
-
-	if (new_active) {
-		/* FIXME: Signal errors upstream. */
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(new_active->dev, 1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(new_active->dev, 1);
-
-		netif_addr_lock_bh(bond->dev);
-		dev_uc_sync(new_active->dev, bond->dev);
-		dev_mc_sync(new_active->dev, bond->dev);
-		netif_addr_unlock_bh(bond->dev);
-	}
-}
-
-/**
- * bond_set_dev_addr - clone slave's address to bond
- * @bond_dev: bond net device
- * @slave_dev: slave net device
- *
- * Should be called with RTNL held.
- */
-static int bond_set_dev_addr(struct net_device *bond_dev,
-			     struct net_device *slave_dev)
-{
-	int err;
-
-	slave_dbg(bond_dev, slave_dev, "bond_dev=%p slave_dev=%p slave_dev->addr_len=%d\n",
-		  bond_dev, slave_dev, slave_dev->addr_len);
-	err = dev_pre_changeaddr_notify(bond_dev, slave_dev->dev_addr, NULL);
-	if (err)
-		return err;
-
-	memcpy(bond_dev->dev_addr, slave_dev->dev_addr, slave_dev->addr_len);
-	bond_dev->addr_assign_type = NET_ADDR_STOLEN;
-	call_netdevice_notifiers(NETDEV_CHANGEADDR, bond_dev);
-	return 0;
-}
-
-static struct slave *bond_get_old_active(struct bonding *bond,
-					 struct slave *new_active)
-{
-	struct slave *slave;
-	struct list_head *iter;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave == new_active)
-			continue;
-
-		if (ether_addr_equal(bond->dev->dev_addr, slave->dev->dev_addr))
-			return slave;
-	}
-
-	return NULL;
-}
-
-/* bond_do_fail_over_mac
- *
- * Perform special MAC address swapping for fail_over_mac settings
- *
- * Called with RTNL
- */
-static void bond_do_fail_over_mac(struct bonding *bond,
-				  struct slave *new_active,
-				  struct slave *old_active)
-{
-	u8 tmp_mac[MAX_ADDR_LEN];
-	struct sockaddr_storage ss;
-	int rv;
-
-	switch (bond->params.fail_over_mac) {
-	case BOND_FOM_ACTIVE:
-		if (new_active) {
-			rv = bond_set_dev_addr(bond->dev, new_active->dev);
-			if (rv)
-				slave_err(bond->dev, new_active->dev, "Error %d setting bond MAC from slave\n",
-					  -rv);
-		}
-		break;
-	case BOND_FOM_FOLLOW:
-		/* if new_active && old_active, swap them
-		 * if just old_active, do nothing (going to no active slave)
-		 * if just new_active, set new_active to bond's MAC
-		 */
-		if (!new_active)
-			return;
-
-		if (!old_active)
-			old_active = bond_get_old_active(bond, new_active);
-
-		if (old_active) {
-			bond_hw_addr_copy(tmp_mac, new_active->dev->dev_addr,
-					  new_active->dev->addr_len);
-			bond_hw_addr_copy(ss.__data,
-					  old_active->dev->dev_addr,
-					  old_active->dev->addr_len);
-			ss.ss_family = new_active->dev->type;
-		} else {
-			bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
-					  bond->dev->addr_len);
-			ss.ss_family = bond->dev->type;
-		}
-
-		rv = dev_set_mac_address(new_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv) {
-			slave_err(bond->dev, new_active->dev, "Error %d setting MAC of new active slave\n",
-				  -rv);
-			goto out;
-		}
-
-		if (!old_active)
-			goto out;
-
-		bond_hw_addr_copy(ss.__data, tmp_mac,
-				  new_active->dev->addr_len);
-		ss.ss_family = old_active->dev->type;
-
-		rv = dev_set_mac_address(old_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv)
-			slave_err(bond->dev, old_active->dev, "Error %d setting MAC of old active slave\n",
-				  -rv);
-out:
-		break;
-	default:
-		netdev_err(bond->dev, "bond_do_fail_over_mac impossible: bad policy %d\n",
-			   bond->params.fail_over_mac);
-		break;
-	}
-
-}
-
-static struct slave *bond_choose_primary_or_current(struct bonding *bond)
-{
-	struct slave *prim = rtnl_dereference(bond->primary_slave);
-	struct slave *curr = rtnl_dereference(bond->curr_active_slave);
-
-	if (!prim || prim->link != BOND_LINK_UP) {
-		if (!curr || curr->link != BOND_LINK_UP)
-			return NULL;
-		return curr;
-	}
-
-	if (bond->force_primary) {
-		bond->force_primary = false;
-		return prim;
-	}
-
-	if (!curr || curr->link != BOND_LINK_UP)
-		return prim;
-
-	/* At this point, prim and curr are both up */
-	switch (bond->params.primary_reselect) {
-	case BOND_PRI_RESELECT_ALWAYS:
-		return prim;
-	case BOND_PRI_RESELECT_BETTER:
-		if (prim->speed < curr->speed)
-			return curr;
-		if (prim->speed == curr->speed && prim->duplex <= curr->duplex)
-			return curr;
-		return prim;
-	case BOND_PRI_RESELECT_FAILURE:
-		return curr;
-	default:
-		netdev_err(bond->dev, "impossible primary_reselect %d\n",
-			   bond->params.primary_reselect);
-		return curr;
-	}
-}
-
-/**
- * bond_find_best_slave - select the best available slave to be the active one
- * @bond: our bonding struct
- */
-static struct slave *bond_find_best_slave(struct bonding *bond)
-{
-	struct slave *slave, *bestslave = NULL;
-	struct list_head *iter;
-	int mintime = bond->params.updelay;
-
-	slave = bond_choose_primary_or_current(bond);
-	if (slave)
-		return slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP)
-			return slave;
-		if (slave->link == BOND_LINK_BACK && bond_slave_is_up(slave) &&
-		    slave->delay < mintime) {
-			mintime = slave->delay;
-			bestslave = slave;
-		}
-	}
-
-	return bestslave;
-}
-
-static bool bond_should_notify_peers(struct bonding *bond)
-{
-	struct slave *slave;
-
-	rcu_read_lock();
-	slave = rcu_dereference(bond->curr_active_slave);
-	rcu_read_unlock();
-
-	netdev_dbg(bond->dev, "bond_should_notify_peers: slave %s\n",
-		   slave ? slave->dev->name : "NULL");
-
-	if (!slave || !bond->send_peer_notif ||
-	    bond->send_peer_notif %
-	    max(1, bond->params.peer_notif_delay) != 0 ||
-	    !netif_carrier_ok(bond->dev) ||
-	    test_bit(__LINK_STATE_LINKWATCH_PENDING, &slave->dev->state))
-		return false;
-
-	return true;
-}
-
-/**
- * change_active_interface - change the active slave into the specified one
- * @bond: our bonding struct
- * @new: the new slave to make the active one
- *
- * Set the new slave to the bond's settings and unset them on the old
- * curr_active_slave.
- * Setting include flags, mc-list, promiscuity, allmulti, etc.
- *
- * If @new's link state is %BOND_LINK_BACK we'll set it to %BOND_LINK_UP,
- * because it is apparently the best available slave we have, even though its
- * updelay hasn't timed out yet.
- *
- * Caller must hold RTNL.
- */
-void bond_change_active_slave(struct bonding *bond, struct slave *new_active)
-{
-	struct slave *old_active;
-
-	ASSERT_RTNL();
-
-	old_active = rtnl_dereference(bond->curr_active_slave);
-
-	if (old_active == new_active)
-		return;
-
-	if (new_active) {
-		new_active->last_link_up = jiffies;
-
-		if (new_active->link == BOND_LINK_BACK) {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one %d ms earlier\n",
-					   (bond->params.updelay - new_active->delay) * bond->params.miimon);
-			}
-
-			new_active->delay = 0;
-			bond_set_slave_link_state(new_active, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_3ad_handle_link_change(new_active, BOND_LINK_UP);
-
-			if (bond_is_lb(bond))
-				bond_alb_handle_link_change(bond, new_active, BOND_LINK_UP);
-		} else {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one\n");
-			}
-		}
-	}
-
-	if (bond_uses_primary(bond))
-		bond_hw_addr_swap(bond, new_active, old_active);
-
-	if (bond_is_lb(bond)) {
-		bond_alb_handle_active_change(bond, new_active);
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-		if (new_active)
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		rcu_assign_pointer(bond->curr_active_slave, new_active);
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP) {
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-		if (new_active) {
-			bool should_notify_peers = false;
-
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-
-			if (bond->params.fail_over_mac)
-				bond_do_fail_over_mac(bond, new_active,
-						      old_active);
-
-			if (netif_running(bond->dev)) {
-				bond->send_peer_notif =
-					bond->params.num_peer_notif *
-					max(1, bond->params.peer_notif_delay);
-				should_notify_peers =
-					bond_should_notify_peers(bond);
-			}
-
-			call_netdevice_notifiers(NETDEV_BONDING_FAILOVER, bond->dev);
-			if (should_notify_peers) {
-				bond->send_peer_notif--;
-				call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-							 bond->dev);
-			}
-		}
-	}
-
-	/* resend IGMP joins since active slave has changed or
-	 * all were sent on curr_active_slave.
-	 * resend only if bond is brought up with the affected
-	 * bonding modes and the retransmission is enabled
-	 */
-	if (netif_running(bond->dev) && (bond->params.resend_igmp > 0) &&
-	    ((bond_uses_primary(bond) && new_active) ||
-	     BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)) {
-		bond->igmp_retrans = bond->params.resend_igmp;
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-	}
-}
-
-/**
- * bond_select_active_slave - select a new active slave, if needed
- * @bond: our bonding struct
- *
- * This functions should be called when one of the following occurs:
- * - The old curr_active_slave has been released or lost its link.
- * - The primary_slave has got its link back.
- * - A slave has got its link back and there's no old curr_active_slave.
- *
- * Caller must hold RTNL.
- */
-void bond_select_active_slave(struct bonding *bond)
-{
-	struct slave *best_slave;
-	int rv;
-
-	ASSERT_RTNL();
-
-	best_slave = bond_find_best_slave(bond);
-	if (best_slave != rtnl_dereference(bond->curr_active_slave)) {
-		struct slave *last_slave = bond->curr_active_slave;
-
-		bond_change_active_slave(bond, best_slave);
-		toe_failover(bond->dev,
-			     bond->curr_active_slave ?
-			     bond->curr_active_slave->dev : NULL,
-			     TOE_ACTIVE_SLAVE,
-			     last_slave ? last_slave->dev : NULL);
-
-		rv = bond_set_carrier(bond);
-		if (!rv)
-			return;
-
-		if (netif_carrier_ok(bond->dev))
-			netdev_info(bond->dev, "active interface up!\n");
-		else
-			netdev_info(bond->dev, "now running without any active interface!\n");
-	}
-}
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	struct netpoll *np;
-	int err = 0;
-
-	np = kzalloc(sizeof(*np), GFP_KERNEL);
-	err = -ENOMEM;
-	if (!np)
-		goto out;
-
-	err = __netpoll_setup(np, slave->dev);
-	if (err) {
-		kfree(np);
-		goto out;
-	}
-	slave->np = np;
-out:
-	return err;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-	struct netpoll *np = slave->np;
-
-	if (!np)
-		return;
-
-	slave->np = NULL;
-
-	__netpoll_free(np);
-}
-
-static void bond_poll_controller(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-	struct ad_info ad_info;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		if (bond_3ad_get_active_agg_info(bond, &ad_info))
-			return;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!bond_slave_is_up(slave))
-			continue;
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg =
-			    SLAVE_AD_INFO(slave)->port.aggregator;
-
-			if (agg &&
-			    agg->aggregator_identifier != ad_info.aggregator_id)
-				continue;
-		}
-
-		netpoll_poll_dev(slave->dev);
-	}
-}
-
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		if (bond_slave_is_up(slave))
-			slave_disable_netpoll(slave);
-}
-
-static int bond_netpoll_setup(struct net_device *dev, struct netpoll_info *ni)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	struct slave *slave;
-	int err = 0;
-
-	bond_for_each_slave(bond, slave, iter) {
-		err = slave_enable_netpoll(slave);
-		if (err) {
-			bond_netpoll_cleanup(dev);
-			break;
-		}
-	}
-	return err;
-}
-#else
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	return 0;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-}
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-}
-#endif
-
-/*---------------------------------- IOCTL ----------------------------------*/
-
-static netdev_features_t bond_fix_features(struct net_device *dev,
-					   netdev_features_t features)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	netdev_features_t mask;
-	struct slave *slave;
-
-	mask = features;
-
-	features &= ~NETIF_F_ONE_FOR_ALL;
-	features |= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		features = netdev_increment_features(features,
-						     slave->dev->features,
-						     mask);
-	}
-	features = netdev_add_tso_features(features, mask);
-
-	return features;
-}
-
-#define BOND_VLAN_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_FRAGLIST | NETIF_F_ALL_TSO | \
-				 NETIF_F_HIGHDMA | NETIF_F_LRO)
-
-#define BOND_ENC_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_RXCSUM | NETIF_F_ALL_TSO)
-
-#define BOND_MPLS_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_ALL_TSO)
-
-static void bond_compute_features(struct bonding *bond)
-{
-	unsigned int dst_release_flag = IFF_XMIT_DST_RELEASE |
-					IFF_XMIT_DST_RELEASE_PERM;
-	netdev_features_t vlan_features = BOND_VLAN_FEATURES;
-	netdev_features_t enc_features  = BOND_ENC_FEATURES;
-	netdev_features_t mpls_features  = BOND_MPLS_FEATURES;
-	struct net_device *bond_dev = bond->dev;
-	struct list_head *iter;
-	struct slave *slave;
-	unsigned short max_hard_header_len = ETH_HLEN;
-	unsigned int gso_max_size = GSO_MAX_SIZE;
-	u16 gso_max_segs = GSO_MAX_SEGS;
-
-	if (!bond_has_slaves(bond))
-		goto done;
-	vlan_features &= NETIF_F_ALL_FOR_ALL;
-	mpls_features &= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		vlan_features = netdev_increment_features(vlan_features,
-			slave->dev->vlan_features, BOND_VLAN_FEATURES);
-
-		enc_features = netdev_increment_features(enc_features,
-							 slave->dev->hw_enc_features,
-							 BOND_ENC_FEATURES);
-
-		mpls_features = netdev_increment_features(mpls_features,
-							  slave->dev->mpls_features,
-							  BOND_MPLS_FEATURES);
-
-		dst_release_flag &= slave->dev->priv_flags;
-		if (slave->dev->hard_header_len > max_hard_header_len)
-			max_hard_header_len = slave->dev->hard_header_len;
-
-		gso_max_size = min(gso_max_size, slave->dev->gso_max_size);
-		gso_max_segs = min(gso_max_segs, slave->dev->gso_max_segs);
-	}
-	bond_dev->hard_header_len = max_hard_header_len;
-
-done:
-	bond_dev->vlan_features = vlan_features;
-	bond_dev->hw_enc_features = enc_features | NETIF_F_GSO_ENCAP_ALL |
-				    NETIF_F_HW_VLAN_CTAG_TX |
-				    NETIF_F_HW_VLAN_STAG_TX |
-				    NETIF_F_GSO_UDP_L4;
-	bond_dev->mpls_features = mpls_features;
-	bond_dev->gso_max_segs = gso_max_segs;
-	netif_set_gso_max_size(bond_dev, gso_max_size);
-
-	bond_dev->priv_flags &= ~IFF_XMIT_DST_RELEASE;
-	if ((bond_dev->priv_flags & IFF_XMIT_DST_RELEASE_PERM) &&
-	    dst_release_flag == (IFF_XMIT_DST_RELEASE | IFF_XMIT_DST_RELEASE_PERM))
-		bond_dev->priv_flags |= IFF_XMIT_DST_RELEASE;
-
-	netdev_change_features(bond_dev);
-}
-
-static void bond_setup_by_slave(struct net_device *bond_dev,
-				struct net_device *slave_dev)
-{
-	bond_dev->header_ops	    = slave_dev->header_ops;
-
-	bond_dev->type		    = slave_dev->type;
-	bond_dev->hard_header_len   = slave_dev->hard_header_len;
-	bond_dev->addr_len	    = slave_dev->addr_len;
-
-	memcpy(bond_dev->broadcast, slave_dev->broadcast,
-		slave_dev->addr_len);
-}
-
-/* On bonding slaves other than the currently active slave, suppress
- * duplicates except for alb non-mcast/bcast.
- */
-static bool bond_should_deliver_exact_match(struct sk_buff *skb,
-					    struct slave *slave,
-					    struct bonding *bond)
-{
-	if (bond_is_slave_inactive(slave)) {
-		if (BOND_MODE(bond) == BOND_MODE_ALB &&
-		    skb->pkt_type != PACKET_BROADCAST &&
-		    skb->pkt_type != PACKET_MULTICAST)
-			return false;
-		return true;
-	}
-	return false;
-}
-
-static rx_handler_result_t bond_handle_frame(struct sk_buff **pskb)
-{
-	struct sk_buff *skb = *pskb;
-	struct slave *slave;
-	struct bonding *bond;
-	int (*recv_probe)(const struct sk_buff *, struct bonding *,
-			  struct slave *);
-	int ret = RX_HANDLER_ANOTHER;
-
-	skb = skb_share_check(skb, GFP_ATOMIC);
-	if (unlikely(!skb))
-		return RX_HANDLER_CONSUMED;
-
-	*pskb = skb;
-
-	slave = bond_slave_get_rcu(skb->dev);
-	bond = slave->bond;
-
-	recv_probe = READ_ONCE(bond->recv_probe);
-	if (recv_probe) {
-		ret = recv_probe(skb, bond, slave);
-		if (ret == RX_HANDLER_CONSUMED) {
-			consume_skb(skb);
-			return ret;
-		}
-	}
-
-	/*
-	 * For packets determined by bond_should_deliver_exact_match() call to
-	 * be suppressed we want to make an exception for link-local packets.
-	 * This is necessary for e.g. LLDP daemons to be able to monitor
-	 * inactive slave links without being forced to bind to them
-	 * explicitly.
-	 *
-	 * At the same time, packets that are passed to the bonding master
-	 * (including link-local ones) can have their originating interface
-	 * determined via PACKET_ORIGDEV socket option.
-	 */
-	if (bond_should_deliver_exact_match(skb, slave, bond)) {
-		if (is_link_local_ether_addr(eth_hdr(skb)->h_dest))
-			return RX_HANDLER_PASS;
-		return RX_HANDLER_EXACT;
-	}
-
-	skb->dev = bond->dev;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB &&
-	    bond->dev->priv_flags & IFF_BRIDGE_PORT &&
-	    skb->pkt_type == PACKET_HOST) {
-
-		if (unlikely(skb_cow_head(skb,
-					  skb->data - skb_mac_header(skb)))) {
-			kfree_skb(skb);
-			return RX_HANDLER_CONSUMED;
-		}
-		bond_hw_addr_copy(eth_hdr(skb)->h_dest, bond->dev->dev_addr,
-				  bond->dev->addr_len);
-	}
-
-	return ret;
-}
-
-static enum netdev_lag_tx_type bond_lag_tx_type(struct bonding *bond)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return NETDEV_LAG_TX_TYPE_ROUNDROBIN;
-	case BOND_MODE_ACTIVEBACKUP:
-		return NETDEV_LAG_TX_TYPE_ACTIVEBACKUP;
-	case BOND_MODE_BROADCAST:
-		return NETDEV_LAG_TX_TYPE_BROADCAST;
-	case BOND_MODE_XOR:
-	case BOND_MODE_8023AD:
-		return NETDEV_LAG_TX_TYPE_HASH;
-	default:
-		return NETDEV_LAG_TX_TYPE_UNKNOWN;
-	}
-}
-
-static enum netdev_lag_hash bond_lag_hash_type(struct bonding *bond,
-					       enum netdev_lag_tx_type type)
-{
-	if (type != NETDEV_LAG_TX_TYPE_HASH)
-		return NETDEV_LAG_HASH_NONE;
-
-	switch (bond->params.xmit_policy) {
-	case BOND_XMIT_POLICY_LAYER2:
-		return NETDEV_LAG_HASH_L2;
-	case BOND_XMIT_POLICY_LAYER34:
-		return NETDEV_LAG_HASH_L34;
-	case BOND_XMIT_POLICY_LAYER23:
-		return NETDEV_LAG_HASH_L23;
-	case BOND_XMIT_POLICY_ENCAP23:
-		return NETDEV_LAG_HASH_E23;
-	case BOND_XMIT_POLICY_ENCAP34:
-		return NETDEV_LAG_HASH_E34;
-	default:
-		return NETDEV_LAG_HASH_UNKNOWN;
-	}
-}
-
-static int bond_master_upper_dev_link(struct bonding *bond, struct slave *slave,
-				      struct netlink_ext_ack *extack)
-{
-	struct netdev_lag_upper_info lag_upper_info;
-	enum netdev_lag_tx_type type;
-
-	type = bond_lag_tx_type(bond);
-	lag_upper_info.tx_type = type;
-	lag_upper_info.hash_type = bond_lag_hash_type(bond, type);
-
-	return netdev_master_upper_dev_link(slave->dev, bond->dev, slave,
-					    &lag_upper_info, extack);
-}
-
-static void bond_upper_dev_unlink(struct bonding *bond, struct slave *slave)
-{
-	netdev_upper_dev_unlink(slave->dev, bond->dev);
-	slave->dev->flags &= ~IFF_SLAVE;
-}
-
-static struct slave *bond_alloc_slave(struct bonding *bond)
-{
-	struct slave *slave = NULL;
-
-	slave = kzalloc(sizeof(*slave), GFP_KERNEL);
-	if (!slave)
-		return NULL;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		SLAVE_AD_INFO(slave) = kzalloc(sizeof(struct ad_slave_info),
-					       GFP_KERNEL);
-		if (!SLAVE_AD_INFO(slave)) {
-			kfree(slave);
-			return NULL;
-		}
-	}
-	INIT_DELAYED_WORK(&slave->notify_work, bond_netdev_notify_work);
-
-	return slave;
-}
-
-static void bond_free_slave(struct slave *slave)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-
-	cancel_delayed_work_sync(&slave->notify_work);
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		kfree(SLAVE_AD_INFO(slave));
-
-	kfree(slave);
-}
-
-static void bond_fill_ifbond(struct bonding *bond, struct ifbond *info)
-{
-	info->bond_mode = BOND_MODE(bond);
-	info->miimon = bond->params.miimon;
-	info->num_slaves = bond->slave_cnt;
-}
-
-static void bond_fill_ifslave(struct slave *slave, struct ifslave *info)
-{
-	strcpy(info->slave_name, slave->dev->name);
-	info->link = slave->link;
-	info->state = bond_slave_state(slave);
-	info->link_failure_count = slave->link_failure_count;
-}
-
-static void bond_netdev_notify_work(struct work_struct *_work)
-{
-	struct slave *slave = container_of(_work, struct slave,
-					   notify_work.work);
-
-	if (rtnl_trylock()) {
-		struct netdev_bonding_info binfo;
-
-		bond_fill_ifslave(slave, &binfo.slave);
-		bond_fill_ifbond(slave->bond, &binfo.master);
-		netdev_bonding_info_change(slave->dev, &binfo);
-		rtnl_unlock();
-	} else {
-		queue_delayed_work(slave->bond->wq, &slave->notify_work, 1);
-	}
-}
-
-void bond_queue_slave_event(struct slave *slave)
-{
-	queue_delayed_work(slave->bond->wq, &slave->notify_work, 0);
-}
-
-void bond_lower_state_changed(struct slave *slave)
-{
-	struct netdev_lag_lower_state_info info;
-
-	info.link_up = slave->link == BOND_LINK_UP ||
-		       slave->link == BOND_LINK_FAIL;
-	info.tx_enabled = bond_is_active_slave(slave);
-	netdev_lower_state_changed(slave->dev, &info);
-}
-
-/* enslave device <slave> to bond device <master> */
-int bond_enslave(struct net_device *bond_dev, struct net_device *slave_dev,
-		 struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	struct slave *new_slave = NULL, *prev_slave;
-	struct sockaddr_storage ss;
-	int link_reporting;
-	int res = 0, i;
-
-	if (!bond->params.use_carrier &&
-	    slave_dev->ethtool_ops->get_link == NULL &&
-	    slave_ops->ndo_do_ioctl == NULL) {
-		slave_warn(bond_dev, slave_dev, "no link monitoring support\n");
-	}
-
-	/* already in-use? */
-	if (netdev_is_rx_handler_busy(slave_dev)) {
-		NL_SET_ERR_MSG(extack, "Device is in use and cannot be enslaved");
-		slave_err(bond_dev, slave_dev,
-			  "Error: Device is in use and cannot be enslaved\n");
-		return -EBUSY;
-	}
-
-	if (bond_dev == slave_dev) {
-		NL_SET_ERR_MSG(extack, "Cannot enslave bond to itself.");
-		netdev_err(bond_dev, "cannot enslave bond to itself.\n");
-		return -EPERM;
-	}
-
-	/* vlan challenged mutual exclusion */
-	/* no need to lock since we're protected by rtnl_lock */
-	if (slave_dev->features & NETIF_F_VLAN_CHALLENGED) {
-		slave_dbg(bond_dev, slave_dev, "is NETIF_F_VLAN_CHALLENGED\n");
-		if (vlan_uses_dev(bond_dev)) {
-			NL_SET_ERR_MSG(extack, "Can not enslave VLAN challenged device to VLAN enabled bond");
-			slave_err(bond_dev, slave_dev, "Error: cannot enslave VLAN challenged slave on VLAN enabled bond\n");
-			return -EPERM;
-		} else {
-			slave_warn(bond_dev, slave_dev, "enslaved VLAN challenged slave. Adding VLANs will be blocked as long as it is part of bond.\n");
-		}
-	} else {
-		slave_dbg(bond_dev, slave_dev, "is !NETIF_F_VLAN_CHALLENGED\n");
-	}
-
-	/* Old ifenslave binaries are no longer supported.  These can
-	 * be identified with moderate accuracy by the state of the slave:
-	 * the current ifenslave will set the interface down prior to
-	 * enslaving it; the old ifenslave will not.
-	 */
-	if (slave_dev->flags & IFF_UP) {
-		NL_SET_ERR_MSG(extack, "Device can not be enslaved while up");
-		slave_err(bond_dev, slave_dev, "slave is up - this may be due to an out of date ifenslave\n");
-		return -EPERM;
-	}
-
-	/* set bonding device ether type by slave - bonding netdevices are
-	 * created with ether_setup, so when the slave type is not ARPHRD_ETHER
-	 * there is a need to override some of the type dependent attribs/funcs.
-	 *
-	 * bond ether type mutual exclusion - don't allow slaves of dissimilar
-	 * ether type (eg ARPHRD_ETHER and ARPHRD_INFINIBAND) share the same bond
-	 */
-	if (!bond_has_slaves(bond)) {
-		if (bond_dev->type != slave_dev->type) {
-			slave_dbg(bond_dev, slave_dev, "change device type from %d to %d\n",
-				  bond_dev->type, slave_dev->type);
-
-			res = call_netdevice_notifiers(NETDEV_PRE_TYPE_CHANGE,
-						       bond_dev);
-			res = notifier_to_errno(res);
-			if (res) {
-				slave_err(bond_dev, slave_dev, "refused to change device type\n");
-				return -EBUSY;
-			}
-
-			/* Flush unicast and multicast addresses */
-			dev_uc_flush(bond_dev);
-			dev_mc_flush(bond_dev);
-
-			if (slave_dev->type != ARPHRD_ETHER)
-				bond_setup_by_slave(bond_dev, slave_dev);
-			else {
-				ether_setup(bond_dev);
-				bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-			}
-
-			call_netdevice_notifiers(NETDEV_POST_TYPE_CHANGE,
-						 bond_dev);
-		}
-	} else if (bond_dev->type != slave_dev->type) {
-		NL_SET_ERR_MSG(extack, "Device type is different from other slaves");
-		slave_err(bond_dev, slave_dev, "ether type (%d) is different from other slaves (%d), can not enslave it\n",
-			  slave_dev->type, bond_dev->type);
-		return -EINVAL;
-	}
-
-	if (slave_dev->type == ARPHRD_INFINIBAND &&
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		NL_SET_ERR_MSG(extack, "Only active-backup mode is supported for infiniband slaves");
-		slave_warn(bond_dev, slave_dev, "Type (%d) supports only active-backup mode\n",
-			   slave_dev->type);
-		res = -EOPNOTSUPP;
-		goto err_undo_flags;
-	}
-
-	if (!slave_ops->ndo_set_mac_address ||
-	    slave_dev->type == ARPHRD_INFINIBAND) {
-		slave_warn(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address\n");
-		if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
-		    bond->params.fail_over_mac != BOND_FOM_ACTIVE) {
-			if (!bond_has_slaves(bond)) {
-				bond->params.fail_over_mac = BOND_FOM_ACTIVE;
-				slave_warn(bond_dev, slave_dev, "Setting fail_over_mac to active for active-backup mode\n");
-			} else {
-				NL_SET_ERR_MSG(extack, "Slave device does not support setting the MAC address, but fail_over_mac is not set to active");
-				slave_err(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address, but fail_over_mac is not set to active\n");
-				res = -EOPNOTSUPP;
-				goto err_undo_flags;
-			}
-		}
-	}
-
-	call_netdevice_notifiers(NETDEV_JOIN, slave_dev);
-
-	/* If this is the first slave, then we need to set the master's hardware
-	 * address to be the same as the slave's.
-	 */
-	if (!bond_has_slaves(bond) &&
-	    bond->dev->addr_assign_type == NET_ADDR_RANDOM) {
-		res = bond_set_dev_addr(bond->dev, slave_dev);
-		if (res)
-			goto err_undo_flags;
-	}
-
-	new_slave = bond_alloc_slave(bond);
-	if (!new_slave) {
-		res = -ENOMEM;
-		goto err_undo_flags;
-	}
-
-	new_slave->bond = bond;
-	new_slave->dev = slave_dev;
-	/* Set the new_slave's queue_id to be zero.  Queue ID mapping
-	 * is set via sysfs or module option if desired.
-	 */
-	new_slave->queue_id = 0;
-
-	/* Save slave's original mtu and then set it to match the bond */
-	new_slave->original_mtu = slave_dev->mtu;
-	res = dev_set_mtu(slave_dev, bond->dev->mtu);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Error %d calling dev_set_mtu\n", res);
-		goto err_free;
-	}
-
-	/* Save slave's original ("permanent") mac address for modes
-	 * that need it, and for restoring it upon release, and then
-	 * set it to the master's address
-	 */
-	bond_hw_addr_copy(new_slave->perm_hwaddr, slave_dev->dev_addr,
-			  slave_dev->addr_len);
-
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* Set slave to master's mac address.  The application already
-		 * set the master's mac address to that of the first slave
-		 */
-		memcpy(ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		res = dev_set_mac_address(slave_dev, (struct sockaddr *)&ss,
-					  extack);
-		if (res) {
-			slave_err(bond_dev, slave_dev, "Error %d calling set_mac_address\n", res);
-			goto err_restore_mtu;
-		}
-	}
-
-	/* set slave flag before open to prevent IPv6 addrconf */
-	slave_dev->flags |= IFF_SLAVE;
-
-	/* open the slave since the application closed it */
-	res = dev_open(slave_dev, extack);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Opening slave failed\n");
-		goto err_restore_mac;
-	}
-
-	slave_dev->priv_flags |= IFF_BONDING;
-	/* initialize slave stats */
-	dev_get_stats(new_slave->dev, &new_slave->slave_stats);
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_init_slave() must be called before all other stages since
-		 * it might fail and we do not want to have to undo everything
-		 */
-		res = bond_alb_init_slave(bond, new_slave);
-		if (res)
-			goto err_close;
-	}
-
-	res = vlan_vids_add_by_dev(slave_dev, bond_dev);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Couldn't add bond vlan ids\n");
-		goto err_close;
-	}
-
-	prev_slave = bond_last_slave(bond);
-
-	new_slave->delay = 0;
-	new_slave->link_failure_count = 0;
-
-	if (bond_update_speed_duplex(new_slave) &&
-	    bond_needs_speed_duplex(bond))
-		new_slave->link = BOND_LINK_DOWN;
-
-	new_slave->last_rx = jiffies -
-		(msecs_to_jiffies(bond->params.arp_interval) + 1);
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
-		new_slave->target_last_arp_rx[i] = new_slave->last_rx;
-
-	if (bond->params.miimon && !bond->params.use_carrier) {
-		link_reporting = bond_check_dev_link(bond, slave_dev, 1);
-
-		if ((link_reporting == -1) && !bond->params.arp_interval) {
-			/* miimon is set but a bonded network driver
-			 * does not support ETHTOOL/MII and
-			 * arp_interval is not set.  Note: if
-			 * use_carrier is enabled, we will never go
-			 * here (because netif_carrier is always
-			 * supported); thus, we don't need to change
-			 * the messages for netif_carrier.
-			 */
-			slave_warn(bond_dev, slave_dev, "MII and ETHTOOL support not available for slave, and arp_interval/arp_ip_target module parameters not specified, thus bonding will not detect link failures! see bonding.txt for details\n");
-		} else if (link_reporting == -1) {
-			/* unable get link status using mii/ethtool */
-			slave_warn(bond_dev, slave_dev, "can't get link status from slave; the network driver associated with this interface does not support MII or ETHTOOL link status reporting, thus miimon has no effect on this interface\n");
-		}
-	}
-
-	/* check for initial state */
-	new_slave->link = BOND_LINK_NOCHANGE;
-	if (bond->params.miimon) {
-		if (bond_check_dev_link(bond, slave_dev, 0) == BMSR_LSTATUS) {
-			if (bond->params.updelay) {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_BACK,
-							  BOND_SLAVE_NOTIFY_NOW);
-				new_slave->delay = bond->params.updelay;
-			} else {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-			}
-		} else {
-			bond_set_slave_link_state(new_slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-		}
-	} else if (bond->params.arp_interval) {
-		bond_set_slave_link_state(new_slave,
-					  (netif_carrier_ok(slave_dev) ?
-					  BOND_LINK_UP : BOND_LINK_DOWN),
-					  BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		bond_set_slave_link_state(new_slave, BOND_LINK_UP,
-					  BOND_SLAVE_NOTIFY_NOW);
-	}
-
-	if (new_slave->link != BOND_LINK_DOWN)
-		new_slave->last_link_up = jiffies;
-	slave_dbg(bond_dev, slave_dev, "Initial state of slave is BOND_LINK_%s\n",
-		  new_slave->link == BOND_LINK_DOWN ? "DOWN" :
-		  (new_slave->link == BOND_LINK_UP ? "UP" : "BACK"));
-
-	if (bond_uses_primary(bond) && bond->params.primary[0]) {
-		/* if there is a primary slave, remember it */
-		if (strcmp(bond->params.primary, new_slave->dev->name) == 0) {
-			rcu_assign_pointer(bond->primary_slave, new_slave);
-			bond->force_primary = true;
-		}
-	}
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ACTIVEBACKUP:
-		bond_set_slave_inactive_flags(new_slave,
-					      BOND_SLAVE_NOTIFY_NOW);
-		break;
-	case BOND_MODE_8023AD:
-		/* in 802.3ad mode, the internal mechanism
-		 * will activate the slaves in the selected
-		 * aggregator
-		 */
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		/* if this is the first slave */
-		if (!prev_slave) {
-			SLAVE_AD_INFO(new_slave)->id = 1;
-			/* Initialize AD with the number of times that the AD timer is called in 1 second
-			 * can be called only after the mac address of the bond is set
-			 */
-			bond_3ad_initialize(bond, 1000/AD_TIMER_INTERVAL);
-		} else {
-			SLAVE_AD_INFO(new_slave)->id =
-				SLAVE_AD_INFO(prev_slave)->id + 1;
-		}
-
-		bond_3ad_bind_slave(new_slave);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_set_active_slave(new_slave);
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		break;
-	default:
-		slave_dbg(bond_dev, slave_dev, "This slave is always active in trunk mode\n");
-
-		/* always active in trunk mode */
-		bond_set_active_slave(new_slave);
-
-		/* In trunking mode there is little meaning to curr_active_slave
-		 * anyway (it holds no special properties of the bond device),
-		 * so we can change it without calling change_active_interface()
-		 */
-		if (!rcu_access_pointer(bond->curr_active_slave) &&
-		    new_slave->link == BOND_LINK_UP)
-			rcu_assign_pointer(bond->curr_active_slave, new_slave);
-
-		break;
-	} /* switch(bond_mode) */
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	if (bond->dev->npinfo) {
-		if (slave_enable_netpoll(new_slave)) {
-			slave_info(bond_dev, slave_dev, "master_dev is using netpoll, but new slave device does not support netpoll\n");
-			res = -EBUSY;
-			goto err_detach;
-		}
-	}
-#endif
-
-	if (!(bond_dev->features & NETIF_F_LRO))
-		dev_disable_lro(slave_dev);
-
-	res = netdev_rx_handler_register(slave_dev, bond_handle_frame,
-					 new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling netdev_rx_handler_register\n", res);
-		goto err_detach;
-	}
-
-	res = bond_master_upper_dev_link(bond, new_slave, extack);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_master_upper_dev_link\n", res);
-		goto err_unregister;
-	}
-
-	res = bond_sysfs_slave_add(new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_sysfs_slave_add\n", res);
-		goto err_upper_unlink;
-	}
-
-	/* If the mode uses primary, then the following is handled by
-	 * bond_change_active_slave().
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* set promiscuity level to new slave */
-		if (bond_dev->flags & IFF_PROMISC) {
-			res = dev_set_promiscuity(slave_dev, 1);
-			if (res)
-				goto err_sysfs_del;
-		}
-
-		/* set allmulti level to new slave */
-		if (bond_dev->flags & IFF_ALLMULTI) {
-			res = dev_set_allmulti(slave_dev, 1);
-			if (res) {
-				if (bond_dev->flags & IFF_PROMISC)
-					dev_set_promiscuity(slave_dev, -1);
-				goto err_sysfs_del;
-			}
-		}
-
-		netif_addr_lock_bh(bond_dev);
-		dev_mc_sync_multiple(slave_dev, bond_dev);
-		dev_uc_sync_multiple(slave_dev, bond_dev);
-		netif_addr_unlock_bh(bond_dev);
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			/* add lacpdu mc addr to mc list */
-			u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-			dev_mc_add(slave_dev, lacpdu_multicast);
-		}
-	}
-
-	bond->slave_cnt++;
-	bond_compute_features(bond);
-	bond_set_carrier(bond);
-
-	if (bond_uses_primary(bond)) {
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-
-	slave_info(bond_dev, slave_dev, "Enslaving as %s interface with %s link\n",
-		   bond_is_active_slave(new_slave) ? "an active" : "a backup",
-		   new_slave->link != BOND_LINK_DOWN ? "an up" : "a down");
-
-	/* enslave is successful */
-	bond_queue_slave_event(new_slave);
-	return 0;
-
-/* Undo stages on error */
-err_sysfs_del:
-	bond_sysfs_slave_del(new_slave);
-
-err_upper_unlink:
-	bond_upper_dev_unlink(bond, new_slave);
-
-err_unregister:
-	netdev_rx_handler_unregister(slave_dev);
-
-err_detach:
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-	if (rcu_access_pointer(bond->primary_slave) == new_slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-	if (rcu_access_pointer(bond->curr_active_slave) == new_slave) {
-		block_netpoll_tx();
-		bond_change_active_slave(bond, NULL);
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-	/* either primary_slave or curr_active_slave might've changed */
-	synchronize_rcu();
-	slave_disable_netpoll(new_slave);
-
-err_close:
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-	dev_close(slave_dev);
-
-err_restore_mac:
-	slave_dev->flags &= ~IFF_SLAVE;
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* XXX TODO - fom follow mode needs to change master's
-		 * MAC if this slave's MAC is in use by the bond, or at
-		 * least print a warning.
-		 */
-		bond_hw_addr_copy(ss.__data, new_slave->perm_hwaddr,
-				  new_slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-err_restore_mtu:
-	dev_set_mtu(slave_dev, new_slave->original_mtu);
-
-err_free:
-	bond_free_slave(new_slave);
-
-err_undo_flags:
-	/* Enslave of first slave has failed and we need to fix master's mac */
-	if (!bond_has_slaves(bond)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr,
-					    slave_dev->dev_addr))
-			eth_hw_addr_random(bond_dev);
-		if (bond_dev->type != ARPHRD_ETHER) {
-			dev_close(bond_dev);
-			ether_setup(bond_dev);
-			bond_dev->flags |= IFF_MASTER;
-			bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-		}
-	}
-
-	return res;
-}
-
-/* Try to release the slave device <slave> from the bond device <master>
- * It is legal to access curr_active_slave without a lock because all the function
- * is RTNL-locked. If "all" is true it means that the function is being called
- * while destroying a bond interface and all slaves are being released.
- *
- * The rules for slave state should be:
- *   for Active/Backup:
- *     Active stays on all backups go down
- *   for Bonded connections:
- *     The first up interface should be left on and all others downed.
- */
-static int __bond_release_one(struct net_device *bond_dev,
-			      struct net_device *slave_dev,
-			      bool all, bool unregister)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *oldcurrent;
-	struct sockaddr_storage ss;
-	int old_flags = bond_dev->flags;
-	netdev_features_t old_features = bond_dev->features;
-
-	/* slave is not a slave or master is not master of this slave */
-	if (!(slave_dev->flags & IFF_SLAVE) ||
-	    !netdev_has_upper_dev(slave_dev, bond_dev)) {
-		slave_dbg(bond_dev, slave_dev, "cannot release slave\n");
-		return -EINVAL;
-	}
-
-	block_netpoll_tx();
-
-	slave = bond_get_slave_by_dev(bond, slave_dev);
-	if (!slave) {
-		/* not a slave of this bond */
-		slave_info(bond_dev, slave_dev, "interface not enslaved\n");
-		unblock_netpoll_tx();
-		return -EINVAL;
-	}
-
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
-	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
-
-	bond_sysfs_slave_del(slave);
-
-	/* recompute stats just before removing the slave */
-	bond_get_stats(bond->dev, &bond->bond_stats);
-
-	bond_upper_dev_unlink(bond, slave);
-	/* unregister rx_handler early so bond_handle_frame wouldn't be called
-	 * for this slave anymore.
-	 */
-	netdev_rx_handler_unregister(slave_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		bond_3ad_unbind_slave(slave);
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, slave);
-
-	slave_info(bond_dev, slave_dev, "Releasing %s interface\n",
-		    bond_is_active_slave(slave) ? "active" : "backup");
-
-	oldcurrent = rcu_access_pointer(bond->curr_active_slave);
-
-	RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-
-	if (!all && (!bond->params.fail_over_mac ||
-		     BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr, slave->perm_hwaddr) &&
-		    bond_has_slaves(bond))
-			slave_warn(bond_dev, slave_dev, "the permanent HWaddr of slave - %pM - is still in use by bond - set the HWaddr of slave to a different address to avoid conflicts\n",
-				   slave->perm_hwaddr);
-	}
-
-	if (rtnl_dereference(bond->primary_slave) == slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-
-	if (oldcurrent == slave)
-		bond_change_active_slave(bond, NULL);
-
-	if (bond_is_lb(bond)) {
-		/* Must be called only after the slave has been
-		 * detached from the list and the curr_active_slave
-		 * has been cleared (if our_slave == old_current),
-		 * but before a new active slave is selected.
-		 */
-		bond_alb_deinit_slave(bond, slave);
-	}
-
-	if (all) {
-		toe_failover(bond_dev, NULL, TOE_RELEASE_ALL, NULL);
-		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
-	} else if (oldcurrent == slave) {
-		/* Note that we hold RTNL over this sequence, so there
-		 * is no concern that another slave add/remove event
-		 * will interfere.
-		 */
-		bond_select_active_slave(bond);
-	}
-
-	if (!bond_has_slaves(bond)) {
-		bond_set_carrier(bond);
-		eth_hw_addr_random(bond_dev);
-	}
-
-	unblock_netpoll_tx();
-	synchronize_rcu();
-	bond->slave_cnt--;
-
-	if (!bond_has_slaves(bond)) {
-		call_netdevice_notifiers(NETDEV_CHANGEADDR, bond->dev);
-		call_netdevice_notifiers(NETDEV_RELEASE, bond->dev);
-	}
-
-	bond_compute_features(bond);
-	if (!(bond_dev->features & NETIF_F_VLAN_CHALLENGED) &&
-	    (old_features & NETIF_F_VLAN_CHALLENGED))
-		slave_info(bond_dev, slave_dev, "last VLAN challenged slave left bond - VLAN blocking is removed\n");
-
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-
-	/* If the mode uses primary, then this case was handled above by
-	 * bond_change_active_slave(..., NULL)
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* unset promiscuity level from slave
-		 * NOTE: The NETDEV_CHANGEADDR call above may change the value
-		 * of the IFF_PROMISC flag in the bond_dev, but we need the
-		 * value of that flag before that change, as that was the value
-		 * when this slave was attached, so we cache at the start of the
-		 * function and use it here. Same goes for ALLMULTI below
-		 */
-		if (old_flags & IFF_PROMISC)
-			dev_set_promiscuity(slave_dev, -1);
-
-		/* unset allmulti level from slave */
-		if (old_flags & IFF_ALLMULTI)
-			dev_set_allmulti(slave_dev, -1);
-
-		bond_hw_addr_flush(bond_dev, slave_dev);
-	}
-
-	slave_disable_netpoll(slave);
-
-	/* close slave before restoring its mac address */
-	dev_close(slave_dev);
-
-	if (bond->params.fail_over_mac != BOND_FOM_ACTIVE ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* restore original ("permanent") mac address */
-		bond_hw_addr_copy(ss.__data, slave->perm_hwaddr,
-				  slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-	if (unregister)
-		__dev_set_mtu(slave_dev, slave->original_mtu);
-	else
-		dev_set_mtu(slave_dev, slave->original_mtu);
-
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-
-	bond_free_slave(slave);
-
-	return 0;
-}
-
-/* A wrapper used because of ndo_del_link */
-int bond_release(struct net_device *bond_dev, struct net_device *slave_dev)
-{
-	return __bond_release_one(bond_dev, slave_dev, false, false);
-}
-
-/* First release a slave and then destroy the bond if no more slaves are left.
- * Must be under rtnl_lock when this function is called.
- */
-static int bond_release_and_destroy(struct net_device *bond_dev,
-				    struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	int ret;
-
-	ret = __bond_release_one(bond_dev, slave_dev, false, true);
-	if (ret == 0 && !bond_has_slaves(bond)) {
-		bond_dev->priv_flags |= IFF_DISABLE_NETPOLL;
-		netdev_info(bond_dev, "Destroying bond\n");
-		bond_remove_proc_entry(bond);
-		unregister_netdevice(bond_dev);
-	}
-	return ret;
-}
-
-static void bond_info_query(struct net_device *bond_dev, struct ifbond *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	bond_fill_ifbond(bond, info);
-}
-
-static int bond_slave_info_query(struct net_device *bond_dev, struct ifslave *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	int i = 0, res = -ENODEV;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (i++ == (int)info->slave_id) {
-			res = 0;
-			bond_fill_ifslave(slave, info);
-			break;
-		}
-	}
-
-	return res;
-}
-
-/*-------------------------------- Monitoring -------------------------------*/
-
-/* called with rcu_read_lock() */
-static int bond_miimon_inspect(struct bonding *bond)
-{
-	int link_state, commit = 0;
-	struct list_head *iter;
-	struct slave *slave;
-	bool ignore_updelay;
-
-	ignore_updelay = !rcu_dereference(bond->curr_active_slave);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		link_state = bond_check_dev_link(bond, slave->dev, 0);
-
-		switch (slave->link) {
-		case BOND_LINK_UP:
-			if (link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_FAIL);
-			commit++;
-			slave->delay = bond->params.downdelay;
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status down for %sinterface, disabling it in %d ms\n",
-					   (BOND_MODE(bond) ==
-					    BOND_MODE_ACTIVEBACKUP) ?
-					    (bond_is_active_slave(slave) ?
-					     "active " : "backup ") : "",
-					   bond->params.downdelay * bond->params.miimon);
-			}
-			/*FALLTHRU*/
-		case BOND_LINK_FAIL:
-			if (link_state) {
-				/* recovered before downdelay expired */
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave->last_link_up = jiffies;
-				slave_info(bond->dev, slave->dev, "link status up again after %d ms\n",
-					   (bond->params.downdelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				commit++;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-
-		case BOND_LINK_DOWN:
-			if (!link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_BACK);
-			commit++;
-			slave->delay = bond->params.updelay;
-
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status up, enabling it in %d ms\n",
-					   ignore_updelay ? 0 :
-					   bond->params.updelay *
-					   bond->params.miimon);
-			}
-			/*FALLTHRU*/
-		case BOND_LINK_BACK:
-			if (!link_state) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_info(bond->dev, slave->dev, "link status down again after %d ms\n",
-					   (bond->params.updelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (ignore_updelay)
-				slave->delay = 0;
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-				ignore_updelay = false;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-		}
-	}
-
-	return commit;
-}
-
-static void bond_miimon_link_change(struct bonding *bond,
-				    struct slave *slave,
-				    char link)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_8023AD:
-		bond_3ad_handle_link_change(slave, link);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_alb_handle_link_change(bond, slave, link);
-		break;
-	case BOND_MODE_XOR:
-		bond_update_slave_arr(bond, NULL);
-		break;
-	}
-}
-
-static void bond_miimon_commit(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave, *primary;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			/* For 802.3ad mode, check current slave speed and
-			 * duplex again in case its port was disabled after
-			 * invalid speed/duplex reporting but recovered before
-			 * link monitoring could make a decision on the actual
-			 * link status
-			 */
-			if (BOND_MODE(bond) == BOND_MODE_8023AD &&
-			    slave->link == BOND_LINK_UP)
-				bond_3ad_adapter_speed_duplex_changed(slave);
-			continue;
-
-		case BOND_LINK_UP:
-			if (bond_update_speed_duplex(slave) &&
-			    bond_needs_speed_duplex(bond)) {
-				slave->link = BOND_LINK_DOWN;
-				if (net_ratelimit())
-					slave_warn(bond->dev, slave->dev,
-						   "failed to get link speed/duplex\n");
-				continue;
-			}
-			bond_set_slave_link_state(slave, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-			slave->last_link_up = jiffies;
-
-			primary = rtnl_dereference(bond->primary_slave);
-			if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-				/* prevent it from being the active one */
-				bond_set_backup_slave(slave);
-			} else if (BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-				/* make it immediately active */
-				bond_set_active_slave(slave);
-			}
-
-			slave_info(bond->dev, slave->dev, "link status definitely up, %u Mbps %s duplex\n",
-				   slave->speed == SPEED_UNKNOWN ? 0 : slave->speed,
-				   slave->duplex ? "full" : "half");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_UP);
-
-			if (BOND_MODE(bond) == BOND_MODE_XOR ||
-			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
-				toe_failover(netdev_master_upper_dev_get(slave->dev),
-					     slave->dev, TOE_LINK_UP, NULL);
-
-			if (!bond->curr_active_slave || slave == primary)
-				goto do_failover;
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP ||
-			    BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_DOWN);
-
-			if (BOND_MODE(bond) == BOND_MODE_XOR ||
-			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
-				toe_failover(netdev_master_upper_dev_get(slave->dev),
-					     slave->dev, TOE_LINK_DOWN, NULL);
-
-			if (slave == rcu_access_pointer(bond->curr_active_slave))
-				goto do_failover;
-
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev, "invalid new link %d on slave\n",
-				  slave->link_new_state);
-			bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* bond_mii_monitor
- *
- * Really a wrapper that splits the mii monitor into two phases: an
- * inspection, then (if inspection indicates something needs to be done)
- * an acquisition of appropriate locks followed by a commit phase to
- * implement whatever link state changes are indicated.
- */
-static void bond_mii_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mii_work.work);
-	bool should_notify_peers = false;
-	bool commit;
-	unsigned long delay;
-	struct slave *slave;
-	struct list_head *iter;
-
-	delay = msecs_to_jiffies(bond->params.miimon);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-	should_notify_peers = bond_should_notify_peers(bond);
-	commit = !!bond_miimon_inspect(bond);
-	if (bond->send_peer_notif) {
-		rcu_read_unlock();
-		if (rtnl_trylock()) {
-			bond->send_peer_notif--;
-			rtnl_unlock();
-		}
-	} else {
-		rcu_read_unlock();
-	}
-
-	if (commit) {
-		/* Race avoidance with bond_close cancel of workqueue */
-		if (!rtnl_trylock()) {
-			delay = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_for_each_slave(bond, slave, iter) {
-			bond_commit_link_state(slave, BOND_SLAVE_NOTIFY_LATER);
-		}
-		bond_miimon_commit(bond);
-
-		rtnl_unlock();	/* might sleep, hold no other locks */
-	}
-
-re_arm:
-	if (bond->params.miimon)
-		queue_delayed_work(bond->wq, &bond->mii_work, delay);
-
-	if (should_notify_peers) {
-		if (!rtnl_trylock())
-			return;
-		call_netdevice_notifiers(NETDEV_NOTIFY_PEERS, bond->dev);
-		rtnl_unlock();
-	}
-}
-
-static int bond_upper_dev_walk(struct net_device *upper, void *data)
-{
-	__be32 ip = *((__be32 *)data);
-
-	return ip == bond_confirm_addr(upper, 0, ip);
-}
-
-static bool bond_has_this_ip(struct bonding *bond, __be32 ip)
-{
-	bool ret = false;
-
-	if (ip == bond_confirm_addr(bond->dev, 0, ip))
-		return true;
-
-	rcu_read_lock();
-	if (netdev_walk_all_upper_dev_rcu(bond->dev, bond_upper_dev_walk, &ip))
-		ret = true;
-	rcu_read_unlock();
-
-	return ret;
-}
-
-/* We go to the (large) trouble of VLAN tagging ARP frames because
- * switches in VLAN mode (especially if ports are configured as
- * "native" to a VLAN) might not pass non-tagged frames.
- */
-static void bond_arp_send(struct slave *slave, int arp_op, __be32 dest_ip,
-			  __be32 src_ip, struct bond_vlan_tag *tags)
-{
-	struct sk_buff *skb;
-	struct bond_vlan_tag *outer_tag = tags;
-	struct net_device *slave_dev = slave->dev;
-	struct net_device *bond_dev = slave->bond->dev;
-
-	slave_dbg(bond_dev, slave_dev, "arp %d on slave: dst %pI4 src %pI4\n",
-		  arp_op, &dest_ip, &src_ip);
-
-	skb = arp_create(arp_op, ETH_P_ARP, dest_ip, slave_dev, src_ip,
-			 NULL, slave_dev->dev_addr, NULL);
-
-	if (!skb) {
-		net_err_ratelimited("ARP packet allocation failed\n");
-		return;
-	}
-
-	if (!tags || tags->vlan_proto == VLAN_N_VID)
-		goto xmit;
-
-	tags++;
-
-	/* Go through all the tags backwards and add them to the packet */
-	while (tags->vlan_proto != VLAN_N_VID) {
-		if (!tags->vlan_id) {
-			tags++;
-			continue;
-		}
-
-		slave_dbg(bond_dev, slave_dev, "inner tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), tags->vlan_id);
-		skb = vlan_insert_tag_set_proto(skb, tags->vlan_proto,
-						tags->vlan_id);
-		if (!skb) {
-			net_err_ratelimited("failed to insert inner VLAN tag\n");
-			return;
-		}
-
-		tags++;
-	}
-	/* Set the outer tag */
-	if (outer_tag->vlan_id) {
-		slave_dbg(bond_dev, slave_dev, "outer tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), outer_tag->vlan_id);
-		__vlan_hwaccel_put_tag(skb, outer_tag->vlan_proto,
-				       outer_tag->vlan_id);
-	}
-
-xmit:
-	arp_xmit(skb);
-}
-
-/* Validate the device path between the @start_dev and the @end_dev.
- * The path is valid if the @end_dev is reachable through device
- * stacking.
- * When the path is validated, collect any vlan information in the
- * path.
- */
-struct bond_vlan_tag *bond_verify_device_path(struct net_device *start_dev,
-					      struct net_device *end_dev,
-					      int level)
-{
-	struct bond_vlan_tag *tags;
-	struct net_device *upper;
-	struct list_head  *iter;
-
-	if (start_dev == end_dev) {
-		tags = kcalloc(level + 1, sizeof(*tags), GFP_ATOMIC);
-		if (!tags)
-			return ERR_PTR(-ENOMEM);
-		tags[level].vlan_proto = VLAN_N_VID;
-		return tags;
-	}
-
-	netdev_for_each_upper_dev_rcu(start_dev, upper, iter) {
-		tags = bond_verify_device_path(upper, end_dev, level + 1);
-		if (IS_ERR_OR_NULL(tags)) {
-			if (IS_ERR(tags))
-				return tags;
-			continue;
-		}
-		if (is_vlan_dev(upper)) {
-			tags[level].vlan_proto = vlan_dev_vlan_proto(upper);
-			tags[level].vlan_id = vlan_dev_vlan_id(upper);
-		}
-
-		return tags;
-	}
-
-	return NULL;
-}
-
-static void bond_arp_send_all(struct bonding *bond, struct slave *slave)
-{
-	struct rtable *rt;
-	struct bond_vlan_tag *tags;
-	__be32 *targets = bond->params.arp_targets, addr;
-	int i;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS && targets[i]; i++) {
-		slave_dbg(bond->dev, slave->dev, "%s: target %pI4\n",
-			  __func__, &targets[i]);
-		tags = NULL;
-
-		/* Find out through which dev should the packet go */
-		rt = ip_route_output(dev_net(bond->dev), targets[i], 0,
-				     RTO_ONLINK, 0);
-		if (IS_ERR(rt)) {
-			/* there's no route to target - try to send arp
-			 * probe to generate any traffic (arp_validate=0)
-			 */
-			if (bond->params.arp_validate)
-				net_warn_ratelimited("%s: no route to arp_ip_target %pI4 and arp_validate is set\n",
-						     bond->dev->name,
-						     &targets[i]);
-			bond_arp_send(slave, ARPOP_REQUEST, targets[i],
-				      0, tags);
-			continue;
-		}
-
-		/* bond device itself */
-		if (rt->dst.dev == bond->dev)
-			goto found;
-
-		rcu_read_lock();
-		tags = bond_verify_device_path(bond->dev, rt->dst.dev, 0);
-		rcu_read_unlock();
-
-		if (!IS_ERR_OR_NULL(tags))
-			goto found;
-
-		/* Not our device - skip */
-		slave_dbg(bond->dev, slave->dev, "no path to arp_ip_target %pI4 via rt.dev %s\n",
-			   &targets[i], rt->dst.dev ? rt->dst.dev->name : "NULL");
-
-		ip_rt_put(rt);
-		continue;
-
-found:
-		addr = bond_confirm_addr(rt->dst.dev, targets[i], 0);
-		ip_rt_put(rt);
-		bond_arp_send(slave, ARPOP_REQUEST, targets[i], addr, tags);
-		kfree(tags);
-	}
-}
-
-static void bond_validate_arp(struct bonding *bond, struct slave *slave, __be32 sip, __be32 tip)
-{
-	int i;
-
-	if (!sip || !bond_has_this_ip(bond, tip)) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 tip %pI4 not found\n",
-			   __func__, &sip, &tip);
-		return;
-	}
-
-	i = bond_get_targets_ip(bond->params.arp_targets, sip);
-	if (i == -1) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 not found in targets\n",
-			   __func__, &sip);
-		return;
-	}
-	slave->last_rx = jiffies;
-	slave->target_last_arp_rx[i] = jiffies;
-}
-
-int bond_arp_rcv(const struct sk_buff *skb, struct bonding *bond,
-		 struct slave *slave)
-{
-	struct arphdr *arp = (struct arphdr *)skb->data;
-	struct slave *curr_active_slave, *curr_arp_slave;
-	unsigned char *arp_ptr;
-	__be32 sip, tip;
-	int is_arp = skb->protocol == __cpu_to_be16(ETH_P_ARP);
-	unsigned int alen;
-
-	if (!slave_do_arp_validate(bond, slave)) {
-		if ((slave_do_arp_validate_only(bond) && is_arp) ||
-		    !slave_do_arp_validate_only(bond))
-			slave->last_rx = jiffies;
-		return RX_HANDLER_ANOTHER;
-	} else if (!is_arp) {
-		return RX_HANDLER_ANOTHER;
-	}
-
-	alen = arp_hdr_len(bond->dev);
-
-	slave_dbg(bond->dev, slave->dev, "%s: skb->dev %s\n",
-		   __func__, skb->dev->name);
-
-	if (alen > skb_headlen(skb)) {
-		arp = kmalloc(alen, GFP_ATOMIC);
-		if (!arp)
-			goto out_unlock;
-		if (skb_copy_bits(skb, 0, arp, alen) < 0)
-			goto out_unlock;
-	}
-
-	if (arp->ar_hln != bond->dev->addr_len ||
-	    skb->pkt_type == PACKET_OTHERHOST ||
-	    skb->pkt_type == PACKET_LOOPBACK ||
-	    arp->ar_hrd != htons(ARPHRD_ETHER) ||
-	    arp->ar_pro != htons(ETH_P_IP) ||
-	    arp->ar_pln != 4)
-		goto out_unlock;
-
-	arp_ptr = (unsigned char *)(arp + 1);
-	arp_ptr += bond->dev->addr_len;
-	memcpy(&sip, arp_ptr, 4);
-	arp_ptr += 4 + bond->dev->addr_len;
-	memcpy(&tip, arp_ptr, 4);
-
-	slave_dbg(bond->dev, slave->dev, "%s: %s/%d av %d sv %d sip %pI4 tip %pI4\n",
-		  __func__, slave->dev->name, bond_slave_state(slave),
-		  bond->params.arp_validate, slave_do_arp_validate(bond, slave),
-		  &sip, &tip);
-
-	curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	curr_arp_slave = rcu_dereference(bond->current_arp_slave);
-
-	/* We 'trust' the received ARP enough to validate it if:
-	 *
-	 * (a) the slave receiving the ARP is active (which includes the
-	 * current ARP slave, if any), or
-	 *
-	 * (b) the receiving slave isn't active, but there is a currently
-	 * active slave and it received valid arp reply(s) after it became
-	 * the currently active slave, or
-	 *
-	 * (c) there is an ARP slave that sent an ARP during the prior ARP
-	 * interval, and we receive an ARP reply on any slave.  We accept
-	 * these because switch FDB update delays may deliver the ARP
-	 * reply to a slave other than the sender of the ARP request.
-	 *
-	 * Note: for (b), backup slaves are receiving the broadcast ARP
-	 * request, not a reply.  This request passes from the sending
-	 * slave through the L2 switch(es) to the receiving slave.  Since
-	 * this is checking the request, sip/tip are swapped for
-	 * validation.
-	 *
-	 * This is done to avoid endless looping when we can't reach the
-	 * arp_ip_target and fool ourselves with our own arp requests.
-	 */
-	if (bond_is_active_slave(slave))
-		bond_validate_arp(bond, slave, sip, tip);
-	else if (curr_active_slave &&
-		 time_after(slave_last_rx(bond, curr_active_slave),
-			    curr_active_slave->last_link_up))
-		bond_validate_arp(bond, slave, tip, sip);
-	else if (curr_arp_slave && (arp->ar_op == htons(ARPOP_REPLY)) &&
-		 bond_time_in_interval(bond,
-				       dev_trans_start(curr_arp_slave->dev), 1))
-		bond_validate_arp(bond, slave, sip, tip);
-
-out_unlock:
-	if (arp != (struct arphdr *)skb->data)
-		kfree(arp);
-	return RX_HANDLER_ANOTHER;
-}
-
-/* function to verify if we're in the arp_interval timeslice, returns true if
- * (last_act - arp_interval) <= jiffies <= (last_act + mod * arp_interval +
- * arp_interval/2) . the arp_interval/2 is needed for really fast networks.
- */
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod)
-{
-	int delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	return time_in_range(jiffies,
-			     last_act - delta_in_ticks,
-			     last_act + mod * delta_in_ticks + delta_in_ticks/2);
-}
-
-/* This function is called regularly to monitor each slave's link
- * ensuring that traffic is being sent and received when arp monitoring
- * is used in load-balancing mode. if the adapter has been dormant, then an
- * arp is transmitted to generate traffic. see activebackup_arp_monitor for
- * arp monitoring in active backup mode.
- */
-static void bond_loadbalance_arp_mon(struct bonding *bond)
-{
-	struct slave *slave, *oldcurrent;
-	struct list_head *iter;
-	int do_failover = 0, slave_state_changed = 0;
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	oldcurrent = rcu_dereference(bond->curr_active_slave);
-	/* see if any of the previous devices are up now (i.e. they have
-	 * xmt and rcv traffic). the curr_active_slave does not come into
-	 * the picture unless it is null. also, slave->last_link_up is not
-	 * needed here because we send an arp on each slave and give a slave
-	 * as long as it needs to get the tx/rx within the delta.
-	 * TODO: what about up/down delay in arp mode? it wasn't here before
-	 *       so it can wait
-	 */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		unsigned long trans_start = dev_trans_start(slave->dev);
-
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, trans_start, 1) &&
-			    bond_time_in_interval(bond, slave->last_rx, 1)) {
-
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave_state_changed = 1;
-
-				/* primary_slave has no meaning in round-robin
-				 * mode. the window of a slave being up and
-				 * curr_active_slave being null after enslaving
-				 * is closed.
-				 */
-				if (!oldcurrent) {
-					slave_info(bond->dev, slave->dev, "link status definitely up\n");
-					do_failover = 1;
-				} else {
-					slave_info(bond->dev, slave->dev, "interface is now up\n");
-				}
-			}
-		} else {
-			/* slave->link == BOND_LINK_UP */
-
-			/* not all switches will respond to an arp request
-			 * when the source ip is 0, so don't take the link down
-			 * if we don't know our ip yet
-			 */
-			if (!bond_time_in_interval(bond, trans_start, 2) ||
-			    !bond_time_in_interval(bond, slave->last_rx, 2)) {
-
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_state_changed = 1;
-
-				if (slave->link_failure_count < UINT_MAX)
-					slave->link_failure_count++;
-
-				slave_info(bond->dev, slave->dev, "interface is now down\n");
-
-				if (slave == oldcurrent)
-					do_failover = 1;
-			}
-		}
-
-		/* note: if switch is in round-robin mode, all links
-		 * must tx arp to ensure all links rx an arp - otherwise
-		 * links may oscillate or not come up at all; if switch is
-		 * in something like xor mode, there is nothing we can
-		 * do - all replies will be rx'ed on same link causing slaves
-		 * to be unstable during low/no traffic periods
-		 */
-		if (bond_slave_is_up(slave))
-			bond_arp_send_all(bond, slave);
-	}
-
-	rcu_read_unlock();
-
-	if (do_failover || slave_state_changed) {
-		if (!rtnl_trylock())
-			goto re_arm;
-
-		bond_for_each_slave(bond, slave, iter) {
-			if (slave->link_new_state != BOND_LINK_NOCHANGE)
-				slave->link = slave->link_new_state;
-		}
-
-		if (slave_state_changed) {
-			bond_slave_state_change(bond);
-			if (BOND_MODE(bond) == BOND_MODE_XOR)
-				bond_update_slave_arr(bond, NULL);
-		}
-		if (do_failover) {
-			block_netpoll_tx();
-			bond_select_active_slave(bond);
-			unblock_netpoll_tx();
-		}
-		rtnl_unlock();
-	}
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work,
-				   msecs_to_jiffies(bond->params.arp_interval));
-}
-
-/* Called to inspect slaves for active-backup mode ARP monitor link state
- * changes.  Sets proposed link state in slaves to specify what action
- * should take place for the slave.  Returns 0 if no changes are found, >0
- * if changes to link states must be committed.
- *
- * Called with rcu_read_lock held.
- */
-static int bond_ab_arp_inspect(struct bonding *bond)
-{
-	unsigned long trans_start, last_rx;
-	struct list_head *iter;
-	struct slave *slave;
-	int commit = 0;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-		last_rx = slave_last_rx(bond, slave);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, last_rx, 1)) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-			}
-			continue;
-		}
-
-		/* Give slaves 2*delta after being enslaved or made
-		 * active.  This avoids bouncing, as the last receive
-		 * times need a full ARP monitor cycle to be updated.
-		 */
-		if (bond_time_in_interval(bond, slave->last_link_up, 2))
-			continue;
-
-		/* Backup slave is down if:
-		 * - No current_arp_slave AND
-		 * - more than 3*delta since last receive AND
-		 * - the bond has an IP address
-		 *
-		 * Note: a non-null current_arp_slave indicates
-		 * the curr_active_slave went down and we are
-		 * searching for a new one; under this condition
-		 * we only take the curr_active_slave down - this
-		 * gives each slave a chance to tx/rx traffic
-		 * before being taken out
-		 */
-		if (!bond_is_active_slave(slave) &&
-		    !rcu_access_pointer(bond->current_arp_slave) &&
-		    !bond_time_in_interval(bond, last_rx, 3)) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-
-		/* Active slave is down if:
-		 * - more than 2*delta since transmitting OR
-		 * - (more than 2*delta since receive AND
-		 *    the bond has an IP address)
-		 */
-		trans_start = dev_trans_start(slave->dev);
-		if (bond_is_active_slave(slave) &&
-		    (!bond_time_in_interval(bond, trans_start, 2) ||
-		     !bond_time_in_interval(bond, last_rx, 2))) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-	}
-
-	return commit;
-}
-
-/* Called to commit link state changes noted by inspection step of
- * active-backup mode ARP monitor.
- *
- * Called with RTNL hold.
- */
-static void bond_ab_arp_commit(struct bonding *bond)
-{
-	unsigned long trans_start;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			continue;
-
-		case BOND_LINK_UP:
-			trans_start = dev_trans_start(slave->dev);
-			if (rtnl_dereference(bond->curr_active_slave) != slave ||
-			    (!rtnl_dereference(bond->curr_active_slave) &&
-			     bond_time_in_interval(bond, trans_start, 1))) {
-				struct slave *current_arp_slave;
-
-				current_arp_slave = rtnl_dereference(bond->current_arp_slave);
-				bond_set_slave_link_state(slave, BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-				if (current_arp_slave) {
-					bond_set_slave_inactive_flags(
-						current_arp_slave,
-						BOND_SLAVE_NOTIFY_NOW);
-					RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				}
-
-				slave_info(bond->dev, slave->dev, "link status definitely up\n");
-
-				if (!rtnl_dereference(bond->curr_active_slave) ||
-				    slave == rtnl_dereference(bond->primary_slave))
-					goto do_failover;
-
-			}
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			if (slave == rtnl_dereference(bond->curr_active_slave)) {
-				RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				goto do_failover;
-			}
-
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev,
-				  "impossible: link_new_state %d on slave\n",
-				  slave->link_new_state);
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* Send ARP probes for active-backup mode ARP monitor.
- *
- * Called with rcu_read_lock held.
- */
-static bool bond_ab_arp_probe(struct bonding *bond)
-{
-	struct slave *slave, *before = NULL, *new_slave = NULL,
-		     *curr_arp_slave = rcu_dereference(bond->current_arp_slave),
-		     *curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	struct list_head *iter;
-	bool found = false;
-	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
-
-	if (curr_arp_slave && curr_active_slave)
-		netdev_info(bond->dev, "PROBE: c_arp %s && cas %s BAD\n",
-			    curr_arp_slave->dev->name,
-			    curr_active_slave->dev->name);
-
-	if (curr_active_slave) {
-		bond_arp_send_all(bond, curr_active_slave);
-		return should_notify_rtnl;
-	}
-
-	/* if we don't have a curr_active_slave, search for the next available
-	 * backup slave from the current_arp_slave and make it the candidate
-	 * for becoming the curr_active_slave
-	 */
-
-	if (!curr_arp_slave) {
-		curr_arp_slave = bond_first_slave_rcu(bond);
-		if (!curr_arp_slave)
-			return should_notify_rtnl;
-	}
-
-	bond_set_slave_inactive_flags(curr_arp_slave, BOND_SLAVE_NOTIFY_LATER);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!found && !before && bond_slave_is_up(slave))
-			before = slave;
-
-		if (found && !new_slave && bond_slave_is_up(slave))
-			new_slave = slave;
-		/* if the link state is up at this point, we
-		 * mark it down - this can happen if we have
-		 * simultaneous link failures and
-		 * reselect_active_interface doesn't make this
-		 * one the current slave so it is still marked
-		 * up when it is actually down
-		 */
-		if (!bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_LATER);
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_LATER);
-
-			slave_info(bond->dev, slave->dev, "backup interface is now down\n");
-		}
-		if (slave == curr_arp_slave)
-			found = true;
-	}
-
-	if (!new_slave && before)
-		new_slave = before;
-
-	if (!new_slave)
-		goto check_state;
-
-	bond_set_slave_link_state(new_slave, BOND_LINK_BACK,
-				  BOND_SLAVE_NOTIFY_LATER);
-	bond_set_slave_active_flags(new_slave, BOND_SLAVE_NOTIFY_LATER);
-	bond_arp_send_all(bond, new_slave);
-	new_slave->last_link_up = jiffies;
-	rcu_assign_pointer(bond->current_arp_slave, new_slave);
-
-check_state:
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->should_notify || slave->should_notify_link) {
-			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
-			break;
-		}
-	}
-	return should_notify_rtnl;
-}
-
-static void bond_activebackup_arp_mon(struct bonding *bond)
-{
-	bool should_notify_peers = false;
-	bool should_notify_rtnl = false;
-	int delta_in_ticks;
-
-	delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	should_notify_peers = bond_should_notify_peers(bond);
-
-	if (bond_ab_arp_inspect(bond)) {
-		rcu_read_unlock();
-
-		/* Race avoidance with bond_close flush of workqueue */
-		if (!rtnl_trylock()) {
-			delta_in_ticks = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_ab_arp_commit(bond);
-
-		rtnl_unlock();
-		rcu_read_lock();
-	}
-
-	should_notify_rtnl = bond_ab_arp_probe(bond);
-	rcu_read_unlock();
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work, delta_in_ticks);
-
-	if (should_notify_peers || should_notify_rtnl) {
-		if (!rtnl_trylock())
-			return;
-
-		if (should_notify_peers)
-			call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-						 bond->dev);
-		if (should_notify_rtnl) {
-			bond_slave_state_notify(bond);
-			bond_slave_link_notify(bond);
-		}
-
-		rtnl_unlock();
-	}
-}
-
-static void bond_arp_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    arp_work.work);
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		bond_activebackup_arp_mon(bond);
-	else
-		bond_loadbalance_arp_mon(bond);
-}
-
-/*-------------------------- netdev event handling --------------------------*/
-
-/* Change device name */
-static int bond_event_changename(struct bonding *bond)
-{
-	bond_remove_proc_entry(bond);
-	bond_create_proc_entry(bond);
-
-	bond_debug_reregister(bond);
-
-	return NOTIFY_DONE;
-}
-
-static int bond_master_netdev_event(unsigned long event,
-				    struct net_device *bond_dev)
-{
-	struct bonding *event_bond = netdev_priv(bond_dev);
-
-	netdev_dbg(bond_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_CHANGENAME:
-		return bond_event_changename(event_bond);
-	case NETDEV_UNREGISTER:
-		bond_remove_proc_entry(event_bond);
-		break;
-	case NETDEV_REGISTER:
-		bond_create_proc_entry(event_bond);
-		break;
-	case NETDEV_DOWN: {
-		struct slave *slave = bond_first_slave(event_bond);
-
-		toe_failover(bond_dev, slave ? slave->dev : NULL,
-			     TOE_BOND_DOWN, NULL);
-		break;
-	}
-	case NETDEV_UP: {
-		struct slave *slave = bond_first_slave(event_bond);
-
-		toe_failover(bond_dev, slave ? slave->dev : NULL,
-			     TOE_BOND_UP, NULL);
-		break;
-	}
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-static int bond_slave_netdev_event(unsigned long event,
-				   struct net_device *slave_dev)
-{
-	struct slave *slave = bond_slave_get_rtnl(slave_dev), *primary;
-	struct bonding *bond;
-	struct net_device *bond_dev;
-
-	/* A netdev event can be generated while enslaving a device
-	 * before netdev_rx_handler_register is called in which case
-	 * slave will be NULL
-	 */
-	if (!slave) {
-		netdev_dbg(slave_dev, "%s called on NULL slave\n", __func__);
-		return NOTIFY_DONE;
-	}
-
-	bond_dev = slave->bond->dev;
-	bond = slave->bond;
-	primary = rtnl_dereference(bond->primary_slave);
-
-	slave_dbg(bond_dev, slave_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_UNREGISTER:
-		if (bond_dev->type != ARPHRD_ETHER)
-			bond_release_and_destroy(bond_dev, slave_dev);
-		else
-			__bond_release_one(bond_dev, slave_dev, false, true);
-		break;
-	case NETDEV_UP:
-	case NETDEV_CHANGE:
-		/* For 802.3ad mode only:
-		 * Getting invalid Speed/Duplex values here will put slave
-		 * in weird state. Mark it as link-fail if the link was
-		 * previously up or link-down if it hasn't yet come up, and
-		 * let link-monitoring (miimon) set it right when correct
-		 * speeds/duplex are available.
-		 */
-		if (bond_update_speed_duplex(slave) &&
-		    BOND_MODE(bond) == BOND_MODE_8023AD) {
-			if (slave->last_link_up)
-				slave->link = BOND_LINK_FAIL;
-			else
-				slave->link = BOND_LINK_DOWN;
-		}
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD)
-			bond_3ad_adapter_speed_duplex_changed(slave);
-		/* Fallthrough */
-	case NETDEV_DOWN:
-		/* Refresh slave-array if applicable!
-		 * If the setup does not use miimon or arpmon (mode-specific!),
-		 * then these events will not cause the slave-array to be
-		 * refreshed. This will cause xmit to use a slave that is not
-		 * usable. Avoid such situation by refeshing the array at these
-		 * events. If these (miimon/arpmon) parameters are configured
-		 * then array gets refreshed twice and that should be fine!
-		 */
-		if (bond_mode_can_use_xmit_hash(bond))
-			bond_update_slave_arr(bond, NULL);
-		break;
-	case NETDEV_CHANGEMTU:
-		/* TODO: Should slaves be allowed to
-		 * independently alter their MTU?  For
-		 * an active-backup bond, slaves need
-		 * not be the same type of device, so
-		 * MTUs may vary.  For other modes,
-		 * slaves arguably should have the
-		 * same MTUs. To do this, we'd need to
-		 * take over the slave's change_mtu
-		 * function for the duration of their
-		 * servitude.
-		 */
-		break;
-	case NETDEV_CHANGENAME:
-		/* we don't care if we don't have primary set */
-		if (!bond_uses_primary(bond) ||
-		    !bond->params.primary[0])
-			break;
-
-		if (slave == primary) {
-			/* slave's name changed - he's no longer primary */
-			RCU_INIT_POINTER(bond->primary_slave, NULL);
-		} else if (!strcmp(slave_dev->name, bond->params.primary)) {
-			/* we have a new primary slave */
-			rcu_assign_pointer(bond->primary_slave, slave);
-		} else { /* we didn't change primary - exit */
-			break;
-		}
-
-		netdev_info(bond->dev, "Primary slave changed to %s, reselecting active slave\n",
-			    primary ? slave_dev->name : "none");
-
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-		break;
-	case NETDEV_FEAT_CHANGE:
-		bond_compute_features(bond);
-		break;
-	case NETDEV_RESEND_IGMP:
-		/* Propagate to master device */
-		call_netdevice_notifiers(event, slave->bond->dev);
-		break;
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-/* bond_netdev_event: handle netdev notifier chain events.
- *
- * This function receives events for the netdev chain.  The caller (an
- * ioctl handler calling blocking_notifier_call_chain) holds the necessary
- * locks for us to safely manipulate the slave devices (RTNL lock,
- * dev_probe_lock).
- */
-static int bond_netdev_event(struct notifier_block *this,
-			     unsigned long event, void *ptr)
-{
-	struct net_device *event_dev = netdev_notifier_info_to_dev(ptr);
-
-	netdev_dbg(event_dev, "%s received %s\n",
-		   __func__, netdev_cmd_to_name(event));
-
-	if (!(event_dev->priv_flags & IFF_BONDING))
-		return NOTIFY_DONE;
-
-	if (event_dev->flags & IFF_MASTER) {
-		int ret;
-
-		ret = bond_master_netdev_event(event, event_dev);
-		if (ret != NOTIFY_DONE)
-			return ret;
-	}
-
-	if (event_dev->flags & IFF_SLAVE)
-		return bond_slave_netdev_event(event, event_dev);
-
-	return NOTIFY_DONE;
-}
-
-static struct notifier_block bond_netdev_notifier = {
-	.notifier_call = bond_netdev_event,
-};
-
-/*---------------------------- Hashing Policies -----------------------------*/
-
-/* L2 hash helper */
-static inline u32 bond_eth_hash(struct sk_buff *skb)
-{
-	struct ethhdr *ep, hdr_tmp;
-
-	ep = skb_header_pointer(skb, 0, sizeof(hdr_tmp), &hdr_tmp);
-	if (ep)
-		return ep->h_dest[5] ^ ep->h_source[5] ^ ep->h_proto;
-	return 0;
-}
-
-/* Extract the appropriate headers based on bond's xmit policy */
-static bool bond_flow_dissect(struct bonding *bond, struct sk_buff *skb,
-			      struct flow_keys *fk)
-{
-	const struct ipv6hdr *iph6;
-	const struct iphdr *iph;
-	int noff, proto = -1;
-
-	if (bond->params.xmit_policy > BOND_XMIT_POLICY_LAYER23)
-		return skb_flow_dissect_flow_keys(skb, fk, 0);
-
-	fk->ports.ports = 0;
-	noff = skb_network_offset(skb);
-	if (skb->protocol == htons(ETH_P_IP)) {
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
-			return false;
-		iph = ip_hdr(skb);
-		iph_to_flow_copy_v4addrs(fk, iph);
-		noff += iph->ihl << 2;
-		if (!ip_is_fragment(iph))
-			proto = iph->protocol;
-	} else if (skb->protocol == htons(ETH_P_IPV6)) {
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph6))))
-			return false;
-		iph6 = ipv6_hdr(skb);
-		iph_to_flow_copy_v6addrs(fk, iph6);
-		noff += sizeof(*iph6);
-		proto = iph6->nexthdr;
-	} else {
-		return false;
-	}
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER34 && proto >= 0)
-		fk->ports.ports = skb_flow_get_ports(skb, noff, proto);
-
-	return true;
-}
-
-/**
- * bond_xmit_hash - generate a hash value based on the xmit policy
- * @bond: bonding device
- * @skb: buffer to use for headers
- *
- * This function will extract the necessary headers from the skb buffer and use
- * them to generate a hash based on the xmit_policy set in the bonding device
- */
-u32 bond_xmit_hash(struct bonding *bond, struct sk_buff *skb)
-{
-	struct flow_keys flow;
-	u32 hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP34 &&
-	    skb->l4_hash)
-		return skb->hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER2 ||
-	    !bond_flow_dissect(bond, skb, &flow))
-		return bond_eth_hash(skb);
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER23 ||
-	    bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP23)
-		hash = bond_eth_hash(skb);
-	else
-		hash = (__force u32)flow.ports.ports;
-	hash ^= (__force u32)flow_get_u32_dst(&flow) ^
-		(__force u32)flow_get_u32_src(&flow);
-	hash ^= (hash >> 16);
-	hash ^= (hash >> 8);
-
-	return hash >> 1;
-}
-
-/*-------------------------- Device entry points ----------------------------*/
-
-void bond_work_init_all(struct bonding *bond)
-{
-	INIT_DELAYED_WORK(&bond->mcast_work,
-			  bond_resend_igmp_join_requests_delayed);
-	INIT_DELAYED_WORK(&bond->alb_work, bond_alb_monitor);
-	INIT_DELAYED_WORK(&bond->mii_work, bond_mii_monitor);
-	INIT_DELAYED_WORK(&bond->arp_work, bond_arp_monitor);
-	INIT_DELAYED_WORK(&bond->ad_work, bond_3ad_state_machine_handler);
-	INIT_DELAYED_WORK(&bond->slave_arr_work, bond_slave_arr_handler);
-}
-
-static void bond_work_cancel_all(struct bonding *bond)
-{
-	cancel_delayed_work_sync(&bond->mii_work);
-	cancel_delayed_work_sync(&bond->arp_work);
-	cancel_delayed_work_sync(&bond->alb_work);
-	cancel_delayed_work_sync(&bond->ad_work);
-	cancel_delayed_work_sync(&bond->mcast_work);
-	cancel_delayed_work_sync(&bond->slave_arr_work);
-}
-
-static int bond_open(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	/* reset slave->backup and slave->inactive */
-	if (bond_has_slaves(bond)) {
-		bond_for_each_slave(bond, slave, iter) {
-			if (bond_uses_primary(bond) &&
-			    slave != rcu_access_pointer(bond->curr_active_slave)) {
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-			} else if (BOND_MODE(bond) != BOND_MODE_8023AD) {
-				bond_set_slave_active_flags(slave,
-							    BOND_SLAVE_NOTIFY_NOW);
-			}
-		}
-	}
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_initialize must be called before the timer
-		 * is started.
-		 */
-		if (bond_alb_initialize(bond, (BOND_MODE(bond) == BOND_MODE_ALB)))
-			return -ENOMEM;
-		if (bond->params.tlb_dynamic_lb || BOND_MODE(bond) == BOND_MODE_ALB)
-			queue_delayed_work(bond->wq, &bond->alb_work, 0);
-	}
-
-	if (bond->params.miimon)  /* link check interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->mii_work, 0);
-
-	if (bond->params.arp_interval) {  /* arp interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->arp_work, 0);
-		bond->recv_probe = bond_arp_rcv;
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		queue_delayed_work(bond->wq, &bond->ad_work, 0);
-		/* register to receive LACPDUs */
-		bond->recv_probe = bond_3ad_lacpdu_recv;
-		bond_3ad_initiate_agg_selection(bond, 1);
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-	return 0;
-}
-
-static int bond_close(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	bond_work_cancel_all(bond);
-	bond->send_peer_notif = 0;
-	if (bond_is_lb(bond))
-		bond_alb_deinitialize(bond);
-	bond->recv_probe = NULL;
-
-	return 0;
-}
-
-/* fold stats, assuming all rtnl_link_stats64 fields are u64, but
- * that some drivers can provide 32bit values only.
- */
-static void bond_fold_stats(struct rtnl_link_stats64 *_res,
-			    const struct rtnl_link_stats64 *_new,
-			    const struct rtnl_link_stats64 *_old)
-{
-	const u64 *new = (const u64 *)_new;
-	const u64 *old = (const u64 *)_old;
-	u64 *res = (u64 *)_res;
-	int i;
-
-	for (i = 0; i < sizeof(*_res) / sizeof(u64); i++) {
-		u64 nv = new[i];
-		u64 ov = old[i];
-		s64 delta = nv - ov;
-
-		/* detects if this particular field is 32bit only */
-		if (((nv | ov) >> 32) == 0)
-			delta = (s64)(s32)((u32)nv - (u32)ov);
-
-		/* filter anomalies, some drivers reset their stats
-		 * at down/up events.
-		 */
-		if (delta > 0)
-			res[i] += delta;
-	}
-}
-
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct rtnl_link_stats64 temp;
-	struct list_head *iter;
-	struct slave *slave;
-
-	spin_lock(&bond->stats_lock);
-	memcpy(stats, &bond->bond_stats, sizeof(*stats));
-
-	rcu_read_lock();
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		const struct rtnl_link_stats64 *new =
-			dev_get_stats(slave->dev, &temp);
-
-		bond_fold_stats(stats, new, &slave->slave_stats);
-
-		/* save off the slave stats for the next run */
-		memcpy(&slave->slave_stats, new, sizeof(*new));
-	}
-	rcu_read_unlock();
-
-	memcpy(&bond->bond_stats, stats, sizeof(*stats));
-	spin_unlock(&bond->stats_lock);
-}
-
-static int bond_do_ioctl(struct net_device *bond_dev, struct ifreq *ifr, int cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct ifbond k_binfo;
-	struct ifbond __user *u_binfo = NULL;
-	struct ifslave k_sinfo;
-	struct ifslave __user *u_sinfo = NULL;
-	struct mii_ioctl_data *mii = NULL;
-	struct bond_opt_value newval;
-	struct net *net;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond_ioctl: cmd=%d\n", cmd);
-
-	switch (cmd) {
-	case SIOCGMIIPHY:
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		mii->phy_id = 0;
-		/* Fall Through */
-	case SIOCGMIIREG:
-		/* We do this again just in case we were called by SIOCGMIIREG
-		 * instead of SIOCGMIIPHY.
-		 */
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		if (mii->reg_num == 1) {
-			mii->val_out = 0;
-			if (netif_carrier_ok(bond->dev))
-				mii->val_out = BMSR_LSTATUS;
-		}
-
-		return 0;
-	case BOND_INFO_QUERY_OLD:
-	case SIOCBONDINFOQUERY:
-		u_binfo = (struct ifbond __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_binfo, u_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		bond_info_query(bond_dev, &k_binfo);
-		if (copy_to_user(u_binfo, &k_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		return 0;
-	case BOND_SLAVE_INFO_QUERY_OLD:
-	case SIOCBONDSLAVEINFOQUERY:
-		u_sinfo = (struct ifslave __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_sinfo, u_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		res = bond_slave_info_query(bond_dev, &k_sinfo);
-		if (res == 0 &&
-		    copy_to_user(u_sinfo, &k_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		return res;
-	default:
-		break;
-	}
-
-	net = dev_net(bond_dev);
-
-	if (!ns_capable(net->user_ns, CAP_NET_ADMIN))
-		return -EPERM;
-
-	slave_dev = __dev_get_by_name(net, ifr->ifr_slave);
-
-	slave_dbg(bond_dev, slave_dev, "slave_dev=%p:\n", slave_dev);
-
-	if (!slave_dev)
-		return -ENODEV;
-
-	switch (cmd) {
-	case BOND_ENSLAVE_OLD:
-	case SIOCBONDENSLAVE:
-		res = bond_enslave(bond_dev, slave_dev, NULL);
-		break;
-	case BOND_RELEASE_OLD:
-	case SIOCBONDRELEASE:
-		res = bond_release(bond_dev, slave_dev);
-		break;
-	case BOND_SETHWADDR_OLD:
-	case SIOCBONDSETHWADDR:
-		res = bond_set_dev_addr(bond_dev, slave_dev);
-		break;
-	case BOND_CHANGE_ACTIVE_OLD:
-	case SIOCBONDCHANGEACTIVE:
-		bond_opt_initstr(&newval, slave_dev->name);
-		res = __bond_opt_set_notify(bond, BOND_OPT_ACTIVE_SLAVE,
-					    &newval);
-		break;
-	default:
-		res = -EOPNOTSUPP;
-	}
-
-	return res;
-}
-
-static void bond_change_rx_flags(struct net_device *bond_dev, int change)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	if (change & IFF_PROMISC)
-		bond_set_promiscuity(bond,
-				     bond_dev->flags & IFF_PROMISC ? 1 : -1);
-
-	if (change & IFF_ALLMULTI)
-		bond_set_allmulti(bond,
-				  bond_dev->flags & IFF_ALLMULTI ? 1 : -1);
-}
-
-static void bond_set_rx_mode(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	rcu_read_lock();
-	if (bond_uses_primary(bond)) {
-		slave = rcu_dereference(bond->curr_active_slave);
-		if (slave) {
-			dev_uc_sync(slave->dev, bond_dev);
-			dev_mc_sync(slave->dev, bond_dev);
-		}
-	} else {
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			dev_uc_sync_multiple(slave->dev, bond_dev);
-			dev_mc_sync_multiple(slave->dev, bond_dev);
-		}
-	}
-	rcu_read_unlock();
-}
-
-static int bond_neigh_init(struct neighbour *n)
-{
-	struct bonding *bond = netdev_priv(n->dev);
-	const struct net_device_ops *slave_ops;
-	struct neigh_parms parms;
-	struct slave *slave;
-	int ret = 0;
-
-	rcu_read_lock();
-	slave = bond_first_slave_rcu(bond);
-	if (!slave)
-		goto out;
-	slave_ops = slave->dev->netdev_ops;
-	if (!slave_ops->ndo_neigh_setup)
-		goto out;
-
-	/* TODO: find another way [1] to implement this.
-	 * Passing a zeroed structure is fragile,
-	 * but at least we do not pass garbage.
-	 *
-	 * [1] One way would be that ndo_neigh_setup() never touch
-	 *     struct neigh_parms, but propagate the new neigh_setup()
-	 *     back to ___neigh_create() / neigh_parms_alloc()
-	 */
-	memset(&parms, 0, sizeof(parms));
-	ret = slave_ops->ndo_neigh_setup(slave->dev, &parms);
-
-	if (ret)
-		goto out;
-
-	if (parms.neigh_setup)
-		ret = parms.neigh_setup(n);
-out:
-	rcu_read_unlock();
-	return ret;
-}
-
-/* The bonding ndo_neigh_setup is called at init time beofre any
- * slave exists. So we must declare proxy setup function which will
- * be used at run time to resolve the actual slave neigh param setup.
- *
- * It's also called by master devices (such as vlans) to setup their
- * underlying devices. In that case - do nothing, we're already set up from
- * our init.
- */
-static int bond_neigh_setup(struct net_device *dev,
-			    struct neigh_parms *parms)
-{
-	/* modify only our neigh_parms */
-	if (parms->dev == dev)
-		parms->neigh_setup = bond_neigh_init;
-
-	return 0;
-}
-
-/* Change the MTU of all of a master's slaves to match the master */
-static int bond_change_mtu(struct net_device *bond_dev, int new_mtu)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond=%p, new_mtu=%d\n", bond, new_mtu);
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "s %p c_m %p\n",
-			   slave, slave->dev->netdev_ops->ndo_change_mtu);
-
-		res = dev_set_mtu(slave->dev, new_mtu);
-
-		if (res) {
-			/* If we failed to set the slave's mtu to the new value
-			 * we must abort the operation even in ACTIVE_BACKUP
-			 * mode, because if we allow the backup slaves to have
-			 * different mtu values than the active slave we'll
-			 * need to change their mtu when doing a failover. That
-			 * means changing their mtu from timer context, which
-			 * is probably not a good idea.
-			 */
-			slave_dbg(bond_dev, slave->dev, "err %d setting mtu to %d\n",
-				  res, new_mtu);
-			goto unwind;
-		}
-	}
-
-	bond_dev->mtu = new_mtu;
-
-	return 0;
-
-unwind:
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mtu(rollback_slave->dev, bond_dev->mtu);
-		if (tmp_res)
-			slave_dbg(bond_dev, rollback_slave->dev, "unwind err %d\n",
-				  tmp_res);
-	}
-
-	return res;
-}
-
-/* Change HW address
- *
- * Note that many devices must be down to change the HW address, and
- * downing the master releases all slaves.  We can make bonds full of
- * bonding devices to test this, however.
- */
-static int bond_set_mac_address(struct net_device *bond_dev, void *addr)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct sockaddr_storage *ss = addr, tmp_ss;
-	struct list_head *iter;
-	int res = 0;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB)
-		return bond_alb_set_mac_address(bond_dev, addr);
-
-
-	netdev_dbg(bond_dev, "%s: bond=%p\n", __func__, bond);
-
-	/* If fail_over_mac is enabled, do nothing and return success.
-	 * Returning an error causes ifenslave to fail.
-	 */
-	if (bond->params.fail_over_mac &&
-	    BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		return 0;
-
-	if (!is_valid_ether_addr(ss->__data))
-		return -EADDRNOTAVAIL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "%s: slave=%p\n",
-			  __func__, slave);
-		res = dev_set_mac_address(slave->dev, addr, NULL);
-		if (res) {
-			/* TODO: consider downing the slave
-			 * and retry ?
-			 * User should expect communications
-			 * breakage anyway until ARP finish
-			 * updating, so...
-			 */
-			slave_dbg(bond_dev, slave->dev, "%s: err %d\n",
-				  __func__, res);
-			goto unwind;
-		}
-	}
-
-	/* success */
-	memcpy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
-	return 0;
-
-unwind:
-	memcpy(tmp_ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-	tmp_ss.ss_family = bond_dev->type;
-
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mac_address(rollback_slave->dev,
-					      (struct sockaddr *)&tmp_ss, NULL);
-		if (tmp_res) {
-			slave_dbg(bond_dev, rollback_slave->dev, "%s: unwind err %d\n",
-				   __func__, tmp_res);
-		}
-	}
-
-	return res;
-}
-
-static struct net_device *bond_xmit_slave_id_select(struct bonding *bond, int slave_id)
-{
-	struct list_head *iter;
-	struct slave *slave;
-	struct net_device *slave_dev = NULL;
-	int i = slave_id;
-
-	/* Here we start from the slave with slave_id */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0) {
-			if (bond_slave_can_tx(slave)) {
-				slave_dev = slave->dev;
-				return slave_dev;
-			}
-		}
-	}
-
-	/* Here we start from the first slave up to slave_id */
-	i = slave_id;
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0)
-			break;
-		if (bond_slave_can_tx(slave)) {
-			slave_dev = slave->dev;
-			return slave_dev;
-		}
-	}
-	return slave_dev;
-}
-
-/**
- * bond_xmit_slave_id - transmit skb through slave with slave_id
- * @bond: bonding device that is transmitting
- * @skb: buffer to transmit
- * @slave_id: slave id up to slave_cnt-1 through which to transmit
- *
- * This function tries to transmit through slave with slave_id but in case
- * it fails, it tries to find the first available slave for transmission.
- * The skb is consumed in all cases, thus the function is void.
- */
-static void bond_xmit_slave_id(struct bonding *bond, struct sk_buff *skb, int slave_id)
-{
-	struct list_head *iter;
-	struct slave *slave;
-	int i = slave_id;
-
-	/* Here we start from the slave with slave_id */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0) {
-			if (bond_slave_can_tx(slave)) {
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-				return;
-			}
-		}
-	}
-
-	/* Here we start from the first slave up to slave_id */
-	i = slave_id;
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0)
-			break;
-		if (bond_slave_can_tx(slave)) {
-			bond_dev_queue_xmit(bond, skb, slave->dev);
-			return;
-		}
-	}
-	/* no slave that can tx has been found */
-	bond_tx_drop(bond->dev, skb);
-}
-
-/**
- * bond_rr_gen_slave_id - generate slave id based on packets_per_slave
- * @bond: bonding device to use
- *
- * Based on the value of the bonding device's packets_per_slave parameter
- * this function generates a slave id, which is usually used as the next
- * slave to transmit through.
- */
-static u32 bond_rr_gen_slave_id(struct bonding *bond)
-{
-	u32 slave_id;
-	struct reciprocal_value reciprocal_packets_per_slave;
-	int packets_per_slave = bond->params.packets_per_slave;
-
-	switch (packets_per_slave) {
-	case 0:
-		slave_id = prandom_u32();
-		break;
-	case 1:
-		slave_id = bond->rr_tx_counter;
-		break;
-	default:
-		reciprocal_packets_per_slave =
-			bond->params.reciprocal_packets_per_slave;
-		slave_id = reciprocal_divide(bond->rr_tx_counter,
-					     reciprocal_packets_per_slave);
-		break;
-	}
-	bond->rr_tx_counter++;
-
-	return slave_id;
-}
-
-static struct net_device *bond_xmit_roundrobin_select(int slave_id,
-						      struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	return bond_xmit_slave_id_select(bond, slave_id);
-}
-
-static netdev_tx_t bond_xmit_roundrobin(struct sk_buff *skb,
-					struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-	int slave_cnt;
-	u32 slave_id;
-
-	/* Start with the curr_active_slave that joined the bond as the
-	 * default for sending IGMP traffic.  For failover purposes one
-	 * needs to maintain some consistency for the interface that will
-	 * send the join/membership reports.  The curr_active_slave found
-	 * will send all of this type of traffic.
-	 */
-	if (skb->protocol == htons(ETH_P_IP)) {
-		int noff = skb_network_offset(skb);
-		struct iphdr *iph;
-
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
-			goto non_igmp;
-
-		iph = ip_hdr(skb);
-		if (iph->protocol == IPPROTO_IGMP) {
-			slave = rcu_dereference(bond->curr_active_slave);
-			if (slave)
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-			else
-				bond_xmit_slave_id(bond, skb, 0);
-			return NETDEV_TX_OK;
-		}
-	}
-
-non_igmp:
-	slave_cnt = READ_ONCE(bond->slave_cnt);
-	if (likely(slave_cnt)) {
-		slave_id = bond_rr_gen_slave_id(bond);
-		bond_xmit_slave_id(bond, skb, slave_id % slave_cnt);
-	} else {
-		bond_tx_drop(bond_dev, skb);
-	}
-	return NETDEV_TX_OK;
-}
-
-static struct net_device *bond_xmit_activebackup_select(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct slave *slave;
-
-	slave = rcu_dereference(bond->curr_active_slave);
-	if (slave)
-		slave_dev = slave->dev;
-
-	return slave_dev;
-}
-
-/* In active-backup mode, we know that bond->curr_active_slave is always valid if
- * the bond has a usable interface.
- */
-static netdev_tx_t bond_xmit_activebackup(struct sk_buff *skb,
-					  struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-
-	slave = rcu_dereference(bond->curr_active_slave);
-	if (slave)
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	else
-		bond_tx_drop(bond_dev, skb);
-
-	return NETDEV_TX_OK;
-}
-
-/* Use this to update slave_array when (a) it's not appropriate to update
- * slave_array right away (note that update_slave_array() may sleep)
- * and / or (b) RTNL is not held.
- */
-void bond_slave_arr_work_rearm(struct bonding *bond, unsigned long delay)
-{
-	queue_delayed_work(bond->wq, &bond->slave_arr_work, delay);
-}
-
-/* Slave array work handler. Holds only RTNL */
-static void bond_slave_arr_handler(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    slave_arr_work.work);
-	int ret;
-
-	if (!rtnl_trylock())
-		goto err;
-
-	ret = bond_update_slave_arr(bond, NULL);
-	rtnl_unlock();
-	if (ret) {
-		pr_warn_ratelimited("Failed to update slave array from WT\n");
-		goto err;
-	}
-	return;
-
-err:
-	bond_slave_arr_work_rearm(bond, 1);
-}
-
-/* Build the usable slaves array in control path for modes that use xmit-hash
- * to determine the slave interface -
- * (a) BOND_MODE_8023AD
- * (b) BOND_MODE_XOR
- * (c) (BOND_MODE_TLB || BOND_MODE_ALB) && tlb_dynamic_lb == 0
- *
- * The caller is expected to hold RTNL only and NO other lock!
- */
-int bond_update_slave_arr(struct bonding *bond, struct slave *skipslave)
-{
-	struct slave *slave;
-	struct list_head *iter;
-	struct bond_up_slave *new_arr, *old_arr;
-	int agg_id = 0;
-	int ret = 0;
-
-#ifdef CONFIG_LOCKDEP
-	WARN_ON(lockdep_is_held(&bond->mode_lock));
-#endif
-
-	new_arr = kzalloc(offsetof(struct bond_up_slave, arr[bond->slave_cnt]),
-			  GFP_KERNEL);
-	if (!new_arr) {
-		ret = -ENOMEM;
-		pr_err("Failed to build slave-array.\n");
-		goto out;
-	}
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-
-		if (bond_3ad_get_active_agg_info(bond, &ad_info)) {
-			pr_debug("bond_3ad_get_active_agg_info failed\n");
-			kfree_rcu(new_arr, rcu);
-			/* No active aggragator means it's not safe to use
-			 * the previous array.
-			 */
-			old_arr = rtnl_dereference(bond->slave_arr);
-			if (old_arr) {
-				RCU_INIT_POINTER(bond->slave_arr, NULL);
-				kfree_rcu(old_arr, rcu);
-			}
-			goto out;
-		}
-		agg_id = ad_info.aggregator_id;
-	}
-	bond_for_each_slave(bond, slave, iter) {
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg;
-
-			agg = SLAVE_AD_INFO(slave)->port.aggregator;
-			if (!agg || agg->aggregator_identifier != agg_id)
-				continue;
-		}
-		if (!bond_slave_can_tx(slave))
-			continue;
-		if (skipslave == slave)
-			continue;
-
-		slave_dbg(bond->dev, slave->dev, "Adding slave to tx hash array[%d]\n",
-			  new_arr->count);
-
-		new_arr->arr[new_arr->count++] = slave;
-	}
-
-	old_arr = rtnl_dereference(bond->slave_arr);
-	rcu_assign_pointer(bond->slave_arr, new_arr);
-	if (old_arr)
-		kfree_rcu(old_arr, rcu);
-out:
-	if (ret != 0 && skipslave) {
-		int idx;
-
-		/* Rare situation where caller has asked to skip a specific
-		 * slave but allocation failed (most likely!). BTW this is
-		 * only possible when the call is initiated from
-		 * __bond_release_one(). In this situation; overwrite the
-		 * skipslave entry in the array with the last entry from the
-		 * array to avoid a situation where the xmit path may choose
-		 * this to-be-skipped slave to send a packet out.
-		 */
-		old_arr = rtnl_dereference(bond->slave_arr);
-		for (idx = 0; old_arr != NULL && idx < old_arr->count; idx++) {
-			if (skipslave == old_arr->arr[idx]) {
-				old_arr->arr[idx] =
-				    old_arr->arr[old_arr->count-1];
-				old_arr->count--;
-				break;
-			}
-		}
-	}
-	return ret;
-}
-
-static struct net_device *bond_xmit_xor_select(int slave_id,
-					       struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_up_slave *slaves;
-	struct slave *slave;
-	struct net_device *slave_dev = NULL;
-	unsigned int count;
-
-	slaves = rcu_dereference(bond->slave_arr);
-	count = slaves ? READ_ONCE(slaves->count) : 0;
-	if (likely(count)) {
-		slave = slaves->arr[slave_id];
-		if (slave)
-			slave_dev = slave->dev;
-	}
-	return slave_dev;
-}
-
-/* Use this Xmit function for 3AD as well as XOR modes. The current
- * usable slave array is formed in the control path. The xmit function
- * just calculates hash and sends the packet out.
- */
-static netdev_tx_t bond_3ad_xor_xmit(struct sk_buff *skb,
-				     struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct slave *slave;
-	struct bond_up_slave *slaves;
-	unsigned int count;
-
-	slaves = rcu_dereference(bond->slave_arr);
-	count = slaves ? READ_ONCE(slaves->count) : 0;
-	if (likely(count)) {
-		slave = slaves->arr[bond_xmit_hash(bond, skb) % count];
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	} else {
-		bond_tx_drop(dev, skb);
-	}
-
-	return NETDEV_TX_OK;
-}
-
-/* in broadcast mode, we send everything to all usable interfaces. */
-static netdev_tx_t bond_xmit_broadcast(struct sk_buff *skb,
-				       struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (bond_is_last_slave(bond, slave))
-			break;
-		if (bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
-
-			if (!skb2) {
-				net_err_ratelimited("%s: Error: %s: skb_clone() failed\n",
-						    bond_dev->name, __func__);
-				continue;
-			}
-			bond_dev_queue_xmit(bond, skb2, slave->dev);
-		}
-	}
-	if (slave && bond_slave_is_up(slave) && slave->link == BOND_LINK_UP)
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	else
-		bond_tx_drop(bond_dev, skb);
-
-	return NETDEV_TX_OK;
-}
-
-/*------------------------- Device initialization ---------------------------*/
-
-/* Lookup the slave that corresponds to a qid */
-static inline int bond_slave_override(struct bonding *bond,
-				      struct sk_buff *skb)
-{
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	if (!skb_rx_queue_recorded(skb))
-		return 1;
-
-	/* Find out if any slaves have the same mapping as this skb. */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->queue_id == skb_get_queue_mapping(skb)) {
-			if (bond_slave_is_up(slave) &&
-			    slave->link == BOND_LINK_UP) {
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-				return 0;
-			}
-			/* If the slave isn't UP, use default transmit policy. */
-			break;
-		}
-	}
-
-	return 1;
-}
-
-
-static u16 bond_select_queue(struct net_device *dev, struct sk_buff *skb,
-			     struct net_device *sb_dev)
-{
-	/* This helper function exists to help dev_pick_tx get the correct
-	 * destination queue.  Using a helper function skips a call to
-	 * skb_tx_hash and will put the skbs in the queue we expect on their
-	 * way down to the bonding driver.
-	 */
-	u16 txq = skb_rx_queue_recorded(skb) ? skb_get_rx_queue(skb) : 0;
-
-	/* Save the original txq to restore before passing to the driver */
-	qdisc_skb_cb(skb)->slave_dev_queue_mapping = skb_get_queue_mapping(skb);
-
-	if (unlikely(txq >= dev->real_num_tx_queues)) {
-		do {
-			txq -= dev->real_num_tx_queues;
-		} while (txq >= dev->real_num_tx_queues);
-	}
-	return txq;
-}
-
-static netdev_tx_t __bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-
-	if (bond_should_override_tx_queue(bond) &&
-	    !bond_slave_override(bond, skb))
-		return NETDEV_TX_OK;
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return bond_xmit_roundrobin(skb, dev);
-	case BOND_MODE_ACTIVEBACKUP:
-		return bond_xmit_activebackup(skb, dev);
-	case BOND_MODE_8023AD:
-	case BOND_MODE_XOR:
-		return bond_3ad_xor_xmit(skb, dev);
-	case BOND_MODE_BROADCAST:
-		return bond_xmit_broadcast(skb, dev);
-	case BOND_MODE_ALB:
-		return bond_alb_xmit(skb, dev);
-	case BOND_MODE_TLB:
-		return bond_tlb_xmit(skb, dev);
-	default:
-		/* Should never happen, mode already checked */
-		netdev_err(dev, "Unknown bonding mode %d\n", BOND_MODE(bond));
-		WARN_ON_ONCE(1);
-		bond_tx_drop(dev, skb);
-		return NETDEV_TX_OK;
-	}
-}
-
-static netdev_tx_t bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	netdev_tx_t ret = NETDEV_TX_OK;
-
-	/* If we risk deadlock from transmitting this in the
-	 * netpoll path, tell netpoll to queue the frame for later tx
-	 */
-	if (unlikely(is_netpoll_tx_blocked(dev)))
-		return NETDEV_TX_BUSY;
-
-	rcu_read_lock();
-	if (bond_has_slaves(bond))
-		ret = __bond_start_xmit(skb, dev);
-	else
-		bond_tx_drop(dev, skb);
-	rcu_read_unlock();
-
-	return ret;
-}
-
-static int bond_ethtool_get_link_ksettings(struct net_device *bond_dev,
-					   struct ethtool_link_ksettings *cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	unsigned long speed = 0;
-	struct list_head *iter;
-	struct slave *slave;
-
-	cmd->base.duplex = DUPLEX_UNKNOWN;
-	cmd->base.port = PORT_OTHER;
-
-	/* Since bond_slave_can_tx returns false for all inactive or down slaves, we
-	 * do not need to check mode.  Though link speed might not represent
-	 * the true receive or transmit bandwidth (not all modes are symmetric)
-	 * this is an accurate maximum.
-	 */
-	bond_for_each_slave(bond, slave, iter) {
-		if (bond_slave_can_tx(slave)) {
-			if (slave->speed != SPEED_UNKNOWN)
-				speed += slave->speed;
-			if (cmd->base.duplex == DUPLEX_UNKNOWN &&
-			    slave->duplex != DUPLEX_UNKNOWN)
-				cmd->base.duplex = slave->duplex;
-		}
-	}
-	cmd->base.speed = speed ? : SPEED_UNKNOWN;
-
-	return 0;
-}
-
-static void bond_ethtool_get_drvinfo(struct net_device *bond_dev,
-				     struct ethtool_drvinfo *drvinfo)
-{
-	strlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));
-	strlcpy(drvinfo->version, DRV_VERSION, sizeof(drvinfo->version));
-	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version), "%d",
-		 BOND_ABI_VERSION);
-}
-
-static const struct ethtool_ops bond_ethtool_ops = {
-	.get_drvinfo		= bond_ethtool_get_drvinfo,
-	.get_link		= ethtool_op_get_link,
-	.get_link_ksettings	= bond_ethtool_get_link_ksettings,
-};
-
-static const struct net_device_ops bond_netdev_ops = {
-	.ndo_init		= bond_init,
-	.ndo_uninit		= bond_uninit,
-	.ndo_open		= bond_open,
-	.ndo_stop		= bond_close,
-	.ndo_start_xmit		= bond_start_xmit,
-	.ndo_select_queue	= bond_select_queue,
-	.ndo_get_stats64	= bond_get_stats,
-	.ndo_do_ioctl		= bond_do_ioctl,
-	.ndo_change_rx_flags	= bond_change_rx_flags,
-	.ndo_set_rx_mode	= bond_set_rx_mode,
-	.ndo_change_mtu		= bond_change_mtu,
-	.ndo_set_mac_address	= bond_set_mac_address,
-	.ndo_neigh_setup	= bond_neigh_setup,
-	.ndo_vlan_rx_add_vid	= bond_vlan_rx_add_vid,
-	.ndo_vlan_rx_kill_vid	= bond_vlan_rx_kill_vid,
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	.ndo_netpoll_setup	= bond_netpoll_setup,
-	.ndo_netpoll_cleanup	= bond_netpoll_cleanup,
-	.ndo_poll_controller	= bond_poll_controller,
-#endif
-	.ndo_add_slave		= bond_enslave,
-	.ndo_del_slave		= bond_release,
-	.ndo_fix_features	= bond_fix_features,
-	.ndo_features_check	= passthru_features_check,
-};
-
-static const struct device_type bond_type = {
-	.name = "bond",
-};
-
-static void bond_destructor(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	if (bond->wq)
-		destroy_workqueue(bond->wq);
-}
-
-void bond_setup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	spin_lock_init(&bond->mode_lock);
-	bond->params = bonding_defaults;
-
-	/* Initialize pointers */
-	bond->dev = bond_dev;
-
-	/* Initialize the device entry points */
-	ether_setup(bond_dev);
-	bond_dev->max_mtu = ETH_MAX_MTU;
-	bond_dev->netdev_ops = &bond_netdev_ops;
-	bond_dev->ethtool_ops = &bond_ethtool_ops;
-
-	bond_dev->needs_free_netdev = true;
-	bond_dev->priv_destructor = bond_destructor;
-
-	SET_NETDEV_DEVTYPE(bond_dev, &bond_type);
-
-	/* Initialize the device options */
-	bond_dev->flags |= IFF_MASTER;
-	bond_dev->priv_flags |= IFF_BONDING | IFF_UNICAST_FLT | IFF_NO_QUEUE;
-	bond_dev->priv_flags &= ~(IFF_XMIT_DST_RELEASE | IFF_TX_SKB_SHARING);
-
-	/* don't acquire bond device's netif_tx_lock when transmitting */
-	bond_dev->features |= NETIF_F_LLTX;
-
-	/* By default, we declare the bond to be fully
-	 * VLAN hardware accelerated capable. Special
-	 * care is taken in the various xmit functions
-	 * when there are slaves that are not hw accel
-	 * capable
-	 */
-
-	/* Don't allow bond devices to change network namespaces. */
-	bond_dev->features |= NETIF_F_NETNS_LOCAL;
-
-	bond_dev->hw_features = BOND_VLAN_FEATURES |
-				NETIF_F_HW_VLAN_CTAG_RX |
-				NETIF_F_HW_VLAN_CTAG_FILTER;
-
-	bond_dev->hw_features |= NETIF_F_GSO_ENCAP_ALL | NETIF_F_GSO_UDP_L4;
-	bond_dev->features |= bond_dev->hw_features;
-	bond_dev->features |= NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_STAG_TX;
-}
-
-/* Destroy a bonding device.
- * Must be under rtnl_lock when this function is called.
- */
-static void bond_uninit(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-	struct bond_up_slave *arr;
-
-	bond_netpoll_cleanup(bond_dev);
-
-	/* Release the bonded slaves */
-	bond_for_each_slave(bond, slave, iter)
-		__bond_release_one(bond_dev, slave->dev, true, true);
-	netdev_info(bond_dev, "Released all slaves\n");
-
-	arr = rtnl_dereference(bond->slave_arr);
-	if (arr) {
-		RCU_INIT_POINTER(bond->slave_arr, NULL);
-		kfree_rcu(arr, rcu);
-	}
-
-	list_del(&bond->bond_list);
-
-	lockdep_unregister_key(&bond->stats_lock_key);
-	bond_debug_unregister(bond);
-}
-
-/*------------------------- Module initialization ---------------------------*/
-
-static int bond_check_params(struct bond_params *params)
-{
-	int arp_validate_value, fail_over_mac_value, primary_reselect_value, i;
-	struct bond_opt_value newval;
-	const struct bond_opt_value *valptr;
-	int arp_all_targets_value = 0;
-	u16 ad_actor_sys_prio = 0;
-	u16 ad_user_port_key = 0;
-	__be32 arp_target[BOND_MAX_ARP_TARGETS] = { 0 };
-	int arp_ip_count;
-	int bond_mode	= BOND_MODE_ROUNDROBIN;
-	int xmit_hashtype = BOND_XMIT_POLICY_LAYER2;
-	int lacp_fast = 0;
-	int tlb_dynamic_lb;
-
-	/* Convert string parameters. */
-	if (mode) {
-		bond_opt_initstr(&newval, mode);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_MODE), &newval);
-		if (!valptr) {
-			pr_err("Error: Invalid bonding mode \"%s\"\n", mode);
-			return -EINVAL;
-		}
-		bond_mode = valptr->value;
-	}
-
-	if (xmit_hash_policy) {
-		if (bond_mode == BOND_MODE_ROUNDROBIN ||
-		    bond_mode == BOND_MODE_ACTIVEBACKUP ||
-		    bond_mode == BOND_MODE_BROADCAST) {
-			pr_info("xmit_hash_policy param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, xmit_hash_policy);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_XMIT_HASH),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid xmit_hash_policy \"%s\"\n",
-				       xmit_hash_policy);
-				return -EINVAL;
-			}
-			xmit_hashtype = valptr->value;
-		}
-	}
-
-	if (lacp_rate) {
-		if (bond_mode != BOND_MODE_8023AD) {
-			pr_info("lacp_rate param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, lacp_rate);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_LACP_RATE),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid lacp rate \"%s\"\n",
-				       lacp_rate);
-				return -EINVAL;
-			}
-			lacp_fast = valptr->value;
-		}
-	}
-
-	if (ad_select) {
-		bond_opt_initstr(&newval, ad_select);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_SELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid ad_select \"%s\"\n", ad_select);
-			return -EINVAL;
-		}
-		params->ad_select = valptr->value;
-		if (bond_mode != BOND_MODE_8023AD)
-			pr_warn("ad_select param only affects 802.3ad mode\n");
-	} else {
-		params->ad_select = BOND_AD_STABLE;
-	}
-
-	if (max_bonds < 0) {
-		pr_warn("Warning: max_bonds (%d) not in range %d-%d, so it was reset to BOND_DEFAULT_MAX_BONDS (%d)\n",
-			max_bonds, 0, INT_MAX, BOND_DEFAULT_MAX_BONDS);
-		max_bonds = BOND_DEFAULT_MAX_BONDS;
-	}
-
-	if (miimon < 0) {
-		pr_warn("Warning: miimon module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			miimon, INT_MAX);
-		miimon = 0;
-	}
-
-	if (updelay < 0) {
-		pr_warn("Warning: updelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			updelay, INT_MAX);
-		updelay = 0;
-	}
-
-	if (downdelay < 0) {
-		pr_warn("Warning: downdelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			downdelay, INT_MAX);
-		downdelay = 0;
-	}
-
-	if ((use_carrier != 0) && (use_carrier != 1)) {
-		pr_warn("Warning: use_carrier module parameter (%d), not of valid value (0/1), so it was set to 1\n",
-			use_carrier);
-		use_carrier = 1;
-	}
-
-	if (num_peer_notif < 0 || num_peer_notif > 255) {
-		pr_warn("Warning: num_grat_arp/num_unsol_na (%d) not in range 0-255 so it was reset to 1\n",
-			num_peer_notif);
-		num_peer_notif = 1;
-	}
-
-	/* reset values for 802.3ad/TLB/ALB */
-	if (!bond_mode_uses_arp(bond_mode)) {
-		if (!miimon) {
-			pr_warn("Warning: miimon must be specified, otherwise bonding will not detect link failure, speed and duplex which are essential for 802.3ad operation\n");
-			pr_warn("Forcing miimon to 100msec\n");
-			miimon = BOND_DEFAULT_MIIMON;
-		}
-	}
-
-	if (tx_queues < 1 || tx_queues > 255) {
-		pr_warn("Warning: tx_queues (%d) should be between 1 and 255, resetting to %d\n",
-			tx_queues, BOND_DEFAULT_TX_QUEUES);
-		tx_queues = BOND_DEFAULT_TX_QUEUES;
-	}
-
-	if ((all_slaves_active != 0) && (all_slaves_active != 1)) {
-		pr_warn("Warning: all_slaves_active module parameter (%d), not of valid value (0/1), so it was set to 0\n",
-			all_slaves_active);
-		all_slaves_active = 0;
-	}
-
-	if (resend_igmp < 0 || resend_igmp > 255) {
-		pr_warn("Warning: resend_igmp (%d) should be between 0 and 255, resetting to %d\n",
-			resend_igmp, BOND_DEFAULT_RESEND_IGMP);
-		resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-	}
-
-	bond_opt_initval(&newval, packets_per_slave);
-	if (!bond_opt_parse(bond_opt_get(BOND_OPT_PACKETS_PER_SLAVE), &newval)) {
-		pr_warn("Warning: packets_per_slave (%d) should be between 0 and %u resetting to 1\n",
-			packets_per_slave, USHRT_MAX);
-		packets_per_slave = 1;
-	}
-
-	if (bond_mode == BOND_MODE_ALB) {
-		pr_notice("In ALB mode you might experience client disconnections upon reconnection of a link if the bonding module updelay parameter (%d msec) is incompatible with the forwarding delay time of the switch\n",
-			  updelay);
-	}
-
-	if (!miimon) {
-		if (updelay || downdelay) {
-			/* just warn the user the up/down delay will have
-			 * no effect since miimon is zero...
-			 */
-			pr_warn("Warning: miimon module parameter not set and updelay (%d) or downdelay (%d) module parameter is set; updelay and downdelay have no effect unless miimon is set\n",
-				updelay, downdelay);
-		}
-	} else {
-		/* don't allow arp monitoring */
-		if (arp_interval) {
-			pr_warn("Warning: miimon (%d) and arp_interval (%d) can't be used simultaneously, disabling ARP monitoring\n",
-				miimon, arp_interval);
-			arp_interval = 0;
-		}
-
-		if ((updelay % miimon) != 0) {
-			pr_warn("Warning: updelay (%d) is not a multiple of miimon (%d), updelay rounded to %d ms\n",
-				updelay, miimon, (updelay / miimon) * miimon);
-		}
-
-		updelay /= miimon;
-
-		if ((downdelay % miimon) != 0) {
-			pr_warn("Warning: downdelay (%d) is not a multiple of miimon (%d), downdelay rounded to %d ms\n",
-				downdelay, miimon,
-				(downdelay / miimon) * miimon);
-		}
-
-		downdelay /= miimon;
-	}
-
-	if (arp_interval < 0) {
-		pr_warn("Warning: arp_interval module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			arp_interval, INT_MAX);
-		arp_interval = 0;
-	}
-
-	for (arp_ip_count = 0, i = 0;
-	     (arp_ip_count < BOND_MAX_ARP_TARGETS) && arp_ip_target[i]; i++) {
-		__be32 ip;
-
-		/* not a complete check, but good enough to catch mistakes */
-		if (!in4_pton(arp_ip_target[i], -1, (u8 *)&ip, -1, NULL) ||
-		    !bond_is_ip_target_ok(ip)) {
-			pr_warn("Warning: bad arp_ip_target module parameter (%s), ARP monitoring will not be performed\n",
-				arp_ip_target[i]);
-			arp_interval = 0;
-		} else {
-			if (bond_get_targets_ip(arp_target, ip) == -1)
-				arp_target[arp_ip_count++] = ip;
-			else
-				pr_warn("Warning: duplicate address %pI4 in arp_ip_target, skipping\n",
-					&ip);
-		}
-	}
-
-	if (arp_interval && !arp_ip_count) {
-		/* don't allow arping if no arp_ip_target given... */
-		pr_warn("Warning: arp_interval module parameter (%d) specified without providing an arp_ip_target parameter, arp_interval was reset to 0\n",
-			arp_interval);
-		arp_interval = 0;
-	}
-
-	if (arp_validate) {
-		if (!arp_interval) {
-			pr_err("arp_validate requires arp_interval\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initstr(&newval, arp_validate);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_VALIDATE),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_validate \"%s\"\n",
-			       arp_validate);
-			return -EINVAL;
-		}
-		arp_validate_value = valptr->value;
-	} else {
-		arp_validate_value = 0;
-	}
-
-	if (arp_all_targets) {
-		bond_opt_initstr(&newval, arp_all_targets);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_ALL_TARGETS),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_all_targets_value \"%s\"\n",
-			       arp_all_targets);
-			arp_all_targets_value = 0;
-		} else {
-			arp_all_targets_value = valptr->value;
-		}
-	}
-
-	if (miimon) {
-		pr_info("MII link monitoring set to %d ms\n", miimon);
-	} else if (arp_interval) {
-		valptr = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
-					  arp_validate_value);
-		pr_info("ARP monitoring set to %d ms, validate %s, with %d target(s):",
-			arp_interval, valptr->string, arp_ip_count);
-
-		for (i = 0; i < arp_ip_count; i++)
-			pr_cont(" %s", arp_ip_target[i]);
-
-		pr_cont("\n");
-
-	} else if (max_bonds) {
-		/* miimon and arp_interval not set, we need one so things
-		 * work as expected, see bonding.txt for details
-		 */
-		pr_debug("Warning: either miimon or arp_interval and arp_ip_target module parameters must be specified, otherwise bonding will not detect link failures! see bonding.txt for details\n");
-	}
-
-	if (primary && !bond_mode_uses_primary(bond_mode)) {
-		/* currently, using a primary only makes sense
-		 * in active backup, TLB or ALB modes
-		 */
-		pr_warn("Warning: %s primary device specified but has no effect in %s mode\n",
-			primary, bond_mode_name(bond_mode));
-		primary = NULL;
-	}
-
-	if (primary && primary_reselect) {
-		bond_opt_initstr(&newval, primary_reselect);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_PRIMARY_RESELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid primary_reselect \"%s\"\n",
-			       primary_reselect);
-			return -EINVAL;
-		}
-		primary_reselect_value = valptr->value;
-	} else {
-		primary_reselect_value = BOND_PRI_RESELECT_ALWAYS;
-	}
-
-	if (fail_over_mac) {
-		bond_opt_initstr(&newval, fail_over_mac);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_FAIL_OVER_MAC),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid fail_over_mac \"%s\"\n",
-			       fail_over_mac);
-			return -EINVAL;
-		}
-		fail_over_mac_value = valptr->value;
-		if (bond_mode != BOND_MODE_ACTIVEBACKUP)
-			pr_warn("Warning: fail_over_mac only affects active-backup mode\n");
-	} else {
-		fail_over_mac_value = BOND_FOM_NONE;
-	}
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(
-			bond_opt_get(BOND_OPT_AD_ACTOR_SYS_PRIO),
-				     &newval);
-	if (!valptr) {
-		pr_err("Error: No ad_actor_sys_prio default value");
-		return -EINVAL;
-	}
-	ad_actor_sys_prio = valptr->value;
-
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_USER_PORT_KEY),
-				&newval);
-	if (!valptr) {
-		pr_err("Error: No ad_user_port_key default value");
-		return -EINVAL;
-	}
-	ad_user_port_key = valptr->value;
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_TLB_DYNAMIC_LB), &newval);
-	if (!valptr) {
-		pr_err("Error: No tlb_dynamic_lb default value");
-		return -EINVAL;
-	}
-	tlb_dynamic_lb = valptr->value;
-
-	if (lp_interval == 0) {
-		pr_warn("Warning: ip_interval must be between 1 and %d, so it was reset to %d\n",
-			INT_MAX, BOND_ALB_DEFAULT_LP_INTERVAL);
-		lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-	}
-
-	/* fill params struct with the proper values */
-	params->mode = bond_mode;
-	params->xmit_policy = xmit_hashtype;
-	params->miimon = miimon;
-	params->num_peer_notif = num_peer_notif;
-	params->arp_interval = arp_interval;
-	params->arp_validate = arp_validate_value;
-	params->arp_all_targets = arp_all_targets_value;
-	params->updelay = updelay;
-	params->downdelay = downdelay;
-	params->peer_notif_delay = 0;
-	params->use_carrier = use_carrier;
-	params->lacp_fast = lacp_fast;
-	params->primary[0] = 0;
-	params->primary_reselect = primary_reselect_value;
-	params->fail_over_mac = fail_over_mac_value;
-	params->tx_queues = tx_queues;
-	params->all_slaves_active = all_slaves_active;
-	params->resend_igmp = resend_igmp;
-	params->min_links = min_links;
-	params->lp_interval = lp_interval;
-	params->packets_per_slave = packets_per_slave;
-	params->tlb_dynamic_lb = tlb_dynamic_lb;
-	params->ad_actor_sys_prio = ad_actor_sys_prio;
-	eth_zero_addr(params->ad_actor_system);
-	params->ad_user_port_key = ad_user_port_key;
-	if (packets_per_slave > 0) {
-		params->reciprocal_packets_per_slave =
-			reciprocal_value(packets_per_slave);
-	} else {
-		/* reciprocal_packets_per_slave is unused if
-		 * packets_per_slave is 0 or 1, just initialize it
-		 */
-		params->reciprocal_packets_per_slave =
-			(struct reciprocal_value) { 0 };
-	}
-
-	if (primary) {
-		strncpy(params->primary, primary, IFNAMSIZ);
-		params->primary[IFNAMSIZ - 1] = 0;
-	}
-
-	memcpy(params->arp_targets, arp_target, sizeof(arp_target));
-
-	return 0;
-}
-
-/* Called from registration process */
-static int bond_init(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	netdev_dbg(bond_dev, "Begin bond_init\n");
-
-	bond->wq = alloc_ordered_workqueue(bond_dev->name, WQ_MEM_RECLAIM);
-	if (!bond->wq)
-		return -ENOMEM;
-
-	spin_lock_init(&bond->stats_lock);
-	lockdep_register_key(&bond->stats_lock_key);
-	lockdep_set_class(&bond->stats_lock, &bond->stats_lock_key);
-
-	list_add_tail(&bond->bond_list, &bn->dev_list);
-
-	bond_prepare_sysfs_group(bond);
-
-	bond_debug_register(bond);
-
-	/* Ensure valid dev_addr */
-	if (is_zero_ether_addr(bond_dev->dev_addr) &&
-	    bond_dev->addr_assign_type == NET_ADDR_PERM)
-		eth_hw_addr_random(bond_dev);
-
-	return 0;
-}
-
-unsigned int bond_get_num_tx_queues(void)
-{
-	return tx_queues;
-}
-
-/* Create a new bond based on the specified name and bonding parameters.
- * If name is NULL, obtain a suitable "bond%d" name for us.
- * Caller must NOT hold rtnl_lock; we need to release it here before we
- * set up our sysfs entries.
- */
-int bond_create(struct net *net, const char *name)
-{
-	struct net_device *bond_dev;
-	struct bonding *bond;
-	struct alb_bond_info *bond_info;
-	int res;
-
-	rtnl_lock();
-
-	bond_dev = alloc_netdev_mq(sizeof(struct bonding),
-				   name ? name : "bond%d", NET_NAME_UNKNOWN,
-				   bond_setup, tx_queues);
-	if (!bond_dev) {
-		pr_err("%s: eek! can't alloc netdev!\n", name);
-		rtnl_unlock();
-		return -ENOMEM;
-	}
-
-	/*
-	 * Initialize rx_hashtbl_used_head to RLB_NULL_INDEX.
-	 * It is set to 0 by default which is wrong.
-	 */
-	bond = netdev_priv(bond_dev);
-	bond_info = &(BOND_ALB_INFO(bond));
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	dev_net_set(bond_dev, net);
-	bond_dev->rtnl_link_ops = &bond_link_ops;
-
-	res = register_netdevice(bond_dev);
-
-	netif_carrier_off(bond_dev);
-
-	bond_work_init_all(bond);
-
-	rtnl_unlock();
-	if (res < 0)
-		free_netdev(bond_dev);
-	return res;
-}
-
-static int __net_init bond_net_init(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-
-	bn->net = net;
-	INIT_LIST_HEAD(&bn->dev_list);
-
-	bond_create_proc_dir(bn);
-	bond_create_sysfs(bn);
-
-	return 0;
-}
-
-static void __net_exit bond_net_exit(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-	struct bonding *bond, *tmp_bond;
-	LIST_HEAD(list);
-
-	bond_destroy_sysfs(bn);
-
-	/* Kill off any bonds created after unregistering bond rtnl ops */
-	rtnl_lock();
-	list_for_each_entry_safe(bond, tmp_bond, &bn->dev_list, bond_list)
-		unregister_netdevice_queue(bond->dev, &list);
-	unregister_netdevice_many(&list);
-	rtnl_unlock();
-
-	bond_destroy_proc_dir(bn);
-}
-
-static struct pernet_operations bond_net_ops = {
-	.init = bond_net_init,
-	.exit = bond_net_exit,
-	.id   = &bond_net_id,
-	.size = sizeof(struct bond_net),
-};
-
-static int __init bonding_init(void)
-{
-	int i;
-	int res;
-
-	pr_info("%s", bond_version);
-
-	res = bond_check_params(&bonding_defaults);
-	if (res)
-		goto out;
-
-	res = register_pernet_subsys(&bond_net_ops);
-	if (res)
-		goto out;
-
-	res = bond_netlink_init();
-	if (res)
-		goto err_link;
-
-	bond_create_debugfs();
-
-	for (i = 0; i < max_bonds; i++) {
-		res = bond_create(&init_net, NULL);
-		if (res)
-			goto err;
-	}
-
-	register_netdevice_notifier(&bond_netdev_notifier);
-
-	register_toe_bond_rr_select_cb(bond_xmit_roundrobin_select);
-	register_toe_bond_acb_select_cb(bond_xmit_activebackup_select);
-	register_toe_bond_8023AD_select_cb(bond_xmit_xor_select);
-	register_toe_bond_xor_select_cb(bond_xmit_xor_select);
-out:
-	return res;
-err:
-	bond_destroy_debugfs();
-	bond_netlink_fini();
-err_link:
-	unregister_pernet_subsys(&bond_net_ops);
-	goto out;
-
-}
-
-static void __exit bonding_exit(void)
-{
-	unregister_netdevice_notifier(&bond_netdev_notifier);
-
-	bond_destroy_debugfs();
-
-	bond_netlink_fini();
-	unregister_pernet_subsys(&bond_net_ops);
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	/* Make sure we don't have an imbalance on our netpoll blocking */
-	WARN_ON(atomic_read(&netpoll_block_tx));
-#endif
-}
-
-module_init(bonding_init);
-module_exit(bonding_exit);
-MODULE_LICENSE("GPL");
-MODULE_VERSION(DRV_VERSION);
-MODULE_DESCRIPTION(DRV_DESCRIPTION ", v" DRV_VERSION);
-MODULE_AUTHOR("Thomas Davis, tadavis@lbl.gov and many others");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bond_main.c.orig
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bond_main.c.orig	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,4926 +0,0 @@
-/*
- * originally based on the dummy device.
- *
- * Copyright 1999, Thomas Davis, tadavis@lbl.gov.
- * Licensed under the GPL. Based on dummy.c, and eql.c devices.
- *
- * bonding.c: an Ethernet Bonding driver
- *
- * This is useful to talk to a Cisco EtherChannel compatible equipment:
- *	Cisco 5500
- *	Sun Trunking (Solaris)
- *	Alteon AceDirector Trunks
- *	Linux Bonding
- *	and probably many L2 switches ...
- *
- * How it works:
- *    ifconfig bond0 ipaddress netmask up
- *      will setup a network device, with an ip address.  No mac address
- *	will be assigned at this time.  The hw mac address will come from
- *	the first slave bonded to the channel.  All slaves will then use
- *	this hw mac address.
- *
- *    ifconfig bond0 down
- *         will release all slaves, marking them as down.
- *
- *    ifenslave bond0 eth0
- *	will attach eth0 to bond0 as a slave.  eth0 hw mac address will either
- *	a: be used as initial mac address
- *	b: if a hw mac address already is there, eth0's hw mac address
- *	   will then be set from bond0.
- *
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/types.h>
-#include <linux/fcntl.h>
-#include <linux/interrupt.h>
-#include <linux/ptrace.h>
-#include <linux/ioport.h>
-#include <linux/in.h>
-#include <net/ip.h>
-#include <linux/ip.h>
-#include <linux/tcp.h>
-#include <linux/udp.h>
-#include <linux/slab.h>
-#include <linux/string.h>
-#include <linux/init.h>
-#include <linux/timer.h>
-#include <linux/socket.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/bitops.h>
-#include <linux/io.h>
-#include <asm/dma.h>
-#include <linux/uaccess.h>
-#include <linux/errno.h>
-#include <linux/netdevice.h>
-#include <linux/inetdevice.h>
-#include <linux/igmp.h>
-#include <linux/etherdevice.h>
-#include <linux/skbuff.h>
-#include <net/sock.h>
-#include <linux/rtnetlink.h>
-#include <linux/smp.h>
-#include <linux/if_ether.h>
-#include <net/arp.h>
-#include <linux/mii.h>
-#include <linux/ethtool.h>
-#include <linux/if_vlan.h>
-#include <linux/if_bonding.h>
-#include <linux/jiffies.h>
-#include <linux/preempt.h>
-#include <net/route.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <net/pkt_sched.h>
-#include <linux/rculist.h>
-#include <net/flow_dissector.h>
-#include <net/bonding.h>
-#include <net/bond_3ad.h>
-#include <net/bond_alb.h>
-
-#include "bonding_priv.h"
-
-/*---------------------------- Module parameters ----------------------------*/
-
-/* monitor all links that often (in milliseconds). <=0 disables monitoring */
-
-static int max_bonds	= BOND_DEFAULT_MAX_BONDS;
-static int tx_queues	= BOND_DEFAULT_TX_QUEUES;
-static int num_peer_notif = 1;
-static int miimon;
-static int updelay;
-static int downdelay;
-static int use_carrier	= 1;
-static char *mode;
-static char *primary;
-static char *primary_reselect;
-static char *lacp_rate;
-static int min_links;
-static char *ad_select;
-static char *xmit_hash_policy;
-static int arp_interval;
-static char *arp_ip_target[BOND_MAX_ARP_TARGETS];
-static char *arp_validate;
-static char *arp_all_targets;
-static char *fail_over_mac;
-static int all_slaves_active;
-static struct bond_params bonding_defaults;
-static int resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-static int packets_per_slave = 1;
-static int lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-
-module_param(max_bonds, int, 0);
-MODULE_PARM_DESC(max_bonds, "Max number of bonded devices");
-module_param(tx_queues, int, 0);
-MODULE_PARM_DESC(tx_queues, "Max number of transmit queues (default = 16)");
-module_param_named(num_grat_arp, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_grat_arp, "Number of peer notifications to send on "
-			       "failover event (alias of num_unsol_na)");
-module_param_named(num_unsol_na, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_unsol_na, "Number of peer notifications to send on "
-			       "failover event (alias of num_grat_arp)");
-module_param(miimon, int, 0);
-MODULE_PARM_DESC(miimon, "Link check interval in milliseconds");
-module_param(updelay, int, 0);
-MODULE_PARM_DESC(updelay, "Delay before considering link up, in milliseconds");
-module_param(downdelay, int, 0);
-MODULE_PARM_DESC(downdelay, "Delay before considering link down, "
-			    "in milliseconds");
-module_param(use_carrier, int, 0);
-MODULE_PARM_DESC(use_carrier, "Use netif_carrier_ok (vs MII ioctls) in miimon; "
-			      "0 for off, 1 for on (default)");
-module_param(mode, charp, 0);
-MODULE_PARM_DESC(mode, "Mode of operation; 0 for balance-rr, "
-		       "1 for active-backup, 2 for balance-xor, "
-		       "3 for broadcast, 4 for 802.3ad, 5 for balance-tlb, "
-		       "6 for balance-alb");
-module_param(primary, charp, 0);
-MODULE_PARM_DESC(primary, "Primary network device to use");
-module_param(primary_reselect, charp, 0);
-MODULE_PARM_DESC(primary_reselect, "Reselect primary slave "
-				   "once it comes up; "
-				   "0 for always (default), "
-				   "1 for only if speed of primary is "
-				   "better, "
-				   "2 for only on active slave "
-				   "failure");
-module_param(lacp_rate, charp, 0);
-MODULE_PARM_DESC(lacp_rate, "LACPDU tx rate to request from 802.3ad partner; "
-			    "0 for slow, 1 for fast");
-module_param(ad_select, charp, 0);
-MODULE_PARM_DESC(ad_select, "802.3ad aggregation selection logic; "
-			    "0 for stable (default), 1 for bandwidth, "
-			    "2 for count");
-module_param(min_links, int, 0);
-MODULE_PARM_DESC(min_links, "Minimum number of available links before turning on carrier");
-
-module_param(xmit_hash_policy, charp, 0);
-MODULE_PARM_DESC(xmit_hash_policy, "balance-alb, balance-tlb, balance-xor, 802.3ad hashing method; "
-				   "0 for layer 2 (default), 1 for layer 3+4, "
-				   "2 for layer 2+3, 3 for encap layer 2+3, "
-				   "4 for encap layer 3+4");
-module_param(arp_interval, int, 0);
-MODULE_PARM_DESC(arp_interval, "arp interval in milliseconds");
-module_param_array(arp_ip_target, charp, NULL, 0);
-MODULE_PARM_DESC(arp_ip_target, "arp targets in n.n.n.n form");
-module_param(arp_validate, charp, 0);
-MODULE_PARM_DESC(arp_validate, "validate src/dst of ARP probes; "
-			       "0 for none (default), 1 for active, "
-			       "2 for backup, 3 for all");
-module_param(arp_all_targets, charp, 0);
-MODULE_PARM_DESC(arp_all_targets, "fail on any/all arp targets timeout; 0 for any (default), 1 for all");
-module_param(fail_over_mac, charp, 0);
-MODULE_PARM_DESC(fail_over_mac, "For active-backup, do not set all slaves to "
-				"the same MAC; 0 for none (default), "
-				"1 for active, 2 for follow");
-module_param(all_slaves_active, int, 0);
-MODULE_PARM_DESC(all_slaves_active, "Keep all frames received on an interface "
-				     "by setting active flag for all slaves; "
-				     "0 for never (default), 1 for always.");
-module_param(resend_igmp, int, 0);
-MODULE_PARM_DESC(resend_igmp, "Number of IGMP membership reports to send on "
-			      "link failure");
-module_param(packets_per_slave, int, 0);
-MODULE_PARM_DESC(packets_per_slave, "Packets to send per slave in balance-rr "
-				    "mode; 0 for a random slave, 1 packet per "
-				    "slave (default), >1 packets per slave.");
-module_param(lp_interval, uint, 0);
-MODULE_PARM_DESC(lp_interval, "The number of seconds between instances where "
-			      "the bonding driver sends learning packets to "
-			      "each slaves peer switch. The default is 1.");
-
-/*----------------------------- Global variables ----------------------------*/
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-atomic_t netpoll_block_tx = ATOMIC_INIT(0);
-#endif
-
-unsigned int bond_net_id __read_mostly;
-
-/*-------------------------- Forward declarations ---------------------------*/
-
-static int bond_init(struct net_device *bond_dev);
-static void bond_uninit(struct net_device *bond_dev);
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats);
-static void bond_slave_arr_handler(struct work_struct *work);
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod);
-static void bond_netdev_notify_work(struct work_struct *work);
-
-/*---------------------------- General routines -----------------------------*/
-
-const char *bond_mode_name(int mode)
-{
-	static const char *names[] = {
-		[BOND_MODE_ROUNDROBIN] = "load balancing (round-robin)",
-		[BOND_MODE_ACTIVEBACKUP] = "fault-tolerance (active-backup)",
-		[BOND_MODE_XOR] = "load balancing (xor)",
-		[BOND_MODE_BROADCAST] = "fault-tolerance (broadcast)",
-		[BOND_MODE_8023AD] = "IEEE 802.3ad Dynamic link aggregation",
-		[BOND_MODE_TLB] = "transmit load balancing",
-		[BOND_MODE_ALB] = "adaptive load balancing",
-	};
-
-	if (mode < BOND_MODE_ROUNDROBIN || mode > BOND_MODE_ALB)
-		return "unknown";
-
-	return names[mode];
-}
-
-/*---------------------------------- VLAN -----------------------------------*/
-
-/**
- * bond_dev_queue_xmit - Prepare skb for xmit.
- *
- * @bond: bond device that got this skb for tx.
- * @skb: hw accel VLAN tagged skb to transmit
- * @slave_dev: slave that is supposed to xmit this skbuff
- */
-void bond_dev_queue_xmit(struct bonding *bond, struct sk_buff *skb,
-			struct net_device *slave_dev)
-{
-	skb->dev = slave_dev;
-
-	BUILD_BUG_ON(sizeof(skb->queue_mapping) !=
-		     sizeof(qdisc_skb_cb(skb)->slave_dev_queue_mapping));
-	skb_set_queue_mapping(skb, qdisc_skb_cb(skb)->slave_dev_queue_mapping);
-
-	if (unlikely(netpoll_tx_running(bond->dev)))
-		bond_netpoll_send_skb(bond_get_slave_by_dev(bond, slave_dev), skb);
-	else
-		dev_queue_xmit(skb);
-}
-
-/* In the following 2 functions, bond_vlan_rx_add_vid and bond_vlan_rx_kill_vid,
- * We don't protect the slave list iteration with a lock because:
- * a. This operation is performed in IOCTL context,
- * b. The operation is protected by the RTNL semaphore in the 8021q code,
- * c. Holding a lock with BH disabled while directly calling a base driver
- *    entry point is generally a BAD idea.
- *
- * The design of synchronization/protection for this operation in the 8021q
- * module is good for one or more VLAN devices over a single physical device
- * and cannot be extended for a teaming solution like bonding, so there is a
- * potential race condition here where a net device from the vlan group might
- * be referenced (either by a base driver or the 8021q code) while it is being
- * removed from the system. However, it turns out we're not making matters
- * worse, and if it works for regular VLAN usage it will work here too.
-*/
-
-/**
- * bond_vlan_rx_add_vid - Propagates adding an id to slaves
- * @bond_dev: bonding net device that got called
- * @vid: vlan id being added
- */
-static int bond_vlan_rx_add_vid(struct net_device *bond_dev,
-				__be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res;
-
-	bond_for_each_slave(bond, slave, iter) {
-		res = vlan_vid_add(slave->dev, proto, vid);
-		if (res)
-			goto unwind;
-	}
-
-	return 0;
-
-unwind:
-	/* unwind to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		if (rollback_slave == slave)
-			break;
-
-		vlan_vid_del(rollback_slave->dev, proto, vid);
-	}
-
-	return res;
-}
-
-/**
- * bond_vlan_rx_kill_vid - Propagates deleting an id to slaves
- * @bond_dev: bonding net device that got called
- * @vid: vlan id being removed
- */
-static int bond_vlan_rx_kill_vid(struct net_device *bond_dev,
-				 __be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		vlan_vid_del(slave->dev, proto, vid);
-
-	if (bond_is_lb(bond))
-		bond_alb_clear_vlan(bond, vid);
-
-	return 0;
-}
-
-/*------------------------------- Link status -------------------------------*/
-
-/* Set the carrier state for the master according to the state of its
- * slaves.  If any slaves are up, the master is up.  In 802.3ad mode,
- * do special 802.3ad magic.
- *
- * Returns zero if carrier state does not change, nonzero if it does.
- */
-int bond_set_carrier(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (!bond_has_slaves(bond))
-		goto down;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		return bond_3ad_set_carrier(bond);
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP) {
-			if (!netif_carrier_ok(bond->dev)) {
-				netif_carrier_on(bond->dev);
-				return 1;
-			}
-			return 0;
-		}
-	}
-
-down:
-	if (netif_carrier_ok(bond->dev)) {
-		netif_carrier_off(bond->dev);
-		return 1;
-	}
-	return 0;
-}
-
-/* Get link speed and duplex from the slave's base driver
- * using ethtool. If for some reason the call fails or the
- * values are invalid, set speed and duplex to -1,
- * and return. Return 1 if speed or duplex settings are
- * UNKNOWN; 0 otherwise.
- */
-static int bond_update_speed_duplex(struct slave *slave)
-{
-	struct net_device *slave_dev = slave->dev;
-	struct ethtool_link_ksettings ecmd;
-	int res;
-
-	slave->speed = SPEED_UNKNOWN;
-	slave->duplex = DUPLEX_UNKNOWN;
-
-	res = __ethtool_get_link_ksettings(slave_dev, &ecmd);
-	if (res < 0)
-		return 1;
-	if (ecmd.base.speed == 0 || ecmd.base.speed == ((__u32)-1))
-		return 1;
-	switch (ecmd.base.duplex) {
-	case DUPLEX_FULL:
-	case DUPLEX_HALF:
-		break;
-	default:
-		return 1;
-	}
-
-	slave->speed = ecmd.base.speed;
-	slave->duplex = ecmd.base.duplex;
-
-	return 0;
-}
-
-const char *bond_slave_link_status(s8 link)
-{
-	switch (link) {
-	case BOND_LINK_UP:
-		return "up";
-	case BOND_LINK_FAIL:
-		return "going down";
-	case BOND_LINK_DOWN:
-		return "down";
-	case BOND_LINK_BACK:
-		return "going back";
-	default:
-		return "unknown";
-	}
-}
-
-/* if <dev> supports MII link status reporting, check its link status.
- *
- * We either do MII/ETHTOOL ioctls, or check netif_carrier_ok(),
- * depending upon the setting of the use_carrier parameter.
- *
- * Return either BMSR_LSTATUS, meaning that the link is up (or we
- * can't tell and just pretend it is), or 0, meaning that the link is
- * down.
- *
- * If reporting is non-zero, instead of faking link up, return -1 if
- * both ETHTOOL and MII ioctls fail (meaning the device does not
- * support them).  If use_carrier is set, return whatever it says.
- * It'd be nice if there was a good way to tell if a driver supports
- * netif_carrier, but there really isn't.
- */
-static int bond_check_dev_link(struct bonding *bond,
-			       struct net_device *slave_dev, int reporting)
-{
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	int (*ioctl)(struct net_device *, struct ifreq *, int);
-	struct ifreq ifr;
-	struct mii_ioctl_data *mii;
-
-	if (!reporting && !netif_running(slave_dev))
-		return 0;
-
-	if (bond->params.use_carrier)
-		return netif_carrier_ok(slave_dev) ? BMSR_LSTATUS : 0;
-
-	/* Try to get link status using Ethtool first. */
-	if (slave_dev->ethtool_ops->get_link)
-		return slave_dev->ethtool_ops->get_link(slave_dev) ?
-			BMSR_LSTATUS : 0;
-
-	/* Ethtool can't be used, fallback to MII ioctls. */
-	ioctl = slave_ops->ndo_do_ioctl;
-	if (ioctl) {
-		/* TODO: set pointer to correct ioctl on a per team member
-		 *       bases to make this more efficient. that is, once
-		 *       we determine the correct ioctl, we will always
-		 *       call it and not the others for that team
-		 *       member.
-		 */
-
-		/* We cannot assume that SIOCGMIIPHY will also read a
-		 * register; not all network drivers (e.g., e100)
-		 * support that.
-		 */
-
-		/* Yes, the mii is overlaid on the ifreq.ifr_ifru */
-		strncpy(ifr.ifr_name, slave_dev->name, IFNAMSIZ);
-		mii = if_mii(&ifr);
-		if (ioctl(slave_dev, &ifr, SIOCGMIIPHY) == 0) {
-			mii->reg_num = MII_BMSR;
-			if (ioctl(slave_dev, &ifr, SIOCGMIIREG) == 0)
-				return mii->val_out & BMSR_LSTATUS;
-		}
-	}
-
-	/* If reporting, report that either there's no dev->do_ioctl,
-	 * or both SIOCGMIIREG and get_link failed (meaning that we
-	 * cannot report link status).  If not reporting, pretend
-	 * we're ok.
-	 */
-	return reporting ? -1 : BMSR_LSTATUS;
-}
-
-/*----------------------------- Multicast list ------------------------------*/
-
-/* Push the promiscuity flag down to appropriate slaves */
-static int bond_set_promiscuity(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_promiscuity(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_promiscuity(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Push the allmulti flag down to all slaves */
-static int bond_set_allmulti(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_allmulti(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_allmulti(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Retrieve the list of registered multicast addresses for the bonding
- * device and retransmit an IGMP JOIN request to the current active
- * slave.
- */
-static void bond_resend_igmp_join_requests_delayed(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mcast_work.work);
-
-	if (!rtnl_trylock()) {
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-		return;
-	}
-	call_netdevice_notifiers(NETDEV_RESEND_IGMP, bond->dev);
-
-	if (bond->igmp_retrans > 1) {
-		bond->igmp_retrans--;
-		queue_delayed_work(bond->wq, &bond->mcast_work, HZ/5);
-	}
-	rtnl_unlock();
-}
-
-/* Flush bond's hardware addresses from slave */
-static void bond_hw_addr_flush(struct net_device *bond_dev,
-			       struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	dev_uc_unsync(slave_dev, bond_dev);
-	dev_mc_unsync(slave_dev, bond_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		/* del lacpdu mc addr from mc list */
-		u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-		dev_mc_del(slave_dev, lacpdu_multicast);
-	}
-}
-
-/*--------------------------- Active slave change ---------------------------*/
-
-/* Update the hardware address list and promisc/allmulti for the new and
- * old active slaves (if any).  Modes that are not using primary keep all
- * slaves up date at all times; only the modes that use primary need to call
- * this function to swap these settings during a failover.
- */
-static void bond_hw_addr_swap(struct bonding *bond, struct slave *new_active,
-			      struct slave *old_active)
-{
-	if (old_active) {
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(old_active->dev, -1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(old_active->dev, -1);
-
-		bond_hw_addr_flush(bond->dev, old_active->dev);
-	}
-
-	if (new_active) {
-		/* FIXME: Signal errors upstream. */
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(new_active->dev, 1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(new_active->dev, 1);
-
-		netif_addr_lock_bh(bond->dev);
-		dev_uc_sync(new_active->dev, bond->dev);
-		dev_mc_sync(new_active->dev, bond->dev);
-		netif_addr_unlock_bh(bond->dev);
-	}
-}
-
-/**
- * bond_set_dev_addr - clone slave's address to bond
- * @bond_dev: bond net device
- * @slave_dev: slave net device
- *
- * Should be called with RTNL held.
- */
-static int bond_set_dev_addr(struct net_device *bond_dev,
-			     struct net_device *slave_dev)
-{
-	int err;
-
-	slave_dbg(bond_dev, slave_dev, "bond_dev=%p slave_dev=%p slave_dev->addr_len=%d\n",
-		  bond_dev, slave_dev, slave_dev->addr_len);
-	err = dev_pre_changeaddr_notify(bond_dev, slave_dev->dev_addr, NULL);
-	if (err)
-		return err;
-
-	memcpy(bond_dev->dev_addr, slave_dev->dev_addr, slave_dev->addr_len);
-	bond_dev->addr_assign_type = NET_ADDR_STOLEN;
-	call_netdevice_notifiers(NETDEV_CHANGEADDR, bond_dev);
-	return 0;
-}
-
-static struct slave *bond_get_old_active(struct bonding *bond,
-					 struct slave *new_active)
-{
-	struct slave *slave;
-	struct list_head *iter;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave == new_active)
-			continue;
-
-		if (ether_addr_equal(bond->dev->dev_addr, slave->dev->dev_addr))
-			return slave;
-	}
-
-	return NULL;
-}
-
-/* bond_do_fail_over_mac
- *
- * Perform special MAC address swapping for fail_over_mac settings
- *
- * Called with RTNL
- */
-static void bond_do_fail_over_mac(struct bonding *bond,
-				  struct slave *new_active,
-				  struct slave *old_active)
-{
-	u8 tmp_mac[MAX_ADDR_LEN];
-	struct sockaddr_storage ss;
-	int rv;
-
-	switch (bond->params.fail_over_mac) {
-	case BOND_FOM_ACTIVE:
-		if (new_active) {
-			rv = bond_set_dev_addr(bond->dev, new_active->dev);
-			if (rv)
-				slave_err(bond->dev, new_active->dev, "Error %d setting bond MAC from slave\n",
-					  -rv);
-		}
-		break;
-	case BOND_FOM_FOLLOW:
-		/* if new_active && old_active, swap them
-		 * if just old_active, do nothing (going to no active slave)
-		 * if just new_active, set new_active to bond's MAC
-		 */
-		if (!new_active)
-			return;
-
-		if (!old_active)
-			old_active = bond_get_old_active(bond, new_active);
-
-		if (old_active) {
-			bond_hw_addr_copy(tmp_mac, new_active->dev->dev_addr,
-					  new_active->dev->addr_len);
-			bond_hw_addr_copy(ss.__data,
-					  old_active->dev->dev_addr,
-					  old_active->dev->addr_len);
-			ss.ss_family = new_active->dev->type;
-		} else {
-			bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
-					  bond->dev->addr_len);
-			ss.ss_family = bond->dev->type;
-		}
-
-		rv = dev_set_mac_address(new_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv) {
-			slave_err(bond->dev, new_active->dev, "Error %d setting MAC of new active slave\n",
-				  -rv);
-			goto out;
-		}
-
-		if (!old_active)
-			goto out;
-
-		bond_hw_addr_copy(ss.__data, tmp_mac,
-				  new_active->dev->addr_len);
-		ss.ss_family = old_active->dev->type;
-
-		rv = dev_set_mac_address(old_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv)
-			slave_err(bond->dev, old_active->dev, "Error %d setting MAC of old active slave\n",
-				  -rv);
-out:
-		break;
-	default:
-		netdev_err(bond->dev, "bond_do_fail_over_mac impossible: bad policy %d\n",
-			   bond->params.fail_over_mac);
-		break;
-	}
-
-}
-
-static struct slave *bond_choose_primary_or_current(struct bonding *bond)
-{
-	struct slave *prim = rtnl_dereference(bond->primary_slave);
-	struct slave *curr = rtnl_dereference(bond->curr_active_slave);
-
-	if (!prim || prim->link != BOND_LINK_UP) {
-		if (!curr || curr->link != BOND_LINK_UP)
-			return NULL;
-		return curr;
-	}
-
-	if (bond->force_primary) {
-		bond->force_primary = false;
-		return prim;
-	}
-
-	if (!curr || curr->link != BOND_LINK_UP)
-		return prim;
-
-	/* At this point, prim and curr are both up */
-	switch (bond->params.primary_reselect) {
-	case BOND_PRI_RESELECT_ALWAYS:
-		return prim;
-	case BOND_PRI_RESELECT_BETTER:
-		if (prim->speed < curr->speed)
-			return curr;
-		if (prim->speed == curr->speed && prim->duplex <= curr->duplex)
-			return curr;
-		return prim;
-	case BOND_PRI_RESELECT_FAILURE:
-		return curr;
-	default:
-		netdev_err(bond->dev, "impossible primary_reselect %d\n",
-			   bond->params.primary_reselect);
-		return curr;
-	}
-}
-
-/**
- * bond_find_best_slave - select the best available slave to be the active one
- * @bond: our bonding struct
- */
-static struct slave *bond_find_best_slave(struct bonding *bond)
-{
-	struct slave *slave, *bestslave = NULL;
-	struct list_head *iter;
-	int mintime = bond->params.updelay;
-
-	slave = bond_choose_primary_or_current(bond);
-	if (slave)
-		return slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP)
-			return slave;
-		if (slave->link == BOND_LINK_BACK && bond_slave_is_up(slave) &&
-		    slave->delay < mintime) {
-			mintime = slave->delay;
-			bestslave = slave;
-		}
-	}
-
-	return bestslave;
-}
-
-static bool bond_should_notify_peers(struct bonding *bond)
-{
-	struct slave *slave;
-
-	rcu_read_lock();
-	slave = rcu_dereference(bond->curr_active_slave);
-	rcu_read_unlock();
-
-	netdev_dbg(bond->dev, "bond_should_notify_peers: slave %s\n",
-		   slave ? slave->dev->name : "NULL");
-
-	if (!slave || !bond->send_peer_notif ||
-	    bond->send_peer_notif %
-	    max(1, bond->params.peer_notif_delay) != 0 ||
-	    !netif_carrier_ok(bond->dev) ||
-	    test_bit(__LINK_STATE_LINKWATCH_PENDING, &slave->dev->state))
-		return false;
-
-	return true;
-}
-
-/**
- * change_active_interface - change the active slave into the specified one
- * @bond: our bonding struct
- * @new: the new slave to make the active one
- *
- * Set the new slave to the bond's settings and unset them on the old
- * curr_active_slave.
- * Setting include flags, mc-list, promiscuity, allmulti, etc.
- *
- * If @new's link state is %BOND_LINK_BACK we'll set it to %BOND_LINK_UP,
- * because it is apparently the best available slave we have, even though its
- * updelay hasn't timed out yet.
- *
- * Caller must hold RTNL.
- */
-void bond_change_active_slave(struct bonding *bond, struct slave *new_active)
-{
-	struct slave *old_active;
-
-	ASSERT_RTNL();
-
-	old_active = rtnl_dereference(bond->curr_active_slave);
-
-	if (old_active == new_active)
-		return;
-
-	if (new_active) {
-		new_active->last_link_up = jiffies;
-
-		if (new_active->link == BOND_LINK_BACK) {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one %d ms earlier\n",
-					   (bond->params.updelay - new_active->delay) * bond->params.miimon);
-			}
-
-			new_active->delay = 0;
-			bond_set_slave_link_state(new_active, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_3ad_handle_link_change(new_active, BOND_LINK_UP);
-
-			if (bond_is_lb(bond))
-				bond_alb_handle_link_change(bond, new_active, BOND_LINK_UP);
-		} else {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one\n");
-			}
-		}
-	}
-
-	if (bond_uses_primary(bond))
-		bond_hw_addr_swap(bond, new_active, old_active);
-
-	if (bond_is_lb(bond)) {
-		bond_alb_handle_active_change(bond, new_active);
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-		if (new_active)
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		rcu_assign_pointer(bond->curr_active_slave, new_active);
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP) {
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-		if (new_active) {
-			bool should_notify_peers = false;
-
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-
-			if (bond->params.fail_over_mac)
-				bond_do_fail_over_mac(bond, new_active,
-						      old_active);
-
-			if (netif_running(bond->dev)) {
-				bond->send_peer_notif =
-					bond->params.num_peer_notif *
-					max(1, bond->params.peer_notif_delay);
-				should_notify_peers =
-					bond_should_notify_peers(bond);
-			}
-
-			call_netdevice_notifiers(NETDEV_BONDING_FAILOVER, bond->dev);
-			if (should_notify_peers) {
-				bond->send_peer_notif--;
-				call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-							 bond->dev);
-			}
-		}
-	}
-
-	/* resend IGMP joins since active slave has changed or
-	 * all were sent on curr_active_slave.
-	 * resend only if bond is brought up with the affected
-	 * bonding modes and the retransmission is enabled
-	 */
-	if (netif_running(bond->dev) && (bond->params.resend_igmp > 0) &&
-	    ((bond_uses_primary(bond) && new_active) ||
-	     BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)) {
-		bond->igmp_retrans = bond->params.resend_igmp;
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-	}
-}
-
-/**
- * bond_select_active_slave - select a new active slave, if needed
- * @bond: our bonding struct
- *
- * This functions should be called when one of the following occurs:
- * - The old curr_active_slave has been released or lost its link.
- * - The primary_slave has got its link back.
- * - A slave has got its link back and there's no old curr_active_slave.
- *
- * Caller must hold RTNL.
- */
-void bond_select_active_slave(struct bonding *bond)
-{
-	struct slave *best_slave;
-	int rv;
-
-	ASSERT_RTNL();
-
-	best_slave = bond_find_best_slave(bond);
-	if (best_slave != rtnl_dereference(bond->curr_active_slave)) {
-		bond_change_active_slave(bond, best_slave);
-		rv = bond_set_carrier(bond);
-		if (!rv)
-			return;
-
-		if (netif_carrier_ok(bond->dev))
-			netdev_info(bond->dev, "active interface up!\n");
-		else
-			netdev_info(bond->dev, "now running without any active interface!\n");
-	}
-}
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	struct netpoll *np;
-	int err = 0;
-
-	np = kzalloc(sizeof(*np), GFP_KERNEL);
-	err = -ENOMEM;
-	if (!np)
-		goto out;
-
-	err = __netpoll_setup(np, slave->dev);
-	if (err) {
-		kfree(np);
-		goto out;
-	}
-	slave->np = np;
-out:
-	return err;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-	struct netpoll *np = slave->np;
-
-	if (!np)
-		return;
-
-	slave->np = NULL;
-
-	__netpoll_free(np);
-}
-
-static void bond_poll_controller(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-	struct ad_info ad_info;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		if (bond_3ad_get_active_agg_info(bond, &ad_info))
-			return;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!bond_slave_is_up(slave))
-			continue;
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg =
-			    SLAVE_AD_INFO(slave)->port.aggregator;
-
-			if (agg &&
-			    agg->aggregator_identifier != ad_info.aggregator_id)
-				continue;
-		}
-
-		netpoll_poll_dev(slave->dev);
-	}
-}
-
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		if (bond_slave_is_up(slave))
-			slave_disable_netpoll(slave);
-}
-
-static int bond_netpoll_setup(struct net_device *dev, struct netpoll_info *ni)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	struct slave *slave;
-	int err = 0;
-
-	bond_for_each_slave(bond, slave, iter) {
-		err = slave_enable_netpoll(slave);
-		if (err) {
-			bond_netpoll_cleanup(dev);
-			break;
-		}
-	}
-	return err;
-}
-#else
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	return 0;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-}
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-}
-#endif
-
-/*---------------------------------- IOCTL ----------------------------------*/
-
-static netdev_features_t bond_fix_features(struct net_device *dev,
-					   netdev_features_t features)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	netdev_features_t mask;
-	struct slave *slave;
-
-	mask = features;
-
-	features &= ~NETIF_F_ONE_FOR_ALL;
-	features |= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		features = netdev_increment_features(features,
-						     slave->dev->features,
-						     mask);
-	}
-	features = netdev_add_tso_features(features, mask);
-
-	return features;
-}
-
-#define BOND_VLAN_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_FRAGLIST | NETIF_F_ALL_TSO | \
-				 NETIF_F_HIGHDMA | NETIF_F_LRO)
-
-#define BOND_ENC_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_RXCSUM | NETIF_F_ALL_TSO)
-
-#define BOND_MPLS_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_ALL_TSO)
-
-static void bond_compute_features(struct bonding *bond)
-{
-	unsigned int dst_release_flag = IFF_XMIT_DST_RELEASE |
-					IFF_XMIT_DST_RELEASE_PERM;
-	netdev_features_t vlan_features = BOND_VLAN_FEATURES;
-	netdev_features_t enc_features  = BOND_ENC_FEATURES;
-	netdev_features_t mpls_features  = BOND_MPLS_FEATURES;
-	struct net_device *bond_dev = bond->dev;
-	struct list_head *iter;
-	struct slave *slave;
-	unsigned short max_hard_header_len = ETH_HLEN;
-	unsigned int gso_max_size = GSO_MAX_SIZE;
-	u16 gso_max_segs = GSO_MAX_SEGS;
-
-	if (!bond_has_slaves(bond))
-		goto done;
-	vlan_features &= NETIF_F_ALL_FOR_ALL;
-	mpls_features &= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		vlan_features = netdev_increment_features(vlan_features,
-			slave->dev->vlan_features, BOND_VLAN_FEATURES);
-
-		enc_features = netdev_increment_features(enc_features,
-							 slave->dev->hw_enc_features,
-							 BOND_ENC_FEATURES);
-
-		mpls_features = netdev_increment_features(mpls_features,
-							  slave->dev->mpls_features,
-							  BOND_MPLS_FEATURES);
-
-		dst_release_flag &= slave->dev->priv_flags;
-		if (slave->dev->hard_header_len > max_hard_header_len)
-			max_hard_header_len = slave->dev->hard_header_len;
-
-		gso_max_size = min(gso_max_size, slave->dev->gso_max_size);
-		gso_max_segs = min(gso_max_segs, slave->dev->gso_max_segs);
-	}
-	bond_dev->hard_header_len = max_hard_header_len;
-
-done:
-	bond_dev->vlan_features = vlan_features;
-	bond_dev->hw_enc_features = enc_features | NETIF_F_GSO_ENCAP_ALL |
-				    NETIF_F_HW_VLAN_CTAG_TX |
-				    NETIF_F_HW_VLAN_STAG_TX |
-				    NETIF_F_GSO_UDP_L4;
-	bond_dev->mpls_features = mpls_features;
-	bond_dev->gso_max_segs = gso_max_segs;
-	netif_set_gso_max_size(bond_dev, gso_max_size);
-
-	bond_dev->priv_flags &= ~IFF_XMIT_DST_RELEASE;
-	if ((bond_dev->priv_flags & IFF_XMIT_DST_RELEASE_PERM) &&
-	    dst_release_flag == (IFF_XMIT_DST_RELEASE | IFF_XMIT_DST_RELEASE_PERM))
-		bond_dev->priv_flags |= IFF_XMIT_DST_RELEASE;
-
-	netdev_change_features(bond_dev);
-}
-
-static void bond_setup_by_slave(struct net_device *bond_dev,
-				struct net_device *slave_dev)
-{
-	bond_dev->header_ops	    = slave_dev->header_ops;
-
-	bond_dev->type		    = slave_dev->type;
-	bond_dev->hard_header_len   = slave_dev->hard_header_len;
-	bond_dev->addr_len	    = slave_dev->addr_len;
-
-	memcpy(bond_dev->broadcast, slave_dev->broadcast,
-		slave_dev->addr_len);
-}
-
-/* On bonding slaves other than the currently active slave, suppress
- * duplicates except for alb non-mcast/bcast.
- */
-static bool bond_should_deliver_exact_match(struct sk_buff *skb,
-					    struct slave *slave,
-					    struct bonding *bond)
-{
-	if (bond_is_slave_inactive(slave)) {
-		if (BOND_MODE(bond) == BOND_MODE_ALB &&
-		    skb->pkt_type != PACKET_BROADCAST &&
-		    skb->pkt_type != PACKET_MULTICAST)
-			return false;
-		return true;
-	}
-	return false;
-}
-
-static rx_handler_result_t bond_handle_frame(struct sk_buff **pskb)
-{
-	struct sk_buff *skb = *pskb;
-	struct slave *slave;
-	struct bonding *bond;
-	int (*recv_probe)(const struct sk_buff *, struct bonding *,
-			  struct slave *);
-	int ret = RX_HANDLER_ANOTHER;
-
-	skb = skb_share_check(skb, GFP_ATOMIC);
-	if (unlikely(!skb))
-		return RX_HANDLER_CONSUMED;
-
-	*pskb = skb;
-
-	slave = bond_slave_get_rcu(skb->dev);
-	bond = slave->bond;
-
-	recv_probe = READ_ONCE(bond->recv_probe);
-	if (recv_probe) {
-		ret = recv_probe(skb, bond, slave);
-		if (ret == RX_HANDLER_CONSUMED) {
-			consume_skb(skb);
-			return ret;
-		}
-	}
-
-	/*
-	 * For packets determined by bond_should_deliver_exact_match() call to
-	 * be suppressed we want to make an exception for link-local packets.
-	 * This is necessary for e.g. LLDP daemons to be able to monitor
-	 * inactive slave links without being forced to bind to them
-	 * explicitly.
-	 *
-	 * At the same time, packets that are passed to the bonding master
-	 * (including link-local ones) can have their originating interface
-	 * determined via PACKET_ORIGDEV socket option.
-	 */
-	if (bond_should_deliver_exact_match(skb, slave, bond)) {
-		if (is_link_local_ether_addr(eth_hdr(skb)->h_dest))
-			return RX_HANDLER_PASS;
-		return RX_HANDLER_EXACT;
-	}
-
-	skb->dev = bond->dev;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB &&
-	    bond->dev->priv_flags & IFF_BRIDGE_PORT &&
-	    skb->pkt_type == PACKET_HOST) {
-
-		if (unlikely(skb_cow_head(skb,
-					  skb->data - skb_mac_header(skb)))) {
-			kfree_skb(skb);
-			return RX_HANDLER_CONSUMED;
-		}
-		bond_hw_addr_copy(eth_hdr(skb)->h_dest, bond->dev->dev_addr,
-				  bond->dev->addr_len);
-	}
-
-	return ret;
-}
-
-static enum netdev_lag_tx_type bond_lag_tx_type(struct bonding *bond)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return NETDEV_LAG_TX_TYPE_ROUNDROBIN;
-	case BOND_MODE_ACTIVEBACKUP:
-		return NETDEV_LAG_TX_TYPE_ACTIVEBACKUP;
-	case BOND_MODE_BROADCAST:
-		return NETDEV_LAG_TX_TYPE_BROADCAST;
-	case BOND_MODE_XOR:
-	case BOND_MODE_8023AD:
-		return NETDEV_LAG_TX_TYPE_HASH;
-	default:
-		return NETDEV_LAG_TX_TYPE_UNKNOWN;
-	}
-}
-
-static enum netdev_lag_hash bond_lag_hash_type(struct bonding *bond,
-					       enum netdev_lag_tx_type type)
-{
-	if (type != NETDEV_LAG_TX_TYPE_HASH)
-		return NETDEV_LAG_HASH_NONE;
-
-	switch (bond->params.xmit_policy) {
-	case BOND_XMIT_POLICY_LAYER2:
-		return NETDEV_LAG_HASH_L2;
-	case BOND_XMIT_POLICY_LAYER34:
-		return NETDEV_LAG_HASH_L34;
-	case BOND_XMIT_POLICY_LAYER23:
-		return NETDEV_LAG_HASH_L23;
-	case BOND_XMIT_POLICY_ENCAP23:
-		return NETDEV_LAG_HASH_E23;
-	case BOND_XMIT_POLICY_ENCAP34:
-		return NETDEV_LAG_HASH_E34;
-	default:
-		return NETDEV_LAG_HASH_UNKNOWN;
-	}
-}
-
-static int bond_master_upper_dev_link(struct bonding *bond, struct slave *slave,
-				      struct netlink_ext_ack *extack)
-{
-	struct netdev_lag_upper_info lag_upper_info;
-	enum netdev_lag_tx_type type;
-
-	type = bond_lag_tx_type(bond);
-	lag_upper_info.tx_type = type;
-	lag_upper_info.hash_type = bond_lag_hash_type(bond, type);
-
-	return netdev_master_upper_dev_link(slave->dev, bond->dev, slave,
-					    &lag_upper_info, extack);
-}
-
-static void bond_upper_dev_unlink(struct bonding *bond, struct slave *slave)
-{
-	netdev_upper_dev_unlink(slave->dev, bond->dev);
-	slave->dev->flags &= ~IFF_SLAVE;
-}
-
-static struct slave *bond_alloc_slave(struct bonding *bond)
-{
-	struct slave *slave = NULL;
-
-	slave = kzalloc(sizeof(*slave), GFP_KERNEL);
-	if (!slave)
-		return NULL;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		SLAVE_AD_INFO(slave) = kzalloc(sizeof(struct ad_slave_info),
-					       GFP_KERNEL);
-		if (!SLAVE_AD_INFO(slave)) {
-			kfree(slave);
-			return NULL;
-		}
-	}
-	INIT_DELAYED_WORK(&slave->notify_work, bond_netdev_notify_work);
-
-	return slave;
-}
-
-static void bond_free_slave(struct slave *slave)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-
-	cancel_delayed_work_sync(&slave->notify_work);
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		kfree(SLAVE_AD_INFO(slave));
-
-	kfree(slave);
-}
-
-static void bond_fill_ifbond(struct bonding *bond, struct ifbond *info)
-{
-	info->bond_mode = BOND_MODE(bond);
-	info->miimon = bond->params.miimon;
-	info->num_slaves = bond->slave_cnt;
-}
-
-static void bond_fill_ifslave(struct slave *slave, struct ifslave *info)
-{
-	strcpy(info->slave_name, slave->dev->name);
-	info->link = slave->link;
-	info->state = bond_slave_state(slave);
-	info->link_failure_count = slave->link_failure_count;
-}
-
-static void bond_netdev_notify_work(struct work_struct *_work)
-{
-	struct slave *slave = container_of(_work, struct slave,
-					   notify_work.work);
-
-	if (rtnl_trylock()) {
-		struct netdev_bonding_info binfo;
-
-		bond_fill_ifslave(slave, &binfo.slave);
-		bond_fill_ifbond(slave->bond, &binfo.master);
-		netdev_bonding_info_change(slave->dev, &binfo);
-		rtnl_unlock();
-	} else {
-		queue_delayed_work(slave->bond->wq, &slave->notify_work, 1);
-	}
-}
-
-void bond_queue_slave_event(struct slave *slave)
-{
-	queue_delayed_work(slave->bond->wq, &slave->notify_work, 0);
-}
-
-void bond_lower_state_changed(struct slave *slave)
-{
-	struct netdev_lag_lower_state_info info;
-
-	info.link_up = slave->link == BOND_LINK_UP ||
-		       slave->link == BOND_LINK_FAIL;
-	info.tx_enabled = bond_is_active_slave(slave);
-	netdev_lower_state_changed(slave->dev, &info);
-}
-
-/* enslave device <slave> to bond device <master> */
-int bond_enslave(struct net_device *bond_dev, struct net_device *slave_dev,
-		 struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	struct slave *new_slave = NULL, *prev_slave;
-	struct sockaddr_storage ss;
-	int link_reporting;
-	int res = 0, i;
-
-	if (!bond->params.use_carrier &&
-	    slave_dev->ethtool_ops->get_link == NULL &&
-	    slave_ops->ndo_do_ioctl == NULL) {
-		slave_warn(bond_dev, slave_dev, "no link monitoring support\n");
-	}
-
-	/* already in-use? */
-	if (netdev_is_rx_handler_busy(slave_dev)) {
-		NL_SET_ERR_MSG(extack, "Device is in use and cannot be enslaved");
-		slave_err(bond_dev, slave_dev,
-			  "Error: Device is in use and cannot be enslaved\n");
-		return -EBUSY;
-	}
-
-	if (bond_dev == slave_dev) {
-		NL_SET_ERR_MSG(extack, "Cannot enslave bond to itself.");
-		netdev_err(bond_dev, "cannot enslave bond to itself.\n");
-		return -EPERM;
-	}
-
-	/* vlan challenged mutual exclusion */
-	/* no need to lock since we're protected by rtnl_lock */
-	if (slave_dev->features & NETIF_F_VLAN_CHALLENGED) {
-		slave_dbg(bond_dev, slave_dev, "is NETIF_F_VLAN_CHALLENGED\n");
-		if (vlan_uses_dev(bond_dev)) {
-			NL_SET_ERR_MSG(extack, "Can not enslave VLAN challenged device to VLAN enabled bond");
-			slave_err(bond_dev, slave_dev, "Error: cannot enslave VLAN challenged slave on VLAN enabled bond\n");
-			return -EPERM;
-		} else {
-			slave_warn(bond_dev, slave_dev, "enslaved VLAN challenged slave. Adding VLANs will be blocked as long as it is part of bond.\n");
-		}
-	} else {
-		slave_dbg(bond_dev, slave_dev, "is !NETIF_F_VLAN_CHALLENGED\n");
-	}
-
-	/* Old ifenslave binaries are no longer supported.  These can
-	 * be identified with moderate accuracy by the state of the slave:
-	 * the current ifenslave will set the interface down prior to
-	 * enslaving it; the old ifenslave will not.
-	 */
-	if (slave_dev->flags & IFF_UP) {
-		NL_SET_ERR_MSG(extack, "Device can not be enslaved while up");
-		slave_err(bond_dev, slave_dev, "slave is up - this may be due to an out of date ifenslave\n");
-		return -EPERM;
-	}
-
-	/* set bonding device ether type by slave - bonding netdevices are
-	 * created with ether_setup, so when the slave type is not ARPHRD_ETHER
-	 * there is a need to override some of the type dependent attribs/funcs.
-	 *
-	 * bond ether type mutual exclusion - don't allow slaves of dissimilar
-	 * ether type (eg ARPHRD_ETHER and ARPHRD_INFINIBAND) share the same bond
-	 */
-	if (!bond_has_slaves(bond)) {
-		if (bond_dev->type != slave_dev->type) {
-			slave_dbg(bond_dev, slave_dev, "change device type from %d to %d\n",
-				  bond_dev->type, slave_dev->type);
-
-			res = call_netdevice_notifiers(NETDEV_PRE_TYPE_CHANGE,
-						       bond_dev);
-			res = notifier_to_errno(res);
-			if (res) {
-				slave_err(bond_dev, slave_dev, "refused to change device type\n");
-				return -EBUSY;
-			}
-
-			/* Flush unicast and multicast addresses */
-			dev_uc_flush(bond_dev);
-			dev_mc_flush(bond_dev);
-
-			if (slave_dev->type != ARPHRD_ETHER)
-				bond_setup_by_slave(bond_dev, slave_dev);
-			else {
-				ether_setup(bond_dev);
-				bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-			}
-
-			call_netdevice_notifiers(NETDEV_POST_TYPE_CHANGE,
-						 bond_dev);
-		}
-	} else if (bond_dev->type != slave_dev->type) {
-		NL_SET_ERR_MSG(extack, "Device type is different from other slaves");
-		slave_err(bond_dev, slave_dev, "ether type (%d) is different from other slaves (%d), can not enslave it\n",
-			  slave_dev->type, bond_dev->type);
-		return -EINVAL;
-	}
-
-	if (slave_dev->type == ARPHRD_INFINIBAND &&
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		NL_SET_ERR_MSG(extack, "Only active-backup mode is supported for infiniband slaves");
-		slave_warn(bond_dev, slave_dev, "Type (%d) supports only active-backup mode\n",
-			   slave_dev->type);
-		res = -EOPNOTSUPP;
-		goto err_undo_flags;
-	}
-
-	if (!slave_ops->ndo_set_mac_address ||
-	    slave_dev->type == ARPHRD_INFINIBAND) {
-		slave_warn(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address\n");
-		if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
-		    bond->params.fail_over_mac != BOND_FOM_ACTIVE) {
-			if (!bond_has_slaves(bond)) {
-				bond->params.fail_over_mac = BOND_FOM_ACTIVE;
-				slave_warn(bond_dev, slave_dev, "Setting fail_over_mac to active for active-backup mode\n");
-			} else {
-				NL_SET_ERR_MSG(extack, "Slave device does not support setting the MAC address, but fail_over_mac is not set to active");
-				slave_err(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address, but fail_over_mac is not set to active\n");
-				res = -EOPNOTSUPP;
-				goto err_undo_flags;
-			}
-		}
-	}
-
-	call_netdevice_notifiers(NETDEV_JOIN, slave_dev);
-
-	/* If this is the first slave, then we need to set the master's hardware
-	 * address to be the same as the slave's.
-	 */
-	if (!bond_has_slaves(bond) &&
-	    bond->dev->addr_assign_type == NET_ADDR_RANDOM) {
-		res = bond_set_dev_addr(bond->dev, slave_dev);
-		if (res)
-			goto err_undo_flags;
-	}
-
-	new_slave = bond_alloc_slave(bond);
-	if (!new_slave) {
-		res = -ENOMEM;
-		goto err_undo_flags;
-	}
-
-	new_slave->bond = bond;
-	new_slave->dev = slave_dev;
-	/* Set the new_slave's queue_id to be zero.  Queue ID mapping
-	 * is set via sysfs or module option if desired.
-	 */
-	new_slave->queue_id = 0;
-
-	/* Save slave's original mtu and then set it to match the bond */
-	new_slave->original_mtu = slave_dev->mtu;
-	res = dev_set_mtu(slave_dev, bond->dev->mtu);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Error %d calling dev_set_mtu\n", res);
-		goto err_free;
-	}
-
-	/* Save slave's original ("permanent") mac address for modes
-	 * that need it, and for restoring it upon release, and then
-	 * set it to the master's address
-	 */
-	bond_hw_addr_copy(new_slave->perm_hwaddr, slave_dev->dev_addr,
-			  slave_dev->addr_len);
-
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* Set slave to master's mac address.  The application already
-		 * set the master's mac address to that of the first slave
-		 */
-		memcpy(ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		res = dev_set_mac_address(slave_dev, (struct sockaddr *)&ss,
-					  extack);
-		if (res) {
-			slave_err(bond_dev, slave_dev, "Error %d calling set_mac_address\n", res);
-			goto err_restore_mtu;
-		}
-	}
-
-	/* set slave flag before open to prevent IPv6 addrconf */
-	slave_dev->flags |= IFF_SLAVE;
-
-	/* open the slave since the application closed it */
-	res = dev_open(slave_dev, extack);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Opening slave failed\n");
-		goto err_restore_mac;
-	}
-
-	slave_dev->priv_flags |= IFF_BONDING;
-	/* initialize slave stats */
-	dev_get_stats(new_slave->dev, &new_slave->slave_stats);
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_init_slave() must be called before all other stages since
-		 * it might fail and we do not want to have to undo everything
-		 */
-		res = bond_alb_init_slave(bond, new_slave);
-		if (res)
-			goto err_close;
-	}
-
-	res = vlan_vids_add_by_dev(slave_dev, bond_dev);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Couldn't add bond vlan ids\n");
-		goto err_close;
-	}
-
-	prev_slave = bond_last_slave(bond);
-
-	new_slave->delay = 0;
-	new_slave->link_failure_count = 0;
-
-	if (bond_update_speed_duplex(new_slave) &&
-	    bond_needs_speed_duplex(bond))
-		new_slave->link = BOND_LINK_DOWN;
-
-	new_slave->last_rx = jiffies -
-		(msecs_to_jiffies(bond->params.arp_interval) + 1);
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
-		new_slave->target_last_arp_rx[i] = new_slave->last_rx;
-
-	if (bond->params.miimon && !bond->params.use_carrier) {
-		link_reporting = bond_check_dev_link(bond, slave_dev, 1);
-
-		if ((link_reporting == -1) && !bond->params.arp_interval) {
-			/* miimon is set but a bonded network driver
-			 * does not support ETHTOOL/MII and
-			 * arp_interval is not set.  Note: if
-			 * use_carrier is enabled, we will never go
-			 * here (because netif_carrier is always
-			 * supported); thus, we don't need to change
-			 * the messages for netif_carrier.
-			 */
-			slave_warn(bond_dev, slave_dev, "MII and ETHTOOL support not available for slave, and arp_interval/arp_ip_target module parameters not specified, thus bonding will not detect link failures! see bonding.txt for details\n");
-		} else if (link_reporting == -1) {
-			/* unable get link status using mii/ethtool */
-			slave_warn(bond_dev, slave_dev, "can't get link status from slave; the network driver associated with this interface does not support MII or ETHTOOL link status reporting, thus miimon has no effect on this interface\n");
-		}
-	}
-
-	/* check for initial state */
-	new_slave->link = BOND_LINK_NOCHANGE;
-	if (bond->params.miimon) {
-		if (bond_check_dev_link(bond, slave_dev, 0) == BMSR_LSTATUS) {
-			if (bond->params.updelay) {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_BACK,
-							  BOND_SLAVE_NOTIFY_NOW);
-				new_slave->delay = bond->params.updelay;
-			} else {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-			}
-		} else {
-			bond_set_slave_link_state(new_slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-		}
-	} else if (bond->params.arp_interval) {
-		bond_set_slave_link_state(new_slave,
-					  (netif_carrier_ok(slave_dev) ?
-					  BOND_LINK_UP : BOND_LINK_DOWN),
-					  BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		bond_set_slave_link_state(new_slave, BOND_LINK_UP,
-					  BOND_SLAVE_NOTIFY_NOW);
-	}
-
-	if (new_slave->link != BOND_LINK_DOWN)
-		new_slave->last_link_up = jiffies;
-	slave_dbg(bond_dev, slave_dev, "Initial state of slave is BOND_LINK_%s\n",
-		  new_slave->link == BOND_LINK_DOWN ? "DOWN" :
-		  (new_slave->link == BOND_LINK_UP ? "UP" : "BACK"));
-
-	if (bond_uses_primary(bond) && bond->params.primary[0]) {
-		/* if there is a primary slave, remember it */
-		if (strcmp(bond->params.primary, new_slave->dev->name) == 0) {
-			rcu_assign_pointer(bond->primary_slave, new_slave);
-			bond->force_primary = true;
-		}
-	}
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ACTIVEBACKUP:
-		bond_set_slave_inactive_flags(new_slave,
-					      BOND_SLAVE_NOTIFY_NOW);
-		break;
-	case BOND_MODE_8023AD:
-		/* in 802.3ad mode, the internal mechanism
-		 * will activate the slaves in the selected
-		 * aggregator
-		 */
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		/* if this is the first slave */
-		if (!prev_slave) {
-			SLAVE_AD_INFO(new_slave)->id = 1;
-			/* Initialize AD with the number of times that the AD timer is called in 1 second
-			 * can be called only after the mac address of the bond is set
-			 */
-			bond_3ad_initialize(bond, 1000/AD_TIMER_INTERVAL);
-		} else {
-			SLAVE_AD_INFO(new_slave)->id =
-				SLAVE_AD_INFO(prev_slave)->id + 1;
-		}
-
-		bond_3ad_bind_slave(new_slave);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_set_active_slave(new_slave);
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		break;
-	default:
-		slave_dbg(bond_dev, slave_dev, "This slave is always active in trunk mode\n");
-
-		/* always active in trunk mode */
-		bond_set_active_slave(new_slave);
-
-		/* In trunking mode there is little meaning to curr_active_slave
-		 * anyway (it holds no special properties of the bond device),
-		 * so we can change it without calling change_active_interface()
-		 */
-		if (!rcu_access_pointer(bond->curr_active_slave) &&
-		    new_slave->link == BOND_LINK_UP)
-			rcu_assign_pointer(bond->curr_active_slave, new_slave);
-
-		break;
-	} /* switch(bond_mode) */
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	if (bond->dev->npinfo) {
-		if (slave_enable_netpoll(new_slave)) {
-			slave_info(bond_dev, slave_dev, "master_dev is using netpoll, but new slave device does not support netpoll\n");
-			res = -EBUSY;
-			goto err_detach;
-		}
-	}
-#endif
-
-	if (!(bond_dev->features & NETIF_F_LRO))
-		dev_disable_lro(slave_dev);
-
-	res = netdev_rx_handler_register(slave_dev, bond_handle_frame,
-					 new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling netdev_rx_handler_register\n", res);
-		goto err_detach;
-	}
-
-	res = bond_master_upper_dev_link(bond, new_slave, extack);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_master_upper_dev_link\n", res);
-		goto err_unregister;
-	}
-
-	res = bond_sysfs_slave_add(new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_sysfs_slave_add\n", res);
-		goto err_upper_unlink;
-	}
-
-	/* If the mode uses primary, then the following is handled by
-	 * bond_change_active_slave().
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* set promiscuity level to new slave */
-		if (bond_dev->flags & IFF_PROMISC) {
-			res = dev_set_promiscuity(slave_dev, 1);
-			if (res)
-				goto err_sysfs_del;
-		}
-
-		/* set allmulti level to new slave */
-		if (bond_dev->flags & IFF_ALLMULTI) {
-			res = dev_set_allmulti(slave_dev, 1);
-			if (res) {
-				if (bond_dev->flags & IFF_PROMISC)
-					dev_set_promiscuity(slave_dev, -1);
-				goto err_sysfs_del;
-			}
-		}
-
-		netif_addr_lock_bh(bond_dev);
-		dev_mc_sync_multiple(slave_dev, bond_dev);
-		dev_uc_sync_multiple(slave_dev, bond_dev);
-		netif_addr_unlock_bh(bond_dev);
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			/* add lacpdu mc addr to mc list */
-			u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-			dev_mc_add(slave_dev, lacpdu_multicast);
-		}
-	}
-
-	bond->slave_cnt++;
-	bond_compute_features(bond);
-	bond_set_carrier(bond);
-
-	if (bond_uses_primary(bond)) {
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-
-	slave_info(bond_dev, slave_dev, "Enslaving as %s interface with %s link\n",
-		   bond_is_active_slave(new_slave) ? "an active" : "a backup",
-		   new_slave->link != BOND_LINK_DOWN ? "an up" : "a down");
-
-	/* enslave is successful */
-	bond_queue_slave_event(new_slave);
-	return 0;
-
-/* Undo stages on error */
-err_sysfs_del:
-	bond_sysfs_slave_del(new_slave);
-
-err_upper_unlink:
-	bond_upper_dev_unlink(bond, new_slave);
-
-err_unregister:
-	netdev_rx_handler_unregister(slave_dev);
-
-err_detach:
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-	if (rcu_access_pointer(bond->primary_slave) == new_slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-	if (rcu_access_pointer(bond->curr_active_slave) == new_slave) {
-		block_netpoll_tx();
-		bond_change_active_slave(bond, NULL);
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-	/* either primary_slave or curr_active_slave might've changed */
-	synchronize_rcu();
-	slave_disable_netpoll(new_slave);
-
-err_close:
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-	dev_close(slave_dev);
-
-err_restore_mac:
-	slave_dev->flags &= ~IFF_SLAVE;
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* XXX TODO - fom follow mode needs to change master's
-		 * MAC if this slave's MAC is in use by the bond, or at
-		 * least print a warning.
-		 */
-		bond_hw_addr_copy(ss.__data, new_slave->perm_hwaddr,
-				  new_slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-err_restore_mtu:
-	dev_set_mtu(slave_dev, new_slave->original_mtu);
-
-err_free:
-	bond_free_slave(new_slave);
-
-err_undo_flags:
-	/* Enslave of first slave has failed and we need to fix master's mac */
-	if (!bond_has_slaves(bond)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr,
-					    slave_dev->dev_addr))
-			eth_hw_addr_random(bond_dev);
-		if (bond_dev->type != ARPHRD_ETHER) {
-			dev_close(bond_dev);
-			ether_setup(bond_dev);
-			bond_dev->flags |= IFF_MASTER;
-			bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-		}
-	}
-
-	return res;
-}
-
-/* Try to release the slave device <slave> from the bond device <master>
- * It is legal to access curr_active_slave without a lock because all the function
- * is RTNL-locked. If "all" is true it means that the function is being called
- * while destroying a bond interface and all slaves are being released.
- *
- * The rules for slave state should be:
- *   for Active/Backup:
- *     Active stays on all backups go down
- *   for Bonded connections:
- *     The first up interface should be left on and all others downed.
- */
-static int __bond_release_one(struct net_device *bond_dev,
-			      struct net_device *slave_dev,
-			      bool all, bool unregister)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *oldcurrent;
-	struct sockaddr_storage ss;
-	int old_flags = bond_dev->flags;
-	netdev_features_t old_features = bond_dev->features;
-
-	/* slave is not a slave or master is not master of this slave */
-	if (!(slave_dev->flags & IFF_SLAVE) ||
-	    !netdev_has_upper_dev(slave_dev, bond_dev)) {
-		slave_dbg(bond_dev, slave_dev, "cannot release slave\n");
-		return -EINVAL;
-	}
-
-	block_netpoll_tx();
-
-	slave = bond_get_slave_by_dev(bond, slave_dev);
-	if (!slave) {
-		/* not a slave of this bond */
-		slave_info(bond_dev, slave_dev, "interface not enslaved\n");
-		unblock_netpoll_tx();
-		return -EINVAL;
-	}
-
-	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
-
-	bond_sysfs_slave_del(slave);
-
-	/* recompute stats just before removing the slave */
-	bond_get_stats(bond->dev, &bond->bond_stats);
-
-	bond_upper_dev_unlink(bond, slave);
-	/* unregister rx_handler early so bond_handle_frame wouldn't be called
-	 * for this slave anymore.
-	 */
-	netdev_rx_handler_unregister(slave_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		bond_3ad_unbind_slave(slave);
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, slave);
-
-	slave_info(bond_dev, slave_dev, "Releasing %s interface\n",
-		    bond_is_active_slave(slave) ? "active" : "backup");
-
-	oldcurrent = rcu_access_pointer(bond->curr_active_slave);
-
-	RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-
-	if (!all && (!bond->params.fail_over_mac ||
-		     BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr, slave->perm_hwaddr) &&
-		    bond_has_slaves(bond))
-			slave_warn(bond_dev, slave_dev, "the permanent HWaddr of slave - %pM - is still in use by bond - set the HWaddr of slave to a different address to avoid conflicts\n",
-				   slave->perm_hwaddr);
-	}
-
-	if (rtnl_dereference(bond->primary_slave) == slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-
-	if (oldcurrent == slave)
-		bond_change_active_slave(bond, NULL);
-
-	if (bond_is_lb(bond)) {
-		/* Must be called only after the slave has been
-		 * detached from the list and the curr_active_slave
-		 * has been cleared (if our_slave == old_current),
-		 * but before a new active slave is selected.
-		 */
-		bond_alb_deinit_slave(bond, slave);
-	}
-
-	if (all) {
-		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
-	} else if (oldcurrent == slave) {
-		/* Note that we hold RTNL over this sequence, so there
-		 * is no concern that another slave add/remove event
-		 * will interfere.
-		 */
-		bond_select_active_slave(bond);
-	}
-
-	if (!bond_has_slaves(bond)) {
-		bond_set_carrier(bond);
-		eth_hw_addr_random(bond_dev);
-	}
-
-	unblock_netpoll_tx();
-	synchronize_rcu();
-	bond->slave_cnt--;
-
-	if (!bond_has_slaves(bond)) {
-		call_netdevice_notifiers(NETDEV_CHANGEADDR, bond->dev);
-		call_netdevice_notifiers(NETDEV_RELEASE, bond->dev);
-	}
-
-	bond_compute_features(bond);
-	if (!(bond_dev->features & NETIF_F_VLAN_CHALLENGED) &&
-	    (old_features & NETIF_F_VLAN_CHALLENGED))
-		slave_info(bond_dev, slave_dev, "last VLAN challenged slave left bond - VLAN blocking is removed\n");
-
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-
-	/* If the mode uses primary, then this case was handled above by
-	 * bond_change_active_slave(..., NULL)
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* unset promiscuity level from slave
-		 * NOTE: The NETDEV_CHANGEADDR call above may change the value
-		 * of the IFF_PROMISC flag in the bond_dev, but we need the
-		 * value of that flag before that change, as that was the value
-		 * when this slave was attached, so we cache at the start of the
-		 * function and use it here. Same goes for ALLMULTI below
-		 */
-		if (old_flags & IFF_PROMISC)
-			dev_set_promiscuity(slave_dev, -1);
-
-		/* unset allmulti level from slave */
-		if (old_flags & IFF_ALLMULTI)
-			dev_set_allmulti(slave_dev, -1);
-
-		bond_hw_addr_flush(bond_dev, slave_dev);
-	}
-
-	slave_disable_netpoll(slave);
-
-	/* close slave before restoring its mac address */
-	dev_close(slave_dev);
-
-	if (bond->params.fail_over_mac != BOND_FOM_ACTIVE ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* restore original ("permanent") mac address */
-		bond_hw_addr_copy(ss.__data, slave->perm_hwaddr,
-				  slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-	if (unregister)
-		__dev_set_mtu(slave_dev, slave->original_mtu);
-	else
-		dev_set_mtu(slave_dev, slave->original_mtu);
-
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-
-	bond_free_slave(slave);
-
-	return 0;
-}
-
-/* A wrapper used because of ndo_del_link */
-int bond_release(struct net_device *bond_dev, struct net_device *slave_dev)
-{
-	return __bond_release_one(bond_dev, slave_dev, false, false);
-}
-
-/* First release a slave and then destroy the bond if no more slaves are left.
- * Must be under rtnl_lock when this function is called.
- */
-static int bond_release_and_destroy(struct net_device *bond_dev,
-				    struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	int ret;
-
-	ret = __bond_release_one(bond_dev, slave_dev, false, true);
-	if (ret == 0 && !bond_has_slaves(bond)) {
-		bond_dev->priv_flags |= IFF_DISABLE_NETPOLL;
-		netdev_info(bond_dev, "Destroying bond\n");
-		bond_remove_proc_entry(bond);
-		unregister_netdevice(bond_dev);
-	}
-	return ret;
-}
-
-static void bond_info_query(struct net_device *bond_dev, struct ifbond *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	bond_fill_ifbond(bond, info);
-}
-
-static int bond_slave_info_query(struct net_device *bond_dev, struct ifslave *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	int i = 0, res = -ENODEV;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (i++ == (int)info->slave_id) {
-			res = 0;
-			bond_fill_ifslave(slave, info);
-			break;
-		}
-	}
-
-	return res;
-}
-
-/*-------------------------------- Monitoring -------------------------------*/
-
-/* called with rcu_read_lock() */
-static int bond_miimon_inspect(struct bonding *bond)
-{
-	int link_state, commit = 0;
-	struct list_head *iter;
-	struct slave *slave;
-	bool ignore_updelay;
-
-	ignore_updelay = !rcu_dereference(bond->curr_active_slave);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		link_state = bond_check_dev_link(bond, slave->dev, 0);
-
-		switch (slave->link) {
-		case BOND_LINK_UP:
-			if (link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_FAIL);
-			commit++;
-			slave->delay = bond->params.downdelay;
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status down for %sinterface, disabling it in %d ms\n",
-					   (BOND_MODE(bond) ==
-					    BOND_MODE_ACTIVEBACKUP) ?
-					    (bond_is_active_slave(slave) ?
-					     "active " : "backup ") : "",
-					   bond->params.downdelay * bond->params.miimon);
-			}
-			/*FALLTHRU*/
-		case BOND_LINK_FAIL:
-			if (link_state) {
-				/* recovered before downdelay expired */
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave->last_link_up = jiffies;
-				slave_info(bond->dev, slave->dev, "link status up again after %d ms\n",
-					   (bond->params.downdelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				commit++;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-
-		case BOND_LINK_DOWN:
-			if (!link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_BACK);
-			commit++;
-			slave->delay = bond->params.updelay;
-
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status up, enabling it in %d ms\n",
-					   ignore_updelay ? 0 :
-					   bond->params.updelay *
-					   bond->params.miimon);
-			}
-			/*FALLTHRU*/
-		case BOND_LINK_BACK:
-			if (!link_state) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_info(bond->dev, slave->dev, "link status down again after %d ms\n",
-					   (bond->params.updelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (ignore_updelay)
-				slave->delay = 0;
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-				ignore_updelay = false;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-		}
-	}
-
-	return commit;
-}
-
-static void bond_miimon_link_change(struct bonding *bond,
-				    struct slave *slave,
-				    char link)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_8023AD:
-		bond_3ad_handle_link_change(slave, link);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_alb_handle_link_change(bond, slave, link);
-		break;
-	case BOND_MODE_XOR:
-		bond_update_slave_arr(bond, NULL);
-		break;
-	}
-}
-
-static void bond_miimon_commit(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave, *primary;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			/* For 802.3ad mode, check current slave speed and
-			 * duplex again in case its port was disabled after
-			 * invalid speed/duplex reporting but recovered before
-			 * link monitoring could make a decision on the actual
-			 * link status
-			 */
-			if (BOND_MODE(bond) == BOND_MODE_8023AD &&
-			    slave->link == BOND_LINK_UP)
-				bond_3ad_adapter_speed_duplex_changed(slave);
-			continue;
-
-		case BOND_LINK_UP:
-			if (bond_update_speed_duplex(slave) &&
-			    bond_needs_speed_duplex(bond)) {
-				slave->link = BOND_LINK_DOWN;
-				if (net_ratelimit())
-					slave_warn(bond->dev, slave->dev,
-						   "failed to get link speed/duplex\n");
-				continue;
-			}
-			bond_set_slave_link_state(slave, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-			slave->last_link_up = jiffies;
-
-			primary = rtnl_dereference(bond->primary_slave);
-			if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-				/* prevent it from being the active one */
-				bond_set_backup_slave(slave);
-			} else if (BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-				/* make it immediately active */
-				bond_set_active_slave(slave);
-			}
-
-			slave_info(bond->dev, slave->dev, "link status definitely up, %u Mbps %s duplex\n",
-				   slave->speed == SPEED_UNKNOWN ? 0 : slave->speed,
-				   slave->duplex ? "full" : "half");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_UP);
-
-			if (!bond->curr_active_slave || slave == primary)
-				goto do_failover;
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP ||
-			    BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_DOWN);
-
-			if (slave == rcu_access_pointer(bond->curr_active_slave))
-				goto do_failover;
-
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev, "invalid new link %d on slave\n",
-				  slave->link_new_state);
-			bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* bond_mii_monitor
- *
- * Really a wrapper that splits the mii monitor into two phases: an
- * inspection, then (if inspection indicates something needs to be done)
- * an acquisition of appropriate locks followed by a commit phase to
- * implement whatever link state changes are indicated.
- */
-static void bond_mii_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mii_work.work);
-	bool should_notify_peers = false;
-	bool commit;
-	unsigned long delay;
-	struct slave *slave;
-	struct list_head *iter;
-
-	delay = msecs_to_jiffies(bond->params.miimon);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-	should_notify_peers = bond_should_notify_peers(bond);
-	commit = !!bond_miimon_inspect(bond);
-	if (bond->send_peer_notif) {
-		rcu_read_unlock();
-		if (rtnl_trylock()) {
-			bond->send_peer_notif--;
-			rtnl_unlock();
-		}
-	} else {
-		rcu_read_unlock();
-	}
-
-	if (commit) {
-		/* Race avoidance with bond_close cancel of workqueue */
-		if (!rtnl_trylock()) {
-			delay = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_for_each_slave(bond, slave, iter) {
-			bond_commit_link_state(slave, BOND_SLAVE_NOTIFY_LATER);
-		}
-		bond_miimon_commit(bond);
-
-		rtnl_unlock();	/* might sleep, hold no other locks */
-	}
-
-re_arm:
-	if (bond->params.miimon)
-		queue_delayed_work(bond->wq, &bond->mii_work, delay);
-
-	if (should_notify_peers) {
-		if (!rtnl_trylock())
-			return;
-		call_netdevice_notifiers(NETDEV_NOTIFY_PEERS, bond->dev);
-		rtnl_unlock();
-	}
-}
-
-static int bond_upper_dev_walk(struct net_device *upper, void *data)
-{
-	__be32 ip = *((__be32 *)data);
-
-	return ip == bond_confirm_addr(upper, 0, ip);
-}
-
-static bool bond_has_this_ip(struct bonding *bond, __be32 ip)
-{
-	bool ret = false;
-
-	if (ip == bond_confirm_addr(bond->dev, 0, ip))
-		return true;
-
-	rcu_read_lock();
-	if (netdev_walk_all_upper_dev_rcu(bond->dev, bond_upper_dev_walk, &ip))
-		ret = true;
-	rcu_read_unlock();
-
-	return ret;
-}
-
-/* We go to the (large) trouble of VLAN tagging ARP frames because
- * switches in VLAN mode (especially if ports are configured as
- * "native" to a VLAN) might not pass non-tagged frames.
- */
-static void bond_arp_send(struct slave *slave, int arp_op, __be32 dest_ip,
-			  __be32 src_ip, struct bond_vlan_tag *tags)
-{
-	struct sk_buff *skb;
-	struct bond_vlan_tag *outer_tag = tags;
-	struct net_device *slave_dev = slave->dev;
-	struct net_device *bond_dev = slave->bond->dev;
-
-	slave_dbg(bond_dev, slave_dev, "arp %d on slave: dst %pI4 src %pI4\n",
-		  arp_op, &dest_ip, &src_ip);
-
-	skb = arp_create(arp_op, ETH_P_ARP, dest_ip, slave_dev, src_ip,
-			 NULL, slave_dev->dev_addr, NULL);
-
-	if (!skb) {
-		net_err_ratelimited("ARP packet allocation failed\n");
-		return;
-	}
-
-	if (!tags || tags->vlan_proto == VLAN_N_VID)
-		goto xmit;
-
-	tags++;
-
-	/* Go through all the tags backwards and add them to the packet */
-	while (tags->vlan_proto != VLAN_N_VID) {
-		if (!tags->vlan_id) {
-			tags++;
-			continue;
-		}
-
-		slave_dbg(bond_dev, slave_dev, "inner tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), tags->vlan_id);
-		skb = vlan_insert_tag_set_proto(skb, tags->vlan_proto,
-						tags->vlan_id);
-		if (!skb) {
-			net_err_ratelimited("failed to insert inner VLAN tag\n");
-			return;
-		}
-
-		tags++;
-	}
-	/* Set the outer tag */
-	if (outer_tag->vlan_id) {
-		slave_dbg(bond_dev, slave_dev, "outer tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), outer_tag->vlan_id);
-		__vlan_hwaccel_put_tag(skb, outer_tag->vlan_proto,
-				       outer_tag->vlan_id);
-	}
-
-xmit:
-	arp_xmit(skb);
-}
-
-/* Validate the device path between the @start_dev and the @end_dev.
- * The path is valid if the @end_dev is reachable through device
- * stacking.
- * When the path is validated, collect any vlan information in the
- * path.
- */
-struct bond_vlan_tag *bond_verify_device_path(struct net_device *start_dev,
-					      struct net_device *end_dev,
-					      int level)
-{
-	struct bond_vlan_tag *tags;
-	struct net_device *upper;
-	struct list_head  *iter;
-
-	if (start_dev == end_dev) {
-		tags = kcalloc(level + 1, sizeof(*tags), GFP_ATOMIC);
-		if (!tags)
-			return ERR_PTR(-ENOMEM);
-		tags[level].vlan_proto = VLAN_N_VID;
-		return tags;
-	}
-
-	netdev_for_each_upper_dev_rcu(start_dev, upper, iter) {
-		tags = bond_verify_device_path(upper, end_dev, level + 1);
-		if (IS_ERR_OR_NULL(tags)) {
-			if (IS_ERR(tags))
-				return tags;
-			continue;
-		}
-		if (is_vlan_dev(upper)) {
-			tags[level].vlan_proto = vlan_dev_vlan_proto(upper);
-			tags[level].vlan_id = vlan_dev_vlan_id(upper);
-		}
-
-		return tags;
-	}
-
-	return NULL;
-}
-
-static void bond_arp_send_all(struct bonding *bond, struct slave *slave)
-{
-	struct rtable *rt;
-	struct bond_vlan_tag *tags;
-	__be32 *targets = bond->params.arp_targets, addr;
-	int i;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS && targets[i]; i++) {
-		slave_dbg(bond->dev, slave->dev, "%s: target %pI4\n",
-			  __func__, &targets[i]);
-		tags = NULL;
-
-		/* Find out through which dev should the packet go */
-		rt = ip_route_output(dev_net(bond->dev), targets[i], 0,
-				     RTO_ONLINK, 0);
-		if (IS_ERR(rt)) {
-			/* there's no route to target - try to send arp
-			 * probe to generate any traffic (arp_validate=0)
-			 */
-			if (bond->params.arp_validate)
-				net_warn_ratelimited("%s: no route to arp_ip_target %pI4 and arp_validate is set\n",
-						     bond->dev->name,
-						     &targets[i]);
-			bond_arp_send(slave, ARPOP_REQUEST, targets[i],
-				      0, tags);
-			continue;
-		}
-
-		/* bond device itself */
-		if (rt->dst.dev == bond->dev)
-			goto found;
-
-		rcu_read_lock();
-		tags = bond_verify_device_path(bond->dev, rt->dst.dev, 0);
-		rcu_read_unlock();
-
-		if (!IS_ERR_OR_NULL(tags))
-			goto found;
-
-		/* Not our device - skip */
-		slave_dbg(bond->dev, slave->dev, "no path to arp_ip_target %pI4 via rt.dev %s\n",
-			   &targets[i], rt->dst.dev ? rt->dst.dev->name : "NULL");
-
-		ip_rt_put(rt);
-		continue;
-
-found:
-		addr = bond_confirm_addr(rt->dst.dev, targets[i], 0);
-		ip_rt_put(rt);
-		bond_arp_send(slave, ARPOP_REQUEST, targets[i], addr, tags);
-		kfree(tags);
-	}
-}
-
-static void bond_validate_arp(struct bonding *bond, struct slave *slave, __be32 sip, __be32 tip)
-{
-	int i;
-
-	if (!sip || !bond_has_this_ip(bond, tip)) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 tip %pI4 not found\n",
-			   __func__, &sip, &tip);
-		return;
-	}
-
-	i = bond_get_targets_ip(bond->params.arp_targets, sip);
-	if (i == -1) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 not found in targets\n",
-			   __func__, &sip);
-		return;
-	}
-	slave->last_rx = jiffies;
-	slave->target_last_arp_rx[i] = jiffies;
-}
-
-int bond_arp_rcv(const struct sk_buff *skb, struct bonding *bond,
-		 struct slave *slave)
-{
-	struct arphdr *arp = (struct arphdr *)skb->data;
-	struct slave *curr_active_slave, *curr_arp_slave;
-	unsigned char *arp_ptr;
-	__be32 sip, tip;
-	int is_arp = skb->protocol == __cpu_to_be16(ETH_P_ARP);
-	unsigned int alen;
-
-	if (!slave_do_arp_validate(bond, slave)) {
-		if ((slave_do_arp_validate_only(bond) && is_arp) ||
-		    !slave_do_arp_validate_only(bond))
-			slave->last_rx = jiffies;
-		return RX_HANDLER_ANOTHER;
-	} else if (!is_arp) {
-		return RX_HANDLER_ANOTHER;
-	}
-
-	alen = arp_hdr_len(bond->dev);
-
-	slave_dbg(bond->dev, slave->dev, "%s: skb->dev %s\n",
-		   __func__, skb->dev->name);
-
-	if (alen > skb_headlen(skb)) {
-		arp = kmalloc(alen, GFP_ATOMIC);
-		if (!arp)
-			goto out_unlock;
-		if (skb_copy_bits(skb, 0, arp, alen) < 0)
-			goto out_unlock;
-	}
-
-	if (arp->ar_hln != bond->dev->addr_len ||
-	    skb->pkt_type == PACKET_OTHERHOST ||
-	    skb->pkt_type == PACKET_LOOPBACK ||
-	    arp->ar_hrd != htons(ARPHRD_ETHER) ||
-	    arp->ar_pro != htons(ETH_P_IP) ||
-	    arp->ar_pln != 4)
-		goto out_unlock;
-
-	arp_ptr = (unsigned char *)(arp + 1);
-	arp_ptr += bond->dev->addr_len;
-	memcpy(&sip, arp_ptr, 4);
-	arp_ptr += 4 + bond->dev->addr_len;
-	memcpy(&tip, arp_ptr, 4);
-
-	slave_dbg(bond->dev, slave->dev, "%s: %s/%d av %d sv %d sip %pI4 tip %pI4\n",
-		  __func__, slave->dev->name, bond_slave_state(slave),
-		  bond->params.arp_validate, slave_do_arp_validate(bond, slave),
-		  &sip, &tip);
-
-	curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	curr_arp_slave = rcu_dereference(bond->current_arp_slave);
-
-	/* We 'trust' the received ARP enough to validate it if:
-	 *
-	 * (a) the slave receiving the ARP is active (which includes the
-	 * current ARP slave, if any), or
-	 *
-	 * (b) the receiving slave isn't active, but there is a currently
-	 * active slave and it received valid arp reply(s) after it became
-	 * the currently active slave, or
-	 *
-	 * (c) there is an ARP slave that sent an ARP during the prior ARP
-	 * interval, and we receive an ARP reply on any slave.  We accept
-	 * these because switch FDB update delays may deliver the ARP
-	 * reply to a slave other than the sender of the ARP request.
-	 *
-	 * Note: for (b), backup slaves are receiving the broadcast ARP
-	 * request, not a reply.  This request passes from the sending
-	 * slave through the L2 switch(es) to the receiving slave.  Since
-	 * this is checking the request, sip/tip are swapped for
-	 * validation.
-	 *
-	 * This is done to avoid endless looping when we can't reach the
-	 * arp_ip_target and fool ourselves with our own arp requests.
-	 */
-	if (bond_is_active_slave(slave))
-		bond_validate_arp(bond, slave, sip, tip);
-	else if (curr_active_slave &&
-		 time_after(slave_last_rx(bond, curr_active_slave),
-			    curr_active_slave->last_link_up))
-		bond_validate_arp(bond, slave, tip, sip);
-	else if (curr_arp_slave && (arp->ar_op == htons(ARPOP_REPLY)) &&
-		 bond_time_in_interval(bond,
-				       dev_trans_start(curr_arp_slave->dev), 1))
-		bond_validate_arp(bond, slave, sip, tip);
-
-out_unlock:
-	if (arp != (struct arphdr *)skb->data)
-		kfree(arp);
-	return RX_HANDLER_ANOTHER;
-}
-
-/* function to verify if we're in the arp_interval timeslice, returns true if
- * (last_act - arp_interval) <= jiffies <= (last_act + mod * arp_interval +
- * arp_interval/2) . the arp_interval/2 is needed for really fast networks.
- */
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod)
-{
-	int delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	return time_in_range(jiffies,
-			     last_act - delta_in_ticks,
-			     last_act + mod * delta_in_ticks + delta_in_ticks/2);
-}
-
-/* This function is called regularly to monitor each slave's link
- * ensuring that traffic is being sent and received when arp monitoring
- * is used in load-balancing mode. if the adapter has been dormant, then an
- * arp is transmitted to generate traffic. see activebackup_arp_monitor for
- * arp monitoring in active backup mode.
- */
-static void bond_loadbalance_arp_mon(struct bonding *bond)
-{
-	struct slave *slave, *oldcurrent;
-	struct list_head *iter;
-	int do_failover = 0, slave_state_changed = 0;
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	oldcurrent = rcu_dereference(bond->curr_active_slave);
-	/* see if any of the previous devices are up now (i.e. they have
-	 * xmt and rcv traffic). the curr_active_slave does not come into
-	 * the picture unless it is null. also, slave->last_link_up is not
-	 * needed here because we send an arp on each slave and give a slave
-	 * as long as it needs to get the tx/rx within the delta.
-	 * TODO: what about up/down delay in arp mode? it wasn't here before
-	 *       so it can wait
-	 */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		unsigned long trans_start = dev_trans_start(slave->dev);
-
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, trans_start, 1) &&
-			    bond_time_in_interval(bond, slave->last_rx, 1)) {
-
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave_state_changed = 1;
-
-				/* primary_slave has no meaning in round-robin
-				 * mode. the window of a slave being up and
-				 * curr_active_slave being null after enslaving
-				 * is closed.
-				 */
-				if (!oldcurrent) {
-					slave_info(bond->dev, slave->dev, "link status definitely up\n");
-					do_failover = 1;
-				} else {
-					slave_info(bond->dev, slave->dev, "interface is now up\n");
-				}
-			}
-		} else {
-			/* slave->link == BOND_LINK_UP */
-
-			/* not all switches will respond to an arp request
-			 * when the source ip is 0, so don't take the link down
-			 * if we don't know our ip yet
-			 */
-			if (!bond_time_in_interval(bond, trans_start, 2) ||
-			    !bond_time_in_interval(bond, slave->last_rx, 2)) {
-
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_state_changed = 1;
-
-				if (slave->link_failure_count < UINT_MAX)
-					slave->link_failure_count++;
-
-				slave_info(bond->dev, slave->dev, "interface is now down\n");
-
-				if (slave == oldcurrent)
-					do_failover = 1;
-			}
-		}
-
-		/* note: if switch is in round-robin mode, all links
-		 * must tx arp to ensure all links rx an arp - otherwise
-		 * links may oscillate or not come up at all; if switch is
-		 * in something like xor mode, there is nothing we can
-		 * do - all replies will be rx'ed on same link causing slaves
-		 * to be unstable during low/no traffic periods
-		 */
-		if (bond_slave_is_up(slave))
-			bond_arp_send_all(bond, slave);
-	}
-
-	rcu_read_unlock();
-
-	if (do_failover || slave_state_changed) {
-		if (!rtnl_trylock())
-			goto re_arm;
-
-		bond_for_each_slave(bond, slave, iter) {
-			if (slave->link_new_state != BOND_LINK_NOCHANGE)
-				slave->link = slave->link_new_state;
-		}
-
-		if (slave_state_changed) {
-			bond_slave_state_change(bond);
-			if (BOND_MODE(bond) == BOND_MODE_XOR)
-				bond_update_slave_arr(bond, NULL);
-		}
-		if (do_failover) {
-			block_netpoll_tx();
-			bond_select_active_slave(bond);
-			unblock_netpoll_tx();
-		}
-		rtnl_unlock();
-	}
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work,
-				   msecs_to_jiffies(bond->params.arp_interval));
-}
-
-/* Called to inspect slaves for active-backup mode ARP monitor link state
- * changes.  Sets proposed link state in slaves to specify what action
- * should take place for the slave.  Returns 0 if no changes are found, >0
- * if changes to link states must be committed.
- *
- * Called with rcu_read_lock held.
- */
-static int bond_ab_arp_inspect(struct bonding *bond)
-{
-	unsigned long trans_start, last_rx;
-	struct list_head *iter;
-	struct slave *slave;
-	int commit = 0;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-		last_rx = slave_last_rx(bond, slave);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, last_rx, 1)) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-			}
-			continue;
-		}
-
-		/* Give slaves 2*delta after being enslaved or made
-		 * active.  This avoids bouncing, as the last receive
-		 * times need a full ARP monitor cycle to be updated.
-		 */
-		if (bond_time_in_interval(bond, slave->last_link_up, 2))
-			continue;
-
-		/* Backup slave is down if:
-		 * - No current_arp_slave AND
-		 * - more than 3*delta since last receive AND
-		 * - the bond has an IP address
-		 *
-		 * Note: a non-null current_arp_slave indicates
-		 * the curr_active_slave went down and we are
-		 * searching for a new one; under this condition
-		 * we only take the curr_active_slave down - this
-		 * gives each slave a chance to tx/rx traffic
-		 * before being taken out
-		 */
-		if (!bond_is_active_slave(slave) &&
-		    !rcu_access_pointer(bond->current_arp_slave) &&
-		    !bond_time_in_interval(bond, last_rx, 3)) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-
-		/* Active slave is down if:
-		 * - more than 2*delta since transmitting OR
-		 * - (more than 2*delta since receive AND
-		 *    the bond has an IP address)
-		 */
-		trans_start = dev_trans_start(slave->dev);
-		if (bond_is_active_slave(slave) &&
-		    (!bond_time_in_interval(bond, trans_start, 2) ||
-		     !bond_time_in_interval(bond, last_rx, 2))) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-	}
-
-	return commit;
-}
-
-/* Called to commit link state changes noted by inspection step of
- * active-backup mode ARP monitor.
- *
- * Called with RTNL hold.
- */
-static void bond_ab_arp_commit(struct bonding *bond)
-{
-	unsigned long trans_start;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			continue;
-
-		case BOND_LINK_UP:
-			trans_start = dev_trans_start(slave->dev);
-			if (rtnl_dereference(bond->curr_active_slave) != slave ||
-			    (!rtnl_dereference(bond->curr_active_slave) &&
-			     bond_time_in_interval(bond, trans_start, 1))) {
-				struct slave *current_arp_slave;
-
-				current_arp_slave = rtnl_dereference(bond->current_arp_slave);
-				bond_set_slave_link_state(slave, BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-				if (current_arp_slave) {
-					bond_set_slave_inactive_flags(
-						current_arp_slave,
-						BOND_SLAVE_NOTIFY_NOW);
-					RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				}
-
-				slave_info(bond->dev, slave->dev, "link status definitely up\n");
-
-				if (!rtnl_dereference(bond->curr_active_slave) ||
-				    slave == rtnl_dereference(bond->primary_slave))
-					goto do_failover;
-
-			}
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			if (slave == rtnl_dereference(bond->curr_active_slave)) {
-				RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				goto do_failover;
-			}
-
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev,
-				  "impossible: link_new_state %d on slave\n",
-				  slave->link_new_state);
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* Send ARP probes for active-backup mode ARP monitor.
- *
- * Called with rcu_read_lock held.
- */
-static bool bond_ab_arp_probe(struct bonding *bond)
-{
-	struct slave *slave, *before = NULL, *new_slave = NULL,
-		     *curr_arp_slave = rcu_dereference(bond->current_arp_slave),
-		     *curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	struct list_head *iter;
-	bool found = false;
-	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
-
-	if (curr_arp_slave && curr_active_slave)
-		netdev_info(bond->dev, "PROBE: c_arp %s && cas %s BAD\n",
-			    curr_arp_slave->dev->name,
-			    curr_active_slave->dev->name);
-
-	if (curr_active_slave) {
-		bond_arp_send_all(bond, curr_active_slave);
-		return should_notify_rtnl;
-	}
-
-	/* if we don't have a curr_active_slave, search for the next available
-	 * backup slave from the current_arp_slave and make it the candidate
-	 * for becoming the curr_active_slave
-	 */
-
-	if (!curr_arp_slave) {
-		curr_arp_slave = bond_first_slave_rcu(bond);
-		if (!curr_arp_slave)
-			return should_notify_rtnl;
-	}
-
-	bond_set_slave_inactive_flags(curr_arp_slave, BOND_SLAVE_NOTIFY_LATER);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!found && !before && bond_slave_is_up(slave))
-			before = slave;
-
-		if (found && !new_slave && bond_slave_is_up(slave))
-			new_slave = slave;
-		/* if the link state is up at this point, we
-		 * mark it down - this can happen if we have
-		 * simultaneous link failures and
-		 * reselect_active_interface doesn't make this
-		 * one the current slave so it is still marked
-		 * up when it is actually down
-		 */
-		if (!bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_LATER);
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_LATER);
-
-			slave_info(bond->dev, slave->dev, "backup interface is now down\n");
-		}
-		if (slave == curr_arp_slave)
-			found = true;
-	}
-
-	if (!new_slave && before)
-		new_slave = before;
-
-	if (!new_slave)
-		goto check_state;
-
-	bond_set_slave_link_state(new_slave, BOND_LINK_BACK,
-				  BOND_SLAVE_NOTIFY_LATER);
-	bond_set_slave_active_flags(new_slave, BOND_SLAVE_NOTIFY_LATER);
-	bond_arp_send_all(bond, new_slave);
-	new_slave->last_link_up = jiffies;
-	rcu_assign_pointer(bond->current_arp_slave, new_slave);
-
-check_state:
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->should_notify || slave->should_notify_link) {
-			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
-			break;
-		}
-	}
-	return should_notify_rtnl;
-}
-
-static void bond_activebackup_arp_mon(struct bonding *bond)
-{
-	bool should_notify_peers = false;
-	bool should_notify_rtnl = false;
-	int delta_in_ticks;
-
-	delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	should_notify_peers = bond_should_notify_peers(bond);
-
-	if (bond_ab_arp_inspect(bond)) {
-		rcu_read_unlock();
-
-		/* Race avoidance with bond_close flush of workqueue */
-		if (!rtnl_trylock()) {
-			delta_in_ticks = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_ab_arp_commit(bond);
-
-		rtnl_unlock();
-		rcu_read_lock();
-	}
-
-	should_notify_rtnl = bond_ab_arp_probe(bond);
-	rcu_read_unlock();
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work, delta_in_ticks);
-
-	if (should_notify_peers || should_notify_rtnl) {
-		if (!rtnl_trylock())
-			return;
-
-		if (should_notify_peers)
-			call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-						 bond->dev);
-		if (should_notify_rtnl) {
-			bond_slave_state_notify(bond);
-			bond_slave_link_notify(bond);
-		}
-
-		rtnl_unlock();
-	}
-}
-
-static void bond_arp_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    arp_work.work);
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		bond_activebackup_arp_mon(bond);
-	else
-		bond_loadbalance_arp_mon(bond);
-}
-
-/*-------------------------- netdev event handling --------------------------*/
-
-/* Change device name */
-static int bond_event_changename(struct bonding *bond)
-{
-	bond_remove_proc_entry(bond);
-	bond_create_proc_entry(bond);
-
-	bond_debug_reregister(bond);
-
-	return NOTIFY_DONE;
-}
-
-static int bond_master_netdev_event(unsigned long event,
-				    struct net_device *bond_dev)
-{
-	struct bonding *event_bond = netdev_priv(bond_dev);
-
-	netdev_dbg(bond_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_CHANGENAME:
-		return bond_event_changename(event_bond);
-	case NETDEV_UNREGISTER:
-		bond_remove_proc_entry(event_bond);
-		break;
-	case NETDEV_REGISTER:
-		bond_create_proc_entry(event_bond);
-		break;
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-static int bond_slave_netdev_event(unsigned long event,
-				   struct net_device *slave_dev)
-{
-	struct slave *slave = bond_slave_get_rtnl(slave_dev), *primary;
-	struct bonding *bond;
-	struct net_device *bond_dev;
-
-	/* A netdev event can be generated while enslaving a device
-	 * before netdev_rx_handler_register is called in which case
-	 * slave will be NULL
-	 */
-	if (!slave) {
-		netdev_dbg(slave_dev, "%s called on NULL slave\n", __func__);
-		return NOTIFY_DONE;
-	}
-
-	bond_dev = slave->bond->dev;
-	bond = slave->bond;
-	primary = rtnl_dereference(bond->primary_slave);
-
-	slave_dbg(bond_dev, slave_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_UNREGISTER:
-		if (bond_dev->type != ARPHRD_ETHER)
-			bond_release_and_destroy(bond_dev, slave_dev);
-		else
-			__bond_release_one(bond_dev, slave_dev, false, true);
-		break;
-	case NETDEV_UP:
-	case NETDEV_CHANGE:
-		/* For 802.3ad mode only:
-		 * Getting invalid Speed/Duplex values here will put slave
-		 * in weird state. Mark it as link-fail if the link was
-		 * previously up or link-down if it hasn't yet come up, and
-		 * let link-monitoring (miimon) set it right when correct
-		 * speeds/duplex are available.
-		 */
-		if (bond_update_speed_duplex(slave) &&
-		    BOND_MODE(bond) == BOND_MODE_8023AD) {
-			if (slave->last_link_up)
-				slave->link = BOND_LINK_FAIL;
-			else
-				slave->link = BOND_LINK_DOWN;
-		}
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD)
-			bond_3ad_adapter_speed_duplex_changed(slave);
-		/* Fallthrough */
-	case NETDEV_DOWN:
-		/* Refresh slave-array if applicable!
-		 * If the setup does not use miimon or arpmon (mode-specific!),
-		 * then these events will not cause the slave-array to be
-		 * refreshed. This will cause xmit to use a slave that is not
-		 * usable. Avoid such situation by refeshing the array at these
-		 * events. If these (miimon/arpmon) parameters are configured
-		 * then array gets refreshed twice and that should be fine!
-		 */
-		if (bond_mode_can_use_xmit_hash(bond))
-			bond_update_slave_arr(bond, NULL);
-		break;
-	case NETDEV_CHANGEMTU:
-		/* TODO: Should slaves be allowed to
-		 * independently alter their MTU?  For
-		 * an active-backup bond, slaves need
-		 * not be the same type of device, so
-		 * MTUs may vary.  For other modes,
-		 * slaves arguably should have the
-		 * same MTUs. To do this, we'd need to
-		 * take over the slave's change_mtu
-		 * function for the duration of their
-		 * servitude.
-		 */
-		break;
-	case NETDEV_CHANGENAME:
-		/* we don't care if we don't have primary set */
-		if (!bond_uses_primary(bond) ||
-		    !bond->params.primary[0])
-			break;
-
-		if (slave == primary) {
-			/* slave's name changed - he's no longer primary */
-			RCU_INIT_POINTER(bond->primary_slave, NULL);
-		} else if (!strcmp(slave_dev->name, bond->params.primary)) {
-			/* we have a new primary slave */
-			rcu_assign_pointer(bond->primary_slave, slave);
-		} else { /* we didn't change primary - exit */
-			break;
-		}
-
-		netdev_info(bond->dev, "Primary slave changed to %s, reselecting active slave\n",
-			    primary ? slave_dev->name : "none");
-
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-		break;
-	case NETDEV_FEAT_CHANGE:
-		bond_compute_features(bond);
-		break;
-	case NETDEV_RESEND_IGMP:
-		/* Propagate to master device */
-		call_netdevice_notifiers(event, slave->bond->dev);
-		break;
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-/* bond_netdev_event: handle netdev notifier chain events.
- *
- * This function receives events for the netdev chain.  The caller (an
- * ioctl handler calling blocking_notifier_call_chain) holds the necessary
- * locks for us to safely manipulate the slave devices (RTNL lock,
- * dev_probe_lock).
- */
-static int bond_netdev_event(struct notifier_block *this,
-			     unsigned long event, void *ptr)
-{
-	struct net_device *event_dev = netdev_notifier_info_to_dev(ptr);
-
-	netdev_dbg(event_dev, "%s received %s\n",
-		   __func__, netdev_cmd_to_name(event));
-
-	if (!(event_dev->priv_flags & IFF_BONDING))
-		return NOTIFY_DONE;
-
-	if (event_dev->flags & IFF_MASTER) {
-		int ret;
-
-		ret = bond_master_netdev_event(event, event_dev);
-		if (ret != NOTIFY_DONE)
-			return ret;
-	}
-
-	if (event_dev->flags & IFF_SLAVE)
-		return bond_slave_netdev_event(event, event_dev);
-
-	return NOTIFY_DONE;
-}
-
-static struct notifier_block bond_netdev_notifier = {
-	.notifier_call = bond_netdev_event,
-};
-
-/*---------------------------- Hashing Policies -----------------------------*/
-
-/* L2 hash helper */
-static inline u32 bond_eth_hash(struct sk_buff *skb)
-{
-	struct ethhdr *ep, hdr_tmp;
-
-	ep = skb_header_pointer(skb, 0, sizeof(hdr_tmp), &hdr_tmp);
-	if (ep)
-		return ep->h_dest[5] ^ ep->h_source[5] ^ ep->h_proto;
-	return 0;
-}
-
-/* Extract the appropriate headers based on bond's xmit policy */
-static bool bond_flow_dissect(struct bonding *bond, struct sk_buff *skb,
-			      struct flow_keys *fk)
-{
-	const struct ipv6hdr *iph6;
-	const struct iphdr *iph;
-	int noff, proto = -1;
-
-	if (bond->params.xmit_policy > BOND_XMIT_POLICY_LAYER23)
-		return skb_flow_dissect_flow_keys(skb, fk, 0);
-
-	fk->ports.ports = 0;
-	noff = skb_network_offset(skb);
-	if (skb->protocol == htons(ETH_P_IP)) {
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
-			return false;
-		iph = ip_hdr(skb);
-		iph_to_flow_copy_v4addrs(fk, iph);
-		noff += iph->ihl << 2;
-		if (!ip_is_fragment(iph))
-			proto = iph->protocol;
-	} else if (skb->protocol == htons(ETH_P_IPV6)) {
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph6))))
-			return false;
-		iph6 = ipv6_hdr(skb);
-		iph_to_flow_copy_v6addrs(fk, iph6);
-		noff += sizeof(*iph6);
-		proto = iph6->nexthdr;
-	} else {
-		return false;
-	}
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER34 && proto >= 0)
-		fk->ports.ports = skb_flow_get_ports(skb, noff, proto);
-
-	return true;
-}
-
-/**
- * bond_xmit_hash - generate a hash value based on the xmit policy
- * @bond: bonding device
- * @skb: buffer to use for headers
- *
- * This function will extract the necessary headers from the skb buffer and use
- * them to generate a hash based on the xmit_policy set in the bonding device
- */
-u32 bond_xmit_hash(struct bonding *bond, struct sk_buff *skb)
-{
-	struct flow_keys flow;
-	u32 hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP34 &&
-	    skb->l4_hash)
-		return skb->hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER2 ||
-	    !bond_flow_dissect(bond, skb, &flow))
-		return bond_eth_hash(skb);
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER23 ||
-	    bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP23)
-		hash = bond_eth_hash(skb);
-	else
-		hash = (__force u32)flow.ports.ports;
-	hash ^= (__force u32)flow_get_u32_dst(&flow) ^
-		(__force u32)flow_get_u32_src(&flow);
-	hash ^= (hash >> 16);
-	hash ^= (hash >> 8);
-
-	return hash >> 1;
-}
-
-/*-------------------------- Device entry points ----------------------------*/
-
-void bond_work_init_all(struct bonding *bond)
-{
-	INIT_DELAYED_WORK(&bond->mcast_work,
-			  bond_resend_igmp_join_requests_delayed);
-	INIT_DELAYED_WORK(&bond->alb_work, bond_alb_monitor);
-	INIT_DELAYED_WORK(&bond->mii_work, bond_mii_monitor);
-	INIT_DELAYED_WORK(&bond->arp_work, bond_arp_monitor);
-	INIT_DELAYED_WORK(&bond->ad_work, bond_3ad_state_machine_handler);
-	INIT_DELAYED_WORK(&bond->slave_arr_work, bond_slave_arr_handler);
-}
-
-static void bond_work_cancel_all(struct bonding *bond)
-{
-	cancel_delayed_work_sync(&bond->mii_work);
-	cancel_delayed_work_sync(&bond->arp_work);
-	cancel_delayed_work_sync(&bond->alb_work);
-	cancel_delayed_work_sync(&bond->ad_work);
-	cancel_delayed_work_sync(&bond->mcast_work);
-	cancel_delayed_work_sync(&bond->slave_arr_work);
-}
-
-static int bond_open(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	/* reset slave->backup and slave->inactive */
-	if (bond_has_slaves(bond)) {
-		bond_for_each_slave(bond, slave, iter) {
-			if (bond_uses_primary(bond) &&
-			    slave != rcu_access_pointer(bond->curr_active_slave)) {
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-			} else if (BOND_MODE(bond) != BOND_MODE_8023AD) {
-				bond_set_slave_active_flags(slave,
-							    BOND_SLAVE_NOTIFY_NOW);
-			}
-		}
-	}
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_initialize must be called before the timer
-		 * is started.
-		 */
-		if (bond_alb_initialize(bond, (BOND_MODE(bond) == BOND_MODE_ALB)))
-			return -ENOMEM;
-		if (bond->params.tlb_dynamic_lb || BOND_MODE(bond) == BOND_MODE_ALB)
-			queue_delayed_work(bond->wq, &bond->alb_work, 0);
-	}
-
-	if (bond->params.miimon)  /* link check interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->mii_work, 0);
-
-	if (bond->params.arp_interval) {  /* arp interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->arp_work, 0);
-		bond->recv_probe = bond_arp_rcv;
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		queue_delayed_work(bond->wq, &bond->ad_work, 0);
-		/* register to receive LACPDUs */
-		bond->recv_probe = bond_3ad_lacpdu_recv;
-		bond_3ad_initiate_agg_selection(bond, 1);
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-	return 0;
-}
-
-static int bond_close(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	bond_work_cancel_all(bond);
-	bond->send_peer_notif = 0;
-	if (bond_is_lb(bond))
-		bond_alb_deinitialize(bond);
-	bond->recv_probe = NULL;
-
-	return 0;
-}
-
-/* fold stats, assuming all rtnl_link_stats64 fields are u64, but
- * that some drivers can provide 32bit values only.
- */
-static void bond_fold_stats(struct rtnl_link_stats64 *_res,
-			    const struct rtnl_link_stats64 *_new,
-			    const struct rtnl_link_stats64 *_old)
-{
-	const u64 *new = (const u64 *)_new;
-	const u64 *old = (const u64 *)_old;
-	u64 *res = (u64 *)_res;
-	int i;
-
-	for (i = 0; i < sizeof(*_res) / sizeof(u64); i++) {
-		u64 nv = new[i];
-		u64 ov = old[i];
-		s64 delta = nv - ov;
-
-		/* detects if this particular field is 32bit only */
-		if (((nv | ov) >> 32) == 0)
-			delta = (s64)(s32)((u32)nv - (u32)ov);
-
-		/* filter anomalies, some drivers reset their stats
-		 * at down/up events.
-		 */
-		if (delta > 0)
-			res[i] += delta;
-	}
-}
-
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct rtnl_link_stats64 temp;
-	struct list_head *iter;
-	struct slave *slave;
-
-	spin_lock(&bond->stats_lock);
-	memcpy(stats, &bond->bond_stats, sizeof(*stats));
-
-	rcu_read_lock();
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		const struct rtnl_link_stats64 *new =
-			dev_get_stats(slave->dev, &temp);
-
-		bond_fold_stats(stats, new, &slave->slave_stats);
-
-		/* save off the slave stats for the next run */
-		memcpy(&slave->slave_stats, new, sizeof(*new));
-	}
-	rcu_read_unlock();
-
-	memcpy(&bond->bond_stats, stats, sizeof(*stats));
-	spin_unlock(&bond->stats_lock);
-}
-
-static int bond_do_ioctl(struct net_device *bond_dev, struct ifreq *ifr, int cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct ifbond k_binfo;
-	struct ifbond __user *u_binfo = NULL;
-	struct ifslave k_sinfo;
-	struct ifslave __user *u_sinfo = NULL;
-	struct mii_ioctl_data *mii = NULL;
-	struct bond_opt_value newval;
-	struct net *net;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond_ioctl: cmd=%d\n", cmd);
-
-	switch (cmd) {
-	case SIOCGMIIPHY:
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		mii->phy_id = 0;
-		/* Fall Through */
-	case SIOCGMIIREG:
-		/* We do this again just in case we were called by SIOCGMIIREG
-		 * instead of SIOCGMIIPHY.
-		 */
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		if (mii->reg_num == 1) {
-			mii->val_out = 0;
-			if (netif_carrier_ok(bond->dev))
-				mii->val_out = BMSR_LSTATUS;
-		}
-
-		return 0;
-	case BOND_INFO_QUERY_OLD:
-	case SIOCBONDINFOQUERY:
-		u_binfo = (struct ifbond __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_binfo, u_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		bond_info_query(bond_dev, &k_binfo);
-		if (copy_to_user(u_binfo, &k_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		return 0;
-	case BOND_SLAVE_INFO_QUERY_OLD:
-	case SIOCBONDSLAVEINFOQUERY:
-		u_sinfo = (struct ifslave __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_sinfo, u_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		res = bond_slave_info_query(bond_dev, &k_sinfo);
-		if (res == 0 &&
-		    copy_to_user(u_sinfo, &k_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		return res;
-	default:
-		break;
-	}
-
-	net = dev_net(bond_dev);
-
-	if (!ns_capable(net->user_ns, CAP_NET_ADMIN))
-		return -EPERM;
-
-	slave_dev = __dev_get_by_name(net, ifr->ifr_slave);
-
-	slave_dbg(bond_dev, slave_dev, "slave_dev=%p:\n", slave_dev);
-
-	if (!slave_dev)
-		return -ENODEV;
-
-	switch (cmd) {
-	case BOND_ENSLAVE_OLD:
-	case SIOCBONDENSLAVE:
-		res = bond_enslave(bond_dev, slave_dev, NULL);
-		break;
-	case BOND_RELEASE_OLD:
-	case SIOCBONDRELEASE:
-		res = bond_release(bond_dev, slave_dev);
-		break;
-	case BOND_SETHWADDR_OLD:
-	case SIOCBONDSETHWADDR:
-		res = bond_set_dev_addr(bond_dev, slave_dev);
-		break;
-	case BOND_CHANGE_ACTIVE_OLD:
-	case SIOCBONDCHANGEACTIVE:
-		bond_opt_initstr(&newval, slave_dev->name);
-		res = __bond_opt_set_notify(bond, BOND_OPT_ACTIVE_SLAVE,
-					    &newval);
-		break;
-	default:
-		res = -EOPNOTSUPP;
-	}
-
-	return res;
-}
-
-static void bond_change_rx_flags(struct net_device *bond_dev, int change)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	if (change & IFF_PROMISC)
-		bond_set_promiscuity(bond,
-				     bond_dev->flags & IFF_PROMISC ? 1 : -1);
-
-	if (change & IFF_ALLMULTI)
-		bond_set_allmulti(bond,
-				  bond_dev->flags & IFF_ALLMULTI ? 1 : -1);
-}
-
-static void bond_set_rx_mode(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	rcu_read_lock();
-	if (bond_uses_primary(bond)) {
-		slave = rcu_dereference(bond->curr_active_slave);
-		if (slave) {
-			dev_uc_sync(slave->dev, bond_dev);
-			dev_mc_sync(slave->dev, bond_dev);
-		}
-	} else {
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			dev_uc_sync_multiple(slave->dev, bond_dev);
-			dev_mc_sync_multiple(slave->dev, bond_dev);
-		}
-	}
-	rcu_read_unlock();
-}
-
-static int bond_neigh_init(struct neighbour *n)
-{
-	struct bonding *bond = netdev_priv(n->dev);
-	const struct net_device_ops *slave_ops;
-	struct neigh_parms parms;
-	struct slave *slave;
-	int ret = 0;
-
-	rcu_read_lock();
-	slave = bond_first_slave_rcu(bond);
-	if (!slave)
-		goto out;
-	slave_ops = slave->dev->netdev_ops;
-	if (!slave_ops->ndo_neigh_setup)
-		goto out;
-
-	/* TODO: find another way [1] to implement this.
-	 * Passing a zeroed structure is fragile,
-	 * but at least we do not pass garbage.
-	 *
-	 * [1] One way would be that ndo_neigh_setup() never touch
-	 *     struct neigh_parms, but propagate the new neigh_setup()
-	 *     back to ___neigh_create() / neigh_parms_alloc()
-	 */
-	memset(&parms, 0, sizeof(parms));
-	ret = slave_ops->ndo_neigh_setup(slave->dev, &parms);
-
-	if (ret)
-		goto out;
-
-	if (parms.neigh_setup)
-		ret = parms.neigh_setup(n);
-out:
-	rcu_read_unlock();
-	return ret;
-}
-
-/* The bonding ndo_neigh_setup is called at init time beofre any
- * slave exists. So we must declare proxy setup function which will
- * be used at run time to resolve the actual slave neigh param setup.
- *
- * It's also called by master devices (such as vlans) to setup their
- * underlying devices. In that case - do nothing, we're already set up from
- * our init.
- */
-static int bond_neigh_setup(struct net_device *dev,
-			    struct neigh_parms *parms)
-{
-	/* modify only our neigh_parms */
-	if (parms->dev == dev)
-		parms->neigh_setup = bond_neigh_init;
-
-	return 0;
-}
-
-/* Change the MTU of all of a master's slaves to match the master */
-static int bond_change_mtu(struct net_device *bond_dev, int new_mtu)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond=%p, new_mtu=%d\n", bond, new_mtu);
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "s %p c_m %p\n",
-			   slave, slave->dev->netdev_ops->ndo_change_mtu);
-
-		res = dev_set_mtu(slave->dev, new_mtu);
-
-		if (res) {
-			/* If we failed to set the slave's mtu to the new value
-			 * we must abort the operation even in ACTIVE_BACKUP
-			 * mode, because if we allow the backup slaves to have
-			 * different mtu values than the active slave we'll
-			 * need to change their mtu when doing a failover. That
-			 * means changing their mtu from timer context, which
-			 * is probably not a good idea.
-			 */
-			slave_dbg(bond_dev, slave->dev, "err %d setting mtu to %d\n",
-				  res, new_mtu);
-			goto unwind;
-		}
-	}
-
-	bond_dev->mtu = new_mtu;
-
-	return 0;
-
-unwind:
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mtu(rollback_slave->dev, bond_dev->mtu);
-		if (tmp_res)
-			slave_dbg(bond_dev, rollback_slave->dev, "unwind err %d\n",
-				  tmp_res);
-	}
-
-	return res;
-}
-
-/* Change HW address
- *
- * Note that many devices must be down to change the HW address, and
- * downing the master releases all slaves.  We can make bonds full of
- * bonding devices to test this, however.
- */
-static int bond_set_mac_address(struct net_device *bond_dev, void *addr)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct sockaddr_storage *ss = addr, tmp_ss;
-	struct list_head *iter;
-	int res = 0;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB)
-		return bond_alb_set_mac_address(bond_dev, addr);
-
-
-	netdev_dbg(bond_dev, "%s: bond=%p\n", __func__, bond);
-
-	/* If fail_over_mac is enabled, do nothing and return success.
-	 * Returning an error causes ifenslave to fail.
-	 */
-	if (bond->params.fail_over_mac &&
-	    BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		return 0;
-
-	if (!is_valid_ether_addr(ss->__data))
-		return -EADDRNOTAVAIL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "%s: slave=%p\n",
-			  __func__, slave);
-		res = dev_set_mac_address(slave->dev, addr, NULL);
-		if (res) {
-			/* TODO: consider downing the slave
-			 * and retry ?
-			 * User should expect communications
-			 * breakage anyway until ARP finish
-			 * updating, so...
-			 */
-			slave_dbg(bond_dev, slave->dev, "%s: err %d\n",
-				  __func__, res);
-			goto unwind;
-		}
-	}
-
-	/* success */
-	memcpy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
-	return 0;
-
-unwind:
-	memcpy(tmp_ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-	tmp_ss.ss_family = bond_dev->type;
-
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mac_address(rollback_slave->dev,
-					      (struct sockaddr *)&tmp_ss, NULL);
-		if (tmp_res) {
-			slave_dbg(bond_dev, rollback_slave->dev, "%s: unwind err %d\n",
-				   __func__, tmp_res);
-		}
-	}
-
-	return res;
-}
-
-/**
- * bond_xmit_slave_id - transmit skb through slave with slave_id
- * @bond: bonding device that is transmitting
- * @skb: buffer to transmit
- * @slave_id: slave id up to slave_cnt-1 through which to transmit
- *
- * This function tries to transmit through slave with slave_id but in case
- * it fails, it tries to find the first available slave for transmission.
- * The skb is consumed in all cases, thus the function is void.
- */
-static void bond_xmit_slave_id(struct bonding *bond, struct sk_buff *skb, int slave_id)
-{
-	struct list_head *iter;
-	struct slave *slave;
-	int i = slave_id;
-
-	/* Here we start from the slave with slave_id */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0) {
-			if (bond_slave_can_tx(slave)) {
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-				return;
-			}
-		}
-	}
-
-	/* Here we start from the first slave up to slave_id */
-	i = slave_id;
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0)
-			break;
-		if (bond_slave_can_tx(slave)) {
-			bond_dev_queue_xmit(bond, skb, slave->dev);
-			return;
-		}
-	}
-	/* no slave that can tx has been found */
-	bond_tx_drop(bond->dev, skb);
-}
-
-/**
- * bond_rr_gen_slave_id - generate slave id based on packets_per_slave
- * @bond: bonding device to use
- *
- * Based on the value of the bonding device's packets_per_slave parameter
- * this function generates a slave id, which is usually used as the next
- * slave to transmit through.
- */
-static u32 bond_rr_gen_slave_id(struct bonding *bond)
-{
-	u32 slave_id;
-	struct reciprocal_value reciprocal_packets_per_slave;
-	int packets_per_slave = bond->params.packets_per_slave;
-
-	switch (packets_per_slave) {
-	case 0:
-		slave_id = prandom_u32();
-		break;
-	case 1:
-		slave_id = bond->rr_tx_counter;
-		break;
-	default:
-		reciprocal_packets_per_slave =
-			bond->params.reciprocal_packets_per_slave;
-		slave_id = reciprocal_divide(bond->rr_tx_counter,
-					     reciprocal_packets_per_slave);
-		break;
-	}
-	bond->rr_tx_counter++;
-
-	return slave_id;
-}
-
-static netdev_tx_t bond_xmit_roundrobin(struct sk_buff *skb,
-					struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-	int slave_cnt;
-	u32 slave_id;
-
-	/* Start with the curr_active_slave that joined the bond as the
-	 * default for sending IGMP traffic.  For failover purposes one
-	 * needs to maintain some consistency for the interface that will
-	 * send the join/membership reports.  The curr_active_slave found
-	 * will send all of this type of traffic.
-	 */
-	if (skb->protocol == htons(ETH_P_IP)) {
-		int noff = skb_network_offset(skb);
-		struct iphdr *iph;
-
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
-			goto non_igmp;
-
-		iph = ip_hdr(skb);
-		if (iph->protocol == IPPROTO_IGMP) {
-			slave = rcu_dereference(bond->curr_active_slave);
-			if (slave)
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-			else
-				bond_xmit_slave_id(bond, skb, 0);
-			return NETDEV_TX_OK;
-		}
-	}
-
-non_igmp:
-	slave_cnt = READ_ONCE(bond->slave_cnt);
-	if (likely(slave_cnt)) {
-		slave_id = bond_rr_gen_slave_id(bond);
-		bond_xmit_slave_id(bond, skb, slave_id % slave_cnt);
-	} else {
-		bond_tx_drop(bond_dev, skb);
-	}
-	return NETDEV_TX_OK;
-}
-
-/* In active-backup mode, we know that bond->curr_active_slave is always valid if
- * the bond has a usable interface.
- */
-static netdev_tx_t bond_xmit_activebackup(struct sk_buff *skb,
-					  struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-
-	slave = rcu_dereference(bond->curr_active_slave);
-	if (slave)
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	else
-		bond_tx_drop(bond_dev, skb);
-
-	return NETDEV_TX_OK;
-}
-
-/* Use this to update slave_array when (a) it's not appropriate to update
- * slave_array right away (note that update_slave_array() may sleep)
- * and / or (b) RTNL is not held.
- */
-void bond_slave_arr_work_rearm(struct bonding *bond, unsigned long delay)
-{
-	queue_delayed_work(bond->wq, &bond->slave_arr_work, delay);
-}
-
-/* Slave array work handler. Holds only RTNL */
-static void bond_slave_arr_handler(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    slave_arr_work.work);
-	int ret;
-
-	if (!rtnl_trylock())
-		goto err;
-
-	ret = bond_update_slave_arr(bond, NULL);
-	rtnl_unlock();
-	if (ret) {
-		pr_warn_ratelimited("Failed to update slave array from WT\n");
-		goto err;
-	}
-	return;
-
-err:
-	bond_slave_arr_work_rearm(bond, 1);
-}
-
-/* Build the usable slaves array in control path for modes that use xmit-hash
- * to determine the slave interface -
- * (a) BOND_MODE_8023AD
- * (b) BOND_MODE_XOR
- * (c) (BOND_MODE_TLB || BOND_MODE_ALB) && tlb_dynamic_lb == 0
- *
- * The caller is expected to hold RTNL only and NO other lock!
- */
-int bond_update_slave_arr(struct bonding *bond, struct slave *skipslave)
-{
-	struct slave *slave;
-	struct list_head *iter;
-	struct bond_up_slave *new_arr, *old_arr;
-	int agg_id = 0;
-	int ret = 0;
-
-#ifdef CONFIG_LOCKDEP
-	WARN_ON(lockdep_is_held(&bond->mode_lock));
-#endif
-
-	new_arr = kzalloc(offsetof(struct bond_up_slave, arr[bond->slave_cnt]),
-			  GFP_KERNEL);
-	if (!new_arr) {
-		ret = -ENOMEM;
-		pr_err("Failed to build slave-array.\n");
-		goto out;
-	}
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-
-		if (bond_3ad_get_active_agg_info(bond, &ad_info)) {
-			pr_debug("bond_3ad_get_active_agg_info failed\n");
-			kfree_rcu(new_arr, rcu);
-			/* No active aggragator means it's not safe to use
-			 * the previous array.
-			 */
-			old_arr = rtnl_dereference(bond->slave_arr);
-			if (old_arr) {
-				RCU_INIT_POINTER(bond->slave_arr, NULL);
-				kfree_rcu(old_arr, rcu);
-			}
-			goto out;
-		}
-		agg_id = ad_info.aggregator_id;
-	}
-	bond_for_each_slave(bond, slave, iter) {
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg;
-
-			agg = SLAVE_AD_INFO(slave)->port.aggregator;
-			if (!agg || agg->aggregator_identifier != agg_id)
-				continue;
-		}
-		if (!bond_slave_can_tx(slave))
-			continue;
-		if (skipslave == slave)
-			continue;
-
-		slave_dbg(bond->dev, slave->dev, "Adding slave to tx hash array[%d]\n",
-			  new_arr->count);
-
-		new_arr->arr[new_arr->count++] = slave;
-	}
-
-	old_arr = rtnl_dereference(bond->slave_arr);
-	rcu_assign_pointer(bond->slave_arr, new_arr);
-	if (old_arr)
-		kfree_rcu(old_arr, rcu);
-out:
-	if (ret != 0 && skipslave) {
-		int idx;
-
-		/* Rare situation where caller has asked to skip a specific
-		 * slave but allocation failed (most likely!). BTW this is
-		 * only possible when the call is initiated from
-		 * __bond_release_one(). In this situation; overwrite the
-		 * skipslave entry in the array with the last entry from the
-		 * array to avoid a situation where the xmit path may choose
-		 * this to-be-skipped slave to send a packet out.
-		 */
-		old_arr = rtnl_dereference(bond->slave_arr);
-		for (idx = 0; old_arr != NULL && idx < old_arr->count; idx++) {
-			if (skipslave == old_arr->arr[idx]) {
-				old_arr->arr[idx] =
-				    old_arr->arr[old_arr->count-1];
-				old_arr->count--;
-				break;
-			}
-		}
-	}
-	return ret;
-}
-
-/* Use this Xmit function for 3AD as well as XOR modes. The current
- * usable slave array is formed in the control path. The xmit function
- * just calculates hash and sends the packet out.
- */
-static netdev_tx_t bond_3ad_xor_xmit(struct sk_buff *skb,
-				     struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct slave *slave;
-	struct bond_up_slave *slaves;
-	unsigned int count;
-
-	slaves = rcu_dereference(bond->slave_arr);
-	count = slaves ? READ_ONCE(slaves->count) : 0;
-	if (likely(count)) {
-		slave = slaves->arr[bond_xmit_hash(bond, skb) % count];
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	} else {
-		bond_tx_drop(dev, skb);
-	}
-
-	return NETDEV_TX_OK;
-}
-
-/* in broadcast mode, we send everything to all usable interfaces. */
-static netdev_tx_t bond_xmit_broadcast(struct sk_buff *skb,
-				       struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (bond_is_last_slave(bond, slave))
-			break;
-		if (bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
-
-			if (!skb2) {
-				net_err_ratelimited("%s: Error: %s: skb_clone() failed\n",
-						    bond_dev->name, __func__);
-				continue;
-			}
-			bond_dev_queue_xmit(bond, skb2, slave->dev);
-		}
-	}
-	if (slave && bond_slave_is_up(slave) && slave->link == BOND_LINK_UP)
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	else
-		bond_tx_drop(bond_dev, skb);
-
-	return NETDEV_TX_OK;
-}
-
-/*------------------------- Device initialization ---------------------------*/
-
-/* Lookup the slave that corresponds to a qid */
-static inline int bond_slave_override(struct bonding *bond,
-				      struct sk_buff *skb)
-{
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	if (!skb_rx_queue_recorded(skb))
-		return 1;
-
-	/* Find out if any slaves have the same mapping as this skb. */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->queue_id == skb_get_queue_mapping(skb)) {
-			if (bond_slave_is_up(slave) &&
-			    slave->link == BOND_LINK_UP) {
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-				return 0;
-			}
-			/* If the slave isn't UP, use default transmit policy. */
-			break;
-		}
-	}
-
-	return 1;
-}
-
-
-static u16 bond_select_queue(struct net_device *dev, struct sk_buff *skb,
-			     struct net_device *sb_dev)
-{
-	/* This helper function exists to help dev_pick_tx get the correct
-	 * destination queue.  Using a helper function skips a call to
-	 * skb_tx_hash and will put the skbs in the queue we expect on their
-	 * way down to the bonding driver.
-	 */
-	u16 txq = skb_rx_queue_recorded(skb) ? skb_get_rx_queue(skb) : 0;
-
-	/* Save the original txq to restore before passing to the driver */
-	qdisc_skb_cb(skb)->slave_dev_queue_mapping = skb_get_queue_mapping(skb);
-
-	if (unlikely(txq >= dev->real_num_tx_queues)) {
-		do {
-			txq -= dev->real_num_tx_queues;
-		} while (txq >= dev->real_num_tx_queues);
-	}
-	return txq;
-}
-
-static netdev_tx_t __bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-
-	if (bond_should_override_tx_queue(bond) &&
-	    !bond_slave_override(bond, skb))
-		return NETDEV_TX_OK;
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return bond_xmit_roundrobin(skb, dev);
-	case BOND_MODE_ACTIVEBACKUP:
-		return bond_xmit_activebackup(skb, dev);
-	case BOND_MODE_8023AD:
-	case BOND_MODE_XOR:
-		return bond_3ad_xor_xmit(skb, dev);
-	case BOND_MODE_BROADCAST:
-		return bond_xmit_broadcast(skb, dev);
-	case BOND_MODE_ALB:
-		return bond_alb_xmit(skb, dev);
-	case BOND_MODE_TLB:
-		return bond_tlb_xmit(skb, dev);
-	default:
-		/* Should never happen, mode already checked */
-		netdev_err(dev, "Unknown bonding mode %d\n", BOND_MODE(bond));
-		WARN_ON_ONCE(1);
-		bond_tx_drop(dev, skb);
-		return NETDEV_TX_OK;
-	}
-}
-
-static netdev_tx_t bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	netdev_tx_t ret = NETDEV_TX_OK;
-
-	/* If we risk deadlock from transmitting this in the
-	 * netpoll path, tell netpoll to queue the frame for later tx
-	 */
-	if (unlikely(is_netpoll_tx_blocked(dev)))
-		return NETDEV_TX_BUSY;
-
-	rcu_read_lock();
-	if (bond_has_slaves(bond))
-		ret = __bond_start_xmit(skb, dev);
-	else
-		bond_tx_drop(dev, skb);
-	rcu_read_unlock();
-
-	return ret;
-}
-
-static int bond_ethtool_get_link_ksettings(struct net_device *bond_dev,
-					   struct ethtool_link_ksettings *cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	unsigned long speed = 0;
-	struct list_head *iter;
-	struct slave *slave;
-
-	cmd->base.duplex = DUPLEX_UNKNOWN;
-	cmd->base.port = PORT_OTHER;
-
-	/* Since bond_slave_can_tx returns false for all inactive or down slaves, we
-	 * do not need to check mode.  Though link speed might not represent
-	 * the true receive or transmit bandwidth (not all modes are symmetric)
-	 * this is an accurate maximum.
-	 */
-	bond_for_each_slave(bond, slave, iter) {
-		if (bond_slave_can_tx(slave)) {
-			if (slave->speed != SPEED_UNKNOWN)
-				speed += slave->speed;
-			if (cmd->base.duplex == DUPLEX_UNKNOWN &&
-			    slave->duplex != DUPLEX_UNKNOWN)
-				cmd->base.duplex = slave->duplex;
-		}
-	}
-	cmd->base.speed = speed ? : SPEED_UNKNOWN;
-
-	return 0;
-}
-
-static void bond_ethtool_get_drvinfo(struct net_device *bond_dev,
-				     struct ethtool_drvinfo *drvinfo)
-{
-	strlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));
-	strlcpy(drvinfo->version, DRV_VERSION, sizeof(drvinfo->version));
-	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version), "%d",
-		 BOND_ABI_VERSION);
-}
-
-static const struct ethtool_ops bond_ethtool_ops = {
-	.get_drvinfo		= bond_ethtool_get_drvinfo,
-	.get_link		= ethtool_op_get_link,
-	.get_link_ksettings	= bond_ethtool_get_link_ksettings,
-};
-
-static const struct net_device_ops bond_netdev_ops = {
-	.ndo_init		= bond_init,
-	.ndo_uninit		= bond_uninit,
-	.ndo_open		= bond_open,
-	.ndo_stop		= bond_close,
-	.ndo_start_xmit		= bond_start_xmit,
-	.ndo_select_queue	= bond_select_queue,
-	.ndo_get_stats64	= bond_get_stats,
-	.ndo_do_ioctl		= bond_do_ioctl,
-	.ndo_change_rx_flags	= bond_change_rx_flags,
-	.ndo_set_rx_mode	= bond_set_rx_mode,
-	.ndo_change_mtu		= bond_change_mtu,
-	.ndo_set_mac_address	= bond_set_mac_address,
-	.ndo_neigh_setup	= bond_neigh_setup,
-	.ndo_vlan_rx_add_vid	= bond_vlan_rx_add_vid,
-	.ndo_vlan_rx_kill_vid	= bond_vlan_rx_kill_vid,
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	.ndo_netpoll_setup	= bond_netpoll_setup,
-	.ndo_netpoll_cleanup	= bond_netpoll_cleanup,
-	.ndo_poll_controller	= bond_poll_controller,
-#endif
-	.ndo_add_slave		= bond_enslave,
-	.ndo_del_slave		= bond_release,
-	.ndo_fix_features	= bond_fix_features,
-	.ndo_features_check	= passthru_features_check,
-};
-
-static const struct device_type bond_type = {
-	.name = "bond",
-};
-
-static void bond_destructor(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	if (bond->wq)
-		destroy_workqueue(bond->wq);
-}
-
-void bond_setup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	spin_lock_init(&bond->mode_lock);
-	bond->params = bonding_defaults;
-
-	/* Initialize pointers */
-	bond->dev = bond_dev;
-
-	/* Initialize the device entry points */
-	ether_setup(bond_dev);
-	bond_dev->max_mtu = ETH_MAX_MTU;
-	bond_dev->netdev_ops = &bond_netdev_ops;
-	bond_dev->ethtool_ops = &bond_ethtool_ops;
-
-	bond_dev->needs_free_netdev = true;
-	bond_dev->priv_destructor = bond_destructor;
-
-	SET_NETDEV_DEVTYPE(bond_dev, &bond_type);
-
-	/* Initialize the device options */
-	bond_dev->flags |= IFF_MASTER;
-	bond_dev->priv_flags |= IFF_BONDING | IFF_UNICAST_FLT | IFF_NO_QUEUE;
-	bond_dev->priv_flags &= ~(IFF_XMIT_DST_RELEASE | IFF_TX_SKB_SHARING);
-
-	/* don't acquire bond device's netif_tx_lock when transmitting */
-	bond_dev->features |= NETIF_F_LLTX;
-
-	/* By default, we declare the bond to be fully
-	 * VLAN hardware accelerated capable. Special
-	 * care is taken in the various xmit functions
-	 * when there are slaves that are not hw accel
-	 * capable
-	 */
-
-	/* Don't allow bond devices to change network namespaces. */
-	bond_dev->features |= NETIF_F_NETNS_LOCAL;
-
-	bond_dev->hw_features = BOND_VLAN_FEATURES |
-				NETIF_F_HW_VLAN_CTAG_RX |
-				NETIF_F_HW_VLAN_CTAG_FILTER;
-
-	bond_dev->hw_features |= NETIF_F_GSO_ENCAP_ALL | NETIF_F_GSO_UDP_L4;
-	bond_dev->features |= bond_dev->hw_features;
-	bond_dev->features |= NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_STAG_TX;
-}
-
-/* Destroy a bonding device.
- * Must be under rtnl_lock when this function is called.
- */
-static void bond_uninit(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-	struct bond_up_slave *arr;
-
-	bond_netpoll_cleanup(bond_dev);
-
-	/* Release the bonded slaves */
-	bond_for_each_slave(bond, slave, iter)
-		__bond_release_one(bond_dev, slave->dev, true, true);
-	netdev_info(bond_dev, "Released all slaves\n");
-
-	arr = rtnl_dereference(bond->slave_arr);
-	if (arr) {
-		RCU_INIT_POINTER(bond->slave_arr, NULL);
-		kfree_rcu(arr, rcu);
-	}
-
-	list_del(&bond->bond_list);
-
-	lockdep_unregister_key(&bond->stats_lock_key);
-	bond_debug_unregister(bond);
-}
-
-/*------------------------- Module initialization ---------------------------*/
-
-static int bond_check_params(struct bond_params *params)
-{
-	int arp_validate_value, fail_over_mac_value, primary_reselect_value, i;
-	struct bond_opt_value newval;
-	const struct bond_opt_value *valptr;
-	int arp_all_targets_value = 0;
-	u16 ad_actor_sys_prio = 0;
-	u16 ad_user_port_key = 0;
-	__be32 arp_target[BOND_MAX_ARP_TARGETS] = { 0 };
-	int arp_ip_count;
-	int bond_mode	= BOND_MODE_ROUNDROBIN;
-	int xmit_hashtype = BOND_XMIT_POLICY_LAYER2;
-	int lacp_fast = 0;
-	int tlb_dynamic_lb;
-
-	/* Convert string parameters. */
-	if (mode) {
-		bond_opt_initstr(&newval, mode);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_MODE), &newval);
-		if (!valptr) {
-			pr_err("Error: Invalid bonding mode \"%s\"\n", mode);
-			return -EINVAL;
-		}
-		bond_mode = valptr->value;
-	}
-
-	if (xmit_hash_policy) {
-		if (bond_mode == BOND_MODE_ROUNDROBIN ||
-		    bond_mode == BOND_MODE_ACTIVEBACKUP ||
-		    bond_mode == BOND_MODE_BROADCAST) {
-			pr_info("xmit_hash_policy param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, xmit_hash_policy);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_XMIT_HASH),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid xmit_hash_policy \"%s\"\n",
-				       xmit_hash_policy);
-				return -EINVAL;
-			}
-			xmit_hashtype = valptr->value;
-		}
-	}
-
-	if (lacp_rate) {
-		if (bond_mode != BOND_MODE_8023AD) {
-			pr_info("lacp_rate param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, lacp_rate);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_LACP_RATE),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid lacp rate \"%s\"\n",
-				       lacp_rate);
-				return -EINVAL;
-			}
-			lacp_fast = valptr->value;
-		}
-	}
-
-	if (ad_select) {
-		bond_opt_initstr(&newval, ad_select);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_SELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid ad_select \"%s\"\n", ad_select);
-			return -EINVAL;
-		}
-		params->ad_select = valptr->value;
-		if (bond_mode != BOND_MODE_8023AD)
-			pr_warn("ad_select param only affects 802.3ad mode\n");
-	} else {
-		params->ad_select = BOND_AD_STABLE;
-	}
-
-	if (max_bonds < 0) {
-		pr_warn("Warning: max_bonds (%d) not in range %d-%d, so it was reset to BOND_DEFAULT_MAX_BONDS (%d)\n",
-			max_bonds, 0, INT_MAX, BOND_DEFAULT_MAX_BONDS);
-		max_bonds = BOND_DEFAULT_MAX_BONDS;
-	}
-
-	if (miimon < 0) {
-		pr_warn("Warning: miimon module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			miimon, INT_MAX);
-		miimon = 0;
-	}
-
-	if (updelay < 0) {
-		pr_warn("Warning: updelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			updelay, INT_MAX);
-		updelay = 0;
-	}
-
-	if (downdelay < 0) {
-		pr_warn("Warning: downdelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			downdelay, INT_MAX);
-		downdelay = 0;
-	}
-
-	if ((use_carrier != 0) && (use_carrier != 1)) {
-		pr_warn("Warning: use_carrier module parameter (%d), not of valid value (0/1), so it was set to 1\n",
-			use_carrier);
-		use_carrier = 1;
-	}
-
-	if (num_peer_notif < 0 || num_peer_notif > 255) {
-		pr_warn("Warning: num_grat_arp/num_unsol_na (%d) not in range 0-255 so it was reset to 1\n",
-			num_peer_notif);
-		num_peer_notif = 1;
-	}
-
-	/* reset values for 802.3ad/TLB/ALB */
-	if (!bond_mode_uses_arp(bond_mode)) {
-		if (!miimon) {
-			pr_warn("Warning: miimon must be specified, otherwise bonding will not detect link failure, speed and duplex which are essential for 802.3ad operation\n");
-			pr_warn("Forcing miimon to 100msec\n");
-			miimon = BOND_DEFAULT_MIIMON;
-		}
-	}
-
-	if (tx_queues < 1 || tx_queues > 255) {
-		pr_warn("Warning: tx_queues (%d) should be between 1 and 255, resetting to %d\n",
-			tx_queues, BOND_DEFAULT_TX_QUEUES);
-		tx_queues = BOND_DEFAULT_TX_QUEUES;
-	}
-
-	if ((all_slaves_active != 0) && (all_slaves_active != 1)) {
-		pr_warn("Warning: all_slaves_active module parameter (%d), not of valid value (0/1), so it was set to 0\n",
-			all_slaves_active);
-		all_slaves_active = 0;
-	}
-
-	if (resend_igmp < 0 || resend_igmp > 255) {
-		pr_warn("Warning: resend_igmp (%d) should be between 0 and 255, resetting to %d\n",
-			resend_igmp, BOND_DEFAULT_RESEND_IGMP);
-		resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-	}
-
-	bond_opt_initval(&newval, packets_per_slave);
-	if (!bond_opt_parse(bond_opt_get(BOND_OPT_PACKETS_PER_SLAVE), &newval)) {
-		pr_warn("Warning: packets_per_slave (%d) should be between 0 and %u resetting to 1\n",
-			packets_per_slave, USHRT_MAX);
-		packets_per_slave = 1;
-	}
-
-	if (bond_mode == BOND_MODE_ALB) {
-		pr_notice("In ALB mode you might experience client disconnections upon reconnection of a link if the bonding module updelay parameter (%d msec) is incompatible with the forwarding delay time of the switch\n",
-			  updelay);
-	}
-
-	if (!miimon) {
-		if (updelay || downdelay) {
-			/* just warn the user the up/down delay will have
-			 * no effect since miimon is zero...
-			 */
-			pr_warn("Warning: miimon module parameter not set and updelay (%d) or downdelay (%d) module parameter is set; updelay and downdelay have no effect unless miimon is set\n",
-				updelay, downdelay);
-		}
-	} else {
-		/* don't allow arp monitoring */
-		if (arp_interval) {
-			pr_warn("Warning: miimon (%d) and arp_interval (%d) can't be used simultaneously, disabling ARP monitoring\n",
-				miimon, arp_interval);
-			arp_interval = 0;
-		}
-
-		if ((updelay % miimon) != 0) {
-			pr_warn("Warning: updelay (%d) is not a multiple of miimon (%d), updelay rounded to %d ms\n",
-				updelay, miimon, (updelay / miimon) * miimon);
-		}
-
-		updelay /= miimon;
-
-		if ((downdelay % miimon) != 0) {
-			pr_warn("Warning: downdelay (%d) is not a multiple of miimon (%d), downdelay rounded to %d ms\n",
-				downdelay, miimon,
-				(downdelay / miimon) * miimon);
-		}
-
-		downdelay /= miimon;
-	}
-
-	if (arp_interval < 0) {
-		pr_warn("Warning: arp_interval module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			arp_interval, INT_MAX);
-		arp_interval = 0;
-	}
-
-	for (arp_ip_count = 0, i = 0;
-	     (arp_ip_count < BOND_MAX_ARP_TARGETS) && arp_ip_target[i]; i++) {
-		__be32 ip;
-
-		/* not a complete check, but good enough to catch mistakes */
-		if (!in4_pton(arp_ip_target[i], -1, (u8 *)&ip, -1, NULL) ||
-		    !bond_is_ip_target_ok(ip)) {
-			pr_warn("Warning: bad arp_ip_target module parameter (%s), ARP monitoring will not be performed\n",
-				arp_ip_target[i]);
-			arp_interval = 0;
-		} else {
-			if (bond_get_targets_ip(arp_target, ip) == -1)
-				arp_target[arp_ip_count++] = ip;
-			else
-				pr_warn("Warning: duplicate address %pI4 in arp_ip_target, skipping\n",
-					&ip);
-		}
-	}
-
-	if (arp_interval && !arp_ip_count) {
-		/* don't allow arping if no arp_ip_target given... */
-		pr_warn("Warning: arp_interval module parameter (%d) specified without providing an arp_ip_target parameter, arp_interval was reset to 0\n",
-			arp_interval);
-		arp_interval = 0;
-	}
-
-	if (arp_validate) {
-		if (!arp_interval) {
-			pr_err("arp_validate requires arp_interval\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initstr(&newval, arp_validate);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_VALIDATE),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_validate \"%s\"\n",
-			       arp_validate);
-			return -EINVAL;
-		}
-		arp_validate_value = valptr->value;
-	} else {
-		arp_validate_value = 0;
-	}
-
-	if (arp_all_targets) {
-		bond_opt_initstr(&newval, arp_all_targets);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_ALL_TARGETS),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_all_targets_value \"%s\"\n",
-			       arp_all_targets);
-			arp_all_targets_value = 0;
-		} else {
-			arp_all_targets_value = valptr->value;
-		}
-	}
-
-	if (miimon) {
-		pr_info("MII link monitoring set to %d ms\n", miimon);
-	} else if (arp_interval) {
-		valptr = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
-					  arp_validate_value);
-		pr_info("ARP monitoring set to %d ms, validate %s, with %d target(s):",
-			arp_interval, valptr->string, arp_ip_count);
-
-		for (i = 0; i < arp_ip_count; i++)
-			pr_cont(" %s", arp_ip_target[i]);
-
-		pr_cont("\n");
-
-	} else if (max_bonds) {
-		/* miimon and arp_interval not set, we need one so things
-		 * work as expected, see bonding.txt for details
-		 */
-		pr_debug("Warning: either miimon or arp_interval and arp_ip_target module parameters must be specified, otherwise bonding will not detect link failures! see bonding.txt for details\n");
-	}
-
-	if (primary && !bond_mode_uses_primary(bond_mode)) {
-		/* currently, using a primary only makes sense
-		 * in active backup, TLB or ALB modes
-		 */
-		pr_warn("Warning: %s primary device specified but has no effect in %s mode\n",
-			primary, bond_mode_name(bond_mode));
-		primary = NULL;
-	}
-
-	if (primary && primary_reselect) {
-		bond_opt_initstr(&newval, primary_reselect);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_PRIMARY_RESELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid primary_reselect \"%s\"\n",
-			       primary_reselect);
-			return -EINVAL;
-		}
-		primary_reselect_value = valptr->value;
-	} else {
-		primary_reselect_value = BOND_PRI_RESELECT_ALWAYS;
-	}
-
-	if (fail_over_mac) {
-		bond_opt_initstr(&newval, fail_over_mac);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_FAIL_OVER_MAC),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid fail_over_mac \"%s\"\n",
-			       fail_over_mac);
-			return -EINVAL;
-		}
-		fail_over_mac_value = valptr->value;
-		if (bond_mode != BOND_MODE_ACTIVEBACKUP)
-			pr_warn("Warning: fail_over_mac only affects active-backup mode\n");
-	} else {
-		fail_over_mac_value = BOND_FOM_NONE;
-	}
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(
-			bond_opt_get(BOND_OPT_AD_ACTOR_SYS_PRIO),
-				     &newval);
-	if (!valptr) {
-		pr_err("Error: No ad_actor_sys_prio default value");
-		return -EINVAL;
-	}
-	ad_actor_sys_prio = valptr->value;
-
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_USER_PORT_KEY),
-				&newval);
-	if (!valptr) {
-		pr_err("Error: No ad_user_port_key default value");
-		return -EINVAL;
-	}
-	ad_user_port_key = valptr->value;
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_TLB_DYNAMIC_LB), &newval);
-	if (!valptr) {
-		pr_err("Error: No tlb_dynamic_lb default value");
-		return -EINVAL;
-	}
-	tlb_dynamic_lb = valptr->value;
-
-	if (lp_interval == 0) {
-		pr_warn("Warning: ip_interval must be between 1 and %d, so it was reset to %d\n",
-			INT_MAX, BOND_ALB_DEFAULT_LP_INTERVAL);
-		lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-	}
-
-	/* fill params struct with the proper values */
-	params->mode = bond_mode;
-	params->xmit_policy = xmit_hashtype;
-	params->miimon = miimon;
-	params->num_peer_notif = num_peer_notif;
-	params->arp_interval = arp_interval;
-	params->arp_validate = arp_validate_value;
-	params->arp_all_targets = arp_all_targets_value;
-	params->updelay = updelay;
-	params->downdelay = downdelay;
-	params->peer_notif_delay = 0;
-	params->use_carrier = use_carrier;
-	params->lacp_fast = lacp_fast;
-	params->primary[0] = 0;
-	params->primary_reselect = primary_reselect_value;
-	params->fail_over_mac = fail_over_mac_value;
-	params->tx_queues = tx_queues;
-	params->all_slaves_active = all_slaves_active;
-	params->resend_igmp = resend_igmp;
-	params->min_links = min_links;
-	params->lp_interval = lp_interval;
-	params->packets_per_slave = packets_per_slave;
-	params->tlb_dynamic_lb = tlb_dynamic_lb;
-	params->ad_actor_sys_prio = ad_actor_sys_prio;
-	eth_zero_addr(params->ad_actor_system);
-	params->ad_user_port_key = ad_user_port_key;
-	if (packets_per_slave > 0) {
-		params->reciprocal_packets_per_slave =
-			reciprocal_value(packets_per_slave);
-	} else {
-		/* reciprocal_packets_per_slave is unused if
-		 * packets_per_slave is 0 or 1, just initialize it
-		 */
-		params->reciprocal_packets_per_slave =
-			(struct reciprocal_value) { 0 };
-	}
-
-	if (primary) {
-		strncpy(params->primary, primary, IFNAMSIZ);
-		params->primary[IFNAMSIZ - 1] = 0;
-	}
-
-	memcpy(params->arp_targets, arp_target, sizeof(arp_target));
-
-	return 0;
-}
-
-/* Called from registration process */
-static int bond_init(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	netdev_dbg(bond_dev, "Begin bond_init\n");
-
-	bond->wq = alloc_ordered_workqueue(bond_dev->name, WQ_MEM_RECLAIM);
-	if (!bond->wq)
-		return -ENOMEM;
-
-	spin_lock_init(&bond->stats_lock);
-	lockdep_register_key(&bond->stats_lock_key);
-	lockdep_set_class(&bond->stats_lock, &bond->stats_lock_key);
-
-	list_add_tail(&bond->bond_list, &bn->dev_list);
-
-	bond_prepare_sysfs_group(bond);
-
-	bond_debug_register(bond);
-
-	/* Ensure valid dev_addr */
-	if (is_zero_ether_addr(bond_dev->dev_addr) &&
-	    bond_dev->addr_assign_type == NET_ADDR_PERM)
-		eth_hw_addr_random(bond_dev);
-
-	return 0;
-}
-
-unsigned int bond_get_num_tx_queues(void)
-{
-	return tx_queues;
-}
-
-/* Create a new bond based on the specified name and bonding parameters.
- * If name is NULL, obtain a suitable "bond%d" name for us.
- * Caller must NOT hold rtnl_lock; we need to release it here before we
- * set up our sysfs entries.
- */
-int bond_create(struct net *net, const char *name)
-{
-	struct net_device *bond_dev;
-	struct bonding *bond;
-	struct alb_bond_info *bond_info;
-	int res;
-
-	rtnl_lock();
-
-	bond_dev = alloc_netdev_mq(sizeof(struct bonding),
-				   name ? name : "bond%d", NET_NAME_UNKNOWN,
-				   bond_setup, tx_queues);
-	if (!bond_dev) {
-		pr_err("%s: eek! can't alloc netdev!\n", name);
-		rtnl_unlock();
-		return -ENOMEM;
-	}
-
-	/*
-	 * Initialize rx_hashtbl_used_head to RLB_NULL_INDEX.
-	 * It is set to 0 by default which is wrong.
-	 */
-	bond = netdev_priv(bond_dev);
-	bond_info = &(BOND_ALB_INFO(bond));
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	dev_net_set(bond_dev, net);
-	bond_dev->rtnl_link_ops = &bond_link_ops;
-
-	res = register_netdevice(bond_dev);
-
-	netif_carrier_off(bond_dev);
-
-	bond_work_init_all(bond);
-
-	rtnl_unlock();
-	if (res < 0)
-		free_netdev(bond_dev);
-	return res;
-}
-
-static int __net_init bond_net_init(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-
-	bn->net = net;
-	INIT_LIST_HEAD(&bn->dev_list);
-
-	bond_create_proc_dir(bn);
-	bond_create_sysfs(bn);
-
-	return 0;
-}
-
-static void __net_exit bond_net_exit(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-	struct bonding *bond, *tmp_bond;
-	LIST_HEAD(list);
-
-	bond_destroy_sysfs(bn);
-
-	/* Kill off any bonds created after unregistering bond rtnl ops */
-	rtnl_lock();
-	list_for_each_entry_safe(bond, tmp_bond, &bn->dev_list, bond_list)
-		unregister_netdevice_queue(bond->dev, &list);
-	unregister_netdevice_many(&list);
-	rtnl_unlock();
-
-	bond_destroy_proc_dir(bn);
-}
-
-static struct pernet_operations bond_net_ops = {
-	.init = bond_net_init,
-	.exit = bond_net_exit,
-	.id   = &bond_net_id,
-	.size = sizeof(struct bond_net),
-};
-
-static int __init bonding_init(void)
-{
-	int i;
-	int res;
-
-	pr_info("%s", bond_version);
-
-	res = bond_check_params(&bonding_defaults);
-	if (res)
-		goto out;
-
-	res = register_pernet_subsys(&bond_net_ops);
-	if (res)
-		goto out;
-
-	res = bond_netlink_init();
-	if (res)
-		goto err_link;
-
-	bond_create_debugfs();
-
-	for (i = 0; i < max_bonds; i++) {
-		res = bond_create(&init_net, NULL);
-		if (res)
-			goto err;
-	}
-
-	register_netdevice_notifier(&bond_netdev_notifier);
-out:
-	return res;
-err:
-	bond_destroy_debugfs();
-	bond_netlink_fini();
-err_link:
-	unregister_pernet_subsys(&bond_net_ops);
-	goto out;
-
-}
-
-static void __exit bonding_exit(void)
-{
-	unregister_netdevice_notifier(&bond_netdev_notifier);
-
-	bond_destroy_debugfs();
-
-	bond_netlink_fini();
-	unregister_pernet_subsys(&bond_net_ops);
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	/* Make sure we don't have an imbalance on our netpoll blocking */
-	WARN_ON(atomic_read(&netpoll_block_tx));
-#endif
-}
-
-module_init(bonding_init);
-module_exit(bonding_exit);
-MODULE_LICENSE("GPL");
-MODULE_VERSION(DRV_VERSION);
-MODULE_DESCRIPTION(DRV_DESCRIPTION ", v" DRV_VERSION);
-MODULE_AUTHOR("Thomas Davis, tadavis@lbl.gov and many others");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bond_main.c.rej
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bond_main.c.rej	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,23 +0,0 @@
---- dev/linux/bonding/4.19.0/bond_main.c	Mon Nov 19 08:34:09 2018 -0800
-+++ dev/linux/bonding/4.19.0/bond_main.c	Mon Nov 19 08:52:26 2018 -0800
-@@ -3094,6 +3116,20 @@
- 	case NETDEV_REGISTER:
- 		bond_create_proc_entry(event_bond);
- 		break;
-+	case NETDEV_DOWN: {
-+		struct slave *slave = bond_first_slave(event_bond);
-+
-+		toe_failover(bond_dev, slave ? slave->dev : NULL,
-+			     TOE_BOND_DOWN, NULL);
-+		break;
-+	}
-+	case NETDEV_UP: {
-+		struct slave *slave = bond_first_slave(event_bond);
-+
-+		toe_failover(bond_dev, slave ? slave->dev : NULL,
-+			     TOE_BOND_UP, NULL);
-+		break;
-+	}
- 	case NETDEV_NOTIFY_PEERS:
- 		if (event_bond->send_peer_notif)
- 			event_bond->send_peer_notif--;
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bond_netlink.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bond_netlink.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,786 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * drivers/net/bond/bond_netlink.c - Netlink interface for bonding
- * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
- * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/module.h>
-#include <linux/errno.h>
-#include <linux/netdevice.h>
-#include <linux/etherdevice.h>
-#include <linux/if_link.h>
-#include <linux/if_ether.h>
-#include <net/netlink.h>
-#include <net/rtnetlink.h>
-#include <net/bonding.h>
-
-static size_t bond_get_slave_size(const struct net_device *bond_dev,
-				  const struct net_device *slave_dev)
-{
-	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_STATE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_MII_STATUS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_SLAVE_LINK_FAILURE_COUNT */
-		nla_total_size(MAX_ADDR_LEN) +	/* IFLA_BOND_SLAVE_PERM_HWADDR */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_QUEUE_ID */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_AGGREGATOR_ID */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE */
-		0;
-}
-
-static int bond_fill_slave_info(struct sk_buff *skb,
-				const struct net_device *bond_dev,
-				const struct net_device *slave_dev)
-{
-	struct slave *slave = bond_slave_get_rtnl(slave_dev);
-
-	if (nla_put_u8(skb, IFLA_BOND_SLAVE_STATE, bond_slave_state(slave)))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_SLAVE_MII_STATUS, slave->link))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_SLAVE_LINK_FAILURE_COUNT,
-			slave->link_failure_count))
-		goto nla_put_failure;
-
-	if (nla_put(skb, IFLA_BOND_SLAVE_PERM_HWADDR,
-		    slave_dev->addr_len, slave->perm_hwaddr))
-		goto nla_put_failure;
-
-	if (nla_put_u16(skb, IFLA_BOND_SLAVE_QUEUE_ID, slave->queue_id))
-		goto nla_put_failure;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		const struct aggregator *agg;
-		const struct port *ad_port;
-
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		agg = SLAVE_AD_INFO(slave)->port.aggregator;
-		if (agg) {
-			if (nla_put_u16(skb, IFLA_BOND_SLAVE_AD_AGGREGATOR_ID,
-					agg->aggregator_identifier))
-				goto nla_put_failure;
-			if (nla_put_u8(skb,
-				       IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE,
-				       ad_port->actor_oper_port_state))
-				goto nla_put_failure;
-			if (nla_put_u16(skb,
-					IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE,
-					ad_port->partner_oper.port_state))
-				goto nla_put_failure;
-		}
-	}
-
-	return 0;
-
-nla_put_failure:
-	return -EMSGSIZE;
-}
-
-static const struct nla_policy bond_policy[IFLA_BOND_MAX + 1] = {
-	[IFLA_BOND_MODE]		= { .type = NLA_U8 },
-	[IFLA_BOND_ACTIVE_SLAVE]	= { .type = NLA_U32 },
-	[IFLA_BOND_MIIMON]		= { .type = NLA_U32 },
-	[IFLA_BOND_UPDELAY]		= { .type = NLA_U32 },
-	[IFLA_BOND_DOWNDELAY]		= { .type = NLA_U32 },
-	[IFLA_BOND_USE_CARRIER]		= { .type = NLA_U8 },
-	[IFLA_BOND_ARP_INTERVAL]	= { .type = NLA_U32 },
-	[IFLA_BOND_ARP_IP_TARGET]	= { .type = NLA_NESTED },
-	[IFLA_BOND_ARP_VALIDATE]	= { .type = NLA_U32 },
-	[IFLA_BOND_ARP_ALL_TARGETS]	= { .type = NLA_U32 },
-	[IFLA_BOND_PRIMARY]		= { .type = NLA_U32 },
-	[IFLA_BOND_PRIMARY_RESELECT]	= { .type = NLA_U8 },
-	[IFLA_BOND_FAIL_OVER_MAC]	= { .type = NLA_U8 },
-	[IFLA_BOND_XMIT_HASH_POLICY]	= { .type = NLA_U8 },
-	[IFLA_BOND_RESEND_IGMP]		= { .type = NLA_U32 },
-	[IFLA_BOND_NUM_PEER_NOTIF]	= { .type = NLA_U8 },
-	[IFLA_BOND_ALL_SLAVES_ACTIVE]	= { .type = NLA_U8 },
-	[IFLA_BOND_MIN_LINKS]		= { .type = NLA_U32 },
-	[IFLA_BOND_LP_INTERVAL]		= { .type = NLA_U32 },
-	[IFLA_BOND_PACKETS_PER_SLAVE]	= { .type = NLA_U32 },
-	[IFLA_BOND_AD_LACP_RATE]	= { .type = NLA_U8 },
-	[IFLA_BOND_AD_SELECT]		= { .type = NLA_U8 },
-	[IFLA_BOND_AD_INFO]		= { .type = NLA_NESTED },
-	[IFLA_BOND_AD_ACTOR_SYS_PRIO]	= { .type = NLA_U16 },
-	[IFLA_BOND_AD_USER_PORT_KEY]	= { .type = NLA_U16 },
-	[IFLA_BOND_AD_ACTOR_SYSTEM]	= { .type = NLA_BINARY,
-					    .len  = ETH_ALEN },
-	[IFLA_BOND_TLB_DYNAMIC_LB]	= { .type = NLA_U8 },
-	[IFLA_BOND_PEER_NOTIF_DELAY]    = { .type = NLA_U32 },
-};
-
-static const struct nla_policy bond_slave_policy[IFLA_BOND_SLAVE_MAX + 1] = {
-	[IFLA_BOND_SLAVE_QUEUE_ID]	= { .type = NLA_U16 },
-};
-
-static int bond_validate(struct nlattr *tb[], struct nlattr *data[],
-			 struct netlink_ext_ack *extack)
-{
-	if (tb[IFLA_ADDRESS]) {
-		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN)
-			return -EINVAL;
-		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS])))
-			return -EADDRNOTAVAIL;
-	}
-	return 0;
-}
-
-static int bond_slave_changelink(struct net_device *bond_dev,
-				 struct net_device *slave_dev,
-				 struct nlattr *tb[], struct nlattr *data[],
-				 struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_opt_value newval;
-	int err;
-
-	if (!data)
-		return 0;
-
-	if (data[IFLA_BOND_SLAVE_QUEUE_ID]) {
-		u16 queue_id = nla_get_u16(data[IFLA_BOND_SLAVE_QUEUE_ID]);
-		char queue_id_str[IFNAMSIZ + 7];
-
-		/* queue_id option setting expects slave_name:queue_id */
-		snprintf(queue_id_str, sizeof(queue_id_str), "%s:%u\n",
-			 slave_dev->name, queue_id);
-		bond_opt_initstr(&newval, queue_id_str);
-		err = __bond_opt_set(bond, BOND_OPT_QUEUE_ID, &newval);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int bond_changelink(struct net_device *bond_dev, struct nlattr *tb[],
-			   struct nlattr *data[],
-			   struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_opt_value newval;
-	int miimon = 0;
-	int err;
-
-	if (!data)
-		return 0;
-
-	if (data[IFLA_BOND_MODE]) {
-		int mode = nla_get_u8(data[IFLA_BOND_MODE]);
-
-		bond_opt_initval(&newval, mode);
-		err = __bond_opt_set(bond, BOND_OPT_MODE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ACTIVE_SLAVE]) {
-		int ifindex = nla_get_u32(data[IFLA_BOND_ACTIVE_SLAVE]);
-		struct net_device *slave_dev;
-		char *active_slave = "";
-
-		if (ifindex != 0) {
-			slave_dev = __dev_get_by_index(dev_net(bond_dev),
-						       ifindex);
-			if (!slave_dev)
-				return -ENODEV;
-			active_slave = slave_dev->name;
-		}
-		bond_opt_initstr(&newval, active_slave);
-		err = __bond_opt_set(bond, BOND_OPT_ACTIVE_SLAVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_MIIMON]) {
-		miimon = nla_get_u32(data[IFLA_BOND_MIIMON]);
-
-		bond_opt_initval(&newval, miimon);
-		err = __bond_opt_set(bond, BOND_OPT_MIIMON, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_UPDELAY]) {
-		int updelay = nla_get_u32(data[IFLA_BOND_UPDELAY]);
-
-		bond_opt_initval(&newval, updelay);
-		err = __bond_opt_set(bond, BOND_OPT_UPDELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_DOWNDELAY]) {
-		int downdelay = nla_get_u32(data[IFLA_BOND_DOWNDELAY]);
-
-		bond_opt_initval(&newval, downdelay);
-		err = __bond_opt_set(bond, BOND_OPT_DOWNDELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PEER_NOTIF_DELAY]) {
-		int delay = nla_get_u32(data[IFLA_BOND_PEER_NOTIF_DELAY]);
-
-		bond_opt_initval(&newval, delay);
-		err = __bond_opt_set(bond, BOND_OPT_PEER_NOTIF_DELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_USE_CARRIER]) {
-		int use_carrier = nla_get_u8(data[IFLA_BOND_USE_CARRIER]);
-
-		bond_opt_initval(&newval, use_carrier);
-		err = __bond_opt_set(bond, BOND_OPT_USE_CARRIER, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_INTERVAL]) {
-		int arp_interval = nla_get_u32(data[IFLA_BOND_ARP_INTERVAL]);
-
-		if (arp_interval && miimon) {
-			netdev_err(bond->dev, "ARP monitoring cannot be used with MII monitoring\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initval(&newval, arp_interval);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_INTERVAL, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_IP_TARGET]) {
-		struct nlattr *attr;
-		int i = 0, rem;
-
-		bond_option_arp_ip_targets_clear(bond);
-		nla_for_each_nested(attr, data[IFLA_BOND_ARP_IP_TARGET], rem) {
-			__be32 target;
-
-			if (nla_len(attr) < sizeof(target))
-				return -EINVAL;
-
-			target = nla_get_be32(attr);
-
-			bond_opt_initval(&newval, (__force u64)target);
-			err = __bond_opt_set(bond, BOND_OPT_ARP_TARGETS,
-					     &newval);
-			if (err)
-				break;
-			i++;
-		}
-		if (i == 0 && bond->params.arp_interval)
-			netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_VALIDATE]) {
-		int arp_validate = nla_get_u32(data[IFLA_BOND_ARP_VALIDATE]);
-
-		if (arp_validate && miimon) {
-			netdev_err(bond->dev, "ARP validating cannot be used with MII monitoring\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initval(&newval, arp_validate);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_VALIDATE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_ALL_TARGETS]) {
-		int arp_all_targets =
-			nla_get_u32(data[IFLA_BOND_ARP_ALL_TARGETS]);
-
-		bond_opt_initval(&newval, arp_all_targets);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_ALL_TARGETS, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PRIMARY]) {
-		int ifindex = nla_get_u32(data[IFLA_BOND_PRIMARY]);
-		struct net_device *dev;
-		char *primary = "";
-
-		dev = __dev_get_by_index(dev_net(bond_dev), ifindex);
-		if (dev)
-			primary = dev->name;
-
-		bond_opt_initstr(&newval, primary);
-		err = __bond_opt_set(bond, BOND_OPT_PRIMARY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PRIMARY_RESELECT]) {
-		int primary_reselect =
-			nla_get_u8(data[IFLA_BOND_PRIMARY_RESELECT]);
-
-		bond_opt_initval(&newval, primary_reselect);
-		err = __bond_opt_set(bond, BOND_OPT_PRIMARY_RESELECT, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_FAIL_OVER_MAC]) {
-		int fail_over_mac =
-			nla_get_u8(data[IFLA_BOND_FAIL_OVER_MAC]);
-
-		bond_opt_initval(&newval, fail_over_mac);
-		err = __bond_opt_set(bond, BOND_OPT_FAIL_OVER_MAC, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_XMIT_HASH_POLICY]) {
-		int xmit_hash_policy =
-			nla_get_u8(data[IFLA_BOND_XMIT_HASH_POLICY]);
-
-		bond_opt_initval(&newval, xmit_hash_policy);
-		err = __bond_opt_set(bond, BOND_OPT_XMIT_HASH, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_RESEND_IGMP]) {
-		int resend_igmp =
-			nla_get_u32(data[IFLA_BOND_RESEND_IGMP]);
-
-		bond_opt_initval(&newval, resend_igmp);
-		err = __bond_opt_set(bond, BOND_OPT_RESEND_IGMP, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_NUM_PEER_NOTIF]) {
-		int num_peer_notif =
-			nla_get_u8(data[IFLA_BOND_NUM_PEER_NOTIF]);
-
-		bond_opt_initval(&newval, num_peer_notif);
-		err = __bond_opt_set(bond, BOND_OPT_NUM_PEER_NOTIF, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ALL_SLAVES_ACTIVE]) {
-		int all_slaves_active =
-			nla_get_u8(data[IFLA_BOND_ALL_SLAVES_ACTIVE]);
-
-		bond_opt_initval(&newval, all_slaves_active);
-		err = __bond_opt_set(bond, BOND_OPT_ALL_SLAVES_ACTIVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_MIN_LINKS]) {
-		int min_links =
-			nla_get_u32(data[IFLA_BOND_MIN_LINKS]);
-
-		bond_opt_initval(&newval, min_links);
-		err = __bond_opt_set(bond, BOND_OPT_MINLINKS, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_LP_INTERVAL]) {
-		int lp_interval =
-			nla_get_u32(data[IFLA_BOND_LP_INTERVAL]);
-
-		bond_opt_initval(&newval, lp_interval);
-		err = __bond_opt_set(bond, BOND_OPT_LP_INTERVAL, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PACKETS_PER_SLAVE]) {
-		int packets_per_slave =
-			nla_get_u32(data[IFLA_BOND_PACKETS_PER_SLAVE]);
-
-		bond_opt_initval(&newval, packets_per_slave);
-		err = __bond_opt_set(bond, BOND_OPT_PACKETS_PER_SLAVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_LACP_RATE]) {
-		int lacp_rate =
-			nla_get_u8(data[IFLA_BOND_AD_LACP_RATE]);
-
-		bond_opt_initval(&newval, lacp_rate);
-		err = __bond_opt_set(bond, BOND_OPT_LACP_RATE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_SELECT]) {
-		int ad_select =
-			nla_get_u8(data[IFLA_BOND_AD_SELECT]);
-
-		bond_opt_initval(&newval, ad_select);
-		err = __bond_opt_set(bond, BOND_OPT_AD_SELECT, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_ACTOR_SYS_PRIO]) {
-		int actor_sys_prio =
-			nla_get_u16(data[IFLA_BOND_AD_ACTOR_SYS_PRIO]);
-
-		bond_opt_initval(&newval, actor_sys_prio);
-		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYS_PRIO, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_USER_PORT_KEY]) {
-		int port_key =
-			nla_get_u16(data[IFLA_BOND_AD_USER_PORT_KEY]);
-
-		bond_opt_initval(&newval, port_key);
-		err = __bond_opt_set(bond, BOND_OPT_AD_USER_PORT_KEY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_ACTOR_SYSTEM]) {
-		if (nla_len(data[IFLA_BOND_AD_ACTOR_SYSTEM]) != ETH_ALEN)
-			return -EINVAL;
-
-		bond_opt_initval(&newval,
-				 nla_get_u64(data[IFLA_BOND_AD_ACTOR_SYSTEM]));
-		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYSTEM, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_TLB_DYNAMIC_LB]) {
-		int dynamic_lb = nla_get_u8(data[IFLA_BOND_TLB_DYNAMIC_LB]);
-
-		bond_opt_initval(&newval, dynamic_lb);
-		err = __bond_opt_set(bond, BOND_OPT_TLB_DYNAMIC_LB, &newval);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int bond_newlink(struct net *src_net, struct net_device *bond_dev,
-			struct nlattr *tb[], struct nlattr *data[],
-			struct netlink_ext_ack *extack)
-{
-	int err;
-
-	err = bond_changelink(bond_dev, tb, data, extack);
-	if (err < 0)
-		return err;
-
-	err = register_netdevice(bond_dev);
-
-	netif_carrier_off(bond_dev);
-	if (!err) {
-		struct bonding *bond = netdev_priv(bond_dev);
-
-		bond_work_init_all(bond);
-	}
-
-	return err;
-}
-
-static size_t bond_get_size(const struct net_device *bond_dev)
-{
-	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_MODE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ACTIVE_SLAVE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIIMON */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_UPDELAY */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_DOWNDELAY */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_USE_CARRIER */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_INTERVAL */
-						/* IFLA_BOND_ARP_IP_TARGET */
-		nla_total_size(sizeof(struct nlattr)) +
-		nla_total_size(sizeof(u32)) * BOND_MAX_ARP_TARGETS +
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_VALIDATE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_ALL_TARGETS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PRIMARY */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_PRIMARY_RESELECT */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_FAIL_OVER_MAC */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_XMIT_HASH_POLICY */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_RESEND_IGMP */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_NUM_PEER_NOTIF */
-		nla_total_size(sizeof(u8)) +   /* IFLA_BOND_ALL_SLAVES_ACTIVE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIN_LINKS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_LP_INTERVAL */
-		nla_total_size(sizeof(u32)) +  /* IFLA_BOND_PACKETS_PER_SLAVE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_LACP_RATE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_SELECT */
-		nla_total_size(sizeof(struct nlattr)) + /* IFLA_BOND_AD_INFO */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_AGGREGATOR */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_NUM_PORTS */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_ACTOR_KEY */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_PARTNER_KEY*/
-		nla_total_size(ETH_ALEN) +    /* IFLA_BOND_AD_INFO_PARTNER_MAC*/
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_ACTOR_SYS_PRIO */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_USER_PORT_KEY */
-		nla_total_size(ETH_ALEN) + /* IFLA_BOND_AD_ACTOR_SYSTEM */
-		nla_total_size(sizeof(u8)) + /* IFLA_BOND_TLB_DYNAMIC_LB */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PEER_NOTIF_DELAY */
-		0;
-}
-
-static int bond_option_active_slave_get_ifindex(struct bonding *bond)
-{
-	const struct net_device *slave;
-	int ifindex;
-
-	rcu_read_lock();
-	slave = bond_option_active_slave_get_rcu(bond);
-	ifindex = slave ? slave->ifindex : 0;
-	rcu_read_unlock();
-	return ifindex;
-}
-
-static int bond_fill_info(struct sk_buff *skb,
-			  const struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	unsigned int packets_per_slave;
-	int ifindex, i, targets_added;
-	struct nlattr *targets;
-	struct slave *primary;
-
-	if (nla_put_u8(skb, IFLA_BOND_MODE, BOND_MODE(bond)))
-		goto nla_put_failure;
-
-	ifindex = bond_option_active_slave_get_ifindex(bond);
-	if (ifindex && nla_put_u32(skb, IFLA_BOND_ACTIVE_SLAVE, ifindex))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_MIIMON, bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_UPDELAY,
-			bond->params.updelay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_DOWNDELAY,
-			bond->params.downdelay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_PEER_NOTIF_DELAY,
-			bond->params.peer_notif_delay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_USE_CARRIER, bond->params.use_carrier))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_INTERVAL, bond->params.arp_interval))
-		goto nla_put_failure;
-
-	targets = nla_nest_start_noflag(skb, IFLA_BOND_ARP_IP_TARGET);
-	if (!targets)
-		goto nla_put_failure;
-
-	targets_added = 0;
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
-		if (bond->params.arp_targets[i]) {
-			if (nla_put_be32(skb, i, bond->params.arp_targets[i]))
-				goto nla_put_failure;
-			targets_added = 1;
-		}
-	}
-
-	if (targets_added)
-		nla_nest_end(skb, targets);
-	else
-		nla_nest_cancel(skb, targets);
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_VALIDATE, bond->params.arp_validate))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_ALL_TARGETS,
-			bond->params.arp_all_targets))
-		goto nla_put_failure;
-
-	primary = rtnl_dereference(bond->primary_slave);
-	if (primary &&
-	    nla_put_u32(skb, IFLA_BOND_PRIMARY, primary->dev->ifindex))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_PRIMARY_RESELECT,
-		       bond->params.primary_reselect))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_FAIL_OVER_MAC,
-		       bond->params.fail_over_mac))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_XMIT_HASH_POLICY,
-		       bond->params.xmit_policy))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_RESEND_IGMP,
-		        bond->params.resend_igmp))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_NUM_PEER_NOTIF,
-		       bond->params.num_peer_notif))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_ALL_SLAVES_ACTIVE,
-		       bond->params.all_slaves_active))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_MIN_LINKS,
-			bond->params.min_links))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_LP_INTERVAL,
-			bond->params.lp_interval))
-		goto nla_put_failure;
-
-	packets_per_slave = bond->params.packets_per_slave;
-	if (nla_put_u32(skb, IFLA_BOND_PACKETS_PER_SLAVE,
-			packets_per_slave))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_AD_LACP_RATE,
-		       bond->params.lacp_fast))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_AD_SELECT,
-		       bond->params.ad_select))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_TLB_DYNAMIC_LB,
-		       bond->params.tlb_dynamic_lb))
-		goto nla_put_failure;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info info;
-
-		if (capable(CAP_NET_ADMIN)) {
-			if (nla_put_u16(skb, IFLA_BOND_AD_ACTOR_SYS_PRIO,
-					bond->params.ad_actor_sys_prio))
-				goto nla_put_failure;
-
-			if (nla_put_u16(skb, IFLA_BOND_AD_USER_PORT_KEY,
-					bond->params.ad_user_port_key))
-				goto nla_put_failure;
-
-			if (nla_put(skb, IFLA_BOND_AD_ACTOR_SYSTEM,
-				    ETH_ALEN, &bond->params.ad_actor_system))
-				goto nla_put_failure;
-		}
-		if (!bond_3ad_get_active_agg_info(bond, &info)) {
-			struct nlattr *nest;
-
-			nest = nla_nest_start_noflag(skb, IFLA_BOND_AD_INFO);
-			if (!nest)
-				goto nla_put_failure;
-
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_AGGREGATOR,
-					info.aggregator_id))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_NUM_PORTS,
-					info.ports))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_ACTOR_KEY,
-					info.actor_key))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_PARTNER_KEY,
-					info.partner_key))
-				goto nla_put_failure;
-			if (nla_put(skb, IFLA_BOND_AD_INFO_PARTNER_MAC,
-				    sizeof(info.partner_system),
-				    &info.partner_system))
-				goto nla_put_failure;
-
-			nla_nest_end(skb, nest);
-		}
-	}
-
-	return 0;
-
-nla_put_failure:
-	return -EMSGSIZE;
-}
-
-static size_t bond_get_linkxstats_size(const struct net_device *dev, int attr)
-{
-	switch (attr) {
-	case IFLA_STATS_LINK_XSTATS:
-	case IFLA_STATS_LINK_XSTATS_SLAVE:
-		break;
-	default:
-		return 0;
-	}
-
-	return bond_3ad_stats_size() + nla_total_size(0);
-}
-
-static int bond_fill_linkxstats(struct sk_buff *skb,
-				const struct net_device *dev,
-				int *prividx, int attr)
-{
-	struct nlattr *nla __maybe_unused;
-	struct slave *slave = NULL;
-	struct nlattr *nest, *nest2;
-	struct bonding *bond;
-
-	switch (attr) {
-	case IFLA_STATS_LINK_XSTATS:
-		bond = netdev_priv(dev);
-		break;
-	case IFLA_STATS_LINK_XSTATS_SLAVE:
-		slave = bond_slave_get_rtnl(dev);
-		if (!slave)
-			return 0;
-		bond = slave->bond;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	nest = nla_nest_start_noflag(skb, LINK_XSTATS_TYPE_BOND);
-	if (!nest)
-		return -EMSGSIZE;
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct bond_3ad_stats *stats;
-
-		if (slave)
-			stats = &SLAVE_AD_INFO(slave)->stats;
-		else
-			stats = &BOND_AD_INFO(bond).stats;
-
-		nest2 = nla_nest_start_noflag(skb, BOND_XSTATS_3AD);
-		if (!nest2) {
-			nla_nest_end(skb, nest);
-			return -EMSGSIZE;
-		}
-
-		if (bond_3ad_stats_fill(skb, stats)) {
-			nla_nest_cancel(skb, nest2);
-			nla_nest_end(skb, nest);
-			return -EMSGSIZE;
-		}
-		nla_nest_end(skb, nest2);
-	}
-	nla_nest_end(skb, nest);
-
-	return 0;
-}
-
-struct rtnl_link_ops bond_link_ops __read_mostly = {
-	.kind			= "bond",
-	.priv_size		= sizeof(struct bonding),
-	.setup			= bond_setup,
-	.maxtype		= IFLA_BOND_MAX,
-	.policy			= bond_policy,
-	.validate		= bond_validate,
-	.newlink		= bond_newlink,
-	.changelink		= bond_changelink,
-	.get_size		= bond_get_size,
-	.fill_info		= bond_fill_info,
-	.get_num_tx_queues	= bond_get_num_tx_queues,
-	.get_num_rx_queues	= bond_get_num_tx_queues, /* Use the same number
-							     as for TX queues */
-	.fill_linkxstats        = bond_fill_linkxstats,
-	.get_linkxstats_size    = bond_get_linkxstats_size,
-	.slave_maxtype		= IFLA_BOND_SLAVE_MAX,
-	.slave_policy		= bond_slave_policy,
-	.slave_changelink	= bond_slave_changelink,
-	.get_slave_size		= bond_get_slave_size,
-	.fill_slave_info	= bond_fill_slave_info,
-};
-
-int __init bond_netlink_init(void)
-{
-	return rtnl_link_register(&bond_link_ops);
-}
-
-void bond_netlink_fini(void)
-{
-	rtnl_link_unregister(&bond_link_ops);
-}
-
-MODULE_ALIAS_RTNL_LINK("bond");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bond_options.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bond_options.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1475 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * drivers/net/bond/bond_options.c - bonding options
- * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
- * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/errno.h>
-#include <linux/if.h>
-#include <linux/netdevice.h>
-#include <linux/spinlock.h>
-#include <linux/rcupdate.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/sched/signal.h>
-
-#include <net/bonding.h>
-
-static int bond_option_active_slave_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_miimon_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_updelay_set(struct bonding *bond,
-				   const struct bond_opt_value *newval);
-static int bond_option_downdelay_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_peer_notif_delay_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_use_carrier_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_arp_interval_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target);
-static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target);
-static int bond_option_arp_ip_targets_set(struct bonding *bond,
-					  const struct bond_opt_value *newval);
-static int bond_option_arp_validate_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_arp_all_targets_set(struct bonding *bond,
-					   const struct bond_opt_value *newval);
-static int bond_option_primary_set(struct bonding *bond,
-				   const struct bond_opt_value *newval);
-static int bond_option_primary_reselect_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_fail_over_mac_set(struct bonding *bond,
-					 const struct bond_opt_value *newval);
-static int bond_option_xmit_hash_policy_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_resend_igmp_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_num_peer_notif_set(struct bonding *bond,
-					  const struct bond_opt_value *newval);
-static int bond_option_all_slaves_active_set(struct bonding *bond,
-					     const struct bond_opt_value *newval);
-static int bond_option_min_links_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_lp_interval_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_pps_set(struct bonding *bond,
-			       const struct bond_opt_value *newval);
-static int bond_option_lacp_rate_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_ad_select_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_queue_id_set(struct bonding *bond,
-				    const struct bond_opt_value *newval);
-static int bond_option_mode_set(struct bonding *bond,
-				const struct bond_opt_value *newval);
-static int bond_option_slaves_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
-					     const struct bond_opt_value *newval);
-static int bond_option_ad_actor_system_set(struct bonding *bond,
-					   const struct bond_opt_value *newval);
-static int bond_option_ad_user_port_key_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-
-
-static const struct bond_opt_value bond_mode_tbl[] = {
-	{ "balance-rr",    BOND_MODE_ROUNDROBIN,   BOND_VALFLAG_DEFAULT},
-	{ "active-backup", BOND_MODE_ACTIVEBACKUP, 0},
-	{ "balance-xor",   BOND_MODE_XOR,          0},
-	{ "broadcast",     BOND_MODE_BROADCAST,    0},
-	{ "802.3ad",       BOND_MODE_8023AD,       0},
-	{ "balance-tlb",   BOND_MODE_TLB,          0},
-	{ "balance-alb",   BOND_MODE_ALB,          0},
-	{ NULL,            -1,                     0},
-};
-
-static const struct bond_opt_value bond_pps_tbl[] = {
-	{ "default", 1,         BOND_VALFLAG_DEFAULT},
-	{ "maxval",  USHRT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,        0},
-};
-
-static const struct bond_opt_value bond_xmit_hashtype_tbl[] = {
-	{ "layer2",   BOND_XMIT_POLICY_LAYER2, BOND_VALFLAG_DEFAULT},
-	{ "layer3+4", BOND_XMIT_POLICY_LAYER34, 0},
-	{ "layer2+3", BOND_XMIT_POLICY_LAYER23, 0},
-	{ "encap2+3", BOND_XMIT_POLICY_ENCAP23, 0},
-	{ "encap3+4", BOND_XMIT_POLICY_ENCAP34, 0},
-	{ NULL,       -1,                       0},
-};
-
-static const struct bond_opt_value bond_arp_validate_tbl[] = {
-	{ "none",		BOND_ARP_VALIDATE_NONE,		BOND_VALFLAG_DEFAULT},
-	{ "active",		BOND_ARP_VALIDATE_ACTIVE,	0},
-	{ "backup",		BOND_ARP_VALIDATE_BACKUP,	0},
-	{ "all",		BOND_ARP_VALIDATE_ALL,		0},
-	{ "filter",		BOND_ARP_FILTER,		0},
-	{ "filter_active",	BOND_ARP_FILTER_ACTIVE,		0},
-	{ "filter_backup",	BOND_ARP_FILTER_BACKUP,		0},
-	{ NULL,			-1,				0},
-};
-
-static const struct bond_opt_value bond_arp_all_targets_tbl[] = {
-	{ "any", BOND_ARP_TARGETS_ANY, BOND_VALFLAG_DEFAULT},
-	{ "all", BOND_ARP_TARGETS_ALL, 0},
-	{ NULL,  -1,                   0},
-};
-
-static const struct bond_opt_value bond_fail_over_mac_tbl[] = {
-	{ "none",   BOND_FOM_NONE,   BOND_VALFLAG_DEFAULT},
-	{ "active", BOND_FOM_ACTIVE, 0},
-	{ "follow", BOND_FOM_FOLLOW, 0},
-	{ NULL,     -1,              0},
-};
-
-static const struct bond_opt_value bond_intmax_tbl[] = {
-	{ "off",     0,       BOND_VALFLAG_DEFAULT},
-	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,      0}
-};
-
-static const struct bond_opt_value bond_lacp_rate_tbl[] = {
-	{ "slow", AD_LACP_SLOW, 0},
-	{ "fast", AD_LACP_FAST, 0},
-	{ NULL,   -1,           0},
-};
-
-static const struct bond_opt_value bond_ad_select_tbl[] = {
-	{ "stable",    BOND_AD_STABLE,    BOND_VALFLAG_DEFAULT},
-	{ "bandwidth", BOND_AD_BANDWIDTH, 0},
-	{ "count",     BOND_AD_COUNT,     0},
-	{ NULL,        -1,                0},
-};
-
-static const struct bond_opt_value bond_num_peer_notif_tbl[] = {
-	{ "off",     0,   0},
-	{ "maxval",  255, BOND_VALFLAG_MAX},
-	{ "default", 1,   BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,  0}
-};
-
-static const struct bond_opt_value bond_primary_reselect_tbl[] = {
-	{ "always",  BOND_PRI_RESELECT_ALWAYS,  BOND_VALFLAG_DEFAULT},
-	{ "better",  BOND_PRI_RESELECT_BETTER,  0},
-	{ "failure", BOND_PRI_RESELECT_FAILURE, 0},
-	{ NULL,      -1},
-};
-
-static const struct bond_opt_value bond_use_carrier_tbl[] = {
-	{ "off", 0,  0},
-	{ "on",  1,  BOND_VALFLAG_DEFAULT},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_all_slaves_active_tbl[] = {
-	{ "off", 0,  BOND_VALFLAG_DEFAULT},
-	{ "on",  1,  0},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_resend_igmp_tbl[] = {
-	{ "off",     0,   0},
-	{ "maxval",  255, BOND_VALFLAG_MAX},
-	{ "default", 1,   BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,  0}
-};
-
-static const struct bond_opt_value bond_lp_interval_tbl[] = {
-	{ "minval",  1,       BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
-	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,      0},
-};
-
-static const struct bond_opt_value bond_tlb_dynamic_lb_tbl[] = {
-	{ "off", 0,  0},
-	{ "on",  1,  BOND_VALFLAG_DEFAULT},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_ad_actor_sys_prio_tbl[] = {
-	{ "minval",  1,     BOND_VALFLAG_MIN},
-	{ "maxval",  65535, BOND_VALFLAG_MAX | BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,    0},
-};
-
-static const struct bond_opt_value bond_ad_user_port_key_tbl[] = {
-	{ "minval",  0,     BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
-	{ "maxval",  1023,  BOND_VALFLAG_MAX},
-	{ NULL,      -1,    0},
-};
-
-static const struct bond_option bond_opts[BOND_OPT_LAST] = {
-	[BOND_OPT_MODE] = {
-		.id = BOND_OPT_MODE,
-		.name = "mode",
-		.desc = "bond device mode",
-		.flags = BOND_OPTFLAG_NOSLAVES | BOND_OPTFLAG_IFDOWN,
-		.values = bond_mode_tbl,
-		.set = bond_option_mode_set
-	},
-	[BOND_OPT_PACKETS_PER_SLAVE] = {
-		.id = BOND_OPT_PACKETS_PER_SLAVE,
-		.name = "packets_per_slave",
-		.desc = "Packets to send per slave in RR mode",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ROUNDROBIN)),
-		.values = bond_pps_tbl,
-		.set = bond_option_pps_set
-	},
-	[BOND_OPT_XMIT_HASH] = {
-		.id = BOND_OPT_XMIT_HASH,
-		.name = "xmit_hash_policy",
-		.desc = "balance-xor, 802.3ad, and tlb hashing method",
-		.values = bond_xmit_hashtype_tbl,
-		.set = bond_option_xmit_hash_policy_set
-	},
-	[BOND_OPT_ARP_VALIDATE] = {
-		.id = BOND_OPT_ARP_VALIDATE,
-		.name = "arp_validate",
-		.desc = "validate src/dst of ARP probes",
-		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
-			       BIT(BOND_MODE_ALB),
-		.values = bond_arp_validate_tbl,
-		.set = bond_option_arp_validate_set
-	},
-	[BOND_OPT_ARP_ALL_TARGETS] = {
-		.id = BOND_OPT_ARP_ALL_TARGETS,
-		.name = "arp_all_targets",
-		.desc = "fail on any/all arp targets timeout",
-		.values = bond_arp_all_targets_tbl,
-		.set = bond_option_arp_all_targets_set
-	},
-	[BOND_OPT_FAIL_OVER_MAC] = {
-		.id = BOND_OPT_FAIL_OVER_MAC,
-		.name = "fail_over_mac",
-		.desc = "For active-backup, do not set all slaves to the same MAC",
-		.flags = BOND_OPTFLAG_NOSLAVES,
-		.values = bond_fail_over_mac_tbl,
-		.set = bond_option_fail_over_mac_set
-	},
-	[BOND_OPT_ARP_INTERVAL] = {
-		.id = BOND_OPT_ARP_INTERVAL,
-		.name = "arp_interval",
-		.desc = "arp interval in milliseconds",
-		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
-			       BIT(BOND_MODE_ALB),
-		.values = bond_intmax_tbl,
-		.set = bond_option_arp_interval_set
-	},
-	[BOND_OPT_ARP_TARGETS] = {
-		.id = BOND_OPT_ARP_TARGETS,
-		.name = "arp_ip_target",
-		.desc = "arp targets in n.n.n.n form",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_arp_ip_targets_set
-	},
-	[BOND_OPT_DOWNDELAY] = {
-		.id = BOND_OPT_DOWNDELAY,
-		.name = "downdelay",
-		.desc = "Delay before considering link down, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_downdelay_set
-	},
-	[BOND_OPT_UPDELAY] = {
-		.id = BOND_OPT_UPDELAY,
-		.name = "updelay",
-		.desc = "Delay before considering link up, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_updelay_set
-	},
-	[BOND_OPT_LACP_RATE] = {
-		.id = BOND_OPT_LACP_RATE,
-		.name = "lacp_rate",
-		.desc = "LACPDU tx rate to request from 802.3ad partner",
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.values = bond_lacp_rate_tbl,
-		.set = bond_option_lacp_rate_set
-	},
-	[BOND_OPT_MINLINKS] = {
-		.id = BOND_OPT_MINLINKS,
-		.name = "min_links",
-		.desc = "Minimum number of available links before turning on carrier",
-		.values = bond_intmax_tbl,
-		.set = bond_option_min_links_set
-	},
-	[BOND_OPT_AD_SELECT] = {
-		.id = BOND_OPT_AD_SELECT,
-		.name = "ad_select",
-		.desc = "803.ad aggregation selection logic",
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.values = bond_ad_select_tbl,
-		.set = bond_option_ad_select_set
-	},
-	[BOND_OPT_NUM_PEER_NOTIF] = {
-		.id = BOND_OPT_NUM_PEER_NOTIF,
-		.name = "num_unsol_na",
-		.desc = "Number of peer notifications to send on failover event",
-		.values = bond_num_peer_notif_tbl,
-		.set = bond_option_num_peer_notif_set
-	},
-	[BOND_OPT_MIIMON] = {
-		.id = BOND_OPT_MIIMON,
-		.name = "miimon",
-		.desc = "Link check interval in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_miimon_set
-	},
-	[BOND_OPT_PRIMARY] = {
-		.id = BOND_OPT_PRIMARY,
-		.name = "primary",
-		.desc = "Primary network device to use",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
-						BIT(BOND_MODE_TLB) |
-						BIT(BOND_MODE_ALB)),
-		.set = bond_option_primary_set
-	},
-	[BOND_OPT_PRIMARY_RESELECT] = {
-		.id = BOND_OPT_PRIMARY_RESELECT,
-		.name = "primary_reselect",
-		.desc = "Reselect primary slave once it comes up",
-		.values = bond_primary_reselect_tbl,
-		.set = bond_option_primary_reselect_set
-	},
-	[BOND_OPT_USE_CARRIER] = {
-		.id = BOND_OPT_USE_CARRIER,
-		.name = "use_carrier",
-		.desc = "Use netif_carrier_ok (vs MII ioctls) in miimon",
-		.values = bond_use_carrier_tbl,
-		.set = bond_option_use_carrier_set
-	},
-	[BOND_OPT_ACTIVE_SLAVE] = {
-		.id = BOND_OPT_ACTIVE_SLAVE,
-		.name = "active_slave",
-		.desc = "Currently active slave",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
-						BIT(BOND_MODE_TLB) |
-						BIT(BOND_MODE_ALB)),
-		.set = bond_option_active_slave_set
-	},
-	[BOND_OPT_QUEUE_ID] = {
-		.id = BOND_OPT_QUEUE_ID,
-		.name = "queue_id",
-		.desc = "Set queue id of a slave",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_queue_id_set
-	},
-	[BOND_OPT_ALL_SLAVES_ACTIVE] = {
-		.id = BOND_OPT_ALL_SLAVES_ACTIVE,
-		.name = "all_slaves_active",
-		.desc = "Keep all frames received on an interface by setting active flag for all slaves",
-		.values = bond_all_slaves_active_tbl,
-		.set = bond_option_all_slaves_active_set
-	},
-	[BOND_OPT_RESEND_IGMP] = {
-		.id = BOND_OPT_RESEND_IGMP,
-		.name = "resend_igmp",
-		.desc = "Number of IGMP membership reports to send on link failure",
-		.values = bond_resend_igmp_tbl,
-		.set = bond_option_resend_igmp_set
-	},
-	[BOND_OPT_LP_INTERVAL] = {
-		.id = BOND_OPT_LP_INTERVAL,
-		.name = "lp_interval",
-		.desc = "The number of seconds between instances where the bonding driver sends learning packets to each slave's peer switch",
-		.values = bond_lp_interval_tbl,
-		.set = bond_option_lp_interval_set
-	},
-	[BOND_OPT_SLAVES] = {
-		.id = BOND_OPT_SLAVES,
-		.name = "slaves",
-		.desc = "Slave membership management",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_slaves_set
-	},
-	[BOND_OPT_TLB_DYNAMIC_LB] = {
-		.id = BOND_OPT_TLB_DYNAMIC_LB,
-		.name = "tlb_dynamic_lb",
-		.desc = "Enable dynamic flow shuffling",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_TLB) | BIT(BOND_MODE_ALB)),
-		.values = bond_tlb_dynamic_lb_tbl,
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.set = bond_option_tlb_dynamic_lb_set,
-	},
-	[BOND_OPT_AD_ACTOR_SYS_PRIO] = {
-		.id = BOND_OPT_AD_ACTOR_SYS_PRIO,
-		.name = "ad_actor_sys_prio",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.values = bond_ad_actor_sys_prio_tbl,
-		.set = bond_option_ad_actor_sys_prio_set,
-	},
-	[BOND_OPT_AD_ACTOR_SYSTEM] = {
-		.id = BOND_OPT_AD_ACTOR_SYSTEM,
-		.name = "ad_actor_system",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_ad_actor_system_set,
-	},
-	[BOND_OPT_AD_USER_PORT_KEY] = {
-		.id = BOND_OPT_AD_USER_PORT_KEY,
-		.name = "ad_user_port_key",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.values = bond_ad_user_port_key_tbl,
-		.set = bond_option_ad_user_port_key_set,
-	},
-	[BOND_OPT_NUM_PEER_NOTIF_ALIAS] = {
-		.id = BOND_OPT_NUM_PEER_NOTIF_ALIAS,
-		.name = "num_grat_arp",
-		.desc = "Number of peer notifications to send on failover event",
-		.values = bond_num_peer_notif_tbl,
-		.set = bond_option_num_peer_notif_set
-	},
-	[BOND_OPT_PEER_NOTIF_DELAY] = {
-		.id = BOND_OPT_PEER_NOTIF_DELAY,
-		.name = "peer_notif_delay",
-		.desc = "Delay between each peer notification on failover event, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_peer_notif_delay_set
-	}
-};
-
-/* Searches for an option by name */
-const struct bond_option *bond_opt_get_by_name(const char *name)
-{
-	const struct bond_option *opt;
-	int option;
-
-	for (option = 0; option < BOND_OPT_LAST; option++) {
-		opt = bond_opt_get(option);
-		if (opt && !strcmp(opt->name, name))
-			return opt;
-	}
-
-	return NULL;
-}
-
-/* Searches for a value in opt's values[] table */
-const struct bond_opt_value *bond_opt_get_val(unsigned int option, u64 val)
-{
-	const struct bond_option *opt;
-	int i;
-
-	opt = bond_opt_get(option);
-	if (WARN_ON(!opt))
-		return NULL;
-	for (i = 0; opt->values && opt->values[i].string; i++)
-		if (opt->values[i].value == val)
-			return &opt->values[i];
-
-	return NULL;
-}
-
-/* Searches for a value in opt's values[] table which matches the flagmask */
-static const struct bond_opt_value *bond_opt_get_flags(const struct bond_option *opt,
-						       u32 flagmask)
-{
-	int i;
-
-	for (i = 0; opt->values && opt->values[i].string; i++)
-		if (opt->values[i].flags & flagmask)
-			return &opt->values[i];
-
-	return NULL;
-}
-
-/* If maxval is missing then there's no range to check. In case minval is
- * missing then it's considered to be 0.
- */
-static bool bond_opt_check_range(const struct bond_option *opt, u64 val)
-{
-	const struct bond_opt_value *minval, *maxval;
-
-	minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
-	maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
-	if (!maxval || (minval && val < minval->value) || val > maxval->value)
-		return false;
-
-	return true;
-}
-
-/**
- * bond_opt_parse - parse option value
- * @opt: the option to parse against
- * @val: value to parse
- *
- * This function tries to extract the value from @val and check if it's
- * a possible match for the option and returns NULL if a match isn't found,
- * or the struct_opt_value that matched. It also strips the new line from
- * @val->string if it's present.
- */
-const struct bond_opt_value *bond_opt_parse(const struct bond_option *opt,
-					    struct bond_opt_value *val)
-{
-	char *p, valstr[BOND_OPT_MAX_NAMELEN + 1] = { 0, };
-	const struct bond_opt_value *tbl;
-	const struct bond_opt_value *ret = NULL;
-	bool checkval;
-	int i, rv;
-
-	/* No parsing if the option wants a raw val */
-	if (opt->flags & BOND_OPTFLAG_RAWVAL)
-		return val;
-
-	tbl = opt->values;
-	if (!tbl)
-		goto out;
-
-	/* ULLONG_MAX is used to bypass string processing */
-	checkval = val->value != ULLONG_MAX;
-	if (!checkval) {
-		if (!val->string)
-			goto out;
-		p = strchr(val->string, '\n');
-		if (p)
-			*p = '\0';
-		for (p = val->string; *p; p++)
-			if (!(isdigit(*p) || isspace(*p)))
-				break;
-		/* The following code extracts the string to match or the value
-		 * and sets checkval appropriately
-		 */
-		if (*p) {
-			rv = sscanf(val->string, "%32s", valstr);
-		} else {
-			rv = sscanf(val->string, "%llu", &val->value);
-			checkval = true;
-		}
-		if (!rv)
-			goto out;
-	}
-
-	for (i = 0; tbl[i].string; i++) {
-		/* Check for exact match */
-		if (checkval) {
-			if (val->value == tbl[i].value)
-				ret = &tbl[i];
-		} else {
-			if (!strcmp(valstr, "default") &&
-			    (tbl[i].flags & BOND_VALFLAG_DEFAULT))
-				ret = &tbl[i];
-
-			if (!strcmp(valstr, tbl[i].string))
-				ret = &tbl[i];
-		}
-		/* Found an exact match */
-		if (ret)
-			goto out;
-	}
-	/* Possible range match */
-	if (checkval && bond_opt_check_range(opt, val->value))
-		ret = val;
-out:
-	return ret;
-}
-
-/* Check opt's dependencies against bond mode and currently set options */
-static int bond_opt_check_deps(struct bonding *bond,
-			       const struct bond_option *opt)
-{
-	struct bond_params *params = &bond->params;
-
-	if (test_bit(params->mode, &opt->unsuppmodes))
-		return -EACCES;
-	if ((opt->flags & BOND_OPTFLAG_NOSLAVES) && bond_has_slaves(bond))
-		return -ENOTEMPTY;
-	if ((opt->flags & BOND_OPTFLAG_IFDOWN) && (bond->dev->flags & IFF_UP))
-		return -EBUSY;
-
-	return 0;
-}
-
-static void bond_opt_dep_print(struct bonding *bond,
-			       const struct bond_option *opt)
-{
-	const struct bond_opt_value *modeval;
-	struct bond_params *params;
-
-	params = &bond->params;
-	modeval = bond_opt_get_val(BOND_OPT_MODE, params->mode);
-	if (test_bit(params->mode, &opt->unsuppmodes))
-		netdev_err(bond->dev, "option %s: mode dependency failed, not supported in mode %s(%llu)\n",
-			   opt->name, modeval->string, modeval->value);
-}
-
-static void bond_opt_error_interpret(struct bonding *bond,
-				     const struct bond_option *opt,
-				     int error, const struct bond_opt_value *val)
-{
-	const struct bond_opt_value *minval, *maxval;
-	char *p;
-
-	switch (error) {
-	case -EINVAL:
-		if (val) {
-			if (val->string) {
-				/* sometimes RAWVAL opts may have new lines */
-				p = strchr(val->string, '\n');
-				if (p)
-					*p = '\0';
-				netdev_err(bond->dev, "option %s: invalid value (%s)\n",
-					   opt->name, val->string);
-			} else {
-				netdev_err(bond->dev, "option %s: invalid value (%llu)\n",
-					   opt->name, val->value);
-			}
-		}
-		minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
-		maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
-		if (!maxval)
-			break;
-		netdev_err(bond->dev, "option %s: allowed values %llu - %llu\n",
-			   opt->name, minval ? minval->value : 0, maxval->value);
-		break;
-	case -EACCES:
-		bond_opt_dep_print(bond, opt);
-		break;
-	case -ENOTEMPTY:
-		netdev_err(bond->dev, "option %s: unable to set because the bond device has slaves\n",
-			   opt->name);
-		break;
-	case -EBUSY:
-		netdev_err(bond->dev, "option %s: unable to set because the bond device is up\n",
-			   opt->name);
-		break;
-	default:
-		break;
-	}
-}
-
-/**
- * __bond_opt_set - set a bonding option
- * @bond: target bond device
- * @option: option to set
- * @val: value to set it to
- *
- * This function is used to change the bond's option value, it can be
- * used for both enabling/changing an option and for disabling it. RTNL lock
- * must be obtained before calling this function.
- */
-int __bond_opt_set(struct bonding *bond,
-		   unsigned int option, struct bond_opt_value *val)
-{
-	const struct bond_opt_value *retval = NULL;
-	const struct bond_option *opt;
-	int ret = -ENOENT;
-
-	ASSERT_RTNL();
-
-	opt = bond_opt_get(option);
-	if (WARN_ON(!val) || WARN_ON(!opt))
-		goto out;
-	ret = bond_opt_check_deps(bond, opt);
-	if (ret)
-		goto out;
-	retval = bond_opt_parse(opt, val);
-	if (!retval) {
-		ret = -EINVAL;
-		goto out;
-	}
-	ret = opt->set(bond, retval);
-out:
-	if (ret)
-		bond_opt_error_interpret(bond, opt, ret, val);
-
-	return ret;
-}
-/**
- * __bond_opt_set_notify - set a bonding option
- * @bond: target bond device
- * @option: option to set
- * @val: value to set it to
- *
- * This function is used to change the bond's option value and trigger
- * a notification to user sapce. It can be used for both enabling/changing
- * an option and for disabling it. RTNL lock must be obtained before calling
- * this function.
- */
-int __bond_opt_set_notify(struct bonding *bond,
-			  unsigned int option, struct bond_opt_value *val)
-{
-	int ret = -ENOENT;
-
-	ASSERT_RTNL();
-
-	ret = __bond_opt_set(bond, option, val);
-
-	if (!ret && (bond->dev->reg_state == NETREG_REGISTERED))
-		call_netdevice_notifiers(NETDEV_CHANGEINFODATA, bond->dev);
-
-	return ret;
-}
-
-/**
- * bond_opt_tryset_rtnl - try to acquire rtnl and call __bond_opt_set
- * @bond: target bond device
- * @option: option to set
- * @buf: value to set it to
- *
- * This function tries to acquire RTNL without blocking and if successful
- * calls __bond_opt_set. It is mainly used for sysfs option manipulation.
- */
-int bond_opt_tryset_rtnl(struct bonding *bond, unsigned int option, char *buf)
-{
-	struct bond_opt_value optval;
-	int ret;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-	bond_opt_initstr(&optval, buf);
-	ret = __bond_opt_set_notify(bond, option, &optval);
-	rtnl_unlock();
-
-	return ret;
-}
-
-/**
- * bond_opt_get - get a pointer to an option
- * @option: option for which to return a pointer
- *
- * This function checks if option is valid and if so returns a pointer
- * to its entry in the bond_opts[] option array.
- */
-const struct bond_option *bond_opt_get(unsigned int option)
-{
-	if (!BOND_OPT_VALID(option))
-		return NULL;
-
-	return &bond_opts[option];
-}
-
-static int bond_option_mode_set(struct bonding *bond,
-				const struct bond_opt_value *newval)
-{
-	if (!bond_mode_uses_arp(newval->value)) {
-		if (bond->params.arp_interval) {
-			netdev_dbg(bond->dev, "%s mode is incompatible with arp monitoring, start mii monitoring\n",
-				   newval->string);
-			/* disable arp monitoring */
-			bond->params.arp_interval = 0;
-		}
-
-		if (!bond->params.miimon) {
-			/* set miimon to default value */
-			bond->params.miimon = BOND_DEFAULT_MIIMON;
-			netdev_dbg(bond->dev, "Setting MII monitoring interval to %d\n",
-				   bond->params.miimon);
-		}
-	}
-
-	if (newval->value == BOND_MODE_ALB)
-		bond->params.tlb_dynamic_lb = 1;
-
-	/* don't cache arp_validate between modes */
-	bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
-	bond->params.mode = newval->value;
-
-	return 0;
-}
-
-static int bond_option_active_slave_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	char ifname[IFNAMSIZ] = { 0, };
-	struct net_device *slave_dev;
-	int ret = 0;
-
-	sscanf(newval->string, "%15s", ifname); /* IFNAMSIZ */
-	if (!strlen(ifname) || newval->string[0] == '\n') {
-		slave_dev = NULL;
-	} else {
-		slave_dev = __dev_get_by_name(dev_net(bond->dev), ifname);
-		if (!slave_dev)
-			return -ENODEV;
-	}
-
-	if (slave_dev) {
-		if (!netif_is_bond_slave(slave_dev)) {
-			slave_err(bond->dev, slave_dev, "Device is not bonding slave\n");
-			return -EINVAL;
-		}
-
-		if (bond->dev != netdev_master_upper_dev_get(slave_dev)) {
-			slave_err(bond->dev, slave_dev, "Device is not our slave\n");
-			return -EINVAL;
-		}
-	}
-
-	block_netpoll_tx();
-	/* check to see if we are clearing active */
-	if (!slave_dev) {
-		netdev_dbg(bond->dev, "Clearing current active slave\n");
-		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
-		bond_select_active_slave(bond);
-	} else {
-		struct slave *old_active = rtnl_dereference(bond->curr_active_slave);
-		struct slave *new_active = bond_slave_get_rtnl(slave_dev);
-
-		BUG_ON(!new_active);
-
-		if (new_active == old_active) {
-			/* do nothing */
-			slave_dbg(bond->dev, new_active->dev, "is already the current active slave\n");
-		} else {
-			if (old_active && (new_active->link == BOND_LINK_UP) &&
-			    bond_slave_is_up(new_active)) {
-				slave_dbg(bond->dev, new_active->dev, "Setting as active slave\n");
-				bond_change_active_slave(bond, new_active);
-			} else {
-				slave_err(bond->dev, new_active->dev, "Could not set as active slave; either %s is down or the link is down\n",
-					  new_active->dev->name);
-				ret = -EINVAL;
-			}
-		}
-	}
-	unblock_netpoll_tx();
-
-	return ret;
-}
-
-/* There are two tricky bits here.  First, if MII monitoring is activated, then
- * we must disable ARP monitoring.  Second, if the timer isn't running, we must
- * start it.
- */
-static int bond_option_miimon_set(struct bonding *bond,
-				  const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting MII monitoring interval to %llu\n",
-		   newval->value);
-	bond->params.miimon = newval->value;
-	if (bond->params.updelay)
-		netdev_dbg(bond->dev, "Note: Updating updelay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.updelay * bond->params.miimon);
-	if (bond->params.downdelay)
-		netdev_dbg(bond->dev, "Note: Updating downdelay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.downdelay * bond->params.miimon);
-	if (bond->params.peer_notif_delay)
-		netdev_dbg(bond->dev, "Note: Updating peer_notif_delay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.peer_notif_delay * bond->params.miimon);
-	if (newval->value && bond->params.arp_interval) {
-		netdev_dbg(bond->dev, "MII monitoring cannot be used with ARP monitoring - disabling ARP monitoring...\n");
-		bond->params.arp_interval = 0;
-		if (bond->params.arp_validate)
-			bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
-	}
-	if (bond->dev->flags & IFF_UP) {
-		/* If the interface is up, we may need to fire off
-		 * the MII timer. If the interface is down, the
-		 * timer will get fired off when the open function
-		 * is called.
-		 */
-		if (!newval->value) {
-			cancel_delayed_work_sync(&bond->mii_work);
-		} else {
-			cancel_delayed_work_sync(&bond->arp_work);
-			queue_delayed_work(bond->wq, &bond->mii_work, 0);
-		}
-	}
-
-	return 0;
-}
-
-/* Set up, down and peer notification delays. These must be multiples
- * of the MII monitoring value, and are stored internally as the
- * multiplier. Thus, we must translate to MS for the real world.
- */
-static int _bond_option_delay_set(struct bonding *bond,
-				  const struct bond_opt_value *newval,
-				  const char *name,
-				  int *target)
-{
-	int value = newval->value;
-
-	if (!bond->params.miimon) {
-		netdev_err(bond->dev, "Unable to set %s as MII monitoring is disabled\n",
-			   name);
-		return -EPERM;
-	}
-	if ((value % bond->params.miimon) != 0) {
-		netdev_warn(bond->dev,
-			    "%s (%d) is not a multiple of miimon (%d), value rounded to %d ms\n",
-			    name,
-			    value, bond->params.miimon,
-			    (value / bond->params.miimon) *
-			    bond->params.miimon);
-	}
-	*target = value / bond->params.miimon;
-	netdev_dbg(bond->dev, "Setting %s to %d\n",
-		   name,
-		   *target * bond->params.miimon);
-
-	return 0;
-}
-
-static int bond_option_updelay_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	return _bond_option_delay_set(bond, newval, "up delay",
-				      &bond->params.updelay);
-}
-
-static int bond_option_downdelay_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	return _bond_option_delay_set(bond, newval, "down delay",
-				      &bond->params.downdelay);
-}
-
-static int bond_option_peer_notif_delay_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	int ret = _bond_option_delay_set(bond, newval,
-					 "peer notification delay",
-					 &bond->params.peer_notif_delay);
-	return ret;
-}
-
-static int bond_option_use_carrier_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting use_carrier to %llu\n",
-		   newval->value);
-	bond->params.use_carrier = newval->value;
-
-	return 0;
-}
-
-/* There are two tricky bits here.  First, if ARP monitoring is activated, then
- * we must disable MII monitoring.  Second, if the ARP timer isn't running,
- * we must start it.
- */
-static int bond_option_arp_interval_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ARP monitoring interval to %llu\n",
-		   newval->value);
-	bond->params.arp_interval = newval->value;
-	if (newval->value) {
-		if (bond->params.miimon) {
-			netdev_dbg(bond->dev, "ARP monitoring cannot be used with MII monitoring. Disabling MII monitoring\n");
-			bond->params.miimon = 0;
-		}
-		if (!bond->params.arp_targets[0])
-			netdev_dbg(bond->dev, "ARP monitoring has been set up, but no ARP targets have been specified\n");
-	}
-	if (bond->dev->flags & IFF_UP) {
-		/* If the interface is up, we may need to fire off
-		 * the ARP timer.  If the interface is down, the
-		 * timer will get fired off when the open function
-		 * is called.
-		 */
-		if (!newval->value) {
-			if (bond->params.arp_validate)
-				bond->recv_probe = NULL;
-			cancel_delayed_work_sync(&bond->arp_work);
-		} else {
-			/* arp_validate can be set only in active-backup mode */
-			bond->recv_probe = bond_arp_rcv;
-			cancel_delayed_work_sync(&bond->mii_work);
-			queue_delayed_work(bond->wq, &bond->arp_work, 0);
-		}
-	}
-
-	return 0;
-}
-
-static void _bond_options_arp_ip_target_set(struct bonding *bond, int slot,
-					    __be32 target,
-					    unsigned long last_rx)
-{
-	__be32 *targets = bond->params.arp_targets;
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (slot >= 0 && slot < BOND_MAX_ARP_TARGETS) {
-		bond_for_each_slave(bond, slave, iter)
-			slave->target_last_arp_rx[slot] = last_rx;
-		targets[slot] = target;
-	}
-}
-
-static int _bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
-{
-	__be32 *targets = bond->params.arp_targets;
-	int ind;
-
-	if (!bond_is_ip_target_ok(target)) {
-		netdev_err(bond->dev, "invalid ARP target %pI4 specified for addition\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	if (bond_get_targets_ip(targets, target) != -1) { /* dup */
-		netdev_err(bond->dev, "ARP target %pI4 is already present\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	ind = bond_get_targets_ip(targets, 0); /* first free slot */
-	if (ind == -1) {
-		netdev_err(bond->dev, "ARP target table is full!\n");
-		return -EINVAL;
-	}
-
-	netdev_dbg(bond->dev, "Adding ARP target %pI4\n", &target);
-
-	_bond_options_arp_ip_target_set(bond, ind, target, jiffies);
-
-	return 0;
-}
-
-static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
-{
-	return _bond_option_arp_ip_target_add(bond, target);
-}
-
-static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target)
-{
-	__be32 *targets = bond->params.arp_targets;
-	struct list_head *iter;
-	struct slave *slave;
-	unsigned long *targets_rx;
-	int ind, i;
-
-	if (!bond_is_ip_target_ok(target)) {
-		netdev_err(bond->dev, "invalid ARP target %pI4 specified for removal\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	ind = bond_get_targets_ip(targets, target);
-	if (ind == -1) {
-		netdev_err(bond->dev, "unable to remove nonexistent ARP target %pI4\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	if (ind == 0 && !targets[1] && bond->params.arp_interval)
-		netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
-
-	netdev_dbg(bond->dev, "Removing ARP target %pI4\n", &target);
-
-	bond_for_each_slave(bond, slave, iter) {
-		targets_rx = slave->target_last_arp_rx;
-		for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
-			targets_rx[i] = targets_rx[i+1];
-		targets_rx[i] = 0;
-	}
-	for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
-		targets[i] = targets[i+1];
-	targets[i] = 0;
-
-	return 0;
-}
-
-void bond_option_arp_ip_targets_clear(struct bonding *bond)
-{
-	int i;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
-		_bond_options_arp_ip_target_set(bond, i, 0, 0);
-}
-
-static int bond_option_arp_ip_targets_set(struct bonding *bond,
-					  const struct bond_opt_value *newval)
-{
-	int ret = -EPERM;
-	__be32 target;
-
-	if (newval->string) {
-		if (!in4_pton(newval->string+1, -1, (u8 *)&target, -1, NULL)) {
-			netdev_err(bond->dev, "invalid ARP target %pI4 specified\n",
-				   &target);
-			return ret;
-		}
-		if (newval->string[0] == '+')
-			ret = bond_option_arp_ip_target_add(bond, target);
-		else if (newval->string[0] == '-')
-			ret = bond_option_arp_ip_target_rem(bond, target);
-		else
-			netdev_err(bond->dev, "no command found in arp_ip_targets file - use +<addr> or -<addr>\n");
-	} else {
-		target = newval->value;
-		ret = bond_option_arp_ip_target_add(bond, target);
-	}
-
-	return ret;
-}
-
-static int bond_option_arp_validate_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting arp_validate to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.arp_validate = newval->value;
-
-	return 0;
-}
-
-static int bond_option_arp_all_targets_set(struct bonding *bond,
-					   const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting arp_all_targets to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.arp_all_targets = newval->value;
-
-	return 0;
-}
-
-static int bond_option_primary_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	char *p, *primary = newval->string;
-	struct list_head *iter;
-	struct slave *slave;
-
-	block_netpoll_tx();
-
-	p = strchr(primary, '\n');
-	if (p)
-		*p = '\0';
-	/* check to see if we are clearing primary */
-	if (!strlen(primary)) {
-		netdev_dbg(bond->dev, "Setting primary slave to None\n");
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-		memset(bond->params.primary, 0, sizeof(bond->params.primary));
-		bond_select_active_slave(bond);
-		goto out;
-	}
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (strncmp(slave->dev->name, primary, IFNAMSIZ) == 0) {
-			slave_dbg(bond->dev, slave->dev, "Setting as primary slave\n");
-			rcu_assign_pointer(bond->primary_slave, slave);
-			strcpy(bond->params.primary, slave->dev->name);
-			bond->force_primary = true;
-			bond_select_active_slave(bond);
-			goto out;
-		}
-	}
-
-	if (rtnl_dereference(bond->primary_slave)) {
-		netdev_dbg(bond->dev, "Setting primary slave to None\n");
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-		bond_select_active_slave(bond);
-	}
-	strncpy(bond->params.primary, primary, IFNAMSIZ);
-	bond->params.primary[IFNAMSIZ - 1] = 0;
-
-	netdev_dbg(bond->dev, "Recording %s as primary, but it has not been enslaved yet\n",
-		   primary);
-
-out:
-	unblock_netpoll_tx();
-
-	return 0;
-}
-
-static int bond_option_primary_reselect_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting primary_reselect to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.primary_reselect = newval->value;
-
-	block_netpoll_tx();
-	bond_select_active_slave(bond);
-	unblock_netpoll_tx();
-
-	return 0;
-}
-
-static int bond_option_fail_over_mac_set(struct bonding *bond,
-					 const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting fail_over_mac to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.fail_over_mac = newval->value;
-
-	return 0;
-}
-
-static int bond_option_xmit_hash_policy_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting xmit hash policy to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.xmit_policy = newval->value;
-
-	return 0;
-}
-
-static int bond_option_resend_igmp_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting resend_igmp to %llu\n",
-		   newval->value);
-	bond->params.resend_igmp = newval->value;
-
-	return 0;
-}
-
-static int bond_option_num_peer_notif_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	bond->params.num_peer_notif = newval->value;
-
-	return 0;
-}
-
-static int bond_option_all_slaves_active_set(struct bonding *bond,
-					     const struct bond_opt_value *newval)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (newval->value == bond->params.all_slaves_active)
-		return 0;
-	bond->params.all_slaves_active = newval->value;
-	bond_for_each_slave(bond, slave, iter) {
-		if (!bond_is_active_slave(slave)) {
-			if (newval->value)
-				slave->inactive = 0;
-			else
-				slave->inactive = 1;
-		}
-	}
-
-	return 0;
-}
-
-static int bond_option_min_links_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting min links value to %llu\n",
-		   newval->value);
-	bond->params.min_links = newval->value;
-	bond_set_carrier(bond);
-
-	return 0;
-}
-
-static int bond_option_lp_interval_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	bond->params.lp_interval = newval->value;
-
-	return 0;
-}
-
-static int bond_option_pps_set(struct bonding *bond,
-			       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting packets per slave to %llu\n",
-		   newval->value);
-	bond->params.packets_per_slave = newval->value;
-	if (newval->value > 0) {
-		bond->params.reciprocal_packets_per_slave =
-			reciprocal_value(newval->value);
-	} else {
-		/* reciprocal_packets_per_slave is unused if
-		 * packets_per_slave is 0 or 1, just initialize it
-		 */
-		bond->params.reciprocal_packets_per_slave =
-			(struct reciprocal_value) { 0 };
-	}
-
-	return 0;
-}
-
-static int bond_option_lacp_rate_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting LACP rate to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.lacp_fast = newval->value;
-	bond_3ad_update_lacp_rate(bond);
-
-	return 0;
-}
-
-static int bond_option_ad_select_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_select to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.ad_select = newval->value;
-
-	return 0;
-}
-
-static int bond_option_queue_id_set(struct bonding *bond,
-				    const struct bond_opt_value *newval)
-{
-	struct slave *slave, *update_slave;
-	struct net_device *sdev;
-	struct list_head *iter;
-	char *delim;
-	int ret = 0;
-	u16 qid;
-
-	/* delim will point to queue id if successful */
-	delim = strchr(newval->string, ':');
-	if (!delim)
-		goto err_no_cmd;
-
-	/* Terminate string that points to device name and bump it
-	 * up one, so we can read the queue id there.
-	 */
-	*delim = '\0';
-	if (sscanf(++delim, "%hd\n", &qid) != 1)
-		goto err_no_cmd;
-
-	/* Check buffer length, valid ifname and queue id */
-	if (!dev_valid_name(newval->string) ||
-	    qid > bond->dev->real_num_tx_queues)
-		goto err_no_cmd;
-
-	/* Get the pointer to that interface if it exists */
-	sdev = __dev_get_by_name(dev_net(bond->dev), newval->string);
-	if (!sdev)
-		goto err_no_cmd;
-
-	/* Search for thes slave and check for duplicate qids */
-	update_slave = NULL;
-	bond_for_each_slave(bond, slave, iter) {
-		if (sdev == slave->dev)
-			/* We don't need to check the matching
-			 * slave for dups, since we're overwriting it
-			 */
-			update_slave = slave;
-		else if (qid && qid == slave->queue_id) {
-			goto err_no_cmd;
-		}
-	}
-
-	if (!update_slave)
-		goto err_no_cmd;
-
-	/* Actually set the qids for the slave */
-	update_slave->queue_id = qid;
-
-out:
-	return ret;
-
-err_no_cmd:
-	netdev_dbg(bond->dev, "invalid input for queue_id set\n");
-	ret = -EPERM;
-	goto out;
-
-}
-
-static int bond_option_slaves_set(struct bonding *bond,
-				  const struct bond_opt_value *newval)
-{
-	char command[IFNAMSIZ + 1] = { 0, };
-	struct net_device *dev;
-	char *ifname;
-	int ret;
-
-	sscanf(newval->string, "%16s", command); /* IFNAMSIZ*/
-	ifname = command + 1;
-	if ((strlen(command) <= 1) ||
-	    (command[0] != '+' && command[0] != '-') ||
-	    !dev_valid_name(ifname))
-		goto err_no_cmd;
-
-	dev = __dev_get_by_name(dev_net(bond->dev), ifname);
-	if (!dev) {
-		netdev_dbg(bond->dev, "interface %s does not exist!\n",
-			   ifname);
-		ret = -ENODEV;
-		goto out;
-	}
-
-	switch (command[0]) {
-	case '+':
-		slave_dbg(bond->dev, dev, "Enslaving interface\n");
-		ret = bond_enslave(bond->dev, dev, NULL);
-		break;
-
-	case '-':
-		slave_dbg(bond->dev, dev, "Releasing interface\n");
-		ret = bond_release(bond->dev, dev);
-		break;
-
-	default:
-		/* should not run here. */
-		goto err_no_cmd;
-	}
-
-out:
-	return ret;
-
-err_no_cmd:
-	netdev_err(bond->dev, "no command found in slaves file - use +ifname or -ifname\n");
-	ret = -EPERM;
-	goto out;
-}
-
-static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
-					  const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting dynamic-lb to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.tlb_dynamic_lb = newval->value;
-
-	return 0;
-}
-
-static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
-					     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_actor_sys_prio to %llu\n",
-		   newval->value);
-
-	bond->params.ad_actor_sys_prio = newval->value;
-	bond_3ad_update_ad_actor_settings(bond);
-
-	return 0;
-}
-
-static int bond_option_ad_actor_system_set(struct bonding *bond,
-					   const struct bond_opt_value *newval)
-{
-	u8 macaddr[ETH_ALEN];
-	u8 *mac;
-
-	if (newval->string) {
-		if (!mac_pton(newval->string, macaddr))
-			goto err;
-		mac = macaddr;
-	} else {
-		mac = (u8 *)&newval->value;
-	}
-
-	if (!is_valid_ether_addr(mac))
-		goto err;
-
-	netdev_dbg(bond->dev, "Setting ad_actor_system to %pM\n", mac);
-	ether_addr_copy(bond->params.ad_actor_system, mac);
-	bond_3ad_update_ad_actor_settings(bond);
-
-	return 0;
-
-err:
-	netdev_err(bond->dev, "Invalid ad_actor_system MAC address.\n");
-	return -EINVAL;
-}
-
-static int bond_option_ad_user_port_key_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_user_port_key to %llu\n",
-		   newval->value);
-
-	bond->params.ad_user_port_key = newval->value;
-	return 0;
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bond_procfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bond_procfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,312 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-#include <linux/proc_fs.h>
-#include <linux/export.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <net/bonding.h>
-
-#include "bonding_priv.h"
-
-static void *bond_info_seq_start(struct seq_file *seq, loff_t *pos)
-	__acquires(RCU)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	struct list_head *iter;
-	struct slave *slave;
-	loff_t off = 0;
-
-	rcu_read_lock();
-
-	if (*pos == 0)
-		return SEQ_START_TOKEN;
-
-	bond_for_each_slave_rcu(bond, slave, iter)
-		if (++off == *pos)
-			return slave;
-
-	return NULL;
-}
-
-static void *bond_info_seq_next(struct seq_file *seq, void *v, loff_t *pos)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	struct list_head *iter;
-	struct slave *slave;
-	bool found = false;
-
-	++*pos;
-	if (v == SEQ_START_TOKEN)
-		return bond_first_slave_rcu(bond);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (found)
-			return slave;
-		if (slave == v)
-			found = true;
-	}
-
-	return NULL;
-}
-
-static void bond_info_seq_stop(struct seq_file *seq, void *v)
-	__releases(RCU)
-{
-	rcu_read_unlock();
-}
-
-static void bond_info_show_master(struct seq_file *seq)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	const struct bond_opt_value *optval;
-	struct slave *curr, *primary;
-	int i;
-
-	curr = rcu_dereference(bond->curr_active_slave);
-
-	seq_printf(seq, "Bonding Mode: %s",
-		   bond_mode_name(BOND_MODE(bond)));
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
-	    bond->params.fail_over_mac) {
-		optval = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
-					  bond->params.fail_over_mac);
-		seq_printf(seq, " (fail_over_mac %s)", optval->string);
-	}
-
-	seq_printf(seq, "\n");
-
-	if (bond_mode_uses_xmit_hash(bond)) {
-		optval = bond_opt_get_val(BOND_OPT_XMIT_HASH,
-					  bond->params.xmit_policy);
-		seq_printf(seq, "Transmit Hash Policy: %s (%d)\n",
-			   optval->string, bond->params.xmit_policy);
-	}
-
-	if (bond_uses_primary(bond)) {
-		primary = rcu_dereference(bond->primary_slave);
-		seq_printf(seq, "Primary Slave: %s",
-			   primary ? primary->dev->name : "None");
-		if (primary) {
-			optval = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
-						  bond->params.primary_reselect);
-			seq_printf(seq, " (primary_reselect %s)",
-				   optval->string);
-		}
-
-		seq_printf(seq, "\nCurrently Active Slave: %s\n",
-			   (curr) ? curr->dev->name : "None");
-	}
-
-	seq_printf(seq, "MII Status: %s\n", netif_carrier_ok(bond->dev) ?
-		   "up" : "down");
-	seq_printf(seq, "MII Polling Interval (ms): %d\n", bond->params.miimon);
-	seq_printf(seq, "Up Delay (ms): %d\n",
-		   bond->params.updelay * bond->params.miimon);
-	seq_printf(seq, "Down Delay (ms): %d\n",
-		   bond->params.downdelay * bond->params.miimon);
-	seq_printf(seq, "Peer Notification Delay (ms): %d\n",
-		   bond->params.peer_notif_delay * bond->params.miimon);
-
-
-	/* ARP information */
-	if (bond->params.arp_interval > 0) {
-		int printed = 0;
-		seq_printf(seq, "ARP Polling Interval (ms): %d\n",
-				bond->params.arp_interval);
-
-		seq_printf(seq, "ARP IP target/s (n.n.n.n form):");
-
-		for (i = 0; (i < BOND_MAX_ARP_TARGETS); i++) {
-			if (!bond->params.arp_targets[i])
-				break;
-			if (printed)
-				seq_printf(seq, ",");
-			seq_printf(seq, " %pI4", &bond->params.arp_targets[i]);
-			printed = 1;
-		}
-		seq_printf(seq, "\n");
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-
-		seq_puts(seq, "\n802.3ad info\n");
-		seq_printf(seq, "LACP rate: %s\n",
-			   (bond->params.lacp_fast) ? "fast" : "slow");
-		seq_printf(seq, "Min links: %d\n", bond->params.min_links);
-		optval = bond_opt_get_val(BOND_OPT_AD_SELECT,
-					  bond->params.ad_select);
-		seq_printf(seq, "Aggregator selection policy (ad_select): %s\n",
-			   optval->string);
-		if (capable(CAP_NET_ADMIN)) {
-			seq_printf(seq, "System priority: %d\n",
-				   BOND_AD_INFO(bond).system.sys_priority);
-			seq_printf(seq, "System MAC address: %pM\n",
-				   &BOND_AD_INFO(bond).system.sys_mac_addr);
-
-			if (__bond_3ad_get_active_agg_info(bond, &ad_info)) {
-				seq_printf(seq,
-					   "bond %s has no active aggregator\n",
-					   bond->dev->name);
-			} else {
-				seq_printf(seq, "Active Aggregator Info:\n");
-
-				seq_printf(seq, "\tAggregator ID: %d\n",
-					   ad_info.aggregator_id);
-				seq_printf(seq, "\tNumber of ports: %d\n",
-					   ad_info.ports);
-				seq_printf(seq, "\tActor Key: %d\n",
-					   ad_info.actor_key);
-				seq_printf(seq, "\tPartner Key: %d\n",
-					   ad_info.partner_key);
-				seq_printf(seq, "\tPartner Mac Address: %pM\n",
-					   ad_info.partner_system);
-			}
-		}
-	}
-}
-
-static void bond_info_show_slave(struct seq_file *seq,
-				 const struct slave *slave)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-
-	seq_printf(seq, "\nSlave Interface: %s\n", slave->dev->name);
-	seq_printf(seq, "MII Status: %s\n", bond_slave_link_status(slave->link));
-	if (slave->speed == SPEED_UNKNOWN)
-		seq_printf(seq, "Speed: %s\n", "Unknown");
-	else
-		seq_printf(seq, "Speed: %d Mbps\n", slave->speed);
-
-	if (slave->duplex == DUPLEX_UNKNOWN)
-		seq_printf(seq, "Duplex: %s\n", "Unknown");
-	else
-		seq_printf(seq, "Duplex: %s\n", slave->duplex ? "full" : "half");
-
-	seq_printf(seq, "Link Failure Count: %u\n",
-		   slave->link_failure_count);
-
-	seq_printf(seq, "Permanent HW addr: %*phC\n",
-		   slave->dev->addr_len, slave->perm_hwaddr);
-	seq_printf(seq, "Slave queue ID: %d\n", slave->queue_id);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		const struct port *port = &SLAVE_AD_INFO(slave)->port;
-		const struct aggregator *agg = port->aggregator;
-
-		if (agg) {
-			seq_printf(seq, "Aggregator ID: %d\n",
-				   agg->aggregator_identifier);
-			seq_printf(seq, "Actor Churn State: %s\n",
-				   bond_3ad_churn_desc(port->sm_churn_actor_state));
-			seq_printf(seq, "Partner Churn State: %s\n",
-				   bond_3ad_churn_desc(port->sm_churn_partner_state));
-			seq_printf(seq, "Actor Churned Count: %d\n",
-				   port->churn_actor_count);
-			seq_printf(seq, "Partner Churned Count: %d\n",
-				   port->churn_partner_count);
-
-			if (capable(CAP_NET_ADMIN)) {
-				seq_puts(seq, "details actor lacp pdu:\n");
-				seq_printf(seq, "    system priority: %d\n",
-					   port->actor_system_priority);
-				seq_printf(seq, "    system mac address: %pM\n",
-					   &port->actor_system);
-				seq_printf(seq, "    port key: %d\n",
-					   port->actor_oper_port_key);
-				seq_printf(seq, "    port priority: %d\n",
-					   port->actor_port_priority);
-				seq_printf(seq, "    port number: %d\n",
-					   port->actor_port_number);
-				seq_printf(seq, "    port state: %d\n",
-					   port->actor_oper_port_state);
-
-				seq_puts(seq, "details partner lacp pdu:\n");
-				seq_printf(seq, "    system priority: %d\n",
-					   port->partner_oper.system_priority);
-				seq_printf(seq, "    system mac address: %pM\n",
-					   &port->partner_oper.system);
-				seq_printf(seq, "    oper key: %d\n",
-					   port->partner_oper.key);
-				seq_printf(seq, "    port priority: %d\n",
-					   port->partner_oper.port_priority);
-				seq_printf(seq, "    port number: %d\n",
-					   port->partner_oper.port_number);
-				seq_printf(seq, "    port state: %d\n",
-					   port->partner_oper.port_state);
-			}
-		} else {
-			seq_puts(seq, "Aggregator ID: N/A\n");
-		}
-	}
-}
-
-static int bond_info_seq_show(struct seq_file *seq, void *v)
-{
-	if (v == SEQ_START_TOKEN) {
-		seq_printf(seq, "%s\n", bond_version);
-		bond_info_show_master(seq);
-	} else
-		bond_info_show_slave(seq, v);
-
-	return 0;
-}
-
-static const struct seq_operations bond_info_seq_ops = {
-	.start = bond_info_seq_start,
-	.next  = bond_info_seq_next,
-	.stop  = bond_info_seq_stop,
-	.show  = bond_info_seq_show,
-};
-
-void bond_create_proc_entry(struct bonding *bond)
-{
-	struct net_device *bond_dev = bond->dev;
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	if (bn->proc_dir) {
-		bond->proc_entry = proc_create_seq_data(bond_dev->name, 0444,
-				bn->proc_dir, &bond_info_seq_ops, bond);
-		if (bond->proc_entry == NULL)
-			netdev_warn(bond_dev, "Cannot create /proc/net/%s/%s\n",
-				    DRV_NAME, bond_dev->name);
-		else
-			memcpy(bond->proc_file_name, bond_dev->name, IFNAMSIZ);
-	}
-}
-
-void bond_remove_proc_entry(struct bonding *bond)
-{
-	struct net_device *bond_dev = bond->dev;
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	if (bn->proc_dir && bond->proc_entry) {
-		remove_proc_entry(bond->proc_file_name, bn->proc_dir);
-		memset(bond->proc_file_name, 0, IFNAMSIZ);
-		bond->proc_entry = NULL;
-	}
-}
-
-/* Create the bonding directory under /proc/net, if doesn't exist yet.
- * Caller must hold rtnl_lock.
- */
-void __net_init bond_create_proc_dir(struct bond_net *bn)
-{
-	if (!bn->proc_dir) {
-		bn->proc_dir = proc_mkdir(DRV_NAME, bn->net->proc_net);
-		if (!bn->proc_dir)
-			pr_warn("Warning: Cannot create /proc/net/%s\n",
-				DRV_NAME);
-	}
-}
-
-/* Destroy the bonding directory under /proc/net, if empty.
- * Caller must hold rtnl_lock.
- */
-void __net_exit bond_destroy_proc_dir(struct bond_net *bn)
-{
-	if (bn->proc_dir) {
-		remove_proc_entry(DRV_NAME, bn->net->proc_net);
-		bn->proc_dir = NULL;
-	}
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bond_sysfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bond_sysfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,816 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 2004-2005 Intel Corporation. All rights reserved.
- */
-
-#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/device.h>
-#include <linux/sched/signal.h>
-#include <linux/fs.h>
-#include <linux/types.h>
-#include <linux/string.h>
-#include <linux/netdevice.h>
-#include <linux/inetdevice.h>
-#include <linux/in.h>
-#include <linux/sysfs.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/rtnetlink.h>
-#include <linux/etherdevice.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <linux/nsproxy.h>
-
-#include <net/bonding.h>
-
-#define to_bond(cd)	((struct bonding *)(netdev_priv(to_net_dev(cd))))
-
-/* "show" function for the bond_masters attribute.
- * The class parameter is ignored.
- */
-static ssize_t bonding_show_bonds(struct class *cls,
-				  struct class_attribute *attr,
-				  char *buf)
-{
-	struct bond_net *bn =
-		container_of(attr, struct bond_net, class_attr_bonding_masters);
-	int res = 0;
-	struct bonding *bond;
-
-	rtnl_lock();
-
-	list_for_each_entry(bond, &bn->dev_list, bond_list) {
-		if (res > (PAGE_SIZE - IFNAMSIZ)) {
-			/* not enough space for another interface name */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s ", bond->dev->name);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	rtnl_unlock();
-	return res;
-}
-
-static struct net_device *bond_get_by_name(struct bond_net *bn, const char *ifname)
-{
-	struct bonding *bond;
-
-	list_for_each_entry(bond, &bn->dev_list, bond_list) {
-		if (strncmp(bond->dev->name, ifname, IFNAMSIZ) == 0)
-			return bond->dev;
-	}
-	return NULL;
-}
-
-/* "store" function for the bond_masters attribute.  This is what
- * creates and deletes entire bonds.
- *
- * The class parameter is ignored.
- */
-static ssize_t bonding_store_bonds(struct class *cls,
-				   struct class_attribute *attr,
-				   const char *buffer, size_t count)
-{
-	struct bond_net *bn =
-		container_of(attr, struct bond_net, class_attr_bonding_masters);
-	char command[IFNAMSIZ + 1] = {0, };
-	char *ifname;
-	int rv, res = count;
-
-	sscanf(buffer, "%16s", command); /* IFNAMSIZ*/
-	ifname = command + 1;
-	if ((strlen(command) <= 1) ||
-	    !dev_valid_name(ifname))
-		goto err_no_cmd;
-
-	if (command[0] == '+') {
-		pr_info("%s is being created...\n", ifname);
-		rv = bond_create(bn->net, ifname);
-		if (rv) {
-			if (rv == -EEXIST)
-				pr_info("%s already exists\n", ifname);
-			else
-				pr_info("%s creation failed\n", ifname);
-			res = rv;
-		}
-	} else if (command[0] == '-') {
-		struct net_device *bond_dev;
-
-		rtnl_lock();
-		bond_dev = bond_get_by_name(bn, ifname);
-		if (bond_dev) {
-			pr_info("%s is being deleted...\n", ifname);
-			unregister_netdevice(bond_dev);
-		} else {
-			pr_err("unable to delete non-existent %s\n", ifname);
-			res = -ENODEV;
-		}
-		rtnl_unlock();
-	} else
-		goto err_no_cmd;
-
-	/* Always return either count or an error.  If you return 0, you'll
-	 * get called forever, which is bad.
-	 */
-	return res;
-
-err_no_cmd:
-	pr_err("no command found in bonding_masters - use +ifname or -ifname\n");
-	return -EPERM;
-}
-
-/* class attribute for bond_masters file.  This ends up in /sys/class/net */
-static const struct class_attribute class_attr_bonding_masters = {
-	.attr = {
-		.name = "bonding_masters",
-		.mode = 0644,
-	},
-	.show = bonding_show_bonds,
-	.store = bonding_store_bonds,
-};
-
-/* Generic "store" method for bonding sysfs option setting */
-static ssize_t bonding_sysfs_store_option(struct device *d,
-					  struct device_attribute *attr,
-					  const char *buffer, size_t count)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_option *opt;
-	char *buffer_clone;
-	int ret;
-
-	opt = bond_opt_get_by_name(attr->attr.name);
-	if (WARN_ON(!opt))
-		return -ENOENT;
-	buffer_clone = kstrndup(buffer, count, GFP_KERNEL);
-	if (!buffer_clone)
-		return -ENOMEM;
-	ret = bond_opt_tryset_rtnl(bond, opt->id, buffer_clone);
-	if (!ret)
-		ret = count;
-	kfree(buffer_clone);
-
-	return ret;
-}
-
-/* Show the slaves in the current bond. */
-static ssize_t bonding_show_slaves(struct device *d,
-				   struct device_attribute *attr, char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct list_head *iter;
-	struct slave *slave;
-	int res = 0;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (res > (PAGE_SIZE - IFNAMSIZ)) {
-			/* not enough space for another interface name */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s ", slave->dev->name);
-	}
-
-	rtnl_unlock();
-
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	return res;
-}
-static DEVICE_ATTR(slaves, 0644, bonding_show_slaves,
-		   bonding_sysfs_store_option);
-
-/* Show the bonding mode. */
-static ssize_t bonding_show_mode(struct device *d,
-				 struct device_attribute *attr, char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_MODE, BOND_MODE(bond));
-
-	return sprintf(buf, "%s %d\n", val->string, BOND_MODE(bond));
-}
-static DEVICE_ATTR(mode, 0644, bonding_show_mode, bonding_sysfs_store_option);
-
-/* Show the bonding transmit hash method. */
-static ssize_t bonding_show_xmit_hash(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_XMIT_HASH, bond->params.xmit_policy);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.xmit_policy);
-}
-static DEVICE_ATTR(xmit_hash_policy, 0644,
-		   bonding_show_xmit_hash, bonding_sysfs_store_option);
-
-/* Show arp_validate. */
-static ssize_t bonding_show_arp_validate(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
-			       bond->params.arp_validate);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.arp_validate);
-}
-static DEVICE_ATTR(arp_validate, 0644, bonding_show_arp_validate,
-		   bonding_sysfs_store_option);
-
-/* Show arp_all_targets. */
-static ssize_t bonding_show_arp_all_targets(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_ARP_ALL_TARGETS,
-			       bond->params.arp_all_targets);
-	return sprintf(buf, "%s %d\n",
-		       val->string, bond->params.arp_all_targets);
-}
-static DEVICE_ATTR(arp_all_targets, 0644,
-		   bonding_show_arp_all_targets, bonding_sysfs_store_option);
-
-/* Show fail_over_mac. */
-static ssize_t bonding_show_fail_over_mac(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
-			       bond->params.fail_over_mac);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.fail_over_mac);
-}
-static DEVICE_ATTR(fail_over_mac, 0644,
-		   bonding_show_fail_over_mac, bonding_sysfs_store_option);
-
-/* Show the arp timer interval. */
-static ssize_t bonding_show_arp_interval(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.arp_interval);
-}
-static DEVICE_ATTR(arp_interval, 0644,
-		   bonding_show_arp_interval, bonding_sysfs_store_option);
-
-/* Show the arp targets. */
-static ssize_t bonding_show_arp_targets(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	int i, res = 0;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
-		if (bond->params.arp_targets[i])
-			res += sprintf(buf + res, "%pI4 ",
-				       &bond->params.arp_targets[i]);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	return res;
-}
-static DEVICE_ATTR(arp_ip_target, 0644,
-		   bonding_show_arp_targets, bonding_sysfs_store_option);
-
-/* Show the up and down delays. */
-static ssize_t bonding_show_downdelay(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.downdelay * bond->params.miimon);
-}
-static DEVICE_ATTR(downdelay, 0644,
-		   bonding_show_downdelay, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_updelay(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.updelay * bond->params.miimon);
-
-}
-static DEVICE_ATTR(updelay, 0644,
-		   bonding_show_updelay, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_peer_notif_delay(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n",
-		       bond->params.peer_notif_delay * bond->params.miimon);
-}
-static DEVICE_ATTR(peer_notif_delay, 0644,
-		   bonding_show_peer_notif_delay, bonding_sysfs_store_option);
-
-/* Show the LACP interval. */
-static ssize_t bonding_show_lacp(struct device *d,
-				 struct device_attribute *attr,
-				 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_LACP_RATE, bond->params.lacp_fast);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.lacp_fast);
-}
-static DEVICE_ATTR(lacp_rate, 0644,
-		   bonding_show_lacp, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_min_links(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%u\n", bond->params.min_links);
-}
-static DEVICE_ATTR(min_links, 0644,
-		   bonding_show_min_links, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_select(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_AD_SELECT, bond->params.ad_select);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.ad_select);
-}
-static DEVICE_ATTR(ad_select, 0644,
-		   bonding_show_ad_select, bonding_sysfs_store_option);
-
-/* Show the number of peer notifications to send after a failover event. */
-static ssize_t bonding_show_num_peer_notif(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	return sprintf(buf, "%d\n", bond->params.num_peer_notif);
-}
-static DEVICE_ATTR(num_grat_arp, 0644,
-		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
-static DEVICE_ATTR(num_unsol_na, 0644,
-		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
-
-/* Show the MII monitor interval. */
-static ssize_t bonding_show_miimon(struct device *d,
-				   struct device_attribute *attr,
-				   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.miimon);
-}
-static DEVICE_ATTR(miimon, 0644,
-		   bonding_show_miimon, bonding_sysfs_store_option);
-
-/* Show the primary slave. */
-static ssize_t bonding_show_primary(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct slave *primary;
-	int count = 0;
-
-	rcu_read_lock();
-	primary = rcu_dereference(bond->primary_slave);
-	if (primary)
-		count = sprintf(buf, "%s\n", primary->dev->name);
-	rcu_read_unlock();
-
-	return count;
-}
-static DEVICE_ATTR(primary, 0644,
-		   bonding_show_primary, bonding_sysfs_store_option);
-
-/* Show the primary_reselect flag. */
-static ssize_t bonding_show_primary_reselect(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
-			       bond->params.primary_reselect);
-
-	return sprintf(buf, "%s %d\n",
-		       val->string, bond->params.primary_reselect);
-}
-static DEVICE_ATTR(primary_reselect, 0644,
-		   bonding_show_primary_reselect, bonding_sysfs_store_option);
-
-/* Show the use_carrier flag. */
-static ssize_t bonding_show_carrier(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.use_carrier);
-}
-static DEVICE_ATTR(use_carrier, 0644,
-		   bonding_show_carrier, bonding_sysfs_store_option);
-
-
-/* Show currently active_slave. */
-static ssize_t bonding_show_active_slave(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct net_device *slave_dev;
-	int count = 0;
-
-	rcu_read_lock();
-	slave_dev = bond_option_active_slave_get_rcu(bond);
-	if (slave_dev)
-		count = sprintf(buf, "%s\n", slave_dev->name);
-	rcu_read_unlock();
-
-	return count;
-}
-static DEVICE_ATTR(active_slave, 0644,
-		   bonding_show_active_slave, bonding_sysfs_store_option);
-
-/* Show link status of the bond interface. */
-static ssize_t bonding_show_mii_status(struct device *d,
-				       struct device_attribute *attr,
-				       char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	bool active = netif_carrier_ok(bond->dev);
-
-	return sprintf(buf, "%s\n", active ? "up" : "down");
-}
-static DEVICE_ATTR(mii_status, 0444, bonding_show_mii_status, NULL);
-
-/* Show current 802.3ad aggregator ID. */
-static ssize_t bonding_show_ad_aggregator(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.aggregator_id);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_aggregator, 0444, bonding_show_ad_aggregator, NULL);
-
-
-/* Show number of active 802.3ad ports. */
-static ssize_t bonding_show_ad_num_ports(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.ports);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_num_ports, 0444, bonding_show_ad_num_ports, NULL);
-
-
-/* Show current 802.3ad actor key. */
-static ssize_t bonding_show_ad_actor_key(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.actor_key);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_actor_key, 0444, bonding_show_ad_actor_key, NULL);
-
-
-/* Show current 802.3ad partner key. */
-static ssize_t bonding_show_ad_partner_key(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.partner_key);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_partner_key, 0444, bonding_show_ad_partner_key, NULL);
-
-
-/* Show current 802.3ad partner mac. */
-static ssize_t bonding_show_ad_partner_mac(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		if (!bond_3ad_get_active_agg_info(bond, &ad_info))
-			count = sprintf(buf, "%pM\n", ad_info.partner_system);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_partner_mac, 0444, bonding_show_ad_partner_mac, NULL);
-
-/* Show the queue_ids of the slaves in the current bond. */
-static ssize_t bonding_show_queue_id(struct device *d,
-				     struct device_attribute *attr,
-				     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct list_head *iter;
-	struct slave *slave;
-	int res = 0;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (res > (PAGE_SIZE - IFNAMSIZ - 6)) {
-			/* not enough space for another interface_name:queue_id pair */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s:%d ",
-			       slave->dev->name, slave->queue_id);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	rtnl_unlock();
-
-	return res;
-}
-static DEVICE_ATTR(queue_id, 0644, bonding_show_queue_id,
-		   bonding_sysfs_store_option);
-
-
-/* Show the all_slaves_active flag. */
-static ssize_t bonding_show_slaves_active(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.all_slaves_active);
-}
-static DEVICE_ATTR(all_slaves_active, 0644,
-		   bonding_show_slaves_active, bonding_sysfs_store_option);
-
-/* Show the number of IGMP membership reports to send on link failure */
-static ssize_t bonding_show_resend_igmp(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.resend_igmp);
-}
-static DEVICE_ATTR(resend_igmp, 0644,
-		   bonding_show_resend_igmp, bonding_sysfs_store_option);
-
-
-static ssize_t bonding_show_lp_interval(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.lp_interval);
-}
-static DEVICE_ATTR(lp_interval, 0644,
-		   bonding_show_lp_interval, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_tlb_dynamic_lb(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	return sprintf(buf, "%d\n", bond->params.tlb_dynamic_lb);
-}
-static DEVICE_ATTR(tlb_dynamic_lb, 0644,
-		   bonding_show_tlb_dynamic_lb, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_packets_per_slave(struct device *d,
-					      struct device_attribute *attr,
-					      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	unsigned int packets_per_slave = bond->params.packets_per_slave;
-
-	return sprintf(buf, "%u\n", packets_per_slave);
-}
-static DEVICE_ATTR(packets_per_slave, 0644,
-		   bonding_show_packets_per_slave, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_actor_sys_prio(struct device *d,
-					      struct device_attribute *attr,
-					      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%hu\n", bond->params.ad_actor_sys_prio);
-
-	return 0;
-}
-static DEVICE_ATTR(ad_actor_sys_prio, 0644,
-		   bonding_show_ad_actor_sys_prio, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_actor_system(struct device *d,
-					    struct device_attribute *attr,
-					    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%pM\n", bond->params.ad_actor_system);
-
-	return 0;
-}
-
-static DEVICE_ATTR(ad_actor_system, 0644,
-		   bonding_show_ad_actor_system, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_user_port_key(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%hu\n", bond->params.ad_user_port_key);
-
-	return 0;
-}
-static DEVICE_ATTR(ad_user_port_key, 0644,
-		   bonding_show_ad_user_port_key, bonding_sysfs_store_option);
-
-static struct attribute *per_bond_attrs[] = {
-	&dev_attr_slaves.attr,
-	&dev_attr_mode.attr,
-	&dev_attr_fail_over_mac.attr,
-	&dev_attr_arp_validate.attr,
-	&dev_attr_arp_all_targets.attr,
-	&dev_attr_arp_interval.attr,
-	&dev_attr_arp_ip_target.attr,
-	&dev_attr_downdelay.attr,
-	&dev_attr_updelay.attr,
-	&dev_attr_peer_notif_delay.attr,
-	&dev_attr_lacp_rate.attr,
-	&dev_attr_ad_select.attr,
-	&dev_attr_xmit_hash_policy.attr,
-	&dev_attr_num_grat_arp.attr,
-	&dev_attr_num_unsol_na.attr,
-	&dev_attr_miimon.attr,
-	&dev_attr_primary.attr,
-	&dev_attr_primary_reselect.attr,
-	&dev_attr_use_carrier.attr,
-	&dev_attr_active_slave.attr,
-	&dev_attr_mii_status.attr,
-	&dev_attr_ad_aggregator.attr,
-	&dev_attr_ad_num_ports.attr,
-	&dev_attr_ad_actor_key.attr,
-	&dev_attr_ad_partner_key.attr,
-	&dev_attr_ad_partner_mac.attr,
-	&dev_attr_queue_id.attr,
-	&dev_attr_all_slaves_active.attr,
-	&dev_attr_resend_igmp.attr,
-	&dev_attr_min_links.attr,
-	&dev_attr_lp_interval.attr,
-	&dev_attr_packets_per_slave.attr,
-	&dev_attr_tlb_dynamic_lb.attr,
-	&dev_attr_ad_actor_sys_prio.attr,
-	&dev_attr_ad_actor_system.attr,
-	&dev_attr_ad_user_port_key.attr,
-	NULL,
-};
-
-static const struct attribute_group bonding_group = {
-	.name = "bonding",
-	.attrs = per_bond_attrs,
-};
-
-/* Initialize sysfs.  This sets up the bonding_masters file in
- * /sys/class/net.
- */
-int bond_create_sysfs(struct bond_net *bn)
-{
-	int ret;
-
-	bn->class_attr_bonding_masters = class_attr_bonding_masters;
-	sysfs_attr_init(&bn->class_attr_bonding_masters.attr);
-
-	ret = netdev_class_create_file_ns(&bn->class_attr_bonding_masters,
-					  bn->net);
-	/* Permit multiple loads of the module by ignoring failures to
-	 * create the bonding_masters sysfs file.  Bonding devices
-	 * created by second or subsequent loads of the module will
-	 * not be listed in, or controllable by, bonding_masters, but
-	 * will have the usual "bonding" sysfs directory.
-	 *
-	 * This is done to preserve backwards compatibility for
-	 * initscripts/sysconfig, which load bonding multiple times to
-	 * configure multiple bonding devices.
-	 */
-	if (ret == -EEXIST) {
-		/* Is someone being kinky and naming a device bonding_master? */
-		if (__dev_get_by_name(bn->net,
-				      class_attr_bonding_masters.attr.name))
-			pr_err("network device named %s already exists in sysfs\n",
-			       class_attr_bonding_masters.attr.name);
-		ret = 0;
-	}
-
-	return ret;
-
-}
-
-/* Remove /sys/class/net/bonding_masters. */
-void bond_destroy_sysfs(struct bond_net *bn)
-{
-	netdev_class_remove_file_ns(&bn->class_attr_bonding_masters, bn->net);
-}
-
-/* Initialize sysfs for each bond.  This sets up and registers
- * the 'bondctl' directory for each individual bond under /sys/class/net.
- */
-void bond_prepare_sysfs_group(struct bonding *bond)
-{
-	bond->dev->sysfs_groups[0] = &bonding_group;
-}
-
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bond_sysfs_slave.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bond_sysfs_slave.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,174 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*	Sysfs attributes of bond slaves
- *
- *      Copyright (c) 2014 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/capability.h>
-#include <linux/kernel.h>
-#include <linux/netdevice.h>
-
-#include <net/bonding.h>
-
-struct slave_attribute {
-	struct attribute attr;
-	ssize_t (*show)(struct slave *, char *);
-};
-
-#define SLAVE_ATTR(_name, _mode, _show)				\
-const struct slave_attribute slave_attr_##_name = {		\
-	.attr = {.name = __stringify(_name),			\
-		 .mode = _mode },				\
-	.show	= _show,					\
-};
-#define SLAVE_ATTR_RO(_name)					\
-	SLAVE_ATTR(_name, 0444, _name##_show)
-
-static ssize_t state_show(struct slave *slave, char *buf)
-{
-	switch (bond_slave_state(slave)) {
-	case BOND_STATE_ACTIVE:
-		return sprintf(buf, "active\n");
-	case BOND_STATE_BACKUP:
-		return sprintf(buf, "backup\n");
-	default:
-		return sprintf(buf, "UNKNOWN\n");
-	}
-}
-static SLAVE_ATTR_RO(state);
-
-static ssize_t mii_status_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%s\n", bond_slave_link_status(slave->link));
-}
-static SLAVE_ATTR_RO(mii_status);
-
-static ssize_t link_failure_count_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%d\n", slave->link_failure_count);
-}
-static SLAVE_ATTR_RO(link_failure_count);
-
-static ssize_t perm_hwaddr_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%*phC\n",
-		       slave->dev->addr_len,
-		       slave->perm_hwaddr);
-}
-static SLAVE_ATTR_RO(perm_hwaddr);
-
-static ssize_t queue_id_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%d\n", slave->queue_id);
-}
-static SLAVE_ATTR_RO(queue_id);
-
-static ssize_t ad_aggregator_id_show(struct slave *slave, char *buf)
-{
-	const struct aggregator *agg;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		agg = SLAVE_AD_INFO(slave)->port.aggregator;
-		if (agg)
-			return sprintf(buf, "%d\n",
-				       agg->aggregator_identifier);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_aggregator_id);
-
-static ssize_t ad_actor_oper_port_state_show(struct slave *slave, char *buf)
-{
-	const struct port *ad_port;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		if (ad_port->aggregator)
-			return sprintf(buf, "%u\n",
-				       ad_port->actor_oper_port_state);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_actor_oper_port_state);
-
-static ssize_t ad_partner_oper_port_state_show(struct slave *slave, char *buf)
-{
-	const struct port *ad_port;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		if (ad_port->aggregator)
-			return sprintf(buf, "%u\n",
-				       ad_port->partner_oper.port_state);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_partner_oper_port_state);
-
-static const struct slave_attribute *slave_attrs[] = {
-	&slave_attr_state,
-	&slave_attr_mii_status,
-	&slave_attr_link_failure_count,
-	&slave_attr_perm_hwaddr,
-	&slave_attr_queue_id,
-	&slave_attr_ad_aggregator_id,
-	&slave_attr_ad_actor_oper_port_state,
-	&slave_attr_ad_partner_oper_port_state,
-	NULL
-};
-
-#define to_slave_attr(_at) container_of(_at, struct slave_attribute, attr)
-#define to_slave(obj)	container_of(obj, struct slave, kobj)
-
-static ssize_t slave_show(struct kobject *kobj,
-			  struct attribute *attr, char *buf)
-{
-	struct slave_attribute *slave_attr = to_slave_attr(attr);
-	struct slave *slave = to_slave(kobj);
-
-	return slave_attr->show(slave, buf);
-}
-
-static const struct sysfs_ops slave_sysfs_ops = {
-	.show = slave_show,
-};
-
-static struct kobj_type slave_ktype = {
-#ifdef CONFIG_SYSFS
-	.sysfs_ops = &slave_sysfs_ops,
-#endif
-};
-
-int bond_sysfs_slave_add(struct slave *slave)
-{
-	const struct slave_attribute **a;
-	int err;
-
-	err = kobject_init_and_add(&slave->kobj, &slave_ktype,
-				   &(slave->dev->dev.kobj), "bonding_slave");
-	if (err)
-		return err;
-
-	for (a = slave_attrs; *a; ++a) {
-		err = sysfs_create_file(&slave->kobj, &((*a)->attr));
-		if (err) {
-			kobject_put(&slave->kobj);
-			return err;
-		}
-	}
-
-	return 0;
-}
-
-void bond_sysfs_slave_del(struct slave *slave)
-{
-	const struct slave_attribute **a;
-
-	for (a = slave_attrs; *a; ++a)
-		sysfs_remove_file(&slave->kobj, &((*a)->attr));
-
-	kobject_put(&slave->kobj);
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bonding.mod.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bonding.mod.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,212 +0,0 @@
-#include <linux/build-salt.h>
-#include <linux/module.h>
-#include <linux/vermagic.h>
-#include <linux/compiler.h>
-
-BUILD_SALT;
-
-MODULE_INFO(vermagic, VERMAGIC_STRING);
-MODULE_INFO(name, KBUILD_MODNAME);
-
-__visible struct module __this_module
-__section(.gnu.linkonce.this_module) = {
-	.name = KBUILD_MODNAME,
-	.init = init_module,
-#ifdef CONFIG_MODULE_UNLOAD
-	.exit = cleanup_module,
-#endif
-	.arch = MODULE_ARCH_INIT,
-};
-
-MODULE_INFO(intree, "Y");
-
-#ifdef CONFIG_RETPOLINE
-MODULE_INFO(retpoline, "Y");
-#endif
-
-static const struct modversion_info ____versions[]
-__used __section(__versions) = {
-	{ 0xaee5dd69, "module_layout" },
-	{ 0xc0c9638f, "register_netdevice" },
-	{ 0xaf0d0b9d, "dev_mc_sync_multiple" },
-	{ 0x93c20051, "kobject_put" },
-	{ 0x5951a741, "netdev_info" },
-	{ 0x4a24d174, "kmalloc_caches" },
-	{ 0xeb233a45, "__kmalloc" },
-	{ 0x860f01e1, "dev_mc_unsync" },
-	{ 0x349cba85, "strchr" },
-	{ 0xf35d38ec, "proc_create_seq_private" },
-	{ 0x8d7f9e17, "param_ops_int" },
-	{ 0x754d539c, "strlen" },
-	{ 0x4817129, "dev_disable_lro" },
-	{ 0x19f462ab, "kfree_call_rcu" },
-	{ 0xde9b9408, "vlan_dev_vlan_id" },
-	{ 0xd315d3a8, "__skb_flow_dissect" },
-	{ 0x79aa04a2, "get_random_bytes" },
-	{ 0xa89d8928, "seq_puts" },
-	{ 0xe197e832, "netdev_rx_handler_register" },
-	{ 0xc7a4fbed, "rtnl_lock" },
-	{ 0xd5a1f5d7, "vlan_uses_dev" },
-	{ 0xfa690589, "netdev_cmd_to_name" },
-	{ 0x368afda6, "netif_carrier_on" },
-	{ 0x58443e98, "dst_release" },
-	{ 0xb3635b01, "_raw_spin_lock_bh" },
-	{ 0x62d3d9f4, "skb_clone" },
-	{ 0xffeedf6a, "delayed_work_timer_fn" },
-	{ 0xbc3bdc7f, "flow_get_u32_src" },
-	{ 0xc601fa37, "seq_printf" },
-	{ 0xd2da1048, "register_netdevice_notifier" },
-	{ 0x9af37447, "netif_carrier_off" },
-	{ 0x56470118, "__warn_printk" },
-	{ 0xc2ee38c6, "netdev_master_upper_dev_get" },
-	{ 0xa1089f32, "remove_proc_entry" },
-	{ 0x837b7b09, "__dynamic_pr_debug" },
-	{ 0x47a40d24, "dev_set_allmulti" },
-	{ 0xf7f1b81c, "vlan_vid_del" },
-	{ 0x5172eb9f, "netpoll_poll_dev" },
-	{ 0x8ba1525, "call_netdevice_notifiers" },
-	{ 0xbc54b88c, "__dev_kfree_skb_any" },
-	{ 0xc6f46339, "init_timer_key" },
-	{ 0x9fa7184a, "cancel_delayed_work_sync" },
-	{ 0xf3c1ecc5, "vlan_vid_add" },
-	{ 0x3520721e, "__netpoll_setup" },
-	{ 0x5bb98c5e, "vlan_vids_del_by_dev" },
-	{ 0x3c3ff9fd, "sprintf" },
-	{ 0x8452c13b, "pv_ops" },
-	{ 0xb809fb16, "netdev_walk_all_upper_dev_rcu" },
-	{ 0x15ba50a6, "jiffies" },
-	{ 0xbdd77179, "__dynamic_netdev_dbg" },
-	{ 0x9d0d6206, "unregister_netdevice_notifier" },
-	{ 0xbc0c91cb, "skb_trim" },
-	{ 0xe2d5255a, "strcmp" },
-	{ 0x85162720, "vlan_vids_add_by_dev" },
-	{ 0x22ef4a46, "netdev_master_upper_dev_link" },
-	{ 0xf6342c8b, "dev_mc_add" },
-	{ 0xf9a011c1, "__netdev_alloc_skb" },
-	{ 0x9132c624, "netdev_lower_get_next_private_rcu" },
-	{ 0x4d7fc13f, "netdev_lower_state_changed" },
-	{ 0x760f2e30, "__pskb_pull_tail" },
-	{ 0x530b00f2, "netdev_change_features" },
-	{ 0x86fcad4, "netpoll_send_skb_on_dev" },
-	{ 0x6b10bee1, "_copy_to_user" },
-	{ 0x8bdbb23f, "PDE_DATA" },
-	{ 0x1f6ccde8, "netdev_has_upper_dev" },
-	{ 0xf1db1704, "nla_memcpy" },
-	{ 0x619877de, "param_ops_charp" },
-	{ 0xd382c48, "dev_set_mac_address" },
-	{ 0x448821dd, "unregister_pernet_subsys" },
-	{ 0x8ce64cfd, "proc_mkdir" },
-	{ 0x9fdecc31, "unregister_netdevice_many" },
-	{ 0x11089ac7, "_ctype" },
-	{ 0xc025016c, "flow_keys_dissector" },
-	{ 0x19a11659, "current_task" },
-	{ 0xf0c26165, "__ethtool_get_link_ksettings" },
-	{ 0x45ba026d, "arp_create" },
-	{ 0xc5850110, "printk" },
-	{ 0xfb66f6b4, "ethtool_op_get_link" },
-	{ 0xbcab6ee6, "sscanf" },
-	{ 0xe1537255, "__list_del_entry_valid" },
-	{ 0xa965ca81, "reciprocal_value" },
-	{ 0xe0e3cea6, "ns_capable" },
-	{ 0x9cf230cf, "kobject_init_and_add" },
-	{ 0x62849ac7, "dev_valid_name" },
-	{ 0x198a797e, "netdev_class_remove_file_ns" },
-	{ 0xcfc1a03c, "free_netdev" },
-	{ 0xe7b00dfb, "__x86_indirect_thunk_r13" },
-	{ 0x9166fada, "strncpy" },
-	{ 0x460ce1ff, "dev_mc_del" },
-	{ 0x20b2a6ce, "nla_put" },
-	{ 0x98cc67c1, "netdev_upper_dev_unlink" },
-	{ 0x5a921311, "strncmp" },
-	{ 0x5792f848, "strlcpy" },
-	{ 0xbc3362a1, "skb_push" },
-	{ 0x652032cb, "mac_pton" },
-	{ 0x8c03d20c, "destroy_workqueue" },
-	{ 0x8da0fc7c, "dev_close" },
-	{ 0xf4f14de6, "rtnl_trylock" },
-	{ 0xcd65b05b, "netdev_bonding_info_change" },
-	{ 0xdfd55ecb, "dev_mc_flush" },
-	{ 0xfda9581f, "prandom_u32" },
-	{ 0x6091797f, "synchronize_rcu" },
-	{ 0x361bca87, "inet_confirm_addr" },
-	{ 0x9ab681a5, "init_net" },
-	{ 0x7f3e62f3, "rtnl_link_unregister" },
-	{ 0x7b2b1090, "__dev_get_by_index" },
-	{ 0x68f31cbd, "__list_add_valid" },
-	{ 0x6cde2296, "netdev_lower_dev_get_private" },
-	{ 0x9eacf8a5, "kstrndup" },
-	{ 0x59d242ba, "dev_open" },
-	{ 0xa9dbdd62, "dev_uc_flush" },
-	{ 0xc6cbbc89, "capable" },
-	{ 0xb601be4c, "__x86_indirect_thunk_rdx" },
-	{ 0xc9ed1a3d, "netdev_upper_get_next_dev_rcu" },
-	{ 0x680ac323, "sysfs_remove_file_ns" },
-	{ 0x49c41a57, "_raw_spin_unlock_bh" },
-	{ 0xb2fcb56d, "queue_delayed_work_on" },
-	{ 0xdecd0b29, "__stack_chk_fail" },
-	{ 0x79e50ab4, "vlan_dev_vlan_proto" },
-	{ 0xbfecf4dc, "netdev_rx_handler_unregister" },
-	{ 0x1d24c881, "___ratelimit" },
-	{ 0xb8b9f817, "kmalloc_order_trace" },
-	{ 0x7187d2d4, "kfree_skb" },
-	{ 0xac5fcec0, "in4_pton" },
-	{ 0x4aea20cf, "passthru_features_check" },
-	{ 0xd5a9684d, "alloc_netdev_mqs" },
-	{ 0x2ea2c95c, "__x86_indirect_thunk_rax" },
-	{ 0x6bd0f787, "arp_xmit" },
-	{ 0x9a58125, "netdev_lower_get_next_private" },
-	{ 0x290060af, "register_pernet_subsys" },
-	{ 0x3674f82a, "pskb_expand_head" },
-	{ 0xbdfb6dbb, "__fentry__" },
-	{ 0x705704fd, "netdev_err" },
-	{ 0x112fd9cb, "ether_setup" },
-	{ 0xfa0fb039, "dev_uc_unsync" },
-	{ 0xc6a4f3e6, "__dev_get_by_name" },
-	{ 0x7bd7a1df, "kmem_cache_alloc_trace" },
-	{ 0xdbf17652, "_raw_spin_lock" },
-	{ 0xc5042aa1, "unregister_netdevice_queue" },
-	{ 0xdf174df0, "ip_route_output_flow" },
-	{ 0xf6ebc03b, "net_ratelimit" },
-	{ 0x7e2827e9, "netdev_warn" },
-	{ 0xd8cf57a9, "__skb_flow_get_ports" },
-	{ 0x65e41b95, "dev_set_promiscuity" },
-	{ 0x8516c14a, "flow_get_u32_dst" },
-	{ 0x37a0cba, "kfree" },
-	{ 0xc75e994b, "dev_uc_sync_multiple" },
-	{ 0x69acdf38, "memcpy" },
-	{ 0x1c6b048f, "param_array_ops" },
-	{ 0x3a8bd2b, "dev_trans_start" },
-	{ 0x5dbe726b, "__dev_set_mtu" },
-	{ 0x2bb7fcb8, "rtnl_link_register" },
-	{ 0xdc919464, "dev_uc_sync" },
-	{ 0x23bcdd0f, "netdev_lower_get_first_private_rcu" },
-	{ 0xa0dad88e, "netdev_adjacent_get_private" },
-	{ 0xca81d5b7, "nla_put_64bit" },
-	{ 0x24c137ee, "__netpoll_free" },
-	{ 0x656e4a6e, "snprintf" },
-	{ 0xb0e602eb, "memmove" },
-	{ 0x6dde072b, "consume_skb" },
-	{ 0x85670f1d, "rtnl_is_locked" },
-	{ 0x7f02188f, "__msecs_to_jiffies" },
-	{ 0x406c0f94, "sysfs_create_file_ns" },
-	{ 0x3b28e685, "dev_queue_xmit" },
-	{ 0x6d26b36b, "netdev_is_rx_handler_busy" },
-	{ 0xc64e196c, "skb_put" },
-	{ 0x13c49cc2, "_copy_from_user" },
-	{ 0x9d93c9d0, "param_ops_uint" },
-	{ 0x43b4a8b, "skb_copy_bits" },
-	{ 0x54f3954a, "dev_mc_sync" },
-	{ 0xdf9208c0, "alloc_workqueue" },
-	{ 0x25bf910d, "dev_pre_changeaddr_notify" },
-	{ 0x6e720ff2, "rtnl_unlock" },
-	{ 0x69668826, "netdev_increment_features" },
-	{ 0xe75af167, "dev_get_stats" },
-	{ 0xd578121c, "netdev_class_create_file_ns" },
-	{ 0xa0d84bb4, "dev_set_mtu" },
-	{ 0xe914e41e, "strcpy" },
-};
-
-MODULE_INFO(depends, "");
-
-
-MODULE_INFO(srcversion, "2066880D7BD17AA9529FC97");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.0/bonding_priv.h
--- a/src/network/bonding/BONDING_KDIRS/5.4.0/bonding_priv.h	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,25 +0,0 @@
-/*
- * Bond several ethernet interfaces into a Cisco, running 'Etherchannel'.
- *
- * Portions are (c) Copyright 1995 Simon "Guru Aleph-Null" Janes
- * NCM: Network and Communications Management, Inc.
- *
- * BUT, I'm the one who modified it for ethernet, so:
- * (c) Copyright 1999, Thomas Davis, tadavis@lbl.gov
- *
- *	This software may be used and distributed according to the terms
- *	of the GNU Public License, incorporated herein by reference.
- *
- */
-
-#ifndef _BONDING_PRIV_H
-#define _BONDING_PRIV_H
-
-#define DRV_VERSION	"3.7.1-chelsio"
-#define DRV_RELDATE	"April 27, 2011"
-#define DRV_NAME	"bonding"
-#define DRV_DESCRIPTION	"Ethernet Channel Bonding Driver with Offload"
-
-#define bond_version DRV_DESCRIPTION ": v" DRV_VERSION " (" DRV_RELDATE ")\n"
-
-#endif
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.19/bond_3ad.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.19/bond_3ad.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,2767 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
- */
-
-#include <linux/skbuff.h>
-#include <linux/if_ether.h>
-#include <linux/netdevice.h>
-#include <linux/spinlock.h>
-#include <linux/ethtool.h>
-#include <linux/etherdevice.h>
-#include <linux/if_bonding.h>
-#include <linux/pkt_sched.h>
-#include <linux/toedev.h>
-#include <net/net_namespace.h>
-#include <net/bonding.h>
-#include <net/bond_3ad.h>
-#include <net/netlink.h>
-
-/* General definitions */
-#define AD_SHORT_TIMEOUT           1
-#define AD_LONG_TIMEOUT            0
-#define AD_STANDBY                 0x2
-#define AD_MAX_TX_IN_SECOND        3
-#define AD_COLLECTOR_MAX_DELAY     0
-
-/* Timer definitions (43.4.4 in the 802.3ad standard) */
-#define AD_FAST_PERIODIC_TIME      1
-#define AD_SLOW_PERIODIC_TIME      30
-#define AD_SHORT_TIMEOUT_TIME      (3*AD_FAST_PERIODIC_TIME)
-#define AD_LONG_TIMEOUT_TIME       (3*AD_SLOW_PERIODIC_TIME)
-#define AD_CHURN_DETECTION_TIME    60
-#define AD_AGGREGATE_WAIT_TIME     2
-
-/* Port state definitions (43.4.2.2 in the 802.3ad standard) */
-#define AD_STATE_LACP_ACTIVITY   0x1
-#define AD_STATE_LACP_TIMEOUT    0x2
-#define AD_STATE_AGGREGATION     0x4
-#define AD_STATE_SYNCHRONIZATION 0x8
-#define AD_STATE_COLLECTING      0x10
-#define AD_STATE_DISTRIBUTING    0x20
-#define AD_STATE_DEFAULTED       0x40
-#define AD_STATE_EXPIRED         0x80
-
-/* Port Variables definitions used by the State Machines (43.4.7 in the
- * 802.3ad standard)
- */
-#define AD_PORT_BEGIN           0x1
-#define AD_PORT_LACP_ENABLED    0x2
-#define AD_PORT_ACTOR_CHURN     0x4
-#define AD_PORT_PARTNER_CHURN   0x8
-#define AD_PORT_READY           0x10
-#define AD_PORT_READY_N         0x20
-#define AD_PORT_MATCHED         0x40
-#define AD_PORT_STANDBY         0x80
-#define AD_PORT_SELECTED        0x100
-#define AD_PORT_MOVED           0x200
-#define AD_PORT_CHURNED         (AD_PORT_ACTOR_CHURN | AD_PORT_PARTNER_CHURN)
-
-/* Port Key definitions
- * key is determined according to the link speed, duplex and
- * user key (which is yet not supported)
- *           --------------------------------------------------------------
- * Port key  | User key (10 bits)           | Speed (5 bits)      | Duplex|
- *           --------------------------------------------------------------
- *           |15                           6|5                   1|0
- */
-#define  AD_DUPLEX_KEY_MASKS    0x1
-#define  AD_SPEED_KEY_MASKS     0x3E
-#define  AD_USER_KEY_MASKS      0xFFC0
-
-enum ad_link_speed_type {
-	AD_LINK_SPEED_1MBPS = 1,
-	AD_LINK_SPEED_10MBPS,
-	AD_LINK_SPEED_100MBPS,
-	AD_LINK_SPEED_1000MBPS,
-	AD_LINK_SPEED_2500MBPS,
-	AD_LINK_SPEED_5000MBPS,
-	AD_LINK_SPEED_10000MBPS,
-	AD_LINK_SPEED_14000MBPS,
-	AD_LINK_SPEED_20000MBPS,
-	AD_LINK_SPEED_25000MBPS,
-	AD_LINK_SPEED_40000MBPS,
-	AD_LINK_SPEED_50000MBPS,
-	AD_LINK_SPEED_56000MBPS,
-	AD_LINK_SPEED_100000MBPS,
-};
-
-/* compare MAC addresses */
-#define MAC_ADDRESS_EQUAL(A, B)	\
-	ether_addr_equal_64bits((const u8 *)A, (const u8 *)B)
-
-static const u8 null_mac_addr[ETH_ALEN + 2] __long_aligned = {
-	0, 0, 0, 0, 0, 0
-};
-static u16 ad_ticks_per_sec;
-static const int ad_delta_in_ticks = (AD_TIMER_INTERVAL * HZ) / 1000;
-
-static const u8 lacpdu_mcast_addr[ETH_ALEN + 2] __long_aligned =
-	MULTICAST_LACPDU_ADDR;
-
-/* ================= main 802.3ad protocol functions ================== */
-static int ad_lacpdu_send(struct port *port);
-static int ad_marker_send(struct port *port, struct bond_marker *marker);
-static void ad_mux_machine(struct port *port, bool *update_slave_arr);
-static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port);
-static void ad_tx_machine(struct port *port);
-static void ad_periodic_machine(struct port *port);
-static void ad_port_selection_logic(struct port *port, bool *update_slave_arr);
-static void ad_agg_selection_logic(struct aggregator *aggregator,
-				   bool *update_slave_arr);
-static void ad_clear_agg(struct aggregator *aggregator);
-static void ad_initialize_agg(struct aggregator *aggregator);
-static void ad_initialize_port(struct port *port, int lacp_fast);
-static void ad_enable_collecting_distributing(struct port *port,
-					      bool *update_slave_arr);
-static void ad_disable_collecting_distributing(struct port *port,
-					       bool *update_slave_arr);
-static void ad_marker_info_received(struct bond_marker *marker_info,
-				    struct port *port);
-static void ad_marker_response_received(struct bond_marker *marker,
-					struct port *port);
-static void ad_update_actor_keys(struct port *port, bool reset);
-
-
-/* ================= api to bonding and kernel code ================== */
-
-/**
- * __get_bond_by_port - get the port's bonding struct
- * @port: the port we're looking at
- *
- * Return @port's bonding struct, or %NULL if it can't be found.
- */
-static inline struct bonding *__get_bond_by_port(struct port *port)
-{
-	if (port->slave == NULL)
-		return NULL;
-
-	return bond_get_bond_by_slave(port->slave);
-}
-
-/**
- * __get_first_agg - get the first aggregator in the bond
- * @bond: the bond we're looking at
- *
- * Return the aggregator of the first slave in @bond, or %NULL if it can't be
- * found.
- * The caller must hold RCU or RTNL lock.
- */
-static inline struct aggregator *__get_first_agg(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-	struct slave *first_slave;
-	struct aggregator *agg;
-
-	/* If there's no bond for this port, or bond has no slaves */
-	if (bond == NULL)
-		return NULL;
-
-	rcu_read_lock();
-	first_slave = bond_first_slave_rcu(bond);
-	agg = first_slave ? &(SLAVE_AD_INFO(first_slave)->aggregator) : NULL;
-	rcu_read_unlock();
-
-	return agg;
-}
-
-/**
- * __agg_has_partner - see if we have a partner
- * @agg: the agregator we're looking at
- *
- * Return nonzero if aggregator has a partner (denoted by a non-zero ether
- * address for the partner). Return 0 if not.
- */
-static inline int __agg_has_partner(struct aggregator *agg)
-{
-	return !is_zero_ether_addr(agg->partner_system.mac_addr_value);
-}
-
-/**
- * __disable_port - disable the port's slave
- * @port: the port we're looking at
- */
-static inline void __disable_port(struct port *port)
-{
-	bond_set_slave_inactive_flags(port->slave, BOND_SLAVE_NOTIFY_LATER);
-}
-
-/**
- * __enable_port - enable the port's slave, if it's up
- * @port: the port we're looking at
- */
-static inline void __enable_port(struct port *port)
-{
-	struct slave *slave = port->slave;
-
-	if ((slave->link == BOND_LINK_UP) && bond_slave_is_up(slave)) {
-		bond_set_slave_active_flags(slave, BOND_SLAVE_NOTIFY_LATER);
-		toe_failover(netdev_master_upper_dev_get_rcu(port->slave->dev),
-			     port->slave->dev, TOE_LINK_UP, NULL);
-	}
-}
-
-/**
- * __port_is_enabled - check if the port's slave is in active state
- * @port: the port we're looking at
- */
-static inline int __port_is_enabled(struct port *port)
-{
-	return bond_is_active_slave(port->slave);
-}
-
-/**
- * __get_agg_selection_mode - get the aggregator selection mode
- * @port: the port we're looking at
- *
- * Get the aggregator selection mode. Can be %STABLE, %BANDWIDTH or %COUNT.
- */
-static inline u32 __get_agg_selection_mode(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-
-	if (bond == NULL)
-		return BOND_AD_STABLE;
-
-	return bond->params.ad_select;
-}
-
-/**
- * __check_agg_selection_timer - check if the selection timer has expired
- * @port: the port we're looking at
- */
-static inline int __check_agg_selection_timer(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-
-	if (bond == NULL)
-		return 0;
-
-	return BOND_AD_INFO(bond).agg_select_timer ? 1 : 0;
-}
-
-/**
- * __get_link_speed - get a port's speed
- * @port: the port we're looking at
- *
- * Return @port's speed in 802.3ad enum format. i.e. one of:
- *     0,
- *     %AD_LINK_SPEED_10MBPS,
- *     %AD_LINK_SPEED_100MBPS,
- *     %AD_LINK_SPEED_1000MBPS,
- *     %AD_LINK_SPEED_2500MBPS,
- *     %AD_LINK_SPEED_5000MBPS,
- *     %AD_LINK_SPEED_10000MBPS
- *     %AD_LINK_SPEED_14000MBPS,
- *     %AD_LINK_SPEED_20000MBPS
- *     %AD_LINK_SPEED_25000MBPS
- *     %AD_LINK_SPEED_40000MBPS
- *     %AD_LINK_SPEED_50000MBPS
- *     %AD_LINK_SPEED_56000MBPS
- *     %AD_LINK_SPEED_100000MBPS
- */
-static u16 __get_link_speed(struct port *port)
-{
-	struct slave *slave = port->slave;
-	u16 speed;
-
-	/* this if covers only a special case: when the configuration starts
-	 * with link down, it sets the speed to 0.
-	 * This is done in spite of the fact that the e100 driver reports 0
-	 * to be compatible with MVT in the future.
-	 */
-	if (slave->link != BOND_LINK_UP)
-		speed = 0;
-	else {
-		switch (slave->speed) {
-		case SPEED_10:
-			speed = AD_LINK_SPEED_10MBPS;
-			break;
-
-		case SPEED_100:
-			speed = AD_LINK_SPEED_100MBPS;
-			break;
-
-		case SPEED_1000:
-			speed = AD_LINK_SPEED_1000MBPS;
-			break;
-
-		case SPEED_2500:
-			speed = AD_LINK_SPEED_2500MBPS;
-			break;
-
-		case SPEED_5000:
-			speed = AD_LINK_SPEED_5000MBPS;
-			break;
-
-		case SPEED_10000:
-			speed = AD_LINK_SPEED_10000MBPS;
-			break;
-
-		case SPEED_14000:
-			speed = AD_LINK_SPEED_14000MBPS;
-			break;
-
-		case SPEED_20000:
-			speed = AD_LINK_SPEED_20000MBPS;
-			break;
-
-		case SPEED_25000:
-			speed = AD_LINK_SPEED_25000MBPS;
-			break;
-
-		case SPEED_40000:
-			speed = AD_LINK_SPEED_40000MBPS;
-			break;
-
-		case SPEED_50000:
-			speed = AD_LINK_SPEED_50000MBPS;
-			break;
-
-		case SPEED_56000:
-			speed = AD_LINK_SPEED_56000MBPS;
-			break;
-
-		case SPEED_100000:
-			speed = AD_LINK_SPEED_100000MBPS;
-			break;
-
-		default:
-			/* unknown speed value from ethtool. shouldn't happen */
-			if (slave->speed != SPEED_UNKNOWN)
-				pr_warn_once("%s: (slave %s): unknown ethtool speed (%d) for port %d (set it to 0)\n",
-					     slave->bond->dev->name,
-					     slave->dev->name, slave->speed,
-					     port->actor_port_number);
-			speed = 0;
-			break;
-		}
-	}
-
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d Received link speed %d update from adapter\n",
-		  port->actor_port_number, speed);
-	return speed;
-}
-
-/**
- * __get_duplex - get a port's duplex
- * @port: the port we're looking at
- *
- * Return @port's duplex in 802.3ad bitmask format. i.e.:
- *     0x01 if in full duplex
- *     0x00 otherwise
- */
-static u8 __get_duplex(struct port *port)
-{
-	struct slave *slave = port->slave;
-	u8 retval = 0x0;
-
-	/* handling a special case: when the configuration starts with
-	 * link down, it sets the duplex to 0.
-	 */
-	if (slave->link == BOND_LINK_UP) {
-		switch (slave->duplex) {
-		case DUPLEX_FULL:
-			retval = 0x1;
-			slave_dbg(slave->bond->dev, slave->dev, "Port %d Received status full duplex update from adapter\n",
-				  port->actor_port_number);
-			break;
-		case DUPLEX_HALF:
-		default:
-			retval = 0x0;
-			slave_dbg(slave->bond->dev, slave->dev, "Port %d Received status NOT full duplex update from adapter\n",
-				  port->actor_port_number);
-			break;
-		}
-	}
-	return retval;
-}
-
-static void __ad_actor_update_port(struct port *port)
-{
-	const struct bonding *bond = bond_get_bond_by_slave(port->slave);
-
-	port->actor_system = BOND_AD_INFO(bond).system.sys_mac_addr;
-	port->actor_system_priority = BOND_AD_INFO(bond).system.sys_priority;
-}
-
-/* Conversions */
-
-/**
- * __ad_timer_to_ticks - convert a given timer type to AD module ticks
- * @timer_type:	which timer to operate
- * @par: timer parameter. see below
- *
- * If @timer_type is %current_while_timer, @par indicates long/short timer.
- * If @timer_type is %periodic_timer, @par is one of %FAST_PERIODIC_TIME,
- *						     %SLOW_PERIODIC_TIME.
- */
-static u16 __ad_timer_to_ticks(u16 timer_type, u16 par)
-{
-	u16 retval = 0; /* to silence the compiler */
-
-	switch (timer_type) {
-	case AD_CURRENT_WHILE_TIMER:	/* for rx machine usage */
-		if (par)
-			retval = (AD_SHORT_TIMEOUT_TIME*ad_ticks_per_sec);
-		else
-			retval = (AD_LONG_TIMEOUT_TIME*ad_ticks_per_sec);
-		break;
-	case AD_ACTOR_CHURN_TIMER:	/* for local churn machine */
-		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
-		break;
-	case AD_PERIODIC_TIMER:		/* for periodic machine */
-		retval = (par*ad_ticks_per_sec); /* long timeout */
-		break;
-	case AD_PARTNER_CHURN_TIMER:	/* for remote churn machine */
-		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
-		break;
-	case AD_WAIT_WHILE_TIMER:	/* for selection machine */
-		retval = (AD_AGGREGATE_WAIT_TIME*ad_ticks_per_sec);
-		break;
-	}
-
-	return retval;
-}
-
-
-/* ================= ad_rx_machine helper functions ================== */
-
-/**
- * __choose_matched - update a port's matched variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Update the value of the matched variable, using parameter values from a
- * newly received lacpdu. Parameter values for the partner carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the actor. Matched is set to TRUE if all of these parameters
- * match and the PDU parameter partner_state.aggregation has the same value as
- * actor_oper_port_state.aggregation and lacp will actively maintain the link
- * in the aggregation. Matched is also set to TRUE if the value of
- * actor_state.aggregation in the received PDU is set to FALSE, i.e., indicates
- * an individual link and lacp will actively maintain the link. Otherwise,
- * matched is set to FALSE. LACP is considered to be actively maintaining the
- * link if either the PDU's actor_state.lacp_activity variable is TRUE or both
- * the actor's actor_oper_port_state.lacp_activity and the PDU's
- * partner_state.lacp_activity variables are TRUE.
- *
- * Note: the AD_PORT_MATCHED "variable" is not specified by 802.3ad; it is
- * used here to implement the language from 802.3ad 43.4.9 that requires
- * recordPDU to "match" the LACPDU parameters to the stored values.
- */
-static void __choose_matched(struct lacpdu *lacpdu, struct port *port)
-{
-	/* check if all parameters are alike
-	 * or this is individual link(aggregation == FALSE)
-	 * then update the state machine Matched variable.
-	 */
-	if (((ntohs(lacpdu->partner_port) == port->actor_port_number) &&
-	     (ntohs(lacpdu->partner_port_priority) == port->actor_port_priority) &&
-	     MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) &&
-	     (ntohs(lacpdu->partner_system_priority) == port->actor_system_priority) &&
-	     (ntohs(lacpdu->partner_key) == port->actor_oper_port_key) &&
-	     ((lacpdu->partner_state & AD_STATE_AGGREGATION) == (port->actor_oper_port_state & AD_STATE_AGGREGATION))) ||
-	    ((lacpdu->actor_state & AD_STATE_AGGREGATION) == 0)
-		) {
-		port->sm_vars |= AD_PORT_MATCHED;
-	} else {
-		port->sm_vars &= ~AD_PORT_MATCHED;
-	}
-}
-
-/**
- * __record_pdu - record parameters from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Record the parameter values for the Actor carried in a received lacpdu as
- * the current partner operational parameter values and sets
- * actor_oper_port_state.defaulted to FALSE.
- */
-static void __record_pdu(struct lacpdu *lacpdu, struct port *port)
-{
-	if (lacpdu && port) {
-		struct port_params *partner = &port->partner_oper;
-
-		__choose_matched(lacpdu, port);
-		/* record the new parameter values for the partner
-		 * operational
-		 */
-		partner->port_number = ntohs(lacpdu->actor_port);
-		partner->port_priority = ntohs(lacpdu->actor_port_priority);
-		partner->system = lacpdu->actor_system;
-		partner->system_priority = ntohs(lacpdu->actor_system_priority);
-		partner->key = ntohs(lacpdu->actor_key);
-		partner->port_state = lacpdu->actor_state;
-
-		/* set actor_oper_port_state.defaulted to FALSE */
-		port->actor_oper_port_state &= ~AD_STATE_DEFAULTED;
-
-		/* set the partner sync. to on if the partner is sync,
-		 * and the port is matched
-		 */
-		if ((port->sm_vars & AD_PORT_MATCHED) &&
-		    (lacpdu->actor_state & AD_STATE_SYNCHRONIZATION)) {
-			partner->port_state |= AD_STATE_SYNCHRONIZATION;
-			slave_dbg(port->slave->bond->dev, port->slave->dev,
-				  "partner sync=1\n");
-		} else {
-			partner->port_state &= ~AD_STATE_SYNCHRONIZATION;
-			slave_dbg(port->slave->bond->dev, port->slave->dev,
-				  "partner sync=0\n");
-		}
-	}
-}
-
-/**
- * __record_default - record default parameters
- * @port: the port we're looking at
- *
- * This function records the default parameter values for the partner carried
- * in the Partner Admin parameters as the current partner operational parameter
- * values and sets actor_oper_port_state.defaulted to TRUE.
- */
-static void __record_default(struct port *port)
-{
-	if (port) {
-		/* record the partner admin parameters */
-		memcpy(&port->partner_oper, &port->partner_admin,
-		       sizeof(struct port_params));
-
-		/* set actor_oper_port_state.defaulted to true */
-		port->actor_oper_port_state |= AD_STATE_DEFAULTED;
-	}
-}
-
-/**
- * __update_selected - update a port's Selected variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Update the value of the selected variable, using parameter values from a
- * newly received lacpdu. The parameter values for the Actor carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the ports partner. If one or more of the comparisons shows that
- * the value(s) received in the PDU differ from the current operational values,
- * then selected is set to FALSE and actor_oper_port_state.synchronization is
- * set to out_of_sync. Otherwise, selected remains unchanged.
- */
-static void __update_selected(struct lacpdu *lacpdu, struct port *port)
-{
-	if (lacpdu && port) {
-		const struct port_params *partner = &port->partner_oper;
-
-		/* check if any parameter is different then
-		 * update the state machine selected variable.
-		 */
-		if (ntohs(lacpdu->actor_port) != partner->port_number ||
-		    ntohs(lacpdu->actor_port_priority) != partner->port_priority ||
-		    !MAC_ADDRESS_EQUAL(&lacpdu->actor_system, &partner->system) ||
-		    ntohs(lacpdu->actor_system_priority) != partner->system_priority ||
-		    ntohs(lacpdu->actor_key) != partner->key ||
-		    (lacpdu->actor_state & AD_STATE_AGGREGATION) != (partner->port_state & AD_STATE_AGGREGATION)) {
-			port->sm_vars &= ~AD_PORT_SELECTED;
-		}
-	}
-}
-
-/**
- * __update_default_selected - update a port's Selected variable from Partner
- * @port: the port we're looking at
- *
- * This function updates the value of the selected variable, using the partner
- * administrative parameter values. The administrative values are compared with
- * the corresponding operational parameter values for the partner. If one or
- * more of the comparisons shows that the administrative value(s) differ from
- * the current operational values, then Selected is set to FALSE and
- * actor_oper_port_state.synchronization is set to OUT_OF_SYNC. Otherwise,
- * Selected remains unchanged.
- */
-static void __update_default_selected(struct port *port)
-{
-	if (port) {
-		const struct port_params *admin = &port->partner_admin;
-		const struct port_params *oper = &port->partner_oper;
-
-		/* check if any parameter is different then
-		 * update the state machine selected variable.
-		 */
-		if (admin->port_number != oper->port_number ||
-		    admin->port_priority != oper->port_priority ||
-		    !MAC_ADDRESS_EQUAL(&admin->system, &oper->system) ||
-		    admin->system_priority != oper->system_priority ||
-		    admin->key != oper->key ||
-		    (admin->port_state & AD_STATE_AGGREGATION)
-			!= (oper->port_state & AD_STATE_AGGREGATION)) {
-			port->sm_vars &= ~AD_PORT_SELECTED;
-		}
-	}
-}
-
-/**
- * __update_ntt - update a port's ntt variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Updates the value of the ntt variable, using parameter values from a newly
- * received lacpdu. The parameter values for the partner carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the Actor. If one or more of the comparisons shows that the
- * value(s) received in the PDU differ from the current operational values,
- * then ntt is set to TRUE. Otherwise, ntt remains unchanged.
- */
-static void __update_ntt(struct lacpdu *lacpdu, struct port *port)
-{
-	/* validate lacpdu and port */
-	if (lacpdu && port) {
-		/* check if any parameter is different then
-		 * update the port->ntt.
-		 */
-		if ((ntohs(lacpdu->partner_port) != port->actor_port_number) ||
-		    (ntohs(lacpdu->partner_port_priority) != port->actor_port_priority) ||
-		    !MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) ||
-		    (ntohs(lacpdu->partner_system_priority) != port->actor_system_priority) ||
-		    (ntohs(lacpdu->partner_key) != port->actor_oper_port_key) ||
-		    ((lacpdu->partner_state & AD_STATE_LACP_ACTIVITY) != (port->actor_oper_port_state & AD_STATE_LACP_ACTIVITY)) ||
-		    ((lacpdu->partner_state & AD_STATE_LACP_TIMEOUT) != (port->actor_oper_port_state & AD_STATE_LACP_TIMEOUT)) ||
-		    ((lacpdu->partner_state & AD_STATE_SYNCHRONIZATION) != (port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION)) ||
-		    ((lacpdu->partner_state & AD_STATE_AGGREGATION) != (port->actor_oper_port_state & AD_STATE_AGGREGATION))
-		   ) {
-			port->ntt = true;
-		}
-	}
-}
-
-/**
- * __agg_ports_are_ready - check if all ports in an aggregator are ready
- * @aggregator: the aggregator we're looking at
- *
- */
-static int __agg_ports_are_ready(struct aggregator *aggregator)
-{
-	struct port *port;
-	int retval = 1;
-
-	if (aggregator) {
-		/* scan all ports in this aggregator to verfy if they are
-		 * all ready.
-		 */
-		for (port = aggregator->lag_ports;
-		     port;
-		     port = port->next_port_in_aggregator) {
-			if (!(port->sm_vars & AD_PORT_READY_N)) {
-				retval = 0;
-				break;
-			}
-		}
-	}
-
-	return retval;
-}
-
-/**
- * __set_agg_ports_ready - set value of Ready bit in all ports of an aggregator
- * @aggregator: the aggregator we're looking at
- * @val: Should the ports' ready bit be set on or off
- *
- */
-static void __set_agg_ports_ready(struct aggregator *aggregator, int val)
-{
-	struct port *port;
-
-	for (port = aggregator->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (val)
-			port->sm_vars |= AD_PORT_READY;
-		else
-			port->sm_vars &= ~AD_PORT_READY;
-	}
-}
-
-static int __agg_active_ports(struct aggregator *agg)
-{
-	struct port *port;
-	int active = 0;
-
-	for (port = agg->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (port->is_enabled)
-			active++;
-	}
-
-	return active;
-}
-
-/**
- * __get_agg_bandwidth - get the total bandwidth of an aggregator
- * @aggregator: the aggregator we're looking at
- *
- */
-static u32 __get_agg_bandwidth(struct aggregator *aggregator)
-{
-	int nports = __agg_active_ports(aggregator);
-	u32 bandwidth = 0;
-
-	if (nports) {
-		switch (__get_link_speed(aggregator->lag_ports)) {
-		case AD_LINK_SPEED_1MBPS:
-			bandwidth = nports;
-			break;
-		case AD_LINK_SPEED_10MBPS:
-			bandwidth = nports * 10;
-			break;
-		case AD_LINK_SPEED_100MBPS:
-			bandwidth = nports * 100;
-			break;
-		case AD_LINK_SPEED_1000MBPS:
-			bandwidth = nports * 1000;
-			break;
-		case AD_LINK_SPEED_2500MBPS:
-			bandwidth = nports * 2500;
-			break;
-		case AD_LINK_SPEED_5000MBPS:
-			bandwidth = nports * 5000;
-			break;
-		case AD_LINK_SPEED_10000MBPS:
-			bandwidth = nports * 10000;
-			break;
-		case AD_LINK_SPEED_14000MBPS:
-			bandwidth = nports * 14000;
-			break;
-		case AD_LINK_SPEED_20000MBPS:
-			bandwidth = nports * 20000;
-			break;
-		case AD_LINK_SPEED_25000MBPS:
-			bandwidth = nports * 25000;
-			break;
-		case AD_LINK_SPEED_40000MBPS:
-			bandwidth = nports * 40000;
-			break;
-		case AD_LINK_SPEED_50000MBPS:
-			bandwidth = nports * 50000;
-			break;
-		case AD_LINK_SPEED_56000MBPS:
-			bandwidth = nports * 56000;
-			break;
-		case AD_LINK_SPEED_100000MBPS:
-			bandwidth = nports * 100000;
-			break;
-		default:
-			bandwidth = 0; /* to silence the compiler */
-		}
-	}
-	return bandwidth;
-}
-
-/**
- * __get_active_agg - get the current active aggregator
- * @aggregator: the aggregator we're looking at
- *
- * Caller must hold RCU lock.
- */
-static struct aggregator *__get_active_agg(struct aggregator *aggregator)
-{
-	struct bonding *bond = aggregator->slave->bond;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave_rcu(bond, slave, iter)
-		if (SLAVE_AD_INFO(slave)->aggregator.is_active)
-			return &(SLAVE_AD_INFO(slave)->aggregator);
-
-	return NULL;
-}
-
-/**
- * __update_lacpdu_from_port - update a port's lacpdu fields
- * @port: the port we're looking at
- */
-static inline void __update_lacpdu_from_port(struct port *port)
-{
-	struct lacpdu *lacpdu = &port->lacpdu;
-	const struct port_params *partner = &port->partner_oper;
-
-	/* update current actual Actor parameters
-	 * lacpdu->subtype                   initialized
-	 * lacpdu->version_number            initialized
-	 * lacpdu->tlv_type_actor_info       initialized
-	 * lacpdu->actor_information_length  initialized
-	 */
-
-	lacpdu->actor_system_priority = htons(port->actor_system_priority);
-	lacpdu->actor_system = port->actor_system;
-	lacpdu->actor_key = htons(port->actor_oper_port_key);
-	lacpdu->actor_port_priority = htons(port->actor_port_priority);
-	lacpdu->actor_port = htons(port->actor_port_number);
-	lacpdu->actor_state = port->actor_oper_port_state;
-	slave_dbg(port->slave->bond->dev, port->slave->dev,
-		  "update lacpdu: actor port state %x\n",
-		  port->actor_oper_port_state);
-
-	/* lacpdu->reserved_3_1              initialized
-	 * lacpdu->tlv_type_partner_info     initialized
-	 * lacpdu->partner_information_length initialized
-	 */
-
-	lacpdu->partner_system_priority = htons(partner->system_priority);
-	lacpdu->partner_system = partner->system;
-	lacpdu->partner_key = htons(partner->key);
-	lacpdu->partner_port_priority = htons(partner->port_priority);
-	lacpdu->partner_port = htons(partner->port_number);
-	lacpdu->partner_state = partner->port_state;
-
-	/* lacpdu->reserved_3_2              initialized
-	 * lacpdu->tlv_type_collector_info   initialized
-	 * lacpdu->collector_information_length initialized
-	 * collector_max_delay                initialized
-	 * reserved_12[12]                   initialized
-	 * tlv_type_terminator               initialized
-	 * terminator_length                 initialized
-	 * reserved_50[50]                   initialized
-	 */
-}
-
-/* ================= main 802.3ad protocol code ========================= */
-
-/**
- * ad_lacpdu_send - send out a lacpdu packet on a given port
- * @port: the port we're looking at
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-static int ad_lacpdu_send(struct port *port)
-{
-	struct slave *slave = port->slave;
-	struct sk_buff *skb;
-	struct lacpdu_header *lacpdu_header;
-	int length = sizeof(struct lacpdu_header);
-
-	skb = dev_alloc_skb(length);
-	if (!skb)
-		return -ENOMEM;
-
-	atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_tx);
-	atomic64_inc(&BOND_AD_INFO(slave->bond).stats.lacpdu_tx);
-
-	skb->dev = slave->dev;
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = PKT_TYPE_LACPDU;
-	skb->priority = TC_PRIO_CONTROL;
-
-	lacpdu_header = skb_put(skb, length);
-
-	ether_addr_copy(lacpdu_header->hdr.h_dest, lacpdu_mcast_addr);
-	/* Note: source address is set to be the member's PERMANENT address,
-	 * because we use it to identify loopback lacpdus in receive.
-	 */
-	ether_addr_copy(lacpdu_header->hdr.h_source, slave->perm_hwaddr);
-	lacpdu_header->hdr.h_proto = PKT_TYPE_LACPDU;
-
-	lacpdu_header->lacpdu = port->lacpdu;
-
-	dev_queue_xmit(skb);
-
-	return 0;
-}
-
-/**
- * ad_marker_send - send marker information/response on a given port
- * @port: the port we're looking at
- * @marker: marker data to send
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-static int ad_marker_send(struct port *port, struct bond_marker *marker)
-{
-	struct slave *slave = port->slave;
-	struct sk_buff *skb;
-	struct bond_marker_header *marker_header;
-	int length = sizeof(struct bond_marker_header);
-
-	skb = dev_alloc_skb(length + 16);
-	if (!skb)
-		return -ENOMEM;
-
-	switch (marker->tlv_type) {
-	case AD_MARKER_INFORMATION_SUBTYPE:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.marker_tx);
-		atomic64_inc(&BOND_AD_INFO(slave->bond).stats.marker_tx);
-		break;
-	case AD_MARKER_RESPONSE_SUBTYPE:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.marker_resp_tx);
-		atomic64_inc(&BOND_AD_INFO(slave->bond).stats.marker_resp_tx);
-		break;
-	}
-
-	skb_reserve(skb, 16);
-
-	skb->dev = slave->dev;
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = PKT_TYPE_LACPDU;
-
-	marker_header = skb_put(skb, length);
-
-	ether_addr_copy(marker_header->hdr.h_dest, lacpdu_mcast_addr);
-	/* Note: source address is set to be the member's PERMANENT address,
-	 * because we use it to identify loopback MARKERs in receive.
-	 */
-	ether_addr_copy(marker_header->hdr.h_source, slave->perm_hwaddr);
-	marker_header->hdr.h_proto = PKT_TYPE_LACPDU;
-
-	marker_header->marker = *marker;
-
-	dev_queue_xmit(skb);
-
-	return 0;
-}
-
-/**
- * ad_mux_machine - handle a port's mux state machine
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- */
-static void ad_mux_machine(struct port *port, bool *update_slave_arr)
-{
-	mux_states_t last_state;
-
-	/* keep current State Machine state to compare later if it was
-	 * changed
-	 */
-	last_state = port->sm_mux_state;
-
-	if (port->sm_vars & AD_PORT_BEGIN) {
-		port->sm_mux_state = AD_MUX_DETACHED;
-	} else {
-		switch (port->sm_mux_state) {
-		case AD_MUX_DETACHED:
-			if ((port->sm_vars & AD_PORT_SELECTED)
-			    || (port->sm_vars & AD_PORT_STANDBY))
-				/* if SELECTED or STANDBY */
-				port->sm_mux_state = AD_MUX_WAITING;
-			break;
-		case AD_MUX_WAITING:
-			/* if SELECTED == FALSE return to DETACH state */
-			if (!(port->sm_vars & AD_PORT_SELECTED)) {
-				port->sm_vars &= ~AD_PORT_READY_N;
-				/* in order to withhold the Selection Logic to
-				 * check all ports READY_N value every callback
-				 * cycle to update ready variable, we check
-				 * READY_N and update READY here
-				 */
-				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-				port->sm_mux_state = AD_MUX_DETACHED;
-				break;
-			}
-
-			/* check if the wait_while_timer expired */
-			if (port->sm_mux_timer_counter
-			    && !(--port->sm_mux_timer_counter))
-				port->sm_vars |= AD_PORT_READY_N;
-
-			/* in order to withhold the selection logic to check
-			 * all ports READY_N value every callback cycle to
-			 * update ready variable, we check READY_N and update
-			 * READY here
-			 */
-			__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-
-			/* if the wait_while_timer expired, and the port is
-			 * in READY state, move to ATTACHED state
-			 */
-			if ((port->sm_vars & AD_PORT_READY)
-			    && !port->sm_mux_timer_counter)
-				port->sm_mux_state = AD_MUX_ATTACHED;
-			break;
-		case AD_MUX_ATTACHED:
-			/* check also if agg_select_timer expired (so the
-			 * edable port will take place only after this timer)
-			 */
-			if ((port->sm_vars & AD_PORT_SELECTED) &&
-			    (port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) &&
-			    !__check_agg_selection_timer(port)) {
-				if (port->aggregator->is_active)
-					port->sm_mux_state =
-					    AD_MUX_COLLECTING_DISTRIBUTING;
-			} else if (!(port->sm_vars & AD_PORT_SELECTED) ||
-				   (port->sm_vars & AD_PORT_STANDBY)) {
-				/* if UNSELECTED or STANDBY */
-				port->sm_vars &= ~AD_PORT_READY_N;
-				/* in order to withhold the selection logic to
-				 * check all ports READY_N value every callback
-				 * cycle to update ready variable, we check
-				 * READY_N and update READY here
-				 */
-				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-				port->sm_mux_state = AD_MUX_DETACHED;
-			} else if (port->aggregator->is_active) {
-				port->actor_oper_port_state |=
-				    AD_STATE_SYNCHRONIZATION;
-			}
-			break;
-		case AD_MUX_COLLECTING_DISTRIBUTING:
-			if (!(port->sm_vars & AD_PORT_SELECTED) ||
-			    (port->sm_vars & AD_PORT_STANDBY) ||
-			    !(port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) ||
-			    !(port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION)) {
-				port->sm_mux_state = AD_MUX_ATTACHED;
-			} else {
-				/* if port state hasn't changed make
-				 * sure that a collecting distributing
-				 * port in an active aggregator is enabled
-				 */
-				if (port->aggregator &&
-				    port->aggregator->is_active &&
-				    !__port_is_enabled(port)) {
-
-					__enable_port(port);
-				}
-			}
-			break;
-		default:
-			break;
-		}
-	}
-
-	/* check if the state machine was changed */
-	if (port->sm_mux_state != last_state) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Mux Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number,
-			  last_state,
-			  port->sm_mux_state);
-		switch (port->sm_mux_state) {
-		case AD_MUX_DETACHED:
-			port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
-			ad_disable_collecting_distributing(port,
-							   update_slave_arr);
-			port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
-			port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
-			port->ntt = true;
-			break;
-		case AD_MUX_WAITING:
-			port->sm_mux_timer_counter = __ad_timer_to_ticks(AD_WAIT_WHILE_TIMER, 0);
-			break;
-		case AD_MUX_ATTACHED:
-			if (port->aggregator->is_active)
-				port->actor_oper_port_state |=
-				    AD_STATE_SYNCHRONIZATION;
-			else
-				port->actor_oper_port_state &=
-				    ~AD_STATE_SYNCHRONIZATION;
-			port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
-			port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
-			ad_disable_collecting_distributing(port,
-							   update_slave_arr);
-			port->ntt = true;
-			break;
-		case AD_MUX_COLLECTING_DISTRIBUTING:
-			port->actor_oper_port_state |= AD_STATE_COLLECTING;
-			port->actor_oper_port_state |= AD_STATE_DISTRIBUTING;
-			port->actor_oper_port_state |= AD_STATE_SYNCHRONIZATION;
-			ad_enable_collecting_distributing(port,
-							  update_slave_arr);
-			port->ntt = true;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_rx_machine - handle a port's rx State Machine
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * If lacpdu arrived, stop previous timer (if exists) and set the next state as
- * CURRENT. If timer expired set the state machine in the proper state.
- * In other cases, this function checks if we need to switch to other state.
- */
-static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port)
-{
-	rx_states_t last_state;
-
-	/* keep current State Machine state to compare later if it was
-	 * changed
-	 */
-	last_state = port->sm_rx_state;
-
-	if (lacpdu) {
-		atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.lacpdu_rx);
-		atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.lacpdu_rx);
-	}
-	/* check if state machine should change state */
-
-	/* first, check if port was reinitialized */
-	if (port->sm_vars & AD_PORT_BEGIN) {
-		port->sm_rx_state = AD_RX_INITIALIZE;
-		port->sm_vars |= AD_PORT_CHURNED;
-	/* check if port is not enabled */
-	} else if (!(port->sm_vars & AD_PORT_BEGIN) && !port->is_enabled)
-		port->sm_rx_state = AD_RX_PORT_DISABLED;
-	/* check if new lacpdu arrived */
-	else if (lacpdu && ((port->sm_rx_state == AD_RX_EXPIRED) ||
-		 (port->sm_rx_state == AD_RX_DEFAULTED) ||
-		 (port->sm_rx_state == AD_RX_CURRENT))) {
-		if (port->sm_rx_state != AD_RX_CURRENT)
-			port->sm_vars |= AD_PORT_CHURNED;
-		port->sm_rx_timer_counter = 0;
-		port->sm_rx_state = AD_RX_CURRENT;
-	} else {
-		/* if timer is on, and if it is expired */
-		if (port->sm_rx_timer_counter &&
-		    !(--port->sm_rx_timer_counter)) {
-			switch (port->sm_rx_state) {
-			case AD_RX_EXPIRED:
-				port->sm_rx_state = AD_RX_DEFAULTED;
-				break;
-			case AD_RX_CURRENT:
-				port->sm_rx_state = AD_RX_EXPIRED;
-				break;
-			default:
-				break;
-			}
-		} else {
-			/* if no lacpdu arrived and no timer is on */
-			switch (port->sm_rx_state) {
-			case AD_RX_PORT_DISABLED:
-				if (port->is_enabled &&
-				    (port->sm_vars & AD_PORT_LACP_ENABLED))
-					port->sm_rx_state = AD_RX_EXPIRED;
-				else if (port->is_enabled
-					 && ((port->sm_vars
-					      & AD_PORT_LACP_ENABLED) == 0))
-					port->sm_rx_state = AD_RX_LACP_DISABLED;
-				break;
-			default:
-				break;
-
-			}
-		}
-	}
-
-	/* check if the State machine was changed or new lacpdu arrived */
-	if ((port->sm_rx_state != last_state) || (lacpdu)) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Rx Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number,
-			  last_state,
-			  port->sm_rx_state);
-		switch (port->sm_rx_state) {
-		case AD_RX_INITIALIZE:
-			if (!(port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS))
-				port->sm_vars &= ~AD_PORT_LACP_ENABLED;
-			else
-				port->sm_vars |= AD_PORT_LACP_ENABLED;
-			port->sm_vars &= ~AD_PORT_SELECTED;
-			__record_default(port);
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			port->sm_rx_state = AD_RX_PORT_DISABLED;
-
-			/* Fall Through */
-		case AD_RX_PORT_DISABLED:
-			port->sm_vars &= ~AD_PORT_MATCHED;
-			break;
-		case AD_RX_LACP_DISABLED:
-			port->sm_vars &= ~AD_PORT_SELECTED;
-			__record_default(port);
-			port->partner_oper.port_state &= ~AD_STATE_AGGREGATION;
-			port->sm_vars |= AD_PORT_MATCHED;
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			break;
-		case AD_RX_EXPIRED:
-			/* Reset of the Synchronization flag (Standard 43.4.12)
-			 * This reset cause to disable this port in the
-			 * COLLECTING_DISTRIBUTING state of the mux machine in
-			 * case of EXPIRED even if LINK_DOWN didn't arrive for
-			 * the port.
-			 */
-			port->partner_oper.port_state &= ~AD_STATE_SYNCHRONIZATION;
-			port->sm_vars &= ~AD_PORT_MATCHED;
-			port->partner_oper.port_state |= AD_STATE_LACP_TIMEOUT;
-			port->partner_oper.port_state |= AD_STATE_LACP_ACTIVITY;
-			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(AD_SHORT_TIMEOUT));
-			port->actor_oper_port_state |= AD_STATE_EXPIRED;
-			port->sm_vars |= AD_PORT_CHURNED;
-			break;
-		case AD_RX_DEFAULTED:
-			__update_default_selected(port);
-			__record_default(port);
-			port->sm_vars |= AD_PORT_MATCHED;
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			break;
-		case AD_RX_CURRENT:
-			/* detect loopback situation */
-			if (MAC_ADDRESS_EQUAL(&(lacpdu->actor_system),
-					      &(port->actor_system))) {
-				slave_err(port->slave->bond->dev, port->slave->dev, "An illegal loopback occurred on slave\n"
-					  "Check the configuration to verify that all adapters are connected to 802.3ad compliant switch ports\n");
-				return;
-			}
-			__update_selected(lacpdu, port);
-			__update_ntt(lacpdu, port);
-			__record_pdu(lacpdu, port);
-			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(port->actor_oper_port_state & AD_STATE_LACP_TIMEOUT));
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_churn_machine - handle port churn's state machine
- * @port: the port we're looking at
- *
- */
-static void ad_churn_machine(struct port *port)
-{
-	if (port->sm_vars & AD_PORT_CHURNED) {
-		port->sm_vars &= ~AD_PORT_CHURNED;
-		port->sm_churn_actor_state = AD_CHURN_MONITOR;
-		port->sm_churn_partner_state = AD_CHURN_MONITOR;
-		port->sm_churn_actor_timer_counter =
-			__ad_timer_to_ticks(AD_ACTOR_CHURN_TIMER, 0);
-		port->sm_churn_partner_timer_counter =
-			 __ad_timer_to_ticks(AD_PARTNER_CHURN_TIMER, 0);
-		return;
-	}
-	if (port->sm_churn_actor_timer_counter &&
-	    !(--port->sm_churn_actor_timer_counter) &&
-	    port->sm_churn_actor_state == AD_CHURN_MONITOR) {
-		if (port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION) {
-			port->sm_churn_actor_state = AD_NO_CHURN;
-		} else {
-			port->churn_actor_count++;
-			port->sm_churn_actor_state = AD_CHURN;
-		}
-	}
-	if (port->sm_churn_partner_timer_counter &&
-	    !(--port->sm_churn_partner_timer_counter) &&
-	    port->sm_churn_partner_state == AD_CHURN_MONITOR) {
-		if (port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) {
-			port->sm_churn_partner_state = AD_NO_CHURN;
-		} else {
-			port->churn_partner_count++;
-			port->sm_churn_partner_state = AD_CHURN;
-		}
-	}
-}
-
-/**
- * ad_tx_machine - handle a port's tx state machine
- * @port: the port we're looking at
- */
-static void ad_tx_machine(struct port *port)
-{
-	/* check if tx timer expired, to verify that we do not send more than
-	 * 3 packets per second
-	 */
-	if (port->sm_tx_timer_counter && !(--port->sm_tx_timer_counter)) {
-		/* check if there is something to send */
-		if (port->ntt && (port->sm_vars & AD_PORT_LACP_ENABLED)) {
-			__update_lacpdu_from_port(port);
-
-			if (ad_lacpdu_send(port) >= 0) {
-				slave_dbg(port->slave->bond->dev,
-					  port->slave->dev,
-					  "Sent LACPDU on port %d\n",
-					  port->actor_port_number);
-
-				/* mark ntt as false, so it will not be sent
-				 * again until demanded
-				 */
-				port->ntt = false;
-			}
-		}
-		/* restart tx timer(to verify that we will not exceed
-		 * AD_MAX_TX_IN_SECOND
-		 */
-		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
-	}
-}
-
-/**
- * ad_periodic_machine - handle a port's periodic state machine
- * @port: the port we're looking at
- *
- * Turn ntt flag on priodically to perform periodic transmission of lacpdu's.
- */
-static void ad_periodic_machine(struct port *port)
-{
-	periodic_states_t last_state;
-
-	/* keep current state machine state to compare later if it was changed */
-	last_state = port->sm_periodic_state;
-
-	/* check if port was reinitialized */
-	if (((port->sm_vars & AD_PORT_BEGIN) || !(port->sm_vars & AD_PORT_LACP_ENABLED) || !port->is_enabled) ||
-	    (!(port->actor_oper_port_state & AD_STATE_LACP_ACTIVITY) && !(port->partner_oper.port_state & AD_STATE_LACP_ACTIVITY))
-	   ) {
-		port->sm_periodic_state = AD_NO_PERIODIC;
-	}
-	/* check if state machine should change state */
-	else if (port->sm_periodic_timer_counter) {
-		/* check if periodic state machine expired */
-		if (!(--port->sm_periodic_timer_counter)) {
-			/* if expired then do tx */
-			port->sm_periodic_state = AD_PERIODIC_TX;
-		} else {
-			/* If not expired, check if there is some new timeout
-			 * parameter from the partner state
-			 */
-			switch (port->sm_periodic_state) {
-			case AD_FAST_PERIODIC:
-				if (!(port->partner_oper.port_state
-				      & AD_STATE_LACP_TIMEOUT))
-					port->sm_periodic_state = AD_SLOW_PERIODIC;
-				break;
-			case AD_SLOW_PERIODIC:
-				if ((port->partner_oper.port_state & AD_STATE_LACP_TIMEOUT)) {
-					port->sm_periodic_timer_counter = 0;
-					port->sm_periodic_state = AD_PERIODIC_TX;
-				}
-				break;
-			default:
-				break;
-			}
-		}
-	} else {
-		switch (port->sm_periodic_state) {
-		case AD_NO_PERIODIC:
-			port->sm_periodic_state = AD_FAST_PERIODIC;
-			break;
-		case AD_PERIODIC_TX:
-			if (!(port->partner_oper.port_state &
-			    AD_STATE_LACP_TIMEOUT))
-				port->sm_periodic_state = AD_SLOW_PERIODIC;
-			else
-				port->sm_periodic_state = AD_FAST_PERIODIC;
-			break;
-		default:
-			break;
-		}
-	}
-
-	/* check if the state machine was changed */
-	if (port->sm_periodic_state != last_state) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Periodic Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number, last_state,
-			  port->sm_periodic_state);
-		switch (port->sm_periodic_state) {
-		case AD_NO_PERIODIC:
-			port->sm_periodic_timer_counter = 0;
-			break;
-		case AD_FAST_PERIODIC:
-			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
-			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_FAST_PERIODIC_TIME))-1;
-			break;
-		case AD_SLOW_PERIODIC:
-			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
-			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_SLOW_PERIODIC_TIME))-1;
-			break;
-		case AD_PERIODIC_TX:
-			port->ntt = true;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_port_selection_logic - select aggregation groups
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * Select aggregation groups, and assign each port for it's aggregetor. The
- * selection logic is called in the inititalization (after all the handshkes),
- * and after every lacpdu receive (if selected is off).
- */
-static void ad_port_selection_logic(struct port *port, bool *update_slave_arr)
-{
-	struct aggregator *aggregator, *free_aggregator = NULL, *temp_aggregator;
-	struct port *last_port = NULL, *curr_port;
-	struct list_head *iter;
-	struct bonding *bond;
-	struct slave *slave;
-	int found = 0;
-
-	/* if the port is already Selected, do nothing */
-	if (port->sm_vars & AD_PORT_SELECTED)
-		return;
-
-	bond = __get_bond_by_port(port);
-
-	/* if the port is connected to other aggregator, detach it */
-	if (port->aggregator) {
-		/* detach the port from its former aggregator */
-		temp_aggregator = port->aggregator;
-		for (curr_port = temp_aggregator->lag_ports; curr_port;
-		     last_port = curr_port,
-		     curr_port = curr_port->next_port_in_aggregator) {
-			if (curr_port == port) {
-				temp_aggregator->num_of_ports--;
-				/* if it is the first port attached to the
-				 * aggregator
-				 */
-				if (!last_port) {
-					temp_aggregator->lag_ports =
-						port->next_port_in_aggregator;
-				} else {
-					/* not the first port attached to the
-					 * aggregator
-					 */
-					last_port->next_port_in_aggregator =
-						port->next_port_in_aggregator;
-				}
-
-				/* clear the port's relations to this
-				 * aggregator
-				 */
-				port->aggregator = NULL;
-				port->next_port_in_aggregator = NULL;
-				port->actor_port_aggregator_identifier = 0;
-
-				slave_dbg(bond->dev, port->slave->dev, "Port %d left LAG %d\n",
-					  port->actor_port_number,
-					  temp_aggregator->aggregator_identifier);
-				/* if the aggregator is empty, clear its
-				 * parameters, and set it ready to be attached
-				 */
-				if (!temp_aggregator->lag_ports)
-					ad_clear_agg(temp_aggregator);
-				break;
-			}
-		}
-		if (!curr_port) {
-			/* meaning: the port was related to an aggregator
-			 * but was not on the aggregator port list
-			 */
-			net_warn_ratelimited("%s: (slave %s): Warning: Port %d was related to aggregator %d but was not on its port list\n",
-					     port->slave->bond->dev->name,
-					     port->slave->dev->name,
-					     port->actor_port_number,
-					     port->aggregator->aggregator_identifier);
-		}
-	}
-	/* search on all aggregators for a suitable aggregator for this port */
-	bond_for_each_slave(bond, slave, iter) {
-		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		/* keep a free aggregator for later use(if needed) */
-		if (!aggregator->lag_ports) {
-			if (!free_aggregator)
-				free_aggregator = aggregator;
-			continue;
-		}
-		/* check if current aggregator suits us */
-		if (((aggregator->actor_oper_aggregator_key == port->actor_oper_port_key) && /* if all parameters match AND */
-		     MAC_ADDRESS_EQUAL(&(aggregator->partner_system), &(port->partner_oper.system)) &&
-		     (aggregator->partner_system_priority == port->partner_oper.system_priority) &&
-		     (aggregator->partner_oper_aggregator_key == port->partner_oper.key)
-		    ) &&
-		    ((!MAC_ADDRESS_EQUAL(&(port->partner_oper.system), &(null_mac_addr)) && /* partner answers */
-		      !aggregator->is_individual)  /* but is not individual OR */
-		    )
-		   ) {
-			/* attach to the founded aggregator */
-			port->aggregator = aggregator;
-			port->actor_port_aggregator_identifier =
-				port->aggregator->aggregator_identifier;
-			port->next_port_in_aggregator = aggregator->lag_ports;
-			port->aggregator->num_of_ports++;
-			aggregator->lag_ports = port;
-			slave_dbg(bond->dev, slave->dev, "Port %d joined LAG %d (existing LAG)\n",
-				  port->actor_port_number,
-				  port->aggregator->aggregator_identifier);
-
-			/* mark this port as selected */
-			port->sm_vars |= AD_PORT_SELECTED;
-			found = 1;
-			break;
-		}
-	}
-
-	/* the port couldn't find an aggregator - attach it to a new
-	 * aggregator
-	 */
-	if (!found) {
-		if (free_aggregator) {
-			/* assign port a new aggregator */
-			port->aggregator = free_aggregator;
-			port->actor_port_aggregator_identifier =
-				port->aggregator->aggregator_identifier;
-
-			/* update the new aggregator's parameters
-			 * if port was responsed from the end-user
-			 */
-			if (port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS)
-				/* if port is full duplex */
-				port->aggregator->is_individual = false;
-			else
-				port->aggregator->is_individual = true;
-
-			port->aggregator->actor_admin_aggregator_key =
-				port->actor_admin_port_key;
-			port->aggregator->actor_oper_aggregator_key =
-				port->actor_oper_port_key;
-			port->aggregator->partner_system =
-				port->partner_oper.system;
-			port->aggregator->partner_system_priority =
-				port->partner_oper.system_priority;
-			port->aggregator->partner_oper_aggregator_key = port->partner_oper.key;
-			port->aggregator->receive_state = 1;
-			port->aggregator->transmit_state = 1;
-			port->aggregator->lag_ports = port;
-			port->aggregator->num_of_ports++;
-
-			/* mark this port as selected */
-			port->sm_vars |= AD_PORT_SELECTED;
-
-			slave_dbg(bond->dev, port->slave->dev, "Port %d joined LAG %d (new LAG)\n",
-				  port->actor_port_number,
-				  port->aggregator->aggregator_identifier);
-		} else {
-			slave_err(bond->dev, port->slave->dev,
-				  "Port %d did not find a suitable aggregator\n",
-				  port->actor_port_number);
-		}
-	}
-	/* if all aggregator's ports are READY_N == TRUE, set ready=TRUE
-	 * in all aggregator's ports, else set ready=FALSE in all
-	 * aggregator's ports
-	 */
-	__set_agg_ports_ready(port->aggregator,
-			      __agg_ports_are_ready(port->aggregator));
-
-	aggregator = __get_first_agg(port);
-	ad_agg_selection_logic(aggregator, update_slave_arr);
-
-	if (!port->aggregator->is_active)
-		port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
-}
-
-/* Decide if "agg" is a better choice for the new active aggregator that
- * the current best, according to the ad_select policy.
- */
-static struct aggregator *ad_agg_selection_test(struct aggregator *best,
-						struct aggregator *curr)
-{
-	/* 0. If no best, select current.
-	 *
-	 * 1. If the current agg is not individual, and the best is
-	 *    individual, select current.
-	 *
-	 * 2. If current agg is individual and the best is not, keep best.
-	 *
-	 * 3. Therefore, current and best are both individual or both not
-	 *    individual, so:
-	 *
-	 * 3a. If current agg partner replied, and best agg partner did not,
-	 *     select current.
-	 *
-	 * 3b. If current agg partner did not reply and best agg partner
-	 *     did reply, keep best.
-	 *
-	 * 4.  Therefore, current and best both have partner replies or
-	 *     both do not, so perform selection policy:
-	 *
-	 * BOND_AD_COUNT: Select by count of ports.  If count is equal,
-	 *     select by bandwidth.
-	 *
-	 * BOND_AD_STABLE, BOND_AD_BANDWIDTH: Select by bandwidth.
-	 */
-	if (!best)
-		return curr;
-
-	if (!curr->is_individual && best->is_individual)
-		return curr;
-
-	if (curr->is_individual && !best->is_individual)
-		return best;
-
-	if (__agg_has_partner(curr) && !__agg_has_partner(best))
-		return curr;
-
-	if (!__agg_has_partner(curr) && __agg_has_partner(best))
-		return best;
-
-	switch (__get_agg_selection_mode(curr->lag_ports)) {
-	case BOND_AD_COUNT:
-		if (__agg_active_ports(curr) > __agg_active_ports(best))
-			return curr;
-
-		if (__agg_active_ports(curr) < __agg_active_ports(best))
-			return best;
-
-		/*FALLTHROUGH*/
-	case BOND_AD_STABLE:
-	case BOND_AD_BANDWIDTH:
-		if (__get_agg_bandwidth(curr) > __get_agg_bandwidth(best))
-			return curr;
-
-		break;
-
-	default:
-		net_warn_ratelimited("%s: (slave %s): Impossible agg select mode %d\n",
-				     curr->slave->bond->dev->name,
-				     curr->slave->dev->name,
-				     __get_agg_selection_mode(curr->lag_ports));
-		break;
-	}
-
-	return best;
-}
-
-static int agg_device_up(const struct aggregator *agg)
-{
-	struct port *port = agg->lag_ports;
-
-	if (!port)
-		return 0;
-
-	for (port = agg->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (netif_running(port->slave->dev) &&
-		    netif_carrier_ok(port->slave->dev))
-			return 1;
-	}
-
-	return 0;
-}
-
-/**
- * ad_agg_selection_logic - select an aggregation group for a team
- * @aggregator: the aggregator we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * It is assumed that only one aggregator may be selected for a team.
- *
- * The logic of this function is to select the aggregator according to
- * the ad_select policy:
- *
- * BOND_AD_STABLE: select the aggregator with the most ports attached to
- * it, and to reselect the active aggregator only if the previous
- * aggregator has no more ports related to it.
- *
- * BOND_AD_BANDWIDTH: select the aggregator with the highest total
- * bandwidth, and reselect whenever a link state change takes place or the
- * set of slaves in the bond changes.
- *
- * BOND_AD_COUNT: select the aggregator with largest number of ports
- * (slaves), and reselect whenever a link state change takes place or the
- * set of slaves in the bond changes.
- *
- * FIXME: this function MUST be called with the first agg in the bond, or
- * __get_active_agg() won't work correctly. This function should be better
- * called with the bond itself, and retrieve the first agg from it.
- */
-static void ad_agg_selection_logic(struct aggregator *agg,
-				   bool *update_slave_arr)
-{
-	struct aggregator *best, *active, *origin;
-	struct bonding *bond = agg->slave->bond;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-
-	rcu_read_lock();
-	origin = agg;
-	active = __get_active_agg(agg);
-	best = (active && agg_device_up(active)) ? active : NULL;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		agg = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		agg->is_active = 0;
-
-		if (__agg_active_ports(agg) && agg_device_up(agg))
-			best = ad_agg_selection_test(best, agg);
-	}
-
-	if (best &&
-	    __get_agg_selection_mode(best->lag_ports) == BOND_AD_STABLE) {
-		/* For the STABLE policy, don't replace the old active
-		 * aggregator if it's still active (it has an answering
-		 * partner) or if both the best and active don't have an
-		 * answering partner.
-		 */
-		if (active && active->lag_ports &&
-		    __agg_active_ports(active) &&
-		    (__agg_has_partner(active) ||
-		     (!__agg_has_partner(active) &&
-		     !__agg_has_partner(best)))) {
-			if (!(!active->actor_oper_aggregator_key &&
-			      best->actor_oper_aggregator_key)) {
-				best = NULL;
-				active->is_active = 1;
-			}
-		}
-	}
-
-	if (best && (best == active)) {
-		best = NULL;
-		active->is_active = 1;
-	}
-
-	/* if there is new best aggregator, activate it */
-	if (best) {
-		netdev_dbg(bond->dev, "(slave %s): best Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier, best->num_of_ports,
-			   best->actor_oper_aggregator_key,
-			   best->partner_oper_aggregator_key,
-			   best->is_individual, best->is_active);
-		netdev_dbg(bond->dev, "(slave %s): best ports %p slave %p\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->lag_ports, best->slave);
-
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			agg = &(SLAVE_AD_INFO(slave)->aggregator);
-
-			slave_dbg(bond->dev, slave->dev, "Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-				  agg->aggregator_identifier, agg->num_of_ports,
-				  agg->actor_oper_aggregator_key,
-				  agg->partner_oper_aggregator_key,
-				  agg->is_individual, agg->is_active);
-		}
-
-		/* check if any partner replies */
-		if (best->is_individual)
-			net_warn_ratelimited("%s: Warning: No 802.3ad response from the link partner for any adapters in the bond\n",
-					     bond->dev->name);
-
-		best->is_active = 1;
-		netdev_dbg(bond->dev, "(slave %s): LAG %d chosen as the active LAG\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier);
-		netdev_dbg(bond->dev, "(slave %s): Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier, best->num_of_ports,
-			   best->actor_oper_aggregator_key,
-			   best->partner_oper_aggregator_key,
-			   best->is_individual, best->is_active);
-
-		/* disable the ports that were related to the former
-		 * active_aggregator
-		 */
-		if (active) {
-			for (port = active->lag_ports; port;
-			     port = port->next_port_in_aggregator) {
-				__disable_port(port);
-			}
-		}
-		/* Slave array needs update. */
-		*update_slave_arr = true;
-	}
-
-	/* if the selected aggregator is of join individuals
-	 * (partner_system is NULL), enable their ports
-	 */
-	active = __get_active_agg(origin);
-
-	if (active) {
-		if (!__agg_has_partner(active)) {
-			for (port = active->lag_ports; port;
-			     port = port->next_port_in_aggregator) {
-				__enable_port(port);
-			}
-		}
-	}
-
-	rcu_read_unlock();
-
-	bond_3ad_set_carrier(bond);
-}
-
-/**
- * ad_clear_agg - clear a given aggregator's parameters
- * @aggregator: the aggregator we're looking at
- */
-static void ad_clear_agg(struct aggregator *aggregator)
-{
-	if (aggregator) {
-		aggregator->is_individual = false;
-		aggregator->actor_admin_aggregator_key = 0;
-		aggregator->actor_oper_aggregator_key = 0;
-		eth_zero_addr(aggregator->partner_system.mac_addr_value);
-		aggregator->partner_system_priority = 0;
-		aggregator->partner_oper_aggregator_key = 0;
-		aggregator->receive_state = 0;
-		aggregator->transmit_state = 0;
-		aggregator->lag_ports = NULL;
-		aggregator->is_active = 0;
-		aggregator->num_of_ports = 0;
-		pr_debug("%s: LAG %d was cleared\n",
-			 aggregator->slave ?
-			 aggregator->slave->dev->name : "NULL",
-			 aggregator->aggregator_identifier);
-	}
-}
-
-/**
- * ad_initialize_agg - initialize a given aggregator's parameters
- * @aggregator: the aggregator we're looking at
- */
-static void ad_initialize_agg(struct aggregator *aggregator)
-{
-	if (aggregator) {
-		ad_clear_agg(aggregator);
-
-		eth_zero_addr(aggregator->aggregator_mac_address.mac_addr_value);
-		aggregator->aggregator_identifier = 0;
-		aggregator->slave = NULL;
-	}
-}
-
-/**
- * ad_initialize_port - initialize a given port's parameters
- * @aggregator: the aggregator we're looking at
- * @lacp_fast: boolean. whether fast periodic should be used
- */
-static void ad_initialize_port(struct port *port, int lacp_fast)
-{
-	static const struct port_params tmpl = {
-		.system_priority = 0xffff,
-		.key             = 1,
-		.port_number     = 1,
-		.port_priority   = 0xff,
-		.port_state      = 1,
-	};
-	static const struct lacpdu lacpdu = {
-		.subtype		= 0x01,
-		.version_number = 0x01,
-		.tlv_type_actor_info = 0x01,
-		.actor_information_length = 0x14,
-		.tlv_type_partner_info = 0x02,
-		.partner_information_length = 0x14,
-		.tlv_type_collector_info = 0x03,
-		.collector_information_length = 0x10,
-		.collector_max_delay = htons(AD_COLLECTOR_MAX_DELAY),
-	};
-
-	if (port) {
-		port->actor_port_priority = 0xff;
-		port->actor_port_aggregator_identifier = 0;
-		port->ntt = false;
-		port->actor_admin_port_state = AD_STATE_AGGREGATION |
-					       AD_STATE_LACP_ACTIVITY;
-		port->actor_oper_port_state  = AD_STATE_AGGREGATION |
-					       AD_STATE_LACP_ACTIVITY;
-
-		if (lacp_fast)
-			port->actor_oper_port_state |= AD_STATE_LACP_TIMEOUT;
-
-		memcpy(&port->partner_admin, &tmpl, sizeof(tmpl));
-		memcpy(&port->partner_oper, &tmpl, sizeof(tmpl));
-
-		port->is_enabled = true;
-		/* private parameters */
-		port->sm_vars = AD_PORT_BEGIN | AD_PORT_LACP_ENABLED;
-		port->sm_rx_state = 0;
-		port->sm_rx_timer_counter = 0;
-		port->sm_periodic_state = 0;
-		port->sm_periodic_timer_counter = 0;
-		port->sm_mux_state = 0;
-		port->sm_mux_timer_counter = 0;
-		port->sm_tx_state = 0;
-		port->aggregator = NULL;
-		port->next_port_in_aggregator = NULL;
-		port->transaction_id = 0;
-
-		port->sm_churn_actor_timer_counter = 0;
-		port->sm_churn_actor_state = 0;
-		port->churn_actor_count = 0;
-		port->sm_churn_partner_timer_counter = 0;
-		port->sm_churn_partner_state = 0;
-		port->churn_partner_count = 0;
-
-		memcpy(&port->lacpdu, &lacpdu, sizeof(lacpdu));
-	}
-}
-
-/**
- * ad_enable_collecting_distributing - enable a port's transmit/receive
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * Enable @port if it's in an active aggregator
- */
-static void ad_enable_collecting_distributing(struct port *port,
-					      bool *update_slave_arr)
-{
-	if (port->aggregator->is_active) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Enabling port %d (LAG %d)\n",
-			  port->actor_port_number,
-			  port->aggregator->aggregator_identifier);
-		__enable_port(port);
-		/* Slave array needs update */
-		*update_slave_arr = true;
-	}
-}
-
-/**
- * ad_disable_collecting_distributing - disable a port's transmit/receive
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- */
-static void ad_disable_collecting_distributing(struct port *port,
-					       bool *update_slave_arr)
-{
-	if (port->aggregator &&
-	    !MAC_ADDRESS_EQUAL(&(port->aggregator->partner_system),
-			       &(null_mac_addr))) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Disabling port %d (LAG %d)\n",
-			  port->actor_port_number,
-			  port->aggregator->aggregator_identifier);
-		__disable_port(port);
-		/* Slave array needs an update */
-		*update_slave_arr = true;
-	}
-}
-
-/**
- * ad_marker_info_received - handle receive of a Marker information frame
- * @marker_info: Marker info received
- * @port: the port we're looking at
- */
-static void ad_marker_info_received(struct bond_marker *marker_info,
-				    struct port *port)
-{
-	struct bond_marker marker;
-
-	atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.marker_rx);
-	atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.marker_rx);
-
-	/* copy the received marker data to the response marker */
-	memcpy(&marker, marker_info, sizeof(struct bond_marker));
-	/* change the marker subtype to marker response */
-	marker.tlv_type = AD_MARKER_RESPONSE_SUBTYPE;
-
-	/* send the marker response */
-	if (ad_marker_send(port, &marker) >= 0)
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Sent Marker Response on port %d\n",
-			  port->actor_port_number);
-}
-
-/**
- * ad_marker_response_received - handle receive of a marker response frame
- * @marker: marker PDU received
- * @port: the port we're looking at
- *
- * This function does nothing since we decided not to implement send and handle
- * response for marker PDU's, in this stage, but only to respond to marker
- * information.
- */
-static void ad_marker_response_received(struct bond_marker *marker,
-					struct port *port)
-{
-	atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.marker_resp_rx);
-	atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.marker_resp_rx);
-
-	/* DO NOTHING, SINCE WE DECIDED NOT TO IMPLEMENT THIS FEATURE FOR NOW */
-}
-
-/* ========= AD exported functions to the main bonding code ========= */
-
-/* Check aggregators status in team every T seconds */
-#define AD_AGGREGATOR_SELECTION_TIMER  8
-
-/**
- * bond_3ad_initiate_agg_selection - initate aggregator selection
- * @bond: bonding struct
- *
- * Set the aggregation selection timer, to initiate an agg selection in
- * the very near future.  Called during first initialization, and during
- * any down to up transitions of the bond.
- */
-void bond_3ad_initiate_agg_selection(struct bonding *bond, int timeout)
-{
-	BOND_AD_INFO(bond).agg_select_timer = timeout;
-}
-
-/**
- * bond_3ad_initialize - initialize a bond's 802.3ad parameters and structures
- * @bond: bonding struct to work on
- * @tick_resolution: tick duration (millisecond resolution)
- *
- * Can be called only after the mac address of the bond is set.
- */
-void bond_3ad_initialize(struct bonding *bond, u16 tick_resolution)
-{
-	/* check that the bond is not initialized yet */
-	if (!MAC_ADDRESS_EQUAL(&(BOND_AD_INFO(bond).system.sys_mac_addr),
-				bond->dev->dev_addr)) {
-
-		BOND_AD_INFO(bond).aggregator_identifier = 0;
-
-		BOND_AD_INFO(bond).system.sys_priority =
-			bond->params.ad_actor_sys_prio;
-		if (is_zero_ether_addr(bond->params.ad_actor_system))
-			BOND_AD_INFO(bond).system.sys_mac_addr =
-			    *((struct mac_addr *)bond->dev->dev_addr);
-		else
-			BOND_AD_INFO(bond).system.sys_mac_addr =
-			    *((struct mac_addr *)bond->params.ad_actor_system);
-
-		/* initialize how many times this module is called in one
-		 * second (should be about every 100ms)
-		 */
-		ad_ticks_per_sec = tick_resolution;
-
-		bond_3ad_initiate_agg_selection(bond,
-						AD_AGGREGATOR_SELECTION_TIMER *
-						ad_ticks_per_sec);
-	}
-}
-
-/**
- * bond_3ad_bind_slave - initialize a slave's port
- * @slave: slave struct to work on
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-void bond_3ad_bind_slave(struct slave *slave)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-	struct port *port;
-	struct aggregator *aggregator;
-
-	/* check that the slave has not been initialized yet. */
-	if (SLAVE_AD_INFO(slave)->port.slave != slave) {
-
-		/* port initialization */
-		port = &(SLAVE_AD_INFO(slave)->port);
-
-		ad_initialize_port(port, bond->params.lacp_fast);
-
-		port->slave = slave;
-		port->actor_port_number = SLAVE_AD_INFO(slave)->id;
-		/* key is determined according to the link speed, duplex and
-		 * user key
-		 */
-		port->actor_admin_port_key = bond->params.ad_user_port_key << 6;
-		ad_update_actor_keys(port, false);
-		/* actor system is the bond's system */
-		__ad_actor_update_port(port);
-		/* tx timer(to verify that no more than MAX_TX_IN_SECOND
-		 * lacpdu's are sent in one second)
-		 */
-		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
-
-		__disable_port(port);
-
-		/* aggregator initialization */
-		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		ad_initialize_agg(aggregator);
-
-		aggregator->aggregator_mac_address = *((struct mac_addr *)bond->dev->dev_addr);
-		aggregator->aggregator_identifier = ++BOND_AD_INFO(bond).aggregator_identifier;
-		aggregator->slave = slave;
-		aggregator->is_active = 0;
-		aggregator->num_of_ports = 0;
-	}
-}
-
-/**
- * bond_3ad_unbind_slave - deinitialize a slave's port
- * @slave: slave struct to work on
- *
- * Search for the aggregator that is related to this port, remove the
- * aggregator and assign another aggregator for other port related to it
- * (if any), and remove the port.
- */
-void bond_3ad_unbind_slave(struct slave *slave)
-{
-	struct port *port, *prev_port, *temp_port;
-	struct aggregator *aggregator, *new_aggregator, *temp_aggregator;
-	int select_new_active_agg = 0;
-	struct bonding *bond = slave->bond;
-	struct slave *slave_iter;
-	struct list_head *iter;
-	bool dummy_slave_update; /* Ignore this value as caller updates array */
-
-	/* Sync against bond_3ad_state_machine_handler() */
-	spin_lock_bh(&bond->mode_lock);
-	aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(bond->dev, slave->dev, "Trying to unbind an uninitialized port\n");
-		goto out;
-	}
-
-	slave_dbg(bond->dev, slave->dev, "Unbinding Link Aggregation Group %d\n",
-		  aggregator->aggregator_identifier);
-
-	/* Tell the partner that this port is not suitable for aggregation */
-	port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
-	port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
-	port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
-	port->actor_oper_port_state &= ~AD_STATE_AGGREGATION;
-	__update_lacpdu_from_port(port);
-	ad_lacpdu_send(port);
-
-	/* check if this aggregator is occupied */
-	if (aggregator->lag_ports) {
-		/* check if there are other ports related to this aggregator
-		 * except the port related to this slave(thats ensure us that
-		 * there is a reason to search for new aggregator, and that we
-		 * will find one
-		 */
-		if ((aggregator->lag_ports != port) ||
-		    (aggregator->lag_ports->next_port_in_aggregator)) {
-			/* find new aggregator for the related port(s) */
-			bond_for_each_slave(bond, slave_iter, iter) {
-				new_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
-				/* if the new aggregator is empty, or it is
-				 * connected to our port only
-				 */
-				if (!new_aggregator->lag_ports ||
-				    ((new_aggregator->lag_ports == port) &&
-				     !new_aggregator->lag_ports->next_port_in_aggregator))
-					break;
-			}
-			if (!slave_iter)
-				new_aggregator = NULL;
-
-			/* if new aggregator found, copy the aggregator's
-			 * parameters and connect the related lag_ports to the
-			 * new aggregator
-			 */
-			if ((new_aggregator) && ((!new_aggregator->lag_ports) || ((new_aggregator->lag_ports == port) && !new_aggregator->lag_ports->next_port_in_aggregator))) {
-				slave_dbg(bond->dev, slave->dev, "Some port(s) related to LAG %d - replacing with LAG %d\n",
-					  aggregator->aggregator_identifier,
-					  new_aggregator->aggregator_identifier);
-
-				if ((new_aggregator->lag_ports == port) &&
-				    new_aggregator->is_active) {
-					slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-					select_new_active_agg = 1;
-				}
-
-				new_aggregator->is_individual = aggregator->is_individual;
-				new_aggregator->actor_admin_aggregator_key = aggregator->actor_admin_aggregator_key;
-				new_aggregator->actor_oper_aggregator_key = aggregator->actor_oper_aggregator_key;
-				new_aggregator->partner_system = aggregator->partner_system;
-				new_aggregator->partner_system_priority = aggregator->partner_system_priority;
-				new_aggregator->partner_oper_aggregator_key = aggregator->partner_oper_aggregator_key;
-				new_aggregator->receive_state = aggregator->receive_state;
-				new_aggregator->transmit_state = aggregator->transmit_state;
-				new_aggregator->lag_ports = aggregator->lag_ports;
-				new_aggregator->is_active = aggregator->is_active;
-				new_aggregator->num_of_ports = aggregator->num_of_ports;
-
-				/* update the information that is written on
-				 * the ports about the aggregator
-				 */
-				for (temp_port = aggregator->lag_ports; temp_port;
-				     temp_port = temp_port->next_port_in_aggregator) {
-					temp_port->aggregator = new_aggregator;
-					temp_port->actor_port_aggregator_identifier = new_aggregator->aggregator_identifier;
-				}
-
-				ad_clear_agg(aggregator);
-
-				if (select_new_active_agg)
-					ad_agg_selection_logic(__get_first_agg(port),
-							       &dummy_slave_update);
-			} else {
-				slave_warn(bond->dev, slave->dev, "unbinding aggregator, and could not find a new aggregator for its ports\n");
-			}
-		} else {
-			/* in case that the only port related to this
-			 * aggregator is the one we want to remove
-			 */
-			select_new_active_agg = aggregator->is_active;
-			ad_clear_agg(aggregator);
-			if (select_new_active_agg) {
-				slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-				/* select new active aggregator */
-				temp_aggregator = __get_first_agg(port);
-				if (temp_aggregator)
-					ad_agg_selection_logic(temp_aggregator,
-							       &dummy_slave_update);
-			}
-		}
-	}
-
-	slave_dbg(bond->dev, slave->dev, "Unbinding port %d\n", port->actor_port_number);
-
-	/* find the aggregator that this port is connected to */
-	bond_for_each_slave(bond, slave_iter, iter) {
-		temp_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
-		prev_port = NULL;
-		/* search the port in the aggregator's related ports */
-		for (temp_port = temp_aggregator->lag_ports; temp_port;
-		     prev_port = temp_port,
-		     temp_port = temp_port->next_port_in_aggregator) {
-			if (temp_port == port) {
-				/* the aggregator found - detach the port from
-				 * this aggregator
-				 */
-				if (prev_port)
-					prev_port->next_port_in_aggregator = temp_port->next_port_in_aggregator;
-				else
-					temp_aggregator->lag_ports = temp_port->next_port_in_aggregator;
-				temp_aggregator->num_of_ports--;
-				if (__agg_active_ports(temp_aggregator) == 0) {
-					select_new_active_agg = temp_aggregator->is_active;
-					ad_clear_agg(temp_aggregator);
-					if (select_new_active_agg) {
-						slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-						/* select new active aggregator */
-						ad_agg_selection_logic(__get_first_agg(port),
-							               &dummy_slave_update);
-					}
-				}
-				break;
-			}
-		}
-	}
-	port->slave = NULL;
-
-out:
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/**
- * bond_3ad_update_ad_actor_settings - reflect change of actor settings to ports
- * @bond: bonding struct to work on
- *
- * If an ad_actor setting gets changed we need to update the individual port
- * settings so the bond device will use the new values when it gets upped.
- */
-void bond_3ad_update_ad_actor_settings(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	ASSERT_RTNL();
-
-	BOND_AD_INFO(bond).system.sys_priority = bond->params.ad_actor_sys_prio;
-	if (is_zero_ether_addr(bond->params.ad_actor_system))
-		BOND_AD_INFO(bond).system.sys_mac_addr =
-		    *((struct mac_addr *)bond->dev->dev_addr);
-	else
-		BOND_AD_INFO(bond).system.sys_mac_addr =
-		    *((struct mac_addr *)bond->params.ad_actor_system);
-
-	spin_lock_bh(&bond->mode_lock);
-	bond_for_each_slave(bond, slave, iter) {
-		struct port *port = &(SLAVE_AD_INFO(slave))->port;
-
-		__ad_actor_update_port(port);
-		port->ntt = true;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/**
- * bond_3ad_state_machine_handler - handle state machines timeout
- * @bond: bonding struct to work on
- *
- * The state machine handling concept in this module is to check every tick
- * which state machine should operate any function. The execution order is
- * round robin, so when we have an interaction between state machines, the
- * reply of one to each other might be delayed until next tick.
- *
- * This function also complete the initialization when the agg_select_timer
- * times out, and it selects an aggregator for the ports that are yet not
- * related to any aggregator, and selects the active aggregator for a bond.
- */
-void bond_3ad_state_machine_handler(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    ad_work.work);
-	struct aggregator *aggregator;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
-	bool update_slave_arr = false;
-
-	/* Lock to protect data accessed by all (e.g., port->sm_vars) and
-	 * against running with bond_3ad_unbind_slave. ad_rx_machine may run
-	 * concurrently due to incoming LACPDU as well.
-	 */
-	spin_lock_bh(&bond->mode_lock);
-	rcu_read_lock();
-
-	/* check if there are any slaves */
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	/* check if agg_select_timer timer after initialize is timed out */
-	if (BOND_AD_INFO(bond).agg_select_timer &&
-	    !(--BOND_AD_INFO(bond).agg_select_timer)) {
-		slave = bond_first_slave_rcu(bond);
-		port = slave ? &(SLAVE_AD_INFO(slave)->port) : NULL;
-
-		/* select the active aggregator for the bond */
-		if (port) {
-			if (!port->slave) {
-				net_warn_ratelimited("%s: Warning: bond's first port is uninitialized\n",
-						     bond->dev->name);
-				goto re_arm;
-			}
-
-			aggregator = __get_first_agg(port);
-			ad_agg_selection_logic(aggregator, &update_slave_arr);
-		}
-		bond_3ad_set_carrier(bond);
-	}
-
-	/* for each port run the state machines */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (!port->slave) {
-			net_warn_ratelimited("%s: Warning: Found an uninitialized port\n",
-					    bond->dev->name);
-			goto re_arm;
-		}
-
-		ad_rx_machine(NULL, port);
-		ad_periodic_machine(port);
-		ad_port_selection_logic(port, &update_slave_arr);
-		ad_mux_machine(port, &update_slave_arr);
-		ad_tx_machine(port);
-		ad_churn_machine(port);
-
-		/* turn off the BEGIN bit, since we already handled it */
-		if (port->sm_vars & AD_PORT_BEGIN)
-			port->sm_vars &= ~AD_PORT_BEGIN;
-	}
-
-re_arm:
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->should_notify) {
-			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
-			break;
-		}
-	}
-	rcu_read_unlock();
-	spin_unlock_bh(&bond->mode_lock);
-
-	if (update_slave_arr)
-		bond_slave_arr_work_rearm(bond, 0);
-
-	if (should_notify_rtnl && rtnl_trylock()) {
-		bond_slave_state_notify(bond);
-		rtnl_unlock();
-	}
-	queue_delayed_work(bond->wq, &bond->ad_work, ad_delta_in_ticks);
-}
-
-/**
- * bond_3ad_rx_indication - handle a received frame
- * @lacpdu: received lacpdu
- * @slave: slave struct to work on
- *
- * It is assumed that frames that were sent on this NIC don't returned as new
- * received frames (loopback). Since only the payload is given to this
- * function, it check for loopback.
- */
-static int bond_3ad_rx_indication(struct lacpdu *lacpdu, struct slave *slave)
-{
-	struct bonding *bond = slave->bond;
-	int ret = RX_HANDLER_ANOTHER;
-	struct bond_marker *marker;
-	struct port *port;
-	atomic64_t *stat;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-	if (!port->slave) {
-		net_warn_ratelimited("%s: Warning: port of slave %s is uninitialized\n",
-				     slave->dev->name, slave->bond->dev->name);
-		return ret;
-	}
-
-	switch (lacpdu->subtype) {
-	case AD_TYPE_LACPDU:
-		ret = RX_HANDLER_CONSUMED;
-		slave_dbg(slave->bond->dev, slave->dev,
-			  "Received LACPDU on port %d\n",
-			  port->actor_port_number);
-		/* Protect against concurrent state machines */
-		spin_lock(&slave->bond->mode_lock);
-		ad_rx_machine(lacpdu, port);
-		spin_unlock(&slave->bond->mode_lock);
-		break;
-	case AD_TYPE_MARKER:
-		ret = RX_HANDLER_CONSUMED;
-		/* No need to convert fields to Little Endian since we
-		 * don't use the marker's fields.
-		 */
-		marker = (struct bond_marker *)lacpdu;
-		switch (marker->tlv_type) {
-		case AD_MARKER_INFORMATION_SUBTYPE:
-			slave_dbg(slave->bond->dev, slave->dev, "Received Marker Information on port %d\n",
-				  port->actor_port_number);
-			ad_marker_info_received(marker, port);
-			break;
-		case AD_MARKER_RESPONSE_SUBTYPE:
-			slave_dbg(slave->bond->dev, slave->dev, "Received Marker Response on port %d\n",
-				  port->actor_port_number);
-			ad_marker_response_received(marker, port);
-			break;
-		default:
-			slave_dbg(slave->bond->dev, slave->dev, "Received an unknown Marker subtype on port %d\n",
-				  port->actor_port_number);
-			stat = &SLAVE_AD_INFO(slave)->stats.marker_unknown_rx;
-			atomic64_inc(stat);
-			stat = &BOND_AD_INFO(bond).stats.marker_unknown_rx;
-			atomic64_inc(stat);
-		}
-		break;
-	default:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_unknown_rx);
-		atomic64_inc(&BOND_AD_INFO(bond).stats.lacpdu_unknown_rx);
-	}
-
-	return ret;
-}
-
-/**
- * ad_update_actor_keys - Update the oper / admin keys for a port based on
- * its current speed and duplex settings.
- *
- * @port: the port we'are looking at
- * @reset: Boolean to just reset the speed and the duplex part of the key
- *
- * The logic to change the oper / admin keys is:
- * (a) A full duplex port can participate in LACP with partner.
- * (b) When the speed is changed, LACP need to be reinitiated.
- */
-static void ad_update_actor_keys(struct port *port, bool reset)
-{
-	u8 duplex = 0;
-	u16 ospeed = 0, speed = 0;
-	u16 old_oper_key = port->actor_oper_port_key;
-
-	port->actor_admin_port_key &= ~(AD_SPEED_KEY_MASKS|AD_DUPLEX_KEY_MASKS);
-	if (!reset) {
-		speed = __get_link_speed(port);
-		ospeed = (old_oper_key & AD_SPEED_KEY_MASKS) >> 1;
-		duplex = __get_duplex(port);
-		port->actor_admin_port_key |= (speed << 1) | duplex;
-	}
-	port->actor_oper_port_key = port->actor_admin_port_key;
-
-	if (old_oper_key != port->actor_oper_port_key) {
-		/* Only 'duplex' port participates in LACP */
-		if (duplex)
-			port->sm_vars |= AD_PORT_LACP_ENABLED;
-		else
-			port->sm_vars &= ~AD_PORT_LACP_ENABLED;
-
-		if (!reset) {
-			if (!speed) {
-				slave_err(port->slave->bond->dev,
-					  port->slave->dev,
-					  "speed changed to 0 on port %d\n",
-					  port->actor_port_number);
-			} else if (duplex && ospeed != speed) {
-				/* Speed change restarts LACP state-machine */
-				port->sm_vars |= AD_PORT_BEGIN;
-			}
-		}
-	}
-}
-
-/**
- * bond_3ad_adapter_speed_duplex_changed - handle a slave's speed / duplex
- * change indication
- *
- * @slave: slave struct to work on
- *
- * Handle reselection of aggregator (if needed) for this port.
- */
-void bond_3ad_adapter_speed_duplex_changed(struct slave *slave)
-{
-	struct port *port;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(slave->bond->dev, slave->dev,
-			   "speed/duplex changed for uninitialized port\n");
-		return;
-	}
-
-	spin_lock_bh(&slave->bond->mode_lock);
-	ad_update_actor_keys(port, false);
-	spin_unlock_bh(&slave->bond->mode_lock);
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d changed speed/duplex\n",
-		  port->actor_port_number);
-}
-
-/**
- * bond_3ad_handle_link_change - handle a slave's link status change indication
- * @slave: slave struct to work on
- * @status: whether the link is now up or down
- *
- * Handle reselection of aggregator (if needed) for this port.
- */
-void bond_3ad_handle_link_change(struct slave *slave, char link)
-{
-	struct aggregator *agg;
-	struct port *port;
-	bool dummy;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(slave->bond->dev, slave->dev, "link status changed for uninitialized port\n");
-		return;
-	}
-
-	spin_lock_bh(&slave->bond->mode_lock);
-	/* on link down we are zeroing duplex and speed since
-	 * some of the adaptors(ce1000.lan) report full duplex/speed
-	 * instead of N/A(duplex) / 0(speed).
-	 *
-	 * on link up we are forcing recheck on the duplex and speed since
-	 * some of he adaptors(ce1000.lan) report.
-	 */
-	if (link == BOND_LINK_UP) {
-		port->is_enabled = true;
-		ad_update_actor_keys(port, false);
-	} else {
-		/* link has failed */
-		port->is_enabled = false;
-		ad_update_actor_keys(port, true);
-		toe_failover(netdev_master_upper_dev_get(slave->dev),
-			     slave->dev, TOE_LINK_DOWN, NULL);
-	}
-	agg = __get_first_agg(port);
-	ad_agg_selection_logic(agg, &dummy);
-
-	spin_unlock_bh(&slave->bond->mode_lock);
-
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d changed link status to %s\n",
-		  port->actor_port_number,
-		  link == BOND_LINK_UP ? "UP" : "DOWN");
-
-	/* RTNL is held and mode_lock is released so it's safe
-	 * to update slave_array here.
-	 */
-	bond_update_slave_arr(slave->bond, NULL);
-}
-
-/**
- * bond_3ad_set_carrier - set link state for bonding master
- * @bond - bonding structure
- *
- * if we have an active aggregator, we're up, if not, we're down.
- * Presumes that we cannot have an active aggregator if there are
- * no slaves with link up.
- *
- * This behavior complies with IEEE 802.3 section 43.3.9.
- *
- * Called by bond_set_carrier(). Return zero if carrier state does not
- * change, nonzero if it does.
- */
-int bond_3ad_set_carrier(struct bonding *bond)
-{
-	struct aggregator *active;
-	struct slave *first_slave;
-	int ret = 1;
-
-	rcu_read_lock();
-	first_slave = bond_first_slave_rcu(bond);
-	if (!first_slave) {
-		ret = 0;
-		goto out;
-	}
-	active = __get_active_agg(&(SLAVE_AD_INFO(first_slave)->aggregator));
-	if (active) {
-		/* are enough slaves available to consider link up? */
-		if (__agg_active_ports(active) < bond->params.min_links) {
-			if (netif_carrier_ok(bond->dev)) {
-				netif_carrier_off(bond->dev);
-				goto out;
-			}
-		} else if (!netif_carrier_ok(bond->dev)) {
-			netif_carrier_on(bond->dev);
-			goto out;
-		}
-	} else if (netif_carrier_ok(bond->dev)) {
-		netif_carrier_off(bond->dev);
-	}
-out:
-	rcu_read_unlock();
-	return ret;
-}
-
-/**
- * __bond_3ad_get_active_agg_info - get information of the active aggregator
- * @bond: bonding struct to work on
- * @ad_info: ad_info struct to fill with the bond's info
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-int __bond_3ad_get_active_agg_info(struct bonding *bond,
-				   struct ad_info *ad_info)
-{
-	struct aggregator *aggregator = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (port->aggregator && port->aggregator->is_active) {
-			aggregator = port->aggregator;
-			break;
-		}
-	}
-
-	if (!aggregator)
-		return -1;
-
-	ad_info->aggregator_id = aggregator->aggregator_identifier;
-	ad_info->ports = __agg_active_ports(aggregator);
-	ad_info->actor_key = aggregator->actor_oper_aggregator_key;
-	ad_info->partner_key = aggregator->partner_oper_aggregator_key;
-	ether_addr_copy(ad_info->partner_system,
-			aggregator->partner_system.mac_addr_value);
-	return 0;
-}
-
-int bond_3ad_get_active_agg_info(struct bonding *bond, struct ad_info *ad_info)
-{
-	int ret;
-
-	rcu_read_lock();
-	ret = __bond_3ad_get_active_agg_info(bond, ad_info);
-	rcu_read_unlock();
-
-	return ret;
-}
-
-int bond_3ad_lacpdu_recv(const struct sk_buff *skb, struct bonding *bond,
-			 struct slave *slave)
-{
-	struct lacpdu *lacpdu, _lacpdu;
-
-	if (skb->protocol != PKT_TYPE_LACPDU)
-		return RX_HANDLER_ANOTHER;
-
-	if (!MAC_ADDRESS_EQUAL(eth_hdr(skb)->h_dest, lacpdu_mcast_addr))
-		return RX_HANDLER_ANOTHER;
-
-	lacpdu = skb_header_pointer(skb, 0, sizeof(_lacpdu), &_lacpdu);
-	if (!lacpdu) {
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_illegal_rx);
-		atomic64_inc(&BOND_AD_INFO(bond).stats.lacpdu_illegal_rx);
-		return RX_HANDLER_ANOTHER;
-	}
-
-	return bond_3ad_rx_indication(lacpdu, slave);
-}
-
-/**
- * bond_3ad_update_lacp_rate - change the lacp rate
- * @bond - bonding struct
- *
- * When modify lacp_rate parameter via sysfs,
- * update actor_oper_port_state of each port.
- *
- * Hold bond->mode_lock,
- * so we can modify port->actor_oper_port_state,
- * no matter bond is up or down.
- */
-void bond_3ad_update_lacp_rate(struct bonding *bond)
-{
-	struct port *port = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	int lacp_fast;
-
-	lacp_fast = bond->params.lacp_fast;
-	spin_lock_bh(&bond->mode_lock);
-	bond_for_each_slave(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (lacp_fast)
-			port->actor_oper_port_state |= AD_STATE_LACP_TIMEOUT;
-		else
-			port->actor_oper_port_state &= ~AD_STATE_LACP_TIMEOUT;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-size_t bond_3ad_stats_size(void)
-{
-	return nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_TX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_UNKNOWN_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_ILLEGAL_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_TX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RESP_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RESP_TX */
-	       nla_total_size_64bit(sizeof(u64)); /* BOND_3AD_STAT_MARKER_UNKNOWN_RX */
-}
-
-int bond_3ad_stats_fill(struct sk_buff *skb, struct bond_3ad_stats *stats)
-{
-	u64 val;
-
-	val = atomic64_read(&stats->lacpdu_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_unknown_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_UNKNOWN_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_illegal_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_ILLEGAL_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-
-	val = atomic64_read(&stats->marker_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_resp_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RESP_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_resp_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RESP_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_unknown_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_UNKNOWN_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-
-	return 0;
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.19/bond_alb.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.19/bond_alb.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1811 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
- */
-
-#include <linux/skbuff.h>
-#include <linux/netdevice.h>
-#include <linux/etherdevice.h>
-#include <linux/pkt_sched.h>
-#include <linux/spinlock.h>
-#include <linux/slab.h>
-#include <linux/timer.h>
-#include <linux/ip.h>
-#include <linux/ipv6.h>
-#include <linux/if_arp.h>
-#include <linux/if_ether.h>
-#include <linux/if_bonding.h>
-#include <linux/if_vlan.h>
-#include <linux/in.h>
-#include <net/ipx.h>
-#include <net/arp.h>
-#include <net/ipv6.h>
-#include <asm/byteorder.h>
-#include <net/bonding.h>
-#include <net/bond_alb.h>
-
-static const u8 mac_v6_allmcast[ETH_ALEN + 2] __long_aligned = {
-	0x33, 0x33, 0x00, 0x00, 0x00, 0x01
-};
-static const int alb_delta_in_ticks = HZ / ALB_TIMER_TICKS_PER_SEC;
-
-#pragma pack(1)
-struct learning_pkt {
-	u8 mac_dst[ETH_ALEN];
-	u8 mac_src[ETH_ALEN];
-	__be16 type;
-	u8 padding[ETH_ZLEN - ETH_HLEN];
-};
-
-struct arp_pkt {
-	__be16  hw_addr_space;
-	__be16  prot_addr_space;
-	u8      hw_addr_len;
-	u8      prot_addr_len;
-	__be16  op_code;
-	u8      mac_src[ETH_ALEN];	/* sender hardware address */
-	__be32  ip_src;			/* sender IP address */
-	u8      mac_dst[ETH_ALEN];	/* target hardware address */
-	__be32  ip_dst;			/* target IP address */
-};
-#pragma pack()
-
-static inline struct arp_pkt *arp_pkt(const struct sk_buff *skb)
-{
-	return (struct arp_pkt *)skb_network_header(skb);
-}
-
-/* Forward declaration */
-static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
-				      bool strict_match);
-static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp);
-static void rlb_src_unlink(struct bonding *bond, u32 index);
-static void rlb_src_link(struct bonding *bond, u32 ip_src_hash,
-			 u32 ip_dst_hash);
-
-static inline u8 _simple_hash(const u8 *hash_start, int hash_size)
-{
-	int i;
-	u8 hash = 0;
-
-	for (i = 0; i < hash_size; i++)
-		hash ^= hash_start[i];
-
-	return hash;
-}
-
-/*********************** tlb specific functions ***************************/
-
-static inline void tlb_init_table_entry(struct tlb_client_info *entry, int save_load)
-{
-	if (save_load) {
-		entry->load_history = 1 + entry->tx_bytes /
-				      BOND_TLB_REBALANCE_INTERVAL;
-		entry->tx_bytes = 0;
-	}
-
-	entry->tx_slave = NULL;
-	entry->next = TLB_NULL_INDEX;
-	entry->prev = TLB_NULL_INDEX;
-}
-
-static inline void tlb_init_slave(struct slave *slave)
-{
-	SLAVE_TLB_INFO(slave).load = 0;
-	SLAVE_TLB_INFO(slave).head = TLB_NULL_INDEX;
-}
-
-static void __tlb_clear_slave(struct bonding *bond, struct slave *slave,
-			 int save_load)
-{
-	struct tlb_client_info *tx_hash_table;
-	u32 index;
-
-	/* clear slave from tx_hashtbl */
-	tx_hash_table = BOND_ALB_INFO(bond).tx_hashtbl;
-
-	/* skip this if we've already freed the tx hash table */
-	if (tx_hash_table) {
-		index = SLAVE_TLB_INFO(slave).head;
-		while (index != TLB_NULL_INDEX) {
-			u32 next_index = tx_hash_table[index].next;
-			tlb_init_table_entry(&tx_hash_table[index], save_load);
-			index = next_index;
-		}
-	}
-
-	tlb_init_slave(slave);
-}
-
-static void tlb_clear_slave(struct bonding *bond, struct slave *slave,
-			 int save_load)
-{
-	spin_lock_bh(&bond->mode_lock);
-	__tlb_clear_slave(bond, slave, save_load);
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* Must be called before starting the monitor timer */
-static int tlb_initialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	int size = TLB_HASH_TABLE_SIZE * sizeof(struct tlb_client_info);
-	struct tlb_client_info *new_hashtbl;
-	int i;
-
-	new_hashtbl = kzalloc(size, GFP_KERNEL);
-	if (!new_hashtbl)
-		return -ENOMEM;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	bond_info->tx_hashtbl = new_hashtbl;
-
-	for (i = 0; i < TLB_HASH_TABLE_SIZE; i++)
-		tlb_init_table_entry(&bond_info->tx_hashtbl[i], 0);
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	return 0;
-}
-
-/* Must be called only after all slaves have been released */
-static void tlb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	spin_lock_bh(&bond->mode_lock);
-
-	kfree(bond_info->tx_hashtbl);
-	bond_info->tx_hashtbl = NULL;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static long long compute_gap(struct slave *slave)
-{
-	return (s64) (slave->speed << 20) - /* Convert to Megabit per sec */
-	       (s64) (SLAVE_TLB_INFO(slave).load << 3); /* Bytes to bits */
-}
-
-static struct slave *tlb_get_least_loaded_slave(struct bonding *bond)
-{
-	struct slave *slave, *least_loaded;
-	struct list_head *iter;
-	long long max_gap;
-
-	least_loaded = NULL;
-	max_gap = LLONG_MIN;
-
-	/* Find the slave with the largest gap */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (bond_slave_can_tx(slave)) {
-			long long gap = compute_gap(slave);
-
-			if (max_gap < gap) {
-				least_loaded = slave;
-				max_gap = gap;
-			}
-		}
-	}
-
-	return least_loaded;
-}
-
-static struct slave *__tlb_choose_channel(struct bonding *bond, u32 hash_index,
-						u32 skb_len)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct tlb_client_info *hash_table;
-	struct slave *assigned_slave;
-
-	hash_table = bond_info->tx_hashtbl;
-	assigned_slave = hash_table[hash_index].tx_slave;
-	if (!assigned_slave) {
-		assigned_slave = tlb_get_least_loaded_slave(bond);
-
-		if (assigned_slave) {
-			struct tlb_slave_info *slave_info =
-				&(SLAVE_TLB_INFO(assigned_slave));
-			u32 next_index = slave_info->head;
-
-			hash_table[hash_index].tx_slave = assigned_slave;
-			hash_table[hash_index].next = next_index;
-			hash_table[hash_index].prev = TLB_NULL_INDEX;
-
-			if (next_index != TLB_NULL_INDEX)
-				hash_table[next_index].prev = hash_index;
-
-			slave_info->head = hash_index;
-			slave_info->load +=
-				hash_table[hash_index].load_history;
-		}
-	}
-
-	if (assigned_slave)
-		hash_table[hash_index].tx_bytes += skb_len;
-
-	return assigned_slave;
-}
-
-static struct slave *tlb_choose_channel(struct bonding *bond, u32 hash_index,
-					u32 skb_len)
-{
-	struct slave *tx_slave;
-
-	/* We don't need to disable softirq here, becase
-	 * tlb_choose_channel() is only called by bond_alb_xmit()
-	 * which already has softirq disabled.
-	 */
-	spin_lock(&bond->mode_lock);
-	tx_slave = __tlb_choose_channel(bond, hash_index, skb_len);
-	spin_unlock(&bond->mode_lock);
-
-	return tx_slave;
-}
-
-/*********************** rlb specific functions ***************************/
-
-/* when an ARP REPLY is received from a client update its info
- * in the rx_hashtbl
- */
-static void rlb_update_entry_from_arp(struct bonding *bond, struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
-	client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-	if ((client_info->assigned) &&
-	    (client_info->ip_src == arp->ip_dst) &&
-	    (client_info->ip_dst == arp->ip_src) &&
-	    (!ether_addr_equal_64bits(client_info->mac_dst, arp->mac_src))) {
-		/* update the clients MAC address */
-		ether_addr_copy(client_info->mac_dst, arp->mac_src);
-		client_info->ntt = 1;
-		bond_info->rx_ntt = 1;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static int rlb_arp_recv(const struct sk_buff *skb, struct bonding *bond,
-			struct slave *slave)
-{
-	struct arp_pkt *arp, _arp;
-
-	if (skb->protocol != cpu_to_be16(ETH_P_ARP))
-		goto out;
-
-	arp = skb_header_pointer(skb, 0, sizeof(_arp), &_arp);
-	if (!arp)
-		goto out;
-
-	/* We received an ARP from arp->ip_src.
-	 * We might have used this IP address previously (on the bonding host
-	 * itself or on a system that is bridged together with the bond).
-	 * However, if arp->mac_src is different than what is stored in
-	 * rx_hashtbl, some other host is now using the IP and we must prevent
-	 * sending out client updates with this IP address and the old MAC
-	 * address.
-	 * Clean up all hash table entries that have this address as ip_src but
-	 * have a different mac_src.
-	 */
-	rlb_purge_src_ip(bond, arp);
-
-	if (arp->op_code == htons(ARPOP_REPLY)) {
-		/* update rx hash table for this ARP */
-		rlb_update_entry_from_arp(bond, arp);
-		slave_dbg(bond->dev, slave->dev, "Server received an ARP Reply from client\n");
-	}
-out:
-	return RX_HANDLER_ANOTHER;
-}
-
-/* Caller must hold rcu_read_lock() */
-static struct slave *__rlb_next_rx_slave(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *before = NULL, *rx_slave = NULL, *slave;
-	struct list_head *iter;
-	bool found = false;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!bond_slave_can_tx(slave))
-			continue;
-		if (!found) {
-			if (!before || before->speed < slave->speed)
-				before = slave;
-		} else {
-			if (!rx_slave || rx_slave->speed < slave->speed)
-				rx_slave = slave;
-		}
-		if (slave == bond_info->rx_slave)
-			found = true;
-	}
-	/* we didn't find anything after the current or we have something
-	 * better before and up to the current slave
-	 */
-	if (!rx_slave || (before && rx_slave->speed < before->speed))
-		rx_slave = before;
-
-	if (rx_slave)
-		bond_info->rx_slave = rx_slave;
-
-	return rx_slave;
-}
-
-/* Caller must hold RTNL, rcu_read_lock is obtained only to silence checkers */
-static struct slave *rlb_next_rx_slave(struct bonding *bond)
-{
-	struct slave *rx_slave;
-
-	ASSERT_RTNL();
-
-	rcu_read_lock();
-	rx_slave = __rlb_next_rx_slave(bond);
-	rcu_read_unlock();
-
-	return rx_slave;
-}
-
-/* teach the switch the mac of a disabled slave
- * on the primary for fault tolerance
- *
- * Caller must hold RTNL
- */
-static void rlb_teach_disabled_mac_on_primary(struct bonding *bond, u8 addr[])
-{
-	struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-	if (!curr_active)
-		return;
-
-	if (!bond->alb_info.primary_is_promisc) {
-		if (!dev_set_promiscuity(curr_active->dev, 1))
-			bond->alb_info.primary_is_promisc = 1;
-		else
-			bond->alb_info.primary_is_promisc = 0;
-	}
-
-	bond->alb_info.rlb_promisc_timeout_counter = 0;
-
-	alb_send_learning_packets(curr_active, addr, true);
-}
-
-/* slave being removed should not be active at this point
- *
- * Caller must hold rtnl.
- */
-static void rlb_clear_slave(struct bonding *bond, struct slave *slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *rx_hash_table;
-	u32 index, next_index;
-
-	/* clear slave from rx_hashtbl */
-	spin_lock_bh(&bond->mode_lock);
-
-	rx_hash_table = bond_info->rx_hashtbl;
-	index = bond_info->rx_hashtbl_used_head;
-	for (; index != RLB_NULL_INDEX; index = next_index) {
-		next_index = rx_hash_table[index].used_next;
-		if (rx_hash_table[index].slave == slave) {
-			struct slave *assigned_slave = rlb_next_rx_slave(bond);
-
-			if (assigned_slave) {
-				rx_hash_table[index].slave = assigned_slave;
-				if (is_valid_ether_addr(rx_hash_table[index].mac_dst)) {
-					bond_info->rx_hashtbl[index].ntt = 1;
-					bond_info->rx_ntt = 1;
-					/* A slave has been removed from the
-					 * table because it is either disabled
-					 * or being released. We must retry the
-					 * update to avoid clients from not
-					 * being updated & disconnecting when
-					 * there is stress
-					 */
-					bond_info->rlb_update_retry_counter =
-						RLB_UPDATE_RETRY;
-				}
-			} else {  /* there is no active slave */
-				rx_hash_table[index].slave = NULL;
-			}
-		}
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	if (slave != rtnl_dereference(bond->curr_active_slave))
-		rlb_teach_disabled_mac_on_primary(bond, slave->dev->dev_addr);
-}
-
-static void rlb_update_client(struct rlb_client_info *client_info)
-{
-	int i;
-
-	if (!client_info->slave || !is_valid_ether_addr(client_info->mac_dst))
-		return;
-
-	for (i = 0; i < RLB_ARP_BURST_SIZE; i++) {
-		struct sk_buff *skb;
-
-		skb = arp_create(ARPOP_REPLY, ETH_P_ARP,
-				 client_info->ip_dst,
-				 client_info->slave->dev,
-				 client_info->ip_src,
-				 client_info->mac_dst,
-				 client_info->slave->dev->dev_addr,
-				 client_info->mac_dst);
-		if (!skb) {
-			slave_err(client_info->slave->bond->dev,
-				  client_info->slave->dev,
-				  "failed to create an ARP packet\n");
-			continue;
-		}
-
-		skb->dev = client_info->slave->dev;
-
-		if (client_info->vlan_id) {
-			__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),
-					       client_info->vlan_id);
-		}
-
-		arp_xmit(skb);
-	}
-}
-
-/* sends ARP REPLIES that update the clients that need updating */
-static void rlb_update_rx_clients(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		if (client_info->ntt) {
-			rlb_update_client(client_info);
-			if (bond_info->rlb_update_retry_counter == 0)
-				client_info->ntt = 0;
-		}
-	}
-
-	/* do not update the entries again until this counter is zero so that
-	 * not to confuse the clients.
-	 */
-	bond_info->rlb_update_delay_counter = RLB_UPDATE_DELAY;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* The slave was assigned a new mac address - update the clients */
-static void rlb_req_update_slave_clients(struct bonding *bond, struct slave *slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	int ntt = 0;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-		if ((client_info->slave == slave) &&
-		    is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			ntt = 1;
-		}
-	}
-
-	/* update the team's flag only after the whole iteration */
-	if (ntt) {
-		bond_info->rx_ntt = 1;
-		/* fasten the change */
-		bond_info->rlb_update_retry_counter = RLB_UPDATE_RETRY;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* mark all clients using src_ip to be updated */
-static void rlb_req_update_subnet_clients(struct bonding *bond, __be32 src_ip)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-		if (!client_info->slave) {
-			netdev_err(bond->dev, "found a client with no channel in the client's hash table\n");
-			continue;
-		}
-		/* update all clients using this src_ip, that are not assigned
-		 * to the team's address (curr_active_slave) and have a known
-		 * unicast mac address.
-		 */
-		if ((client_info->ip_src == src_ip) &&
-		    !ether_addr_equal_64bits(client_info->slave->dev->dev_addr,
-					     bond->dev->dev_addr) &&
-		    is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			bond_info->rx_ntt = 1;
-		}
-	}
-
-	spin_unlock(&bond->mode_lock);
-}
-
-static struct slave *rlb_choose_channel(struct sk_buff *skb, struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct arp_pkt *arp = arp_pkt(skb);
-	struct slave *assigned_slave, *curr_active_slave;
-	struct rlb_client_info *client_info;
-	u32 hash_index = 0;
-
-	spin_lock(&bond->mode_lock);
-
-	curr_active_slave = rcu_dereference(bond->curr_active_slave);
-
-	hash_index = _simple_hash((u8 *)&arp->ip_dst, sizeof(arp->ip_dst));
-	client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-	if (client_info->assigned) {
-		if ((client_info->ip_src == arp->ip_src) &&
-		    (client_info->ip_dst == arp->ip_dst)) {
-			/* the entry is already assigned to this client */
-			if (!is_broadcast_ether_addr(arp->mac_dst)) {
-				/* update mac address from arp */
-				ether_addr_copy(client_info->mac_dst, arp->mac_dst);
-			}
-			ether_addr_copy(client_info->mac_src, arp->mac_src);
-
-			assigned_slave = client_info->slave;
-			if (assigned_slave) {
-				spin_unlock(&bond->mode_lock);
-				return assigned_slave;
-			}
-		} else {
-			/* the entry is already assigned to some other client,
-			 * move the old client to primary (curr_active_slave) so
-			 * that the new client can be assigned to this entry.
-			 */
-			if (curr_active_slave &&
-			    client_info->slave != curr_active_slave) {
-				client_info->slave = curr_active_slave;
-				rlb_update_client(client_info);
-			}
-		}
-	}
-	/* assign a new slave */
-	assigned_slave = __rlb_next_rx_slave(bond);
-
-	if (assigned_slave) {
-		if (!(client_info->assigned &&
-		      client_info->ip_src == arp->ip_src)) {
-			/* ip_src is going to be updated,
-			 * fix the src hash list
-			 */
-			u32 hash_src = _simple_hash((u8 *)&arp->ip_src,
-						    sizeof(arp->ip_src));
-			rlb_src_unlink(bond, hash_index);
-			rlb_src_link(bond, hash_src, hash_index);
-		}
-
-		client_info->ip_src = arp->ip_src;
-		client_info->ip_dst = arp->ip_dst;
-		/* arp->mac_dst is broadcast for arp reqeusts.
-		 * will be updated with clients actual unicast mac address
-		 * upon receiving an arp reply.
-		 */
-		ether_addr_copy(client_info->mac_dst, arp->mac_dst);
-		ether_addr_copy(client_info->mac_src, arp->mac_src);
-		client_info->slave = assigned_slave;
-
-		if (is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			bond->alb_info.rx_ntt = 1;
-		} else {
-			client_info->ntt = 0;
-		}
-
-		if (vlan_get_tag(skb, &client_info->vlan_id))
-			client_info->vlan_id = 0;
-
-		if (!client_info->assigned) {
-			u32 prev_tbl_head = bond_info->rx_hashtbl_used_head;
-			bond_info->rx_hashtbl_used_head = hash_index;
-			client_info->used_next = prev_tbl_head;
-			if (prev_tbl_head != RLB_NULL_INDEX) {
-				bond_info->rx_hashtbl[prev_tbl_head].used_prev =
-					hash_index;
-			}
-			client_info->assigned = 1;
-		}
-	}
-
-	spin_unlock(&bond->mode_lock);
-
-	return assigned_slave;
-}
-
-/* chooses (and returns) transmit channel for arp reply
- * does not choose channel for other arp types since they are
- * sent on the curr_active_slave
- */
-static struct slave *rlb_arp_xmit(struct sk_buff *skb, struct bonding *bond)
-{
-	struct arp_pkt *arp = arp_pkt(skb);
-	struct slave *tx_slave = NULL;
-
-	/* Don't modify or load balance ARPs that do not originate locally
-	 * (e.g.,arrive via a bridge).
-	 */
-	if (!bond_slave_has_mac_rx(bond, arp->mac_src))
-		return NULL;
-
-	if (arp->op_code == htons(ARPOP_REPLY)) {
-		/* the arp must be sent on the selected rx channel */
-		tx_slave = rlb_choose_channel(skb, bond);
-		if (tx_slave)
-			bond_hw_addr_copy(arp->mac_src, tx_slave->dev->dev_addr,
-					  tx_slave->dev->addr_len);
-		netdev_dbg(bond->dev, "(slave %s): Server sent ARP Reply packet\n",
-			   tx_slave ? tx_slave->dev->name : "NULL");
-	} else if (arp->op_code == htons(ARPOP_REQUEST)) {
-		/* Create an entry in the rx_hashtbl for this client as a
-		 * place holder.
-		 * When the arp reply is received the entry will be updated
-		 * with the correct unicast address of the client.
-		 */
-		tx_slave = rlb_choose_channel(skb, bond);
-
-		/* The ARP reply packets must be delayed so that
-		 * they can cancel out the influence of the ARP request.
-		 */
-		bond->alb_info.rlb_update_delay_counter = RLB_UPDATE_DELAY;
-
-		/* arp requests are broadcast and are sent on the primary
-		 * the arp request will collapse all clients on the subnet to
-		 * the primary slave. We must register these clients to be
-		 * updated with their assigned mac.
-		 */
-		rlb_req_update_subnet_clients(bond, arp->ip_src);
-		netdev_dbg(bond->dev, "(slave %s): Server sent ARP Request packet\n",
-			   tx_slave ? tx_slave->dev->name : "NULL");
-	}
-
-	return tx_slave;
-}
-
-static void rlb_rebalance(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *assigned_slave;
-	struct rlb_client_info *client_info;
-	int ntt;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	ntt = 0;
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		assigned_slave = __rlb_next_rx_slave(bond);
-		if (assigned_slave && (client_info->slave != assigned_slave)) {
-			client_info->slave = assigned_slave;
-			if (!is_zero_ether_addr(client_info->mac_dst)) {
-				client_info->ntt = 1;
-				ntt = 1;
-			}
-		}
-	}
-
-	/* update the team's flag only after the whole iteration */
-	if (ntt)
-		bond_info->rx_ntt = 1;
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* Caller must hold mode_lock */
-static void rlb_init_table_entry_dst(struct rlb_client_info *entry)
-{
-	entry->used_next = RLB_NULL_INDEX;
-	entry->used_prev = RLB_NULL_INDEX;
-	entry->assigned = 0;
-	entry->slave = NULL;
-	entry->vlan_id = 0;
-}
-static void rlb_init_table_entry_src(struct rlb_client_info *entry)
-{
-	entry->src_first = RLB_NULL_INDEX;
-	entry->src_prev = RLB_NULL_INDEX;
-	entry->src_next = RLB_NULL_INDEX;
-}
-
-static void rlb_init_table_entry(struct rlb_client_info *entry)
-{
-	memset(entry, 0, sizeof(struct rlb_client_info));
-	rlb_init_table_entry_dst(entry);
-	rlb_init_table_entry_src(entry);
-}
-
-static void rlb_delete_table_entry_dst(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next_index = bond_info->rx_hashtbl[index].used_next;
-	u32 prev_index = bond_info->rx_hashtbl[index].used_prev;
-
-	if (index == bond_info->rx_hashtbl_used_head)
-		bond_info->rx_hashtbl_used_head = next_index;
-	if (prev_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[prev_index].used_next = next_index;
-	if (next_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next_index].used_prev = prev_index;
-}
-
-/* unlink a rlb hash table entry from the src list */
-static void rlb_src_unlink(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next_index = bond_info->rx_hashtbl[index].src_next;
-	u32 prev_index = bond_info->rx_hashtbl[index].src_prev;
-
-	bond_info->rx_hashtbl[index].src_next = RLB_NULL_INDEX;
-	bond_info->rx_hashtbl[index].src_prev = RLB_NULL_INDEX;
-
-	if (next_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next_index].src_prev = prev_index;
-
-	if (prev_index == RLB_NULL_INDEX)
-		return;
-
-	/* is prev_index pointing to the head of this list? */
-	if (bond_info->rx_hashtbl[prev_index].src_first == index)
-		bond_info->rx_hashtbl[prev_index].src_first = next_index;
-	else
-		bond_info->rx_hashtbl[prev_index].src_next = next_index;
-
-}
-
-static void rlb_delete_table_entry(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
-
-	rlb_delete_table_entry_dst(bond, index);
-	rlb_init_table_entry_dst(entry);
-
-	rlb_src_unlink(bond, index);
-}
-
-/* add the rx_hashtbl[ip_dst_hash] entry to the list
- * of entries with identical ip_src_hash
- */
-static void rlb_src_link(struct bonding *bond, u32 ip_src_hash, u32 ip_dst_hash)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next;
-
-	bond_info->rx_hashtbl[ip_dst_hash].src_prev = ip_src_hash;
-	next = bond_info->rx_hashtbl[ip_src_hash].src_first;
-	bond_info->rx_hashtbl[ip_dst_hash].src_next = next;
-	if (next != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next].src_prev = ip_dst_hash;
-	bond_info->rx_hashtbl[ip_src_hash].src_first = ip_dst_hash;
-}
-
-/* deletes all rx_hashtbl entries with arp->ip_src if their mac_src does
- * not match arp->mac_src
- */
-static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 ip_src_hash = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
-	u32 index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	index = bond_info->rx_hashtbl[ip_src_hash].src_first;
-	while (index != RLB_NULL_INDEX) {
-		struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
-		u32 next_index = entry->src_next;
-		if (entry->ip_src == arp->ip_src &&
-		    !ether_addr_equal_64bits(arp->mac_src, entry->mac_src))
-				rlb_delete_table_entry(bond, index);
-		index = next_index;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static int rlb_initialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info	*new_hashtbl;
-	int size = RLB_HASH_TABLE_SIZE * sizeof(struct rlb_client_info);
-	int i;
-
-	new_hashtbl = kmalloc(size, GFP_KERNEL);
-	if (!new_hashtbl)
-		return -1;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	bond_info->rx_hashtbl = new_hashtbl;
-
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	for (i = 0; i < RLB_HASH_TABLE_SIZE; i++)
-		rlb_init_table_entry(bond_info->rx_hashtbl + i);
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	/* register to receive ARPs */
-	bond->recv_probe = rlb_arp_recv;
-
-	return 0;
-}
-
-static void rlb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	spin_lock_bh(&bond->mode_lock);
-
-	kfree(bond_info->rx_hashtbl);
-	bond_info->rx_hashtbl = NULL;
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static void rlb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 curr_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	curr_index = bond_info->rx_hashtbl_used_head;
-	while (curr_index != RLB_NULL_INDEX) {
-		struct rlb_client_info *curr = &(bond_info->rx_hashtbl[curr_index]);
-		u32 next_index = bond_info->rx_hashtbl[curr_index].used_next;
-
-		if (curr->vlan_id == vlan_id)
-			rlb_delete_table_entry(bond, curr_index);
-
-		curr_index = next_index;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/*********************** tlb/rlb shared functions *********************/
-
-static void alb_send_lp_vid(struct slave *slave, u8 mac_addr[],
-			    __be16 vlan_proto, u16 vid)
-{
-	struct learning_pkt pkt;
-	struct sk_buff *skb;
-	int size = sizeof(struct learning_pkt);
-
-	memset(&pkt, 0, size);
-	ether_addr_copy(pkt.mac_dst, mac_addr);
-	ether_addr_copy(pkt.mac_src, mac_addr);
-	pkt.type = cpu_to_be16(ETH_P_LOOPBACK);
-
-	skb = dev_alloc_skb(size);
-	if (!skb)
-		return;
-
-	skb_put_data(skb, &pkt, size);
-
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = pkt.type;
-	skb->priority = TC_PRIO_CONTROL;
-	skb->dev = slave->dev;
-
-	slave_dbg(slave->bond->dev, slave->dev,
-		  "Send learning packet: mac %pM vlan %d\n", mac_addr, vid);
-
-	if (vid)
-		__vlan_hwaccel_put_tag(skb, vlan_proto, vid);
-
-	dev_queue_xmit(skb);
-}
-
-struct alb_walk_data {
-	struct bonding *bond;
-	struct slave *slave;
-	u8 *mac_addr;
-	bool strict_match;
-};
-
-static int alb_upper_dev_walk(struct net_device *upper, void *_data)
-{
-	struct alb_walk_data *data = _data;
-	bool strict_match = data->strict_match;
-	struct bonding *bond = data->bond;
-	struct slave *slave = data->slave;
-	u8 *mac_addr = data->mac_addr;
-	struct bond_vlan_tag *tags;
-
-	if (is_vlan_dev(upper) &&
-	    bond->dev->lower_level == upper->lower_level - 1) {
-		if (upper->addr_assign_type == NET_ADDR_STOLEN) {
-			alb_send_lp_vid(slave, mac_addr,
-					vlan_dev_vlan_proto(upper),
-					vlan_dev_vlan_id(upper));
-		} else {
-			alb_send_lp_vid(slave, upper->dev_addr,
-					vlan_dev_vlan_proto(upper),
-					vlan_dev_vlan_id(upper));
-		}
-	}
-
-	/* If this is a macvlan device, then only send updates
-	 * when strict_match is turned off.
-	 */
-	if (netif_is_macvlan(upper) && !strict_match) {
-		tags = bond_verify_device_path(bond->dev, upper, 0);
-		if (IS_ERR_OR_NULL(tags))
-			BUG();
-		alb_send_lp_vid(slave, upper->dev_addr,
-				tags[0].vlan_proto, tags[0].vlan_id);
-		kfree(tags);
-	}
-
-	return 0;
-}
-
-static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
-				      bool strict_match)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-	struct alb_walk_data data = {
-		.strict_match = strict_match,
-		.mac_addr = mac_addr,
-		.slave = slave,
-		.bond = bond,
-	};
-
-	/* send untagged */
-	alb_send_lp_vid(slave, mac_addr, 0, 0);
-
-	/* loop through all devices and see if we need to send a packet
-	 * for that device.
-	 */
-	rcu_read_lock();
-	netdev_walk_all_upper_dev_rcu(bond->dev, alb_upper_dev_walk, &data);
-	rcu_read_unlock();
-}
-
-static int alb_set_slave_mac_addr(struct slave *slave, u8 addr[],
-				  unsigned int len)
-{
-	struct net_device *dev = slave->dev;
-	struct sockaddr_storage ss;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_TLB) {
-		memcpy(dev->dev_addr, addr, len);
-		return 0;
-	}
-
-	/* for rlb each slave must have a unique hw mac addresses so that
-	 * each slave will receive packets destined to a different mac
-	 */
-	memcpy(ss.__data, addr, len);
-	ss.ss_family = dev->type;
-	if (dev_set_mac_address(dev, (struct sockaddr *)&ss, NULL)) {
-		slave_err(slave->bond->dev, dev, "dev_set_mac_address on slave failed! ALB mode requires that the base driver support setting the hw address also when the network device's interface is open\n");
-		return -EOPNOTSUPP;
-	}
-	return 0;
-}
-
-/* Swap MAC addresses between two slaves.
- *
- * Called with RTNL held, and no other locks.
- */
-static void alb_swap_mac_addr(struct slave *slave1, struct slave *slave2)
-{
-	u8 tmp_mac_addr[MAX_ADDR_LEN];
-
-	bond_hw_addr_copy(tmp_mac_addr, slave1->dev->dev_addr,
-			  slave1->dev->addr_len);
-	alb_set_slave_mac_addr(slave1, slave2->dev->dev_addr,
-			       slave2->dev->addr_len);
-	alb_set_slave_mac_addr(slave2, tmp_mac_addr,
-			       slave1->dev->addr_len);
-
-}
-
-/* Send learning packets after MAC address swap.
- *
- * Called with RTNL and no other locks
- */
-static void alb_fasten_mac_swap(struct bonding *bond, struct slave *slave1,
-				struct slave *slave2)
-{
-	int slaves_state_differ = (bond_slave_can_tx(slave1) != bond_slave_can_tx(slave2));
-	struct slave *disabled_slave = NULL;
-
-	ASSERT_RTNL();
-
-	/* fasten the change in the switch */
-	if (bond_slave_can_tx(slave1)) {
-		alb_send_learning_packets(slave1, slave1->dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform the clients that the mac address
-			 * has changed
-			 */
-			rlb_req_update_slave_clients(bond, slave1);
-		}
-	} else {
-		disabled_slave = slave1;
-	}
-
-	if (bond_slave_can_tx(slave2)) {
-		alb_send_learning_packets(slave2, slave2->dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform the clients that the mac address
-			 * has changed
-			 */
-			rlb_req_update_slave_clients(bond, slave2);
-		}
-	} else {
-		disabled_slave = slave2;
-	}
-
-	if (bond->alb_info.rlb_enabled && slaves_state_differ) {
-		/* A disabled slave was assigned an active mac addr */
-		rlb_teach_disabled_mac_on_primary(bond,
-						  disabled_slave->dev->dev_addr);
-	}
-}
-
-/**
- * alb_change_hw_addr_on_detach
- * @bond: bonding we're working on
- * @slave: the slave that was just detached
- *
- * We assume that @slave was already detached from the slave list.
- *
- * If @slave's permanent hw address is different both from its current
- * address and from @bond's address, then somewhere in the bond there's
- * a slave that has @slave's permanet address as its current address.
- * We'll make sure that that slave no longer uses @slave's permanent address.
- *
- * Caller must hold RTNL and no other locks
- */
-static void alb_change_hw_addr_on_detach(struct bonding *bond, struct slave *slave)
-{
-	int perm_curr_diff;
-	int perm_bond_diff;
-	struct slave *found_slave;
-
-	perm_curr_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
-						  slave->dev->dev_addr);
-	perm_bond_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
-						  bond->dev->dev_addr);
-
-	if (perm_curr_diff && perm_bond_diff) {
-		found_slave = bond_slave_has_mac(bond, slave->perm_hwaddr);
-
-		if (found_slave) {
-			alb_swap_mac_addr(slave, found_slave);
-			alb_fasten_mac_swap(bond, slave, found_slave);
-		}
-	}
-}
-
-/**
- * alb_handle_addr_collision_on_attach
- * @bond: bonding we're working on
- * @slave: the slave that was just attached
- *
- * checks uniqueness of slave's mac address and handles the case the
- * new slave uses the bonds mac address.
- *
- * If the permanent hw address of @slave is @bond's hw address, we need to
- * find a different hw address to give @slave, that isn't in use by any other
- * slave in the bond. This address must be, of course, one of the permanent
- * addresses of the other slaves.
- *
- * We go over the slave list, and for each slave there we compare its
- * permanent hw address with the current address of all the other slaves.
- * If no match was found, then we've found a slave with a permanent address
- * that isn't used by any other slave in the bond, so we can assign it to
- * @slave.
- *
- * assumption: this function is called before @slave is attached to the
- *	       bond slave list.
- */
-static int alb_handle_addr_collision_on_attach(struct bonding *bond, struct slave *slave)
-{
-	struct slave *has_bond_addr = rcu_access_pointer(bond->curr_active_slave);
-	struct slave *tmp_slave1, *free_mac_slave = NULL;
-	struct list_head *iter;
-
-	if (!bond_has_slaves(bond)) {
-		/* this is the first slave */
-		return 0;
-	}
-
-	/* if slave's mac address differs from bond's mac address
-	 * check uniqueness of slave's mac address against the other
-	 * slaves in the bond.
-	 */
-	if (!ether_addr_equal_64bits(slave->perm_hwaddr, bond->dev->dev_addr)) {
-		if (!bond_slave_has_mac(bond, slave->dev->dev_addr))
-			return 0;
-
-		/* Try setting slave mac to bond address and fall-through
-		 * to code handling that situation below...
-		 */
-		alb_set_slave_mac_addr(slave, bond->dev->dev_addr,
-				       bond->dev->addr_len);
-	}
-
-	/* The slave's address is equal to the address of the bond.
-	 * Search for a spare address in the bond for this slave.
-	 */
-	bond_for_each_slave(bond, tmp_slave1, iter) {
-		if (!bond_slave_has_mac(bond, tmp_slave1->perm_hwaddr)) {
-			/* no slave has tmp_slave1's perm addr
-			 * as its curr addr
-			 */
-			free_mac_slave = tmp_slave1;
-			break;
-		}
-
-		if (!has_bond_addr) {
-			if (ether_addr_equal_64bits(tmp_slave1->dev->dev_addr,
-						    bond->dev->dev_addr)) {
-
-				has_bond_addr = tmp_slave1;
-			}
-		}
-	}
-
-	if (free_mac_slave) {
-		alb_set_slave_mac_addr(slave, free_mac_slave->perm_hwaddr,
-				       free_mac_slave->dev->addr_len);
-
-		slave_warn(bond->dev, slave->dev, "the slave hw address is in use by the bond; giving it the hw address of %s\n",
-			   free_mac_slave->dev->name);
-
-	} else if (has_bond_addr) {
-		slave_err(bond->dev, slave->dev, "the slave hw address is in use by the bond; couldn't find a slave with a free hw address to give it (this should not have happened)\n");
-		return -EFAULT;
-	}
-
-	return 0;
-}
-
-/**
- * alb_set_mac_address
- * @bond:
- * @addr:
- *
- * In TLB mode all slaves are configured to the bond's hw address, but set
- * their dev_addr field to different addresses (based on their permanent hw
- * addresses).
- *
- * For each slave, this function sets the interface to the new address and then
- * changes its dev_addr field to its previous value.
- *
- * Unwinding assumes bond's mac address has not yet changed.
- */
-static int alb_set_mac_address(struct bonding *bond, void *addr)
-{
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	struct sockaddr_storage ss;
-	char tmp_addr[MAX_ADDR_LEN];
-	int res;
-
-	if (bond->alb_info.rlb_enabled)
-		return 0;
-
-	bond_for_each_slave(bond, slave, iter) {
-		/* save net_device's current hw address */
-		bond_hw_addr_copy(tmp_addr, slave->dev->dev_addr,
-				  slave->dev->addr_len);
-
-		res = dev_set_mac_address(slave->dev, addr, NULL);
-
-		/* restore net_device's hw address */
-		bond_hw_addr_copy(slave->dev->dev_addr, tmp_addr,
-				  slave->dev->addr_len);
-
-		if (res)
-			goto unwind;
-	}
-
-	return 0;
-
-unwind:
-	memcpy(ss.__data, bond->dev->dev_addr, bond->dev->addr_len);
-	ss.ss_family = bond->dev->type;
-
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		if (rollback_slave == slave)
-			break;
-		bond_hw_addr_copy(tmp_addr, rollback_slave->dev->dev_addr,
-				  rollback_slave->dev->addr_len);
-		dev_set_mac_address(rollback_slave->dev,
-				    (struct sockaddr *)&ss, NULL);
-		bond_hw_addr_copy(rollback_slave->dev->dev_addr, tmp_addr,
-				  rollback_slave->dev->addr_len);
-	}
-
-	return res;
-}
-
-/************************ exported alb funcions ************************/
-
-int bond_alb_initialize(struct bonding *bond, int rlb_enabled)
-{
-	int res;
-
-	res = tlb_initialize(bond);
-	if (res)
-		return res;
-
-	if (rlb_enabled) {
-		bond->alb_info.rlb_enabled = 1;
-		res = rlb_initialize(bond);
-		if (res) {
-			tlb_deinitialize(bond);
-			return res;
-		}
-	} else {
-		bond->alb_info.rlb_enabled = 0;
-	}
-
-	return 0;
-}
-
-void bond_alb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	tlb_deinitialize(bond);
-
-	if (bond_info->rlb_enabled)
-		rlb_deinitialize(bond);
-}
-
-static netdev_tx_t bond_do_alb_xmit(struct sk_buff *skb, struct bonding *bond,
-				    struct slave *tx_slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct ethhdr *eth_data = eth_hdr(skb);
-
-	if (!tx_slave) {
-		/* unbalanced or unassigned, send through primary */
-		tx_slave = rcu_dereference(bond->curr_active_slave);
-		if (bond->params.tlb_dynamic_lb)
-			bond_info->unbalanced_load += skb->len;
-	}
-
-	if (tx_slave && bond_slave_can_tx(tx_slave)) {
-		if (tx_slave != rcu_access_pointer(bond->curr_active_slave)) {
-			ether_addr_copy(eth_data->h_source,
-					tx_slave->dev->dev_addr);
-		}
-
-		bond_dev_queue_xmit(bond, skb, tx_slave->dev);
-		goto out;
-	}
-
-	if (tx_slave && bond->params.tlb_dynamic_lb) {
-		spin_lock(&bond->mode_lock);
-		__tlb_clear_slave(bond, tx_slave, 0);
-		spin_unlock(&bond->mode_lock);
-	}
-
-	/* no suitable interface, frame not sent */
-	bond_tx_drop(bond->dev, skb);
-out:
-	return NETDEV_TX_OK;
-}
-
-netdev_tx_t bond_tlb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct ethhdr *eth_data;
-	struct slave *tx_slave = NULL;
-	u32 hash_index;
-
-	skb_reset_mac_header(skb);
-	eth_data = eth_hdr(skb);
-
-	/* Do not TX balance any multicast or broadcast */
-	if (!is_multicast_ether_addr(eth_data->h_dest)) {
-		switch (skb->protocol) {
-		case htons(ETH_P_IP):
-		case htons(ETH_P_IPX):
-		    /* In case of IPX, it will falback to L2 hash */
-		case htons(ETH_P_IPV6):
-			hash_index = bond_xmit_hash(bond, skb);
-			if (bond->params.tlb_dynamic_lb) {
-				tx_slave = tlb_choose_channel(bond,
-							      hash_index & 0xFF,
-							      skb->len);
-			} else {
-				struct bond_up_slave *slaves;
-				unsigned int count;
-
-				slaves = rcu_dereference(bond->slave_arr);
-				count = slaves ? READ_ONCE(slaves->count) : 0;
-				if (likely(count))
-					tx_slave = slaves->arr[hash_index %
-							       count];
-			}
-			break;
-		}
-	}
-	return bond_do_alb_xmit(skb, bond, tx_slave);
-}
-
-netdev_tx_t bond_alb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct ethhdr *eth_data;
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *tx_slave = NULL;
-	static const __be32 ip_bcast = htonl(0xffffffff);
-	int hash_size = 0;
-	bool do_tx_balance = true;
-	u32 hash_index = 0;
-	const u8 *hash_start = NULL;
-
-	skb_reset_mac_header(skb);
-	eth_data = eth_hdr(skb);
-
-	switch (ntohs(skb->protocol)) {
-	case ETH_P_IP: {
-		const struct iphdr *iph;
-
-		if (is_broadcast_ether_addr(eth_data->h_dest) ||
-		    !pskb_network_may_pull(skb, sizeof(*iph))) {
-			do_tx_balance = false;
-			break;
-		}
-		iph = ip_hdr(skb);
-		if (iph->daddr == ip_bcast || iph->protocol == IPPROTO_IGMP) {
-			do_tx_balance = false;
-			break;
-		}
-		hash_start = (char *)&(iph->daddr);
-		hash_size = sizeof(iph->daddr);
-		break;
-	}
-	case ETH_P_IPV6: {
-		const struct ipv6hdr *ip6hdr;
-
-		/* IPv6 doesn't really use broadcast mac address, but leave
-		 * that here just in case.
-		 */
-		if (is_broadcast_ether_addr(eth_data->h_dest)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		/* IPv6 uses all-nodes multicast as an equivalent to
-		 * broadcasts in IPv4.
-		 */
-		if (ether_addr_equal_64bits(eth_data->h_dest, mac_v6_allmcast)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		if (!pskb_network_may_pull(skb, sizeof(*ip6hdr))) {
-			do_tx_balance = false;
-			break;
-		}
-		/* Additionally, DAD probes should not be tx-balanced as that
-		 * will lead to false positives for duplicate addresses and
-		 * prevent address configuration from working.
-		 */
-		ip6hdr = ipv6_hdr(skb);
-		if (ipv6_addr_any(&ip6hdr->saddr)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		hash_start = (char *)&ip6hdr->daddr;
-		hash_size = sizeof(ip6hdr->daddr);
-		break;
-	}
-	case ETH_P_IPX: {
-		const struct ipxhdr *ipxhdr;
-
-		if (pskb_network_may_pull(skb, sizeof(*ipxhdr))) {
-			do_tx_balance = false;
-			break;
-		}
-		ipxhdr = (struct ipxhdr *)skb_network_header(skb);
-
-		if (ipxhdr->ipx_checksum != IPX_NO_CHECKSUM) {
-			/* something is wrong with this packet */
-			do_tx_balance = false;
-			break;
-		}
-
-		if (ipxhdr->ipx_type != IPX_TYPE_NCP) {
-			/* The only protocol worth balancing in
-			 * this family since it has an "ARP" like
-			 * mechanism
-			 */
-			do_tx_balance = false;
-			break;
-		}
-
-		eth_data = eth_hdr(skb);
-		hash_start = (char *)eth_data->h_dest;
-		hash_size = ETH_ALEN;
-		break;
-	}
-	case ETH_P_ARP:
-		do_tx_balance = false;
-		if (bond_info->rlb_enabled)
-			tx_slave = rlb_arp_xmit(skb, bond);
-		break;
-	default:
-		do_tx_balance = false;
-		break;
-	}
-
-	if (do_tx_balance) {
-		if (bond->params.tlb_dynamic_lb) {
-			hash_index = _simple_hash(hash_start, hash_size);
-			tx_slave = tlb_choose_channel(bond, hash_index, skb->len);
-		} else {
-			/*
-			 * do_tx_balance means we are free to select the tx_slave
-			 * So we do exactly what tlb would do for hash selection
-			 */
-
-			struct bond_up_slave *slaves;
-			unsigned int count;
-
-			slaves = rcu_dereference(bond->slave_arr);
-			count = slaves ? READ_ONCE(slaves->count) : 0;
-			if (likely(count))
-				tx_slave = slaves->arr[bond_xmit_hash(bond, skb) %
-						       count];
-		}
-	}
-
-	return bond_do_alb_xmit(skb, bond, tx_slave);
-}
-
-void bond_alb_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    alb_work.work);
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (!bond_has_slaves(bond)) {
-		bond_info->tx_rebalance_counter = 0;
-		bond_info->lp_counter = 0;
-		goto re_arm;
-	}
-
-	rcu_read_lock();
-
-	bond_info->tx_rebalance_counter++;
-	bond_info->lp_counter++;
-
-	/* send learning packets */
-	if (bond_info->lp_counter >= BOND_ALB_LP_TICKS(bond)) {
-		bool strict_match;
-
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			/* If updating current_active, use all currently
-			 * user mac addreses (!strict_match).  Otherwise, only
-			 * use mac of the slave device.
-			 * In RLB mode, we always use strict matches.
-			 */
-			strict_match = (slave != rcu_access_pointer(bond->curr_active_slave) ||
-					bond_info->rlb_enabled);
-			alb_send_learning_packets(slave, slave->dev->dev_addr,
-						  strict_match);
-		}
-		bond_info->lp_counter = 0;
-	}
-
-	/* rebalance tx traffic */
-	if (bond_info->tx_rebalance_counter >= BOND_TLB_REBALANCE_TICKS) {
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			tlb_clear_slave(bond, slave, 1);
-			if (slave == rcu_access_pointer(bond->curr_active_slave)) {
-				SLAVE_TLB_INFO(slave).load =
-					bond_info->unbalanced_load /
-						BOND_TLB_REBALANCE_INTERVAL;
-				bond_info->unbalanced_load = 0;
-			}
-		}
-		bond_info->tx_rebalance_counter = 0;
-	}
-
-	if (bond_info->rlb_enabled) {
-		if (bond_info->primary_is_promisc &&
-		    (++bond_info->rlb_promisc_timeout_counter >= RLB_PROMISC_TIMEOUT)) {
-
-			/* dev_set_promiscuity requires rtnl and
-			 * nothing else.  Avoid race with bond_close.
-			 */
-			rcu_read_unlock();
-			if (!rtnl_trylock())
-				goto re_arm;
-
-			bond_info->rlb_promisc_timeout_counter = 0;
-
-			/* If the primary was set to promiscuous mode
-			 * because a slave was disabled then
-			 * it can now leave promiscuous mode.
-			 */
-			dev_set_promiscuity(rtnl_dereference(bond->curr_active_slave)->dev,
-					    -1);
-			bond_info->primary_is_promisc = 0;
-
-			rtnl_unlock();
-			rcu_read_lock();
-		}
-
-		if (bond_info->rlb_rebalance) {
-			bond_info->rlb_rebalance = 0;
-			rlb_rebalance(bond);
-		}
-
-		/* check if clients need updating */
-		if (bond_info->rx_ntt) {
-			if (bond_info->rlb_update_delay_counter) {
-				--bond_info->rlb_update_delay_counter;
-			} else {
-				rlb_update_rx_clients(bond);
-				if (bond_info->rlb_update_retry_counter)
-					--bond_info->rlb_update_retry_counter;
-				else
-					bond_info->rx_ntt = 0;
-			}
-		}
-	}
-	rcu_read_unlock();
-re_arm:
-	queue_delayed_work(bond->wq, &bond->alb_work, alb_delta_in_ticks);
-}
-
-/* assumption: called before the slave is attached to the bond
- * and not locked by the bond lock
- */
-int bond_alb_init_slave(struct bonding *bond, struct slave *slave)
-{
-	int res;
-
-	res = alb_set_slave_mac_addr(slave, slave->perm_hwaddr,
-				     slave->dev->addr_len);
-	if (res)
-		return res;
-
-	res = alb_handle_addr_collision_on_attach(bond, slave);
-	if (res)
-		return res;
-
-	tlb_init_slave(slave);
-
-	/* order a rebalance ASAP */
-	bond->alb_info.tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
-
-	if (bond->alb_info.rlb_enabled)
-		bond->alb_info.rlb_rebalance = 1;
-
-	return 0;
-}
-
-/* Remove slave from tlb and rlb hash tables, and fix up MAC addresses
- * if necessary.
- *
- * Caller must hold RTNL and no other locks
- */
-void bond_alb_deinit_slave(struct bonding *bond, struct slave *slave)
-{
-	if (bond_has_slaves(bond))
-		alb_change_hw_addr_on_detach(bond, slave);
-
-	tlb_clear_slave(bond, slave, 0);
-
-	if (bond->alb_info.rlb_enabled) {
-		bond->alb_info.rx_slave = NULL;
-		rlb_clear_slave(bond, slave);
-	}
-
-}
-
-void bond_alb_handle_link_change(struct bonding *bond, struct slave *slave, char link)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	if (link == BOND_LINK_DOWN) {
-		tlb_clear_slave(bond, slave, 0);
-		if (bond->alb_info.rlb_enabled)
-			rlb_clear_slave(bond, slave);
-	} else if (link == BOND_LINK_UP) {
-		/* order a rebalance ASAP */
-		bond_info->tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
-		if (bond->alb_info.rlb_enabled) {
-			bond->alb_info.rlb_rebalance = 1;
-			/* If the updelay module parameter is smaller than the
-			 * forwarding delay of the switch the rebalance will
-			 * not work because the rebalance arp replies will
-			 * not be forwarded to the clients..
-			 */
-		}
-	}
-
-	if (bond_is_nondyn_tlb(bond)) {
-		if (bond_update_slave_arr(bond, NULL))
-			pr_err("Failed to build slave-array for TLB mode.\n");
-	}
-}
-
-/**
- * bond_alb_handle_active_change - assign new curr_active_slave
- * @bond: our bonding struct
- * @new_slave: new slave to assign
- *
- * Set the bond->curr_active_slave to @new_slave and handle
- * mac address swapping and promiscuity changes as needed.
- *
- * Caller must hold RTNL
- */
-void bond_alb_handle_active_change(struct bonding *bond, struct slave *new_slave)
-{
-	struct slave *swap_slave;
-	struct slave *curr_active;
-
-	curr_active = rtnl_dereference(bond->curr_active_slave);
-	if (curr_active == new_slave)
-		return;
-
-	if (curr_active && bond->alb_info.primary_is_promisc) {
-		dev_set_promiscuity(curr_active->dev, -1);
-		bond->alb_info.primary_is_promisc = 0;
-		bond->alb_info.rlb_promisc_timeout_counter = 0;
-	}
-
-	swap_slave = curr_active;
-	rcu_assign_pointer(bond->curr_active_slave, new_slave);
-
-	if (!new_slave || !bond_has_slaves(bond))
-		return;
-
-	/* set the new curr_active_slave to the bonds mac address
-	 * i.e. swap mac addresses of old curr_active_slave and new curr_active_slave
-	 */
-	if (!swap_slave)
-		swap_slave = bond_slave_has_mac(bond, bond->dev->dev_addr);
-
-	/* Arrange for swap_slave and new_slave to temporarily be
-	 * ignored so we can mess with their MAC addresses without
-	 * fear of interference from transmit activity.
-	 */
-	if (swap_slave)
-		tlb_clear_slave(bond, swap_slave, 1);
-	tlb_clear_slave(bond, new_slave, 1);
-
-	/* in TLB mode, the slave might flip down/up with the old dev_addr,
-	 * and thus filter bond->dev_addr's packets, so force bond's mac
-	 */
-	if (BOND_MODE(bond) == BOND_MODE_TLB) {
-		struct sockaddr_storage ss;
-		u8 tmp_addr[MAX_ADDR_LEN];
-
-		bond_hw_addr_copy(tmp_addr, new_slave->dev->dev_addr,
-				  new_slave->dev->addr_len);
-
-		bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
-				  bond->dev->addr_len);
-		ss.ss_family = bond->dev->type;
-		/* we don't care if it can't change its mac, best effort */
-		dev_set_mac_address(new_slave->dev, (struct sockaddr *)&ss,
-				    NULL);
-
-		bond_hw_addr_copy(new_slave->dev->dev_addr, tmp_addr,
-				  new_slave->dev->addr_len);
-	}
-
-	/* curr_active_slave must be set before calling alb_swap_mac_addr */
-	if (swap_slave) {
-		/* swap mac address */
-		alb_swap_mac_addr(swap_slave, new_slave);
-		alb_fasten_mac_swap(bond, swap_slave, new_slave);
-	} else {
-		/* set the new_slave to the bond mac address */
-		alb_set_slave_mac_addr(new_slave, bond->dev->dev_addr,
-				       bond->dev->addr_len);
-		alb_send_learning_packets(new_slave, bond->dev->dev_addr,
-					  false);
-	}
-}
-
-/* Called with RTNL */
-int bond_alb_set_mac_address(struct net_device *bond_dev, void *addr)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct sockaddr_storage *ss = addr;
-	struct slave *curr_active;
-	struct slave *swap_slave;
-	int res;
-
-	if (!is_valid_ether_addr(ss->__data))
-		return -EADDRNOTAVAIL;
-
-	res = alb_set_mac_address(bond, addr);
-	if (res)
-		return res;
-
-	bond_hw_addr_copy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
-
-	/* If there is no curr_active_slave there is nothing else to do.
-	 * Otherwise we'll need to pass the new address to it and handle
-	 * duplications.
-	 */
-	curr_active = rtnl_dereference(bond->curr_active_slave);
-	if (!curr_active)
-		return 0;
-
-	swap_slave = bond_slave_has_mac(bond, bond_dev->dev_addr);
-
-	if (swap_slave) {
-		alb_swap_mac_addr(swap_slave, curr_active);
-		alb_fasten_mac_swap(bond, swap_slave, curr_active);
-	} else {
-		alb_set_slave_mac_addr(curr_active, bond_dev->dev_addr,
-				       bond_dev->addr_len);
-
-		alb_send_learning_packets(curr_active,
-					  bond_dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform clients mac address has changed */
-			rlb_req_update_slave_clients(bond, curr_active);
-		}
-	}
-
-	return 0;
-}
-
-void bond_alb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
-{
-	if (bond->alb_info.rlb_enabled)
-		rlb_clear_vlan(bond, vlan_id);
-}
-
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.19/bond_debugfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.19/bond_debugfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,125 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/device.h>
-#include <linux/netdevice.h>
-
-#include <net/bonding.h>
-#include <net/bond_alb.h>
-
-#if defined(CONFIG_DEBUG_FS) && !defined(CONFIG_NET_NS)
-
-#include <linux/debugfs.h>
-#include <linux/seq_file.h>
-
-static struct dentry *bonding_debug_root;
-
-/* Show RLB hash table */
-static int bond_debug_rlb_hash_show(struct seq_file *m, void *v)
-{
-	struct bonding *bond = m->private;
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	if (BOND_MODE(bond) != BOND_MODE_ALB)
-		return 0;
-
-	seq_printf(m, "SourceIP        DestinationIP   "
-			"Destination MAC   DEV\n");
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		seq_printf(m, "%-15pI4 %-15pI4 %-17pM %s\n",
-			&client_info->ip_src,
-			&client_info->ip_dst,
-			&client_info->mac_dst,
-			client_info->slave->dev->name);
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	return 0;
-}
-DEFINE_SHOW_ATTRIBUTE(bond_debug_rlb_hash);
-
-void bond_debug_register(struct bonding *bond)
-{
-	if (!bonding_debug_root)
-		return;
-
-	bond->debug_dir =
-		debugfs_create_dir(bond->dev->name, bonding_debug_root);
-
-	debugfs_create_file("rlb_hash_table", 0400, bond->debug_dir,
-				bond, &bond_debug_rlb_hash_fops);
-}
-
-void bond_debug_unregister(struct bonding *bond)
-{
-	if (!bonding_debug_root)
-		return;
-
-	debugfs_remove_recursive(bond->debug_dir);
-}
-
-void bond_debug_reregister(struct bonding *bond)
-{
-	struct dentry *d;
-
-	if (!bonding_debug_root)
-		return;
-
-	d = debugfs_rename(bonding_debug_root, bond->debug_dir,
-			   bonding_debug_root, bond->dev->name);
-	if (d) {
-		bond->debug_dir = d;
-	} else {
-		netdev_warn(bond->dev, "failed to reregister, so just unregister old one\n");
-		bond_debug_unregister(bond);
-	}
-}
-
-void bond_create_debugfs(void)
-{
-	bonding_debug_root = debugfs_create_dir("bonding", NULL);
-
-	if (!bonding_debug_root) {
-		pr_warn("Warning: Cannot create bonding directory in debugfs\n");
-	}
-}
-
-void bond_destroy_debugfs(void)
-{
-	debugfs_remove_recursive(bonding_debug_root);
-	bonding_debug_root = NULL;
-}
-
-
-#else /* !CONFIG_DEBUG_FS */
-
-void bond_debug_register(struct bonding *bond)
-{
-}
-
-void bond_debug_unregister(struct bonding *bond)
-{
-}
-
-void bond_debug_reregister(struct bonding *bond)
-{
-}
-
-void bond_create_debugfs(void)
-{
-}
-
-void bond_destroy_debugfs(void)
-{
-}
-
-#endif /* CONFIG_DEBUG_FS */
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.19/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.19/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,5035 +0,0 @@
-/*
- * originally based on the dummy device.
- *
- * Copyright 1999, Thomas Davis, tadavis@lbl.gov.
- * Licensed under the GPL. Based on dummy.c, and eql.c devices.
- *
- * bonding.c: an Ethernet Bonding driver
- *
- * This is useful to talk to a Cisco EtherChannel compatible equipment:
- *	Cisco 5500
- *	Sun Trunking (Solaris)
- *	Alteon AceDirector Trunks
- *	Linux Bonding
- *	and probably many L2 switches ...
- *
- * How it works:
- *    ifconfig bond0 ipaddress netmask up
- *      will setup a network device, with an ip address.  No mac address
- *	will be assigned at this time.  The hw mac address will come from
- *	the first slave bonded to the channel.  All slaves will then use
- *	this hw mac address.
- *
- *    ifconfig bond0 down
- *         will release all slaves, marking them as down.
- *
- *    ifenslave bond0 eth0
- *	will attach eth0 to bond0 as a slave.  eth0 hw mac address will either
- *	a: be used as initial mac address
- *	b: if a hw mac address already is there, eth0's hw mac address
- *	   will then be set from bond0.
- *
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/types.h>
-#include <linux/fcntl.h>
-#include <linux/interrupt.h>
-#include <linux/ptrace.h>
-#include <linux/ioport.h>
-#include <linux/in.h>
-#include <net/ip.h>
-#include <linux/ip.h>
-#include <linux/tcp.h>
-#include <linux/udp.h>
-#include <linux/slab.h>
-#include <linux/string.h>
-#include <linux/init.h>
-#include <linux/timer.h>
-#include <linux/socket.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/bitops.h>
-#include <linux/io.h>
-#include <asm/dma.h>
-#include <linux/uaccess.h>
-#include <linux/errno.h>
-#include <linux/netdevice.h>
-#include <linux/inetdevice.h>
-#include <linux/igmp.h>
-#include <linux/etherdevice.h>
-#include <linux/skbuff.h>
-#include <net/sock.h>
-#include <linux/rtnetlink.h>
-#include <linux/smp.h>
-#include <linux/if_ether.h>
-#include <net/arp.h>
-#include <linux/mii.h>
-#include <linux/ethtool.h>
-#include <linux/if_vlan.h>
-#include <linux/if_bonding.h>
-#include <linux/jiffies.h>
-#include <linux/preempt.h>
-#include <net/route.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <net/pkt_sched.h>
-#include <linux/rculist.h>
-#include <linux/toedev.h>
-#include <net/flow_dissector.h>
-#include <net/bonding.h>
-#include <net/bond_3ad.h>
-#include <net/bond_alb.h>
-
-#include "bonding_priv.h"
-
-/*---------------------------- Module parameters ----------------------------*/
-
-/* monitor all links that often (in milliseconds). <=0 disables monitoring */
-
-static int max_bonds	= BOND_DEFAULT_MAX_BONDS;
-static int tx_queues	= BOND_DEFAULT_TX_QUEUES;
-static int num_peer_notif = 1;
-static int miimon;
-static int updelay;
-static int downdelay;
-static int use_carrier	= 1;
-static char *mode;
-static char *primary;
-static char *primary_reselect;
-static char *lacp_rate;
-static int min_links;
-static char *ad_select;
-static char *xmit_hash_policy;
-static int arp_interval;
-static char *arp_ip_target[BOND_MAX_ARP_TARGETS];
-static char *arp_validate;
-static char *arp_all_targets;
-static char *fail_over_mac;
-static int all_slaves_active;
-static struct bond_params bonding_defaults;
-static int resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-static int packets_per_slave = 1;
-static int lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-
-module_param(max_bonds, int, 0);
-MODULE_PARM_DESC(max_bonds, "Max number of bonded devices");
-module_param(tx_queues, int, 0);
-MODULE_PARM_DESC(tx_queues, "Max number of transmit queues (default = 16)");
-module_param_named(num_grat_arp, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_grat_arp, "Number of peer notifications to send on "
-			       "failover event (alias of num_unsol_na)");
-module_param_named(num_unsol_na, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_unsol_na, "Number of peer notifications to send on "
-			       "failover event (alias of num_grat_arp)");
-module_param(miimon, int, 0);
-MODULE_PARM_DESC(miimon, "Link check interval in milliseconds");
-module_param(updelay, int, 0);
-MODULE_PARM_DESC(updelay, "Delay before considering link up, in milliseconds");
-module_param(downdelay, int, 0);
-MODULE_PARM_DESC(downdelay, "Delay before considering link down, "
-			    "in milliseconds");
-module_param(use_carrier, int, 0);
-MODULE_PARM_DESC(use_carrier, "Use netif_carrier_ok (vs MII ioctls) in miimon; "
-			      "0 for off, 1 for on (default)");
-module_param(mode, charp, 0);
-MODULE_PARM_DESC(mode, "Mode of operation; 0 for balance-rr, "
-		       "1 for active-backup, 2 for balance-xor, "
-		       "3 for broadcast, 4 for 802.3ad, 5 for balance-tlb, "
-		       "6 for balance-alb");
-module_param(primary, charp, 0);
-MODULE_PARM_DESC(primary, "Primary network device to use");
-module_param(primary_reselect, charp, 0);
-MODULE_PARM_DESC(primary_reselect, "Reselect primary slave "
-				   "once it comes up; "
-				   "0 for always (default), "
-				   "1 for only if speed of primary is "
-				   "better, "
-				   "2 for only on active slave "
-				   "failure");
-module_param(lacp_rate, charp, 0);
-MODULE_PARM_DESC(lacp_rate, "LACPDU tx rate to request from 802.3ad partner; "
-			    "0 for slow, 1 for fast");
-module_param(ad_select, charp, 0);
-MODULE_PARM_DESC(ad_select, "802.3ad aggregation selection logic; "
-			    "0 for stable (default), 1 for bandwidth, "
-			    "2 for count");
-module_param(min_links, int, 0);
-MODULE_PARM_DESC(min_links, "Minimum number of available links before turning on carrier");
-
-module_param(xmit_hash_policy, charp, 0);
-MODULE_PARM_DESC(xmit_hash_policy, "balance-alb, balance-tlb, balance-xor, 802.3ad hashing method; "
-				   "0 for layer 2 (default), 1 for layer 3+4, "
-				   "2 for layer 2+3, 3 for encap layer 2+3, "
-				   "4 for encap layer 3+4");
-module_param(arp_interval, int, 0);
-MODULE_PARM_DESC(arp_interval, "arp interval in milliseconds");
-module_param_array(arp_ip_target, charp, NULL, 0);
-MODULE_PARM_DESC(arp_ip_target, "arp targets in n.n.n.n form");
-module_param(arp_validate, charp, 0);
-MODULE_PARM_DESC(arp_validate, "validate src/dst of ARP probes; "
-			       "0 for none (default), 1 for active, "
-			       "2 for backup, 3 for all");
-module_param(arp_all_targets, charp, 0);
-MODULE_PARM_DESC(arp_all_targets, "fail on any/all arp targets timeout; 0 for any (default), 1 for all");
-module_param(fail_over_mac, charp, 0);
-MODULE_PARM_DESC(fail_over_mac, "For active-backup, do not set all slaves to "
-				"the same MAC; 0 for none (default), "
-				"1 for active, 2 for follow");
-module_param(all_slaves_active, int, 0);
-MODULE_PARM_DESC(all_slaves_active, "Keep all frames received on an interface "
-				     "by setting active flag for all slaves; "
-				     "0 for never (default), 1 for always.");
-module_param(resend_igmp, int, 0);
-MODULE_PARM_DESC(resend_igmp, "Number of IGMP membership reports to send on "
-			      "link failure");
-module_param(packets_per_slave, int, 0);
-MODULE_PARM_DESC(packets_per_slave, "Packets to send per slave in balance-rr "
-				    "mode; 0 for a random slave, 1 packet per "
-				    "slave (default), >1 packets per slave.");
-module_param(lp_interval, uint, 0);
-MODULE_PARM_DESC(lp_interval, "The number of seconds between instances where "
-			      "the bonding driver sends learning packets to "
-			      "each slaves peer switch. The default is 1.");
-
-/*----------------------------- Global variables ----------------------------*/
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-atomic_t netpoll_block_tx = ATOMIC_INIT(0);
-#endif
-
-unsigned int bond_net_id __read_mostly;
-
-/*-------------------------- Forward declarations ---------------------------*/
-
-static int bond_init(struct net_device *bond_dev);
-static void bond_uninit(struct net_device *bond_dev);
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats);
-static void bond_slave_arr_handler(struct work_struct *work);
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod);
-static void bond_netdev_notify_work(struct work_struct *work);
-
-/*---------------------------- General routines -----------------------------*/
-
-const char *bond_mode_name(int mode)
-{
-	static const char *names[] = {
-		[BOND_MODE_ROUNDROBIN] = "load balancing (round-robin)",
-		[BOND_MODE_ACTIVEBACKUP] = "fault-tolerance (active-backup)",
-		[BOND_MODE_XOR] = "load balancing (xor)",
-		[BOND_MODE_BROADCAST] = "fault-tolerance (broadcast)",
-		[BOND_MODE_8023AD] = "IEEE 802.3ad Dynamic link aggregation",
-		[BOND_MODE_TLB] = "transmit load balancing",
-		[BOND_MODE_ALB] = "adaptive load balancing",
-	};
-
-	if (mode < BOND_MODE_ROUNDROBIN || mode > BOND_MODE_ALB)
-		return "unknown";
-
-	return names[mode];
-}
-
-/*---------------------------------- VLAN -----------------------------------*/
-
-/**
- * bond_dev_queue_xmit - Prepare skb for xmit.
- *
- * @bond: bond device that got this skb for tx.
- * @skb: hw accel VLAN tagged skb to transmit
- * @slave_dev: slave that is supposed to xmit this skbuff
- */
-void bond_dev_queue_xmit(struct bonding *bond, struct sk_buff *skb,
-			struct net_device *slave_dev)
-{
-	skb->dev = slave_dev;
-
-	BUILD_BUG_ON(sizeof(skb->queue_mapping) !=
-		     sizeof(qdisc_skb_cb(skb)->slave_dev_queue_mapping));
-	skb_set_queue_mapping(skb, qdisc_skb_cb(skb)->slave_dev_queue_mapping);
-
-	if (unlikely(netpoll_tx_running(bond->dev)))
-		bond_netpoll_send_skb(bond_get_slave_by_dev(bond, slave_dev), skb);
-	else
-		dev_queue_xmit(skb);
-}
-
-/* In the following 2 functions, bond_vlan_rx_add_vid and bond_vlan_rx_kill_vid,
- * We don't protect the slave list iteration with a lock because:
- * a. This operation is performed in IOCTL context,
- * b. The operation is protected by the RTNL semaphore in the 8021q code,
- * c. Holding a lock with BH disabled while directly calling a base driver
- *    entry point is generally a BAD idea.
- *
- * The design of synchronization/protection for this operation in the 8021q
- * module is good for one or more VLAN devices over a single physical device
- * and cannot be extended for a teaming solution like bonding, so there is a
- * potential race condition here where a net device from the vlan group might
- * be referenced (either by a base driver or the 8021q code) while it is being
- * removed from the system. However, it turns out we're not making matters
- * worse, and if it works for regular VLAN usage it will work here too.
-*/
-
-/**
- * bond_vlan_rx_add_vid - Propagates adding an id to slaves
- * @bond_dev: bonding net device that got called
- * @vid: vlan id being added
- */
-static int bond_vlan_rx_add_vid(struct net_device *bond_dev,
-				__be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res;
-
-	bond_for_each_slave(bond, slave, iter) {
-		res = vlan_vid_add(slave->dev, proto, vid);
-		if (res)
-			goto unwind;
-	}
-
-	return 0;
-
-unwind:
-	/* unwind to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		if (rollback_slave == slave)
-			break;
-
-		vlan_vid_del(rollback_slave->dev, proto, vid);
-	}
-
-	return res;
-}
-
-/**
- * bond_vlan_rx_kill_vid - Propagates deleting an id to slaves
- * @bond_dev: bonding net device that got called
- * @vid: vlan id being removed
- */
-static int bond_vlan_rx_kill_vid(struct net_device *bond_dev,
-				 __be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		vlan_vid_del(slave->dev, proto, vid);
-
-	if (bond_is_lb(bond))
-		bond_alb_clear_vlan(bond, vid);
-
-	return 0;
-}
-
-/*------------------------------- Link status -------------------------------*/
-
-/* Set the carrier state for the master according to the state of its
- * slaves.  If any slaves are up, the master is up.  In 802.3ad mode,
- * do special 802.3ad magic.
- *
- * Returns zero if carrier state does not change, nonzero if it does.
- */
-int bond_set_carrier(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (!bond_has_slaves(bond))
-		goto down;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		return bond_3ad_set_carrier(bond);
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP) {
-			if (!netif_carrier_ok(bond->dev)) {
-				netif_carrier_on(bond->dev);
-				return 1;
-			}
-			return 0;
-		}
-	}
-
-down:
-	if (netif_carrier_ok(bond->dev)) {
-		netif_carrier_off(bond->dev);
-		return 1;
-	}
-	return 0;
-}
-
-/* Get link speed and duplex from the slave's base driver
- * using ethtool. If for some reason the call fails or the
- * values are invalid, set speed and duplex to -1,
- * and return. Return 1 if speed or duplex settings are
- * UNKNOWN; 0 otherwise.
- */
-static int bond_update_speed_duplex(struct slave *slave)
-{
-	struct net_device *slave_dev = slave->dev;
-	struct ethtool_link_ksettings ecmd;
-	int res;
-
-	slave->speed = SPEED_UNKNOWN;
-	slave->duplex = DUPLEX_UNKNOWN;
-
-	res = __ethtool_get_link_ksettings(slave_dev, &ecmd);
-	if (res < 0)
-		return 1;
-	if (ecmd.base.speed == 0 || ecmd.base.speed == ((__u32)-1))
-		return 1;
-	switch (ecmd.base.duplex) {
-	case DUPLEX_FULL:
-	case DUPLEX_HALF:
-		break;
-	default:
-		return 1;
-	}
-
-	slave->speed = ecmd.base.speed;
-	slave->duplex = ecmd.base.duplex;
-
-	return 0;
-}
-
-const char *bond_slave_link_status(s8 link)
-{
-	switch (link) {
-	case BOND_LINK_UP:
-		return "up";
-	case BOND_LINK_FAIL:
-		return "going down";
-	case BOND_LINK_DOWN:
-		return "down";
-	case BOND_LINK_BACK:
-		return "going back";
-	default:
-		return "unknown";
-	}
-}
-
-/* if <dev> supports MII link status reporting, check its link status.
- *
- * We either do MII/ETHTOOL ioctls, or check netif_carrier_ok(),
- * depending upon the setting of the use_carrier parameter.
- *
- * Return either BMSR_LSTATUS, meaning that the link is up (or we
- * can't tell and just pretend it is), or 0, meaning that the link is
- * down.
- *
- * If reporting is non-zero, instead of faking link up, return -1 if
- * both ETHTOOL and MII ioctls fail (meaning the device does not
- * support them).  If use_carrier is set, return whatever it says.
- * It'd be nice if there was a good way to tell if a driver supports
- * netif_carrier, but there really isn't.
- */
-static int bond_check_dev_link(struct bonding *bond,
-			       struct net_device *slave_dev, int reporting)
-{
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	int (*ioctl)(struct net_device *, struct ifreq *, int);
-	struct ifreq ifr;
-	struct mii_ioctl_data *mii;
-
-	if (!reporting && !netif_running(slave_dev))
-		return 0;
-
-	if (bond->params.use_carrier)
-		return netif_carrier_ok(slave_dev) ? BMSR_LSTATUS : 0;
-
-	/* Try to get link status using Ethtool first. */
-	if (slave_dev->ethtool_ops->get_link)
-		return slave_dev->ethtool_ops->get_link(slave_dev) ?
-			BMSR_LSTATUS : 0;
-
-	/* Ethtool can't be used, fallback to MII ioctls. */
-	ioctl = slave_ops->ndo_do_ioctl;
-	if (ioctl) {
-		/* TODO: set pointer to correct ioctl on a per team member
-		 *       bases to make this more efficient. that is, once
-		 *       we determine the correct ioctl, we will always
-		 *       call it and not the others for that team
-		 *       member.
-		 */
-
-		/* We cannot assume that SIOCGMIIPHY will also read a
-		 * register; not all network drivers (e.g., e100)
-		 * support that.
-		 */
-
-		/* Yes, the mii is overlaid on the ifreq.ifr_ifru */
-		strncpy(ifr.ifr_name, slave_dev->name, IFNAMSIZ);
-		mii = if_mii(&ifr);
-		if (ioctl(slave_dev, &ifr, SIOCGMIIPHY) == 0) {
-			mii->reg_num = MII_BMSR;
-			if (ioctl(slave_dev, &ifr, SIOCGMIIREG) == 0)
-				return mii->val_out & BMSR_LSTATUS;
-		}
-	}
-
-	/* If reporting, report that either there's no dev->do_ioctl,
-	 * or both SIOCGMIIREG and get_link failed (meaning that we
-	 * cannot report link status).  If not reporting, pretend
-	 * we're ok.
-	 */
-	return reporting ? -1 : BMSR_LSTATUS;
-}
-
-/*----------------------------- Multicast list ------------------------------*/
-
-/* Push the promiscuity flag down to appropriate slaves */
-static int bond_set_promiscuity(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_promiscuity(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_promiscuity(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Push the allmulti flag down to all slaves */
-static int bond_set_allmulti(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_allmulti(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_allmulti(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Retrieve the list of registered multicast addresses for the bonding
- * device and retransmit an IGMP JOIN request to the current active
- * slave.
- */
-static void bond_resend_igmp_join_requests_delayed(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mcast_work.work);
-
-	if (!rtnl_trylock()) {
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-		return;
-	}
-	call_netdevice_notifiers(NETDEV_RESEND_IGMP, bond->dev);
-
-	if (bond->igmp_retrans > 1) {
-		bond->igmp_retrans--;
-		queue_delayed_work(bond->wq, &bond->mcast_work, HZ/5);
-	}
-	rtnl_unlock();
-}
-
-/* Flush bond's hardware addresses from slave */
-static void bond_hw_addr_flush(struct net_device *bond_dev,
-			       struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	dev_uc_unsync(slave_dev, bond_dev);
-	dev_mc_unsync(slave_dev, bond_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		/* del lacpdu mc addr from mc list */
-		u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-		dev_mc_del(slave_dev, lacpdu_multicast);
-	}
-}
-
-/*--------------------------- Active slave change ---------------------------*/
-
-/* Update the hardware address list and promisc/allmulti for the new and
- * old active slaves (if any).  Modes that are not using primary keep all
- * slaves up date at all times; only the modes that use primary need to call
- * this function to swap these settings during a failover.
- */
-static void bond_hw_addr_swap(struct bonding *bond, struct slave *new_active,
-			      struct slave *old_active)
-{
-	if (old_active) {
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(old_active->dev, -1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(old_active->dev, -1);
-
-		bond_hw_addr_flush(bond->dev, old_active->dev);
-	}
-
-	if (new_active) {
-		/* FIXME: Signal errors upstream. */
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(new_active->dev, 1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(new_active->dev, 1);
-
-		netif_addr_lock_bh(bond->dev);
-		dev_uc_sync(new_active->dev, bond->dev);
-		dev_mc_sync(new_active->dev, bond->dev);
-		netif_addr_unlock_bh(bond->dev);
-	}
-}
-
-/**
- * bond_set_dev_addr - clone slave's address to bond
- * @bond_dev: bond net device
- * @slave_dev: slave net device
- *
- * Should be called with RTNL held.
- */
-static int bond_set_dev_addr(struct net_device *bond_dev,
-			     struct net_device *slave_dev)
-{
-	int err;
-
-	slave_dbg(bond_dev, slave_dev, "bond_dev=%p slave_dev=%p slave_dev->addr_len=%d\n",
-		  bond_dev, slave_dev, slave_dev->addr_len);
-	err = dev_pre_changeaddr_notify(bond_dev, slave_dev->dev_addr, NULL);
-	if (err)
-		return err;
-
-	memcpy(bond_dev->dev_addr, slave_dev->dev_addr, slave_dev->addr_len);
-	bond_dev->addr_assign_type = NET_ADDR_STOLEN;
-	call_netdevice_notifiers(NETDEV_CHANGEADDR, bond_dev);
-	return 0;
-}
-
-static struct slave *bond_get_old_active(struct bonding *bond,
-					 struct slave *new_active)
-{
-	struct slave *slave;
-	struct list_head *iter;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave == new_active)
-			continue;
-
-		if (ether_addr_equal(bond->dev->dev_addr, slave->dev->dev_addr))
-			return slave;
-	}
-
-	return NULL;
-}
-
-/* bond_do_fail_over_mac
- *
- * Perform special MAC address swapping for fail_over_mac settings
- *
- * Called with RTNL
- */
-static void bond_do_fail_over_mac(struct bonding *bond,
-				  struct slave *new_active,
-				  struct slave *old_active)
-{
-	u8 tmp_mac[MAX_ADDR_LEN];
-	struct sockaddr_storage ss;
-	int rv;
-
-	switch (bond->params.fail_over_mac) {
-	case BOND_FOM_ACTIVE:
-		if (new_active) {
-			rv = bond_set_dev_addr(bond->dev, new_active->dev);
-			if (rv)
-				slave_err(bond->dev, new_active->dev, "Error %d setting bond MAC from slave\n",
-					  -rv);
-		}
-		break;
-	case BOND_FOM_FOLLOW:
-		/* if new_active && old_active, swap them
-		 * if just old_active, do nothing (going to no active slave)
-		 * if just new_active, set new_active to bond's MAC
-		 */
-		if (!new_active)
-			return;
-
-		if (!old_active)
-			old_active = bond_get_old_active(bond, new_active);
-
-		if (old_active) {
-			bond_hw_addr_copy(tmp_mac, new_active->dev->dev_addr,
-					  new_active->dev->addr_len);
-			bond_hw_addr_copy(ss.__data,
-					  old_active->dev->dev_addr,
-					  old_active->dev->addr_len);
-			ss.ss_family = new_active->dev->type;
-		} else {
-			bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
-					  bond->dev->addr_len);
-			ss.ss_family = bond->dev->type;
-		}
-
-		rv = dev_set_mac_address(new_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv) {
-			slave_err(bond->dev, new_active->dev, "Error %d setting MAC of new active slave\n",
-				  -rv);
-			goto out;
-		}
-
-		if (!old_active)
-			goto out;
-
-		bond_hw_addr_copy(ss.__data, tmp_mac,
-				  new_active->dev->addr_len);
-		ss.ss_family = old_active->dev->type;
-
-		rv = dev_set_mac_address(old_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv)
-			slave_err(bond->dev, old_active->dev, "Error %d setting MAC of old active slave\n",
-				  -rv);
-out:
-		break;
-	default:
-		netdev_err(bond->dev, "bond_do_fail_over_mac impossible: bad policy %d\n",
-			   bond->params.fail_over_mac);
-		break;
-	}
-
-}
-
-static struct slave *bond_choose_primary_or_current(struct bonding *bond)
-{
-	struct slave *prim = rtnl_dereference(bond->primary_slave);
-	struct slave *curr = rtnl_dereference(bond->curr_active_slave);
-
-	if (!prim || prim->link != BOND_LINK_UP) {
-		if (!curr || curr->link != BOND_LINK_UP)
-			return NULL;
-		return curr;
-	}
-
-	if (bond->force_primary) {
-		bond->force_primary = false;
-		return prim;
-	}
-
-	if (!curr || curr->link != BOND_LINK_UP)
-		return prim;
-
-	/* At this point, prim and curr are both up */
-	switch (bond->params.primary_reselect) {
-	case BOND_PRI_RESELECT_ALWAYS:
-		return prim;
-	case BOND_PRI_RESELECT_BETTER:
-		if (prim->speed < curr->speed)
-			return curr;
-		if (prim->speed == curr->speed && prim->duplex <= curr->duplex)
-			return curr;
-		return prim;
-	case BOND_PRI_RESELECT_FAILURE:
-		return curr;
-	default:
-		netdev_err(bond->dev, "impossible primary_reselect %d\n",
-			   bond->params.primary_reselect);
-		return curr;
-	}
-}
-
-/**
- * bond_find_best_slave - select the best available slave to be the active one
- * @bond: our bonding struct
- */
-static struct slave *bond_find_best_slave(struct bonding *bond)
-{
-	struct slave *slave, *bestslave = NULL;
-	struct list_head *iter;
-	int mintime = bond->params.updelay;
-
-	slave = bond_choose_primary_or_current(bond);
-	if (slave)
-		return slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP)
-			return slave;
-		if (slave->link == BOND_LINK_BACK && bond_slave_is_up(slave) &&
-		    slave->delay < mintime) {
-			mintime = slave->delay;
-			bestslave = slave;
-		}
-	}
-
-	return bestslave;
-}
-
-static bool bond_should_notify_peers(struct bonding *bond)
-{
-	struct slave *slave;
-
-	rcu_read_lock();
-	slave = rcu_dereference(bond->curr_active_slave);
-	rcu_read_unlock();
-
-	netdev_dbg(bond->dev, "bond_should_notify_peers: slave %s\n",
-		   slave ? slave->dev->name : "NULL");
-
-	if (!slave || !bond->send_peer_notif ||
-	    bond->send_peer_notif %
-	    max(1, bond->params.peer_notif_delay) != 0 ||
-	    !netif_carrier_ok(bond->dev) ||
-	    test_bit(__LINK_STATE_LINKWATCH_PENDING, &slave->dev->state))
-		return false;
-
-	return true;
-}
-
-/**
- * change_active_interface - change the active slave into the specified one
- * @bond: our bonding struct
- * @new: the new slave to make the active one
- *
- * Set the new slave to the bond's settings and unset them on the old
- * curr_active_slave.
- * Setting include flags, mc-list, promiscuity, allmulti, etc.
- *
- * If @new's link state is %BOND_LINK_BACK we'll set it to %BOND_LINK_UP,
- * because it is apparently the best available slave we have, even though its
- * updelay hasn't timed out yet.
- *
- * Caller must hold RTNL.
- */
-void bond_change_active_slave(struct bonding *bond, struct slave *new_active)
-{
-	struct slave *old_active;
-
-	ASSERT_RTNL();
-
-	old_active = rtnl_dereference(bond->curr_active_slave);
-
-	if (old_active == new_active)
-		return;
-
-	if (new_active) {
-		new_active->last_link_up = jiffies;
-
-		if (new_active->link == BOND_LINK_BACK) {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one %d ms earlier\n",
-					   (bond->params.updelay - new_active->delay) * bond->params.miimon);
-			}
-
-			new_active->delay = 0;
-			bond_set_slave_link_state(new_active, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_3ad_handle_link_change(new_active, BOND_LINK_UP);
-
-			if (bond_is_lb(bond))
-				bond_alb_handle_link_change(bond, new_active, BOND_LINK_UP);
-		} else {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one\n");
-			}
-		}
-	}
-
-	if (bond_uses_primary(bond))
-		bond_hw_addr_swap(bond, new_active, old_active);
-
-	if (bond_is_lb(bond)) {
-		bond_alb_handle_active_change(bond, new_active);
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-		if (new_active)
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		rcu_assign_pointer(bond->curr_active_slave, new_active);
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP) {
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-		if (new_active) {
-			bool should_notify_peers = false;
-
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-
-			if (bond->params.fail_over_mac)
-				bond_do_fail_over_mac(bond, new_active,
-						      old_active);
-
-			if (netif_running(bond->dev)) {
-				bond->send_peer_notif =
-					bond->params.num_peer_notif *
-					max(1, bond->params.peer_notif_delay);
-				should_notify_peers =
-					bond_should_notify_peers(bond);
-			}
-
-			call_netdevice_notifiers(NETDEV_BONDING_FAILOVER, bond->dev);
-			if (should_notify_peers) {
-				bond->send_peer_notif--;
-				call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-							 bond->dev);
-			}
-		}
-	}
-
-	/* resend IGMP joins since active slave has changed or
-	 * all were sent on curr_active_slave.
-	 * resend only if bond is brought up with the affected
-	 * bonding modes and the retransmission is enabled
-	 */
-	if (netif_running(bond->dev) && (bond->params.resend_igmp > 0) &&
-	    ((bond_uses_primary(bond) && new_active) ||
-	     BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)) {
-		bond->igmp_retrans = bond->params.resend_igmp;
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-	}
-}
-
-/**
- * bond_select_active_slave - select a new active slave, if needed
- * @bond: our bonding struct
- *
- * This functions should be called when one of the following occurs:
- * - The old curr_active_slave has been released or lost its link.
- * - The primary_slave has got its link back.
- * - A slave has got its link back and there's no old curr_active_slave.
- *
- * Caller must hold RTNL.
- */
-void bond_select_active_slave(struct bonding *bond)
-{
-	struct slave *best_slave;
-	int rv;
-
-	ASSERT_RTNL();
-
-	best_slave = bond_find_best_slave(bond);
-	if (best_slave != rtnl_dereference(bond->curr_active_slave)) {
-		struct slave *last_slave = bond->curr_active_slave;
-
-		bond_change_active_slave(bond, best_slave);
-		toe_failover(bond->dev,
-			     bond->curr_active_slave ?
-			     bond->curr_active_slave->dev : NULL,
-			     TOE_ACTIVE_SLAVE,
-			     last_slave ? last_slave->dev : NULL);
-
-		rv = bond_set_carrier(bond);
-		if (!rv)
-			return;
-
-		if (netif_carrier_ok(bond->dev))
-			netdev_info(bond->dev, "active interface up!\n");
-		else
-			netdev_info(bond->dev, "now running without any active interface!\n");
-	}
-}
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	struct netpoll *np;
-	int err = 0;
-
-	np = kzalloc(sizeof(*np), GFP_KERNEL);
-	err = -ENOMEM;
-	if (!np)
-		goto out;
-
-	err = __netpoll_setup(np, slave->dev);
-	if (err) {
-		kfree(np);
-		goto out;
-	}
-	slave->np = np;
-out:
-	return err;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-	struct netpoll *np = slave->np;
-
-	if (!np)
-		return;
-
-	slave->np = NULL;
-
-	__netpoll_free(np);
-}
-
-static void bond_poll_controller(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-	struct ad_info ad_info;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		if (bond_3ad_get_active_agg_info(bond, &ad_info))
-			return;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!bond_slave_is_up(slave))
-			continue;
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg =
-			    SLAVE_AD_INFO(slave)->port.aggregator;
-
-			if (agg &&
-			    agg->aggregator_identifier != ad_info.aggregator_id)
-				continue;
-		}
-
-		netpoll_poll_dev(slave->dev);
-	}
-}
-
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		if (bond_slave_is_up(slave))
-			slave_disable_netpoll(slave);
-}
-
-static int bond_netpoll_setup(struct net_device *dev, struct netpoll_info *ni)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	struct slave *slave;
-	int err = 0;
-
-	bond_for_each_slave(bond, slave, iter) {
-		err = slave_enable_netpoll(slave);
-		if (err) {
-			bond_netpoll_cleanup(dev);
-			break;
-		}
-	}
-	return err;
-}
-#else
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	return 0;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-}
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-}
-#endif
-
-/*---------------------------------- IOCTL ----------------------------------*/
-
-static netdev_features_t bond_fix_features(struct net_device *dev,
-					   netdev_features_t features)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	netdev_features_t mask;
-	struct slave *slave;
-
-	mask = features;
-
-	features &= ~NETIF_F_ONE_FOR_ALL;
-	features |= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		features = netdev_increment_features(features,
-						     slave->dev->features,
-						     mask);
-	}
-	features = netdev_add_tso_features(features, mask);
-
-	return features;
-}
-
-#define BOND_VLAN_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_FRAGLIST | NETIF_F_ALL_TSO | \
-				 NETIF_F_HIGHDMA | NETIF_F_LRO)
-
-#define BOND_ENC_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_RXCSUM | NETIF_F_ALL_TSO)
-
-#define BOND_MPLS_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_ALL_TSO)
-
-static void bond_compute_features(struct bonding *bond)
-{
-	unsigned int dst_release_flag = IFF_XMIT_DST_RELEASE |
-					IFF_XMIT_DST_RELEASE_PERM;
-	netdev_features_t vlan_features = BOND_VLAN_FEATURES;
-	netdev_features_t enc_features  = BOND_ENC_FEATURES;
-	netdev_features_t mpls_features  = BOND_MPLS_FEATURES;
-	struct net_device *bond_dev = bond->dev;
-	struct list_head *iter;
-	struct slave *slave;
-	unsigned short max_hard_header_len = ETH_HLEN;
-	unsigned int gso_max_size = GSO_MAX_SIZE;
-	u16 gso_max_segs = GSO_MAX_SEGS;
-
-	if (!bond_has_slaves(bond))
-		goto done;
-	vlan_features &= NETIF_F_ALL_FOR_ALL;
-	mpls_features &= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		vlan_features = netdev_increment_features(vlan_features,
-			slave->dev->vlan_features, BOND_VLAN_FEATURES);
-
-		enc_features = netdev_increment_features(enc_features,
-							 slave->dev->hw_enc_features,
-							 BOND_ENC_FEATURES);
-
-		mpls_features = netdev_increment_features(mpls_features,
-							  slave->dev->mpls_features,
-							  BOND_MPLS_FEATURES);
-
-		dst_release_flag &= slave->dev->priv_flags;
-		if (slave->dev->hard_header_len > max_hard_header_len)
-			max_hard_header_len = slave->dev->hard_header_len;
-
-		gso_max_size = min(gso_max_size, slave->dev->gso_max_size);
-		gso_max_segs = min(gso_max_segs, slave->dev->gso_max_segs);
-	}
-	bond_dev->hard_header_len = max_hard_header_len;
-
-done:
-	bond_dev->vlan_features = vlan_features;
-	bond_dev->hw_enc_features = enc_features | NETIF_F_GSO_ENCAP_ALL |
-				    NETIF_F_HW_VLAN_CTAG_TX |
-				    NETIF_F_HW_VLAN_STAG_TX |
-				    NETIF_F_GSO_UDP_L4;
-	bond_dev->mpls_features = mpls_features;
-	bond_dev->gso_max_segs = gso_max_segs;
-	netif_set_gso_max_size(bond_dev, gso_max_size);
-
-	bond_dev->priv_flags &= ~IFF_XMIT_DST_RELEASE;
-	if ((bond_dev->priv_flags & IFF_XMIT_DST_RELEASE_PERM) &&
-	    dst_release_flag == (IFF_XMIT_DST_RELEASE | IFF_XMIT_DST_RELEASE_PERM))
-		bond_dev->priv_flags |= IFF_XMIT_DST_RELEASE;
-
-	netdev_change_features(bond_dev);
-}
-
-static void bond_setup_by_slave(struct net_device *bond_dev,
-				struct net_device *slave_dev)
-{
-	bond_dev->header_ops	    = slave_dev->header_ops;
-
-	bond_dev->type		    = slave_dev->type;
-	bond_dev->hard_header_len   = slave_dev->hard_header_len;
-	bond_dev->addr_len	    = slave_dev->addr_len;
-
-	memcpy(bond_dev->broadcast, slave_dev->broadcast,
-		slave_dev->addr_len);
-}
-
-/* On bonding slaves other than the currently active slave, suppress
- * duplicates except for alb non-mcast/bcast.
- */
-static bool bond_should_deliver_exact_match(struct sk_buff *skb,
-					    struct slave *slave,
-					    struct bonding *bond)
-{
-	if (bond_is_slave_inactive(slave)) {
-		if (BOND_MODE(bond) == BOND_MODE_ALB &&
-		    skb->pkt_type != PACKET_BROADCAST &&
-		    skb->pkt_type != PACKET_MULTICAST)
-			return false;
-		return true;
-	}
-	return false;
-}
-
-static rx_handler_result_t bond_handle_frame(struct sk_buff **pskb)
-{
-	struct sk_buff *skb = *pskb;
-	struct slave *slave;
-	struct bonding *bond;
-	int (*recv_probe)(const struct sk_buff *, struct bonding *,
-			  struct slave *);
-	int ret = RX_HANDLER_ANOTHER;
-
-	skb = skb_share_check(skb, GFP_ATOMIC);
-	if (unlikely(!skb))
-		return RX_HANDLER_CONSUMED;
-
-	*pskb = skb;
-
-	slave = bond_slave_get_rcu(skb->dev);
-	bond = slave->bond;
-
-	recv_probe = READ_ONCE(bond->recv_probe);
-	if (recv_probe) {
-		ret = recv_probe(skb, bond, slave);
-		if (ret == RX_HANDLER_CONSUMED) {
-			consume_skb(skb);
-			return ret;
-		}
-	}
-
-	/*
-	 * For packets determined by bond_should_deliver_exact_match() call to
-	 * be suppressed we want to make an exception for link-local packets.
-	 * This is necessary for e.g. LLDP daemons to be able to monitor
-	 * inactive slave links without being forced to bind to them
-	 * explicitly.
-	 *
-	 * At the same time, packets that are passed to the bonding master
-	 * (including link-local ones) can have their originating interface
-	 * determined via PACKET_ORIGDEV socket option.
-	 */
-	if (bond_should_deliver_exact_match(skb, slave, bond)) {
-		if (is_link_local_ether_addr(eth_hdr(skb)->h_dest))
-			return RX_HANDLER_PASS;
-		return RX_HANDLER_EXACT;
-	}
-
-	skb->dev = bond->dev;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB &&
-	    bond->dev->priv_flags & IFF_BRIDGE_PORT &&
-	    skb->pkt_type == PACKET_HOST) {
-
-		if (unlikely(skb_cow_head(skb,
-					  skb->data - skb_mac_header(skb)))) {
-			kfree_skb(skb);
-			return RX_HANDLER_CONSUMED;
-		}
-		bond_hw_addr_copy(eth_hdr(skb)->h_dest, bond->dev->dev_addr,
-				  bond->dev->addr_len);
-	}
-
-	return ret;
-}
-
-static enum netdev_lag_tx_type bond_lag_tx_type(struct bonding *bond)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return NETDEV_LAG_TX_TYPE_ROUNDROBIN;
-	case BOND_MODE_ACTIVEBACKUP:
-		return NETDEV_LAG_TX_TYPE_ACTIVEBACKUP;
-	case BOND_MODE_BROADCAST:
-		return NETDEV_LAG_TX_TYPE_BROADCAST;
-	case BOND_MODE_XOR:
-	case BOND_MODE_8023AD:
-		return NETDEV_LAG_TX_TYPE_HASH;
-	default:
-		return NETDEV_LAG_TX_TYPE_UNKNOWN;
-	}
-}
-
-static enum netdev_lag_hash bond_lag_hash_type(struct bonding *bond,
-					       enum netdev_lag_tx_type type)
-{
-	if (type != NETDEV_LAG_TX_TYPE_HASH)
-		return NETDEV_LAG_HASH_NONE;
-
-	switch (bond->params.xmit_policy) {
-	case BOND_XMIT_POLICY_LAYER2:
-		return NETDEV_LAG_HASH_L2;
-	case BOND_XMIT_POLICY_LAYER34:
-		return NETDEV_LAG_HASH_L34;
-	case BOND_XMIT_POLICY_LAYER23:
-		return NETDEV_LAG_HASH_L23;
-	case BOND_XMIT_POLICY_ENCAP23:
-		return NETDEV_LAG_HASH_E23;
-	case BOND_XMIT_POLICY_ENCAP34:
-		return NETDEV_LAG_HASH_E34;
-	default:
-		return NETDEV_LAG_HASH_UNKNOWN;
-	}
-}
-
-static int bond_master_upper_dev_link(struct bonding *bond, struct slave *slave,
-				      struct netlink_ext_ack *extack)
-{
-	struct netdev_lag_upper_info lag_upper_info;
-	enum netdev_lag_tx_type type;
-
-	type = bond_lag_tx_type(bond);
-	lag_upper_info.tx_type = type;
-	lag_upper_info.hash_type = bond_lag_hash_type(bond, type);
-
-	return netdev_master_upper_dev_link(slave->dev, bond->dev, slave,
-					    &lag_upper_info, extack);
-}
-
-static void bond_upper_dev_unlink(struct bonding *bond, struct slave *slave)
-{
-	netdev_upper_dev_unlink(slave->dev, bond->dev);
-	slave->dev->flags &= ~IFF_SLAVE;
-}
-
-static struct slave *bond_alloc_slave(struct bonding *bond)
-{
-	struct slave *slave = NULL;
-
-	slave = kzalloc(sizeof(*slave), GFP_KERNEL);
-	if (!slave)
-		return NULL;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		SLAVE_AD_INFO(slave) = kzalloc(sizeof(struct ad_slave_info),
-					       GFP_KERNEL);
-		if (!SLAVE_AD_INFO(slave)) {
-			kfree(slave);
-			return NULL;
-		}
-	}
-	INIT_DELAYED_WORK(&slave->notify_work, bond_netdev_notify_work);
-
-	return slave;
-}
-
-static void bond_free_slave(struct slave *slave)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-
-	cancel_delayed_work_sync(&slave->notify_work);
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		kfree(SLAVE_AD_INFO(slave));
-
-	kfree(slave);
-}
-
-static void bond_fill_ifbond(struct bonding *bond, struct ifbond *info)
-{
-	info->bond_mode = BOND_MODE(bond);
-	info->miimon = bond->params.miimon;
-	info->num_slaves = bond->slave_cnt;
-}
-
-static void bond_fill_ifslave(struct slave *slave, struct ifslave *info)
-{
-	strcpy(info->slave_name, slave->dev->name);
-	info->link = slave->link;
-	info->state = bond_slave_state(slave);
-	info->link_failure_count = slave->link_failure_count;
-}
-
-static void bond_netdev_notify_work(struct work_struct *_work)
-{
-	struct slave *slave = container_of(_work, struct slave,
-					   notify_work.work);
-
-	if (rtnl_trylock()) {
-		struct netdev_bonding_info binfo;
-
-		bond_fill_ifslave(slave, &binfo.slave);
-		bond_fill_ifbond(slave->bond, &binfo.master);
-		netdev_bonding_info_change(slave->dev, &binfo);
-		rtnl_unlock();
-	} else {
-		queue_delayed_work(slave->bond->wq, &slave->notify_work, 1);
-	}
-}
-
-void bond_queue_slave_event(struct slave *slave)
-{
-	queue_delayed_work(slave->bond->wq, &slave->notify_work, 0);
-}
-
-void bond_lower_state_changed(struct slave *slave)
-{
-	struct netdev_lag_lower_state_info info;
-
-	info.link_up = slave->link == BOND_LINK_UP ||
-		       slave->link == BOND_LINK_FAIL;
-	info.tx_enabled = bond_is_active_slave(slave);
-	netdev_lower_state_changed(slave->dev, &info);
-}
-
-/* enslave device <slave> to bond device <master> */
-int bond_enslave(struct net_device *bond_dev, struct net_device *slave_dev,
-		 struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	struct slave *new_slave = NULL, *prev_slave;
-	struct sockaddr_storage ss;
-	int link_reporting;
-	int res = 0, i;
-
-	if (!bond->params.use_carrier &&
-	    slave_dev->ethtool_ops->get_link == NULL &&
-	    slave_ops->ndo_do_ioctl == NULL) {
-		slave_warn(bond_dev, slave_dev, "no link monitoring support\n");
-	}
-
-	/* already in-use? */
-	if (netdev_is_rx_handler_busy(slave_dev)) {
-		NL_SET_ERR_MSG(extack, "Device is in use and cannot be enslaved");
-		slave_err(bond_dev, slave_dev,
-			  "Error: Device is in use and cannot be enslaved\n");
-		return -EBUSY;
-	}
-
-	if (bond_dev == slave_dev) {
-		NL_SET_ERR_MSG(extack, "Cannot enslave bond to itself.");
-		netdev_err(bond_dev, "cannot enslave bond to itself.\n");
-		return -EPERM;
-	}
-
-	/* vlan challenged mutual exclusion */
-	/* no need to lock since we're protected by rtnl_lock */
-	if (slave_dev->features & NETIF_F_VLAN_CHALLENGED) {
-		slave_dbg(bond_dev, slave_dev, "is NETIF_F_VLAN_CHALLENGED\n");
-		if (vlan_uses_dev(bond_dev)) {
-			NL_SET_ERR_MSG(extack, "Can not enslave VLAN challenged device to VLAN enabled bond");
-			slave_err(bond_dev, slave_dev, "Error: cannot enslave VLAN challenged slave on VLAN enabled bond\n");
-			return -EPERM;
-		} else {
-			slave_warn(bond_dev, slave_dev, "enslaved VLAN challenged slave. Adding VLANs will be blocked as long as it is part of bond.\n");
-		}
-	} else {
-		slave_dbg(bond_dev, slave_dev, "is !NETIF_F_VLAN_CHALLENGED\n");
-	}
-
-	/* Old ifenslave binaries are no longer supported.  These can
-	 * be identified with moderate accuracy by the state of the slave:
-	 * the current ifenslave will set the interface down prior to
-	 * enslaving it; the old ifenslave will not.
-	 */
-	if (slave_dev->flags & IFF_UP) {
-		NL_SET_ERR_MSG(extack, "Device can not be enslaved while up");
-		slave_err(bond_dev, slave_dev, "slave is up - this may be due to an out of date ifenslave\n");
-		return -EPERM;
-	}
-
-	/* set bonding device ether type by slave - bonding netdevices are
-	 * created with ether_setup, so when the slave type is not ARPHRD_ETHER
-	 * there is a need to override some of the type dependent attribs/funcs.
-	 *
-	 * bond ether type mutual exclusion - don't allow slaves of dissimilar
-	 * ether type (eg ARPHRD_ETHER and ARPHRD_INFINIBAND) share the same bond
-	 */
-	if (!bond_has_slaves(bond)) {
-		if (bond_dev->type != slave_dev->type) {
-			slave_dbg(bond_dev, slave_dev, "change device type from %d to %d\n",
-				  bond_dev->type, slave_dev->type);
-
-			res = call_netdevice_notifiers(NETDEV_PRE_TYPE_CHANGE,
-						       bond_dev);
-			res = notifier_to_errno(res);
-			if (res) {
-				slave_err(bond_dev, slave_dev, "refused to change device type\n");
-				return -EBUSY;
-			}
-
-			/* Flush unicast and multicast addresses */
-			dev_uc_flush(bond_dev);
-			dev_mc_flush(bond_dev);
-
-			if (slave_dev->type != ARPHRD_ETHER)
-				bond_setup_by_slave(bond_dev, slave_dev);
-			else {
-				ether_setup(bond_dev);
-				bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-			}
-
-			call_netdevice_notifiers(NETDEV_POST_TYPE_CHANGE,
-						 bond_dev);
-		}
-	} else if (bond_dev->type != slave_dev->type) {
-		NL_SET_ERR_MSG(extack, "Device type is different from other slaves");
-		slave_err(bond_dev, slave_dev, "ether type (%d) is different from other slaves (%d), can not enslave it\n",
-			  slave_dev->type, bond_dev->type);
-		return -EINVAL;
-	}
-
-	if (slave_dev->type == ARPHRD_INFINIBAND &&
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		NL_SET_ERR_MSG(extack, "Only active-backup mode is supported for infiniband slaves");
-		slave_warn(bond_dev, slave_dev, "Type (%d) supports only active-backup mode\n",
-			   slave_dev->type);
-		res = -EOPNOTSUPP;
-		goto err_undo_flags;
-	}
-
-	if (!slave_ops->ndo_set_mac_address ||
-	    slave_dev->type == ARPHRD_INFINIBAND) {
-		slave_warn(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address\n");
-		if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
-		    bond->params.fail_over_mac != BOND_FOM_ACTIVE) {
-			if (!bond_has_slaves(bond)) {
-				bond->params.fail_over_mac = BOND_FOM_ACTIVE;
-				slave_warn(bond_dev, slave_dev, "Setting fail_over_mac to active for active-backup mode\n");
-			} else {
-				NL_SET_ERR_MSG(extack, "Slave device does not support setting the MAC address, but fail_over_mac is not set to active");
-				slave_err(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address, but fail_over_mac is not set to active\n");
-				res = -EOPNOTSUPP;
-				goto err_undo_flags;
-			}
-		}
-	}
-
-	call_netdevice_notifiers(NETDEV_JOIN, slave_dev);
-
-	/* If this is the first slave, then we need to set the master's hardware
-	 * address to be the same as the slave's.
-	 */
-	if (!bond_has_slaves(bond) &&
-	    bond->dev->addr_assign_type == NET_ADDR_RANDOM) {
-		res = bond_set_dev_addr(bond->dev, slave_dev);
-		if (res)
-			goto err_undo_flags;
-	}
-
-	new_slave = bond_alloc_slave(bond);
-	if (!new_slave) {
-		res = -ENOMEM;
-		goto err_undo_flags;
-	}
-
-	new_slave->bond = bond;
-	new_slave->dev = slave_dev;
-	/* Set the new_slave's queue_id to be zero.  Queue ID mapping
-	 * is set via sysfs or module option if desired.
-	 */
-	new_slave->queue_id = 0;
-
-	/* Save slave's original mtu and then set it to match the bond */
-	new_slave->original_mtu = slave_dev->mtu;
-	res = dev_set_mtu(slave_dev, bond->dev->mtu);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Error %d calling dev_set_mtu\n", res);
-		goto err_free;
-	}
-
-	/* Save slave's original ("permanent") mac address for modes
-	 * that need it, and for restoring it upon release, and then
-	 * set it to the master's address
-	 */
-	bond_hw_addr_copy(new_slave->perm_hwaddr, slave_dev->dev_addr,
-			  slave_dev->addr_len);
-
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* Set slave to master's mac address.  The application already
-		 * set the master's mac address to that of the first slave
-		 */
-		memcpy(ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		res = dev_set_mac_address(slave_dev, (struct sockaddr *)&ss,
-					  extack);
-		if (res) {
-			slave_err(bond_dev, slave_dev, "Error %d calling set_mac_address\n", res);
-			goto err_restore_mtu;
-		}
-	}
-
-	/* set slave flag before open to prevent IPv6 addrconf */
-	slave_dev->flags |= IFF_SLAVE;
-
-	/* open the slave since the application closed it */
-	res = dev_open(slave_dev, extack);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Opening slave failed\n");
-		goto err_restore_mac;
-	}
-
-	slave_dev->priv_flags |= IFF_BONDING;
-	/* initialize slave stats */
-	dev_get_stats(new_slave->dev, &new_slave->slave_stats);
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_init_slave() must be called before all other stages since
-		 * it might fail and we do not want to have to undo everything
-		 */
-		res = bond_alb_init_slave(bond, new_slave);
-		if (res)
-			goto err_close;
-	}
-
-	res = vlan_vids_add_by_dev(slave_dev, bond_dev);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Couldn't add bond vlan ids\n");
-		goto err_close;
-	}
-
-	prev_slave = bond_last_slave(bond);
-
-	new_slave->delay = 0;
-	new_slave->link_failure_count = 0;
-
-	if (bond_update_speed_duplex(new_slave) &&
-	    bond_needs_speed_duplex(bond))
-		new_slave->link = BOND_LINK_DOWN;
-
-	new_slave->last_rx = jiffies -
-		(msecs_to_jiffies(bond->params.arp_interval) + 1);
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
-		new_slave->target_last_arp_rx[i] = new_slave->last_rx;
-
-	if (bond->params.miimon && !bond->params.use_carrier) {
-		link_reporting = bond_check_dev_link(bond, slave_dev, 1);
-
-		if ((link_reporting == -1) && !bond->params.arp_interval) {
-			/* miimon is set but a bonded network driver
-			 * does not support ETHTOOL/MII and
-			 * arp_interval is not set.  Note: if
-			 * use_carrier is enabled, we will never go
-			 * here (because netif_carrier is always
-			 * supported); thus, we don't need to change
-			 * the messages for netif_carrier.
-			 */
-			slave_warn(bond_dev, slave_dev, "MII and ETHTOOL support not available for slave, and arp_interval/arp_ip_target module parameters not specified, thus bonding will not detect link failures! see bonding.txt for details\n");
-		} else if (link_reporting == -1) {
-			/* unable get link status using mii/ethtool */
-			slave_warn(bond_dev, slave_dev, "can't get link status from slave; the network driver associated with this interface does not support MII or ETHTOOL link status reporting, thus miimon has no effect on this interface\n");
-		}
-	}
-
-	/* check for initial state */
-	new_slave->link = BOND_LINK_NOCHANGE;
-	if (bond->params.miimon) {
-		if (bond_check_dev_link(bond, slave_dev, 0) == BMSR_LSTATUS) {
-			if (bond->params.updelay) {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_BACK,
-							  BOND_SLAVE_NOTIFY_NOW);
-				new_slave->delay = bond->params.updelay;
-			} else {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-			}
-		} else {
-			bond_set_slave_link_state(new_slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-		}
-	} else if (bond->params.arp_interval) {
-		bond_set_slave_link_state(new_slave,
-					  (netif_carrier_ok(slave_dev) ?
-					  BOND_LINK_UP : BOND_LINK_DOWN),
-					  BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		bond_set_slave_link_state(new_slave, BOND_LINK_UP,
-					  BOND_SLAVE_NOTIFY_NOW);
-	}
-
-	if (new_slave->link != BOND_LINK_DOWN)
-		new_slave->last_link_up = jiffies;
-	slave_dbg(bond_dev, slave_dev, "Initial state of slave is BOND_LINK_%s\n",
-		  new_slave->link == BOND_LINK_DOWN ? "DOWN" :
-		  (new_slave->link == BOND_LINK_UP ? "UP" : "BACK"));
-
-	if (bond_uses_primary(bond) && bond->params.primary[0]) {
-		/* if there is a primary slave, remember it */
-		if (strcmp(bond->params.primary, new_slave->dev->name) == 0) {
-			rcu_assign_pointer(bond->primary_slave, new_slave);
-			bond->force_primary = true;
-		}
-	}
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ACTIVEBACKUP:
-		bond_set_slave_inactive_flags(new_slave,
-					      BOND_SLAVE_NOTIFY_NOW);
-		break;
-	case BOND_MODE_8023AD:
-		/* in 802.3ad mode, the internal mechanism
-		 * will activate the slaves in the selected
-		 * aggregator
-		 */
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		/* if this is the first slave */
-		if (!prev_slave) {
-			SLAVE_AD_INFO(new_slave)->id = 1;
-			/* Initialize AD with the number of times that the AD timer is called in 1 second
-			 * can be called only after the mac address of the bond is set
-			 */
-			bond_3ad_initialize(bond, 1000/AD_TIMER_INTERVAL);
-		} else {
-			SLAVE_AD_INFO(new_slave)->id =
-				SLAVE_AD_INFO(prev_slave)->id + 1;
-		}
-
-		bond_3ad_bind_slave(new_slave);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_set_active_slave(new_slave);
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		break;
-	default:
-		slave_dbg(bond_dev, slave_dev, "This slave is always active in trunk mode\n");
-
-		/* always active in trunk mode */
-		bond_set_active_slave(new_slave);
-
-		/* In trunking mode there is little meaning to curr_active_slave
-		 * anyway (it holds no special properties of the bond device),
-		 * so we can change it without calling change_active_interface()
-		 */
-		if (!rcu_access_pointer(bond->curr_active_slave) &&
-		    new_slave->link == BOND_LINK_UP)
-			rcu_assign_pointer(bond->curr_active_slave, new_slave);
-
-		break;
-	} /* switch(bond_mode) */
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	if (bond->dev->npinfo) {
-		if (slave_enable_netpoll(new_slave)) {
-			slave_info(bond_dev, slave_dev, "master_dev is using netpoll, but new slave device does not support netpoll\n");
-			res = -EBUSY;
-			goto err_detach;
-		}
-	}
-#endif
-
-	if (!(bond_dev->features & NETIF_F_LRO))
-		dev_disable_lro(slave_dev);
-
-	res = netdev_rx_handler_register(slave_dev, bond_handle_frame,
-					 new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling netdev_rx_handler_register\n", res);
-		goto err_detach;
-	}
-
-	res = bond_master_upper_dev_link(bond, new_slave, extack);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_master_upper_dev_link\n", res);
-		goto err_unregister;
-	}
-
-	res = bond_sysfs_slave_add(new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_sysfs_slave_add\n", res);
-		goto err_upper_unlink;
-	}
-
-	/* If the mode uses primary, then the following is handled by
-	 * bond_change_active_slave().
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* set promiscuity level to new slave */
-		if (bond_dev->flags & IFF_PROMISC) {
-			res = dev_set_promiscuity(slave_dev, 1);
-			if (res)
-				goto err_sysfs_del;
-		}
-
-		/* set allmulti level to new slave */
-		if (bond_dev->flags & IFF_ALLMULTI) {
-			res = dev_set_allmulti(slave_dev, 1);
-			if (res) {
-				if (bond_dev->flags & IFF_PROMISC)
-					dev_set_promiscuity(slave_dev, -1);
-				goto err_sysfs_del;
-			}
-		}
-
-		netif_addr_lock_bh(bond_dev);
-		dev_mc_sync_multiple(slave_dev, bond_dev);
-		dev_uc_sync_multiple(slave_dev, bond_dev);
-		netif_addr_unlock_bh(bond_dev);
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			/* add lacpdu mc addr to mc list */
-			u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-			dev_mc_add(slave_dev, lacpdu_multicast);
-		}
-	}
-
-	bond->slave_cnt++;
-	bond_compute_features(bond);
-	bond_set_carrier(bond);
-
-	if (bond_uses_primary(bond)) {
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-
-	slave_info(bond_dev, slave_dev, "Enslaving as %s interface with %s link\n",
-		   bond_is_active_slave(new_slave) ? "an active" : "a backup",
-		   new_slave->link != BOND_LINK_DOWN ? "an up" : "a down");
-
-	/* enslave is successful */
-	bond_queue_slave_event(new_slave);
-	return 0;
-
-/* Undo stages on error */
-err_sysfs_del:
-	bond_sysfs_slave_del(new_slave);
-
-err_upper_unlink:
-	bond_upper_dev_unlink(bond, new_slave);
-
-err_unregister:
-	netdev_rx_handler_unregister(slave_dev);
-
-err_detach:
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-	if (rcu_access_pointer(bond->primary_slave) == new_slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-	if (rcu_access_pointer(bond->curr_active_slave) == new_slave) {
-		block_netpoll_tx();
-		bond_change_active_slave(bond, NULL);
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-	/* either primary_slave or curr_active_slave might've changed */
-	synchronize_rcu();
-	slave_disable_netpoll(new_slave);
-
-err_close:
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-	dev_close(slave_dev);
-
-err_restore_mac:
-	slave_dev->flags &= ~IFF_SLAVE;
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* XXX TODO - fom follow mode needs to change master's
-		 * MAC if this slave's MAC is in use by the bond, or at
-		 * least print a warning.
-		 */
-		bond_hw_addr_copy(ss.__data, new_slave->perm_hwaddr,
-				  new_slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-err_restore_mtu:
-	dev_set_mtu(slave_dev, new_slave->original_mtu);
-
-err_free:
-	bond_free_slave(new_slave);
-
-err_undo_flags:
-	/* Enslave of first slave has failed and we need to fix master's mac */
-	if (!bond_has_slaves(bond)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr,
-					    slave_dev->dev_addr))
-			eth_hw_addr_random(bond_dev);
-		if (bond_dev->type != ARPHRD_ETHER) {
-			dev_close(bond_dev);
-			ether_setup(bond_dev);
-			bond_dev->flags |= IFF_MASTER;
-			bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-		}
-	}
-
-	return res;
-}
-
-/* Try to release the slave device <slave> from the bond device <master>
- * It is legal to access curr_active_slave without a lock because all the function
- * is RTNL-locked. If "all" is true it means that the function is being called
- * while destroying a bond interface and all slaves are being released.
- *
- * The rules for slave state should be:
- *   for Active/Backup:
- *     Active stays on all backups go down
- *   for Bonded connections:
- *     The first up interface should be left on and all others downed.
- */
-static int __bond_release_one(struct net_device *bond_dev,
-			      struct net_device *slave_dev,
-			      bool all, bool unregister)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *oldcurrent;
-	struct sockaddr_storage ss;
-	int old_flags = bond_dev->flags;
-	netdev_features_t old_features = bond_dev->features;
-
-	/* slave is not a slave or master is not master of this slave */
-	if (!(slave_dev->flags & IFF_SLAVE) ||
-	    !netdev_has_upper_dev(slave_dev, bond_dev)) {
-		slave_dbg(bond_dev, slave_dev, "cannot release slave\n");
-		return -EINVAL;
-	}
-
-	block_netpoll_tx();
-
-	slave = bond_get_slave_by_dev(bond, slave_dev);
-	if (!slave) {
-		/* not a slave of this bond */
-		slave_info(bond_dev, slave_dev, "interface not enslaved\n");
-		unblock_netpoll_tx();
-		return -EINVAL;
-	}
-
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
-	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
-
-	bond_sysfs_slave_del(slave);
-
-	/* recompute stats just before removing the slave */
-	bond_get_stats(bond->dev, &bond->bond_stats);
-
-	bond_upper_dev_unlink(bond, slave);
-	/* unregister rx_handler early so bond_handle_frame wouldn't be called
-	 * for this slave anymore.
-	 */
-	netdev_rx_handler_unregister(slave_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		bond_3ad_unbind_slave(slave);
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, slave);
-
-	slave_info(bond_dev, slave_dev, "Releasing %s interface\n",
-		    bond_is_active_slave(slave) ? "active" : "backup");
-
-	oldcurrent = rcu_access_pointer(bond->curr_active_slave);
-
-	RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-
-	if (!all && (!bond->params.fail_over_mac ||
-		     BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr, slave->perm_hwaddr) &&
-		    bond_has_slaves(bond))
-			slave_warn(bond_dev, slave_dev, "the permanent HWaddr of slave - %pM - is still in use by bond - set the HWaddr of slave to a different address to avoid conflicts\n",
-				   slave->perm_hwaddr);
-	}
-
-	if (rtnl_dereference(bond->primary_slave) == slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-
-	if (oldcurrent == slave)
-		bond_change_active_slave(bond, NULL);
-
-	if (bond_is_lb(bond)) {
-		/* Must be called only after the slave has been
-		 * detached from the list and the curr_active_slave
-		 * has been cleared (if our_slave == old_current),
-		 * but before a new active slave is selected.
-		 */
-		bond_alb_deinit_slave(bond, slave);
-	}
-
-	if (all) {
-		toe_failover(bond_dev, NULL, TOE_RELEASE_ALL, NULL);
-		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
-	} else if (oldcurrent == slave) {
-		/* Note that we hold RTNL over this sequence, so there
-		 * is no concern that another slave add/remove event
-		 * will interfere.
-		 */
-		bond_select_active_slave(bond);
-	}
-
-	if (!bond_has_slaves(bond)) {
-		bond_set_carrier(bond);
-		eth_hw_addr_random(bond_dev);
-	}
-
-	unblock_netpoll_tx();
-	synchronize_rcu();
-	bond->slave_cnt--;
-
-	if (!bond_has_slaves(bond)) {
-		call_netdevice_notifiers(NETDEV_CHANGEADDR, bond->dev);
-		call_netdevice_notifiers(NETDEV_RELEASE, bond->dev);
-	}
-
-	bond_compute_features(bond);
-	if (!(bond_dev->features & NETIF_F_VLAN_CHALLENGED) &&
-	    (old_features & NETIF_F_VLAN_CHALLENGED))
-		slave_info(bond_dev, slave_dev, "last VLAN challenged slave left bond - VLAN blocking is removed\n");
-
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-
-	/* If the mode uses primary, then this case was handled above by
-	 * bond_change_active_slave(..., NULL)
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* unset promiscuity level from slave
-		 * NOTE: The NETDEV_CHANGEADDR call above may change the value
-		 * of the IFF_PROMISC flag in the bond_dev, but we need the
-		 * value of that flag before that change, as that was the value
-		 * when this slave was attached, so we cache at the start of the
-		 * function and use it here. Same goes for ALLMULTI below
-		 */
-		if (old_flags & IFF_PROMISC)
-			dev_set_promiscuity(slave_dev, -1);
-
-		/* unset allmulti level from slave */
-		if (old_flags & IFF_ALLMULTI)
-			dev_set_allmulti(slave_dev, -1);
-
-		bond_hw_addr_flush(bond_dev, slave_dev);
-	}
-
-	slave_disable_netpoll(slave);
-
-	/* close slave before restoring its mac address */
-	dev_close(slave_dev);
-
-	if (bond->params.fail_over_mac != BOND_FOM_ACTIVE ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* restore original ("permanent") mac address */
-		bond_hw_addr_copy(ss.__data, slave->perm_hwaddr,
-				  slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-	if (unregister)
-		__dev_set_mtu(slave_dev, slave->original_mtu);
-	else
-		dev_set_mtu(slave_dev, slave->original_mtu);
-
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-
-	bond_free_slave(slave);
-
-	return 0;
-}
-
-/* A wrapper used because of ndo_del_link */
-int bond_release(struct net_device *bond_dev, struct net_device *slave_dev)
-{
-	return __bond_release_one(bond_dev, slave_dev, false, false);
-}
-
-/* First release a slave and then destroy the bond if no more slaves are left.
- * Must be under rtnl_lock when this function is called.
- */
-static int bond_release_and_destroy(struct net_device *bond_dev,
-				    struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	int ret;
-
-	ret = __bond_release_one(bond_dev, slave_dev, false, true);
-	if (ret == 0 && !bond_has_slaves(bond)) {
-		bond_dev->priv_flags |= IFF_DISABLE_NETPOLL;
-		netdev_info(bond_dev, "Destroying bond\n");
-		bond_remove_proc_entry(bond);
-		unregister_netdevice(bond_dev);
-	}
-	return ret;
-}
-
-static void bond_info_query(struct net_device *bond_dev, struct ifbond *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	bond_fill_ifbond(bond, info);
-}
-
-static int bond_slave_info_query(struct net_device *bond_dev, struct ifslave *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	int i = 0, res = -ENODEV;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (i++ == (int)info->slave_id) {
-			res = 0;
-			bond_fill_ifslave(slave, info);
-			break;
-		}
-	}
-
-	return res;
-}
-
-/*-------------------------------- Monitoring -------------------------------*/
-
-/* called with rcu_read_lock() */
-static int bond_miimon_inspect(struct bonding *bond)
-{
-	int link_state, commit = 0;
-	struct list_head *iter;
-	struct slave *slave;
-	bool ignore_updelay;
-
-	ignore_updelay = !rcu_dereference(bond->curr_active_slave);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		link_state = bond_check_dev_link(bond, slave->dev, 0);
-
-		switch (slave->link) {
-		case BOND_LINK_UP:
-			if (link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_FAIL);
-			commit++;
-			slave->delay = bond->params.downdelay;
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status down for %sinterface, disabling it in %d ms\n",
-					   (BOND_MODE(bond) ==
-					    BOND_MODE_ACTIVEBACKUP) ?
-					    (bond_is_active_slave(slave) ?
-					     "active " : "backup ") : "",
-					   bond->params.downdelay * bond->params.miimon);
-			}
-			/*FALLTHRU*/
-		case BOND_LINK_FAIL:
-			if (link_state) {
-				/* recovered before downdelay expired */
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave->last_link_up = jiffies;
-				slave_info(bond->dev, slave->dev, "link status up again after %d ms\n",
-					   (bond->params.downdelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				commit++;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-
-		case BOND_LINK_DOWN:
-			if (!link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_BACK);
-			commit++;
-			slave->delay = bond->params.updelay;
-
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status up, enabling it in %d ms\n",
-					   ignore_updelay ? 0 :
-					   bond->params.updelay *
-					   bond->params.miimon);
-			}
-			/*FALLTHRU*/
-		case BOND_LINK_BACK:
-			if (!link_state) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_info(bond->dev, slave->dev, "link status down again after %d ms\n",
-					   (bond->params.updelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (ignore_updelay)
-				slave->delay = 0;
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-				ignore_updelay = false;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-		}
-	}
-
-	return commit;
-}
-
-static void bond_miimon_link_change(struct bonding *bond,
-				    struct slave *slave,
-				    char link)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_8023AD:
-		bond_3ad_handle_link_change(slave, link);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_alb_handle_link_change(bond, slave, link);
-		break;
-	case BOND_MODE_XOR:
-		bond_update_slave_arr(bond, NULL);
-		break;
-	}
-}
-
-static void bond_miimon_commit(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave, *primary;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			/* For 802.3ad mode, check current slave speed and
-			 * duplex again in case its port was disabled after
-			 * invalid speed/duplex reporting but recovered before
-			 * link monitoring could make a decision on the actual
-			 * link status
-			 */
-			if (BOND_MODE(bond) == BOND_MODE_8023AD &&
-			    slave->link == BOND_LINK_UP)
-				bond_3ad_adapter_speed_duplex_changed(slave);
-			continue;
-
-		case BOND_LINK_UP:
-			if (bond_update_speed_duplex(slave) &&
-			    bond_needs_speed_duplex(bond)) {
-				slave->link = BOND_LINK_DOWN;
-				if (net_ratelimit())
-					slave_warn(bond->dev, slave->dev,
-						   "failed to get link speed/duplex\n");
-				continue;
-			}
-			bond_set_slave_link_state(slave, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-			slave->last_link_up = jiffies;
-
-			primary = rtnl_dereference(bond->primary_slave);
-			if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-				/* prevent it from being the active one */
-				bond_set_backup_slave(slave);
-			} else if (BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-				/* make it immediately active */
-				bond_set_active_slave(slave);
-			}
-
-			slave_info(bond->dev, slave->dev, "link status definitely up, %u Mbps %s duplex\n",
-				   slave->speed == SPEED_UNKNOWN ? 0 : slave->speed,
-				   slave->duplex ? "full" : "half");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_UP);
-
-			if (BOND_MODE(bond) == BOND_MODE_XOR ||
-			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
-				toe_failover(netdev_master_upper_dev_get(slave->dev),
-					     slave->dev, TOE_LINK_UP, NULL);
-			if (!bond->curr_active_slave || slave == primary)
-				goto do_failover;
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP ||
-			    BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_DOWN);
-
-			if (BOND_MODE(bond) == BOND_MODE_XOR ||
-			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
-				toe_failover(netdev_master_upper_dev_get(slave->dev),
-					     slave->dev, TOE_LINK_DOWN, NULL);
-			if (slave == rcu_access_pointer(bond->curr_active_slave))
-				goto do_failover;
-
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev, "invalid new link %d on slave\n",
-				  slave->link_new_state);
-			bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* bond_mii_monitor
- *
- * Really a wrapper that splits the mii monitor into two phases: an
- * inspection, then (if inspection indicates something needs to be done)
- * an acquisition of appropriate locks followed by a commit phase to
- * implement whatever link state changes are indicated.
- */
-static void bond_mii_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mii_work.work);
-	bool should_notify_peers = false;
-	bool commit;
-	unsigned long delay;
-	struct slave *slave;
-	struct list_head *iter;
-
-	delay = msecs_to_jiffies(bond->params.miimon);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-	should_notify_peers = bond_should_notify_peers(bond);
-	commit = !!bond_miimon_inspect(bond);
-	if (bond->send_peer_notif) {
-		rcu_read_unlock();
-		if (rtnl_trylock()) {
-			bond->send_peer_notif--;
-			rtnl_unlock();
-		}
-	} else {
-		rcu_read_unlock();
-	}
-
-	if (commit) {
-		/* Race avoidance with bond_close cancel of workqueue */
-		if (!rtnl_trylock()) {
-			delay = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_for_each_slave(bond, slave, iter) {
-			bond_commit_link_state(slave, BOND_SLAVE_NOTIFY_LATER);
-		}
-		bond_miimon_commit(bond);
-
-		rtnl_unlock();	/* might sleep, hold no other locks */
-	}
-
-re_arm:
-	if (bond->params.miimon)
-		queue_delayed_work(bond->wq, &bond->mii_work, delay);
-
-	if (should_notify_peers) {
-		if (!rtnl_trylock())
-			return;
-		call_netdevice_notifiers(NETDEV_NOTIFY_PEERS, bond->dev);
-		rtnl_unlock();
-	}
-}
-
-static int bond_upper_dev_walk(struct net_device *upper, void *data)
-{
-	__be32 ip = *((__be32 *)data);
-
-	return ip == bond_confirm_addr(upper, 0, ip);
-}
-
-static bool bond_has_this_ip(struct bonding *bond, __be32 ip)
-{
-	bool ret = false;
-
-	if (ip == bond_confirm_addr(bond->dev, 0, ip))
-		return true;
-
-	rcu_read_lock();
-	if (netdev_walk_all_upper_dev_rcu(bond->dev, bond_upper_dev_walk, &ip))
-		ret = true;
-	rcu_read_unlock();
-
-	return ret;
-}
-
-/* We go to the (large) trouble of VLAN tagging ARP frames because
- * switches in VLAN mode (especially if ports are configured as
- * "native" to a VLAN) might not pass non-tagged frames.
- */
-static void bond_arp_send(struct slave *slave, int arp_op, __be32 dest_ip,
-			  __be32 src_ip, struct bond_vlan_tag *tags)
-{
-	struct sk_buff *skb;
-	struct bond_vlan_tag *outer_tag = tags;
-	struct net_device *slave_dev = slave->dev;
-	struct net_device *bond_dev = slave->bond->dev;
-
-	slave_dbg(bond_dev, slave_dev, "arp %d on slave: dst %pI4 src %pI4\n",
-		  arp_op, &dest_ip, &src_ip);
-
-	skb = arp_create(arp_op, ETH_P_ARP, dest_ip, slave_dev, src_ip,
-			 NULL, slave_dev->dev_addr, NULL);
-
-	if (!skb) {
-		net_err_ratelimited("ARP packet allocation failed\n");
-		return;
-	}
-
-	if (!tags || tags->vlan_proto == VLAN_N_VID)
-		goto xmit;
-
-	tags++;
-
-	/* Go through all the tags backwards and add them to the packet */
-	while (tags->vlan_proto != VLAN_N_VID) {
-		if (!tags->vlan_id) {
-			tags++;
-			continue;
-		}
-
-		slave_dbg(bond_dev, slave_dev, "inner tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), tags->vlan_id);
-		skb = vlan_insert_tag_set_proto(skb, tags->vlan_proto,
-						tags->vlan_id);
-		if (!skb) {
-			net_err_ratelimited("failed to insert inner VLAN tag\n");
-			return;
-		}
-
-		tags++;
-	}
-	/* Set the outer tag */
-	if (outer_tag->vlan_id) {
-		slave_dbg(bond_dev, slave_dev, "outer tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), outer_tag->vlan_id);
-		__vlan_hwaccel_put_tag(skb, outer_tag->vlan_proto,
-				       outer_tag->vlan_id);
-	}
-
-xmit:
-	arp_xmit(skb);
-}
-
-/* Validate the device path between the @start_dev and the @end_dev.
- * The path is valid if the @end_dev is reachable through device
- * stacking.
- * When the path is validated, collect any vlan information in the
- * path.
- */
-struct bond_vlan_tag *bond_verify_device_path(struct net_device *start_dev,
-					      struct net_device *end_dev,
-					      int level)
-{
-	struct bond_vlan_tag *tags;
-	struct net_device *upper;
-	struct list_head  *iter;
-
-	if (start_dev == end_dev) {
-		tags = kcalloc(level + 1, sizeof(*tags), GFP_ATOMIC);
-		if (!tags)
-			return ERR_PTR(-ENOMEM);
-		tags[level].vlan_proto = VLAN_N_VID;
-		return tags;
-	}
-
-	netdev_for_each_upper_dev_rcu(start_dev, upper, iter) {
-		tags = bond_verify_device_path(upper, end_dev, level + 1);
-		if (IS_ERR_OR_NULL(tags)) {
-			if (IS_ERR(tags))
-				return tags;
-			continue;
-		}
-		if (is_vlan_dev(upper)) {
-			tags[level].vlan_proto = vlan_dev_vlan_proto(upper);
-			tags[level].vlan_id = vlan_dev_vlan_id(upper);
-		}
-
-		return tags;
-	}
-
-	return NULL;
-}
-
-static void bond_arp_send_all(struct bonding *bond, struct slave *slave)
-{
-	struct rtable *rt;
-	struct bond_vlan_tag *tags;
-	__be32 *targets = bond->params.arp_targets, addr;
-	int i;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS && targets[i]; i++) {
-		slave_dbg(bond->dev, slave->dev, "%s: target %pI4\n",
-			  __func__, &targets[i]);
-		tags = NULL;
-
-		/* Find out through which dev should the packet go */
-		rt = ip_route_output(dev_net(bond->dev), targets[i], 0,
-				     RTO_ONLINK, 0);
-		if (IS_ERR(rt)) {
-			/* there's no route to target - try to send arp
-			 * probe to generate any traffic (arp_validate=0)
-			 */
-			if (bond->params.arp_validate)
-				net_warn_ratelimited("%s: no route to arp_ip_target %pI4 and arp_validate is set\n",
-						     bond->dev->name,
-						     &targets[i]);
-			bond_arp_send(slave, ARPOP_REQUEST, targets[i],
-				      0, tags);
-			continue;
-		}
-
-		/* bond device itself */
-		if (rt->dst.dev == bond->dev)
-			goto found;
-
-		rcu_read_lock();
-		tags = bond_verify_device_path(bond->dev, rt->dst.dev, 0);
-		rcu_read_unlock();
-
-		if (!IS_ERR_OR_NULL(tags))
-			goto found;
-
-		/* Not our device - skip */
-		slave_dbg(bond->dev, slave->dev, "no path to arp_ip_target %pI4 via rt.dev %s\n",
-			   &targets[i], rt->dst.dev ? rt->dst.dev->name : "NULL");
-
-		ip_rt_put(rt);
-		continue;
-
-found:
-		addr = bond_confirm_addr(rt->dst.dev, targets[i], 0);
-		ip_rt_put(rt);
-		bond_arp_send(slave, ARPOP_REQUEST, targets[i], addr, tags);
-		kfree(tags);
-	}
-}
-
-static void bond_validate_arp(struct bonding *bond, struct slave *slave, __be32 sip, __be32 tip)
-{
-	int i;
-
-	if (!sip || !bond_has_this_ip(bond, tip)) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 tip %pI4 not found\n",
-			   __func__, &sip, &tip);
-		return;
-	}
-
-	i = bond_get_targets_ip(bond->params.arp_targets, sip);
-	if (i == -1) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 not found in targets\n",
-			   __func__, &sip);
-		return;
-	}
-	slave->last_rx = jiffies;
-	slave->target_last_arp_rx[i] = jiffies;
-}
-
-int bond_arp_rcv(const struct sk_buff *skb, struct bonding *bond,
-		 struct slave *slave)
-{
-	struct arphdr *arp = (struct arphdr *)skb->data;
-	struct slave *curr_active_slave, *curr_arp_slave;
-	unsigned char *arp_ptr;
-	__be32 sip, tip;
-	int is_arp = skb->protocol == __cpu_to_be16(ETH_P_ARP);
-	unsigned int alen;
-
-	if (!slave_do_arp_validate(bond, slave)) {
-		if ((slave_do_arp_validate_only(bond) && is_arp) ||
-		    !slave_do_arp_validate_only(bond))
-			slave->last_rx = jiffies;
-		return RX_HANDLER_ANOTHER;
-	} else if (!is_arp) {
-		return RX_HANDLER_ANOTHER;
-	}
-
-	alen = arp_hdr_len(bond->dev);
-
-	slave_dbg(bond->dev, slave->dev, "%s: skb->dev %s\n",
-		   __func__, skb->dev->name);
-
-	if (alen > skb_headlen(skb)) {
-		arp = kmalloc(alen, GFP_ATOMIC);
-		if (!arp)
-			goto out_unlock;
-		if (skb_copy_bits(skb, 0, arp, alen) < 0)
-			goto out_unlock;
-	}
-
-	if (arp->ar_hln != bond->dev->addr_len ||
-	    skb->pkt_type == PACKET_OTHERHOST ||
-	    skb->pkt_type == PACKET_LOOPBACK ||
-	    arp->ar_hrd != htons(ARPHRD_ETHER) ||
-	    arp->ar_pro != htons(ETH_P_IP) ||
-	    arp->ar_pln != 4)
-		goto out_unlock;
-
-	arp_ptr = (unsigned char *)(arp + 1);
-	arp_ptr += bond->dev->addr_len;
-	memcpy(&sip, arp_ptr, 4);
-	arp_ptr += 4 + bond->dev->addr_len;
-	memcpy(&tip, arp_ptr, 4);
-
-	slave_dbg(bond->dev, slave->dev, "%s: %s/%d av %d sv %d sip %pI4 tip %pI4\n",
-		  __func__, slave->dev->name, bond_slave_state(slave),
-		  bond->params.arp_validate, slave_do_arp_validate(bond, slave),
-		  &sip, &tip);
-
-	curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	curr_arp_slave = rcu_dereference(bond->current_arp_slave);
-
-	/* We 'trust' the received ARP enough to validate it if:
-	 *
-	 * (a) the slave receiving the ARP is active (which includes the
-	 * current ARP slave, if any), or
-	 *
-	 * (b) the receiving slave isn't active, but there is a currently
-	 * active slave and it received valid arp reply(s) after it became
-	 * the currently active slave, or
-	 *
-	 * (c) there is an ARP slave that sent an ARP during the prior ARP
-	 * interval, and we receive an ARP reply on any slave.  We accept
-	 * these because switch FDB update delays may deliver the ARP
-	 * reply to a slave other than the sender of the ARP request.
-	 *
-	 * Note: for (b), backup slaves are receiving the broadcast ARP
-	 * request, not a reply.  This request passes from the sending
-	 * slave through the L2 switch(es) to the receiving slave.  Since
-	 * this is checking the request, sip/tip are swapped for
-	 * validation.
-	 *
-	 * This is done to avoid endless looping when we can't reach the
-	 * arp_ip_target and fool ourselves with our own arp requests.
-	 */
-	if (bond_is_active_slave(slave))
-		bond_validate_arp(bond, slave, sip, tip);
-	else if (curr_active_slave &&
-		 time_after(slave_last_rx(bond, curr_active_slave),
-			    curr_active_slave->last_link_up))
-		bond_validate_arp(bond, slave, tip, sip);
-	else if (curr_arp_slave && (arp->ar_op == htons(ARPOP_REPLY)) &&
-		 bond_time_in_interval(bond,
-				       dev_trans_start(curr_arp_slave->dev), 1))
-		bond_validate_arp(bond, slave, sip, tip);
-
-out_unlock:
-	if (arp != (struct arphdr *)skb->data)
-		kfree(arp);
-	return RX_HANDLER_ANOTHER;
-}
-
-/* function to verify if we're in the arp_interval timeslice, returns true if
- * (last_act - arp_interval) <= jiffies <= (last_act + mod * arp_interval +
- * arp_interval/2) . the arp_interval/2 is needed for really fast networks.
- */
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod)
-{
-	int delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	return time_in_range(jiffies,
-			     last_act - delta_in_ticks,
-			     last_act + mod * delta_in_ticks + delta_in_ticks/2);
-}
-
-/* This function is called regularly to monitor each slave's link
- * ensuring that traffic is being sent and received when arp monitoring
- * is used in load-balancing mode. if the adapter has been dormant, then an
- * arp is transmitted to generate traffic. see activebackup_arp_monitor for
- * arp monitoring in active backup mode.
- */
-static void bond_loadbalance_arp_mon(struct bonding *bond)
-{
-	struct slave *slave, *oldcurrent;
-	struct list_head *iter;
-	int do_failover = 0, slave_state_changed = 0;
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	oldcurrent = rcu_dereference(bond->curr_active_slave);
-	/* see if any of the previous devices are up now (i.e. they have
-	 * xmt and rcv traffic). the curr_active_slave does not come into
-	 * the picture unless it is null. also, slave->last_link_up is not
-	 * needed here because we send an arp on each slave and give a slave
-	 * as long as it needs to get the tx/rx within the delta.
-	 * TODO: what about up/down delay in arp mode? it wasn't here before
-	 *       so it can wait
-	 */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		unsigned long trans_start = dev_trans_start(slave->dev);
-
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, trans_start, 1) &&
-			    bond_time_in_interval(bond, slave->last_rx, 1)) {
-
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave_state_changed = 1;
-
-				/* primary_slave has no meaning in round-robin
-				 * mode. the window of a slave being up and
-				 * curr_active_slave being null after enslaving
-				 * is closed.
-				 */
-				if (!oldcurrent) {
-					slave_info(bond->dev, slave->dev, "link status definitely up\n");
-					do_failover = 1;
-				} else {
-					slave_info(bond->dev, slave->dev, "interface is now up\n");
-				}
-			}
-		} else {
-			/* slave->link == BOND_LINK_UP */
-
-			/* not all switches will respond to an arp request
-			 * when the source ip is 0, so don't take the link down
-			 * if we don't know our ip yet
-			 */
-			if (!bond_time_in_interval(bond, trans_start, 2) ||
-			    !bond_time_in_interval(bond, slave->last_rx, 2)) {
-
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_state_changed = 1;
-
-				if (slave->link_failure_count < UINT_MAX)
-					slave->link_failure_count++;
-
-				slave_info(bond->dev, slave->dev, "interface is now down\n");
-
-				if (slave == oldcurrent)
-					do_failover = 1;
-			}
-		}
-
-		/* note: if switch is in round-robin mode, all links
-		 * must tx arp to ensure all links rx an arp - otherwise
-		 * links may oscillate or not come up at all; if switch is
-		 * in something like xor mode, there is nothing we can
-		 * do - all replies will be rx'ed on same link causing slaves
-		 * to be unstable during low/no traffic periods
-		 */
-		if (bond_slave_is_up(slave))
-			bond_arp_send_all(bond, slave);
-	}
-
-	rcu_read_unlock();
-
-	if (do_failover || slave_state_changed) {
-		if (!rtnl_trylock())
-			goto re_arm;
-
-		bond_for_each_slave(bond, slave, iter) {
-			if (slave->link_new_state != BOND_LINK_NOCHANGE)
-				slave->link = slave->link_new_state;
-		}
-
-		if (slave_state_changed) {
-			bond_slave_state_change(bond);
-			if (BOND_MODE(bond) == BOND_MODE_XOR)
-				bond_update_slave_arr(bond, NULL);
-		}
-		if (do_failover) {
-			block_netpoll_tx();
-			bond_select_active_slave(bond);
-			unblock_netpoll_tx();
-		}
-		rtnl_unlock();
-	}
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work,
-				   msecs_to_jiffies(bond->params.arp_interval));
-}
-
-/* Called to inspect slaves for active-backup mode ARP monitor link state
- * changes.  Sets proposed link state in slaves to specify what action
- * should take place for the slave.  Returns 0 if no changes are found, >0
- * if changes to link states must be committed.
- *
- * Called with rcu_read_lock held.
- */
-static int bond_ab_arp_inspect(struct bonding *bond)
-{
-	unsigned long trans_start, last_rx;
-	struct list_head *iter;
-	struct slave *slave;
-	int commit = 0;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-		last_rx = slave_last_rx(bond, slave);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, last_rx, 1)) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-			}
-			continue;
-		}
-
-		/* Give slaves 2*delta after being enslaved or made
-		 * active.  This avoids bouncing, as the last receive
-		 * times need a full ARP monitor cycle to be updated.
-		 */
-		if (bond_time_in_interval(bond, slave->last_link_up, 2))
-			continue;
-
-		/* Backup slave is down if:
-		 * - No current_arp_slave AND
-		 * - more than 3*delta since last receive AND
-		 * - the bond has an IP address
-		 *
-		 * Note: a non-null current_arp_slave indicates
-		 * the curr_active_slave went down and we are
-		 * searching for a new one; under this condition
-		 * we only take the curr_active_slave down - this
-		 * gives each slave a chance to tx/rx traffic
-		 * before being taken out
-		 */
-		if (!bond_is_active_slave(slave) &&
-		    !rcu_access_pointer(bond->current_arp_slave) &&
-		    !bond_time_in_interval(bond, last_rx, 3)) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-
-		/* Active slave is down if:
-		 * - more than 2*delta since transmitting OR
-		 * - (more than 2*delta since receive AND
-		 *    the bond has an IP address)
-		 */
-		trans_start = dev_trans_start(slave->dev);
-		if (bond_is_active_slave(slave) &&
-		    (!bond_time_in_interval(bond, trans_start, 2) ||
-		     !bond_time_in_interval(bond, last_rx, 2))) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-	}
-
-	return commit;
-}
-
-/* Called to commit link state changes noted by inspection step of
- * active-backup mode ARP monitor.
- *
- * Called with RTNL hold.
- */
-static void bond_ab_arp_commit(struct bonding *bond)
-{
-	unsigned long trans_start;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			continue;
-
-		case BOND_LINK_UP:
-			trans_start = dev_trans_start(slave->dev);
-			if (rtnl_dereference(bond->curr_active_slave) != slave ||
-			    (!rtnl_dereference(bond->curr_active_slave) &&
-			     bond_time_in_interval(bond, trans_start, 1))) {
-				struct slave *current_arp_slave;
-
-				current_arp_slave = rtnl_dereference(bond->current_arp_slave);
-				bond_set_slave_link_state(slave, BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-				if (current_arp_slave) {
-					bond_set_slave_inactive_flags(
-						current_arp_slave,
-						BOND_SLAVE_NOTIFY_NOW);
-					RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				}
-
-				slave_info(bond->dev, slave->dev, "link status definitely up\n");
-
-				if (!rtnl_dereference(bond->curr_active_slave) ||
-				    slave == rtnl_dereference(bond->primary_slave))
-					goto do_failover;
-
-			}
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			if (slave == rtnl_dereference(bond->curr_active_slave)) {
-				RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				goto do_failover;
-			}
-
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev,
-				  "impossible: link_new_state %d on slave\n",
-				  slave->link_new_state);
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* Send ARP probes for active-backup mode ARP monitor.
- *
- * Called with rcu_read_lock held.
- */
-static bool bond_ab_arp_probe(struct bonding *bond)
-{
-	struct slave *slave, *before = NULL, *new_slave = NULL,
-		     *curr_arp_slave = rcu_dereference(bond->current_arp_slave),
-		     *curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	struct list_head *iter;
-	bool found = false;
-	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
-
-	if (curr_arp_slave && curr_active_slave)
-		netdev_info(bond->dev, "PROBE: c_arp %s && cas %s BAD\n",
-			    curr_arp_slave->dev->name,
-			    curr_active_slave->dev->name);
-
-	if (curr_active_slave) {
-		bond_arp_send_all(bond, curr_active_slave);
-		return should_notify_rtnl;
-	}
-
-	/* if we don't have a curr_active_slave, search for the next available
-	 * backup slave from the current_arp_slave and make it the candidate
-	 * for becoming the curr_active_slave
-	 */
-
-	if (!curr_arp_slave) {
-		curr_arp_slave = bond_first_slave_rcu(bond);
-		if (!curr_arp_slave)
-			return should_notify_rtnl;
-	}
-
-	bond_set_slave_inactive_flags(curr_arp_slave, BOND_SLAVE_NOTIFY_LATER);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!found && !before && bond_slave_is_up(slave))
-			before = slave;
-
-		if (found && !new_slave && bond_slave_is_up(slave))
-			new_slave = slave;
-		/* if the link state is up at this point, we
-		 * mark it down - this can happen if we have
-		 * simultaneous link failures and
-		 * reselect_active_interface doesn't make this
-		 * one the current slave so it is still marked
-		 * up when it is actually down
-		 */
-		if (!bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_LATER);
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_LATER);
-
-			slave_info(bond->dev, slave->dev, "backup interface is now down\n");
-		}
-		if (slave == curr_arp_slave)
-			found = true;
-	}
-
-	if (!new_slave && before)
-		new_slave = before;
-
-	if (!new_slave)
-		goto check_state;
-
-	bond_set_slave_link_state(new_slave, BOND_LINK_BACK,
-				  BOND_SLAVE_NOTIFY_LATER);
-	bond_set_slave_active_flags(new_slave, BOND_SLAVE_NOTIFY_LATER);
-	bond_arp_send_all(bond, new_slave);
-	new_slave->last_link_up = jiffies;
-	rcu_assign_pointer(bond->current_arp_slave, new_slave);
-
-check_state:
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->should_notify || slave->should_notify_link) {
-			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
-			break;
-		}
-	}
-	return should_notify_rtnl;
-}
-
-static void bond_activebackup_arp_mon(struct bonding *bond)
-{
-	bool should_notify_peers = false;
-	bool should_notify_rtnl = false;
-	int delta_in_ticks;
-
-	delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	should_notify_peers = bond_should_notify_peers(bond);
-
-	if (bond_ab_arp_inspect(bond)) {
-		rcu_read_unlock();
-
-		/* Race avoidance with bond_close flush of workqueue */
-		if (!rtnl_trylock()) {
-			delta_in_ticks = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_ab_arp_commit(bond);
-
-		rtnl_unlock();
-		rcu_read_lock();
-	}
-
-	should_notify_rtnl = bond_ab_arp_probe(bond);
-	rcu_read_unlock();
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work, delta_in_ticks);
-
-	if (should_notify_peers || should_notify_rtnl) {
-		if (!rtnl_trylock())
-			return;
-
-		if (should_notify_peers)
-			call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-						 bond->dev);
-		if (should_notify_rtnl) {
-			bond_slave_state_notify(bond);
-			bond_slave_link_notify(bond);
-		}
-
-		rtnl_unlock();
-	}
-}
-
-static void bond_arp_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    arp_work.work);
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		bond_activebackup_arp_mon(bond);
-	else
-		bond_loadbalance_arp_mon(bond);
-}
-
-/*-------------------------- netdev event handling --------------------------*/
-
-/* Change device name */
-static int bond_event_changename(struct bonding *bond)
-{
-	bond_remove_proc_entry(bond);
-	bond_create_proc_entry(bond);
-
-	bond_debug_reregister(bond);
-
-	return NOTIFY_DONE;
-}
-
-static int bond_master_netdev_event(unsigned long event,
-				    struct net_device *bond_dev)
-{
-	struct bonding *event_bond = netdev_priv(bond_dev);
-
-	netdev_dbg(bond_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_CHANGENAME:
-		return bond_event_changename(event_bond);
-	case NETDEV_UNREGISTER:
-		bond_remove_proc_entry(event_bond);
-		break;
-	case NETDEV_REGISTER:
-		bond_create_proc_entry(event_bond);
-		break;
-	case NETDEV_DOWN: {
-		struct slave *slave = bond_first_slave(event_bond);
-
-		toe_failover(bond_dev, slave ? slave->dev : NULL,
-			     TOE_BOND_DOWN, NULL);
-		break;
-	}
-	case NETDEV_UP: {
-		struct slave *slave = bond_first_slave(event_bond);
-
-		toe_failover(bond_dev, slave ? slave->dev : NULL,
-			     TOE_BOND_UP, NULL);
-		break;
-	}
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-static int bond_slave_netdev_event(unsigned long event,
-				   struct net_device *slave_dev)
-{
-	struct slave *slave = bond_slave_get_rtnl(slave_dev), *primary;
-	struct bonding *bond;
-	struct net_device *bond_dev;
-
-	/* A netdev event can be generated while enslaving a device
-	 * before netdev_rx_handler_register is called in which case
-	 * slave will be NULL
-	 */
-	if (!slave) {
-		netdev_dbg(slave_dev, "%s called on NULL slave\n", __func__);
-		return NOTIFY_DONE;
-	}
-
-	bond_dev = slave->bond->dev;
-	bond = slave->bond;
-	primary = rtnl_dereference(bond->primary_slave);
-
-	slave_dbg(bond_dev, slave_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_UNREGISTER:
-		if (bond_dev->type != ARPHRD_ETHER)
-			bond_release_and_destroy(bond_dev, slave_dev);
-		else
-			__bond_release_one(bond_dev, slave_dev, false, true);
-		break;
-	case NETDEV_UP:
-	case NETDEV_CHANGE:
-		/* For 802.3ad mode only:
-		 * Getting invalid Speed/Duplex values here will put slave
-		 * in weird state. Mark it as link-fail if the link was
-		 * previously up or link-down if it hasn't yet come up, and
-		 * let link-monitoring (miimon) set it right when correct
-		 * speeds/duplex are available.
-		 */
-		if (bond_update_speed_duplex(slave) &&
-		    BOND_MODE(bond) == BOND_MODE_8023AD) {
-			if (slave->last_link_up)
-				slave->link = BOND_LINK_FAIL;
-			else
-				slave->link = BOND_LINK_DOWN;
-		}
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD)
-			bond_3ad_adapter_speed_duplex_changed(slave);
-		/* Fallthrough */
-	case NETDEV_DOWN:
-		/* Refresh slave-array if applicable!
-		 * If the setup does not use miimon or arpmon (mode-specific!),
-		 * then these events will not cause the slave-array to be
-		 * refreshed. This will cause xmit to use a slave that is not
-		 * usable. Avoid such situation by refeshing the array at these
-		 * events. If these (miimon/arpmon) parameters are configured
-		 * then array gets refreshed twice and that should be fine!
-		 */
-		if (bond_mode_can_use_xmit_hash(bond))
-			bond_update_slave_arr(bond, NULL);
-		break;
-	case NETDEV_CHANGEMTU:
-		/* TODO: Should slaves be allowed to
-		 * independently alter their MTU?  For
-		 * an active-backup bond, slaves need
-		 * not be the same type of device, so
-		 * MTUs may vary.  For other modes,
-		 * slaves arguably should have the
-		 * same MTUs. To do this, we'd need to
-		 * take over the slave's change_mtu
-		 * function for the duration of their
-		 * servitude.
-		 */
-		break;
-	case NETDEV_CHANGENAME:
-		/* we don't care if we don't have primary set */
-		if (!bond_uses_primary(bond) ||
-		    !bond->params.primary[0])
-			break;
-
-		if (slave == primary) {
-			/* slave's name changed - he's no longer primary */
-			RCU_INIT_POINTER(bond->primary_slave, NULL);
-		} else if (!strcmp(slave_dev->name, bond->params.primary)) {
-			/* we have a new primary slave */
-			rcu_assign_pointer(bond->primary_slave, slave);
-		} else { /* we didn't change primary - exit */
-			break;
-		}
-
-		netdev_info(bond->dev, "Primary slave changed to %s, reselecting active slave\n",
-			    primary ? slave_dev->name : "none");
-
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-		break;
-	case NETDEV_FEAT_CHANGE:
-		bond_compute_features(bond);
-		break;
-	case NETDEV_RESEND_IGMP:
-		/* Propagate to master device */
-		call_netdevice_notifiers(event, slave->bond->dev);
-		break;
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-/* bond_netdev_event: handle netdev notifier chain events.
- *
- * This function receives events for the netdev chain.  The caller (an
- * ioctl handler calling blocking_notifier_call_chain) holds the necessary
- * locks for us to safely manipulate the slave devices (RTNL lock,
- * dev_probe_lock).
- */
-static int bond_netdev_event(struct notifier_block *this,
-			     unsigned long event, void *ptr)
-{
-	struct net_device *event_dev = netdev_notifier_info_to_dev(ptr);
-
-	netdev_dbg(event_dev, "%s received %s\n",
-		   __func__, netdev_cmd_to_name(event));
-
-	if (!(event_dev->priv_flags & IFF_BONDING))
-		return NOTIFY_DONE;
-
-	if (event_dev->flags & IFF_MASTER) {
-		int ret;
-
-		ret = bond_master_netdev_event(event, event_dev);
-		if (ret != NOTIFY_DONE)
-			return ret;
-	}
-
-	if (event_dev->flags & IFF_SLAVE)
-		return bond_slave_netdev_event(event, event_dev);
-
-	return NOTIFY_DONE;
-}
-
-static struct notifier_block bond_netdev_notifier = {
-	.notifier_call = bond_netdev_event,
-};
-
-/*---------------------------- Hashing Policies -----------------------------*/
-
-/* L2 hash helper */
-static inline u32 bond_eth_hash(struct sk_buff *skb)
-{
-	struct ethhdr *ep, hdr_tmp;
-
-	ep = skb_header_pointer(skb, 0, sizeof(hdr_tmp), &hdr_tmp);
-	if (ep)
-		return ep->h_dest[5] ^ ep->h_source[5] ^ ep->h_proto;
-	return 0;
-}
-
-/* Extract the appropriate headers based on bond's xmit policy */
-static bool bond_flow_dissect(struct bonding *bond, struct sk_buff *skb,
-			      struct flow_keys *fk)
-{
-	const struct ipv6hdr *iph6;
-	const struct iphdr *iph;
-	int noff, proto = -1;
-
-	if (bond->params.xmit_policy > BOND_XMIT_POLICY_LAYER23)
-		return skb_flow_dissect_flow_keys(skb, fk, 0);
-
-	fk->ports.ports = 0;
-	noff = skb_network_offset(skb);
-	if (skb->protocol == htons(ETH_P_IP)) {
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
-			return false;
-		iph = ip_hdr(skb);
-		iph_to_flow_copy_v4addrs(fk, iph);
-		noff += iph->ihl << 2;
-		if (!ip_is_fragment(iph))
-			proto = iph->protocol;
-	} else if (skb->protocol == htons(ETH_P_IPV6)) {
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph6))))
-			return false;
-		iph6 = ipv6_hdr(skb);
-		iph_to_flow_copy_v6addrs(fk, iph6);
-		noff += sizeof(*iph6);
-		proto = iph6->nexthdr;
-	} else {
-		return false;
-	}
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER34 && proto >= 0)
-		fk->ports.ports = skb_flow_get_ports(skb, noff, proto);
-
-	return true;
-}
-
-/**
- * bond_xmit_hash - generate a hash value based on the xmit policy
- * @bond: bonding device
- * @skb: buffer to use for headers
- *
- * This function will extract the necessary headers from the skb buffer and use
- * them to generate a hash based on the xmit_policy set in the bonding device
- */
-u32 bond_xmit_hash(struct bonding *bond, struct sk_buff *skb)
-{
-	struct flow_keys flow;
-	u32 hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP34 &&
-	    skb->l4_hash)
-		return skb->hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER2 ||
-	    !bond_flow_dissect(bond, skb, &flow))
-		return bond_eth_hash(skb);
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER23 ||
-	    bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP23)
-		hash = bond_eth_hash(skb);
-	else
-		hash = (__force u32)flow.ports.ports;
-	hash ^= (__force u32)flow_get_u32_dst(&flow) ^
-		(__force u32)flow_get_u32_src(&flow);
-	hash ^= (hash >> 16);
-	hash ^= (hash >> 8);
-
-	return hash >> 1;
-}
-
-/*-------------------------- Device entry points ----------------------------*/
-
-void bond_work_init_all(struct bonding *bond)
-{
-	INIT_DELAYED_WORK(&bond->mcast_work,
-			  bond_resend_igmp_join_requests_delayed);
-	INIT_DELAYED_WORK(&bond->alb_work, bond_alb_monitor);
-	INIT_DELAYED_WORK(&bond->mii_work, bond_mii_monitor);
-	INIT_DELAYED_WORK(&bond->arp_work, bond_arp_monitor);
-	INIT_DELAYED_WORK(&bond->ad_work, bond_3ad_state_machine_handler);
-	INIT_DELAYED_WORK(&bond->slave_arr_work, bond_slave_arr_handler);
-}
-
-static void bond_work_cancel_all(struct bonding *bond)
-{
-	cancel_delayed_work_sync(&bond->mii_work);
-	cancel_delayed_work_sync(&bond->arp_work);
-	cancel_delayed_work_sync(&bond->alb_work);
-	cancel_delayed_work_sync(&bond->ad_work);
-	cancel_delayed_work_sync(&bond->mcast_work);
-	cancel_delayed_work_sync(&bond->slave_arr_work);
-}
-
-static int bond_open(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	/* reset slave->backup and slave->inactive */
-	if (bond_has_slaves(bond)) {
-		bond_for_each_slave(bond, slave, iter) {
-			if (bond_uses_primary(bond) &&
-			    slave != rcu_access_pointer(bond->curr_active_slave)) {
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-			} else if (BOND_MODE(bond) != BOND_MODE_8023AD) {
-				bond_set_slave_active_flags(slave,
-							    BOND_SLAVE_NOTIFY_NOW);
-			}
-		}
-	}
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_initialize must be called before the timer
-		 * is started.
-		 */
-		if (bond_alb_initialize(bond, (BOND_MODE(bond) == BOND_MODE_ALB)))
-			return -ENOMEM;
-		if (bond->params.tlb_dynamic_lb || BOND_MODE(bond) == BOND_MODE_ALB)
-			queue_delayed_work(bond->wq, &bond->alb_work, 0);
-	}
-
-	if (bond->params.miimon)  /* link check interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->mii_work, 0);
-
-	if (bond->params.arp_interval) {  /* arp interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->arp_work, 0);
-		bond->recv_probe = bond_arp_rcv;
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		queue_delayed_work(bond->wq, &bond->ad_work, 0);
-		/* register to receive LACPDUs */
-		bond->recv_probe = bond_3ad_lacpdu_recv;
-		bond_3ad_initiate_agg_selection(bond, 1);
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-	return 0;
-}
-
-static int bond_close(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	bond_work_cancel_all(bond);
-	bond->send_peer_notif = 0;
-	if (bond_is_lb(bond))
-		bond_alb_deinitialize(bond);
-	bond->recv_probe = NULL;
-
-	return 0;
-}
-
-/* fold stats, assuming all rtnl_link_stats64 fields are u64, but
- * that some drivers can provide 32bit values only.
- */
-static void bond_fold_stats(struct rtnl_link_stats64 *_res,
-			    const struct rtnl_link_stats64 *_new,
-			    const struct rtnl_link_stats64 *_old)
-{
-	const u64 *new = (const u64 *)_new;
-	const u64 *old = (const u64 *)_old;
-	u64 *res = (u64 *)_res;
-	int i;
-
-	for (i = 0; i < sizeof(*_res) / sizeof(u64); i++) {
-		u64 nv = new[i];
-		u64 ov = old[i];
-		s64 delta = nv - ov;
-
-		/* detects if this particular field is 32bit only */
-		if (((nv | ov) >> 32) == 0)
-			delta = (s64)(s32)((u32)nv - (u32)ov);
-
-		/* filter anomalies, some drivers reset their stats
-		 * at down/up events.
-		 */
-		if (delta > 0)
-			res[i] += delta;
-	}
-}
-
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct rtnl_link_stats64 temp;
-	struct list_head *iter;
-	struct slave *slave;
-
-	spin_lock(&bond->stats_lock);
-	memcpy(stats, &bond->bond_stats, sizeof(*stats));
-
-	rcu_read_lock();
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		const struct rtnl_link_stats64 *new =
-			dev_get_stats(slave->dev, &temp);
-
-		bond_fold_stats(stats, new, &slave->slave_stats);
-
-		/* save off the slave stats for the next run */
-		memcpy(&slave->slave_stats, new, sizeof(*new));
-	}
-	rcu_read_unlock();
-
-	memcpy(&bond->bond_stats, stats, sizeof(*stats));
-	spin_unlock(&bond->stats_lock);
-}
-
-static int bond_do_ioctl(struct net_device *bond_dev, struct ifreq *ifr, int cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct ifbond k_binfo;
-	struct ifbond __user *u_binfo = NULL;
-	struct ifslave k_sinfo;
-	struct ifslave __user *u_sinfo = NULL;
-	struct mii_ioctl_data *mii = NULL;
-	struct bond_opt_value newval;
-	struct net *net;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond_ioctl: cmd=%d\n", cmd);
-
-	switch (cmd) {
-	case SIOCGMIIPHY:
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		mii->phy_id = 0;
-		/* Fall Through */
-	case SIOCGMIIREG:
-		/* We do this again just in case we were called by SIOCGMIIREG
-		 * instead of SIOCGMIIPHY.
-		 */
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		if (mii->reg_num == 1) {
-			mii->val_out = 0;
-			if (netif_carrier_ok(bond->dev))
-				mii->val_out = BMSR_LSTATUS;
-		}
-
-		return 0;
-	case BOND_INFO_QUERY_OLD:
-	case SIOCBONDINFOQUERY:
-		u_binfo = (struct ifbond __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_binfo, u_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		bond_info_query(bond_dev, &k_binfo);
-		if (copy_to_user(u_binfo, &k_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		return 0;
-	case BOND_SLAVE_INFO_QUERY_OLD:
-	case SIOCBONDSLAVEINFOQUERY:
-		u_sinfo = (struct ifslave __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_sinfo, u_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		res = bond_slave_info_query(bond_dev, &k_sinfo);
-		if (res == 0 &&
-		    copy_to_user(u_sinfo, &k_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		return res;
-	default:
-		break;
-	}
-
-	net = dev_net(bond_dev);
-
-	if (!ns_capable(net->user_ns, CAP_NET_ADMIN))
-		return -EPERM;
-
-	slave_dev = __dev_get_by_name(net, ifr->ifr_slave);
-
-	slave_dbg(bond_dev, slave_dev, "slave_dev=%p:\n", slave_dev);
-
-	if (!slave_dev)
-		return -ENODEV;
-
-	switch (cmd) {
-	case BOND_ENSLAVE_OLD:
-	case SIOCBONDENSLAVE:
-		res = bond_enslave(bond_dev, slave_dev, NULL);
-		break;
-	case BOND_RELEASE_OLD:
-	case SIOCBONDRELEASE:
-		res = bond_release(bond_dev, slave_dev);
-		break;
-	case BOND_SETHWADDR_OLD:
-	case SIOCBONDSETHWADDR:
-		res = bond_set_dev_addr(bond_dev, slave_dev);
-		break;
-	case BOND_CHANGE_ACTIVE_OLD:
-	case SIOCBONDCHANGEACTIVE:
-		bond_opt_initstr(&newval, slave_dev->name);
-		res = __bond_opt_set_notify(bond, BOND_OPT_ACTIVE_SLAVE,
-					    &newval);
-		break;
-	default:
-		res = -EOPNOTSUPP;
-	}
-
-	return res;
-}
-
-static void bond_change_rx_flags(struct net_device *bond_dev, int change)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	if (change & IFF_PROMISC)
-		bond_set_promiscuity(bond,
-				     bond_dev->flags & IFF_PROMISC ? 1 : -1);
-
-	if (change & IFF_ALLMULTI)
-		bond_set_allmulti(bond,
-				  bond_dev->flags & IFF_ALLMULTI ? 1 : -1);
-}
-
-static void bond_set_rx_mode(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	rcu_read_lock();
-	if (bond_uses_primary(bond)) {
-		slave = rcu_dereference(bond->curr_active_slave);
-		if (slave) {
-			dev_uc_sync(slave->dev, bond_dev);
-			dev_mc_sync(slave->dev, bond_dev);
-		}
-	} else {
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			dev_uc_sync_multiple(slave->dev, bond_dev);
-			dev_mc_sync_multiple(slave->dev, bond_dev);
-		}
-	}
-	rcu_read_unlock();
-}
-
-static int bond_neigh_init(struct neighbour *n)
-{
-	struct bonding *bond = netdev_priv(n->dev);
-	const struct net_device_ops *slave_ops;
-	struct neigh_parms parms;
-	struct slave *slave;
-	int ret = 0;
-
-	rcu_read_lock();
-	slave = bond_first_slave_rcu(bond);
-	if (!slave)
-		goto out;
-	slave_ops = slave->dev->netdev_ops;
-	if (!slave_ops->ndo_neigh_setup)
-		goto out;
-
-	/* TODO: find another way [1] to implement this.
-	 * Passing a zeroed structure is fragile,
-	 * but at least we do not pass garbage.
-	 *
-	 * [1] One way would be that ndo_neigh_setup() never touch
-	 *     struct neigh_parms, but propagate the new neigh_setup()
-	 *     back to ___neigh_create() / neigh_parms_alloc()
-	 */
-	memset(&parms, 0, sizeof(parms));
-	ret = slave_ops->ndo_neigh_setup(slave->dev, &parms);
-
-	if (ret)
-		goto out;
-
-	if (parms.neigh_setup)
-		ret = parms.neigh_setup(n);
-out:
-	rcu_read_unlock();
-	return ret;
-}
-
-/* The bonding ndo_neigh_setup is called at init time beofre any
- * slave exists. So we must declare proxy setup function which will
- * be used at run time to resolve the actual slave neigh param setup.
- *
- * It's also called by master devices (such as vlans) to setup their
- * underlying devices. In that case - do nothing, we're already set up from
- * our init.
- */
-static int bond_neigh_setup(struct net_device *dev,
-			    struct neigh_parms *parms)
-{
-	/* modify only our neigh_parms */
-	if (parms->dev == dev)
-		parms->neigh_setup = bond_neigh_init;
-
-	return 0;
-}
-
-/* Change the MTU of all of a master's slaves to match the master */
-static int bond_change_mtu(struct net_device *bond_dev, int new_mtu)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond=%p, new_mtu=%d\n", bond, new_mtu);
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "s %p c_m %p\n",
-			   slave, slave->dev->netdev_ops->ndo_change_mtu);
-
-		res = dev_set_mtu(slave->dev, new_mtu);
-
-		if (res) {
-			/* If we failed to set the slave's mtu to the new value
-			 * we must abort the operation even in ACTIVE_BACKUP
-			 * mode, because if we allow the backup slaves to have
-			 * different mtu values than the active slave we'll
-			 * need to change their mtu when doing a failover. That
-			 * means changing their mtu from timer context, which
-			 * is probably not a good idea.
-			 */
-			slave_dbg(bond_dev, slave->dev, "err %d setting mtu to %d\n",
-				  res, new_mtu);
-			goto unwind;
-		}
-	}
-
-	bond_dev->mtu = new_mtu;
-
-	return 0;
-
-unwind:
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mtu(rollback_slave->dev, bond_dev->mtu);
-		if (tmp_res)
-			slave_dbg(bond_dev, rollback_slave->dev, "unwind err %d\n",
-				  tmp_res);
-	}
-
-	return res;
-}
-
-/* Change HW address
- *
- * Note that many devices must be down to change the HW address, and
- * downing the master releases all slaves.  We can make bonds full of
- * bonding devices to test this, however.
- */
-static int bond_set_mac_address(struct net_device *bond_dev, void *addr)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct sockaddr_storage *ss = addr, tmp_ss;
-	struct list_head *iter;
-	int res = 0;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB)
-		return bond_alb_set_mac_address(bond_dev, addr);
-
-
-	netdev_dbg(bond_dev, "%s: bond=%p\n", __func__, bond);
-
-	/* If fail_over_mac is enabled, do nothing and return success.
-	 * Returning an error causes ifenslave to fail.
-	 */
-	if (bond->params.fail_over_mac &&
-	    BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		return 0;
-
-	if (!is_valid_ether_addr(ss->__data))
-		return -EADDRNOTAVAIL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "%s: slave=%p\n",
-			  __func__, slave);
-		res = dev_set_mac_address(slave->dev, addr, NULL);
-		if (res) {
-			/* TODO: consider downing the slave
-			 * and retry ?
-			 * User should expect communications
-			 * breakage anyway until ARP finish
-			 * updating, so...
-			 */
-			slave_dbg(bond_dev, slave->dev, "%s: err %d\n",
-				  __func__, res);
-			goto unwind;
-		}
-	}
-
-	/* success */
-	memcpy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
-	return 0;
-
-unwind:
-	memcpy(tmp_ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-	tmp_ss.ss_family = bond_dev->type;
-
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mac_address(rollback_slave->dev,
-					      (struct sockaddr *)&tmp_ss, NULL);
-		if (tmp_res) {
-			slave_dbg(bond_dev, rollback_slave->dev, "%s: unwind err %d\n",
-				   __func__, tmp_res);
-		}
-	}
-
-	return res;
-}
-
-static struct net_device *bond_xmit_slave_id_select(struct bonding *bond, int slave_id)
-{
-	struct list_head *iter;
-	struct slave *slave;
-	struct net_device *slave_dev = NULL;
-	int i = slave_id;
-
-	/* Here we start from the slave with slave_id */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0) {
-			if (bond_slave_can_tx(slave)) {
-				slave_dev = slave->dev;
-				return slave_dev;
-			}
-		}
-	}
-
-	/* Here we start from the first slave up to slave_id */
-	i = slave_id;
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0)
-			break;
-		if (bond_slave_can_tx(slave)) {
-			slave_dev = slave->dev;
-			return slave_dev;
-		}
-	}
-	return slave_dev;
-}
-
-/**
- * bond_xmit_slave_id - transmit skb through slave with slave_id
- * @bond: bonding device that is transmitting
- * @skb: buffer to transmit
- * @slave_id: slave id up to slave_cnt-1 through which to transmit
- *
- * This function tries to transmit through slave with slave_id but in case
- * it fails, it tries to find the first available slave for transmission.
- * The skb is consumed in all cases, thus the function is void.
- */
-static void bond_xmit_slave_id(struct bonding *bond, struct sk_buff *skb, int slave_id)
-{
-	struct list_head *iter;
-	struct slave *slave;
-	int i = slave_id;
-
-	/* Here we start from the slave with slave_id */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0) {
-			if (bond_slave_can_tx(slave)) {
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-				return;
-			}
-		}
-	}
-
-	/* Here we start from the first slave up to slave_id */
-	i = slave_id;
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0)
-			break;
-		if (bond_slave_can_tx(slave)) {
-			bond_dev_queue_xmit(bond, skb, slave->dev);
-			return;
-		}
-	}
-	/* no slave that can tx has been found */
-	bond_tx_drop(bond->dev, skb);
-}
-
-/**
- * bond_rr_gen_slave_id - generate slave id based on packets_per_slave
- * @bond: bonding device to use
- *
- * Based on the value of the bonding device's packets_per_slave parameter
- * this function generates a slave id, which is usually used as the next
- * slave to transmit through.
- */
-static u32 bond_rr_gen_slave_id(struct bonding *bond)
-{
-	u32 slave_id;
-	struct reciprocal_value reciprocal_packets_per_slave;
-	int packets_per_slave = bond->params.packets_per_slave;
-
-	switch (packets_per_slave) {
-	case 0:
-		slave_id = prandom_u32();
-		break;
-	case 1:
-		slave_id = bond->rr_tx_counter;
-		break;
-	default:
-		reciprocal_packets_per_slave =
-			bond->params.reciprocal_packets_per_slave;
-		slave_id = reciprocal_divide(bond->rr_tx_counter,
-					     reciprocal_packets_per_slave);
-		break;
-	}
-	bond->rr_tx_counter++;
-
-	return slave_id;
-}
-
-static struct net_device *bond_xmit_roundrobin_select(int slave_id,
-						     struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	return bond_xmit_slave_id_select(bond, slave_id);
-}
-
-static netdev_tx_t bond_xmit_roundrobin(struct sk_buff *skb,
-					struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-	int slave_cnt;
-	u32 slave_id;
-
-	/* Start with the curr_active_slave that joined the bond as the
-	 * default for sending IGMP traffic.  For failover purposes one
-	 * needs to maintain some consistency for the interface that will
-	 * send the join/membership reports.  The curr_active_slave found
-	 * will send all of this type of traffic.
-	 */
-	if (skb->protocol == htons(ETH_P_IP)) {
-		int noff = skb_network_offset(skb);
-		struct iphdr *iph;
-
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
-			goto non_igmp;
-
-		iph = ip_hdr(skb);
-		if (iph->protocol == IPPROTO_IGMP) {
-			slave = rcu_dereference(bond->curr_active_slave);
-			if (slave)
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-			else
-				bond_xmit_slave_id(bond, skb, 0);
-			return NETDEV_TX_OK;
-		}
-	}
-
-non_igmp:
-	slave_cnt = READ_ONCE(bond->slave_cnt);
-	if (likely(slave_cnt)) {
-		slave_id = bond_rr_gen_slave_id(bond);
-		bond_xmit_slave_id(bond, skb, slave_id % slave_cnt);
-	} else {
-		bond_tx_drop(bond_dev, skb);
-	}
-	return NETDEV_TX_OK;
-}
-
-static struct net_device *bond_xmit_activebackup_select(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct slave *slave;
-
-	slave = rcu_dereference(bond->curr_active_slave);
-	if (slave)
-		slave_dev = slave->dev;
-
-	return slave_dev;
-}
-
-/* In active-backup mode, we know that bond->curr_active_slave is always valid if
- * the bond has a usable interface.
- */
-static netdev_tx_t bond_xmit_activebackup(struct sk_buff *skb,
-					  struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-
-	slave = rcu_dereference(bond->curr_active_slave);
-	if (slave)
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	else
-		bond_tx_drop(bond_dev, skb);
-
-	return NETDEV_TX_OK;
-}
-
-/* Use this to update slave_array when (a) it's not appropriate to update
- * slave_array right away (note that update_slave_array() may sleep)
- * and / or (b) RTNL is not held.
- */
-void bond_slave_arr_work_rearm(struct bonding *bond, unsigned long delay)
-{
-	queue_delayed_work(bond->wq, &bond->slave_arr_work, delay);
-}
-
-/* Slave array work handler. Holds only RTNL */
-static void bond_slave_arr_handler(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    slave_arr_work.work);
-	int ret;
-
-	if (!rtnl_trylock())
-		goto err;
-
-	ret = bond_update_slave_arr(bond, NULL);
-	rtnl_unlock();
-	if (ret) {
-		pr_warn_ratelimited("Failed to update slave array from WT\n");
-		goto err;
-	}
-	return;
-
-err:
-	bond_slave_arr_work_rearm(bond, 1);
-}
-
-/* Build the usable slaves array in control path for modes that use xmit-hash
- * to determine the slave interface -
- * (a) BOND_MODE_8023AD
- * (b) BOND_MODE_XOR
- * (c) (BOND_MODE_TLB || BOND_MODE_ALB) && tlb_dynamic_lb == 0
- *
- * The caller is expected to hold RTNL only and NO other lock!
- */
-int bond_update_slave_arr(struct bonding *bond, struct slave *skipslave)
-{
-	struct slave *slave;
-	struct list_head *iter;
-	struct bond_up_slave *new_arr, *old_arr;
-	int agg_id = 0;
-	int ret = 0;
-
-#ifdef CONFIG_LOCKDEP
-	WARN_ON(lockdep_is_held(&bond->mode_lock));
-#endif
-
-	new_arr = kzalloc(offsetof(struct bond_up_slave, arr[bond->slave_cnt]),
-			  GFP_KERNEL);
-	if (!new_arr) {
-		ret = -ENOMEM;
-		pr_err("Failed to build slave-array.\n");
-		goto out;
-	}
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-
-		if (bond_3ad_get_active_agg_info(bond, &ad_info)) {
-			pr_debug("bond_3ad_get_active_agg_info failed\n");
-			kfree_rcu(new_arr, rcu);
-			/* No active aggragator means it's not safe to use
-			 * the previous array.
-			 */
-			old_arr = rtnl_dereference(bond->slave_arr);
-			if (old_arr) {
-				RCU_INIT_POINTER(bond->slave_arr, NULL);
-				kfree_rcu(old_arr, rcu);
-			}
-			goto out;
-		}
-		agg_id = ad_info.aggregator_id;
-	}
-	bond_for_each_slave(bond, slave, iter) {
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg;
-
-			agg = SLAVE_AD_INFO(slave)->port.aggregator;
-			if (!agg || agg->aggregator_identifier != agg_id)
-				continue;
-		}
-		if (!bond_slave_can_tx(slave))
-			continue;
-		if (skipslave == slave)
-			continue;
-
-		slave_dbg(bond->dev, slave->dev, "Adding slave to tx hash array[%d]\n",
-			  new_arr->count);
-
-		new_arr->arr[new_arr->count++] = slave;
-	}
-
-	old_arr = rtnl_dereference(bond->slave_arr);
-	rcu_assign_pointer(bond->slave_arr, new_arr);
-	if (old_arr)
-		kfree_rcu(old_arr, rcu);
-out:
-	if (ret != 0 && skipslave) {
-		int idx;
-
-		/* Rare situation where caller has asked to skip a specific
-		 * slave but allocation failed (most likely!). BTW this is
-		 * only possible when the call is initiated from
-		 * __bond_release_one(). In this situation; overwrite the
-		 * skipslave entry in the array with the last entry from the
-		 * array to avoid a situation where the xmit path may choose
-		 * this to-be-skipped slave to send a packet out.
-		 */
-		old_arr = rtnl_dereference(bond->slave_arr);
-		for (idx = 0; old_arr != NULL && idx < old_arr->count; idx++) {
-			if (skipslave == old_arr->arr[idx]) {
-				old_arr->arr[idx] =
-				    old_arr->arr[old_arr->count-1];
-				old_arr->count--;
-				break;
-			}
-		}
-	}
-	return ret;
-}
-
-static struct net_device *bond_xmit_xor_select(int slave_id,
-					       struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_up_slave *slaves;
-	struct slave *slave;
-	struct net_device *slave_dev = NULL;
-	unsigned int count;
-
-	slaves = rcu_dereference(bond->slave_arr);
-	count = slaves ? READ_ONCE(slaves->count) : 0;
-	if (likely(count)) {
-		slave = slaves->arr[slave_id];
-		if (slave)
-			slave_dev = slave->dev;
-	}
-	return slave_dev;
-}
-
-/* Use this Xmit function for 3AD as well as XOR modes. The current
- * usable slave array is formed in the control path. The xmit function
- * just calculates hash and sends the packet out.
- */
-static netdev_tx_t bond_3ad_xor_xmit(struct sk_buff *skb,
-				     struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct slave *slave;
-	struct bond_up_slave *slaves;
-	unsigned int count;
-
-	slaves = rcu_dereference(bond->slave_arr);
-	count = slaves ? READ_ONCE(slaves->count) : 0;
-	if (likely(count)) {
-		slave = slaves->arr[bond_xmit_hash(bond, skb) % count];
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	} else {
-		bond_tx_drop(dev, skb);
-	}
-
-	return NETDEV_TX_OK;
-}
-
-/* in broadcast mode, we send everything to all usable interfaces. */
-static netdev_tx_t bond_xmit_broadcast(struct sk_buff *skb,
-				       struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (bond_is_last_slave(bond, slave))
-			break;
-		if (bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
-
-			if (!skb2) {
-				net_err_ratelimited("%s: Error: %s: skb_clone() failed\n",
-						    bond_dev->name, __func__);
-				continue;
-			}
-			bond_dev_queue_xmit(bond, skb2, slave->dev);
-		}
-	}
-	if (slave && bond_slave_is_up(slave) && slave->link == BOND_LINK_UP)
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	else
-		bond_tx_drop(bond_dev, skb);
-
-	return NETDEV_TX_OK;
-}
-
-/*------------------------- Device initialization ---------------------------*/
-
-/* Lookup the slave that corresponds to a qid */
-static inline int bond_slave_override(struct bonding *bond,
-				      struct sk_buff *skb)
-{
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	if (!skb_rx_queue_recorded(skb))
-		return 1;
-
-	/* Find out if any slaves have the same mapping as this skb. */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->queue_id == skb_get_queue_mapping(skb)) {
-			if (bond_slave_is_up(slave) &&
-			    slave->link == BOND_LINK_UP) {
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-				return 0;
-			}
-			/* If the slave isn't UP, use default transmit policy. */
-			break;
-		}
-	}
-
-	return 1;
-}
-
-
-static u16 bond_select_queue(struct net_device *dev, struct sk_buff *skb,
-			     struct net_device *sb_dev)
-{
-	/* This helper function exists to help dev_pick_tx get the correct
-	 * destination queue.  Using a helper function skips a call to
-	 * skb_tx_hash and will put the skbs in the queue we expect on their
-	 * way down to the bonding driver.
-	 */
-	u16 txq = skb_rx_queue_recorded(skb) ? skb_get_rx_queue(skb) : 0;
-
-	/* Save the original txq to restore before passing to the driver */
-	qdisc_skb_cb(skb)->slave_dev_queue_mapping = skb_get_queue_mapping(skb);
-
-	if (unlikely(txq >= dev->real_num_tx_queues)) {
-		do {
-			txq -= dev->real_num_tx_queues;
-		} while (txq >= dev->real_num_tx_queues);
-	}
-	return txq;
-}
-
-static netdev_tx_t __bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-
-	if (bond_should_override_tx_queue(bond) &&
-	    !bond_slave_override(bond, skb))
-		return NETDEV_TX_OK;
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return bond_xmit_roundrobin(skb, dev);
-	case BOND_MODE_ACTIVEBACKUP:
-		return bond_xmit_activebackup(skb, dev);
-	case BOND_MODE_8023AD:
-	case BOND_MODE_XOR:
-		return bond_3ad_xor_xmit(skb, dev);
-	case BOND_MODE_BROADCAST:
-		return bond_xmit_broadcast(skb, dev);
-	case BOND_MODE_ALB:
-		return bond_alb_xmit(skb, dev);
-	case BOND_MODE_TLB:
-		return bond_tlb_xmit(skb, dev);
-	default:
-		/* Should never happen, mode already checked */
-		netdev_err(dev, "Unknown bonding mode %d\n", BOND_MODE(bond));
-		WARN_ON_ONCE(1);
-		bond_tx_drop(dev, skb);
-		return NETDEV_TX_OK;
-	}
-}
-
-static netdev_tx_t bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	netdev_tx_t ret = NETDEV_TX_OK;
-
-	/* If we risk deadlock from transmitting this in the
-	 * netpoll path, tell netpoll to queue the frame for later tx
-	 */
-	if (unlikely(is_netpoll_tx_blocked(dev)))
-		return NETDEV_TX_BUSY;
-
-	rcu_read_lock();
-	if (bond_has_slaves(bond))
-		ret = __bond_start_xmit(skb, dev);
-	else
-		bond_tx_drop(dev, skb);
-	rcu_read_unlock();
-
-	return ret;
-}
-
-static int bond_ethtool_get_link_ksettings(struct net_device *bond_dev,
-					   struct ethtool_link_ksettings *cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	unsigned long speed = 0;
-	struct list_head *iter;
-	struct slave *slave;
-
-	cmd->base.duplex = DUPLEX_UNKNOWN;
-	cmd->base.port = PORT_OTHER;
-
-	/* Since bond_slave_can_tx returns false for all inactive or down slaves, we
-	 * do not need to check mode.  Though link speed might not represent
-	 * the true receive or transmit bandwidth (not all modes are symmetric)
-	 * this is an accurate maximum.
-	 */
-	bond_for_each_slave(bond, slave, iter) {
-		if (bond_slave_can_tx(slave)) {
-			if (slave->speed != SPEED_UNKNOWN)
-				speed += slave->speed;
-			if (cmd->base.duplex == DUPLEX_UNKNOWN &&
-			    slave->duplex != DUPLEX_UNKNOWN)
-				cmd->base.duplex = slave->duplex;
-		}
-	}
-	cmd->base.speed = speed ? : SPEED_UNKNOWN;
-
-	return 0;
-}
-
-static void bond_ethtool_get_drvinfo(struct net_device *bond_dev,
-				     struct ethtool_drvinfo *drvinfo)
-{
-	strlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));
-	strlcpy(drvinfo->version, DRV_VERSION, sizeof(drvinfo->version));
-	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version), "%d",
-		 BOND_ABI_VERSION);
-}
-
-static const struct ethtool_ops bond_ethtool_ops = {
-	.get_drvinfo		= bond_ethtool_get_drvinfo,
-	.get_link		= ethtool_op_get_link,
-	.get_link_ksettings	= bond_ethtool_get_link_ksettings,
-};
-
-static const struct net_device_ops bond_netdev_ops = {
-	.ndo_init		= bond_init,
-	.ndo_uninit		= bond_uninit,
-	.ndo_open		= bond_open,
-	.ndo_stop		= bond_close,
-	.ndo_start_xmit		= bond_start_xmit,
-	.ndo_select_queue	= bond_select_queue,
-	.ndo_get_stats64	= bond_get_stats,
-	.ndo_do_ioctl		= bond_do_ioctl,
-	.ndo_change_rx_flags	= bond_change_rx_flags,
-	.ndo_set_rx_mode	= bond_set_rx_mode,
-	.ndo_change_mtu		= bond_change_mtu,
-	.ndo_set_mac_address	= bond_set_mac_address,
-	.ndo_neigh_setup	= bond_neigh_setup,
-	.ndo_vlan_rx_add_vid	= bond_vlan_rx_add_vid,
-	.ndo_vlan_rx_kill_vid	= bond_vlan_rx_kill_vid,
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	.ndo_netpoll_setup	= bond_netpoll_setup,
-	.ndo_netpoll_cleanup	= bond_netpoll_cleanup,
-	.ndo_poll_controller	= bond_poll_controller,
-#endif
-	.ndo_add_slave		= bond_enslave,
-	.ndo_del_slave		= bond_release,
-	.ndo_fix_features	= bond_fix_features,
-	.ndo_features_check	= passthru_features_check,
-};
-
-static const struct device_type bond_type = {
-	.name = "bond",
-};
-
-static void bond_destructor(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	if (bond->wq)
-		destroy_workqueue(bond->wq);
-}
-
-void bond_setup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	spin_lock_init(&bond->mode_lock);
-	bond->params = bonding_defaults;
-
-	/* Initialize pointers */
-	bond->dev = bond_dev;
-
-	/* Initialize the device entry points */
-	ether_setup(bond_dev);
-	bond_dev->max_mtu = ETH_MAX_MTU;
-	bond_dev->netdev_ops = &bond_netdev_ops;
-	bond_dev->ethtool_ops = &bond_ethtool_ops;
-
-	bond_dev->needs_free_netdev = true;
-	bond_dev->priv_destructor = bond_destructor;
-
-	SET_NETDEV_DEVTYPE(bond_dev, &bond_type);
-
-	/* Initialize the device options */
-	bond_dev->flags |= IFF_MASTER;
-	bond_dev->priv_flags |= IFF_BONDING | IFF_UNICAST_FLT | IFF_NO_QUEUE;
-	bond_dev->priv_flags &= ~(IFF_XMIT_DST_RELEASE | IFF_TX_SKB_SHARING);
-
-	/* don't acquire bond device's netif_tx_lock when transmitting */
-	bond_dev->features |= NETIF_F_LLTX;
-
-	/* By default, we declare the bond to be fully
-	 * VLAN hardware accelerated capable. Special
-	 * care is taken in the various xmit functions
-	 * when there are slaves that are not hw accel
-	 * capable
-	 */
-
-	/* Don't allow bond devices to change network namespaces. */
-	bond_dev->features |= NETIF_F_NETNS_LOCAL;
-
-	bond_dev->hw_features = BOND_VLAN_FEATURES |
-				NETIF_F_HW_VLAN_CTAG_RX |
-				NETIF_F_HW_VLAN_CTAG_FILTER;
-
-	bond_dev->hw_features |= NETIF_F_GSO_ENCAP_ALL | NETIF_F_GSO_UDP_L4;
-	bond_dev->features |= bond_dev->hw_features;
-	bond_dev->features |= NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_STAG_TX;
-}
-
-/* Destroy a bonding device.
- * Must be under rtnl_lock when this function is called.
- */
-static void bond_uninit(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-	struct bond_up_slave *arr;
-
-	bond_netpoll_cleanup(bond_dev);
-
-	/* Release the bonded slaves */
-	bond_for_each_slave(bond, slave, iter)
-		__bond_release_one(bond_dev, slave->dev, true, true);
-	netdev_info(bond_dev, "Released all slaves\n");
-
-	arr = rtnl_dereference(bond->slave_arr);
-	if (arr) {
-		RCU_INIT_POINTER(bond->slave_arr, NULL);
-		kfree_rcu(arr, rcu);
-	}
-
-	list_del(&bond->bond_list);
-
-	lockdep_unregister_key(&bond->stats_lock_key);
-	bond_debug_unregister(bond);
-}
-
-/*------------------------- Module initialization ---------------------------*/
-
-static int bond_check_params(struct bond_params *params)
-{
-	int arp_validate_value, fail_over_mac_value, primary_reselect_value, i;
-	struct bond_opt_value newval;
-	const struct bond_opt_value *valptr;
-	int arp_all_targets_value = 0;
-	u16 ad_actor_sys_prio = 0;
-	u16 ad_user_port_key = 0;
-	__be32 arp_target[BOND_MAX_ARP_TARGETS] = { 0 };
-	int arp_ip_count;
-	int bond_mode	= BOND_MODE_ROUNDROBIN;
-	int xmit_hashtype = BOND_XMIT_POLICY_LAYER2;
-	int lacp_fast = 0;
-	int tlb_dynamic_lb;
-
-	/* Convert string parameters. */
-	if (mode) {
-		bond_opt_initstr(&newval, mode);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_MODE), &newval);
-		if (!valptr) {
-			pr_err("Error: Invalid bonding mode \"%s\"\n", mode);
-			return -EINVAL;
-		}
-		bond_mode = valptr->value;
-	}
-
-	if (xmit_hash_policy) {
-		if (bond_mode == BOND_MODE_ROUNDROBIN ||
-		    bond_mode == BOND_MODE_ACTIVEBACKUP ||
-		    bond_mode == BOND_MODE_BROADCAST) {
-			pr_info("xmit_hash_policy param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, xmit_hash_policy);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_XMIT_HASH),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid xmit_hash_policy \"%s\"\n",
-				       xmit_hash_policy);
-				return -EINVAL;
-			}
-			xmit_hashtype = valptr->value;
-		}
-	}
-
-	if (lacp_rate) {
-		if (bond_mode != BOND_MODE_8023AD) {
-			pr_info("lacp_rate param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, lacp_rate);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_LACP_RATE),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid lacp rate \"%s\"\n",
-				       lacp_rate);
-				return -EINVAL;
-			}
-			lacp_fast = valptr->value;
-		}
-	}
-
-	if (ad_select) {
-		bond_opt_initstr(&newval, ad_select);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_SELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid ad_select \"%s\"\n", ad_select);
-			return -EINVAL;
-		}
-		params->ad_select = valptr->value;
-		if (bond_mode != BOND_MODE_8023AD)
-			pr_warn("ad_select param only affects 802.3ad mode\n");
-	} else {
-		params->ad_select = BOND_AD_STABLE;
-	}
-
-	if (max_bonds < 0) {
-		pr_warn("Warning: max_bonds (%d) not in range %d-%d, so it was reset to BOND_DEFAULT_MAX_BONDS (%d)\n",
-			max_bonds, 0, INT_MAX, BOND_DEFAULT_MAX_BONDS);
-		max_bonds = BOND_DEFAULT_MAX_BONDS;
-	}
-
-	if (miimon < 0) {
-		pr_warn("Warning: miimon module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			miimon, INT_MAX);
-		miimon = 0;
-	}
-
-	if (updelay < 0) {
-		pr_warn("Warning: updelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			updelay, INT_MAX);
-		updelay = 0;
-	}
-
-	if (downdelay < 0) {
-		pr_warn("Warning: downdelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			downdelay, INT_MAX);
-		downdelay = 0;
-	}
-
-	if ((use_carrier != 0) && (use_carrier != 1)) {
-		pr_warn("Warning: use_carrier module parameter (%d), not of valid value (0/1), so it was set to 1\n",
-			use_carrier);
-		use_carrier = 1;
-	}
-
-	if (num_peer_notif < 0 || num_peer_notif > 255) {
-		pr_warn("Warning: num_grat_arp/num_unsol_na (%d) not in range 0-255 so it was reset to 1\n",
-			num_peer_notif);
-		num_peer_notif = 1;
-	}
-
-	/* reset values for 802.3ad/TLB/ALB */
-	if (!bond_mode_uses_arp(bond_mode)) {
-		if (!miimon) {
-			pr_warn("Warning: miimon must be specified, otherwise bonding will not detect link failure, speed and duplex which are essential for 802.3ad operation\n");
-			pr_warn("Forcing miimon to 100msec\n");
-			miimon = BOND_DEFAULT_MIIMON;
-		}
-	}
-
-	if (tx_queues < 1 || tx_queues > 255) {
-		pr_warn("Warning: tx_queues (%d) should be between 1 and 255, resetting to %d\n",
-			tx_queues, BOND_DEFAULT_TX_QUEUES);
-		tx_queues = BOND_DEFAULT_TX_QUEUES;
-	}
-
-	if ((all_slaves_active != 0) && (all_slaves_active != 1)) {
-		pr_warn("Warning: all_slaves_active module parameter (%d), not of valid value (0/1), so it was set to 0\n",
-			all_slaves_active);
-		all_slaves_active = 0;
-	}
-
-	if (resend_igmp < 0 || resend_igmp > 255) {
-		pr_warn("Warning: resend_igmp (%d) should be between 0 and 255, resetting to %d\n",
-			resend_igmp, BOND_DEFAULT_RESEND_IGMP);
-		resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-	}
-
-	bond_opt_initval(&newval, packets_per_slave);
-	if (!bond_opt_parse(bond_opt_get(BOND_OPT_PACKETS_PER_SLAVE), &newval)) {
-		pr_warn("Warning: packets_per_slave (%d) should be between 0 and %u resetting to 1\n",
-			packets_per_slave, USHRT_MAX);
-		packets_per_slave = 1;
-	}
-
-	if (bond_mode == BOND_MODE_ALB) {
-		pr_notice("In ALB mode you might experience client disconnections upon reconnection of a link if the bonding module updelay parameter (%d msec) is incompatible with the forwarding delay time of the switch\n",
-			  updelay);
-	}
-
-	if (!miimon) {
-		if (updelay || downdelay) {
-			/* just warn the user the up/down delay will have
-			 * no effect since miimon is zero...
-			 */
-			pr_warn("Warning: miimon module parameter not set and updelay (%d) or downdelay (%d) module parameter is set; updelay and downdelay have no effect unless miimon is set\n",
-				updelay, downdelay);
-		}
-	} else {
-		/* don't allow arp monitoring */
-		if (arp_interval) {
-			pr_warn("Warning: miimon (%d) and arp_interval (%d) can't be used simultaneously, disabling ARP monitoring\n",
-				miimon, arp_interval);
-			arp_interval = 0;
-		}
-
-		if ((updelay % miimon) != 0) {
-			pr_warn("Warning: updelay (%d) is not a multiple of miimon (%d), updelay rounded to %d ms\n",
-				updelay, miimon, (updelay / miimon) * miimon);
-		}
-
-		updelay /= miimon;
-
-		if ((downdelay % miimon) != 0) {
-			pr_warn("Warning: downdelay (%d) is not a multiple of miimon (%d), downdelay rounded to %d ms\n",
-				downdelay, miimon,
-				(downdelay / miimon) * miimon);
-		}
-
-		downdelay /= miimon;
-	}
-
-	if (arp_interval < 0) {
-		pr_warn("Warning: arp_interval module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			arp_interval, INT_MAX);
-		arp_interval = 0;
-	}
-
-	for (arp_ip_count = 0, i = 0;
-	     (arp_ip_count < BOND_MAX_ARP_TARGETS) && arp_ip_target[i]; i++) {
-		__be32 ip;
-
-		/* not a complete check, but good enough to catch mistakes */
-		if (!in4_pton(arp_ip_target[i], -1, (u8 *)&ip, -1, NULL) ||
-		    !bond_is_ip_target_ok(ip)) {
-			pr_warn("Warning: bad arp_ip_target module parameter (%s), ARP monitoring will not be performed\n",
-				arp_ip_target[i]);
-			arp_interval = 0;
-		} else {
-			if (bond_get_targets_ip(arp_target, ip) == -1)
-				arp_target[arp_ip_count++] = ip;
-			else
-				pr_warn("Warning: duplicate address %pI4 in arp_ip_target, skipping\n",
-					&ip);
-		}
-	}
-
-	if (arp_interval && !arp_ip_count) {
-		/* don't allow arping if no arp_ip_target given... */
-		pr_warn("Warning: arp_interval module parameter (%d) specified without providing an arp_ip_target parameter, arp_interval was reset to 0\n",
-			arp_interval);
-		arp_interval = 0;
-	}
-
-	if (arp_validate) {
-		if (!arp_interval) {
-			pr_err("arp_validate requires arp_interval\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initstr(&newval, arp_validate);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_VALIDATE),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_validate \"%s\"\n",
-			       arp_validate);
-			return -EINVAL;
-		}
-		arp_validate_value = valptr->value;
-	} else {
-		arp_validate_value = 0;
-	}
-
-	if (arp_all_targets) {
-		bond_opt_initstr(&newval, arp_all_targets);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_ALL_TARGETS),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_all_targets_value \"%s\"\n",
-			       arp_all_targets);
-			arp_all_targets_value = 0;
-		} else {
-			arp_all_targets_value = valptr->value;
-		}
-	}
-
-	if (miimon) {
-		pr_info("MII link monitoring set to %d ms\n", miimon);
-	} else if (arp_interval) {
-		valptr = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
-					  arp_validate_value);
-		pr_info("ARP monitoring set to %d ms, validate %s, with %d target(s):",
-			arp_interval, valptr->string, arp_ip_count);
-
-		for (i = 0; i < arp_ip_count; i++)
-			pr_cont(" %s", arp_ip_target[i]);
-
-		pr_cont("\n");
-
-	} else if (max_bonds) {
-		/* miimon and arp_interval not set, we need one so things
-		 * work as expected, see bonding.txt for details
-		 */
-		pr_debug("Warning: either miimon or arp_interval and arp_ip_target module parameters must be specified, otherwise bonding will not detect link failures! see bonding.txt for details\n");
-	}
-
-	if (primary && !bond_mode_uses_primary(bond_mode)) {
-		/* currently, using a primary only makes sense
-		 * in active backup, TLB or ALB modes
-		 */
-		pr_warn("Warning: %s primary device specified but has no effect in %s mode\n",
-			primary, bond_mode_name(bond_mode));
-		primary = NULL;
-	}
-
-	if (primary && primary_reselect) {
-		bond_opt_initstr(&newval, primary_reselect);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_PRIMARY_RESELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid primary_reselect \"%s\"\n",
-			       primary_reselect);
-			return -EINVAL;
-		}
-		primary_reselect_value = valptr->value;
-	} else {
-		primary_reselect_value = BOND_PRI_RESELECT_ALWAYS;
-	}
-
-	if (fail_over_mac) {
-		bond_opt_initstr(&newval, fail_over_mac);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_FAIL_OVER_MAC),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid fail_over_mac \"%s\"\n",
-			       fail_over_mac);
-			return -EINVAL;
-		}
-		fail_over_mac_value = valptr->value;
-		if (bond_mode != BOND_MODE_ACTIVEBACKUP)
-			pr_warn("Warning: fail_over_mac only affects active-backup mode\n");
-	} else {
-		fail_over_mac_value = BOND_FOM_NONE;
-	}
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(
-			bond_opt_get(BOND_OPT_AD_ACTOR_SYS_PRIO),
-				     &newval);
-	if (!valptr) {
-		pr_err("Error: No ad_actor_sys_prio default value");
-		return -EINVAL;
-	}
-	ad_actor_sys_prio = valptr->value;
-
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_USER_PORT_KEY),
-				&newval);
-	if (!valptr) {
-		pr_err("Error: No ad_user_port_key default value");
-		return -EINVAL;
-	}
-	ad_user_port_key = valptr->value;
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_TLB_DYNAMIC_LB), &newval);
-	if (!valptr) {
-		pr_err("Error: No tlb_dynamic_lb default value");
-		return -EINVAL;
-	}
-	tlb_dynamic_lb = valptr->value;
-
-	if (lp_interval == 0) {
-		pr_warn("Warning: ip_interval must be between 1 and %d, so it was reset to %d\n",
-			INT_MAX, BOND_ALB_DEFAULT_LP_INTERVAL);
-		lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-	}
-
-	/* fill params struct with the proper values */
-	params->mode = bond_mode;
-	params->xmit_policy = xmit_hashtype;
-	params->miimon = miimon;
-	params->num_peer_notif = num_peer_notif;
-	params->arp_interval = arp_interval;
-	params->arp_validate = arp_validate_value;
-	params->arp_all_targets = arp_all_targets_value;
-	params->updelay = updelay;
-	params->downdelay = downdelay;
-	params->peer_notif_delay = 0;
-	params->use_carrier = use_carrier;
-	params->lacp_fast = lacp_fast;
-	params->primary[0] = 0;
-	params->primary_reselect = primary_reselect_value;
-	params->fail_over_mac = fail_over_mac_value;
-	params->tx_queues = tx_queues;
-	params->all_slaves_active = all_slaves_active;
-	params->resend_igmp = resend_igmp;
-	params->min_links = min_links;
-	params->lp_interval = lp_interval;
-	params->packets_per_slave = packets_per_slave;
-	params->tlb_dynamic_lb = tlb_dynamic_lb;
-	params->ad_actor_sys_prio = ad_actor_sys_prio;
-	eth_zero_addr(params->ad_actor_system);
-	params->ad_user_port_key = ad_user_port_key;
-	if (packets_per_slave > 0) {
-		params->reciprocal_packets_per_slave =
-			reciprocal_value(packets_per_slave);
-	} else {
-		/* reciprocal_packets_per_slave is unused if
-		 * packets_per_slave is 0 or 1, just initialize it
-		 */
-		params->reciprocal_packets_per_slave =
-			(struct reciprocal_value) { 0 };
-	}
-
-	if (primary) {
-		strncpy(params->primary, primary, IFNAMSIZ);
-		params->primary[IFNAMSIZ - 1] = 0;
-	}
-
-	memcpy(params->arp_targets, arp_target, sizeof(arp_target));
-
-	return 0;
-}
-
-/* Called from registration process */
-static int bond_init(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	netdev_dbg(bond_dev, "Begin bond_init\n");
-
-	bond->wq = alloc_ordered_workqueue(bond_dev->name, WQ_MEM_RECLAIM);
-	if (!bond->wq)
-		return -ENOMEM;
-
-	spin_lock_init(&bond->stats_lock);
-	lockdep_register_key(&bond->stats_lock_key);
-	lockdep_set_class(&bond->stats_lock, &bond->stats_lock_key);
-
-	list_add_tail(&bond->bond_list, &bn->dev_list);
-
-	bond_prepare_sysfs_group(bond);
-
-	bond_debug_register(bond);
-
-	/* Ensure valid dev_addr */
-	if (is_zero_ether_addr(bond_dev->dev_addr) &&
-	    bond_dev->addr_assign_type == NET_ADDR_PERM)
-		eth_hw_addr_random(bond_dev);
-
-	return 0;
-}
-
-unsigned int bond_get_num_tx_queues(void)
-{
-	return tx_queues;
-}
-
-/* Create a new bond based on the specified name and bonding parameters.
- * If name is NULL, obtain a suitable "bond%d" name for us.
- * Caller must NOT hold rtnl_lock; we need to release it here before we
- * set up our sysfs entries.
- */
-int bond_create(struct net *net, const char *name)
-{
-	struct net_device *bond_dev;
-	struct bonding *bond;
-	struct alb_bond_info *bond_info;
-	int res;
-
-	rtnl_lock();
-
-	bond_dev = alloc_netdev_mq(sizeof(struct bonding),
-				   name ? name : "bond%d", NET_NAME_UNKNOWN,
-				   bond_setup, tx_queues);
-	if (!bond_dev) {
-		pr_err("%s: eek! can't alloc netdev!\n", name);
-		rtnl_unlock();
-		return -ENOMEM;
-	}
-
-	/*
-	 * Initialize rx_hashtbl_used_head to RLB_NULL_INDEX.
-	 * It is set to 0 by default which is wrong.
-	 */
-	bond = netdev_priv(bond_dev);
-	bond_info = &(BOND_ALB_INFO(bond));
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	dev_net_set(bond_dev, net);
-	bond_dev->rtnl_link_ops = &bond_link_ops;
-
-	res = register_netdevice(bond_dev);
-
-	netif_carrier_off(bond_dev);
-
-	bond_work_init_all(bond);
-
-	rtnl_unlock();
-	if (res < 0)
-		free_netdev(bond_dev);
-	return res;
-}
-
-static int __net_init bond_net_init(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-
-	bn->net = net;
-	INIT_LIST_HEAD(&bn->dev_list);
-
-	bond_create_proc_dir(bn);
-	bond_create_sysfs(bn);
-
-	return 0;
-}
-
-static void __net_exit bond_net_exit(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-	struct bonding *bond, *tmp_bond;
-	LIST_HEAD(list);
-
-	bond_destroy_sysfs(bn);
-
-	/* Kill off any bonds created after unregistering bond rtnl ops */
-	rtnl_lock();
-	list_for_each_entry_safe(bond, tmp_bond, &bn->dev_list, bond_list)
-		unregister_netdevice_queue(bond->dev, &list);
-	unregister_netdevice_many(&list);
-	rtnl_unlock();
-
-	bond_destroy_proc_dir(bn);
-}
-
-static struct pernet_operations bond_net_ops = {
-	.init = bond_net_init,
-	.exit = bond_net_exit,
-	.id   = &bond_net_id,
-	.size = sizeof(struct bond_net),
-};
-
-static int __init bonding_init(void)
-{
-	int i;
-	int res;
-
-	pr_info("%s", bond_version);
-
-	res = bond_check_params(&bonding_defaults);
-	if (res)
-		goto out;
-
-	res = register_pernet_subsys(&bond_net_ops);
-	if (res)
-		goto out;
-
-	res = bond_netlink_init();
-	if (res)
-		goto err_link;
-
-	bond_create_debugfs();
-
-	for (i = 0; i < max_bonds; i++) {
-		res = bond_create(&init_net, NULL);
-		if (res)
-			goto err;
-	}
-
-	register_netdevice_notifier(&bond_netdev_notifier);
-
-	register_toe_bond_rr_select_cb(bond_xmit_roundrobin_select);
-	register_toe_bond_acb_select_cb(bond_xmit_activebackup_select);
-	register_toe_bond_8023AD_select_cb(bond_xmit_xor_select);
-	register_toe_bond_xor_select_cb(bond_xmit_xor_select);
-out:
-	return res;
-err:
-	bond_destroy_debugfs();
-	bond_netlink_fini();
-err_link:
-	unregister_pernet_subsys(&bond_net_ops);
-	goto out;
-
-}
-
-static void __exit bonding_exit(void)
-{
-	unregister_netdevice_notifier(&bond_netdev_notifier);
-
-	bond_destroy_debugfs();
-
-	bond_netlink_fini();
-	unregister_pernet_subsys(&bond_net_ops);
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	/* Make sure we don't have an imbalance on our netpoll blocking */
-	WARN_ON(atomic_read(&netpoll_block_tx));
-#endif
-}
-
-module_init(bonding_init);
-module_exit(bonding_exit);
-MODULE_LICENSE("GPL");
-MODULE_VERSION(DRV_VERSION);
-MODULE_DESCRIPTION(DRV_DESCRIPTION ", v" DRV_VERSION);
-MODULE_AUTHOR("Thomas Davis, tadavis@lbl.gov and many others");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.19/bond_netlink.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.19/bond_netlink.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,786 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * drivers/net/bond/bond_netlink.c - Netlink interface for bonding
- * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
- * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/module.h>
-#include <linux/errno.h>
-#include <linux/netdevice.h>
-#include <linux/etherdevice.h>
-#include <linux/if_link.h>
-#include <linux/if_ether.h>
-#include <net/netlink.h>
-#include <net/rtnetlink.h>
-#include <net/bonding.h>
-
-static size_t bond_get_slave_size(const struct net_device *bond_dev,
-				  const struct net_device *slave_dev)
-{
-	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_STATE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_MII_STATUS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_SLAVE_LINK_FAILURE_COUNT */
-		nla_total_size(MAX_ADDR_LEN) +	/* IFLA_BOND_SLAVE_PERM_HWADDR */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_QUEUE_ID */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_AGGREGATOR_ID */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE */
-		0;
-}
-
-static int bond_fill_slave_info(struct sk_buff *skb,
-				const struct net_device *bond_dev,
-				const struct net_device *slave_dev)
-{
-	struct slave *slave = bond_slave_get_rtnl(slave_dev);
-
-	if (nla_put_u8(skb, IFLA_BOND_SLAVE_STATE, bond_slave_state(slave)))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_SLAVE_MII_STATUS, slave->link))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_SLAVE_LINK_FAILURE_COUNT,
-			slave->link_failure_count))
-		goto nla_put_failure;
-
-	if (nla_put(skb, IFLA_BOND_SLAVE_PERM_HWADDR,
-		    slave_dev->addr_len, slave->perm_hwaddr))
-		goto nla_put_failure;
-
-	if (nla_put_u16(skb, IFLA_BOND_SLAVE_QUEUE_ID, slave->queue_id))
-		goto nla_put_failure;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		const struct aggregator *agg;
-		const struct port *ad_port;
-
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		agg = SLAVE_AD_INFO(slave)->port.aggregator;
-		if (agg) {
-			if (nla_put_u16(skb, IFLA_BOND_SLAVE_AD_AGGREGATOR_ID,
-					agg->aggregator_identifier))
-				goto nla_put_failure;
-			if (nla_put_u8(skb,
-				       IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE,
-				       ad_port->actor_oper_port_state))
-				goto nla_put_failure;
-			if (nla_put_u16(skb,
-					IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE,
-					ad_port->partner_oper.port_state))
-				goto nla_put_failure;
-		}
-	}
-
-	return 0;
-
-nla_put_failure:
-	return -EMSGSIZE;
-}
-
-static const struct nla_policy bond_policy[IFLA_BOND_MAX + 1] = {
-	[IFLA_BOND_MODE]		= { .type = NLA_U8 },
-	[IFLA_BOND_ACTIVE_SLAVE]	= { .type = NLA_U32 },
-	[IFLA_BOND_MIIMON]		= { .type = NLA_U32 },
-	[IFLA_BOND_UPDELAY]		= { .type = NLA_U32 },
-	[IFLA_BOND_DOWNDELAY]		= { .type = NLA_U32 },
-	[IFLA_BOND_USE_CARRIER]		= { .type = NLA_U8 },
-	[IFLA_BOND_ARP_INTERVAL]	= { .type = NLA_U32 },
-	[IFLA_BOND_ARP_IP_TARGET]	= { .type = NLA_NESTED },
-	[IFLA_BOND_ARP_VALIDATE]	= { .type = NLA_U32 },
-	[IFLA_BOND_ARP_ALL_TARGETS]	= { .type = NLA_U32 },
-	[IFLA_BOND_PRIMARY]		= { .type = NLA_U32 },
-	[IFLA_BOND_PRIMARY_RESELECT]	= { .type = NLA_U8 },
-	[IFLA_BOND_FAIL_OVER_MAC]	= { .type = NLA_U8 },
-	[IFLA_BOND_XMIT_HASH_POLICY]	= { .type = NLA_U8 },
-	[IFLA_BOND_RESEND_IGMP]		= { .type = NLA_U32 },
-	[IFLA_BOND_NUM_PEER_NOTIF]	= { .type = NLA_U8 },
-	[IFLA_BOND_ALL_SLAVES_ACTIVE]	= { .type = NLA_U8 },
-	[IFLA_BOND_MIN_LINKS]		= { .type = NLA_U32 },
-	[IFLA_BOND_LP_INTERVAL]		= { .type = NLA_U32 },
-	[IFLA_BOND_PACKETS_PER_SLAVE]	= { .type = NLA_U32 },
-	[IFLA_BOND_AD_LACP_RATE]	= { .type = NLA_U8 },
-	[IFLA_BOND_AD_SELECT]		= { .type = NLA_U8 },
-	[IFLA_BOND_AD_INFO]		= { .type = NLA_NESTED },
-	[IFLA_BOND_AD_ACTOR_SYS_PRIO]	= { .type = NLA_U16 },
-	[IFLA_BOND_AD_USER_PORT_KEY]	= { .type = NLA_U16 },
-	[IFLA_BOND_AD_ACTOR_SYSTEM]	= { .type = NLA_BINARY,
-					    .len  = ETH_ALEN },
-	[IFLA_BOND_TLB_DYNAMIC_LB]	= { .type = NLA_U8 },
-	[IFLA_BOND_PEER_NOTIF_DELAY]    = { .type = NLA_U32 },
-};
-
-static const struct nla_policy bond_slave_policy[IFLA_BOND_SLAVE_MAX + 1] = {
-	[IFLA_BOND_SLAVE_QUEUE_ID]	= { .type = NLA_U16 },
-};
-
-static int bond_validate(struct nlattr *tb[], struct nlattr *data[],
-			 struct netlink_ext_ack *extack)
-{
-	if (tb[IFLA_ADDRESS]) {
-		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN)
-			return -EINVAL;
-		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS])))
-			return -EADDRNOTAVAIL;
-	}
-	return 0;
-}
-
-static int bond_slave_changelink(struct net_device *bond_dev,
-				 struct net_device *slave_dev,
-				 struct nlattr *tb[], struct nlattr *data[],
-				 struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_opt_value newval;
-	int err;
-
-	if (!data)
-		return 0;
-
-	if (data[IFLA_BOND_SLAVE_QUEUE_ID]) {
-		u16 queue_id = nla_get_u16(data[IFLA_BOND_SLAVE_QUEUE_ID]);
-		char queue_id_str[IFNAMSIZ + 7];
-
-		/* queue_id option setting expects slave_name:queue_id */
-		snprintf(queue_id_str, sizeof(queue_id_str), "%s:%u\n",
-			 slave_dev->name, queue_id);
-		bond_opt_initstr(&newval, queue_id_str);
-		err = __bond_opt_set(bond, BOND_OPT_QUEUE_ID, &newval);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int bond_changelink(struct net_device *bond_dev, struct nlattr *tb[],
-			   struct nlattr *data[],
-			   struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_opt_value newval;
-	int miimon = 0;
-	int err;
-
-	if (!data)
-		return 0;
-
-	if (data[IFLA_BOND_MODE]) {
-		int mode = nla_get_u8(data[IFLA_BOND_MODE]);
-
-		bond_opt_initval(&newval, mode);
-		err = __bond_opt_set(bond, BOND_OPT_MODE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ACTIVE_SLAVE]) {
-		int ifindex = nla_get_u32(data[IFLA_BOND_ACTIVE_SLAVE]);
-		struct net_device *slave_dev;
-		char *active_slave = "";
-
-		if (ifindex != 0) {
-			slave_dev = __dev_get_by_index(dev_net(bond_dev),
-						       ifindex);
-			if (!slave_dev)
-				return -ENODEV;
-			active_slave = slave_dev->name;
-		}
-		bond_opt_initstr(&newval, active_slave);
-		err = __bond_opt_set(bond, BOND_OPT_ACTIVE_SLAVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_MIIMON]) {
-		miimon = nla_get_u32(data[IFLA_BOND_MIIMON]);
-
-		bond_opt_initval(&newval, miimon);
-		err = __bond_opt_set(bond, BOND_OPT_MIIMON, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_UPDELAY]) {
-		int updelay = nla_get_u32(data[IFLA_BOND_UPDELAY]);
-
-		bond_opt_initval(&newval, updelay);
-		err = __bond_opt_set(bond, BOND_OPT_UPDELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_DOWNDELAY]) {
-		int downdelay = nla_get_u32(data[IFLA_BOND_DOWNDELAY]);
-
-		bond_opt_initval(&newval, downdelay);
-		err = __bond_opt_set(bond, BOND_OPT_DOWNDELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PEER_NOTIF_DELAY]) {
-		int delay = nla_get_u32(data[IFLA_BOND_PEER_NOTIF_DELAY]);
-
-		bond_opt_initval(&newval, delay);
-		err = __bond_opt_set(bond, BOND_OPT_PEER_NOTIF_DELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_USE_CARRIER]) {
-		int use_carrier = nla_get_u8(data[IFLA_BOND_USE_CARRIER]);
-
-		bond_opt_initval(&newval, use_carrier);
-		err = __bond_opt_set(bond, BOND_OPT_USE_CARRIER, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_INTERVAL]) {
-		int arp_interval = nla_get_u32(data[IFLA_BOND_ARP_INTERVAL]);
-
-		if (arp_interval && miimon) {
-			netdev_err(bond->dev, "ARP monitoring cannot be used with MII monitoring\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initval(&newval, arp_interval);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_INTERVAL, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_IP_TARGET]) {
-		struct nlattr *attr;
-		int i = 0, rem;
-
-		bond_option_arp_ip_targets_clear(bond);
-		nla_for_each_nested(attr, data[IFLA_BOND_ARP_IP_TARGET], rem) {
-			__be32 target;
-
-			if (nla_len(attr) < sizeof(target))
-				return -EINVAL;
-
-			target = nla_get_be32(attr);
-
-			bond_opt_initval(&newval, (__force u64)target);
-			err = __bond_opt_set(bond, BOND_OPT_ARP_TARGETS,
-					     &newval);
-			if (err)
-				break;
-			i++;
-		}
-		if (i == 0 && bond->params.arp_interval)
-			netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_VALIDATE]) {
-		int arp_validate = nla_get_u32(data[IFLA_BOND_ARP_VALIDATE]);
-
-		if (arp_validate && miimon) {
-			netdev_err(bond->dev, "ARP validating cannot be used with MII monitoring\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initval(&newval, arp_validate);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_VALIDATE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_ALL_TARGETS]) {
-		int arp_all_targets =
-			nla_get_u32(data[IFLA_BOND_ARP_ALL_TARGETS]);
-
-		bond_opt_initval(&newval, arp_all_targets);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_ALL_TARGETS, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PRIMARY]) {
-		int ifindex = nla_get_u32(data[IFLA_BOND_PRIMARY]);
-		struct net_device *dev;
-		char *primary = "";
-
-		dev = __dev_get_by_index(dev_net(bond_dev), ifindex);
-		if (dev)
-			primary = dev->name;
-
-		bond_opt_initstr(&newval, primary);
-		err = __bond_opt_set(bond, BOND_OPT_PRIMARY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PRIMARY_RESELECT]) {
-		int primary_reselect =
-			nla_get_u8(data[IFLA_BOND_PRIMARY_RESELECT]);
-
-		bond_opt_initval(&newval, primary_reselect);
-		err = __bond_opt_set(bond, BOND_OPT_PRIMARY_RESELECT, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_FAIL_OVER_MAC]) {
-		int fail_over_mac =
-			nla_get_u8(data[IFLA_BOND_FAIL_OVER_MAC]);
-
-		bond_opt_initval(&newval, fail_over_mac);
-		err = __bond_opt_set(bond, BOND_OPT_FAIL_OVER_MAC, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_XMIT_HASH_POLICY]) {
-		int xmit_hash_policy =
-			nla_get_u8(data[IFLA_BOND_XMIT_HASH_POLICY]);
-
-		bond_opt_initval(&newval, xmit_hash_policy);
-		err = __bond_opt_set(bond, BOND_OPT_XMIT_HASH, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_RESEND_IGMP]) {
-		int resend_igmp =
-			nla_get_u32(data[IFLA_BOND_RESEND_IGMP]);
-
-		bond_opt_initval(&newval, resend_igmp);
-		err = __bond_opt_set(bond, BOND_OPT_RESEND_IGMP, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_NUM_PEER_NOTIF]) {
-		int num_peer_notif =
-			nla_get_u8(data[IFLA_BOND_NUM_PEER_NOTIF]);
-
-		bond_opt_initval(&newval, num_peer_notif);
-		err = __bond_opt_set(bond, BOND_OPT_NUM_PEER_NOTIF, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ALL_SLAVES_ACTIVE]) {
-		int all_slaves_active =
-			nla_get_u8(data[IFLA_BOND_ALL_SLAVES_ACTIVE]);
-
-		bond_opt_initval(&newval, all_slaves_active);
-		err = __bond_opt_set(bond, BOND_OPT_ALL_SLAVES_ACTIVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_MIN_LINKS]) {
-		int min_links =
-			nla_get_u32(data[IFLA_BOND_MIN_LINKS]);
-
-		bond_opt_initval(&newval, min_links);
-		err = __bond_opt_set(bond, BOND_OPT_MINLINKS, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_LP_INTERVAL]) {
-		int lp_interval =
-			nla_get_u32(data[IFLA_BOND_LP_INTERVAL]);
-
-		bond_opt_initval(&newval, lp_interval);
-		err = __bond_opt_set(bond, BOND_OPT_LP_INTERVAL, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PACKETS_PER_SLAVE]) {
-		int packets_per_slave =
-			nla_get_u32(data[IFLA_BOND_PACKETS_PER_SLAVE]);
-
-		bond_opt_initval(&newval, packets_per_slave);
-		err = __bond_opt_set(bond, BOND_OPT_PACKETS_PER_SLAVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_LACP_RATE]) {
-		int lacp_rate =
-			nla_get_u8(data[IFLA_BOND_AD_LACP_RATE]);
-
-		bond_opt_initval(&newval, lacp_rate);
-		err = __bond_opt_set(bond, BOND_OPT_LACP_RATE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_SELECT]) {
-		int ad_select =
-			nla_get_u8(data[IFLA_BOND_AD_SELECT]);
-
-		bond_opt_initval(&newval, ad_select);
-		err = __bond_opt_set(bond, BOND_OPT_AD_SELECT, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_ACTOR_SYS_PRIO]) {
-		int actor_sys_prio =
-			nla_get_u16(data[IFLA_BOND_AD_ACTOR_SYS_PRIO]);
-
-		bond_opt_initval(&newval, actor_sys_prio);
-		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYS_PRIO, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_USER_PORT_KEY]) {
-		int port_key =
-			nla_get_u16(data[IFLA_BOND_AD_USER_PORT_KEY]);
-
-		bond_opt_initval(&newval, port_key);
-		err = __bond_opt_set(bond, BOND_OPT_AD_USER_PORT_KEY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_ACTOR_SYSTEM]) {
-		if (nla_len(data[IFLA_BOND_AD_ACTOR_SYSTEM]) != ETH_ALEN)
-			return -EINVAL;
-
-		bond_opt_initval(&newval,
-				 nla_get_u64(data[IFLA_BOND_AD_ACTOR_SYSTEM]));
-		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYSTEM, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_TLB_DYNAMIC_LB]) {
-		int dynamic_lb = nla_get_u8(data[IFLA_BOND_TLB_DYNAMIC_LB]);
-
-		bond_opt_initval(&newval, dynamic_lb);
-		err = __bond_opt_set(bond, BOND_OPT_TLB_DYNAMIC_LB, &newval);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int bond_newlink(struct net *src_net, struct net_device *bond_dev,
-			struct nlattr *tb[], struct nlattr *data[],
-			struct netlink_ext_ack *extack)
-{
-	int err;
-
-	err = bond_changelink(bond_dev, tb, data, extack);
-	if (err < 0)
-		return err;
-
-	err = register_netdevice(bond_dev);
-
-	netif_carrier_off(bond_dev);
-	if (!err) {
-		struct bonding *bond = netdev_priv(bond_dev);
-
-		bond_work_init_all(bond);
-	}
-
-	return err;
-}
-
-static size_t bond_get_size(const struct net_device *bond_dev)
-{
-	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_MODE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ACTIVE_SLAVE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIIMON */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_UPDELAY */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_DOWNDELAY */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_USE_CARRIER */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_INTERVAL */
-						/* IFLA_BOND_ARP_IP_TARGET */
-		nla_total_size(sizeof(struct nlattr)) +
-		nla_total_size(sizeof(u32)) * BOND_MAX_ARP_TARGETS +
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_VALIDATE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_ALL_TARGETS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PRIMARY */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_PRIMARY_RESELECT */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_FAIL_OVER_MAC */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_XMIT_HASH_POLICY */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_RESEND_IGMP */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_NUM_PEER_NOTIF */
-		nla_total_size(sizeof(u8)) +   /* IFLA_BOND_ALL_SLAVES_ACTIVE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIN_LINKS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_LP_INTERVAL */
-		nla_total_size(sizeof(u32)) +  /* IFLA_BOND_PACKETS_PER_SLAVE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_LACP_RATE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_SELECT */
-		nla_total_size(sizeof(struct nlattr)) + /* IFLA_BOND_AD_INFO */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_AGGREGATOR */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_NUM_PORTS */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_ACTOR_KEY */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_PARTNER_KEY*/
-		nla_total_size(ETH_ALEN) +    /* IFLA_BOND_AD_INFO_PARTNER_MAC*/
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_ACTOR_SYS_PRIO */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_USER_PORT_KEY */
-		nla_total_size(ETH_ALEN) + /* IFLA_BOND_AD_ACTOR_SYSTEM */
-		nla_total_size(sizeof(u8)) + /* IFLA_BOND_TLB_DYNAMIC_LB */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PEER_NOTIF_DELAY */
-		0;
-}
-
-static int bond_option_active_slave_get_ifindex(struct bonding *bond)
-{
-	const struct net_device *slave;
-	int ifindex;
-
-	rcu_read_lock();
-	slave = bond_option_active_slave_get_rcu(bond);
-	ifindex = slave ? slave->ifindex : 0;
-	rcu_read_unlock();
-	return ifindex;
-}
-
-static int bond_fill_info(struct sk_buff *skb,
-			  const struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	unsigned int packets_per_slave;
-	int ifindex, i, targets_added;
-	struct nlattr *targets;
-	struct slave *primary;
-
-	if (nla_put_u8(skb, IFLA_BOND_MODE, BOND_MODE(bond)))
-		goto nla_put_failure;
-
-	ifindex = bond_option_active_slave_get_ifindex(bond);
-	if (ifindex && nla_put_u32(skb, IFLA_BOND_ACTIVE_SLAVE, ifindex))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_MIIMON, bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_UPDELAY,
-			bond->params.updelay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_DOWNDELAY,
-			bond->params.downdelay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_PEER_NOTIF_DELAY,
-			bond->params.peer_notif_delay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_USE_CARRIER, bond->params.use_carrier))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_INTERVAL, bond->params.arp_interval))
-		goto nla_put_failure;
-
-	targets = nla_nest_start_noflag(skb, IFLA_BOND_ARP_IP_TARGET);
-	if (!targets)
-		goto nla_put_failure;
-
-	targets_added = 0;
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
-		if (bond->params.arp_targets[i]) {
-			if (nla_put_be32(skb, i, bond->params.arp_targets[i]))
-				goto nla_put_failure;
-			targets_added = 1;
-		}
-	}
-
-	if (targets_added)
-		nla_nest_end(skb, targets);
-	else
-		nla_nest_cancel(skb, targets);
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_VALIDATE, bond->params.arp_validate))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_ALL_TARGETS,
-			bond->params.arp_all_targets))
-		goto nla_put_failure;
-
-	primary = rtnl_dereference(bond->primary_slave);
-	if (primary &&
-	    nla_put_u32(skb, IFLA_BOND_PRIMARY, primary->dev->ifindex))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_PRIMARY_RESELECT,
-		       bond->params.primary_reselect))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_FAIL_OVER_MAC,
-		       bond->params.fail_over_mac))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_XMIT_HASH_POLICY,
-		       bond->params.xmit_policy))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_RESEND_IGMP,
-		        bond->params.resend_igmp))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_NUM_PEER_NOTIF,
-		       bond->params.num_peer_notif))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_ALL_SLAVES_ACTIVE,
-		       bond->params.all_slaves_active))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_MIN_LINKS,
-			bond->params.min_links))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_LP_INTERVAL,
-			bond->params.lp_interval))
-		goto nla_put_failure;
-
-	packets_per_slave = bond->params.packets_per_slave;
-	if (nla_put_u32(skb, IFLA_BOND_PACKETS_PER_SLAVE,
-			packets_per_slave))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_AD_LACP_RATE,
-		       bond->params.lacp_fast))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_AD_SELECT,
-		       bond->params.ad_select))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_TLB_DYNAMIC_LB,
-		       bond->params.tlb_dynamic_lb))
-		goto nla_put_failure;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info info;
-
-		if (capable(CAP_NET_ADMIN)) {
-			if (nla_put_u16(skb, IFLA_BOND_AD_ACTOR_SYS_PRIO,
-					bond->params.ad_actor_sys_prio))
-				goto nla_put_failure;
-
-			if (nla_put_u16(skb, IFLA_BOND_AD_USER_PORT_KEY,
-					bond->params.ad_user_port_key))
-				goto nla_put_failure;
-
-			if (nla_put(skb, IFLA_BOND_AD_ACTOR_SYSTEM,
-				    ETH_ALEN, &bond->params.ad_actor_system))
-				goto nla_put_failure;
-		}
-		if (!bond_3ad_get_active_agg_info(bond, &info)) {
-			struct nlattr *nest;
-
-			nest = nla_nest_start_noflag(skb, IFLA_BOND_AD_INFO);
-			if (!nest)
-				goto nla_put_failure;
-
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_AGGREGATOR,
-					info.aggregator_id))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_NUM_PORTS,
-					info.ports))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_ACTOR_KEY,
-					info.actor_key))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_PARTNER_KEY,
-					info.partner_key))
-				goto nla_put_failure;
-			if (nla_put(skb, IFLA_BOND_AD_INFO_PARTNER_MAC,
-				    sizeof(info.partner_system),
-				    &info.partner_system))
-				goto nla_put_failure;
-
-			nla_nest_end(skb, nest);
-		}
-	}
-
-	return 0;
-
-nla_put_failure:
-	return -EMSGSIZE;
-}
-
-static size_t bond_get_linkxstats_size(const struct net_device *dev, int attr)
-{
-	switch (attr) {
-	case IFLA_STATS_LINK_XSTATS:
-	case IFLA_STATS_LINK_XSTATS_SLAVE:
-		break;
-	default:
-		return 0;
-	}
-
-	return bond_3ad_stats_size() + nla_total_size(0);
-}
-
-static int bond_fill_linkxstats(struct sk_buff *skb,
-				const struct net_device *dev,
-				int *prividx, int attr)
-{
-	struct nlattr *nla __maybe_unused;
-	struct slave *slave = NULL;
-	struct nlattr *nest, *nest2;
-	struct bonding *bond;
-
-	switch (attr) {
-	case IFLA_STATS_LINK_XSTATS:
-		bond = netdev_priv(dev);
-		break;
-	case IFLA_STATS_LINK_XSTATS_SLAVE:
-		slave = bond_slave_get_rtnl(dev);
-		if (!slave)
-			return 0;
-		bond = slave->bond;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	nest = nla_nest_start_noflag(skb, LINK_XSTATS_TYPE_BOND);
-	if (!nest)
-		return -EMSGSIZE;
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct bond_3ad_stats *stats;
-
-		if (slave)
-			stats = &SLAVE_AD_INFO(slave)->stats;
-		else
-			stats = &BOND_AD_INFO(bond).stats;
-
-		nest2 = nla_nest_start_noflag(skb, BOND_XSTATS_3AD);
-		if (!nest2) {
-			nla_nest_end(skb, nest);
-			return -EMSGSIZE;
-		}
-
-		if (bond_3ad_stats_fill(skb, stats)) {
-			nla_nest_cancel(skb, nest2);
-			nla_nest_end(skb, nest);
-			return -EMSGSIZE;
-		}
-		nla_nest_end(skb, nest2);
-	}
-	nla_nest_end(skb, nest);
-
-	return 0;
-}
-
-struct rtnl_link_ops bond_link_ops __read_mostly = {
-	.kind			= "bond",
-	.priv_size		= sizeof(struct bonding),
-	.setup			= bond_setup,
-	.maxtype		= IFLA_BOND_MAX,
-	.policy			= bond_policy,
-	.validate		= bond_validate,
-	.newlink		= bond_newlink,
-	.changelink		= bond_changelink,
-	.get_size		= bond_get_size,
-	.fill_info		= bond_fill_info,
-	.get_num_tx_queues	= bond_get_num_tx_queues,
-	.get_num_rx_queues	= bond_get_num_tx_queues, /* Use the same number
-							     as for TX queues */
-	.fill_linkxstats        = bond_fill_linkxstats,
-	.get_linkxstats_size    = bond_get_linkxstats_size,
-	.slave_maxtype		= IFLA_BOND_SLAVE_MAX,
-	.slave_policy		= bond_slave_policy,
-	.slave_changelink	= bond_slave_changelink,
-	.get_slave_size		= bond_get_slave_size,
-	.fill_slave_info	= bond_fill_slave_info,
-};
-
-int __init bond_netlink_init(void)
-{
-	return rtnl_link_register(&bond_link_ops);
-}
-
-void bond_netlink_fini(void)
-{
-	rtnl_link_unregister(&bond_link_ops);
-}
-
-MODULE_ALIAS_RTNL_LINK("bond");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.19/bond_options.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.19/bond_options.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1475 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * drivers/net/bond/bond_options.c - bonding options
- * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
- * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/errno.h>
-#include <linux/if.h>
-#include <linux/netdevice.h>
-#include <linux/spinlock.h>
-#include <linux/rcupdate.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/sched/signal.h>
-
-#include <net/bonding.h>
-
-static int bond_option_active_slave_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_miimon_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_updelay_set(struct bonding *bond,
-				   const struct bond_opt_value *newval);
-static int bond_option_downdelay_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_peer_notif_delay_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_use_carrier_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_arp_interval_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target);
-static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target);
-static int bond_option_arp_ip_targets_set(struct bonding *bond,
-					  const struct bond_opt_value *newval);
-static int bond_option_arp_validate_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_arp_all_targets_set(struct bonding *bond,
-					   const struct bond_opt_value *newval);
-static int bond_option_primary_set(struct bonding *bond,
-				   const struct bond_opt_value *newval);
-static int bond_option_primary_reselect_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_fail_over_mac_set(struct bonding *bond,
-					 const struct bond_opt_value *newval);
-static int bond_option_xmit_hash_policy_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_resend_igmp_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_num_peer_notif_set(struct bonding *bond,
-					  const struct bond_opt_value *newval);
-static int bond_option_all_slaves_active_set(struct bonding *bond,
-					     const struct bond_opt_value *newval);
-static int bond_option_min_links_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_lp_interval_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_pps_set(struct bonding *bond,
-			       const struct bond_opt_value *newval);
-static int bond_option_lacp_rate_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_ad_select_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_queue_id_set(struct bonding *bond,
-				    const struct bond_opt_value *newval);
-static int bond_option_mode_set(struct bonding *bond,
-				const struct bond_opt_value *newval);
-static int bond_option_slaves_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
-					     const struct bond_opt_value *newval);
-static int bond_option_ad_actor_system_set(struct bonding *bond,
-					   const struct bond_opt_value *newval);
-static int bond_option_ad_user_port_key_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-
-
-static const struct bond_opt_value bond_mode_tbl[] = {
-	{ "balance-rr",    BOND_MODE_ROUNDROBIN,   BOND_VALFLAG_DEFAULT},
-	{ "active-backup", BOND_MODE_ACTIVEBACKUP, 0},
-	{ "balance-xor",   BOND_MODE_XOR,          0},
-	{ "broadcast",     BOND_MODE_BROADCAST,    0},
-	{ "802.3ad",       BOND_MODE_8023AD,       0},
-	{ "balance-tlb",   BOND_MODE_TLB,          0},
-	{ "balance-alb",   BOND_MODE_ALB,          0},
-	{ NULL,            -1,                     0},
-};
-
-static const struct bond_opt_value bond_pps_tbl[] = {
-	{ "default", 1,         BOND_VALFLAG_DEFAULT},
-	{ "maxval",  USHRT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,        0},
-};
-
-static const struct bond_opt_value bond_xmit_hashtype_tbl[] = {
-	{ "layer2",   BOND_XMIT_POLICY_LAYER2, BOND_VALFLAG_DEFAULT},
-	{ "layer3+4", BOND_XMIT_POLICY_LAYER34, 0},
-	{ "layer2+3", BOND_XMIT_POLICY_LAYER23, 0},
-	{ "encap2+3", BOND_XMIT_POLICY_ENCAP23, 0},
-	{ "encap3+4", BOND_XMIT_POLICY_ENCAP34, 0},
-	{ NULL,       -1,                       0},
-};
-
-static const struct bond_opt_value bond_arp_validate_tbl[] = {
-	{ "none",		BOND_ARP_VALIDATE_NONE,		BOND_VALFLAG_DEFAULT},
-	{ "active",		BOND_ARP_VALIDATE_ACTIVE,	0},
-	{ "backup",		BOND_ARP_VALIDATE_BACKUP,	0},
-	{ "all",		BOND_ARP_VALIDATE_ALL,		0},
-	{ "filter",		BOND_ARP_FILTER,		0},
-	{ "filter_active",	BOND_ARP_FILTER_ACTIVE,		0},
-	{ "filter_backup",	BOND_ARP_FILTER_BACKUP,		0},
-	{ NULL,			-1,				0},
-};
-
-static const struct bond_opt_value bond_arp_all_targets_tbl[] = {
-	{ "any", BOND_ARP_TARGETS_ANY, BOND_VALFLAG_DEFAULT},
-	{ "all", BOND_ARP_TARGETS_ALL, 0},
-	{ NULL,  -1,                   0},
-};
-
-static const struct bond_opt_value bond_fail_over_mac_tbl[] = {
-	{ "none",   BOND_FOM_NONE,   BOND_VALFLAG_DEFAULT},
-	{ "active", BOND_FOM_ACTIVE, 0},
-	{ "follow", BOND_FOM_FOLLOW, 0},
-	{ NULL,     -1,              0},
-};
-
-static const struct bond_opt_value bond_intmax_tbl[] = {
-	{ "off",     0,       BOND_VALFLAG_DEFAULT},
-	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,      0}
-};
-
-static const struct bond_opt_value bond_lacp_rate_tbl[] = {
-	{ "slow", AD_LACP_SLOW, 0},
-	{ "fast", AD_LACP_FAST, 0},
-	{ NULL,   -1,           0},
-};
-
-static const struct bond_opt_value bond_ad_select_tbl[] = {
-	{ "stable",    BOND_AD_STABLE,    BOND_VALFLAG_DEFAULT},
-	{ "bandwidth", BOND_AD_BANDWIDTH, 0},
-	{ "count",     BOND_AD_COUNT,     0},
-	{ NULL,        -1,                0},
-};
-
-static const struct bond_opt_value bond_num_peer_notif_tbl[] = {
-	{ "off",     0,   0},
-	{ "maxval",  255, BOND_VALFLAG_MAX},
-	{ "default", 1,   BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,  0}
-};
-
-static const struct bond_opt_value bond_primary_reselect_tbl[] = {
-	{ "always",  BOND_PRI_RESELECT_ALWAYS,  BOND_VALFLAG_DEFAULT},
-	{ "better",  BOND_PRI_RESELECT_BETTER,  0},
-	{ "failure", BOND_PRI_RESELECT_FAILURE, 0},
-	{ NULL,      -1},
-};
-
-static const struct bond_opt_value bond_use_carrier_tbl[] = {
-	{ "off", 0,  0},
-	{ "on",  1,  BOND_VALFLAG_DEFAULT},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_all_slaves_active_tbl[] = {
-	{ "off", 0,  BOND_VALFLAG_DEFAULT},
-	{ "on",  1,  0},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_resend_igmp_tbl[] = {
-	{ "off",     0,   0},
-	{ "maxval",  255, BOND_VALFLAG_MAX},
-	{ "default", 1,   BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,  0}
-};
-
-static const struct bond_opt_value bond_lp_interval_tbl[] = {
-	{ "minval",  1,       BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
-	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,      0},
-};
-
-static const struct bond_opt_value bond_tlb_dynamic_lb_tbl[] = {
-	{ "off", 0,  0},
-	{ "on",  1,  BOND_VALFLAG_DEFAULT},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_ad_actor_sys_prio_tbl[] = {
-	{ "minval",  1,     BOND_VALFLAG_MIN},
-	{ "maxval",  65535, BOND_VALFLAG_MAX | BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,    0},
-};
-
-static const struct bond_opt_value bond_ad_user_port_key_tbl[] = {
-	{ "minval",  0,     BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
-	{ "maxval",  1023,  BOND_VALFLAG_MAX},
-	{ NULL,      -1,    0},
-};
-
-static const struct bond_option bond_opts[BOND_OPT_LAST] = {
-	[BOND_OPT_MODE] = {
-		.id = BOND_OPT_MODE,
-		.name = "mode",
-		.desc = "bond device mode",
-		.flags = BOND_OPTFLAG_NOSLAVES | BOND_OPTFLAG_IFDOWN,
-		.values = bond_mode_tbl,
-		.set = bond_option_mode_set
-	},
-	[BOND_OPT_PACKETS_PER_SLAVE] = {
-		.id = BOND_OPT_PACKETS_PER_SLAVE,
-		.name = "packets_per_slave",
-		.desc = "Packets to send per slave in RR mode",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ROUNDROBIN)),
-		.values = bond_pps_tbl,
-		.set = bond_option_pps_set
-	},
-	[BOND_OPT_XMIT_HASH] = {
-		.id = BOND_OPT_XMIT_HASH,
-		.name = "xmit_hash_policy",
-		.desc = "balance-xor, 802.3ad, and tlb hashing method",
-		.values = bond_xmit_hashtype_tbl,
-		.set = bond_option_xmit_hash_policy_set
-	},
-	[BOND_OPT_ARP_VALIDATE] = {
-		.id = BOND_OPT_ARP_VALIDATE,
-		.name = "arp_validate",
-		.desc = "validate src/dst of ARP probes",
-		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
-			       BIT(BOND_MODE_ALB),
-		.values = bond_arp_validate_tbl,
-		.set = bond_option_arp_validate_set
-	},
-	[BOND_OPT_ARP_ALL_TARGETS] = {
-		.id = BOND_OPT_ARP_ALL_TARGETS,
-		.name = "arp_all_targets",
-		.desc = "fail on any/all arp targets timeout",
-		.values = bond_arp_all_targets_tbl,
-		.set = bond_option_arp_all_targets_set
-	},
-	[BOND_OPT_FAIL_OVER_MAC] = {
-		.id = BOND_OPT_FAIL_OVER_MAC,
-		.name = "fail_over_mac",
-		.desc = "For active-backup, do not set all slaves to the same MAC",
-		.flags = BOND_OPTFLAG_NOSLAVES,
-		.values = bond_fail_over_mac_tbl,
-		.set = bond_option_fail_over_mac_set
-	},
-	[BOND_OPT_ARP_INTERVAL] = {
-		.id = BOND_OPT_ARP_INTERVAL,
-		.name = "arp_interval",
-		.desc = "arp interval in milliseconds",
-		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
-			       BIT(BOND_MODE_ALB),
-		.values = bond_intmax_tbl,
-		.set = bond_option_arp_interval_set
-	},
-	[BOND_OPT_ARP_TARGETS] = {
-		.id = BOND_OPT_ARP_TARGETS,
-		.name = "arp_ip_target",
-		.desc = "arp targets in n.n.n.n form",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_arp_ip_targets_set
-	},
-	[BOND_OPT_DOWNDELAY] = {
-		.id = BOND_OPT_DOWNDELAY,
-		.name = "downdelay",
-		.desc = "Delay before considering link down, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_downdelay_set
-	},
-	[BOND_OPT_UPDELAY] = {
-		.id = BOND_OPT_UPDELAY,
-		.name = "updelay",
-		.desc = "Delay before considering link up, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_updelay_set
-	},
-	[BOND_OPT_LACP_RATE] = {
-		.id = BOND_OPT_LACP_RATE,
-		.name = "lacp_rate",
-		.desc = "LACPDU tx rate to request from 802.3ad partner",
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.values = bond_lacp_rate_tbl,
-		.set = bond_option_lacp_rate_set
-	},
-	[BOND_OPT_MINLINKS] = {
-		.id = BOND_OPT_MINLINKS,
-		.name = "min_links",
-		.desc = "Minimum number of available links before turning on carrier",
-		.values = bond_intmax_tbl,
-		.set = bond_option_min_links_set
-	},
-	[BOND_OPT_AD_SELECT] = {
-		.id = BOND_OPT_AD_SELECT,
-		.name = "ad_select",
-		.desc = "802.3ad aggregation selection logic",
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.values = bond_ad_select_tbl,
-		.set = bond_option_ad_select_set
-	},
-	[BOND_OPT_NUM_PEER_NOTIF] = {
-		.id = BOND_OPT_NUM_PEER_NOTIF,
-		.name = "num_unsol_na",
-		.desc = "Number of peer notifications to send on failover event",
-		.values = bond_num_peer_notif_tbl,
-		.set = bond_option_num_peer_notif_set
-	},
-	[BOND_OPT_MIIMON] = {
-		.id = BOND_OPT_MIIMON,
-		.name = "miimon",
-		.desc = "Link check interval in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_miimon_set
-	},
-	[BOND_OPT_PRIMARY] = {
-		.id = BOND_OPT_PRIMARY,
-		.name = "primary",
-		.desc = "Primary network device to use",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
-						BIT(BOND_MODE_TLB) |
-						BIT(BOND_MODE_ALB)),
-		.set = bond_option_primary_set
-	},
-	[BOND_OPT_PRIMARY_RESELECT] = {
-		.id = BOND_OPT_PRIMARY_RESELECT,
-		.name = "primary_reselect",
-		.desc = "Reselect primary slave once it comes up",
-		.values = bond_primary_reselect_tbl,
-		.set = bond_option_primary_reselect_set
-	},
-	[BOND_OPT_USE_CARRIER] = {
-		.id = BOND_OPT_USE_CARRIER,
-		.name = "use_carrier",
-		.desc = "Use netif_carrier_ok (vs MII ioctls) in miimon",
-		.values = bond_use_carrier_tbl,
-		.set = bond_option_use_carrier_set
-	},
-	[BOND_OPT_ACTIVE_SLAVE] = {
-		.id = BOND_OPT_ACTIVE_SLAVE,
-		.name = "active_slave",
-		.desc = "Currently active slave",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
-						BIT(BOND_MODE_TLB) |
-						BIT(BOND_MODE_ALB)),
-		.set = bond_option_active_slave_set
-	},
-	[BOND_OPT_QUEUE_ID] = {
-		.id = BOND_OPT_QUEUE_ID,
-		.name = "queue_id",
-		.desc = "Set queue id of a slave",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_queue_id_set
-	},
-	[BOND_OPT_ALL_SLAVES_ACTIVE] = {
-		.id = BOND_OPT_ALL_SLAVES_ACTIVE,
-		.name = "all_slaves_active",
-		.desc = "Keep all frames received on an interface by setting active flag for all slaves",
-		.values = bond_all_slaves_active_tbl,
-		.set = bond_option_all_slaves_active_set
-	},
-	[BOND_OPT_RESEND_IGMP] = {
-		.id = BOND_OPT_RESEND_IGMP,
-		.name = "resend_igmp",
-		.desc = "Number of IGMP membership reports to send on link failure",
-		.values = bond_resend_igmp_tbl,
-		.set = bond_option_resend_igmp_set
-	},
-	[BOND_OPT_LP_INTERVAL] = {
-		.id = BOND_OPT_LP_INTERVAL,
-		.name = "lp_interval",
-		.desc = "The number of seconds between instances where the bonding driver sends learning packets to each slave's peer switch",
-		.values = bond_lp_interval_tbl,
-		.set = bond_option_lp_interval_set
-	},
-	[BOND_OPT_SLAVES] = {
-		.id = BOND_OPT_SLAVES,
-		.name = "slaves",
-		.desc = "Slave membership management",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_slaves_set
-	},
-	[BOND_OPT_TLB_DYNAMIC_LB] = {
-		.id = BOND_OPT_TLB_DYNAMIC_LB,
-		.name = "tlb_dynamic_lb",
-		.desc = "Enable dynamic flow shuffling",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_TLB) | BIT(BOND_MODE_ALB)),
-		.values = bond_tlb_dynamic_lb_tbl,
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.set = bond_option_tlb_dynamic_lb_set,
-	},
-	[BOND_OPT_AD_ACTOR_SYS_PRIO] = {
-		.id = BOND_OPT_AD_ACTOR_SYS_PRIO,
-		.name = "ad_actor_sys_prio",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.values = bond_ad_actor_sys_prio_tbl,
-		.set = bond_option_ad_actor_sys_prio_set,
-	},
-	[BOND_OPT_AD_ACTOR_SYSTEM] = {
-		.id = BOND_OPT_AD_ACTOR_SYSTEM,
-		.name = "ad_actor_system",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_ad_actor_system_set,
-	},
-	[BOND_OPT_AD_USER_PORT_KEY] = {
-		.id = BOND_OPT_AD_USER_PORT_KEY,
-		.name = "ad_user_port_key",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.values = bond_ad_user_port_key_tbl,
-		.set = bond_option_ad_user_port_key_set,
-	},
-	[BOND_OPT_NUM_PEER_NOTIF_ALIAS] = {
-		.id = BOND_OPT_NUM_PEER_NOTIF_ALIAS,
-		.name = "num_grat_arp",
-		.desc = "Number of peer notifications to send on failover event",
-		.values = bond_num_peer_notif_tbl,
-		.set = bond_option_num_peer_notif_set
-	},
-	[BOND_OPT_PEER_NOTIF_DELAY] = {
-		.id = BOND_OPT_PEER_NOTIF_DELAY,
-		.name = "peer_notif_delay",
-		.desc = "Delay between each peer notification on failover event, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_peer_notif_delay_set
-	}
-};
-
-/* Searches for an option by name */
-const struct bond_option *bond_opt_get_by_name(const char *name)
-{
-	const struct bond_option *opt;
-	int option;
-
-	for (option = 0; option < BOND_OPT_LAST; option++) {
-		opt = bond_opt_get(option);
-		if (opt && !strcmp(opt->name, name))
-			return opt;
-	}
-
-	return NULL;
-}
-
-/* Searches for a value in opt's values[] table */
-const struct bond_opt_value *bond_opt_get_val(unsigned int option, u64 val)
-{
-	const struct bond_option *opt;
-	int i;
-
-	opt = bond_opt_get(option);
-	if (WARN_ON(!opt))
-		return NULL;
-	for (i = 0; opt->values && opt->values[i].string; i++)
-		if (opt->values[i].value == val)
-			return &opt->values[i];
-
-	return NULL;
-}
-
-/* Searches for a value in opt's values[] table which matches the flagmask */
-static const struct bond_opt_value *bond_opt_get_flags(const struct bond_option *opt,
-						       u32 flagmask)
-{
-	int i;
-
-	for (i = 0; opt->values && opt->values[i].string; i++)
-		if (opt->values[i].flags & flagmask)
-			return &opt->values[i];
-
-	return NULL;
-}
-
-/* If maxval is missing then there's no range to check. In case minval is
- * missing then it's considered to be 0.
- */
-static bool bond_opt_check_range(const struct bond_option *opt, u64 val)
-{
-	const struct bond_opt_value *minval, *maxval;
-
-	minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
-	maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
-	if (!maxval || (minval && val < minval->value) || val > maxval->value)
-		return false;
-
-	return true;
-}
-
-/**
- * bond_opt_parse - parse option value
- * @opt: the option to parse against
- * @val: value to parse
- *
- * This function tries to extract the value from @val and check if it's
- * a possible match for the option and returns NULL if a match isn't found,
- * or the struct_opt_value that matched. It also strips the new line from
- * @val->string if it's present.
- */
-const struct bond_opt_value *bond_opt_parse(const struct bond_option *opt,
-					    struct bond_opt_value *val)
-{
-	char *p, valstr[BOND_OPT_MAX_NAMELEN + 1] = { 0, };
-	const struct bond_opt_value *tbl;
-	const struct bond_opt_value *ret = NULL;
-	bool checkval;
-	int i, rv;
-
-	/* No parsing if the option wants a raw val */
-	if (opt->flags & BOND_OPTFLAG_RAWVAL)
-		return val;
-
-	tbl = opt->values;
-	if (!tbl)
-		goto out;
-
-	/* ULLONG_MAX is used to bypass string processing */
-	checkval = val->value != ULLONG_MAX;
-	if (!checkval) {
-		if (!val->string)
-			goto out;
-		p = strchr(val->string, '\n');
-		if (p)
-			*p = '\0';
-		for (p = val->string; *p; p++)
-			if (!(isdigit(*p) || isspace(*p)))
-				break;
-		/* The following code extracts the string to match or the value
-		 * and sets checkval appropriately
-		 */
-		if (*p) {
-			rv = sscanf(val->string, "%32s", valstr);
-		} else {
-			rv = sscanf(val->string, "%llu", &val->value);
-			checkval = true;
-		}
-		if (!rv)
-			goto out;
-	}
-
-	for (i = 0; tbl[i].string; i++) {
-		/* Check for exact match */
-		if (checkval) {
-			if (val->value == tbl[i].value)
-				ret = &tbl[i];
-		} else {
-			if (!strcmp(valstr, "default") &&
-			    (tbl[i].flags & BOND_VALFLAG_DEFAULT))
-				ret = &tbl[i];
-
-			if (!strcmp(valstr, tbl[i].string))
-				ret = &tbl[i];
-		}
-		/* Found an exact match */
-		if (ret)
-			goto out;
-	}
-	/* Possible range match */
-	if (checkval && bond_opt_check_range(opt, val->value))
-		ret = val;
-out:
-	return ret;
-}
-
-/* Check opt's dependencies against bond mode and currently set options */
-static int bond_opt_check_deps(struct bonding *bond,
-			       const struct bond_option *opt)
-{
-	struct bond_params *params = &bond->params;
-
-	if (test_bit(params->mode, &opt->unsuppmodes))
-		return -EACCES;
-	if ((opt->flags & BOND_OPTFLAG_NOSLAVES) && bond_has_slaves(bond))
-		return -ENOTEMPTY;
-	if ((opt->flags & BOND_OPTFLAG_IFDOWN) && (bond->dev->flags & IFF_UP))
-		return -EBUSY;
-
-	return 0;
-}
-
-static void bond_opt_dep_print(struct bonding *bond,
-			       const struct bond_option *opt)
-{
-	const struct bond_opt_value *modeval;
-	struct bond_params *params;
-
-	params = &bond->params;
-	modeval = bond_opt_get_val(BOND_OPT_MODE, params->mode);
-	if (test_bit(params->mode, &opt->unsuppmodes))
-		netdev_err(bond->dev, "option %s: mode dependency failed, not supported in mode %s(%llu)\n",
-			   opt->name, modeval->string, modeval->value);
-}
-
-static void bond_opt_error_interpret(struct bonding *bond,
-				     const struct bond_option *opt,
-				     int error, const struct bond_opt_value *val)
-{
-	const struct bond_opt_value *minval, *maxval;
-	char *p;
-
-	switch (error) {
-	case -EINVAL:
-		if (val) {
-			if (val->string) {
-				/* sometimes RAWVAL opts may have new lines */
-				p = strchr(val->string, '\n');
-				if (p)
-					*p = '\0';
-				netdev_err(bond->dev, "option %s: invalid value (%s)\n",
-					   opt->name, val->string);
-			} else {
-				netdev_err(bond->dev, "option %s: invalid value (%llu)\n",
-					   opt->name, val->value);
-			}
-		}
-		minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
-		maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
-		if (!maxval)
-			break;
-		netdev_err(bond->dev, "option %s: allowed values %llu - %llu\n",
-			   opt->name, minval ? minval->value : 0, maxval->value);
-		break;
-	case -EACCES:
-		bond_opt_dep_print(bond, opt);
-		break;
-	case -ENOTEMPTY:
-		netdev_err(bond->dev, "option %s: unable to set because the bond device has slaves\n",
-			   opt->name);
-		break;
-	case -EBUSY:
-		netdev_err(bond->dev, "option %s: unable to set because the bond device is up\n",
-			   opt->name);
-		break;
-	default:
-		break;
-	}
-}
-
-/**
- * __bond_opt_set - set a bonding option
- * @bond: target bond device
- * @option: option to set
- * @val: value to set it to
- *
- * This function is used to change the bond's option value, it can be
- * used for both enabling/changing an option and for disabling it. RTNL lock
- * must be obtained before calling this function.
- */
-int __bond_opt_set(struct bonding *bond,
-		   unsigned int option, struct bond_opt_value *val)
-{
-	const struct bond_opt_value *retval = NULL;
-	const struct bond_option *opt;
-	int ret = -ENOENT;
-
-	ASSERT_RTNL();
-
-	opt = bond_opt_get(option);
-	if (WARN_ON(!val) || WARN_ON(!opt))
-		goto out;
-	ret = bond_opt_check_deps(bond, opt);
-	if (ret)
-		goto out;
-	retval = bond_opt_parse(opt, val);
-	if (!retval) {
-		ret = -EINVAL;
-		goto out;
-	}
-	ret = opt->set(bond, retval);
-out:
-	if (ret)
-		bond_opt_error_interpret(bond, opt, ret, val);
-
-	return ret;
-}
-/**
- * __bond_opt_set_notify - set a bonding option
- * @bond: target bond device
- * @option: option to set
- * @val: value to set it to
- *
- * This function is used to change the bond's option value and trigger
- * a notification to user sapce. It can be used for both enabling/changing
- * an option and for disabling it. RTNL lock must be obtained before calling
- * this function.
- */
-int __bond_opt_set_notify(struct bonding *bond,
-			  unsigned int option, struct bond_opt_value *val)
-{
-	int ret = -ENOENT;
-
-	ASSERT_RTNL();
-
-	ret = __bond_opt_set(bond, option, val);
-
-	if (!ret && (bond->dev->reg_state == NETREG_REGISTERED))
-		call_netdevice_notifiers(NETDEV_CHANGEINFODATA, bond->dev);
-
-	return ret;
-}
-
-/**
- * bond_opt_tryset_rtnl - try to acquire rtnl and call __bond_opt_set
- * @bond: target bond device
- * @option: option to set
- * @buf: value to set it to
- *
- * This function tries to acquire RTNL without blocking and if successful
- * calls __bond_opt_set. It is mainly used for sysfs option manipulation.
- */
-int bond_opt_tryset_rtnl(struct bonding *bond, unsigned int option, char *buf)
-{
-	struct bond_opt_value optval;
-	int ret;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-	bond_opt_initstr(&optval, buf);
-	ret = __bond_opt_set_notify(bond, option, &optval);
-	rtnl_unlock();
-
-	return ret;
-}
-
-/**
- * bond_opt_get - get a pointer to an option
- * @option: option for which to return a pointer
- *
- * This function checks if option is valid and if so returns a pointer
- * to its entry in the bond_opts[] option array.
- */
-const struct bond_option *bond_opt_get(unsigned int option)
-{
-	if (!BOND_OPT_VALID(option))
-		return NULL;
-
-	return &bond_opts[option];
-}
-
-static int bond_option_mode_set(struct bonding *bond,
-				const struct bond_opt_value *newval)
-{
-	if (!bond_mode_uses_arp(newval->value)) {
-		if (bond->params.arp_interval) {
-			netdev_dbg(bond->dev, "%s mode is incompatible with arp monitoring, start mii monitoring\n",
-				   newval->string);
-			/* disable arp monitoring */
-			bond->params.arp_interval = 0;
-		}
-
-		if (!bond->params.miimon) {
-			/* set miimon to default value */
-			bond->params.miimon = BOND_DEFAULT_MIIMON;
-			netdev_dbg(bond->dev, "Setting MII monitoring interval to %d\n",
-				   bond->params.miimon);
-		}
-	}
-
-	if (newval->value == BOND_MODE_ALB)
-		bond->params.tlb_dynamic_lb = 1;
-
-	/* don't cache arp_validate between modes */
-	bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
-	bond->params.mode = newval->value;
-
-	return 0;
-}
-
-static int bond_option_active_slave_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	char ifname[IFNAMSIZ] = { 0, };
-	struct net_device *slave_dev;
-	int ret = 0;
-
-	sscanf(newval->string, "%15s", ifname); /* IFNAMSIZ */
-	if (!strlen(ifname) || newval->string[0] == '\n') {
-		slave_dev = NULL;
-	} else {
-		slave_dev = __dev_get_by_name(dev_net(bond->dev), ifname);
-		if (!slave_dev)
-			return -ENODEV;
-	}
-
-	if (slave_dev) {
-		if (!netif_is_bond_slave(slave_dev)) {
-			slave_err(bond->dev, slave_dev, "Device is not bonding slave\n");
-			return -EINVAL;
-		}
-
-		if (bond->dev != netdev_master_upper_dev_get(slave_dev)) {
-			slave_err(bond->dev, slave_dev, "Device is not our slave\n");
-			return -EINVAL;
-		}
-	}
-
-	block_netpoll_tx();
-	/* check to see if we are clearing active */
-	if (!slave_dev) {
-		netdev_dbg(bond->dev, "Clearing current active slave\n");
-		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
-		bond_select_active_slave(bond);
-	} else {
-		struct slave *old_active = rtnl_dereference(bond->curr_active_slave);
-		struct slave *new_active = bond_slave_get_rtnl(slave_dev);
-
-		BUG_ON(!new_active);
-
-		if (new_active == old_active) {
-			/* do nothing */
-			slave_dbg(bond->dev, new_active->dev, "is already the current active slave\n");
-		} else {
-			if (old_active && (new_active->link == BOND_LINK_UP) &&
-			    bond_slave_is_up(new_active)) {
-				slave_dbg(bond->dev, new_active->dev, "Setting as active slave\n");
-				bond_change_active_slave(bond, new_active);
-			} else {
-				slave_err(bond->dev, new_active->dev, "Could not set as active slave; either %s is down or the link is down\n",
-					  new_active->dev->name);
-				ret = -EINVAL;
-			}
-		}
-	}
-	unblock_netpoll_tx();
-
-	return ret;
-}
-
-/* There are two tricky bits here.  First, if MII monitoring is activated, then
- * we must disable ARP monitoring.  Second, if the timer isn't running, we must
- * start it.
- */
-static int bond_option_miimon_set(struct bonding *bond,
-				  const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting MII monitoring interval to %llu\n",
-		   newval->value);
-	bond->params.miimon = newval->value;
-	if (bond->params.updelay)
-		netdev_dbg(bond->dev, "Note: Updating updelay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.updelay * bond->params.miimon);
-	if (bond->params.downdelay)
-		netdev_dbg(bond->dev, "Note: Updating downdelay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.downdelay * bond->params.miimon);
-	if (bond->params.peer_notif_delay)
-		netdev_dbg(bond->dev, "Note: Updating peer_notif_delay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.peer_notif_delay * bond->params.miimon);
-	if (newval->value && bond->params.arp_interval) {
-		netdev_dbg(bond->dev, "MII monitoring cannot be used with ARP monitoring - disabling ARP monitoring...\n");
-		bond->params.arp_interval = 0;
-		if (bond->params.arp_validate)
-			bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
-	}
-	if (bond->dev->flags & IFF_UP) {
-		/* If the interface is up, we may need to fire off
-		 * the MII timer. If the interface is down, the
-		 * timer will get fired off when the open function
-		 * is called.
-		 */
-		if (!newval->value) {
-			cancel_delayed_work_sync(&bond->mii_work);
-		} else {
-			cancel_delayed_work_sync(&bond->arp_work);
-			queue_delayed_work(bond->wq, &bond->mii_work, 0);
-		}
-	}
-
-	return 0;
-}
-
-/* Set up, down and peer notification delays. These must be multiples
- * of the MII monitoring value, and are stored internally as the
- * multiplier. Thus, we must translate to MS for the real world.
- */
-static int _bond_option_delay_set(struct bonding *bond,
-				  const struct bond_opt_value *newval,
-				  const char *name,
-				  int *target)
-{
-	int value = newval->value;
-
-	if (!bond->params.miimon) {
-		netdev_err(bond->dev, "Unable to set %s as MII monitoring is disabled\n",
-			   name);
-		return -EPERM;
-	}
-	if ((value % bond->params.miimon) != 0) {
-		netdev_warn(bond->dev,
-			    "%s (%d) is not a multiple of miimon (%d), value rounded to %d ms\n",
-			    name,
-			    value, bond->params.miimon,
-			    (value / bond->params.miimon) *
-			    bond->params.miimon);
-	}
-	*target = value / bond->params.miimon;
-	netdev_dbg(bond->dev, "Setting %s to %d\n",
-		   name,
-		   *target * bond->params.miimon);
-
-	return 0;
-}
-
-static int bond_option_updelay_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	return _bond_option_delay_set(bond, newval, "up delay",
-				      &bond->params.updelay);
-}
-
-static int bond_option_downdelay_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	return _bond_option_delay_set(bond, newval, "down delay",
-				      &bond->params.downdelay);
-}
-
-static int bond_option_peer_notif_delay_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	int ret = _bond_option_delay_set(bond, newval,
-					 "peer notification delay",
-					 &bond->params.peer_notif_delay);
-	return ret;
-}
-
-static int bond_option_use_carrier_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting use_carrier to %llu\n",
-		   newval->value);
-	bond->params.use_carrier = newval->value;
-
-	return 0;
-}
-
-/* There are two tricky bits here.  First, if ARP monitoring is activated, then
- * we must disable MII monitoring.  Second, if the ARP timer isn't running,
- * we must start it.
- */
-static int bond_option_arp_interval_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ARP monitoring interval to %llu\n",
-		   newval->value);
-	bond->params.arp_interval = newval->value;
-	if (newval->value) {
-		if (bond->params.miimon) {
-			netdev_dbg(bond->dev, "ARP monitoring cannot be used with MII monitoring. Disabling MII monitoring\n");
-			bond->params.miimon = 0;
-		}
-		if (!bond->params.arp_targets[0])
-			netdev_dbg(bond->dev, "ARP monitoring has been set up, but no ARP targets have been specified\n");
-	}
-	if (bond->dev->flags & IFF_UP) {
-		/* If the interface is up, we may need to fire off
-		 * the ARP timer.  If the interface is down, the
-		 * timer will get fired off when the open function
-		 * is called.
-		 */
-		if (!newval->value) {
-			if (bond->params.arp_validate)
-				bond->recv_probe = NULL;
-			cancel_delayed_work_sync(&bond->arp_work);
-		} else {
-			/* arp_validate can be set only in active-backup mode */
-			bond->recv_probe = bond_arp_rcv;
-			cancel_delayed_work_sync(&bond->mii_work);
-			queue_delayed_work(bond->wq, &bond->arp_work, 0);
-		}
-	}
-
-	return 0;
-}
-
-static void _bond_options_arp_ip_target_set(struct bonding *bond, int slot,
-					    __be32 target,
-					    unsigned long last_rx)
-{
-	__be32 *targets = bond->params.arp_targets;
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (slot >= 0 && slot < BOND_MAX_ARP_TARGETS) {
-		bond_for_each_slave(bond, slave, iter)
-			slave->target_last_arp_rx[slot] = last_rx;
-		targets[slot] = target;
-	}
-}
-
-static int _bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
-{
-	__be32 *targets = bond->params.arp_targets;
-	int ind;
-
-	if (!bond_is_ip_target_ok(target)) {
-		netdev_err(bond->dev, "invalid ARP target %pI4 specified for addition\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	if (bond_get_targets_ip(targets, target) != -1) { /* dup */
-		netdev_err(bond->dev, "ARP target %pI4 is already present\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	ind = bond_get_targets_ip(targets, 0); /* first free slot */
-	if (ind == -1) {
-		netdev_err(bond->dev, "ARP target table is full!\n");
-		return -EINVAL;
-	}
-
-	netdev_dbg(bond->dev, "Adding ARP target %pI4\n", &target);
-
-	_bond_options_arp_ip_target_set(bond, ind, target, jiffies);
-
-	return 0;
-}
-
-static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
-{
-	return _bond_option_arp_ip_target_add(bond, target);
-}
-
-static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target)
-{
-	__be32 *targets = bond->params.arp_targets;
-	struct list_head *iter;
-	struct slave *slave;
-	unsigned long *targets_rx;
-	int ind, i;
-
-	if (!bond_is_ip_target_ok(target)) {
-		netdev_err(bond->dev, "invalid ARP target %pI4 specified for removal\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	ind = bond_get_targets_ip(targets, target);
-	if (ind == -1) {
-		netdev_err(bond->dev, "unable to remove nonexistent ARP target %pI4\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	if (ind == 0 && !targets[1] && bond->params.arp_interval)
-		netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
-
-	netdev_dbg(bond->dev, "Removing ARP target %pI4\n", &target);
-
-	bond_for_each_slave(bond, slave, iter) {
-		targets_rx = slave->target_last_arp_rx;
-		for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
-			targets_rx[i] = targets_rx[i+1];
-		targets_rx[i] = 0;
-	}
-	for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
-		targets[i] = targets[i+1];
-	targets[i] = 0;
-
-	return 0;
-}
-
-void bond_option_arp_ip_targets_clear(struct bonding *bond)
-{
-	int i;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
-		_bond_options_arp_ip_target_set(bond, i, 0, 0);
-}
-
-static int bond_option_arp_ip_targets_set(struct bonding *bond,
-					  const struct bond_opt_value *newval)
-{
-	int ret = -EPERM;
-	__be32 target;
-
-	if (newval->string) {
-		if (!in4_pton(newval->string+1, -1, (u8 *)&target, -1, NULL)) {
-			netdev_err(bond->dev, "invalid ARP target %pI4 specified\n",
-				   &target);
-			return ret;
-		}
-		if (newval->string[0] == '+')
-			ret = bond_option_arp_ip_target_add(bond, target);
-		else if (newval->string[0] == '-')
-			ret = bond_option_arp_ip_target_rem(bond, target);
-		else
-			netdev_err(bond->dev, "no command found in arp_ip_targets file - use +<addr> or -<addr>\n");
-	} else {
-		target = newval->value;
-		ret = bond_option_arp_ip_target_add(bond, target);
-	}
-
-	return ret;
-}
-
-static int bond_option_arp_validate_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting arp_validate to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.arp_validate = newval->value;
-
-	return 0;
-}
-
-static int bond_option_arp_all_targets_set(struct bonding *bond,
-					   const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting arp_all_targets to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.arp_all_targets = newval->value;
-
-	return 0;
-}
-
-static int bond_option_primary_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	char *p, *primary = newval->string;
-	struct list_head *iter;
-	struct slave *slave;
-
-	block_netpoll_tx();
-
-	p = strchr(primary, '\n');
-	if (p)
-		*p = '\0';
-	/* check to see if we are clearing primary */
-	if (!strlen(primary)) {
-		netdev_dbg(bond->dev, "Setting primary slave to None\n");
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-		memset(bond->params.primary, 0, sizeof(bond->params.primary));
-		bond_select_active_slave(bond);
-		goto out;
-	}
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (strncmp(slave->dev->name, primary, IFNAMSIZ) == 0) {
-			slave_dbg(bond->dev, slave->dev, "Setting as primary slave\n");
-			rcu_assign_pointer(bond->primary_slave, slave);
-			strcpy(bond->params.primary, slave->dev->name);
-			bond->force_primary = true;
-			bond_select_active_slave(bond);
-			goto out;
-		}
-	}
-
-	if (rtnl_dereference(bond->primary_slave)) {
-		netdev_dbg(bond->dev, "Setting primary slave to None\n");
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-		bond_select_active_slave(bond);
-	}
-	strncpy(bond->params.primary, primary, IFNAMSIZ);
-	bond->params.primary[IFNAMSIZ - 1] = 0;
-
-	netdev_dbg(bond->dev, "Recording %s as primary, but it has not been enslaved yet\n",
-		   primary);
-
-out:
-	unblock_netpoll_tx();
-
-	return 0;
-}
-
-static int bond_option_primary_reselect_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting primary_reselect to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.primary_reselect = newval->value;
-
-	block_netpoll_tx();
-	bond_select_active_slave(bond);
-	unblock_netpoll_tx();
-
-	return 0;
-}
-
-static int bond_option_fail_over_mac_set(struct bonding *bond,
-					 const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting fail_over_mac to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.fail_over_mac = newval->value;
-
-	return 0;
-}
-
-static int bond_option_xmit_hash_policy_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting xmit hash policy to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.xmit_policy = newval->value;
-
-	return 0;
-}
-
-static int bond_option_resend_igmp_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting resend_igmp to %llu\n",
-		   newval->value);
-	bond->params.resend_igmp = newval->value;
-
-	return 0;
-}
-
-static int bond_option_num_peer_notif_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	bond->params.num_peer_notif = newval->value;
-
-	return 0;
-}
-
-static int bond_option_all_slaves_active_set(struct bonding *bond,
-					     const struct bond_opt_value *newval)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (newval->value == bond->params.all_slaves_active)
-		return 0;
-	bond->params.all_slaves_active = newval->value;
-	bond_for_each_slave(bond, slave, iter) {
-		if (!bond_is_active_slave(slave)) {
-			if (newval->value)
-				slave->inactive = 0;
-			else
-				slave->inactive = 1;
-		}
-	}
-
-	return 0;
-}
-
-static int bond_option_min_links_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting min links value to %llu\n",
-		   newval->value);
-	bond->params.min_links = newval->value;
-	bond_set_carrier(bond);
-
-	return 0;
-}
-
-static int bond_option_lp_interval_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	bond->params.lp_interval = newval->value;
-
-	return 0;
-}
-
-static int bond_option_pps_set(struct bonding *bond,
-			       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting packets per slave to %llu\n",
-		   newval->value);
-	bond->params.packets_per_slave = newval->value;
-	if (newval->value > 0) {
-		bond->params.reciprocal_packets_per_slave =
-			reciprocal_value(newval->value);
-	} else {
-		/* reciprocal_packets_per_slave is unused if
-		 * packets_per_slave is 0 or 1, just initialize it
-		 */
-		bond->params.reciprocal_packets_per_slave =
-			(struct reciprocal_value) { 0 };
-	}
-
-	return 0;
-}
-
-static int bond_option_lacp_rate_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting LACP rate to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.lacp_fast = newval->value;
-	bond_3ad_update_lacp_rate(bond);
-
-	return 0;
-}
-
-static int bond_option_ad_select_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_select to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.ad_select = newval->value;
-
-	return 0;
-}
-
-static int bond_option_queue_id_set(struct bonding *bond,
-				    const struct bond_opt_value *newval)
-{
-	struct slave *slave, *update_slave;
-	struct net_device *sdev;
-	struct list_head *iter;
-	char *delim;
-	int ret = 0;
-	u16 qid;
-
-	/* delim will point to queue id if successful */
-	delim = strchr(newval->string, ':');
-	if (!delim)
-		goto err_no_cmd;
-
-	/* Terminate string that points to device name and bump it
-	 * up one, so we can read the queue id there.
-	 */
-	*delim = '\0';
-	if (sscanf(++delim, "%hd\n", &qid) != 1)
-		goto err_no_cmd;
-
-	/* Check buffer length, valid ifname and queue id */
-	if (!dev_valid_name(newval->string) ||
-	    qid > bond->dev->real_num_tx_queues)
-		goto err_no_cmd;
-
-	/* Get the pointer to that interface if it exists */
-	sdev = __dev_get_by_name(dev_net(bond->dev), newval->string);
-	if (!sdev)
-		goto err_no_cmd;
-
-	/* Search for thes slave and check for duplicate qids */
-	update_slave = NULL;
-	bond_for_each_slave(bond, slave, iter) {
-		if (sdev == slave->dev)
-			/* We don't need to check the matching
-			 * slave for dups, since we're overwriting it
-			 */
-			update_slave = slave;
-		else if (qid && qid == slave->queue_id) {
-			goto err_no_cmd;
-		}
-	}
-
-	if (!update_slave)
-		goto err_no_cmd;
-
-	/* Actually set the qids for the slave */
-	update_slave->queue_id = qid;
-
-out:
-	return ret;
-
-err_no_cmd:
-	netdev_dbg(bond->dev, "invalid input for queue_id set\n");
-	ret = -EPERM;
-	goto out;
-
-}
-
-static int bond_option_slaves_set(struct bonding *bond,
-				  const struct bond_opt_value *newval)
-{
-	char command[IFNAMSIZ + 1] = { 0, };
-	struct net_device *dev;
-	char *ifname;
-	int ret;
-
-	sscanf(newval->string, "%16s", command); /* IFNAMSIZ*/
-	ifname = command + 1;
-	if ((strlen(command) <= 1) ||
-	    (command[0] != '+' && command[0] != '-') ||
-	    !dev_valid_name(ifname))
-		goto err_no_cmd;
-
-	dev = __dev_get_by_name(dev_net(bond->dev), ifname);
-	if (!dev) {
-		netdev_dbg(bond->dev, "interface %s does not exist!\n",
-			   ifname);
-		ret = -ENODEV;
-		goto out;
-	}
-
-	switch (command[0]) {
-	case '+':
-		slave_dbg(bond->dev, dev, "Enslaving interface\n");
-		ret = bond_enslave(bond->dev, dev, NULL);
-		break;
-
-	case '-':
-		slave_dbg(bond->dev, dev, "Releasing interface\n");
-		ret = bond_release(bond->dev, dev);
-		break;
-
-	default:
-		/* should not run here. */
-		goto err_no_cmd;
-	}
-
-out:
-	return ret;
-
-err_no_cmd:
-	netdev_err(bond->dev, "no command found in slaves file - use +ifname or -ifname\n");
-	ret = -EPERM;
-	goto out;
-}
-
-static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
-					  const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting dynamic-lb to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.tlb_dynamic_lb = newval->value;
-
-	return 0;
-}
-
-static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
-					     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_actor_sys_prio to %llu\n",
-		   newval->value);
-
-	bond->params.ad_actor_sys_prio = newval->value;
-	bond_3ad_update_ad_actor_settings(bond);
-
-	return 0;
-}
-
-static int bond_option_ad_actor_system_set(struct bonding *bond,
-					   const struct bond_opt_value *newval)
-{
-	u8 macaddr[ETH_ALEN];
-	u8 *mac;
-
-	if (newval->string) {
-		if (!mac_pton(newval->string, macaddr))
-			goto err;
-		mac = macaddr;
-	} else {
-		mac = (u8 *)&newval->value;
-	}
-
-	if (!is_valid_ether_addr(mac))
-		goto err;
-
-	netdev_dbg(bond->dev, "Setting ad_actor_system to %pM\n", mac);
-	ether_addr_copy(bond->params.ad_actor_system, mac);
-	bond_3ad_update_ad_actor_settings(bond);
-
-	return 0;
-
-err:
-	netdev_err(bond->dev, "Invalid ad_actor_system MAC address.\n");
-	return -EINVAL;
-}
-
-static int bond_option_ad_user_port_key_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_user_port_key to %llu\n",
-		   newval->value);
-
-	bond->params.ad_user_port_key = newval->value;
-	return 0;
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.19/bond_procfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.19/bond_procfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,312 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-#include <linux/proc_fs.h>
-#include <linux/export.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <net/bonding.h>
-
-#include "bonding_priv.h"
-
-static void *bond_info_seq_start(struct seq_file *seq, loff_t *pos)
-	__acquires(RCU)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	struct list_head *iter;
-	struct slave *slave;
-	loff_t off = 0;
-
-	rcu_read_lock();
-
-	if (*pos == 0)
-		return SEQ_START_TOKEN;
-
-	bond_for_each_slave_rcu(bond, slave, iter)
-		if (++off == *pos)
-			return slave;
-
-	return NULL;
-}
-
-static void *bond_info_seq_next(struct seq_file *seq, void *v, loff_t *pos)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	struct list_head *iter;
-	struct slave *slave;
-	bool found = false;
-
-	++*pos;
-	if (v == SEQ_START_TOKEN)
-		return bond_first_slave_rcu(bond);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (found)
-			return slave;
-		if (slave == v)
-			found = true;
-	}
-
-	return NULL;
-}
-
-static void bond_info_seq_stop(struct seq_file *seq, void *v)
-	__releases(RCU)
-{
-	rcu_read_unlock();
-}
-
-static void bond_info_show_master(struct seq_file *seq)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	const struct bond_opt_value *optval;
-	struct slave *curr, *primary;
-	int i;
-
-	curr = rcu_dereference(bond->curr_active_slave);
-
-	seq_printf(seq, "Bonding Mode: %s",
-		   bond_mode_name(BOND_MODE(bond)));
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
-	    bond->params.fail_over_mac) {
-		optval = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
-					  bond->params.fail_over_mac);
-		seq_printf(seq, " (fail_over_mac %s)", optval->string);
-	}
-
-	seq_printf(seq, "\n");
-
-	if (bond_mode_uses_xmit_hash(bond)) {
-		optval = bond_opt_get_val(BOND_OPT_XMIT_HASH,
-					  bond->params.xmit_policy);
-		seq_printf(seq, "Transmit Hash Policy: %s (%d)\n",
-			   optval->string, bond->params.xmit_policy);
-	}
-
-	if (bond_uses_primary(bond)) {
-		primary = rcu_dereference(bond->primary_slave);
-		seq_printf(seq, "Primary Slave: %s",
-			   primary ? primary->dev->name : "None");
-		if (primary) {
-			optval = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
-						  bond->params.primary_reselect);
-			seq_printf(seq, " (primary_reselect %s)",
-				   optval->string);
-		}
-
-		seq_printf(seq, "\nCurrently Active Slave: %s\n",
-			   (curr) ? curr->dev->name : "None");
-	}
-
-	seq_printf(seq, "MII Status: %s\n", netif_carrier_ok(bond->dev) ?
-		   "up" : "down");
-	seq_printf(seq, "MII Polling Interval (ms): %d\n", bond->params.miimon);
-	seq_printf(seq, "Up Delay (ms): %d\n",
-		   bond->params.updelay * bond->params.miimon);
-	seq_printf(seq, "Down Delay (ms): %d\n",
-		   bond->params.downdelay * bond->params.miimon);
-	seq_printf(seq, "Peer Notification Delay (ms): %d\n",
-		   bond->params.peer_notif_delay * bond->params.miimon);
-
-
-	/* ARP information */
-	if (bond->params.arp_interval > 0) {
-		int printed = 0;
-		seq_printf(seq, "ARP Polling Interval (ms): %d\n",
-				bond->params.arp_interval);
-
-		seq_printf(seq, "ARP IP target/s (n.n.n.n form):");
-
-		for (i = 0; (i < BOND_MAX_ARP_TARGETS); i++) {
-			if (!bond->params.arp_targets[i])
-				break;
-			if (printed)
-				seq_printf(seq, ",");
-			seq_printf(seq, " %pI4", &bond->params.arp_targets[i]);
-			printed = 1;
-		}
-		seq_printf(seq, "\n");
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-
-		seq_puts(seq, "\n802.3ad info\n");
-		seq_printf(seq, "LACP rate: %s\n",
-			   (bond->params.lacp_fast) ? "fast" : "slow");
-		seq_printf(seq, "Min links: %d\n", bond->params.min_links);
-		optval = bond_opt_get_val(BOND_OPT_AD_SELECT,
-					  bond->params.ad_select);
-		seq_printf(seq, "Aggregator selection policy (ad_select): %s\n",
-			   optval->string);
-		if (capable(CAP_NET_ADMIN)) {
-			seq_printf(seq, "System priority: %d\n",
-				   BOND_AD_INFO(bond).system.sys_priority);
-			seq_printf(seq, "System MAC address: %pM\n",
-				   &BOND_AD_INFO(bond).system.sys_mac_addr);
-
-			if (__bond_3ad_get_active_agg_info(bond, &ad_info)) {
-				seq_printf(seq,
-					   "bond %s has no active aggregator\n",
-					   bond->dev->name);
-			} else {
-				seq_printf(seq, "Active Aggregator Info:\n");
-
-				seq_printf(seq, "\tAggregator ID: %d\n",
-					   ad_info.aggregator_id);
-				seq_printf(seq, "\tNumber of ports: %d\n",
-					   ad_info.ports);
-				seq_printf(seq, "\tActor Key: %d\n",
-					   ad_info.actor_key);
-				seq_printf(seq, "\tPartner Key: %d\n",
-					   ad_info.partner_key);
-				seq_printf(seq, "\tPartner Mac Address: %pM\n",
-					   ad_info.partner_system);
-			}
-		}
-	}
-}
-
-static void bond_info_show_slave(struct seq_file *seq,
-				 const struct slave *slave)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-
-	seq_printf(seq, "\nSlave Interface: %s\n", slave->dev->name);
-	seq_printf(seq, "MII Status: %s\n", bond_slave_link_status(slave->link));
-	if (slave->speed == SPEED_UNKNOWN)
-		seq_printf(seq, "Speed: %s\n", "Unknown");
-	else
-		seq_printf(seq, "Speed: %d Mbps\n", slave->speed);
-
-	if (slave->duplex == DUPLEX_UNKNOWN)
-		seq_printf(seq, "Duplex: %s\n", "Unknown");
-	else
-		seq_printf(seq, "Duplex: %s\n", slave->duplex ? "full" : "half");
-
-	seq_printf(seq, "Link Failure Count: %u\n",
-		   slave->link_failure_count);
-
-	seq_printf(seq, "Permanent HW addr: %*phC\n",
-		   slave->dev->addr_len, slave->perm_hwaddr);
-	seq_printf(seq, "Slave queue ID: %d\n", slave->queue_id);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		const struct port *port = &SLAVE_AD_INFO(slave)->port;
-		const struct aggregator *agg = port->aggregator;
-
-		if (agg) {
-			seq_printf(seq, "Aggregator ID: %d\n",
-				   agg->aggregator_identifier);
-			seq_printf(seq, "Actor Churn State: %s\n",
-				   bond_3ad_churn_desc(port->sm_churn_actor_state));
-			seq_printf(seq, "Partner Churn State: %s\n",
-				   bond_3ad_churn_desc(port->sm_churn_partner_state));
-			seq_printf(seq, "Actor Churned Count: %d\n",
-				   port->churn_actor_count);
-			seq_printf(seq, "Partner Churned Count: %d\n",
-				   port->churn_partner_count);
-
-			if (capable(CAP_NET_ADMIN)) {
-				seq_puts(seq, "details actor lacp pdu:\n");
-				seq_printf(seq, "    system priority: %d\n",
-					   port->actor_system_priority);
-				seq_printf(seq, "    system mac address: %pM\n",
-					   &port->actor_system);
-				seq_printf(seq, "    port key: %d\n",
-					   port->actor_oper_port_key);
-				seq_printf(seq, "    port priority: %d\n",
-					   port->actor_port_priority);
-				seq_printf(seq, "    port number: %d\n",
-					   port->actor_port_number);
-				seq_printf(seq, "    port state: %d\n",
-					   port->actor_oper_port_state);
-
-				seq_puts(seq, "details partner lacp pdu:\n");
-				seq_printf(seq, "    system priority: %d\n",
-					   port->partner_oper.system_priority);
-				seq_printf(seq, "    system mac address: %pM\n",
-					   &port->partner_oper.system);
-				seq_printf(seq, "    oper key: %d\n",
-					   port->partner_oper.key);
-				seq_printf(seq, "    port priority: %d\n",
-					   port->partner_oper.port_priority);
-				seq_printf(seq, "    port number: %d\n",
-					   port->partner_oper.port_number);
-				seq_printf(seq, "    port state: %d\n",
-					   port->partner_oper.port_state);
-			}
-		} else {
-			seq_puts(seq, "Aggregator ID: N/A\n");
-		}
-	}
-}
-
-static int bond_info_seq_show(struct seq_file *seq, void *v)
-{
-	if (v == SEQ_START_TOKEN) {
-		seq_printf(seq, "%s\n", bond_version);
-		bond_info_show_master(seq);
-	} else
-		bond_info_show_slave(seq, v);
-
-	return 0;
-}
-
-static const struct seq_operations bond_info_seq_ops = {
-	.start = bond_info_seq_start,
-	.next  = bond_info_seq_next,
-	.stop  = bond_info_seq_stop,
-	.show  = bond_info_seq_show,
-};
-
-void bond_create_proc_entry(struct bonding *bond)
-{
-	struct net_device *bond_dev = bond->dev;
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	if (bn->proc_dir) {
-		bond->proc_entry = proc_create_seq_data(bond_dev->name, 0444,
-				bn->proc_dir, &bond_info_seq_ops, bond);
-		if (bond->proc_entry == NULL)
-			netdev_warn(bond_dev, "Cannot create /proc/net/%s/%s\n",
-				    DRV_NAME, bond_dev->name);
-		else
-			memcpy(bond->proc_file_name, bond_dev->name, IFNAMSIZ);
-	}
-}
-
-void bond_remove_proc_entry(struct bonding *bond)
-{
-	struct net_device *bond_dev = bond->dev;
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	if (bn->proc_dir && bond->proc_entry) {
-		remove_proc_entry(bond->proc_file_name, bn->proc_dir);
-		memset(bond->proc_file_name, 0, IFNAMSIZ);
-		bond->proc_entry = NULL;
-	}
-}
-
-/* Create the bonding directory under /proc/net, if doesn't exist yet.
- * Caller must hold rtnl_lock.
- */
-void __net_init bond_create_proc_dir(struct bond_net *bn)
-{
-	if (!bn->proc_dir) {
-		bn->proc_dir = proc_mkdir(DRV_NAME, bn->net->proc_net);
-		if (!bn->proc_dir)
-			pr_warn("Warning: Cannot create /proc/net/%s\n",
-				DRV_NAME);
-	}
-}
-
-/* Destroy the bonding directory under /proc/net, if empty.
- * Caller must hold rtnl_lock.
- */
-void __net_exit bond_destroy_proc_dir(struct bond_net *bn)
-{
-	if (bn->proc_dir) {
-		remove_proc_entry(DRV_NAME, bn->net->proc_net);
-		bn->proc_dir = NULL;
-	}
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.19/bond_sysfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.19/bond_sysfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,816 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 2004-2005 Intel Corporation. All rights reserved.
- */
-
-#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/device.h>
-#include <linux/sched/signal.h>
-#include <linux/fs.h>
-#include <linux/types.h>
-#include <linux/string.h>
-#include <linux/netdevice.h>
-#include <linux/inetdevice.h>
-#include <linux/in.h>
-#include <linux/sysfs.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/rtnetlink.h>
-#include <linux/etherdevice.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <linux/nsproxy.h>
-
-#include <net/bonding.h>
-
-#define to_bond(cd)	((struct bonding *)(netdev_priv(to_net_dev(cd))))
-
-/* "show" function for the bond_masters attribute.
- * The class parameter is ignored.
- */
-static ssize_t bonding_show_bonds(struct class *cls,
-				  struct class_attribute *attr,
-				  char *buf)
-{
-	struct bond_net *bn =
-		container_of(attr, struct bond_net, class_attr_bonding_masters);
-	int res = 0;
-	struct bonding *bond;
-
-	rtnl_lock();
-
-	list_for_each_entry(bond, &bn->dev_list, bond_list) {
-		if (res > (PAGE_SIZE - IFNAMSIZ)) {
-			/* not enough space for another interface name */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s ", bond->dev->name);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	rtnl_unlock();
-	return res;
-}
-
-static struct net_device *bond_get_by_name(struct bond_net *bn, const char *ifname)
-{
-	struct bonding *bond;
-
-	list_for_each_entry(bond, &bn->dev_list, bond_list) {
-		if (strncmp(bond->dev->name, ifname, IFNAMSIZ) == 0)
-			return bond->dev;
-	}
-	return NULL;
-}
-
-/* "store" function for the bond_masters attribute.  This is what
- * creates and deletes entire bonds.
- *
- * The class parameter is ignored.
- */
-static ssize_t bonding_store_bonds(struct class *cls,
-				   struct class_attribute *attr,
-				   const char *buffer, size_t count)
-{
-	struct bond_net *bn =
-		container_of(attr, struct bond_net, class_attr_bonding_masters);
-	char command[IFNAMSIZ + 1] = {0, };
-	char *ifname;
-	int rv, res = count;
-
-	sscanf(buffer, "%16s", command); /* IFNAMSIZ*/
-	ifname = command + 1;
-	if ((strlen(command) <= 1) ||
-	    !dev_valid_name(ifname))
-		goto err_no_cmd;
-
-	if (command[0] == '+') {
-		pr_info("%s is being created...\n", ifname);
-		rv = bond_create(bn->net, ifname);
-		if (rv) {
-			if (rv == -EEXIST)
-				pr_info("%s already exists\n", ifname);
-			else
-				pr_info("%s creation failed\n", ifname);
-			res = rv;
-		}
-	} else if (command[0] == '-') {
-		struct net_device *bond_dev;
-
-		rtnl_lock();
-		bond_dev = bond_get_by_name(bn, ifname);
-		if (bond_dev) {
-			pr_info("%s is being deleted...\n", ifname);
-			unregister_netdevice(bond_dev);
-		} else {
-			pr_err("unable to delete non-existent %s\n", ifname);
-			res = -ENODEV;
-		}
-		rtnl_unlock();
-	} else
-		goto err_no_cmd;
-
-	/* Always return either count or an error.  If you return 0, you'll
-	 * get called forever, which is bad.
-	 */
-	return res;
-
-err_no_cmd:
-	pr_err("no command found in bonding_masters - use +ifname or -ifname\n");
-	return -EPERM;
-}
-
-/* class attribute for bond_masters file.  This ends up in /sys/class/net */
-static const struct class_attribute class_attr_bonding_masters = {
-	.attr = {
-		.name = "bonding_masters",
-		.mode = 0644,
-	},
-	.show = bonding_show_bonds,
-	.store = bonding_store_bonds,
-};
-
-/* Generic "store" method for bonding sysfs option setting */
-static ssize_t bonding_sysfs_store_option(struct device *d,
-					  struct device_attribute *attr,
-					  const char *buffer, size_t count)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_option *opt;
-	char *buffer_clone;
-	int ret;
-
-	opt = bond_opt_get_by_name(attr->attr.name);
-	if (WARN_ON(!opt))
-		return -ENOENT;
-	buffer_clone = kstrndup(buffer, count, GFP_KERNEL);
-	if (!buffer_clone)
-		return -ENOMEM;
-	ret = bond_opt_tryset_rtnl(bond, opt->id, buffer_clone);
-	if (!ret)
-		ret = count;
-	kfree(buffer_clone);
-
-	return ret;
-}
-
-/* Show the slaves in the current bond. */
-static ssize_t bonding_show_slaves(struct device *d,
-				   struct device_attribute *attr, char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct list_head *iter;
-	struct slave *slave;
-	int res = 0;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (res > (PAGE_SIZE - IFNAMSIZ)) {
-			/* not enough space for another interface name */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s ", slave->dev->name);
-	}
-
-	rtnl_unlock();
-
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	return res;
-}
-static DEVICE_ATTR(slaves, 0644, bonding_show_slaves,
-		   bonding_sysfs_store_option);
-
-/* Show the bonding mode. */
-static ssize_t bonding_show_mode(struct device *d,
-				 struct device_attribute *attr, char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_MODE, BOND_MODE(bond));
-
-	return sprintf(buf, "%s %d\n", val->string, BOND_MODE(bond));
-}
-static DEVICE_ATTR(mode, 0644, bonding_show_mode, bonding_sysfs_store_option);
-
-/* Show the bonding transmit hash method. */
-static ssize_t bonding_show_xmit_hash(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_XMIT_HASH, bond->params.xmit_policy);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.xmit_policy);
-}
-static DEVICE_ATTR(xmit_hash_policy, 0644,
-		   bonding_show_xmit_hash, bonding_sysfs_store_option);
-
-/* Show arp_validate. */
-static ssize_t bonding_show_arp_validate(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
-			       bond->params.arp_validate);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.arp_validate);
-}
-static DEVICE_ATTR(arp_validate, 0644, bonding_show_arp_validate,
-		   bonding_sysfs_store_option);
-
-/* Show arp_all_targets. */
-static ssize_t bonding_show_arp_all_targets(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_ARP_ALL_TARGETS,
-			       bond->params.arp_all_targets);
-	return sprintf(buf, "%s %d\n",
-		       val->string, bond->params.arp_all_targets);
-}
-static DEVICE_ATTR(arp_all_targets, 0644,
-		   bonding_show_arp_all_targets, bonding_sysfs_store_option);
-
-/* Show fail_over_mac. */
-static ssize_t bonding_show_fail_over_mac(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
-			       bond->params.fail_over_mac);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.fail_over_mac);
-}
-static DEVICE_ATTR(fail_over_mac, 0644,
-		   bonding_show_fail_over_mac, bonding_sysfs_store_option);
-
-/* Show the arp timer interval. */
-static ssize_t bonding_show_arp_interval(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.arp_interval);
-}
-static DEVICE_ATTR(arp_interval, 0644,
-		   bonding_show_arp_interval, bonding_sysfs_store_option);
-
-/* Show the arp targets. */
-static ssize_t bonding_show_arp_targets(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	int i, res = 0;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
-		if (bond->params.arp_targets[i])
-			res += sprintf(buf + res, "%pI4 ",
-				       &bond->params.arp_targets[i]);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	return res;
-}
-static DEVICE_ATTR(arp_ip_target, 0644,
-		   bonding_show_arp_targets, bonding_sysfs_store_option);
-
-/* Show the up and down delays. */
-static ssize_t bonding_show_downdelay(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.downdelay * bond->params.miimon);
-}
-static DEVICE_ATTR(downdelay, 0644,
-		   bonding_show_downdelay, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_updelay(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.updelay * bond->params.miimon);
-
-}
-static DEVICE_ATTR(updelay, 0644,
-		   bonding_show_updelay, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_peer_notif_delay(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n",
-		       bond->params.peer_notif_delay * bond->params.miimon);
-}
-static DEVICE_ATTR(peer_notif_delay, 0644,
-		   bonding_show_peer_notif_delay, bonding_sysfs_store_option);
-
-/* Show the LACP interval. */
-static ssize_t bonding_show_lacp(struct device *d,
-				 struct device_attribute *attr,
-				 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_LACP_RATE, bond->params.lacp_fast);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.lacp_fast);
-}
-static DEVICE_ATTR(lacp_rate, 0644,
-		   bonding_show_lacp, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_min_links(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%u\n", bond->params.min_links);
-}
-static DEVICE_ATTR(min_links, 0644,
-		   bonding_show_min_links, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_select(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_AD_SELECT, bond->params.ad_select);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.ad_select);
-}
-static DEVICE_ATTR(ad_select, 0644,
-		   bonding_show_ad_select, bonding_sysfs_store_option);
-
-/* Show the number of peer notifications to send after a failover event. */
-static ssize_t bonding_show_num_peer_notif(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	return sprintf(buf, "%d\n", bond->params.num_peer_notif);
-}
-static DEVICE_ATTR(num_grat_arp, 0644,
-		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
-static DEVICE_ATTR(num_unsol_na, 0644,
-		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
-
-/* Show the MII monitor interval. */
-static ssize_t bonding_show_miimon(struct device *d,
-				   struct device_attribute *attr,
-				   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.miimon);
-}
-static DEVICE_ATTR(miimon, 0644,
-		   bonding_show_miimon, bonding_sysfs_store_option);
-
-/* Show the primary slave. */
-static ssize_t bonding_show_primary(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct slave *primary;
-	int count = 0;
-
-	rcu_read_lock();
-	primary = rcu_dereference(bond->primary_slave);
-	if (primary)
-		count = sprintf(buf, "%s\n", primary->dev->name);
-	rcu_read_unlock();
-
-	return count;
-}
-static DEVICE_ATTR(primary, 0644,
-		   bonding_show_primary, bonding_sysfs_store_option);
-
-/* Show the primary_reselect flag. */
-static ssize_t bonding_show_primary_reselect(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
-			       bond->params.primary_reselect);
-
-	return sprintf(buf, "%s %d\n",
-		       val->string, bond->params.primary_reselect);
-}
-static DEVICE_ATTR(primary_reselect, 0644,
-		   bonding_show_primary_reselect, bonding_sysfs_store_option);
-
-/* Show the use_carrier flag. */
-static ssize_t bonding_show_carrier(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.use_carrier);
-}
-static DEVICE_ATTR(use_carrier, 0644,
-		   bonding_show_carrier, bonding_sysfs_store_option);
-
-
-/* Show currently active_slave. */
-static ssize_t bonding_show_active_slave(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct net_device *slave_dev;
-	int count = 0;
-
-	rcu_read_lock();
-	slave_dev = bond_option_active_slave_get_rcu(bond);
-	if (slave_dev)
-		count = sprintf(buf, "%s\n", slave_dev->name);
-	rcu_read_unlock();
-
-	return count;
-}
-static DEVICE_ATTR(active_slave, 0644,
-		   bonding_show_active_slave, bonding_sysfs_store_option);
-
-/* Show link status of the bond interface. */
-static ssize_t bonding_show_mii_status(struct device *d,
-				       struct device_attribute *attr,
-				       char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	bool active = netif_carrier_ok(bond->dev);
-
-	return sprintf(buf, "%s\n", active ? "up" : "down");
-}
-static DEVICE_ATTR(mii_status, 0444, bonding_show_mii_status, NULL);
-
-/* Show current 802.3ad aggregator ID. */
-static ssize_t bonding_show_ad_aggregator(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.aggregator_id);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_aggregator, 0444, bonding_show_ad_aggregator, NULL);
-
-
-/* Show number of active 802.3ad ports. */
-static ssize_t bonding_show_ad_num_ports(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.ports);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_num_ports, 0444, bonding_show_ad_num_ports, NULL);
-
-
-/* Show current 802.3ad actor key. */
-static ssize_t bonding_show_ad_actor_key(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.actor_key);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_actor_key, 0444, bonding_show_ad_actor_key, NULL);
-
-
-/* Show current 802.3ad partner key. */
-static ssize_t bonding_show_ad_partner_key(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.partner_key);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_partner_key, 0444, bonding_show_ad_partner_key, NULL);
-
-
-/* Show current 802.3ad partner mac. */
-static ssize_t bonding_show_ad_partner_mac(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		if (!bond_3ad_get_active_agg_info(bond, &ad_info))
-			count = sprintf(buf, "%pM\n", ad_info.partner_system);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_partner_mac, 0444, bonding_show_ad_partner_mac, NULL);
-
-/* Show the queue_ids of the slaves in the current bond. */
-static ssize_t bonding_show_queue_id(struct device *d,
-				     struct device_attribute *attr,
-				     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct list_head *iter;
-	struct slave *slave;
-	int res = 0;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (res > (PAGE_SIZE - IFNAMSIZ - 6)) {
-			/* not enough space for another interface_name:queue_id pair */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s:%d ",
-			       slave->dev->name, slave->queue_id);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	rtnl_unlock();
-
-	return res;
-}
-static DEVICE_ATTR(queue_id, 0644, bonding_show_queue_id,
-		   bonding_sysfs_store_option);
-
-
-/* Show the all_slaves_active flag. */
-static ssize_t bonding_show_slaves_active(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.all_slaves_active);
-}
-static DEVICE_ATTR(all_slaves_active, 0644,
-		   bonding_show_slaves_active, bonding_sysfs_store_option);
-
-/* Show the number of IGMP membership reports to send on link failure */
-static ssize_t bonding_show_resend_igmp(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.resend_igmp);
-}
-static DEVICE_ATTR(resend_igmp, 0644,
-		   bonding_show_resend_igmp, bonding_sysfs_store_option);
-
-
-static ssize_t bonding_show_lp_interval(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.lp_interval);
-}
-static DEVICE_ATTR(lp_interval, 0644,
-		   bonding_show_lp_interval, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_tlb_dynamic_lb(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	return sprintf(buf, "%d\n", bond->params.tlb_dynamic_lb);
-}
-static DEVICE_ATTR(tlb_dynamic_lb, 0644,
-		   bonding_show_tlb_dynamic_lb, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_packets_per_slave(struct device *d,
-					      struct device_attribute *attr,
-					      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	unsigned int packets_per_slave = bond->params.packets_per_slave;
-
-	return sprintf(buf, "%u\n", packets_per_slave);
-}
-static DEVICE_ATTR(packets_per_slave, 0644,
-		   bonding_show_packets_per_slave, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_actor_sys_prio(struct device *d,
-					      struct device_attribute *attr,
-					      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%hu\n", bond->params.ad_actor_sys_prio);
-
-	return 0;
-}
-static DEVICE_ATTR(ad_actor_sys_prio, 0644,
-		   bonding_show_ad_actor_sys_prio, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_actor_system(struct device *d,
-					    struct device_attribute *attr,
-					    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%pM\n", bond->params.ad_actor_system);
-
-	return 0;
-}
-
-static DEVICE_ATTR(ad_actor_system, 0644,
-		   bonding_show_ad_actor_system, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_user_port_key(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%hu\n", bond->params.ad_user_port_key);
-
-	return 0;
-}
-static DEVICE_ATTR(ad_user_port_key, 0644,
-		   bonding_show_ad_user_port_key, bonding_sysfs_store_option);
-
-static struct attribute *per_bond_attrs[] = {
-	&dev_attr_slaves.attr,
-	&dev_attr_mode.attr,
-	&dev_attr_fail_over_mac.attr,
-	&dev_attr_arp_validate.attr,
-	&dev_attr_arp_all_targets.attr,
-	&dev_attr_arp_interval.attr,
-	&dev_attr_arp_ip_target.attr,
-	&dev_attr_downdelay.attr,
-	&dev_attr_updelay.attr,
-	&dev_attr_peer_notif_delay.attr,
-	&dev_attr_lacp_rate.attr,
-	&dev_attr_ad_select.attr,
-	&dev_attr_xmit_hash_policy.attr,
-	&dev_attr_num_grat_arp.attr,
-	&dev_attr_num_unsol_na.attr,
-	&dev_attr_miimon.attr,
-	&dev_attr_primary.attr,
-	&dev_attr_primary_reselect.attr,
-	&dev_attr_use_carrier.attr,
-	&dev_attr_active_slave.attr,
-	&dev_attr_mii_status.attr,
-	&dev_attr_ad_aggregator.attr,
-	&dev_attr_ad_num_ports.attr,
-	&dev_attr_ad_actor_key.attr,
-	&dev_attr_ad_partner_key.attr,
-	&dev_attr_ad_partner_mac.attr,
-	&dev_attr_queue_id.attr,
-	&dev_attr_all_slaves_active.attr,
-	&dev_attr_resend_igmp.attr,
-	&dev_attr_min_links.attr,
-	&dev_attr_lp_interval.attr,
-	&dev_attr_packets_per_slave.attr,
-	&dev_attr_tlb_dynamic_lb.attr,
-	&dev_attr_ad_actor_sys_prio.attr,
-	&dev_attr_ad_actor_system.attr,
-	&dev_attr_ad_user_port_key.attr,
-	NULL,
-};
-
-static const struct attribute_group bonding_group = {
-	.name = "bonding",
-	.attrs = per_bond_attrs,
-};
-
-/* Initialize sysfs.  This sets up the bonding_masters file in
- * /sys/class/net.
- */
-int bond_create_sysfs(struct bond_net *bn)
-{
-	int ret;
-
-	bn->class_attr_bonding_masters = class_attr_bonding_masters;
-	sysfs_attr_init(&bn->class_attr_bonding_masters.attr);
-
-	ret = netdev_class_create_file_ns(&bn->class_attr_bonding_masters,
-					  bn->net);
-	/* Permit multiple loads of the module by ignoring failures to
-	 * create the bonding_masters sysfs file.  Bonding devices
-	 * created by second or subsequent loads of the module will
-	 * not be listed in, or controllable by, bonding_masters, but
-	 * will have the usual "bonding" sysfs directory.
-	 *
-	 * This is done to preserve backwards compatibility for
-	 * initscripts/sysconfig, which load bonding multiple times to
-	 * configure multiple bonding devices.
-	 */
-	if (ret == -EEXIST) {
-		/* Is someone being kinky and naming a device bonding_master? */
-		if (__dev_get_by_name(bn->net,
-				      class_attr_bonding_masters.attr.name))
-			pr_err("network device named %s already exists in sysfs\n",
-			       class_attr_bonding_masters.attr.name);
-		ret = 0;
-	}
-
-	return ret;
-
-}
-
-/* Remove /sys/class/net/bonding_masters. */
-void bond_destroy_sysfs(struct bond_net *bn)
-{
-	netdev_class_remove_file_ns(&bn->class_attr_bonding_masters, bn->net);
-}
-
-/* Initialize sysfs for each bond.  This sets up and registers
- * the 'bondctl' directory for each individual bond under /sys/class/net.
- */
-void bond_prepare_sysfs_group(struct bonding *bond)
-{
-	bond->dev->sysfs_groups[0] = &bonding_group;
-}
-
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.19/bond_sysfs_slave.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.19/bond_sysfs_slave.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,174 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*	Sysfs attributes of bond slaves
- *
- *      Copyright (c) 2014 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/capability.h>
-#include <linux/kernel.h>
-#include <linux/netdevice.h>
-
-#include <net/bonding.h>
-
-struct slave_attribute {
-	struct attribute attr;
-	ssize_t (*show)(struct slave *, char *);
-};
-
-#define SLAVE_ATTR(_name, _mode, _show)				\
-const struct slave_attribute slave_attr_##_name = {		\
-	.attr = {.name = __stringify(_name),			\
-		 .mode = _mode },				\
-	.show	= _show,					\
-};
-#define SLAVE_ATTR_RO(_name)					\
-	SLAVE_ATTR(_name, 0444, _name##_show)
-
-static ssize_t state_show(struct slave *slave, char *buf)
-{
-	switch (bond_slave_state(slave)) {
-	case BOND_STATE_ACTIVE:
-		return sprintf(buf, "active\n");
-	case BOND_STATE_BACKUP:
-		return sprintf(buf, "backup\n");
-	default:
-		return sprintf(buf, "UNKNOWN\n");
-	}
-}
-static SLAVE_ATTR_RO(state);
-
-static ssize_t mii_status_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%s\n", bond_slave_link_status(slave->link));
-}
-static SLAVE_ATTR_RO(mii_status);
-
-static ssize_t link_failure_count_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%d\n", slave->link_failure_count);
-}
-static SLAVE_ATTR_RO(link_failure_count);
-
-static ssize_t perm_hwaddr_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%*phC\n",
-		       slave->dev->addr_len,
-		       slave->perm_hwaddr);
-}
-static SLAVE_ATTR_RO(perm_hwaddr);
-
-static ssize_t queue_id_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%d\n", slave->queue_id);
-}
-static SLAVE_ATTR_RO(queue_id);
-
-static ssize_t ad_aggregator_id_show(struct slave *slave, char *buf)
-{
-	const struct aggregator *agg;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		agg = SLAVE_AD_INFO(slave)->port.aggregator;
-		if (agg)
-			return sprintf(buf, "%d\n",
-				       agg->aggregator_identifier);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_aggregator_id);
-
-static ssize_t ad_actor_oper_port_state_show(struct slave *slave, char *buf)
-{
-	const struct port *ad_port;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		if (ad_port->aggregator)
-			return sprintf(buf, "%u\n",
-				       ad_port->actor_oper_port_state);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_actor_oper_port_state);
-
-static ssize_t ad_partner_oper_port_state_show(struct slave *slave, char *buf)
-{
-	const struct port *ad_port;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		if (ad_port->aggregator)
-			return sprintf(buf, "%u\n",
-				       ad_port->partner_oper.port_state);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_partner_oper_port_state);
-
-static const struct slave_attribute *slave_attrs[] = {
-	&slave_attr_state,
-	&slave_attr_mii_status,
-	&slave_attr_link_failure_count,
-	&slave_attr_perm_hwaddr,
-	&slave_attr_queue_id,
-	&slave_attr_ad_aggregator_id,
-	&slave_attr_ad_actor_oper_port_state,
-	&slave_attr_ad_partner_oper_port_state,
-	NULL
-};
-
-#define to_slave_attr(_at) container_of(_at, struct slave_attribute, attr)
-#define to_slave(obj)	container_of(obj, struct slave, kobj)
-
-static ssize_t slave_show(struct kobject *kobj,
-			  struct attribute *attr, char *buf)
-{
-	struct slave_attribute *slave_attr = to_slave_attr(attr);
-	struct slave *slave = to_slave(kobj);
-
-	return slave_attr->show(slave, buf);
-}
-
-static const struct sysfs_ops slave_sysfs_ops = {
-	.show = slave_show,
-};
-
-static struct kobj_type slave_ktype = {
-#ifdef CONFIG_SYSFS
-	.sysfs_ops = &slave_sysfs_ops,
-#endif
-};
-
-int bond_sysfs_slave_add(struct slave *slave)
-{
-	const struct slave_attribute **a;
-	int err;
-
-	err = kobject_init_and_add(&slave->kobj, &slave_ktype,
-				   &(slave->dev->dev.kobj), "bonding_slave");
-	if (err)
-		return err;
-
-	for (a = slave_attrs; *a; ++a) {
-		err = sysfs_create_file(&slave->kobj, &((*a)->attr));
-		if (err) {
-			kobject_put(&slave->kobj);
-			return err;
-		}
-	}
-
-	return 0;
-}
-
-void bond_sysfs_slave_del(struct slave *slave)
-{
-	const struct slave_attribute **a;
-
-	for (a = slave_attrs; *a; ++a)
-		sysfs_remove_file(&slave->kobj, &((*a)->attr));
-
-	kobject_put(&slave->kobj);
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.19/bonding.mod.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.19/bonding.mod.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,212 +0,0 @@
-#include <linux/build-salt.h>
-#include <linux/module.h>
-#include <linux/vermagic.h>
-#include <linux/compiler.h>
-
-BUILD_SALT;
-
-MODULE_INFO(vermagic, VERMAGIC_STRING);
-MODULE_INFO(name, KBUILD_MODNAME);
-
-__visible struct module __this_module
-__section(.gnu.linkonce.this_module) = {
-	.name = KBUILD_MODNAME,
-	.init = init_module,
-#ifdef CONFIG_MODULE_UNLOAD
-	.exit = cleanup_module,
-#endif
-	.arch = MODULE_ARCH_INIT,
-};
-
-MODULE_INFO(intree, "Y");
-
-#ifdef CONFIG_RETPOLINE
-MODULE_INFO(retpoline, "Y");
-#endif
-
-static const struct modversion_info ____versions[]
-__used __section(__versions) = {
-	{ 0x8ea849e, "module_layout" },
-	{ 0xe9186521, "register_netdevice" },
-	{ 0x8739f334, "dev_mc_sync_multiple" },
-	{ 0x93c20051, "kobject_put" },
-	{ 0xe95e308e, "netdev_info" },
-	{ 0xab652df1, "kmalloc_caches" },
-	{ 0xeb233a45, "__kmalloc" },
-	{ 0x867ef945, "dev_mc_unsync" },
-	{ 0x349cba85, "strchr" },
-	{ 0xca905177, "proc_create_seq_private" },
-	{ 0xe3deb977, "param_ops_int" },
-	{ 0x754d539c, "strlen" },
-	{ 0xf078fd67, "dev_disable_lro" },
-	{ 0x19f462ab, "kfree_call_rcu" },
-	{ 0xa207869b, "vlan_dev_vlan_id" },
-	{ 0x7dba91eb, "__skb_flow_dissect" },
-	{ 0x79aa04a2, "get_random_bytes" },
-	{ 0x1fbcca2a, "seq_puts" },
-	{ 0x676f41c, "netdev_rx_handler_register" },
-	{ 0xc7a4fbed, "rtnl_lock" },
-	{ 0x4cba4ca4, "vlan_uses_dev" },
-	{ 0xfa690589, "netdev_cmd_to_name" },
-	{ 0x25f0412e, "netif_carrier_on" },
-	{ 0xef50cae4, "dst_release" },
-	{ 0xb3635b01, "_raw_spin_lock_bh" },
-	{ 0xa2272dc8, "skb_clone" },
-	{ 0xffeedf6a, "delayed_work_timer_fn" },
-	{ 0xbc3bdc7f, "flow_get_u32_src" },
-	{ 0xcc5ee855, "seq_printf" },
-	{ 0xd2da1048, "register_netdevice_notifier" },
-	{ 0xd50e8a85, "netif_carrier_off" },
-	{ 0x56470118, "__warn_printk" },
-	{ 0x2df5580c, "netdev_master_upper_dev_get" },
-	{ 0xd4dcfc9f, "remove_proc_entry" },
-	{ 0x837b7b09, "__dynamic_pr_debug" },
-	{ 0xf36a3159, "dev_set_allmulti" },
-	{ 0x6ac8e490, "vlan_vid_del" },
-	{ 0x974b80f1, "netpoll_poll_dev" },
-	{ 0x427b95e2, "call_netdevice_notifiers" },
-	{ 0xb659397a, "__dev_kfree_skb_any" },
-	{ 0xc6f46339, "init_timer_key" },
-	{ 0x9fa7184a, "cancel_delayed_work_sync" },
-	{ 0xbcb0eb0b, "vlan_vid_add" },
-	{ 0xe7941a72, "__netpoll_setup" },
-	{ 0x70eff63e, "vlan_vids_del_by_dev" },
-	{ 0x3c3ff9fd, "sprintf" },
-	{ 0xc10f0ffb, "pv_ops" },
-	{ 0xaeca8b04, "netdev_walk_all_upper_dev_rcu" },
-	{ 0x15ba50a6, "jiffies" },
-	{ 0x5f43e360, "__dynamic_netdev_dbg" },
-	{ 0x9d0d6206, "unregister_netdevice_notifier" },
-	{ 0xfddcf1d, "skb_trim" },
-	{ 0xe2d5255a, "strcmp" },
-	{ 0xb5c70ad6, "vlan_vids_add_by_dev" },
-	{ 0x7aba6573, "netdev_master_upper_dev_link" },
-	{ 0x2c581fd4, "dev_mc_add" },
-	{ 0x4f14051e, "__netdev_alloc_skb" },
-	{ 0xb7885dcc, "netdev_lower_get_next_private_rcu" },
-	{ 0xd318e213, "netdev_lower_state_changed" },
-	{ 0xdf84e749, "__pskb_pull_tail" },
-	{ 0x84837dfe, "netdev_change_features" },
-	{ 0xcd5c6c21, "netpoll_send_skb_on_dev" },
-	{ 0x6b10bee1, "_copy_to_user" },
-	{ 0x367a4d53, "PDE_DATA" },
-	{ 0x4136a96f, "netdev_has_upper_dev" },
-	{ 0xf1db1704, "nla_memcpy" },
-	{ 0xa16fc7b3, "param_ops_charp" },
-	{ 0x5f155dd7, "dev_set_mac_address" },
-	{ 0xeba59bcd, "unregister_pernet_subsys" },
-	{ 0xe877be74, "proc_mkdir" },
-	{ 0x9fdecc31, "unregister_netdevice_many" },
-	{ 0x11089ac7, "_ctype" },
-	{ 0xc025016c, "flow_keys_dissector" },
-	{ 0x38643aa3, "current_task" },
-	{ 0x4c29440, "__ethtool_get_link_ksettings" },
-	{ 0xac9b67d7, "arp_create" },
-	{ 0xc5850110, "printk" },
-	{ 0x27562caa, "ethtool_op_get_link" },
-	{ 0xbcab6ee6, "sscanf" },
-	{ 0xe1537255, "__list_del_entry_valid" },
-	{ 0xa965ca81, "reciprocal_value" },
-	{ 0xe0e3cea6, "ns_capable" },
-	{ 0x9cf230cf, "kobject_init_and_add" },
-	{ 0x62849ac7, "dev_valid_name" },
-	{ 0x54a25aaf, "netdev_class_remove_file_ns" },
-	{ 0x6606939d, "free_netdev" },
-	{ 0xe7b00dfb, "__x86_indirect_thunk_r13" },
-	{ 0x9166fada, "strncpy" },
-	{ 0x7b855f37, "dev_mc_del" },
-	{ 0xe429d9a0, "nla_put" },
-	{ 0xf3847883, "netdev_upper_dev_unlink" },
-	{ 0x5a921311, "strncmp" },
-	{ 0x5792f848, "strlcpy" },
-	{ 0xab1248be, "skb_push" },
-	{ 0x652032cb, "mac_pton" },
-	{ 0x8c03d20c, "destroy_workqueue" },
-	{ 0x37f36ab6, "dev_close" },
-	{ 0xf4f14de6, "rtnl_trylock" },
-	{ 0x122994b7, "netdev_bonding_info_change" },
-	{ 0xeb31264c, "dev_mc_flush" },
-	{ 0xfda9581f, "prandom_u32" },
-	{ 0x6091797f, "synchronize_rcu" },
-	{ 0x396ffb6d, "inet_confirm_addr" },
-	{ 0x90cfa369, "init_net" },
-	{ 0x262b5ec7, "rtnl_link_unregister" },
-	{ 0x9a49c55, "__dev_get_by_index" },
-	{ 0x68f31cbd, "__list_add_valid" },
-	{ 0xfa731956, "netdev_lower_dev_get_private" },
-	{ 0x9eacf8a5, "kstrndup" },
-	{ 0x371b5e60, "dev_open" },
-	{ 0xae414502, "dev_uc_flush" },
-	{ 0xc6cbbc89, "capable" },
-	{ 0xb601be4c, "__x86_indirect_thunk_rdx" },
-	{ 0x1d05158e, "netdev_upper_get_next_dev_rcu" },
-	{ 0x2e89682e, "sysfs_remove_file_ns" },
-	{ 0x49c41a57, "_raw_spin_unlock_bh" },
-	{ 0xb2fcb56d, "queue_delayed_work_on" },
-	{ 0xdecd0b29, "__stack_chk_fail" },
-	{ 0x869db7f, "vlan_dev_vlan_proto" },
-	{ 0x49d026fd, "netdev_rx_handler_unregister" },
-	{ 0x1d24c881, "___ratelimit" },
-	{ 0xb8b9f817, "kmalloc_order_trace" },
-	{ 0x5a460992, "kfree_skb" },
-	{ 0xac5fcec0, "in4_pton" },
-	{ 0x9eb26fb5, "passthru_features_check" },
-	{ 0xdff5a870, "alloc_netdev_mqs" },
-	{ 0x2ea2c95c, "__x86_indirect_thunk_rax" },
-	{ 0xc38d2e99, "arp_xmit" },
-	{ 0x46571785, "netdev_lower_get_next_private" },
-	{ 0xa751f358, "register_pernet_subsys" },
-	{ 0x94f5f1a, "pskb_expand_head" },
-	{ 0xbdfb6dbb, "__fentry__" },
-	{ 0x1426720b, "netdev_err" },
-	{ 0x7bcee6c0, "ether_setup" },
-	{ 0x23d1c7a1, "dev_uc_unsync" },
-	{ 0xd7a02f91, "__dev_get_by_name" },
-	{ 0x9fad3bb0, "kmem_cache_alloc_trace" },
-	{ 0xdbf17652, "_raw_spin_lock" },
-	{ 0x8e024d8f, "unregister_netdevice_queue" },
-	{ 0x16104dc3, "ip_route_output_flow" },
-	{ 0xf6ebc03b, "net_ratelimit" },
-	{ 0x688a7c42, "netdev_warn" },
-	{ 0x4fb92907, "__skb_flow_get_ports" },
-	{ 0x406eadda, "dev_set_promiscuity" },
-	{ 0x8516c14a, "flow_get_u32_dst" },
-	{ 0x37a0cba, "kfree" },
-	{ 0xc664f69d, "dev_uc_sync_multiple" },
-	{ 0x69acdf38, "memcpy" },
-	{ 0xdc9cb4e2, "param_array_ops" },
-	{ 0xca1b8576, "dev_trans_start" },
-	{ 0xc91d6876, "__dev_set_mtu" },
-	{ 0x799debac, "rtnl_link_register" },
-	{ 0xdfbaba18, "dev_uc_sync" },
-	{ 0x8d7079b3, "netdev_lower_get_first_private_rcu" },
-	{ 0xa0dad88e, "netdev_adjacent_get_private" },
-	{ 0x901d0e5, "nla_put_64bit" },
-	{ 0x74f424ff, "__netpoll_free" },
-	{ 0x656e4a6e, "snprintf" },
-	{ 0xb0e602eb, "memmove" },
-	{ 0x7eb890a3, "consume_skb" },
-	{ 0x85670f1d, "rtnl_is_locked" },
-	{ 0x7f02188f, "__msecs_to_jiffies" },
-	{ 0xf416b840, "sysfs_create_file_ns" },
-	{ 0xe56ac49e, "dev_queue_xmit" },
-	{ 0x9a9985f1, "netdev_is_rx_handler_busy" },
-	{ 0x6dfebd71, "skb_put" },
-	{ 0x13c49cc2, "_copy_from_user" },
-	{ 0xd04f09af, "param_ops_uint" },
-	{ 0x78131b29, "skb_copy_bits" },
-	{ 0x5e80f63f, "dev_mc_sync" },
-	{ 0xdf9208c0, "alloc_workqueue" },
-	{ 0x7ea0e08b, "dev_pre_changeaddr_notify" },
-	{ 0x6e720ff2, "rtnl_unlock" },
-	{ 0x69668826, "netdev_increment_features" },
-	{ 0x210763d6, "dev_get_stats" },
-	{ 0x7af5935f, "netdev_class_create_file_ns" },
-	{ 0xc0013de6, "dev_set_mtu" },
-	{ 0xe914e41e, "strcpy" },
-};
-
-MODULE_INFO(depends, "");
-
-
-MODULE_INFO(srcversion, "D3884F53B7ABFFC65462996");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.19/bonding_priv.h
--- a/src/network/bonding/BONDING_KDIRS/5.4.19/bonding_priv.h	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,25 +0,0 @@
-/*
- * Bond several ethernet interfaces into a Cisco, running 'Etherchannel'.
- *
- * Portions are (c) Copyright 1995 Simon "Guru Aleph-Null" Janes
- * NCM: Network and Communications Management, Inc.
- *
- * BUT, I'm the one who modified it for ethernet, so:
- * (c) Copyright 1999, Thomas Davis, tadavis@lbl.gov
- *
- *	This software may be used and distributed according to the terms
- *	of the GNU Public License, incorporated herein by reference.
- *
- */
-
-#ifndef _BONDING_PRIV_H
-#define _BONDING_PRIV_H
-
-#define DRV_VERSION	"3.7.1-chelsio"
-#define DRV_RELDATE	"April 27, 2011"
-#define DRV_NAME	"bonding"
-#define DRV_DESCRIPTION	"Ethernet Channel Bonding Driver with Offload"
-
-#define bond_version DRV_DESCRIPTION ": v" DRV_VERSION " (" DRV_RELDATE ")\n"
-
-#endif
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.82/bond_3ad.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.82/bond_3ad.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,2767 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
- */
-
-#include <linux/skbuff.h>
-#include <linux/if_ether.h>
-#include <linux/netdevice.h>
-#include <linux/spinlock.h>
-#include <linux/ethtool.h>
-#include <linux/etherdevice.h>
-#include <linux/if_bonding.h>
-#include <linux/pkt_sched.h>
-#include <linux/toedev.h>
-#include <net/net_namespace.h>
-#include <net/bonding.h>
-#include <net/bond_3ad.h>
-#include <net/netlink.h>
-
-/* General definitions */
-#define AD_SHORT_TIMEOUT           1
-#define AD_LONG_TIMEOUT            0
-#define AD_STANDBY                 0x2
-#define AD_MAX_TX_IN_SECOND        3
-#define AD_COLLECTOR_MAX_DELAY     0
-
-/* Timer definitions (43.4.4 in the 802.3ad standard) */
-#define AD_FAST_PERIODIC_TIME      1
-#define AD_SLOW_PERIODIC_TIME      30
-#define AD_SHORT_TIMEOUT_TIME      (3*AD_FAST_PERIODIC_TIME)
-#define AD_LONG_TIMEOUT_TIME       (3*AD_SLOW_PERIODIC_TIME)
-#define AD_CHURN_DETECTION_TIME    60
-#define AD_AGGREGATE_WAIT_TIME     2
-
-/* Port state definitions (43.4.2.2 in the 802.3ad standard) */
-#define AD_STATE_LACP_ACTIVITY   0x1
-#define AD_STATE_LACP_TIMEOUT    0x2
-#define AD_STATE_AGGREGATION     0x4
-#define AD_STATE_SYNCHRONIZATION 0x8
-#define AD_STATE_COLLECTING      0x10
-#define AD_STATE_DISTRIBUTING    0x20
-#define AD_STATE_DEFAULTED       0x40
-#define AD_STATE_EXPIRED         0x80
-
-/* Port Variables definitions used by the State Machines (43.4.7 in the
- * 802.3ad standard)
- */
-#define AD_PORT_BEGIN           0x1
-#define AD_PORT_LACP_ENABLED    0x2
-#define AD_PORT_ACTOR_CHURN     0x4
-#define AD_PORT_PARTNER_CHURN   0x8
-#define AD_PORT_READY           0x10
-#define AD_PORT_READY_N         0x20
-#define AD_PORT_MATCHED         0x40
-#define AD_PORT_STANDBY         0x80
-#define AD_PORT_SELECTED        0x100
-#define AD_PORT_MOVED           0x200
-#define AD_PORT_CHURNED         (AD_PORT_ACTOR_CHURN | AD_PORT_PARTNER_CHURN)
-
-/* Port Key definitions
- * key is determined according to the link speed, duplex and
- * user key (which is yet not supported)
- *           --------------------------------------------------------------
- * Port key  | User key (10 bits)           | Speed (5 bits)      | Duplex|
- *           --------------------------------------------------------------
- *           |15                           6|5                   1|0
- */
-#define  AD_DUPLEX_KEY_MASKS    0x1
-#define  AD_SPEED_KEY_MASKS     0x3E
-#define  AD_USER_KEY_MASKS      0xFFC0
-
-enum ad_link_speed_type {
-	AD_LINK_SPEED_1MBPS = 1,
-	AD_LINK_SPEED_10MBPS,
-	AD_LINK_SPEED_100MBPS,
-	AD_LINK_SPEED_1000MBPS,
-	AD_LINK_SPEED_2500MBPS,
-	AD_LINK_SPEED_5000MBPS,
-	AD_LINK_SPEED_10000MBPS,
-	AD_LINK_SPEED_14000MBPS,
-	AD_LINK_SPEED_20000MBPS,
-	AD_LINK_SPEED_25000MBPS,
-	AD_LINK_SPEED_40000MBPS,
-	AD_LINK_SPEED_50000MBPS,
-	AD_LINK_SPEED_56000MBPS,
-	AD_LINK_SPEED_100000MBPS,
-};
-
-/* compare MAC addresses */
-#define MAC_ADDRESS_EQUAL(A, B)	\
-	ether_addr_equal_64bits((const u8 *)A, (const u8 *)B)
-
-static const u8 null_mac_addr[ETH_ALEN + 2] __long_aligned = {
-	0, 0, 0, 0, 0, 0
-};
-static u16 ad_ticks_per_sec;
-static const int ad_delta_in_ticks = (AD_TIMER_INTERVAL * HZ) / 1000;
-
-static const u8 lacpdu_mcast_addr[ETH_ALEN + 2] __long_aligned =
-	MULTICAST_LACPDU_ADDR;
-
-/* ================= main 802.3ad protocol functions ================== */
-static int ad_lacpdu_send(struct port *port);
-static int ad_marker_send(struct port *port, struct bond_marker *marker);
-static void ad_mux_machine(struct port *port, bool *update_slave_arr);
-static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port);
-static void ad_tx_machine(struct port *port);
-static void ad_periodic_machine(struct port *port);
-static void ad_port_selection_logic(struct port *port, bool *update_slave_arr);
-static void ad_agg_selection_logic(struct aggregator *aggregator,
-				   bool *update_slave_arr);
-static void ad_clear_agg(struct aggregator *aggregator);
-static void ad_initialize_agg(struct aggregator *aggregator);
-static void ad_initialize_port(struct port *port, int lacp_fast);
-static void ad_enable_collecting_distributing(struct port *port,
-					      bool *update_slave_arr);
-static void ad_disable_collecting_distributing(struct port *port,
-					       bool *update_slave_arr);
-static void ad_marker_info_received(struct bond_marker *marker_info,
-				    struct port *port);
-static void ad_marker_response_received(struct bond_marker *marker,
-					struct port *port);
-static void ad_update_actor_keys(struct port *port, bool reset);
-
-
-/* ================= api to bonding and kernel code ================== */
-
-/**
- * __get_bond_by_port - get the port's bonding struct
- * @port: the port we're looking at
- *
- * Return @port's bonding struct, or %NULL if it can't be found.
- */
-static inline struct bonding *__get_bond_by_port(struct port *port)
-{
-	if (port->slave == NULL)
-		return NULL;
-
-	return bond_get_bond_by_slave(port->slave);
-}
-
-/**
- * __get_first_agg - get the first aggregator in the bond
- * @bond: the bond we're looking at
- *
- * Return the aggregator of the first slave in @bond, or %NULL if it can't be
- * found.
- * The caller must hold RCU or RTNL lock.
- */
-static inline struct aggregator *__get_first_agg(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-	struct slave *first_slave;
-	struct aggregator *agg;
-
-	/* If there's no bond for this port, or bond has no slaves */
-	if (bond == NULL)
-		return NULL;
-
-	rcu_read_lock();
-	first_slave = bond_first_slave_rcu(bond);
-	agg = first_slave ? &(SLAVE_AD_INFO(first_slave)->aggregator) : NULL;
-	rcu_read_unlock();
-
-	return agg;
-}
-
-/**
- * __agg_has_partner - see if we have a partner
- * @agg: the agregator we're looking at
- *
- * Return nonzero if aggregator has a partner (denoted by a non-zero ether
- * address for the partner). Return 0 if not.
- */
-static inline int __agg_has_partner(struct aggregator *agg)
-{
-	return !is_zero_ether_addr(agg->partner_system.mac_addr_value);
-}
-
-/**
- * __disable_port - disable the port's slave
- * @port: the port we're looking at
- */
-static inline void __disable_port(struct port *port)
-{
-	bond_set_slave_inactive_flags(port->slave, BOND_SLAVE_NOTIFY_LATER);
-}
-
-/**
- * __enable_port - enable the port's slave, if it's up
- * @port: the port we're looking at
- */
-static inline void __enable_port(struct port *port)
-{
-	struct slave *slave = port->slave;
-
-	if ((slave->link == BOND_LINK_UP) && bond_slave_is_up(slave)) {
-		bond_set_slave_active_flags(slave, BOND_SLAVE_NOTIFY_LATER);
-		toe_failover(netdev_master_upper_dev_get_rcu(port->slave->dev),
-			     port->slave->dev, TOE_LINK_UP, NULL);
-	}
-}
-
-/**
- * __port_is_enabled - check if the port's slave is in active state
- * @port: the port we're looking at
- */
-static inline int __port_is_enabled(struct port *port)
-{
-	return bond_is_active_slave(port->slave);
-}
-
-/**
- * __get_agg_selection_mode - get the aggregator selection mode
- * @port: the port we're looking at
- *
- * Get the aggregator selection mode. Can be %STABLE, %BANDWIDTH or %COUNT.
- */
-static inline u32 __get_agg_selection_mode(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-
-	if (bond == NULL)
-		return BOND_AD_STABLE;
-
-	return bond->params.ad_select;
-}
-
-/**
- * __check_agg_selection_timer - check if the selection timer has expired
- * @port: the port we're looking at
- */
-static inline int __check_agg_selection_timer(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-
-	if (bond == NULL)
-		return 0;
-
-	return BOND_AD_INFO(bond).agg_select_timer ? 1 : 0;
-}
-
-/**
- * __get_link_speed - get a port's speed
- * @port: the port we're looking at
- *
- * Return @port's speed in 802.3ad enum format. i.e. one of:
- *     0,
- *     %AD_LINK_SPEED_10MBPS,
- *     %AD_LINK_SPEED_100MBPS,
- *     %AD_LINK_SPEED_1000MBPS,
- *     %AD_LINK_SPEED_2500MBPS,
- *     %AD_LINK_SPEED_5000MBPS,
- *     %AD_LINK_SPEED_10000MBPS
- *     %AD_LINK_SPEED_14000MBPS,
- *     %AD_LINK_SPEED_20000MBPS
- *     %AD_LINK_SPEED_25000MBPS
- *     %AD_LINK_SPEED_40000MBPS
- *     %AD_LINK_SPEED_50000MBPS
- *     %AD_LINK_SPEED_56000MBPS
- *     %AD_LINK_SPEED_100000MBPS
- */
-static u16 __get_link_speed(struct port *port)
-{
-	struct slave *slave = port->slave;
-	u16 speed;
-
-	/* this if covers only a special case: when the configuration starts
-	 * with link down, it sets the speed to 0.
-	 * This is done in spite of the fact that the e100 driver reports 0
-	 * to be compatible with MVT in the future.
-	 */
-	if (slave->link != BOND_LINK_UP)
-		speed = 0;
-	else {
-		switch (slave->speed) {
-		case SPEED_10:
-			speed = AD_LINK_SPEED_10MBPS;
-			break;
-
-		case SPEED_100:
-			speed = AD_LINK_SPEED_100MBPS;
-			break;
-
-		case SPEED_1000:
-			speed = AD_LINK_SPEED_1000MBPS;
-			break;
-
-		case SPEED_2500:
-			speed = AD_LINK_SPEED_2500MBPS;
-			break;
-
-		case SPEED_5000:
-			speed = AD_LINK_SPEED_5000MBPS;
-			break;
-
-		case SPEED_10000:
-			speed = AD_LINK_SPEED_10000MBPS;
-			break;
-
-		case SPEED_14000:
-			speed = AD_LINK_SPEED_14000MBPS;
-			break;
-
-		case SPEED_20000:
-			speed = AD_LINK_SPEED_20000MBPS;
-			break;
-
-		case SPEED_25000:
-			speed = AD_LINK_SPEED_25000MBPS;
-			break;
-
-		case SPEED_40000:
-			speed = AD_LINK_SPEED_40000MBPS;
-			break;
-
-		case SPEED_50000:
-			speed = AD_LINK_SPEED_50000MBPS;
-			break;
-
-		case SPEED_56000:
-			speed = AD_LINK_SPEED_56000MBPS;
-			break;
-
-		case SPEED_100000:
-			speed = AD_LINK_SPEED_100000MBPS;
-			break;
-
-		default:
-			/* unknown speed value from ethtool. shouldn't happen */
-			if (slave->speed != SPEED_UNKNOWN)
-				pr_warn_once("%s: (slave %s): unknown ethtool speed (%d) for port %d (set it to 0)\n",
-					     slave->bond->dev->name,
-					     slave->dev->name, slave->speed,
-					     port->actor_port_number);
-			speed = 0;
-			break;
-		}
-	}
-
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d Received link speed %d update from adapter\n",
-		  port->actor_port_number, speed);
-	return speed;
-}
-
-/**
- * __get_duplex - get a port's duplex
- * @port: the port we're looking at
- *
- * Return @port's duplex in 802.3ad bitmask format. i.e.:
- *     0x01 if in full duplex
- *     0x00 otherwise
- */
-static u8 __get_duplex(struct port *port)
-{
-	struct slave *slave = port->slave;
-	u8 retval = 0x0;
-
-	/* handling a special case: when the configuration starts with
-	 * link down, it sets the duplex to 0.
-	 */
-	if (slave->link == BOND_LINK_UP) {
-		switch (slave->duplex) {
-		case DUPLEX_FULL:
-			retval = 0x1;
-			slave_dbg(slave->bond->dev, slave->dev, "Port %d Received status full duplex update from adapter\n",
-				  port->actor_port_number);
-			break;
-		case DUPLEX_HALF:
-		default:
-			retval = 0x0;
-			slave_dbg(slave->bond->dev, slave->dev, "Port %d Received status NOT full duplex update from adapter\n",
-				  port->actor_port_number);
-			break;
-		}
-	}
-	return retval;
-}
-
-static void __ad_actor_update_port(struct port *port)
-{
-	const struct bonding *bond = bond_get_bond_by_slave(port->slave);
-
-	port->actor_system = BOND_AD_INFO(bond).system.sys_mac_addr;
-	port->actor_system_priority = BOND_AD_INFO(bond).system.sys_priority;
-}
-
-/* Conversions */
-
-/**
- * __ad_timer_to_ticks - convert a given timer type to AD module ticks
- * @timer_type:	which timer to operate
- * @par: timer parameter. see below
- *
- * If @timer_type is %current_while_timer, @par indicates long/short timer.
- * If @timer_type is %periodic_timer, @par is one of %FAST_PERIODIC_TIME,
- *						     %SLOW_PERIODIC_TIME.
- */
-static u16 __ad_timer_to_ticks(u16 timer_type, u16 par)
-{
-	u16 retval = 0; /* to silence the compiler */
-
-	switch (timer_type) {
-	case AD_CURRENT_WHILE_TIMER:	/* for rx machine usage */
-		if (par)
-			retval = (AD_SHORT_TIMEOUT_TIME*ad_ticks_per_sec);
-		else
-			retval = (AD_LONG_TIMEOUT_TIME*ad_ticks_per_sec);
-		break;
-	case AD_ACTOR_CHURN_TIMER:	/* for local churn machine */
-		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
-		break;
-	case AD_PERIODIC_TIMER:		/* for periodic machine */
-		retval = (par*ad_ticks_per_sec); /* long timeout */
-		break;
-	case AD_PARTNER_CHURN_TIMER:	/* for remote churn machine */
-		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
-		break;
-	case AD_WAIT_WHILE_TIMER:	/* for selection machine */
-		retval = (AD_AGGREGATE_WAIT_TIME*ad_ticks_per_sec);
-		break;
-	}
-
-	return retval;
-}
-
-
-/* ================= ad_rx_machine helper functions ================== */
-
-/**
- * __choose_matched - update a port's matched variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Update the value of the matched variable, using parameter values from a
- * newly received lacpdu. Parameter values for the partner carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the actor. Matched is set to TRUE if all of these parameters
- * match and the PDU parameter partner_state.aggregation has the same value as
- * actor_oper_port_state.aggregation and lacp will actively maintain the link
- * in the aggregation. Matched is also set to TRUE if the value of
- * actor_state.aggregation in the received PDU is set to FALSE, i.e., indicates
- * an individual link and lacp will actively maintain the link. Otherwise,
- * matched is set to FALSE. LACP is considered to be actively maintaining the
- * link if either the PDU's actor_state.lacp_activity variable is TRUE or both
- * the actor's actor_oper_port_state.lacp_activity and the PDU's
- * partner_state.lacp_activity variables are TRUE.
- *
- * Note: the AD_PORT_MATCHED "variable" is not specified by 802.3ad; it is
- * used here to implement the language from 802.3ad 43.4.9 that requires
- * recordPDU to "match" the LACPDU parameters to the stored values.
- */
-static void __choose_matched(struct lacpdu *lacpdu, struct port *port)
-{
-	/* check if all parameters are alike
-	 * or this is individual link(aggregation == FALSE)
-	 * then update the state machine Matched variable.
-	 */
-	if (((ntohs(lacpdu->partner_port) == port->actor_port_number) &&
-	     (ntohs(lacpdu->partner_port_priority) == port->actor_port_priority) &&
-	     MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) &&
-	     (ntohs(lacpdu->partner_system_priority) == port->actor_system_priority) &&
-	     (ntohs(lacpdu->partner_key) == port->actor_oper_port_key) &&
-	     ((lacpdu->partner_state & AD_STATE_AGGREGATION) == (port->actor_oper_port_state & AD_STATE_AGGREGATION))) ||
-	    ((lacpdu->actor_state & AD_STATE_AGGREGATION) == 0)
-		) {
-		port->sm_vars |= AD_PORT_MATCHED;
-	} else {
-		port->sm_vars &= ~AD_PORT_MATCHED;
-	}
-}
-
-/**
- * __record_pdu - record parameters from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Record the parameter values for the Actor carried in a received lacpdu as
- * the current partner operational parameter values and sets
- * actor_oper_port_state.defaulted to FALSE.
- */
-static void __record_pdu(struct lacpdu *lacpdu, struct port *port)
-{
-	if (lacpdu && port) {
-		struct port_params *partner = &port->partner_oper;
-
-		__choose_matched(lacpdu, port);
-		/* record the new parameter values for the partner
-		 * operational
-		 */
-		partner->port_number = ntohs(lacpdu->actor_port);
-		partner->port_priority = ntohs(lacpdu->actor_port_priority);
-		partner->system = lacpdu->actor_system;
-		partner->system_priority = ntohs(lacpdu->actor_system_priority);
-		partner->key = ntohs(lacpdu->actor_key);
-		partner->port_state = lacpdu->actor_state;
-
-		/* set actor_oper_port_state.defaulted to FALSE */
-		port->actor_oper_port_state &= ~AD_STATE_DEFAULTED;
-
-		/* set the partner sync. to on if the partner is sync,
-		 * and the port is matched
-		 */
-		if ((port->sm_vars & AD_PORT_MATCHED) &&
-		    (lacpdu->actor_state & AD_STATE_SYNCHRONIZATION)) {
-			partner->port_state |= AD_STATE_SYNCHRONIZATION;
-			slave_dbg(port->slave->bond->dev, port->slave->dev,
-				  "partner sync=1\n");
-		} else {
-			partner->port_state &= ~AD_STATE_SYNCHRONIZATION;
-			slave_dbg(port->slave->bond->dev, port->slave->dev,
-				  "partner sync=0\n");
-		}
-	}
-}
-
-/**
- * __record_default - record default parameters
- * @port: the port we're looking at
- *
- * This function records the default parameter values for the partner carried
- * in the Partner Admin parameters as the current partner operational parameter
- * values and sets actor_oper_port_state.defaulted to TRUE.
- */
-static void __record_default(struct port *port)
-{
-	if (port) {
-		/* record the partner admin parameters */
-		memcpy(&port->partner_oper, &port->partner_admin,
-		       sizeof(struct port_params));
-
-		/* set actor_oper_port_state.defaulted to true */
-		port->actor_oper_port_state |= AD_STATE_DEFAULTED;
-	}
-}
-
-/**
- * __update_selected - update a port's Selected variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Update the value of the selected variable, using parameter values from a
- * newly received lacpdu. The parameter values for the Actor carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the ports partner. If one or more of the comparisons shows that
- * the value(s) received in the PDU differ from the current operational values,
- * then selected is set to FALSE and actor_oper_port_state.synchronization is
- * set to out_of_sync. Otherwise, selected remains unchanged.
- */
-static void __update_selected(struct lacpdu *lacpdu, struct port *port)
-{
-	if (lacpdu && port) {
-		const struct port_params *partner = &port->partner_oper;
-
-		/* check if any parameter is different then
-		 * update the state machine selected variable.
-		 */
-		if (ntohs(lacpdu->actor_port) != partner->port_number ||
-		    ntohs(lacpdu->actor_port_priority) != partner->port_priority ||
-		    !MAC_ADDRESS_EQUAL(&lacpdu->actor_system, &partner->system) ||
-		    ntohs(lacpdu->actor_system_priority) != partner->system_priority ||
-		    ntohs(lacpdu->actor_key) != partner->key ||
-		    (lacpdu->actor_state & AD_STATE_AGGREGATION) != (partner->port_state & AD_STATE_AGGREGATION)) {
-			port->sm_vars &= ~AD_PORT_SELECTED;
-		}
-	}
-}
-
-/**
- * __update_default_selected - update a port's Selected variable from Partner
- * @port: the port we're looking at
- *
- * This function updates the value of the selected variable, using the partner
- * administrative parameter values. The administrative values are compared with
- * the corresponding operational parameter values for the partner. If one or
- * more of the comparisons shows that the administrative value(s) differ from
- * the current operational values, then Selected is set to FALSE and
- * actor_oper_port_state.synchronization is set to OUT_OF_SYNC. Otherwise,
- * Selected remains unchanged.
- */
-static void __update_default_selected(struct port *port)
-{
-	if (port) {
-		const struct port_params *admin = &port->partner_admin;
-		const struct port_params *oper = &port->partner_oper;
-
-		/* check if any parameter is different then
-		 * update the state machine selected variable.
-		 */
-		if (admin->port_number != oper->port_number ||
-		    admin->port_priority != oper->port_priority ||
-		    !MAC_ADDRESS_EQUAL(&admin->system, &oper->system) ||
-		    admin->system_priority != oper->system_priority ||
-		    admin->key != oper->key ||
-		    (admin->port_state & AD_STATE_AGGREGATION)
-			!= (oper->port_state & AD_STATE_AGGREGATION)) {
-			port->sm_vars &= ~AD_PORT_SELECTED;
-		}
-	}
-}
-
-/**
- * __update_ntt - update a port's ntt variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Updates the value of the ntt variable, using parameter values from a newly
- * received lacpdu. The parameter values for the partner carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the Actor. If one or more of the comparisons shows that the
- * value(s) received in the PDU differ from the current operational values,
- * then ntt is set to TRUE. Otherwise, ntt remains unchanged.
- */
-static void __update_ntt(struct lacpdu *lacpdu, struct port *port)
-{
-	/* validate lacpdu and port */
-	if (lacpdu && port) {
-		/* check if any parameter is different then
-		 * update the port->ntt.
-		 */
-		if ((ntohs(lacpdu->partner_port) != port->actor_port_number) ||
-		    (ntohs(lacpdu->partner_port_priority) != port->actor_port_priority) ||
-		    !MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) ||
-		    (ntohs(lacpdu->partner_system_priority) != port->actor_system_priority) ||
-		    (ntohs(lacpdu->partner_key) != port->actor_oper_port_key) ||
-		    ((lacpdu->partner_state & AD_STATE_LACP_ACTIVITY) != (port->actor_oper_port_state & AD_STATE_LACP_ACTIVITY)) ||
-		    ((lacpdu->partner_state & AD_STATE_LACP_TIMEOUT) != (port->actor_oper_port_state & AD_STATE_LACP_TIMEOUT)) ||
-		    ((lacpdu->partner_state & AD_STATE_SYNCHRONIZATION) != (port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION)) ||
-		    ((lacpdu->partner_state & AD_STATE_AGGREGATION) != (port->actor_oper_port_state & AD_STATE_AGGREGATION))
-		   ) {
-			port->ntt = true;
-		}
-	}
-}
-
-/**
- * __agg_ports_are_ready - check if all ports in an aggregator are ready
- * @aggregator: the aggregator we're looking at
- *
- */
-static int __agg_ports_are_ready(struct aggregator *aggregator)
-{
-	struct port *port;
-	int retval = 1;
-
-	if (aggregator) {
-		/* scan all ports in this aggregator to verfy if they are
-		 * all ready.
-		 */
-		for (port = aggregator->lag_ports;
-		     port;
-		     port = port->next_port_in_aggregator) {
-			if (!(port->sm_vars & AD_PORT_READY_N)) {
-				retval = 0;
-				break;
-			}
-		}
-	}
-
-	return retval;
-}
-
-/**
- * __set_agg_ports_ready - set value of Ready bit in all ports of an aggregator
- * @aggregator: the aggregator we're looking at
- * @val: Should the ports' ready bit be set on or off
- *
- */
-static void __set_agg_ports_ready(struct aggregator *aggregator, int val)
-{
-	struct port *port;
-
-	for (port = aggregator->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (val)
-			port->sm_vars |= AD_PORT_READY;
-		else
-			port->sm_vars &= ~AD_PORT_READY;
-	}
-}
-
-static int __agg_active_ports(struct aggregator *agg)
-{
-	struct port *port;
-	int active = 0;
-
-	for (port = agg->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (port->is_enabled)
-			active++;
-	}
-
-	return active;
-}
-
-/**
- * __get_agg_bandwidth - get the total bandwidth of an aggregator
- * @aggregator: the aggregator we're looking at
- *
- */
-static u32 __get_agg_bandwidth(struct aggregator *aggregator)
-{
-	int nports = __agg_active_ports(aggregator);
-	u32 bandwidth = 0;
-
-	if (nports) {
-		switch (__get_link_speed(aggregator->lag_ports)) {
-		case AD_LINK_SPEED_1MBPS:
-			bandwidth = nports;
-			break;
-		case AD_LINK_SPEED_10MBPS:
-			bandwidth = nports * 10;
-			break;
-		case AD_LINK_SPEED_100MBPS:
-			bandwidth = nports * 100;
-			break;
-		case AD_LINK_SPEED_1000MBPS:
-			bandwidth = nports * 1000;
-			break;
-		case AD_LINK_SPEED_2500MBPS:
-			bandwidth = nports * 2500;
-			break;
-		case AD_LINK_SPEED_5000MBPS:
-			bandwidth = nports * 5000;
-			break;
-		case AD_LINK_SPEED_10000MBPS:
-			bandwidth = nports * 10000;
-			break;
-		case AD_LINK_SPEED_14000MBPS:
-			bandwidth = nports * 14000;
-			break;
-		case AD_LINK_SPEED_20000MBPS:
-			bandwidth = nports * 20000;
-			break;
-		case AD_LINK_SPEED_25000MBPS:
-			bandwidth = nports * 25000;
-			break;
-		case AD_LINK_SPEED_40000MBPS:
-			bandwidth = nports * 40000;
-			break;
-		case AD_LINK_SPEED_50000MBPS:
-			bandwidth = nports * 50000;
-			break;
-		case AD_LINK_SPEED_56000MBPS:
-			bandwidth = nports * 56000;
-			break;
-		case AD_LINK_SPEED_100000MBPS:
-			bandwidth = nports * 100000;
-			break;
-		default:
-			bandwidth = 0; /* to silence the compiler */
-		}
-	}
-	return bandwidth;
-}
-
-/**
- * __get_active_agg - get the current active aggregator
- * @aggregator: the aggregator we're looking at
- *
- * Caller must hold RCU lock.
- */
-static struct aggregator *__get_active_agg(struct aggregator *aggregator)
-{
-	struct bonding *bond = aggregator->slave->bond;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave_rcu(bond, slave, iter)
-		if (SLAVE_AD_INFO(slave)->aggregator.is_active)
-			return &(SLAVE_AD_INFO(slave)->aggregator);
-
-	return NULL;
-}
-
-/**
- * __update_lacpdu_from_port - update a port's lacpdu fields
- * @port: the port we're looking at
- */
-static inline void __update_lacpdu_from_port(struct port *port)
-{
-	struct lacpdu *lacpdu = &port->lacpdu;
-	const struct port_params *partner = &port->partner_oper;
-
-	/* update current actual Actor parameters
-	 * lacpdu->subtype                   initialized
-	 * lacpdu->version_number            initialized
-	 * lacpdu->tlv_type_actor_info       initialized
-	 * lacpdu->actor_information_length  initialized
-	 */
-
-	lacpdu->actor_system_priority = htons(port->actor_system_priority);
-	lacpdu->actor_system = port->actor_system;
-	lacpdu->actor_key = htons(port->actor_oper_port_key);
-	lacpdu->actor_port_priority = htons(port->actor_port_priority);
-	lacpdu->actor_port = htons(port->actor_port_number);
-	lacpdu->actor_state = port->actor_oper_port_state;
-	slave_dbg(port->slave->bond->dev, port->slave->dev,
-		  "update lacpdu: actor port state %x\n",
-		  port->actor_oper_port_state);
-
-	/* lacpdu->reserved_3_1              initialized
-	 * lacpdu->tlv_type_partner_info     initialized
-	 * lacpdu->partner_information_length initialized
-	 */
-
-	lacpdu->partner_system_priority = htons(partner->system_priority);
-	lacpdu->partner_system = partner->system;
-	lacpdu->partner_key = htons(partner->key);
-	lacpdu->partner_port_priority = htons(partner->port_priority);
-	lacpdu->partner_port = htons(partner->port_number);
-	lacpdu->partner_state = partner->port_state;
-
-	/* lacpdu->reserved_3_2              initialized
-	 * lacpdu->tlv_type_collector_info   initialized
-	 * lacpdu->collector_information_length initialized
-	 * collector_max_delay                initialized
-	 * reserved_12[12]                   initialized
-	 * tlv_type_terminator               initialized
-	 * terminator_length                 initialized
-	 * reserved_50[50]                   initialized
-	 */
-}
-
-/* ================= main 802.3ad protocol code ========================= */
-
-/**
- * ad_lacpdu_send - send out a lacpdu packet on a given port
- * @port: the port we're looking at
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-static int ad_lacpdu_send(struct port *port)
-{
-	struct slave *slave = port->slave;
-	struct sk_buff *skb;
-	struct lacpdu_header *lacpdu_header;
-	int length = sizeof(struct lacpdu_header);
-
-	skb = dev_alloc_skb(length);
-	if (!skb)
-		return -ENOMEM;
-
-	atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_tx);
-	atomic64_inc(&BOND_AD_INFO(slave->bond).stats.lacpdu_tx);
-
-	skb->dev = slave->dev;
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = PKT_TYPE_LACPDU;
-	skb->priority = TC_PRIO_CONTROL;
-
-	lacpdu_header = skb_put(skb, length);
-
-	ether_addr_copy(lacpdu_header->hdr.h_dest, lacpdu_mcast_addr);
-	/* Note: source address is set to be the member's PERMANENT address,
-	 * because we use it to identify loopback lacpdus in receive.
-	 */
-	ether_addr_copy(lacpdu_header->hdr.h_source, slave->perm_hwaddr);
-	lacpdu_header->hdr.h_proto = PKT_TYPE_LACPDU;
-
-	lacpdu_header->lacpdu = port->lacpdu;
-
-	dev_queue_xmit(skb);
-
-	return 0;
-}
-
-/**
- * ad_marker_send - send marker information/response on a given port
- * @port: the port we're looking at
- * @marker: marker data to send
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-static int ad_marker_send(struct port *port, struct bond_marker *marker)
-{
-	struct slave *slave = port->slave;
-	struct sk_buff *skb;
-	struct bond_marker_header *marker_header;
-	int length = sizeof(struct bond_marker_header);
-
-	skb = dev_alloc_skb(length + 16);
-	if (!skb)
-		return -ENOMEM;
-
-	switch (marker->tlv_type) {
-	case AD_MARKER_INFORMATION_SUBTYPE:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.marker_tx);
-		atomic64_inc(&BOND_AD_INFO(slave->bond).stats.marker_tx);
-		break;
-	case AD_MARKER_RESPONSE_SUBTYPE:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.marker_resp_tx);
-		atomic64_inc(&BOND_AD_INFO(slave->bond).stats.marker_resp_tx);
-		break;
-	}
-
-	skb_reserve(skb, 16);
-
-	skb->dev = slave->dev;
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = PKT_TYPE_LACPDU;
-
-	marker_header = skb_put(skb, length);
-
-	ether_addr_copy(marker_header->hdr.h_dest, lacpdu_mcast_addr);
-	/* Note: source address is set to be the member's PERMANENT address,
-	 * because we use it to identify loopback MARKERs in receive.
-	 */
-	ether_addr_copy(marker_header->hdr.h_source, slave->perm_hwaddr);
-	marker_header->hdr.h_proto = PKT_TYPE_LACPDU;
-
-	marker_header->marker = *marker;
-
-	dev_queue_xmit(skb);
-
-	return 0;
-}
-
-/**
- * ad_mux_machine - handle a port's mux state machine
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- */
-static void ad_mux_machine(struct port *port, bool *update_slave_arr)
-{
-	mux_states_t last_state;
-
-	/* keep current State Machine state to compare later if it was
-	 * changed
-	 */
-	last_state = port->sm_mux_state;
-
-	if (port->sm_vars & AD_PORT_BEGIN) {
-		port->sm_mux_state = AD_MUX_DETACHED;
-	} else {
-		switch (port->sm_mux_state) {
-		case AD_MUX_DETACHED:
-			if ((port->sm_vars & AD_PORT_SELECTED)
-			    || (port->sm_vars & AD_PORT_STANDBY))
-				/* if SELECTED or STANDBY */
-				port->sm_mux_state = AD_MUX_WAITING;
-			break;
-		case AD_MUX_WAITING:
-			/* if SELECTED == FALSE return to DETACH state */
-			if (!(port->sm_vars & AD_PORT_SELECTED)) {
-				port->sm_vars &= ~AD_PORT_READY_N;
-				/* in order to withhold the Selection Logic to
-				 * check all ports READY_N value every callback
-				 * cycle to update ready variable, we check
-				 * READY_N and update READY here
-				 */
-				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-				port->sm_mux_state = AD_MUX_DETACHED;
-				break;
-			}
-
-			/* check if the wait_while_timer expired */
-			if (port->sm_mux_timer_counter
-			    && !(--port->sm_mux_timer_counter))
-				port->sm_vars |= AD_PORT_READY_N;
-
-			/* in order to withhold the selection logic to check
-			 * all ports READY_N value every callback cycle to
-			 * update ready variable, we check READY_N and update
-			 * READY here
-			 */
-			__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-
-			/* if the wait_while_timer expired, and the port is
-			 * in READY state, move to ATTACHED state
-			 */
-			if ((port->sm_vars & AD_PORT_READY)
-			    && !port->sm_mux_timer_counter)
-				port->sm_mux_state = AD_MUX_ATTACHED;
-			break;
-		case AD_MUX_ATTACHED:
-			/* check also if agg_select_timer expired (so the
-			 * edable port will take place only after this timer)
-			 */
-			if ((port->sm_vars & AD_PORT_SELECTED) &&
-			    (port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) &&
-			    !__check_agg_selection_timer(port)) {
-				if (port->aggregator->is_active)
-					port->sm_mux_state =
-					    AD_MUX_COLLECTING_DISTRIBUTING;
-			} else if (!(port->sm_vars & AD_PORT_SELECTED) ||
-				   (port->sm_vars & AD_PORT_STANDBY)) {
-				/* if UNSELECTED or STANDBY */
-				port->sm_vars &= ~AD_PORT_READY_N;
-				/* in order to withhold the selection logic to
-				 * check all ports READY_N value every callback
-				 * cycle to update ready variable, we check
-				 * READY_N and update READY here
-				 */
-				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-				port->sm_mux_state = AD_MUX_DETACHED;
-			} else if (port->aggregator->is_active) {
-				port->actor_oper_port_state |=
-				    AD_STATE_SYNCHRONIZATION;
-			}
-			break;
-		case AD_MUX_COLLECTING_DISTRIBUTING:
-			if (!(port->sm_vars & AD_PORT_SELECTED) ||
-			    (port->sm_vars & AD_PORT_STANDBY) ||
-			    !(port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) ||
-			    !(port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION)) {
-				port->sm_mux_state = AD_MUX_ATTACHED;
-			} else {
-				/* if port state hasn't changed make
-				 * sure that a collecting distributing
-				 * port in an active aggregator is enabled
-				 */
-				if (port->aggregator &&
-				    port->aggregator->is_active &&
-				    !__port_is_enabled(port)) {
-
-					__enable_port(port);
-				}
-			}
-			break;
-		default:
-			break;
-		}
-	}
-
-	/* check if the state machine was changed */
-	if (port->sm_mux_state != last_state) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Mux Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number,
-			  last_state,
-			  port->sm_mux_state);
-		switch (port->sm_mux_state) {
-		case AD_MUX_DETACHED:
-			port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
-			ad_disable_collecting_distributing(port,
-							   update_slave_arr);
-			port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
-			port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
-			port->ntt = true;
-			break;
-		case AD_MUX_WAITING:
-			port->sm_mux_timer_counter = __ad_timer_to_ticks(AD_WAIT_WHILE_TIMER, 0);
-			break;
-		case AD_MUX_ATTACHED:
-			if (port->aggregator->is_active)
-				port->actor_oper_port_state |=
-				    AD_STATE_SYNCHRONIZATION;
-			else
-				port->actor_oper_port_state &=
-				    ~AD_STATE_SYNCHRONIZATION;
-			port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
-			port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
-			ad_disable_collecting_distributing(port,
-							   update_slave_arr);
-			port->ntt = true;
-			break;
-		case AD_MUX_COLLECTING_DISTRIBUTING:
-			port->actor_oper_port_state |= AD_STATE_COLLECTING;
-			port->actor_oper_port_state |= AD_STATE_DISTRIBUTING;
-			port->actor_oper_port_state |= AD_STATE_SYNCHRONIZATION;
-			ad_enable_collecting_distributing(port,
-							  update_slave_arr);
-			port->ntt = true;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_rx_machine - handle a port's rx State Machine
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * If lacpdu arrived, stop previous timer (if exists) and set the next state as
- * CURRENT. If timer expired set the state machine in the proper state.
- * In other cases, this function checks if we need to switch to other state.
- */
-static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port)
-{
-	rx_states_t last_state;
-
-	/* keep current State Machine state to compare later if it was
-	 * changed
-	 */
-	last_state = port->sm_rx_state;
-
-	if (lacpdu) {
-		atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.lacpdu_rx);
-		atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.lacpdu_rx);
-	}
-	/* check if state machine should change state */
-
-	/* first, check if port was reinitialized */
-	if (port->sm_vars & AD_PORT_BEGIN) {
-		port->sm_rx_state = AD_RX_INITIALIZE;
-		port->sm_vars |= AD_PORT_CHURNED;
-	/* check if port is not enabled */
-	} else if (!(port->sm_vars & AD_PORT_BEGIN) && !port->is_enabled)
-		port->sm_rx_state = AD_RX_PORT_DISABLED;
-	/* check if new lacpdu arrived */
-	else if (lacpdu && ((port->sm_rx_state == AD_RX_EXPIRED) ||
-		 (port->sm_rx_state == AD_RX_DEFAULTED) ||
-		 (port->sm_rx_state == AD_RX_CURRENT))) {
-		if (port->sm_rx_state != AD_RX_CURRENT)
-			port->sm_vars |= AD_PORT_CHURNED;
-		port->sm_rx_timer_counter = 0;
-		port->sm_rx_state = AD_RX_CURRENT;
-	} else {
-		/* if timer is on, and if it is expired */
-		if (port->sm_rx_timer_counter &&
-		    !(--port->sm_rx_timer_counter)) {
-			switch (port->sm_rx_state) {
-			case AD_RX_EXPIRED:
-				port->sm_rx_state = AD_RX_DEFAULTED;
-				break;
-			case AD_RX_CURRENT:
-				port->sm_rx_state = AD_RX_EXPIRED;
-				break;
-			default:
-				break;
-			}
-		} else {
-			/* if no lacpdu arrived and no timer is on */
-			switch (port->sm_rx_state) {
-			case AD_RX_PORT_DISABLED:
-				if (port->is_enabled &&
-				    (port->sm_vars & AD_PORT_LACP_ENABLED))
-					port->sm_rx_state = AD_RX_EXPIRED;
-				else if (port->is_enabled
-					 && ((port->sm_vars
-					      & AD_PORT_LACP_ENABLED) == 0))
-					port->sm_rx_state = AD_RX_LACP_DISABLED;
-				break;
-			default:
-				break;
-
-			}
-		}
-	}
-
-	/* check if the State machine was changed or new lacpdu arrived */
-	if ((port->sm_rx_state != last_state) || (lacpdu)) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Rx Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number,
-			  last_state,
-			  port->sm_rx_state);
-		switch (port->sm_rx_state) {
-		case AD_RX_INITIALIZE:
-			if (!(port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS))
-				port->sm_vars &= ~AD_PORT_LACP_ENABLED;
-			else
-				port->sm_vars |= AD_PORT_LACP_ENABLED;
-			port->sm_vars &= ~AD_PORT_SELECTED;
-			__record_default(port);
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			port->sm_rx_state = AD_RX_PORT_DISABLED;
-
-			/* Fall Through */
-		case AD_RX_PORT_DISABLED:
-			port->sm_vars &= ~AD_PORT_MATCHED;
-			break;
-		case AD_RX_LACP_DISABLED:
-			port->sm_vars &= ~AD_PORT_SELECTED;
-			__record_default(port);
-			port->partner_oper.port_state &= ~AD_STATE_AGGREGATION;
-			port->sm_vars |= AD_PORT_MATCHED;
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			break;
-		case AD_RX_EXPIRED:
-			/* Reset of the Synchronization flag (Standard 43.4.12)
-			 * This reset cause to disable this port in the
-			 * COLLECTING_DISTRIBUTING state of the mux machine in
-			 * case of EXPIRED even if LINK_DOWN didn't arrive for
-			 * the port.
-			 */
-			port->partner_oper.port_state &= ~AD_STATE_SYNCHRONIZATION;
-			port->sm_vars &= ~AD_PORT_MATCHED;
-			port->partner_oper.port_state |= AD_STATE_LACP_TIMEOUT;
-			port->partner_oper.port_state |= AD_STATE_LACP_ACTIVITY;
-			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(AD_SHORT_TIMEOUT));
-			port->actor_oper_port_state |= AD_STATE_EXPIRED;
-			port->sm_vars |= AD_PORT_CHURNED;
-			break;
-		case AD_RX_DEFAULTED:
-			__update_default_selected(port);
-			__record_default(port);
-			port->sm_vars |= AD_PORT_MATCHED;
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			break;
-		case AD_RX_CURRENT:
-			/* detect loopback situation */
-			if (MAC_ADDRESS_EQUAL(&(lacpdu->actor_system),
-					      &(port->actor_system))) {
-				slave_err(port->slave->bond->dev, port->slave->dev, "An illegal loopback occurred on slave\n"
-					  "Check the configuration to verify that all adapters are connected to 802.3ad compliant switch ports\n");
-				return;
-			}
-			__update_selected(lacpdu, port);
-			__update_ntt(lacpdu, port);
-			__record_pdu(lacpdu, port);
-			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(port->actor_oper_port_state & AD_STATE_LACP_TIMEOUT));
-			port->actor_oper_port_state &= ~AD_STATE_EXPIRED;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_churn_machine - handle port churn's state machine
- * @port: the port we're looking at
- *
- */
-static void ad_churn_machine(struct port *port)
-{
-	if (port->sm_vars & AD_PORT_CHURNED) {
-		port->sm_vars &= ~AD_PORT_CHURNED;
-		port->sm_churn_actor_state = AD_CHURN_MONITOR;
-		port->sm_churn_partner_state = AD_CHURN_MONITOR;
-		port->sm_churn_actor_timer_counter =
-			__ad_timer_to_ticks(AD_ACTOR_CHURN_TIMER, 0);
-		port->sm_churn_partner_timer_counter =
-			 __ad_timer_to_ticks(AD_PARTNER_CHURN_TIMER, 0);
-		return;
-	}
-	if (port->sm_churn_actor_timer_counter &&
-	    !(--port->sm_churn_actor_timer_counter) &&
-	    port->sm_churn_actor_state == AD_CHURN_MONITOR) {
-		if (port->actor_oper_port_state & AD_STATE_SYNCHRONIZATION) {
-			port->sm_churn_actor_state = AD_NO_CHURN;
-		} else {
-			port->churn_actor_count++;
-			port->sm_churn_actor_state = AD_CHURN;
-		}
-	}
-	if (port->sm_churn_partner_timer_counter &&
-	    !(--port->sm_churn_partner_timer_counter) &&
-	    port->sm_churn_partner_state == AD_CHURN_MONITOR) {
-		if (port->partner_oper.port_state & AD_STATE_SYNCHRONIZATION) {
-			port->sm_churn_partner_state = AD_NO_CHURN;
-		} else {
-			port->churn_partner_count++;
-			port->sm_churn_partner_state = AD_CHURN;
-		}
-	}
-}
-
-/**
- * ad_tx_machine - handle a port's tx state machine
- * @port: the port we're looking at
- */
-static void ad_tx_machine(struct port *port)
-{
-	/* check if tx timer expired, to verify that we do not send more than
-	 * 3 packets per second
-	 */
-	if (port->sm_tx_timer_counter && !(--port->sm_tx_timer_counter)) {
-		/* check if there is something to send */
-		if (port->ntt && (port->sm_vars & AD_PORT_LACP_ENABLED)) {
-			__update_lacpdu_from_port(port);
-
-			if (ad_lacpdu_send(port) >= 0) {
-				slave_dbg(port->slave->bond->dev,
-					  port->slave->dev,
-					  "Sent LACPDU on port %d\n",
-					  port->actor_port_number);
-
-				/* mark ntt as false, so it will not be sent
-				 * again until demanded
-				 */
-				port->ntt = false;
-			}
-		}
-		/* restart tx timer(to verify that we will not exceed
-		 * AD_MAX_TX_IN_SECOND
-		 */
-		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
-	}
-}
-
-/**
- * ad_periodic_machine - handle a port's periodic state machine
- * @port: the port we're looking at
- *
- * Turn ntt flag on priodically to perform periodic transmission of lacpdu's.
- */
-static void ad_periodic_machine(struct port *port)
-{
-	periodic_states_t last_state;
-
-	/* keep current state machine state to compare later if it was changed */
-	last_state = port->sm_periodic_state;
-
-	/* check if port was reinitialized */
-	if (((port->sm_vars & AD_PORT_BEGIN) || !(port->sm_vars & AD_PORT_LACP_ENABLED) || !port->is_enabled) ||
-	    (!(port->actor_oper_port_state & AD_STATE_LACP_ACTIVITY) && !(port->partner_oper.port_state & AD_STATE_LACP_ACTIVITY))
-	   ) {
-		port->sm_periodic_state = AD_NO_PERIODIC;
-	}
-	/* check if state machine should change state */
-	else if (port->sm_periodic_timer_counter) {
-		/* check if periodic state machine expired */
-		if (!(--port->sm_periodic_timer_counter)) {
-			/* if expired then do tx */
-			port->sm_periodic_state = AD_PERIODIC_TX;
-		} else {
-			/* If not expired, check if there is some new timeout
-			 * parameter from the partner state
-			 */
-			switch (port->sm_periodic_state) {
-			case AD_FAST_PERIODIC:
-				if (!(port->partner_oper.port_state
-				      & AD_STATE_LACP_TIMEOUT))
-					port->sm_periodic_state = AD_SLOW_PERIODIC;
-				break;
-			case AD_SLOW_PERIODIC:
-				if ((port->partner_oper.port_state & AD_STATE_LACP_TIMEOUT)) {
-					port->sm_periodic_timer_counter = 0;
-					port->sm_periodic_state = AD_PERIODIC_TX;
-				}
-				break;
-			default:
-				break;
-			}
-		}
-	} else {
-		switch (port->sm_periodic_state) {
-		case AD_NO_PERIODIC:
-			port->sm_periodic_state = AD_FAST_PERIODIC;
-			break;
-		case AD_PERIODIC_TX:
-			if (!(port->partner_oper.port_state &
-			    AD_STATE_LACP_TIMEOUT))
-				port->sm_periodic_state = AD_SLOW_PERIODIC;
-			else
-				port->sm_periodic_state = AD_FAST_PERIODIC;
-			break;
-		default:
-			break;
-		}
-	}
-
-	/* check if the state machine was changed */
-	if (port->sm_periodic_state != last_state) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Periodic Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number, last_state,
-			  port->sm_periodic_state);
-		switch (port->sm_periodic_state) {
-		case AD_NO_PERIODIC:
-			port->sm_periodic_timer_counter = 0;
-			break;
-		case AD_FAST_PERIODIC:
-			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
-			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_FAST_PERIODIC_TIME))-1;
-			break;
-		case AD_SLOW_PERIODIC:
-			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
-			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_SLOW_PERIODIC_TIME))-1;
-			break;
-		case AD_PERIODIC_TX:
-			port->ntt = true;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_port_selection_logic - select aggregation groups
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * Select aggregation groups, and assign each port for it's aggregetor. The
- * selection logic is called in the inititalization (after all the handshkes),
- * and after every lacpdu receive (if selected is off).
- */
-static void ad_port_selection_logic(struct port *port, bool *update_slave_arr)
-{
-	struct aggregator *aggregator, *free_aggregator = NULL, *temp_aggregator;
-	struct port *last_port = NULL, *curr_port;
-	struct list_head *iter;
-	struct bonding *bond;
-	struct slave *slave;
-	int found = 0;
-
-	/* if the port is already Selected, do nothing */
-	if (port->sm_vars & AD_PORT_SELECTED)
-		return;
-
-	bond = __get_bond_by_port(port);
-
-	/* if the port is connected to other aggregator, detach it */
-	if (port->aggregator) {
-		/* detach the port from its former aggregator */
-		temp_aggregator = port->aggregator;
-		for (curr_port = temp_aggregator->lag_ports; curr_port;
-		     last_port = curr_port,
-		     curr_port = curr_port->next_port_in_aggregator) {
-			if (curr_port == port) {
-				temp_aggregator->num_of_ports--;
-				/* if it is the first port attached to the
-				 * aggregator
-				 */
-				if (!last_port) {
-					temp_aggregator->lag_ports =
-						port->next_port_in_aggregator;
-				} else {
-					/* not the first port attached to the
-					 * aggregator
-					 */
-					last_port->next_port_in_aggregator =
-						port->next_port_in_aggregator;
-				}
-
-				/* clear the port's relations to this
-				 * aggregator
-				 */
-				port->aggregator = NULL;
-				port->next_port_in_aggregator = NULL;
-				port->actor_port_aggregator_identifier = 0;
-
-				slave_dbg(bond->dev, port->slave->dev, "Port %d left LAG %d\n",
-					  port->actor_port_number,
-					  temp_aggregator->aggregator_identifier);
-				/* if the aggregator is empty, clear its
-				 * parameters, and set it ready to be attached
-				 */
-				if (!temp_aggregator->lag_ports)
-					ad_clear_agg(temp_aggregator);
-				break;
-			}
-		}
-		if (!curr_port) {
-			/* meaning: the port was related to an aggregator
-			 * but was not on the aggregator port list
-			 */
-			net_warn_ratelimited("%s: (slave %s): Warning: Port %d was related to aggregator %d but was not on its port list\n",
-					     port->slave->bond->dev->name,
-					     port->slave->dev->name,
-					     port->actor_port_number,
-					     port->aggregator->aggregator_identifier);
-		}
-	}
-	/* search on all aggregators for a suitable aggregator for this port */
-	bond_for_each_slave(bond, slave, iter) {
-		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		/* keep a free aggregator for later use(if needed) */
-		if (!aggregator->lag_ports) {
-			if (!free_aggregator)
-				free_aggregator = aggregator;
-			continue;
-		}
-		/* check if current aggregator suits us */
-		if (((aggregator->actor_oper_aggregator_key == port->actor_oper_port_key) && /* if all parameters match AND */
-		     MAC_ADDRESS_EQUAL(&(aggregator->partner_system), &(port->partner_oper.system)) &&
-		     (aggregator->partner_system_priority == port->partner_oper.system_priority) &&
-		     (aggregator->partner_oper_aggregator_key == port->partner_oper.key)
-		    ) &&
-		    ((!MAC_ADDRESS_EQUAL(&(port->partner_oper.system), &(null_mac_addr)) && /* partner answers */
-		      !aggregator->is_individual)  /* but is not individual OR */
-		    )
-		   ) {
-			/* attach to the founded aggregator */
-			port->aggregator = aggregator;
-			port->actor_port_aggregator_identifier =
-				port->aggregator->aggregator_identifier;
-			port->next_port_in_aggregator = aggregator->lag_ports;
-			port->aggregator->num_of_ports++;
-			aggregator->lag_ports = port;
-			slave_dbg(bond->dev, slave->dev, "Port %d joined LAG %d (existing LAG)\n",
-				  port->actor_port_number,
-				  port->aggregator->aggregator_identifier);
-
-			/* mark this port as selected */
-			port->sm_vars |= AD_PORT_SELECTED;
-			found = 1;
-			break;
-		}
-	}
-
-	/* the port couldn't find an aggregator - attach it to a new
-	 * aggregator
-	 */
-	if (!found) {
-		if (free_aggregator) {
-			/* assign port a new aggregator */
-			port->aggregator = free_aggregator;
-			port->actor_port_aggregator_identifier =
-				port->aggregator->aggregator_identifier;
-
-			/* update the new aggregator's parameters
-			 * if port was responsed from the end-user
-			 */
-			if (port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS)
-				/* if port is full duplex */
-				port->aggregator->is_individual = false;
-			else
-				port->aggregator->is_individual = true;
-
-			port->aggregator->actor_admin_aggregator_key =
-				port->actor_admin_port_key;
-			port->aggregator->actor_oper_aggregator_key =
-				port->actor_oper_port_key;
-			port->aggregator->partner_system =
-				port->partner_oper.system;
-			port->aggregator->partner_system_priority =
-				port->partner_oper.system_priority;
-			port->aggregator->partner_oper_aggregator_key = port->partner_oper.key;
-			port->aggregator->receive_state = 1;
-			port->aggregator->transmit_state = 1;
-			port->aggregator->lag_ports = port;
-			port->aggregator->num_of_ports++;
-
-			/* mark this port as selected */
-			port->sm_vars |= AD_PORT_SELECTED;
-
-			slave_dbg(bond->dev, port->slave->dev, "Port %d joined LAG %d (new LAG)\n",
-				  port->actor_port_number,
-				  port->aggregator->aggregator_identifier);
-		} else {
-			slave_err(bond->dev, port->slave->dev,
-				  "Port %d did not find a suitable aggregator\n",
-				  port->actor_port_number);
-		}
-	}
-	/* if all aggregator's ports are READY_N == TRUE, set ready=TRUE
-	 * in all aggregator's ports, else set ready=FALSE in all
-	 * aggregator's ports
-	 */
-	__set_agg_ports_ready(port->aggregator,
-			      __agg_ports_are_ready(port->aggregator));
-
-	aggregator = __get_first_agg(port);
-	ad_agg_selection_logic(aggregator, update_slave_arr);
-
-	if (!port->aggregator->is_active)
-		port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
-}
-
-/* Decide if "agg" is a better choice for the new active aggregator that
- * the current best, according to the ad_select policy.
- */
-static struct aggregator *ad_agg_selection_test(struct aggregator *best,
-						struct aggregator *curr)
-{
-	/* 0. If no best, select current.
-	 *
-	 * 1. If the current agg is not individual, and the best is
-	 *    individual, select current.
-	 *
-	 * 2. If current agg is individual and the best is not, keep best.
-	 *
-	 * 3. Therefore, current and best are both individual or both not
-	 *    individual, so:
-	 *
-	 * 3a. If current agg partner replied, and best agg partner did not,
-	 *     select current.
-	 *
-	 * 3b. If current agg partner did not reply and best agg partner
-	 *     did reply, keep best.
-	 *
-	 * 4.  Therefore, current and best both have partner replies or
-	 *     both do not, so perform selection policy:
-	 *
-	 * BOND_AD_COUNT: Select by count of ports.  If count is equal,
-	 *     select by bandwidth.
-	 *
-	 * BOND_AD_STABLE, BOND_AD_BANDWIDTH: Select by bandwidth.
-	 */
-	if (!best)
-		return curr;
-
-	if (!curr->is_individual && best->is_individual)
-		return curr;
-
-	if (curr->is_individual && !best->is_individual)
-		return best;
-
-	if (__agg_has_partner(curr) && !__agg_has_partner(best))
-		return curr;
-
-	if (!__agg_has_partner(curr) && __agg_has_partner(best))
-		return best;
-
-	switch (__get_agg_selection_mode(curr->lag_ports)) {
-	case BOND_AD_COUNT:
-		if (__agg_active_ports(curr) > __agg_active_ports(best))
-			return curr;
-
-		if (__agg_active_ports(curr) < __agg_active_ports(best))
-			return best;
-
-		/*FALLTHROUGH*/
-	case BOND_AD_STABLE:
-	case BOND_AD_BANDWIDTH:
-		if (__get_agg_bandwidth(curr) > __get_agg_bandwidth(best))
-			return curr;
-
-		break;
-
-	default:
-		net_warn_ratelimited("%s: (slave %s): Impossible agg select mode %d\n",
-				     curr->slave->bond->dev->name,
-				     curr->slave->dev->name,
-				     __get_agg_selection_mode(curr->lag_ports));
-		break;
-	}
-
-	return best;
-}
-
-static int agg_device_up(const struct aggregator *agg)
-{
-	struct port *port = agg->lag_ports;
-
-	if (!port)
-		return 0;
-
-	for (port = agg->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (netif_running(port->slave->dev) &&
-		    netif_carrier_ok(port->slave->dev))
-			return 1;
-	}
-
-	return 0;
-}
-
-/**
- * ad_agg_selection_logic - select an aggregation group for a team
- * @aggregator: the aggregator we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * It is assumed that only one aggregator may be selected for a team.
- *
- * The logic of this function is to select the aggregator according to
- * the ad_select policy:
- *
- * BOND_AD_STABLE: select the aggregator with the most ports attached to
- * it, and to reselect the active aggregator only if the previous
- * aggregator has no more ports related to it.
- *
- * BOND_AD_BANDWIDTH: select the aggregator with the highest total
- * bandwidth, and reselect whenever a link state change takes place or the
- * set of slaves in the bond changes.
- *
- * BOND_AD_COUNT: select the aggregator with largest number of ports
- * (slaves), and reselect whenever a link state change takes place or the
- * set of slaves in the bond changes.
- *
- * FIXME: this function MUST be called with the first agg in the bond, or
- * __get_active_agg() won't work correctly. This function should be better
- * called with the bond itself, and retrieve the first agg from it.
- */
-static void ad_agg_selection_logic(struct aggregator *agg,
-				   bool *update_slave_arr)
-{
-	struct aggregator *best, *active, *origin;
-	struct bonding *bond = agg->slave->bond;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-
-	rcu_read_lock();
-	origin = agg;
-	active = __get_active_agg(agg);
-	best = (active && agg_device_up(active)) ? active : NULL;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		agg = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		agg->is_active = 0;
-
-		if (__agg_active_ports(agg) && agg_device_up(agg))
-			best = ad_agg_selection_test(best, agg);
-	}
-
-	if (best &&
-	    __get_agg_selection_mode(best->lag_ports) == BOND_AD_STABLE) {
-		/* For the STABLE policy, don't replace the old active
-		 * aggregator if it's still active (it has an answering
-		 * partner) or if both the best and active don't have an
-		 * answering partner.
-		 */
-		if (active && active->lag_ports &&
-		    __agg_active_ports(active) &&
-		    (__agg_has_partner(active) ||
-		     (!__agg_has_partner(active) &&
-		     !__agg_has_partner(best)))) {
-			if (!(!active->actor_oper_aggregator_key &&
-			      best->actor_oper_aggregator_key)) {
-				best = NULL;
-				active->is_active = 1;
-			}
-		}
-	}
-
-	if (best && (best == active)) {
-		best = NULL;
-		active->is_active = 1;
-	}
-
-	/* if there is new best aggregator, activate it */
-	if (best) {
-		netdev_dbg(bond->dev, "(slave %s): best Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier, best->num_of_ports,
-			   best->actor_oper_aggregator_key,
-			   best->partner_oper_aggregator_key,
-			   best->is_individual, best->is_active);
-		netdev_dbg(bond->dev, "(slave %s): best ports %p slave %p\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->lag_ports, best->slave);
-
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			agg = &(SLAVE_AD_INFO(slave)->aggregator);
-
-			slave_dbg(bond->dev, slave->dev, "Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-				  agg->aggregator_identifier, agg->num_of_ports,
-				  agg->actor_oper_aggregator_key,
-				  agg->partner_oper_aggregator_key,
-				  agg->is_individual, agg->is_active);
-		}
-
-		/* check if any partner replies */
-		if (best->is_individual)
-			net_warn_ratelimited("%s: Warning: No 802.3ad response from the link partner for any adapters in the bond\n",
-					     bond->dev->name);
-
-		best->is_active = 1;
-		netdev_dbg(bond->dev, "(slave %s): LAG %d chosen as the active LAG\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier);
-		netdev_dbg(bond->dev, "(slave %s): Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier, best->num_of_ports,
-			   best->actor_oper_aggregator_key,
-			   best->partner_oper_aggregator_key,
-			   best->is_individual, best->is_active);
-
-		/* disable the ports that were related to the former
-		 * active_aggregator
-		 */
-		if (active) {
-			for (port = active->lag_ports; port;
-			     port = port->next_port_in_aggregator) {
-				__disable_port(port);
-			}
-		}
-		/* Slave array needs update. */
-		*update_slave_arr = true;
-	}
-
-	/* if the selected aggregator is of join individuals
-	 * (partner_system is NULL), enable their ports
-	 */
-	active = __get_active_agg(origin);
-
-	if (active) {
-		if (!__agg_has_partner(active)) {
-			for (port = active->lag_ports; port;
-			     port = port->next_port_in_aggregator) {
-				__enable_port(port);
-			}
-		}
-	}
-
-	rcu_read_unlock();
-
-	bond_3ad_set_carrier(bond);
-}
-
-/**
- * ad_clear_agg - clear a given aggregator's parameters
- * @aggregator: the aggregator we're looking at
- */
-static void ad_clear_agg(struct aggregator *aggregator)
-{
-	if (aggregator) {
-		aggregator->is_individual = false;
-		aggregator->actor_admin_aggregator_key = 0;
-		aggregator->actor_oper_aggregator_key = 0;
-		eth_zero_addr(aggregator->partner_system.mac_addr_value);
-		aggregator->partner_system_priority = 0;
-		aggregator->partner_oper_aggregator_key = 0;
-		aggregator->receive_state = 0;
-		aggregator->transmit_state = 0;
-		aggregator->lag_ports = NULL;
-		aggregator->is_active = 0;
-		aggregator->num_of_ports = 0;
-		pr_debug("%s: LAG %d was cleared\n",
-			 aggregator->slave ?
-			 aggregator->slave->dev->name : "NULL",
-			 aggregator->aggregator_identifier);
-	}
-}
-
-/**
- * ad_initialize_agg - initialize a given aggregator's parameters
- * @aggregator: the aggregator we're looking at
- */
-static void ad_initialize_agg(struct aggregator *aggregator)
-{
-	if (aggregator) {
-		ad_clear_agg(aggregator);
-
-		eth_zero_addr(aggregator->aggregator_mac_address.mac_addr_value);
-		aggregator->aggregator_identifier = 0;
-		aggregator->slave = NULL;
-	}
-}
-
-/**
- * ad_initialize_port - initialize a given port's parameters
- * @aggregator: the aggregator we're looking at
- * @lacp_fast: boolean. whether fast periodic should be used
- */
-static void ad_initialize_port(struct port *port, int lacp_fast)
-{
-	static const struct port_params tmpl = {
-		.system_priority = 0xffff,
-		.key             = 1,
-		.port_number     = 1,
-		.port_priority   = 0xff,
-		.port_state      = 1,
-	};
-	static const struct lacpdu lacpdu = {
-		.subtype		= 0x01,
-		.version_number = 0x01,
-		.tlv_type_actor_info = 0x01,
-		.actor_information_length = 0x14,
-		.tlv_type_partner_info = 0x02,
-		.partner_information_length = 0x14,
-		.tlv_type_collector_info = 0x03,
-		.collector_information_length = 0x10,
-		.collector_max_delay = htons(AD_COLLECTOR_MAX_DELAY),
-	};
-
-	if (port) {
-		port->actor_port_priority = 0xff;
-		port->actor_port_aggregator_identifier = 0;
-		port->ntt = false;
-		port->actor_admin_port_state = AD_STATE_AGGREGATION |
-					       AD_STATE_LACP_ACTIVITY;
-		port->actor_oper_port_state  = AD_STATE_AGGREGATION |
-					       AD_STATE_LACP_ACTIVITY;
-
-		if (lacp_fast)
-			port->actor_oper_port_state |= AD_STATE_LACP_TIMEOUT;
-
-		memcpy(&port->partner_admin, &tmpl, sizeof(tmpl));
-		memcpy(&port->partner_oper, &tmpl, sizeof(tmpl));
-
-		port->is_enabled = true;
-		/* private parameters */
-		port->sm_vars = AD_PORT_BEGIN | AD_PORT_LACP_ENABLED;
-		port->sm_rx_state = 0;
-		port->sm_rx_timer_counter = 0;
-		port->sm_periodic_state = 0;
-		port->sm_periodic_timer_counter = 0;
-		port->sm_mux_state = 0;
-		port->sm_mux_timer_counter = 0;
-		port->sm_tx_state = 0;
-		port->aggregator = NULL;
-		port->next_port_in_aggregator = NULL;
-		port->transaction_id = 0;
-
-		port->sm_churn_actor_timer_counter = 0;
-		port->sm_churn_actor_state = 0;
-		port->churn_actor_count = 0;
-		port->sm_churn_partner_timer_counter = 0;
-		port->sm_churn_partner_state = 0;
-		port->churn_partner_count = 0;
-
-		memcpy(&port->lacpdu, &lacpdu, sizeof(lacpdu));
-	}
-}
-
-/**
- * ad_enable_collecting_distributing - enable a port's transmit/receive
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * Enable @port if it's in an active aggregator
- */
-static void ad_enable_collecting_distributing(struct port *port,
-					      bool *update_slave_arr)
-{
-	if (port->aggregator->is_active) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Enabling port %d (LAG %d)\n",
-			  port->actor_port_number,
-			  port->aggregator->aggregator_identifier);
-		__enable_port(port);
-		/* Slave array needs update */
-		*update_slave_arr = true;
-	}
-}
-
-/**
- * ad_disable_collecting_distributing - disable a port's transmit/receive
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- */
-static void ad_disable_collecting_distributing(struct port *port,
-					       bool *update_slave_arr)
-{
-	if (port->aggregator &&
-	    !MAC_ADDRESS_EQUAL(&(port->aggregator->partner_system),
-			       &(null_mac_addr))) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Disabling port %d (LAG %d)\n",
-			  port->actor_port_number,
-			  port->aggregator->aggregator_identifier);
-		__disable_port(port);
-		/* Slave array needs an update */
-		*update_slave_arr = true;
-	}
-}
-
-/**
- * ad_marker_info_received - handle receive of a Marker information frame
- * @marker_info: Marker info received
- * @port: the port we're looking at
- */
-static void ad_marker_info_received(struct bond_marker *marker_info,
-				    struct port *port)
-{
-	struct bond_marker marker;
-
-	atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.marker_rx);
-	atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.marker_rx);
-
-	/* copy the received marker data to the response marker */
-	memcpy(&marker, marker_info, sizeof(struct bond_marker));
-	/* change the marker subtype to marker response */
-	marker.tlv_type = AD_MARKER_RESPONSE_SUBTYPE;
-
-	/* send the marker response */
-	if (ad_marker_send(port, &marker) >= 0)
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Sent Marker Response on port %d\n",
-			  port->actor_port_number);
-}
-
-/**
- * ad_marker_response_received - handle receive of a marker response frame
- * @marker: marker PDU received
- * @port: the port we're looking at
- *
- * This function does nothing since we decided not to implement send and handle
- * response for marker PDU's, in this stage, but only to respond to marker
- * information.
- */
-static void ad_marker_response_received(struct bond_marker *marker,
-					struct port *port)
-{
-	atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.marker_resp_rx);
-	atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.marker_resp_rx);
-
-	/* DO NOTHING, SINCE WE DECIDED NOT TO IMPLEMENT THIS FEATURE FOR NOW */
-}
-
-/* ========= AD exported functions to the main bonding code ========= */
-
-/* Check aggregators status in team every T seconds */
-#define AD_AGGREGATOR_SELECTION_TIMER  8
-
-/**
- * bond_3ad_initiate_agg_selection - initate aggregator selection
- * @bond: bonding struct
- *
- * Set the aggregation selection timer, to initiate an agg selection in
- * the very near future.  Called during first initialization, and during
- * any down to up transitions of the bond.
- */
-void bond_3ad_initiate_agg_selection(struct bonding *bond, int timeout)
-{
-	BOND_AD_INFO(bond).agg_select_timer = timeout;
-}
-
-/**
- * bond_3ad_initialize - initialize a bond's 802.3ad parameters and structures
- * @bond: bonding struct to work on
- * @tick_resolution: tick duration (millisecond resolution)
- *
- * Can be called only after the mac address of the bond is set.
- */
-void bond_3ad_initialize(struct bonding *bond, u16 tick_resolution)
-{
-	/* check that the bond is not initialized yet */
-	if (!MAC_ADDRESS_EQUAL(&(BOND_AD_INFO(bond).system.sys_mac_addr),
-				bond->dev->dev_addr)) {
-
-		BOND_AD_INFO(bond).aggregator_identifier = 0;
-
-		BOND_AD_INFO(bond).system.sys_priority =
-			bond->params.ad_actor_sys_prio;
-		if (is_zero_ether_addr(bond->params.ad_actor_system))
-			BOND_AD_INFO(bond).system.sys_mac_addr =
-			    *((struct mac_addr *)bond->dev->dev_addr);
-		else
-			BOND_AD_INFO(bond).system.sys_mac_addr =
-			    *((struct mac_addr *)bond->params.ad_actor_system);
-
-		/* initialize how many times this module is called in one
-		 * second (should be about every 100ms)
-		 */
-		ad_ticks_per_sec = tick_resolution;
-
-		bond_3ad_initiate_agg_selection(bond,
-						AD_AGGREGATOR_SELECTION_TIMER *
-						ad_ticks_per_sec);
-	}
-}
-
-/**
- * bond_3ad_bind_slave - initialize a slave's port
- * @slave: slave struct to work on
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-void bond_3ad_bind_slave(struct slave *slave)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-	struct port *port;
-	struct aggregator *aggregator;
-
-	/* check that the slave has not been initialized yet. */
-	if (SLAVE_AD_INFO(slave)->port.slave != slave) {
-
-		/* port initialization */
-		port = &(SLAVE_AD_INFO(slave)->port);
-
-		ad_initialize_port(port, bond->params.lacp_fast);
-
-		port->slave = slave;
-		port->actor_port_number = SLAVE_AD_INFO(slave)->id;
-		/* key is determined according to the link speed, duplex and
-		 * user key
-		 */
-		port->actor_admin_port_key = bond->params.ad_user_port_key << 6;
-		ad_update_actor_keys(port, false);
-		/* actor system is the bond's system */
-		__ad_actor_update_port(port);
-		/* tx timer(to verify that no more than MAX_TX_IN_SECOND
-		 * lacpdu's are sent in one second)
-		 */
-		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
-
-		__disable_port(port);
-
-		/* aggregator initialization */
-		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		ad_initialize_agg(aggregator);
-
-		aggregator->aggregator_mac_address = *((struct mac_addr *)bond->dev->dev_addr);
-		aggregator->aggregator_identifier = ++BOND_AD_INFO(bond).aggregator_identifier;
-		aggregator->slave = slave;
-		aggregator->is_active = 0;
-		aggregator->num_of_ports = 0;
-	}
-}
-
-/**
- * bond_3ad_unbind_slave - deinitialize a slave's port
- * @slave: slave struct to work on
- *
- * Search for the aggregator that is related to this port, remove the
- * aggregator and assign another aggregator for other port related to it
- * (if any), and remove the port.
- */
-void bond_3ad_unbind_slave(struct slave *slave)
-{
-	struct port *port, *prev_port, *temp_port;
-	struct aggregator *aggregator, *new_aggregator, *temp_aggregator;
-	int select_new_active_agg = 0;
-	struct bonding *bond = slave->bond;
-	struct slave *slave_iter;
-	struct list_head *iter;
-	bool dummy_slave_update; /* Ignore this value as caller updates array */
-
-	/* Sync against bond_3ad_state_machine_handler() */
-	spin_lock_bh(&bond->mode_lock);
-	aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(bond->dev, slave->dev, "Trying to unbind an uninitialized port\n");
-		goto out;
-	}
-
-	slave_dbg(bond->dev, slave->dev, "Unbinding Link Aggregation Group %d\n",
-		  aggregator->aggregator_identifier);
-
-	/* Tell the partner that this port is not suitable for aggregation */
-	port->actor_oper_port_state &= ~AD_STATE_SYNCHRONIZATION;
-	port->actor_oper_port_state &= ~AD_STATE_COLLECTING;
-	port->actor_oper_port_state &= ~AD_STATE_DISTRIBUTING;
-	port->actor_oper_port_state &= ~AD_STATE_AGGREGATION;
-	__update_lacpdu_from_port(port);
-	ad_lacpdu_send(port);
-
-	/* check if this aggregator is occupied */
-	if (aggregator->lag_ports) {
-		/* check if there are other ports related to this aggregator
-		 * except the port related to this slave(thats ensure us that
-		 * there is a reason to search for new aggregator, and that we
-		 * will find one
-		 */
-		if ((aggregator->lag_ports != port) ||
-		    (aggregator->lag_ports->next_port_in_aggregator)) {
-			/* find new aggregator for the related port(s) */
-			bond_for_each_slave(bond, slave_iter, iter) {
-				new_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
-				/* if the new aggregator is empty, or it is
-				 * connected to our port only
-				 */
-				if (!new_aggregator->lag_ports ||
-				    ((new_aggregator->lag_ports == port) &&
-				     !new_aggregator->lag_ports->next_port_in_aggregator))
-					break;
-			}
-			if (!slave_iter)
-				new_aggregator = NULL;
-
-			/* if new aggregator found, copy the aggregator's
-			 * parameters and connect the related lag_ports to the
-			 * new aggregator
-			 */
-			if ((new_aggregator) && ((!new_aggregator->lag_ports) || ((new_aggregator->lag_ports == port) && !new_aggregator->lag_ports->next_port_in_aggregator))) {
-				slave_dbg(bond->dev, slave->dev, "Some port(s) related to LAG %d - replacing with LAG %d\n",
-					  aggregator->aggregator_identifier,
-					  new_aggregator->aggregator_identifier);
-
-				if ((new_aggregator->lag_ports == port) &&
-				    new_aggregator->is_active) {
-					slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-					select_new_active_agg = 1;
-				}
-
-				new_aggregator->is_individual = aggregator->is_individual;
-				new_aggregator->actor_admin_aggregator_key = aggregator->actor_admin_aggregator_key;
-				new_aggregator->actor_oper_aggregator_key = aggregator->actor_oper_aggregator_key;
-				new_aggregator->partner_system = aggregator->partner_system;
-				new_aggregator->partner_system_priority = aggregator->partner_system_priority;
-				new_aggregator->partner_oper_aggregator_key = aggregator->partner_oper_aggregator_key;
-				new_aggregator->receive_state = aggregator->receive_state;
-				new_aggregator->transmit_state = aggregator->transmit_state;
-				new_aggregator->lag_ports = aggregator->lag_ports;
-				new_aggregator->is_active = aggregator->is_active;
-				new_aggregator->num_of_ports = aggregator->num_of_ports;
-
-				/* update the information that is written on
-				 * the ports about the aggregator
-				 */
-				for (temp_port = aggregator->lag_ports; temp_port;
-				     temp_port = temp_port->next_port_in_aggregator) {
-					temp_port->aggregator = new_aggregator;
-					temp_port->actor_port_aggregator_identifier = new_aggregator->aggregator_identifier;
-				}
-
-				ad_clear_agg(aggregator);
-
-				if (select_new_active_agg)
-					ad_agg_selection_logic(__get_first_agg(port),
-							       &dummy_slave_update);
-			} else {
-				slave_warn(bond->dev, slave->dev, "unbinding aggregator, and could not find a new aggregator for its ports\n");
-			}
-		} else {
-			/* in case that the only port related to this
-			 * aggregator is the one we want to remove
-			 */
-			select_new_active_agg = aggregator->is_active;
-			ad_clear_agg(aggregator);
-			if (select_new_active_agg) {
-				slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-				/* select new active aggregator */
-				temp_aggregator = __get_first_agg(port);
-				if (temp_aggregator)
-					ad_agg_selection_logic(temp_aggregator,
-							       &dummy_slave_update);
-			}
-		}
-	}
-
-	slave_dbg(bond->dev, slave->dev, "Unbinding port %d\n", port->actor_port_number);
-
-	/* find the aggregator that this port is connected to */
-	bond_for_each_slave(bond, slave_iter, iter) {
-		temp_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
-		prev_port = NULL;
-		/* search the port in the aggregator's related ports */
-		for (temp_port = temp_aggregator->lag_ports; temp_port;
-		     prev_port = temp_port,
-		     temp_port = temp_port->next_port_in_aggregator) {
-			if (temp_port == port) {
-				/* the aggregator found - detach the port from
-				 * this aggregator
-				 */
-				if (prev_port)
-					prev_port->next_port_in_aggregator = temp_port->next_port_in_aggregator;
-				else
-					temp_aggregator->lag_ports = temp_port->next_port_in_aggregator;
-				temp_aggregator->num_of_ports--;
-				if (__agg_active_ports(temp_aggregator) == 0) {
-					select_new_active_agg = temp_aggregator->is_active;
-					ad_clear_agg(temp_aggregator);
-					if (select_new_active_agg) {
-						slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-						/* select new active aggregator */
-						ad_agg_selection_logic(__get_first_agg(port),
-							               &dummy_slave_update);
-					}
-				}
-				break;
-			}
-		}
-	}
-	port->slave = NULL;
-
-out:
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/**
- * bond_3ad_update_ad_actor_settings - reflect change of actor settings to ports
- * @bond: bonding struct to work on
- *
- * If an ad_actor setting gets changed we need to update the individual port
- * settings so the bond device will use the new values when it gets upped.
- */
-void bond_3ad_update_ad_actor_settings(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	ASSERT_RTNL();
-
-	BOND_AD_INFO(bond).system.sys_priority = bond->params.ad_actor_sys_prio;
-	if (is_zero_ether_addr(bond->params.ad_actor_system))
-		BOND_AD_INFO(bond).system.sys_mac_addr =
-		    *((struct mac_addr *)bond->dev->dev_addr);
-	else
-		BOND_AD_INFO(bond).system.sys_mac_addr =
-		    *((struct mac_addr *)bond->params.ad_actor_system);
-
-	spin_lock_bh(&bond->mode_lock);
-	bond_for_each_slave(bond, slave, iter) {
-		struct port *port = &(SLAVE_AD_INFO(slave))->port;
-
-		__ad_actor_update_port(port);
-		port->ntt = true;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/**
- * bond_3ad_state_machine_handler - handle state machines timeout
- * @bond: bonding struct to work on
- *
- * The state machine handling concept in this module is to check every tick
- * which state machine should operate any function. The execution order is
- * round robin, so when we have an interaction between state machines, the
- * reply of one to each other might be delayed until next tick.
- *
- * This function also complete the initialization when the agg_select_timer
- * times out, and it selects an aggregator for the ports that are yet not
- * related to any aggregator, and selects the active aggregator for a bond.
- */
-void bond_3ad_state_machine_handler(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    ad_work.work);
-	struct aggregator *aggregator;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
-	bool update_slave_arr = false;
-
-	/* Lock to protect data accessed by all (e.g., port->sm_vars) and
-	 * against running with bond_3ad_unbind_slave. ad_rx_machine may run
-	 * concurrently due to incoming LACPDU as well.
-	 */
-	spin_lock_bh(&bond->mode_lock);
-	rcu_read_lock();
-
-	/* check if there are any slaves */
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	/* check if agg_select_timer timer after initialize is timed out */
-	if (BOND_AD_INFO(bond).agg_select_timer &&
-	    !(--BOND_AD_INFO(bond).agg_select_timer)) {
-		slave = bond_first_slave_rcu(bond);
-		port = slave ? &(SLAVE_AD_INFO(slave)->port) : NULL;
-
-		/* select the active aggregator for the bond */
-		if (port) {
-			if (!port->slave) {
-				net_warn_ratelimited("%s: Warning: bond's first port is uninitialized\n",
-						     bond->dev->name);
-				goto re_arm;
-			}
-
-			aggregator = __get_first_agg(port);
-			ad_agg_selection_logic(aggregator, &update_slave_arr);
-		}
-		bond_3ad_set_carrier(bond);
-	}
-
-	/* for each port run the state machines */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (!port->slave) {
-			net_warn_ratelimited("%s: Warning: Found an uninitialized port\n",
-					    bond->dev->name);
-			goto re_arm;
-		}
-
-		ad_rx_machine(NULL, port);
-		ad_periodic_machine(port);
-		ad_port_selection_logic(port, &update_slave_arr);
-		ad_mux_machine(port, &update_slave_arr);
-		ad_tx_machine(port);
-		ad_churn_machine(port);
-
-		/* turn off the BEGIN bit, since we already handled it */
-		if (port->sm_vars & AD_PORT_BEGIN)
-			port->sm_vars &= ~AD_PORT_BEGIN;
-	}
-
-re_arm:
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->should_notify) {
-			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
-			break;
-		}
-	}
-	rcu_read_unlock();
-	spin_unlock_bh(&bond->mode_lock);
-
-	if (update_slave_arr)
-		bond_slave_arr_work_rearm(bond, 0);
-
-	if (should_notify_rtnl && rtnl_trylock()) {
-		bond_slave_state_notify(bond);
-		rtnl_unlock();
-	}
-	queue_delayed_work(bond->wq, &bond->ad_work, ad_delta_in_ticks);
-}
-
-/**
- * bond_3ad_rx_indication - handle a received frame
- * @lacpdu: received lacpdu
- * @slave: slave struct to work on
- *
- * It is assumed that frames that were sent on this NIC don't returned as new
- * received frames (loopback). Since only the payload is given to this
- * function, it check for loopback.
- */
-static int bond_3ad_rx_indication(struct lacpdu *lacpdu, struct slave *slave)
-{
-	struct bonding *bond = slave->bond;
-	int ret = RX_HANDLER_ANOTHER;
-	struct bond_marker *marker;
-	struct port *port;
-	atomic64_t *stat;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-	if (!port->slave) {
-		net_warn_ratelimited("%s: Warning: port of slave %s is uninitialized\n",
-				     slave->dev->name, slave->bond->dev->name);
-		return ret;
-	}
-
-	switch (lacpdu->subtype) {
-	case AD_TYPE_LACPDU:
-		ret = RX_HANDLER_CONSUMED;
-		slave_dbg(slave->bond->dev, slave->dev,
-			  "Received LACPDU on port %d\n",
-			  port->actor_port_number);
-		/* Protect against concurrent state machines */
-		spin_lock(&slave->bond->mode_lock);
-		ad_rx_machine(lacpdu, port);
-		spin_unlock(&slave->bond->mode_lock);
-		break;
-	case AD_TYPE_MARKER:
-		ret = RX_HANDLER_CONSUMED;
-		/* No need to convert fields to Little Endian since we
-		 * don't use the marker's fields.
-		 */
-		marker = (struct bond_marker *)lacpdu;
-		switch (marker->tlv_type) {
-		case AD_MARKER_INFORMATION_SUBTYPE:
-			slave_dbg(slave->bond->dev, slave->dev, "Received Marker Information on port %d\n",
-				  port->actor_port_number);
-			ad_marker_info_received(marker, port);
-			break;
-		case AD_MARKER_RESPONSE_SUBTYPE:
-			slave_dbg(slave->bond->dev, slave->dev, "Received Marker Response on port %d\n",
-				  port->actor_port_number);
-			ad_marker_response_received(marker, port);
-			break;
-		default:
-			slave_dbg(slave->bond->dev, slave->dev, "Received an unknown Marker subtype on port %d\n",
-				  port->actor_port_number);
-			stat = &SLAVE_AD_INFO(slave)->stats.marker_unknown_rx;
-			atomic64_inc(stat);
-			stat = &BOND_AD_INFO(bond).stats.marker_unknown_rx;
-			atomic64_inc(stat);
-		}
-		break;
-	default:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_unknown_rx);
-		atomic64_inc(&BOND_AD_INFO(bond).stats.lacpdu_unknown_rx);
-	}
-
-	return ret;
-}
-
-/**
- * ad_update_actor_keys - Update the oper / admin keys for a port based on
- * its current speed and duplex settings.
- *
- * @port: the port we'are looking at
- * @reset: Boolean to just reset the speed and the duplex part of the key
- *
- * The logic to change the oper / admin keys is:
- * (a) A full duplex port can participate in LACP with partner.
- * (b) When the speed is changed, LACP need to be reinitiated.
- */
-static void ad_update_actor_keys(struct port *port, bool reset)
-{
-	u8 duplex = 0;
-	u16 ospeed = 0, speed = 0;
-	u16 old_oper_key = port->actor_oper_port_key;
-
-	port->actor_admin_port_key &= ~(AD_SPEED_KEY_MASKS|AD_DUPLEX_KEY_MASKS);
-	if (!reset) {
-		speed = __get_link_speed(port);
-		ospeed = (old_oper_key & AD_SPEED_KEY_MASKS) >> 1;
-		duplex = __get_duplex(port);
-		port->actor_admin_port_key |= (speed << 1) | duplex;
-	}
-	port->actor_oper_port_key = port->actor_admin_port_key;
-
-	if (old_oper_key != port->actor_oper_port_key) {
-		/* Only 'duplex' port participates in LACP */
-		if (duplex)
-			port->sm_vars |= AD_PORT_LACP_ENABLED;
-		else
-			port->sm_vars &= ~AD_PORT_LACP_ENABLED;
-
-		if (!reset) {
-			if (!speed) {
-				slave_err(port->slave->bond->dev,
-					  port->slave->dev,
-					  "speed changed to 0 on port %d\n",
-					  port->actor_port_number);
-			} else if (duplex && ospeed != speed) {
-				/* Speed change restarts LACP state-machine */
-				port->sm_vars |= AD_PORT_BEGIN;
-			}
-		}
-	}
-}
-
-/**
- * bond_3ad_adapter_speed_duplex_changed - handle a slave's speed / duplex
- * change indication
- *
- * @slave: slave struct to work on
- *
- * Handle reselection of aggregator (if needed) for this port.
- */
-void bond_3ad_adapter_speed_duplex_changed(struct slave *slave)
-{
-	struct port *port;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(slave->bond->dev, slave->dev,
-			   "speed/duplex changed for uninitialized port\n");
-		return;
-	}
-
-	spin_lock_bh(&slave->bond->mode_lock);
-	ad_update_actor_keys(port, false);
-	spin_unlock_bh(&slave->bond->mode_lock);
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d changed speed/duplex\n",
-		  port->actor_port_number);
-}
-
-/**
- * bond_3ad_handle_link_change - handle a slave's link status change indication
- * @slave: slave struct to work on
- * @status: whether the link is now up or down
- *
- * Handle reselection of aggregator (if needed) for this port.
- */
-void bond_3ad_handle_link_change(struct slave *slave, char link)
-{
-	struct aggregator *agg;
-	struct port *port;
-	bool dummy;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(slave->bond->dev, slave->dev, "link status changed for uninitialized port\n");
-		return;
-	}
-
-	spin_lock_bh(&slave->bond->mode_lock);
-	/* on link down we are zeroing duplex and speed since
-	 * some of the adaptors(ce1000.lan) report full duplex/speed
-	 * instead of N/A(duplex) / 0(speed).
-	 *
-	 * on link up we are forcing recheck on the duplex and speed since
-	 * some of he adaptors(ce1000.lan) report.
-	 */
-	if (link == BOND_LINK_UP) {
-		port->is_enabled = true;
-		ad_update_actor_keys(port, false);
-	} else {
-		/* link has failed */
-		port->is_enabled = false;
-		ad_update_actor_keys(port, true);
-		toe_failover(netdev_master_upper_dev_get(slave->dev),
-			     slave->dev, TOE_LINK_DOWN, NULL);
-	}
-	agg = __get_first_agg(port);
-	ad_agg_selection_logic(agg, &dummy);
-
-	spin_unlock_bh(&slave->bond->mode_lock);
-
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d changed link status to %s\n",
-		  port->actor_port_number,
-		  link == BOND_LINK_UP ? "UP" : "DOWN");
-
-	/* RTNL is held and mode_lock is released so it's safe
-	 * to update slave_array here.
-	 */
-	bond_update_slave_arr(slave->bond, NULL);
-}
-
-/**
- * bond_3ad_set_carrier - set link state for bonding master
- * @bond - bonding structure
- *
- * if we have an active aggregator, we're up, if not, we're down.
- * Presumes that we cannot have an active aggregator if there are
- * no slaves with link up.
- *
- * This behavior complies with IEEE 802.3 section 43.3.9.
- *
- * Called by bond_set_carrier(). Return zero if carrier state does not
- * change, nonzero if it does.
- */
-int bond_3ad_set_carrier(struct bonding *bond)
-{
-	struct aggregator *active;
-	struct slave *first_slave;
-	int ret = 1;
-
-	rcu_read_lock();
-	first_slave = bond_first_slave_rcu(bond);
-	if (!first_slave) {
-		ret = 0;
-		goto out;
-	}
-	active = __get_active_agg(&(SLAVE_AD_INFO(first_slave)->aggregator));
-	if (active) {
-		/* are enough slaves available to consider link up? */
-		if (__agg_active_ports(active) < bond->params.min_links) {
-			if (netif_carrier_ok(bond->dev)) {
-				netif_carrier_off(bond->dev);
-				goto out;
-			}
-		} else if (!netif_carrier_ok(bond->dev)) {
-			netif_carrier_on(bond->dev);
-			goto out;
-		}
-	} else if (netif_carrier_ok(bond->dev)) {
-		netif_carrier_off(bond->dev);
-	}
-out:
-	rcu_read_unlock();
-	return ret;
-}
-
-/**
- * __bond_3ad_get_active_agg_info - get information of the active aggregator
- * @bond: bonding struct to work on
- * @ad_info: ad_info struct to fill with the bond's info
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-int __bond_3ad_get_active_agg_info(struct bonding *bond,
-				   struct ad_info *ad_info)
-{
-	struct aggregator *aggregator = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (port->aggregator && port->aggregator->is_active) {
-			aggregator = port->aggregator;
-			break;
-		}
-	}
-
-	if (!aggregator)
-		return -1;
-
-	ad_info->aggregator_id = aggregator->aggregator_identifier;
-	ad_info->ports = __agg_active_ports(aggregator);
-	ad_info->actor_key = aggregator->actor_oper_aggregator_key;
-	ad_info->partner_key = aggregator->partner_oper_aggregator_key;
-	ether_addr_copy(ad_info->partner_system,
-			aggregator->partner_system.mac_addr_value);
-	return 0;
-}
-
-int bond_3ad_get_active_agg_info(struct bonding *bond, struct ad_info *ad_info)
-{
-	int ret;
-
-	rcu_read_lock();
-	ret = __bond_3ad_get_active_agg_info(bond, ad_info);
-	rcu_read_unlock();
-
-	return ret;
-}
-
-int bond_3ad_lacpdu_recv(const struct sk_buff *skb, struct bonding *bond,
-			 struct slave *slave)
-{
-	struct lacpdu *lacpdu, _lacpdu;
-
-	if (skb->protocol != PKT_TYPE_LACPDU)
-		return RX_HANDLER_ANOTHER;
-
-	if (!MAC_ADDRESS_EQUAL(eth_hdr(skb)->h_dest, lacpdu_mcast_addr))
-		return RX_HANDLER_ANOTHER;
-
-	lacpdu = skb_header_pointer(skb, 0, sizeof(_lacpdu), &_lacpdu);
-	if (!lacpdu) {
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_illegal_rx);
-		atomic64_inc(&BOND_AD_INFO(bond).stats.lacpdu_illegal_rx);
-		return RX_HANDLER_ANOTHER;
-	}
-
-	return bond_3ad_rx_indication(lacpdu, slave);
-}
-
-/**
- * bond_3ad_update_lacp_rate - change the lacp rate
- * @bond - bonding struct
- *
- * When modify lacp_rate parameter via sysfs,
- * update actor_oper_port_state of each port.
- *
- * Hold bond->mode_lock,
- * so we can modify port->actor_oper_port_state,
- * no matter bond is up or down.
- */
-void bond_3ad_update_lacp_rate(struct bonding *bond)
-{
-	struct port *port = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	int lacp_fast;
-
-	lacp_fast = bond->params.lacp_fast;
-	spin_lock_bh(&bond->mode_lock);
-	bond_for_each_slave(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (lacp_fast)
-			port->actor_oper_port_state |= AD_STATE_LACP_TIMEOUT;
-		else
-			port->actor_oper_port_state &= ~AD_STATE_LACP_TIMEOUT;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-size_t bond_3ad_stats_size(void)
-{
-	return nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_TX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_UNKNOWN_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_ILLEGAL_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_TX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RESP_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RESP_TX */
-	       nla_total_size_64bit(sizeof(u64)); /* BOND_3AD_STAT_MARKER_UNKNOWN_RX */
-}
-
-int bond_3ad_stats_fill(struct sk_buff *skb, struct bond_3ad_stats *stats)
-{
-	u64 val;
-
-	val = atomic64_read(&stats->lacpdu_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_unknown_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_UNKNOWN_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_illegal_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_ILLEGAL_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-
-	val = atomic64_read(&stats->marker_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_resp_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RESP_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_resp_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RESP_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_unknown_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_UNKNOWN_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-
-	return 0;
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.82/bond_alb.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.82/bond_alb.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1811 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
- */
-
-#include <linux/skbuff.h>
-#include <linux/netdevice.h>
-#include <linux/etherdevice.h>
-#include <linux/pkt_sched.h>
-#include <linux/spinlock.h>
-#include <linux/slab.h>
-#include <linux/timer.h>
-#include <linux/ip.h>
-#include <linux/ipv6.h>
-#include <linux/if_arp.h>
-#include <linux/if_ether.h>
-#include <linux/if_bonding.h>
-#include <linux/if_vlan.h>
-#include <linux/in.h>
-#include <net/ipx.h>
-#include <net/arp.h>
-#include <net/ipv6.h>
-#include <asm/byteorder.h>
-#include <net/bonding.h>
-#include <net/bond_alb.h>
-
-static const u8 mac_v6_allmcast[ETH_ALEN + 2] __long_aligned = {
-	0x33, 0x33, 0x00, 0x00, 0x00, 0x01
-};
-static const int alb_delta_in_ticks = HZ / ALB_TIMER_TICKS_PER_SEC;
-
-#pragma pack(1)
-struct learning_pkt {
-	u8 mac_dst[ETH_ALEN];
-	u8 mac_src[ETH_ALEN];
-	__be16 type;
-	u8 padding[ETH_ZLEN - ETH_HLEN];
-};
-
-struct arp_pkt {
-	__be16  hw_addr_space;
-	__be16  prot_addr_space;
-	u8      hw_addr_len;
-	u8      prot_addr_len;
-	__be16  op_code;
-	u8      mac_src[ETH_ALEN];	/* sender hardware address */
-	__be32  ip_src;			/* sender IP address */
-	u8      mac_dst[ETH_ALEN];	/* target hardware address */
-	__be32  ip_dst;			/* target IP address */
-};
-#pragma pack()
-
-/* Forward declaration */
-static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
-				      bool strict_match);
-static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp);
-static void rlb_src_unlink(struct bonding *bond, u32 index);
-static void rlb_src_link(struct bonding *bond, u32 ip_src_hash,
-			 u32 ip_dst_hash);
-
-static inline u8 _simple_hash(const u8 *hash_start, int hash_size)
-{
-	int i;
-	u8 hash = 0;
-
-	for (i = 0; i < hash_size; i++)
-		hash ^= hash_start[i];
-
-	return hash;
-}
-
-/*********************** tlb specific functions ***************************/
-
-static inline void tlb_init_table_entry(struct tlb_client_info *entry, int save_load)
-{
-	if (save_load) {
-		entry->load_history = 1 + entry->tx_bytes /
-				      BOND_TLB_REBALANCE_INTERVAL;
-		entry->tx_bytes = 0;
-	}
-
-	entry->tx_slave = NULL;
-	entry->next = TLB_NULL_INDEX;
-	entry->prev = TLB_NULL_INDEX;
-}
-
-static inline void tlb_init_slave(struct slave *slave)
-{
-	SLAVE_TLB_INFO(slave).load = 0;
-	SLAVE_TLB_INFO(slave).head = TLB_NULL_INDEX;
-}
-
-static void __tlb_clear_slave(struct bonding *bond, struct slave *slave,
-			 int save_load)
-{
-	struct tlb_client_info *tx_hash_table;
-	u32 index;
-
-	/* clear slave from tx_hashtbl */
-	tx_hash_table = BOND_ALB_INFO(bond).tx_hashtbl;
-
-	/* skip this if we've already freed the tx hash table */
-	if (tx_hash_table) {
-		index = SLAVE_TLB_INFO(slave).head;
-		while (index != TLB_NULL_INDEX) {
-			u32 next_index = tx_hash_table[index].next;
-			tlb_init_table_entry(&tx_hash_table[index], save_load);
-			index = next_index;
-		}
-	}
-
-	tlb_init_slave(slave);
-}
-
-static void tlb_clear_slave(struct bonding *bond, struct slave *slave,
-			 int save_load)
-{
-	spin_lock_bh(&bond->mode_lock);
-	__tlb_clear_slave(bond, slave, save_load);
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* Must be called before starting the monitor timer */
-static int tlb_initialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	int size = TLB_HASH_TABLE_SIZE * sizeof(struct tlb_client_info);
-	struct tlb_client_info *new_hashtbl;
-	int i;
-
-	new_hashtbl = kzalloc(size, GFP_KERNEL);
-	if (!new_hashtbl)
-		return -ENOMEM;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	bond_info->tx_hashtbl = new_hashtbl;
-
-	for (i = 0; i < TLB_HASH_TABLE_SIZE; i++)
-		tlb_init_table_entry(&bond_info->tx_hashtbl[i], 0);
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	return 0;
-}
-
-/* Must be called only after all slaves have been released */
-static void tlb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	spin_lock_bh(&bond->mode_lock);
-
-	kfree(bond_info->tx_hashtbl);
-	bond_info->tx_hashtbl = NULL;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static long long compute_gap(struct slave *slave)
-{
-	return (s64) (slave->speed << 20) - /* Convert to Megabit per sec */
-	       (s64) (SLAVE_TLB_INFO(slave).load << 3); /* Bytes to bits */
-}
-
-static struct slave *tlb_get_least_loaded_slave(struct bonding *bond)
-{
-	struct slave *slave, *least_loaded;
-	struct list_head *iter;
-	long long max_gap;
-
-	least_loaded = NULL;
-	max_gap = LLONG_MIN;
-
-	/* Find the slave with the largest gap */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (bond_slave_can_tx(slave)) {
-			long long gap = compute_gap(slave);
-
-			if (max_gap < gap) {
-				least_loaded = slave;
-				max_gap = gap;
-			}
-		}
-	}
-
-	return least_loaded;
-}
-
-static struct slave *__tlb_choose_channel(struct bonding *bond, u32 hash_index,
-						u32 skb_len)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct tlb_client_info *hash_table;
-	struct slave *assigned_slave;
-
-	hash_table = bond_info->tx_hashtbl;
-	assigned_slave = hash_table[hash_index].tx_slave;
-	if (!assigned_slave) {
-		assigned_slave = tlb_get_least_loaded_slave(bond);
-
-		if (assigned_slave) {
-			struct tlb_slave_info *slave_info =
-				&(SLAVE_TLB_INFO(assigned_slave));
-			u32 next_index = slave_info->head;
-
-			hash_table[hash_index].tx_slave = assigned_slave;
-			hash_table[hash_index].next = next_index;
-			hash_table[hash_index].prev = TLB_NULL_INDEX;
-
-			if (next_index != TLB_NULL_INDEX)
-				hash_table[next_index].prev = hash_index;
-
-			slave_info->head = hash_index;
-			slave_info->load +=
-				hash_table[hash_index].load_history;
-		}
-	}
-
-	if (assigned_slave)
-		hash_table[hash_index].tx_bytes += skb_len;
-
-	return assigned_slave;
-}
-
-static struct slave *tlb_choose_channel(struct bonding *bond, u32 hash_index,
-					u32 skb_len)
-{
-	struct slave *tx_slave;
-
-	/* We don't need to disable softirq here, becase
-	 * tlb_choose_channel() is only called by bond_alb_xmit()
-	 * which already has softirq disabled.
-	 */
-	spin_lock(&bond->mode_lock);
-	tx_slave = __tlb_choose_channel(bond, hash_index, skb_len);
-	spin_unlock(&bond->mode_lock);
-
-	return tx_slave;
-}
-
-/*********************** rlb specific functions ***************************/
-
-/* when an ARP REPLY is received from a client update its info
- * in the rx_hashtbl
- */
-static void rlb_update_entry_from_arp(struct bonding *bond, struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
-	client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-	if ((client_info->assigned) &&
-	    (client_info->ip_src == arp->ip_dst) &&
-	    (client_info->ip_dst == arp->ip_src) &&
-	    (!ether_addr_equal_64bits(client_info->mac_dst, arp->mac_src))) {
-		/* update the clients MAC address */
-		ether_addr_copy(client_info->mac_dst, arp->mac_src);
-		client_info->ntt = 1;
-		bond_info->rx_ntt = 1;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static int rlb_arp_recv(const struct sk_buff *skb, struct bonding *bond,
-			struct slave *slave)
-{
-	struct arp_pkt *arp, _arp;
-
-	if (skb->protocol != cpu_to_be16(ETH_P_ARP))
-		goto out;
-
-	arp = skb_header_pointer(skb, 0, sizeof(_arp), &_arp);
-	if (!arp)
-		goto out;
-
-	/* We received an ARP from arp->ip_src.
-	 * We might have used this IP address previously (on the bonding host
-	 * itself or on a system that is bridged together with the bond).
-	 * However, if arp->mac_src is different than what is stored in
-	 * rx_hashtbl, some other host is now using the IP and we must prevent
-	 * sending out client updates with this IP address and the old MAC
-	 * address.
-	 * Clean up all hash table entries that have this address as ip_src but
-	 * have a different mac_src.
-	 */
-	rlb_purge_src_ip(bond, arp);
-
-	if (arp->op_code == htons(ARPOP_REPLY)) {
-		/* update rx hash table for this ARP */
-		rlb_update_entry_from_arp(bond, arp);
-		slave_dbg(bond->dev, slave->dev, "Server received an ARP Reply from client\n");
-	}
-out:
-	return RX_HANDLER_ANOTHER;
-}
-
-/* Caller must hold rcu_read_lock() */
-static struct slave *__rlb_next_rx_slave(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *before = NULL, *rx_slave = NULL, *slave;
-	struct list_head *iter;
-	bool found = false;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!bond_slave_can_tx(slave))
-			continue;
-		if (!found) {
-			if (!before || before->speed < slave->speed)
-				before = slave;
-		} else {
-			if (!rx_slave || rx_slave->speed < slave->speed)
-				rx_slave = slave;
-		}
-		if (slave == bond_info->rx_slave)
-			found = true;
-	}
-	/* we didn't find anything after the current or we have something
-	 * better before and up to the current slave
-	 */
-	if (!rx_slave || (before && rx_slave->speed < before->speed))
-		rx_slave = before;
-
-	if (rx_slave)
-		bond_info->rx_slave = rx_slave;
-
-	return rx_slave;
-}
-
-/* Caller must hold RTNL, rcu_read_lock is obtained only to silence checkers */
-static struct slave *rlb_next_rx_slave(struct bonding *bond)
-{
-	struct slave *rx_slave;
-
-	ASSERT_RTNL();
-
-	rcu_read_lock();
-	rx_slave = __rlb_next_rx_slave(bond);
-	rcu_read_unlock();
-
-	return rx_slave;
-}
-
-/* teach the switch the mac of a disabled slave
- * on the primary for fault tolerance
- *
- * Caller must hold RTNL
- */
-static void rlb_teach_disabled_mac_on_primary(struct bonding *bond, u8 addr[])
-{
-	struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-	if (!curr_active)
-		return;
-
-	if (!bond->alb_info.primary_is_promisc) {
-		if (!dev_set_promiscuity(curr_active->dev, 1))
-			bond->alb_info.primary_is_promisc = 1;
-		else
-			bond->alb_info.primary_is_promisc = 0;
-	}
-
-	bond->alb_info.rlb_promisc_timeout_counter = 0;
-
-	alb_send_learning_packets(curr_active, addr, true);
-}
-
-/* slave being removed should not be active at this point
- *
- * Caller must hold rtnl.
- */
-static void rlb_clear_slave(struct bonding *bond, struct slave *slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *rx_hash_table;
-	u32 index, next_index;
-
-	/* clear slave from rx_hashtbl */
-	spin_lock_bh(&bond->mode_lock);
-
-	rx_hash_table = bond_info->rx_hashtbl;
-	index = bond_info->rx_hashtbl_used_head;
-	for (; index != RLB_NULL_INDEX; index = next_index) {
-		next_index = rx_hash_table[index].used_next;
-		if (rx_hash_table[index].slave == slave) {
-			struct slave *assigned_slave = rlb_next_rx_slave(bond);
-
-			if (assigned_slave) {
-				rx_hash_table[index].slave = assigned_slave;
-				if (is_valid_ether_addr(rx_hash_table[index].mac_dst)) {
-					bond_info->rx_hashtbl[index].ntt = 1;
-					bond_info->rx_ntt = 1;
-					/* A slave has been removed from the
-					 * table because it is either disabled
-					 * or being released. We must retry the
-					 * update to avoid clients from not
-					 * being updated & disconnecting when
-					 * there is stress
-					 */
-					bond_info->rlb_update_retry_counter =
-						RLB_UPDATE_RETRY;
-				}
-			} else {  /* there is no active slave */
-				rx_hash_table[index].slave = NULL;
-			}
-		}
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	if (slave != rtnl_dereference(bond->curr_active_slave))
-		rlb_teach_disabled_mac_on_primary(bond, slave->dev->dev_addr);
-}
-
-static void rlb_update_client(struct rlb_client_info *client_info)
-{
-	int i;
-
-	if (!client_info->slave || !is_valid_ether_addr(client_info->mac_dst))
-		return;
-
-	for (i = 0; i < RLB_ARP_BURST_SIZE; i++) {
-		struct sk_buff *skb;
-
-		skb = arp_create(ARPOP_REPLY, ETH_P_ARP,
-				 client_info->ip_dst,
-				 client_info->slave->dev,
-				 client_info->ip_src,
-				 client_info->mac_dst,
-				 client_info->slave->dev->dev_addr,
-				 client_info->mac_dst);
-		if (!skb) {
-			slave_err(client_info->slave->bond->dev,
-				  client_info->slave->dev,
-				  "failed to create an ARP packet\n");
-			continue;
-		}
-
-		skb->dev = client_info->slave->dev;
-
-		if (client_info->vlan_id) {
-			__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),
-					       client_info->vlan_id);
-		}
-
-		arp_xmit(skb);
-	}
-}
-
-/* sends ARP REPLIES that update the clients that need updating */
-static void rlb_update_rx_clients(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		if (client_info->ntt) {
-			rlb_update_client(client_info);
-			if (bond_info->rlb_update_retry_counter == 0)
-				client_info->ntt = 0;
-		}
-	}
-
-	/* do not update the entries again until this counter is zero so that
-	 * not to confuse the clients.
-	 */
-	bond_info->rlb_update_delay_counter = RLB_UPDATE_DELAY;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* The slave was assigned a new mac address - update the clients */
-static void rlb_req_update_slave_clients(struct bonding *bond, struct slave *slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	int ntt = 0;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-		if ((client_info->slave == slave) &&
-		    is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			ntt = 1;
-		}
-	}
-
-	/* update the team's flag only after the whole iteration */
-	if (ntt) {
-		bond_info->rx_ntt = 1;
-		/* fasten the change */
-		bond_info->rlb_update_retry_counter = RLB_UPDATE_RETRY;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* mark all clients using src_ip to be updated */
-static void rlb_req_update_subnet_clients(struct bonding *bond, __be32 src_ip)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-		if (!client_info->slave) {
-			netdev_err(bond->dev, "found a client with no channel in the client's hash table\n");
-			continue;
-		}
-		/* update all clients using this src_ip, that are not assigned
-		 * to the team's address (curr_active_slave) and have a known
-		 * unicast mac address.
-		 */
-		if ((client_info->ip_src == src_ip) &&
-		    !ether_addr_equal_64bits(client_info->slave->dev->dev_addr,
-					     bond->dev->dev_addr) &&
-		    is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			bond_info->rx_ntt = 1;
-		}
-	}
-
-	spin_unlock(&bond->mode_lock);
-}
-
-static struct slave *rlb_choose_channel(struct sk_buff *skb,
-					struct bonding *bond,
-					const struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *assigned_slave, *curr_active_slave;
-	struct rlb_client_info *client_info;
-	u32 hash_index = 0;
-
-	spin_lock(&bond->mode_lock);
-
-	curr_active_slave = rcu_dereference(bond->curr_active_slave);
-
-	hash_index = _simple_hash((u8 *)&arp->ip_dst, sizeof(arp->ip_dst));
-	client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-	if (client_info->assigned) {
-		if ((client_info->ip_src == arp->ip_src) &&
-		    (client_info->ip_dst == arp->ip_dst)) {
-			/* the entry is already assigned to this client */
-			if (!is_broadcast_ether_addr(arp->mac_dst)) {
-				/* update mac address from arp */
-				ether_addr_copy(client_info->mac_dst, arp->mac_dst);
-			}
-			ether_addr_copy(client_info->mac_src, arp->mac_src);
-
-			assigned_slave = client_info->slave;
-			if (assigned_slave) {
-				spin_unlock(&bond->mode_lock);
-				return assigned_slave;
-			}
-		} else {
-			/* the entry is already assigned to some other client,
-			 * move the old client to primary (curr_active_slave) so
-			 * that the new client can be assigned to this entry.
-			 */
-			if (curr_active_slave &&
-			    client_info->slave != curr_active_slave) {
-				client_info->slave = curr_active_slave;
-				rlb_update_client(client_info);
-			}
-		}
-	}
-	/* assign a new slave */
-	assigned_slave = __rlb_next_rx_slave(bond);
-
-	if (assigned_slave) {
-		if (!(client_info->assigned &&
-		      client_info->ip_src == arp->ip_src)) {
-			/* ip_src is going to be updated,
-			 * fix the src hash list
-			 */
-			u32 hash_src = _simple_hash((u8 *)&arp->ip_src,
-						    sizeof(arp->ip_src));
-			rlb_src_unlink(bond, hash_index);
-			rlb_src_link(bond, hash_src, hash_index);
-		}
-
-		client_info->ip_src = arp->ip_src;
-		client_info->ip_dst = arp->ip_dst;
-		/* arp->mac_dst is broadcast for arp reqeusts.
-		 * will be updated with clients actual unicast mac address
-		 * upon receiving an arp reply.
-		 */
-		ether_addr_copy(client_info->mac_dst, arp->mac_dst);
-		ether_addr_copy(client_info->mac_src, arp->mac_src);
-		client_info->slave = assigned_slave;
-
-		if (is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			bond->alb_info.rx_ntt = 1;
-		} else {
-			client_info->ntt = 0;
-		}
-
-		if (vlan_get_tag(skb, &client_info->vlan_id))
-			client_info->vlan_id = 0;
-
-		if (!client_info->assigned) {
-			u32 prev_tbl_head = bond_info->rx_hashtbl_used_head;
-			bond_info->rx_hashtbl_used_head = hash_index;
-			client_info->used_next = prev_tbl_head;
-			if (prev_tbl_head != RLB_NULL_INDEX) {
-				bond_info->rx_hashtbl[prev_tbl_head].used_prev =
-					hash_index;
-			}
-			client_info->assigned = 1;
-		}
-	}
-
-	spin_unlock(&bond->mode_lock);
-
-	return assigned_slave;
-}
-
-/* chooses (and returns) transmit channel for arp reply
- * does not choose channel for other arp types since they are
- * sent on the curr_active_slave
- */
-static struct slave *rlb_arp_xmit(struct sk_buff *skb, struct bonding *bond)
-{
-	struct slave *tx_slave = NULL;
-	struct arp_pkt *arp;
-
-	if (!pskb_network_may_pull(skb, sizeof(*arp)))
-		return NULL;
-	arp = (struct arp_pkt *)skb_network_header(skb);
-
-	/* Don't modify or load balance ARPs that do not originate locally
-	 * (e.g.,arrive via a bridge).
-	 */
-	if (!bond_slave_has_mac_rx(bond, arp->mac_src))
-		return NULL;
-
-	if (arp->op_code == htons(ARPOP_REPLY)) {
-		/* the arp must be sent on the selected rx channel */
-		tx_slave = rlb_choose_channel(skb, bond, arp);
-		if (tx_slave)
-			bond_hw_addr_copy(arp->mac_src, tx_slave->dev->dev_addr,
-					  tx_slave->dev->addr_len);
-		netdev_dbg(bond->dev, "(slave %s): Server sent ARP Reply packet\n",
-			   tx_slave ? tx_slave->dev->name : "NULL");
-	} else if (arp->op_code == htons(ARPOP_REQUEST)) {
-		/* Create an entry in the rx_hashtbl for this client as a
-		 * place holder.
-		 * When the arp reply is received the entry will be updated
-		 * with the correct unicast address of the client.
-		 */
-		tx_slave = rlb_choose_channel(skb, bond, arp);
-
-		/* The ARP reply packets must be delayed so that
-		 * they can cancel out the influence of the ARP request.
-		 */
-		bond->alb_info.rlb_update_delay_counter = RLB_UPDATE_DELAY;
-
-		/* arp requests are broadcast and are sent on the primary
-		 * the arp request will collapse all clients on the subnet to
-		 * the primary slave. We must register these clients to be
-		 * updated with their assigned mac.
-		 */
-		rlb_req_update_subnet_clients(bond, arp->ip_src);
-		netdev_dbg(bond->dev, "(slave %s): Server sent ARP Request packet\n",
-			   tx_slave ? tx_slave->dev->name : "NULL");
-	}
-
-	return tx_slave;
-}
-
-static void rlb_rebalance(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *assigned_slave;
-	struct rlb_client_info *client_info;
-	int ntt;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	ntt = 0;
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		assigned_slave = __rlb_next_rx_slave(bond);
-		if (assigned_slave && (client_info->slave != assigned_slave)) {
-			client_info->slave = assigned_slave;
-			if (!is_zero_ether_addr(client_info->mac_dst)) {
-				client_info->ntt = 1;
-				ntt = 1;
-			}
-		}
-	}
-
-	/* update the team's flag only after the whole iteration */
-	if (ntt)
-		bond_info->rx_ntt = 1;
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* Caller must hold mode_lock */
-static void rlb_init_table_entry_dst(struct rlb_client_info *entry)
-{
-	entry->used_next = RLB_NULL_INDEX;
-	entry->used_prev = RLB_NULL_INDEX;
-	entry->assigned = 0;
-	entry->slave = NULL;
-	entry->vlan_id = 0;
-}
-static void rlb_init_table_entry_src(struct rlb_client_info *entry)
-{
-	entry->src_first = RLB_NULL_INDEX;
-	entry->src_prev = RLB_NULL_INDEX;
-	entry->src_next = RLB_NULL_INDEX;
-}
-
-static void rlb_init_table_entry(struct rlb_client_info *entry)
-{
-	memset(entry, 0, sizeof(struct rlb_client_info));
-	rlb_init_table_entry_dst(entry);
-	rlb_init_table_entry_src(entry);
-}
-
-static void rlb_delete_table_entry_dst(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next_index = bond_info->rx_hashtbl[index].used_next;
-	u32 prev_index = bond_info->rx_hashtbl[index].used_prev;
-
-	if (index == bond_info->rx_hashtbl_used_head)
-		bond_info->rx_hashtbl_used_head = next_index;
-	if (prev_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[prev_index].used_next = next_index;
-	if (next_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next_index].used_prev = prev_index;
-}
-
-/* unlink a rlb hash table entry from the src list */
-static void rlb_src_unlink(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next_index = bond_info->rx_hashtbl[index].src_next;
-	u32 prev_index = bond_info->rx_hashtbl[index].src_prev;
-
-	bond_info->rx_hashtbl[index].src_next = RLB_NULL_INDEX;
-	bond_info->rx_hashtbl[index].src_prev = RLB_NULL_INDEX;
-
-	if (next_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next_index].src_prev = prev_index;
-
-	if (prev_index == RLB_NULL_INDEX)
-		return;
-
-	/* is prev_index pointing to the head of this list? */
-	if (bond_info->rx_hashtbl[prev_index].src_first == index)
-		bond_info->rx_hashtbl[prev_index].src_first = next_index;
-	else
-		bond_info->rx_hashtbl[prev_index].src_next = next_index;
-
-}
-
-static void rlb_delete_table_entry(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
-
-	rlb_delete_table_entry_dst(bond, index);
-	rlb_init_table_entry_dst(entry);
-
-	rlb_src_unlink(bond, index);
-}
-
-/* add the rx_hashtbl[ip_dst_hash] entry to the list
- * of entries with identical ip_src_hash
- */
-static void rlb_src_link(struct bonding *bond, u32 ip_src_hash, u32 ip_dst_hash)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next;
-
-	bond_info->rx_hashtbl[ip_dst_hash].src_prev = ip_src_hash;
-	next = bond_info->rx_hashtbl[ip_src_hash].src_first;
-	bond_info->rx_hashtbl[ip_dst_hash].src_next = next;
-	if (next != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next].src_prev = ip_dst_hash;
-	bond_info->rx_hashtbl[ip_src_hash].src_first = ip_dst_hash;
-}
-
-/* deletes all rx_hashtbl entries with arp->ip_src if their mac_src does
- * not match arp->mac_src
- */
-static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 ip_src_hash = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
-	u32 index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	index = bond_info->rx_hashtbl[ip_src_hash].src_first;
-	while (index != RLB_NULL_INDEX) {
-		struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
-		u32 next_index = entry->src_next;
-		if (entry->ip_src == arp->ip_src &&
-		    !ether_addr_equal_64bits(arp->mac_src, entry->mac_src))
-				rlb_delete_table_entry(bond, index);
-		index = next_index;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static int rlb_initialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info	*new_hashtbl;
-	int size = RLB_HASH_TABLE_SIZE * sizeof(struct rlb_client_info);
-	int i;
-
-	new_hashtbl = kmalloc(size, GFP_KERNEL);
-	if (!new_hashtbl)
-		return -1;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	bond_info->rx_hashtbl = new_hashtbl;
-
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	for (i = 0; i < RLB_HASH_TABLE_SIZE; i++)
-		rlb_init_table_entry(bond_info->rx_hashtbl + i);
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	/* register to receive ARPs */
-	bond->recv_probe = rlb_arp_recv;
-
-	return 0;
-}
-
-static void rlb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	spin_lock_bh(&bond->mode_lock);
-
-	kfree(bond_info->rx_hashtbl);
-	bond_info->rx_hashtbl = NULL;
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static void rlb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 curr_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	curr_index = bond_info->rx_hashtbl_used_head;
-	while (curr_index != RLB_NULL_INDEX) {
-		struct rlb_client_info *curr = &(bond_info->rx_hashtbl[curr_index]);
-		u32 next_index = bond_info->rx_hashtbl[curr_index].used_next;
-
-		if (curr->vlan_id == vlan_id)
-			rlb_delete_table_entry(bond, curr_index);
-
-		curr_index = next_index;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/*********************** tlb/rlb shared functions *********************/
-
-static void alb_send_lp_vid(struct slave *slave, u8 mac_addr[],
-			    __be16 vlan_proto, u16 vid)
-{
-	struct learning_pkt pkt;
-	struct sk_buff *skb;
-	int size = sizeof(struct learning_pkt);
-
-	memset(&pkt, 0, size);
-	ether_addr_copy(pkt.mac_dst, mac_addr);
-	ether_addr_copy(pkt.mac_src, mac_addr);
-	pkt.type = cpu_to_be16(ETH_P_LOOPBACK);
-
-	skb = dev_alloc_skb(size);
-	if (!skb)
-		return;
-
-	skb_put_data(skb, &pkt, size);
-
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = pkt.type;
-	skb->priority = TC_PRIO_CONTROL;
-	skb->dev = slave->dev;
-
-	slave_dbg(slave->bond->dev, slave->dev,
-		  "Send learning packet: mac %pM vlan %d\n", mac_addr, vid);
-
-	if (vid)
-		__vlan_hwaccel_put_tag(skb, vlan_proto, vid);
-
-	dev_queue_xmit(skb);
-}
-
-struct alb_walk_data {
-	struct bonding *bond;
-	struct slave *slave;
-	u8 *mac_addr;
-	bool strict_match;
-};
-
-static int alb_upper_dev_walk(struct net_device *upper, void *_data)
-{
-	struct alb_walk_data *data = _data;
-	bool strict_match = data->strict_match;
-	struct bonding *bond = data->bond;
-	struct slave *slave = data->slave;
-	u8 *mac_addr = data->mac_addr;
-	struct bond_vlan_tag *tags;
-
-	if (is_vlan_dev(upper) &&
-	    bond->dev->lower_level == upper->lower_level - 1) {
-		if (upper->addr_assign_type == NET_ADDR_STOLEN) {
-			alb_send_lp_vid(slave, mac_addr,
-					vlan_dev_vlan_proto(upper),
-					vlan_dev_vlan_id(upper));
-		} else {
-			alb_send_lp_vid(slave, upper->dev_addr,
-					vlan_dev_vlan_proto(upper),
-					vlan_dev_vlan_id(upper));
-		}
-	}
-
-	/* If this is a macvlan device, then only send updates
-	 * when strict_match is turned off.
-	 */
-	if (netif_is_macvlan(upper) && !strict_match) {
-		tags = bond_verify_device_path(bond->dev, upper, 0);
-		if (IS_ERR_OR_NULL(tags))
-			BUG();
-		alb_send_lp_vid(slave, upper->dev_addr,
-				tags[0].vlan_proto, tags[0].vlan_id);
-		kfree(tags);
-	}
-
-	return 0;
-}
-
-static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
-				      bool strict_match)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-	struct alb_walk_data data = {
-		.strict_match = strict_match,
-		.mac_addr = mac_addr,
-		.slave = slave,
-		.bond = bond,
-	};
-
-	/* send untagged */
-	alb_send_lp_vid(slave, mac_addr, 0, 0);
-
-	/* loop through all devices and see if we need to send a packet
-	 * for that device.
-	 */
-	rcu_read_lock();
-	netdev_walk_all_upper_dev_rcu(bond->dev, alb_upper_dev_walk, &data);
-	rcu_read_unlock();
-}
-
-static int alb_set_slave_mac_addr(struct slave *slave, u8 addr[],
-				  unsigned int len)
-{
-	struct net_device *dev = slave->dev;
-	struct sockaddr_storage ss;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_TLB) {
-		memcpy(dev->dev_addr, addr, len);
-		return 0;
-	}
-
-	/* for rlb each slave must have a unique hw mac addresses so that
-	 * each slave will receive packets destined to a different mac
-	 */
-	memcpy(ss.__data, addr, len);
-	ss.ss_family = dev->type;
-	if (dev_set_mac_address(dev, (struct sockaddr *)&ss, NULL)) {
-		slave_err(slave->bond->dev, dev, "dev_set_mac_address on slave failed! ALB mode requires that the base driver support setting the hw address also when the network device's interface is open\n");
-		return -EOPNOTSUPP;
-	}
-	return 0;
-}
-
-/* Swap MAC addresses between two slaves.
- *
- * Called with RTNL held, and no other locks.
- */
-static void alb_swap_mac_addr(struct slave *slave1, struct slave *slave2)
-{
-	u8 tmp_mac_addr[MAX_ADDR_LEN];
-
-	bond_hw_addr_copy(tmp_mac_addr, slave1->dev->dev_addr,
-			  slave1->dev->addr_len);
-	alb_set_slave_mac_addr(slave1, slave2->dev->dev_addr,
-			       slave2->dev->addr_len);
-	alb_set_slave_mac_addr(slave2, tmp_mac_addr,
-			       slave1->dev->addr_len);
-
-}
-
-/* Send learning packets after MAC address swap.
- *
- * Called with RTNL and no other locks
- */
-static void alb_fasten_mac_swap(struct bonding *bond, struct slave *slave1,
-				struct slave *slave2)
-{
-	int slaves_state_differ = (bond_slave_can_tx(slave1) != bond_slave_can_tx(slave2));
-	struct slave *disabled_slave = NULL;
-
-	ASSERT_RTNL();
-
-	/* fasten the change in the switch */
-	if (bond_slave_can_tx(slave1)) {
-		alb_send_learning_packets(slave1, slave1->dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform the clients that the mac address
-			 * has changed
-			 */
-			rlb_req_update_slave_clients(bond, slave1);
-		}
-	} else {
-		disabled_slave = slave1;
-	}
-
-	if (bond_slave_can_tx(slave2)) {
-		alb_send_learning_packets(slave2, slave2->dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform the clients that the mac address
-			 * has changed
-			 */
-			rlb_req_update_slave_clients(bond, slave2);
-		}
-	} else {
-		disabled_slave = slave2;
-	}
-
-	if (bond->alb_info.rlb_enabled && slaves_state_differ) {
-		/* A disabled slave was assigned an active mac addr */
-		rlb_teach_disabled_mac_on_primary(bond,
-						  disabled_slave->dev->dev_addr);
-	}
-}
-
-/**
- * alb_change_hw_addr_on_detach
- * @bond: bonding we're working on
- * @slave: the slave that was just detached
- *
- * We assume that @slave was already detached from the slave list.
- *
- * If @slave's permanent hw address is different both from its current
- * address and from @bond's address, then somewhere in the bond there's
- * a slave that has @slave's permanet address as its current address.
- * We'll make sure that that slave no longer uses @slave's permanent address.
- *
- * Caller must hold RTNL and no other locks
- */
-static void alb_change_hw_addr_on_detach(struct bonding *bond, struct slave *slave)
-{
-	int perm_curr_diff;
-	int perm_bond_diff;
-	struct slave *found_slave;
-
-	perm_curr_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
-						  slave->dev->dev_addr);
-	perm_bond_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
-						  bond->dev->dev_addr);
-
-	if (perm_curr_diff && perm_bond_diff) {
-		found_slave = bond_slave_has_mac(bond, slave->perm_hwaddr);
-
-		if (found_slave) {
-			alb_swap_mac_addr(slave, found_slave);
-			alb_fasten_mac_swap(bond, slave, found_slave);
-		}
-	}
-}
-
-/**
- * alb_handle_addr_collision_on_attach
- * @bond: bonding we're working on
- * @slave: the slave that was just attached
- *
- * checks uniqueness of slave's mac address and handles the case the
- * new slave uses the bonds mac address.
- *
- * If the permanent hw address of @slave is @bond's hw address, we need to
- * find a different hw address to give @slave, that isn't in use by any other
- * slave in the bond. This address must be, of course, one of the permanent
- * addresses of the other slaves.
- *
- * We go over the slave list, and for each slave there we compare its
- * permanent hw address with the current address of all the other slaves.
- * If no match was found, then we've found a slave with a permanent address
- * that isn't used by any other slave in the bond, so we can assign it to
- * @slave.
- *
- * assumption: this function is called before @slave is attached to the
- *	       bond slave list.
- */
-static int alb_handle_addr_collision_on_attach(struct bonding *bond, struct slave *slave)
-{
-	struct slave *has_bond_addr = rcu_access_pointer(bond->curr_active_slave);
-	struct slave *tmp_slave1, *free_mac_slave = NULL;
-	struct list_head *iter;
-
-	if (!bond_has_slaves(bond)) {
-		/* this is the first slave */
-		return 0;
-	}
-
-	/* if slave's mac address differs from bond's mac address
-	 * check uniqueness of slave's mac address against the other
-	 * slaves in the bond.
-	 */
-	if (!ether_addr_equal_64bits(slave->perm_hwaddr, bond->dev->dev_addr)) {
-		if (!bond_slave_has_mac(bond, slave->dev->dev_addr))
-			return 0;
-
-		/* Try setting slave mac to bond address and fall-through
-		 * to code handling that situation below...
-		 */
-		alb_set_slave_mac_addr(slave, bond->dev->dev_addr,
-				       bond->dev->addr_len);
-	}
-
-	/* The slave's address is equal to the address of the bond.
-	 * Search for a spare address in the bond for this slave.
-	 */
-	bond_for_each_slave(bond, tmp_slave1, iter) {
-		if (!bond_slave_has_mac(bond, tmp_slave1->perm_hwaddr)) {
-			/* no slave has tmp_slave1's perm addr
-			 * as its curr addr
-			 */
-			free_mac_slave = tmp_slave1;
-			break;
-		}
-
-		if (!has_bond_addr) {
-			if (ether_addr_equal_64bits(tmp_slave1->dev->dev_addr,
-						    bond->dev->dev_addr)) {
-
-				has_bond_addr = tmp_slave1;
-			}
-		}
-	}
-
-	if (free_mac_slave) {
-		alb_set_slave_mac_addr(slave, free_mac_slave->perm_hwaddr,
-				       free_mac_slave->dev->addr_len);
-
-		slave_warn(bond->dev, slave->dev, "the slave hw address is in use by the bond; giving it the hw address of %s\n",
-			   free_mac_slave->dev->name);
-
-	} else if (has_bond_addr) {
-		slave_err(bond->dev, slave->dev, "the slave hw address is in use by the bond; couldn't find a slave with a free hw address to give it (this should not have happened)\n");
-		return -EFAULT;
-	}
-
-	return 0;
-}
-
-/**
- * alb_set_mac_address
- * @bond:
- * @addr:
- *
- * In TLB mode all slaves are configured to the bond's hw address, but set
- * their dev_addr field to different addresses (based on their permanent hw
- * addresses).
- *
- * For each slave, this function sets the interface to the new address and then
- * changes its dev_addr field to its previous value.
- *
- * Unwinding assumes bond's mac address has not yet changed.
- */
-static int alb_set_mac_address(struct bonding *bond, void *addr)
-{
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	struct sockaddr_storage ss;
-	char tmp_addr[MAX_ADDR_LEN];
-	int res;
-
-	if (bond->alb_info.rlb_enabled)
-		return 0;
-
-	bond_for_each_slave(bond, slave, iter) {
-		/* save net_device's current hw address */
-		bond_hw_addr_copy(tmp_addr, slave->dev->dev_addr,
-				  slave->dev->addr_len);
-
-		res = dev_set_mac_address(slave->dev, addr, NULL);
-
-		/* restore net_device's hw address */
-		bond_hw_addr_copy(slave->dev->dev_addr, tmp_addr,
-				  slave->dev->addr_len);
-
-		if (res)
-			goto unwind;
-	}
-
-	return 0;
-
-unwind:
-	memcpy(ss.__data, bond->dev->dev_addr, bond->dev->addr_len);
-	ss.ss_family = bond->dev->type;
-
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		if (rollback_slave == slave)
-			break;
-		bond_hw_addr_copy(tmp_addr, rollback_slave->dev->dev_addr,
-				  rollback_slave->dev->addr_len);
-		dev_set_mac_address(rollback_slave->dev,
-				    (struct sockaddr *)&ss, NULL);
-		bond_hw_addr_copy(rollback_slave->dev->dev_addr, tmp_addr,
-				  rollback_slave->dev->addr_len);
-	}
-
-	return res;
-}
-
-/************************ exported alb funcions ************************/
-
-int bond_alb_initialize(struct bonding *bond, int rlb_enabled)
-{
-	int res;
-
-	res = tlb_initialize(bond);
-	if (res)
-		return res;
-
-	if (rlb_enabled) {
-		bond->alb_info.rlb_enabled = 1;
-		res = rlb_initialize(bond);
-		if (res) {
-			tlb_deinitialize(bond);
-			return res;
-		}
-	} else {
-		bond->alb_info.rlb_enabled = 0;
-	}
-
-	return 0;
-}
-
-void bond_alb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	tlb_deinitialize(bond);
-
-	if (bond_info->rlb_enabled)
-		rlb_deinitialize(bond);
-}
-
-static netdev_tx_t bond_do_alb_xmit(struct sk_buff *skb, struct bonding *bond,
-				    struct slave *tx_slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct ethhdr *eth_data = eth_hdr(skb);
-
-	if (!tx_slave) {
-		/* unbalanced or unassigned, send through primary */
-		tx_slave = rcu_dereference(bond->curr_active_slave);
-		if (bond->params.tlb_dynamic_lb)
-			bond_info->unbalanced_load += skb->len;
-	}
-
-	if (tx_slave && bond_slave_can_tx(tx_slave)) {
-		if (tx_slave != rcu_access_pointer(bond->curr_active_slave)) {
-			ether_addr_copy(eth_data->h_source,
-					tx_slave->dev->dev_addr);
-		}
-
-		bond_dev_queue_xmit(bond, skb, tx_slave->dev);
-		goto out;
-	}
-
-	if (tx_slave && bond->params.tlb_dynamic_lb) {
-		spin_lock(&bond->mode_lock);
-		__tlb_clear_slave(bond, tx_slave, 0);
-		spin_unlock(&bond->mode_lock);
-	}
-
-	/* no suitable interface, frame not sent */
-	bond_tx_drop(bond->dev, skb);
-out:
-	return NETDEV_TX_OK;
-}
-
-netdev_tx_t bond_tlb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct ethhdr *eth_data;
-	struct slave *tx_slave = NULL;
-	u32 hash_index;
-
-	skb_reset_mac_header(skb);
-	eth_data = eth_hdr(skb);
-
-	/* Do not TX balance any multicast or broadcast */
-	if (!is_multicast_ether_addr(eth_data->h_dest)) {
-		switch (skb->protocol) {
-		case htons(ETH_P_IP):
-		case htons(ETH_P_IPX):
-		    /* In case of IPX, it will falback to L2 hash */
-		case htons(ETH_P_IPV6):
-			hash_index = bond_xmit_hash(bond, skb);
-			if (bond->params.tlb_dynamic_lb) {
-				tx_slave = tlb_choose_channel(bond,
-							      hash_index & 0xFF,
-							      skb->len);
-			} else {
-				struct bond_up_slave *slaves;
-				unsigned int count;
-
-				slaves = rcu_dereference(bond->slave_arr);
-				count = slaves ? READ_ONCE(slaves->count) : 0;
-				if (likely(count))
-					tx_slave = slaves->arr[hash_index %
-							       count];
-			}
-			break;
-		}
-	}
-	return bond_do_alb_xmit(skb, bond, tx_slave);
-}
-
-netdev_tx_t bond_alb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct ethhdr *eth_data;
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *tx_slave = NULL;
-	static const __be32 ip_bcast = htonl(0xffffffff);
-	int hash_size = 0;
-	bool do_tx_balance = true;
-	u32 hash_index = 0;
-	const u8 *hash_start = NULL;
-
-	skb_reset_mac_header(skb);
-	eth_data = eth_hdr(skb);
-
-	switch (ntohs(skb->protocol)) {
-	case ETH_P_IP: {
-		const struct iphdr *iph;
-
-		if (is_broadcast_ether_addr(eth_data->h_dest) ||
-		    !pskb_network_may_pull(skb, sizeof(*iph))) {
-			do_tx_balance = false;
-			break;
-		}
-		iph = ip_hdr(skb);
-		if (iph->daddr == ip_bcast || iph->protocol == IPPROTO_IGMP) {
-			do_tx_balance = false;
-			break;
-		}
-		hash_start = (char *)&(iph->daddr);
-		hash_size = sizeof(iph->daddr);
-		break;
-	}
-	case ETH_P_IPV6: {
-		const struct ipv6hdr *ip6hdr;
-
-		/* IPv6 doesn't really use broadcast mac address, but leave
-		 * that here just in case.
-		 */
-		if (is_broadcast_ether_addr(eth_data->h_dest)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		/* IPv6 uses all-nodes multicast as an equivalent to
-		 * broadcasts in IPv4.
-		 */
-		if (ether_addr_equal_64bits(eth_data->h_dest, mac_v6_allmcast)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		if (!pskb_network_may_pull(skb, sizeof(*ip6hdr))) {
-			do_tx_balance = false;
-			break;
-		}
-		/* Additionally, DAD probes should not be tx-balanced as that
-		 * will lead to false positives for duplicate addresses and
-		 * prevent address configuration from working.
-		 */
-		ip6hdr = ipv6_hdr(skb);
-		if (ipv6_addr_any(&ip6hdr->saddr)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		hash_start = (char *)&ip6hdr->daddr;
-		hash_size = sizeof(ip6hdr->daddr);
-		break;
-	}
-	case ETH_P_IPX: {
-		const struct ipxhdr *ipxhdr;
-
-		if (pskb_network_may_pull(skb, sizeof(*ipxhdr))) {
-			do_tx_balance = false;
-			break;
-		}
-		ipxhdr = (struct ipxhdr *)skb_network_header(skb);
-
-		if (ipxhdr->ipx_checksum != IPX_NO_CHECKSUM) {
-			/* something is wrong with this packet */
-			do_tx_balance = false;
-			break;
-		}
-
-		if (ipxhdr->ipx_type != IPX_TYPE_NCP) {
-			/* The only protocol worth balancing in
-			 * this family since it has an "ARP" like
-			 * mechanism
-			 */
-			do_tx_balance = false;
-			break;
-		}
-
-		eth_data = eth_hdr(skb);
-		hash_start = (char *)eth_data->h_dest;
-		hash_size = ETH_ALEN;
-		break;
-	}
-	case ETH_P_ARP:
-		do_tx_balance = false;
-		if (bond_info->rlb_enabled)
-			tx_slave = rlb_arp_xmit(skb, bond);
-		break;
-	default:
-		do_tx_balance = false;
-		break;
-	}
-
-	if (do_tx_balance) {
-		if (bond->params.tlb_dynamic_lb) {
-			hash_index = _simple_hash(hash_start, hash_size);
-			tx_slave = tlb_choose_channel(bond, hash_index, skb->len);
-		} else {
-			/*
-			 * do_tx_balance means we are free to select the tx_slave
-			 * So we do exactly what tlb would do for hash selection
-			 */
-
-			struct bond_up_slave *slaves;
-			unsigned int count;
-
-			slaves = rcu_dereference(bond->slave_arr);
-			count = slaves ? READ_ONCE(slaves->count) : 0;
-			if (likely(count))
-				tx_slave = slaves->arr[bond_xmit_hash(bond, skb) %
-						       count];
-		}
-	}
-
-	return bond_do_alb_xmit(skb, bond, tx_slave);
-}
-
-void bond_alb_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    alb_work.work);
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (!bond_has_slaves(bond)) {
-		bond_info->tx_rebalance_counter = 0;
-		bond_info->lp_counter = 0;
-		goto re_arm;
-	}
-
-	rcu_read_lock();
-
-	bond_info->tx_rebalance_counter++;
-	bond_info->lp_counter++;
-
-	/* send learning packets */
-	if (bond_info->lp_counter >= BOND_ALB_LP_TICKS(bond)) {
-		bool strict_match;
-
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			/* If updating current_active, use all currently
-			 * user mac addreses (!strict_match).  Otherwise, only
-			 * use mac of the slave device.
-			 * In RLB mode, we always use strict matches.
-			 */
-			strict_match = (slave != rcu_access_pointer(bond->curr_active_slave) ||
-					bond_info->rlb_enabled);
-			alb_send_learning_packets(slave, slave->dev->dev_addr,
-						  strict_match);
-		}
-		bond_info->lp_counter = 0;
-	}
-
-	/* rebalance tx traffic */
-	if (bond_info->tx_rebalance_counter >= BOND_TLB_REBALANCE_TICKS) {
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			tlb_clear_slave(bond, slave, 1);
-			if (slave == rcu_access_pointer(bond->curr_active_slave)) {
-				SLAVE_TLB_INFO(slave).load =
-					bond_info->unbalanced_load /
-						BOND_TLB_REBALANCE_INTERVAL;
-				bond_info->unbalanced_load = 0;
-			}
-		}
-		bond_info->tx_rebalance_counter = 0;
-	}
-
-	if (bond_info->rlb_enabled) {
-		if (bond_info->primary_is_promisc &&
-		    (++bond_info->rlb_promisc_timeout_counter >= RLB_PROMISC_TIMEOUT)) {
-
-			/* dev_set_promiscuity requires rtnl and
-			 * nothing else.  Avoid race with bond_close.
-			 */
-			rcu_read_unlock();
-			if (!rtnl_trylock())
-				goto re_arm;
-
-			bond_info->rlb_promisc_timeout_counter = 0;
-
-			/* If the primary was set to promiscuous mode
-			 * because a slave was disabled then
-			 * it can now leave promiscuous mode.
-			 */
-			dev_set_promiscuity(rtnl_dereference(bond->curr_active_slave)->dev,
-					    -1);
-			bond_info->primary_is_promisc = 0;
-
-			rtnl_unlock();
-			rcu_read_lock();
-		}
-
-		if (bond_info->rlb_rebalance) {
-			bond_info->rlb_rebalance = 0;
-			rlb_rebalance(bond);
-		}
-
-		/* check if clients need updating */
-		if (bond_info->rx_ntt) {
-			if (bond_info->rlb_update_delay_counter) {
-				--bond_info->rlb_update_delay_counter;
-			} else {
-				rlb_update_rx_clients(bond);
-				if (bond_info->rlb_update_retry_counter)
-					--bond_info->rlb_update_retry_counter;
-				else
-					bond_info->rx_ntt = 0;
-			}
-		}
-	}
-	rcu_read_unlock();
-re_arm:
-	queue_delayed_work(bond->wq, &bond->alb_work, alb_delta_in_ticks);
-}
-
-/* assumption: called before the slave is attached to the bond
- * and not locked by the bond lock
- */
-int bond_alb_init_slave(struct bonding *bond, struct slave *slave)
-{
-	int res;
-
-	res = alb_set_slave_mac_addr(slave, slave->perm_hwaddr,
-				     slave->dev->addr_len);
-	if (res)
-		return res;
-
-	res = alb_handle_addr_collision_on_attach(bond, slave);
-	if (res)
-		return res;
-
-	tlb_init_slave(slave);
-
-	/* order a rebalance ASAP */
-	bond->alb_info.tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
-
-	if (bond->alb_info.rlb_enabled)
-		bond->alb_info.rlb_rebalance = 1;
-
-	return 0;
-}
-
-/* Remove slave from tlb and rlb hash tables, and fix up MAC addresses
- * if necessary.
- *
- * Caller must hold RTNL and no other locks
- */
-void bond_alb_deinit_slave(struct bonding *bond, struct slave *slave)
-{
-	if (bond_has_slaves(bond))
-		alb_change_hw_addr_on_detach(bond, slave);
-
-	tlb_clear_slave(bond, slave, 0);
-
-	if (bond->alb_info.rlb_enabled) {
-		bond->alb_info.rx_slave = NULL;
-		rlb_clear_slave(bond, slave);
-	}
-
-}
-
-void bond_alb_handle_link_change(struct bonding *bond, struct slave *slave, char link)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	if (link == BOND_LINK_DOWN) {
-		tlb_clear_slave(bond, slave, 0);
-		if (bond->alb_info.rlb_enabled)
-			rlb_clear_slave(bond, slave);
-	} else if (link == BOND_LINK_UP) {
-		/* order a rebalance ASAP */
-		bond_info->tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
-		if (bond->alb_info.rlb_enabled) {
-			bond->alb_info.rlb_rebalance = 1;
-			/* If the updelay module parameter is smaller than the
-			 * forwarding delay of the switch the rebalance will
-			 * not work because the rebalance arp replies will
-			 * not be forwarded to the clients..
-			 */
-		}
-	}
-
-	if (bond_is_nondyn_tlb(bond)) {
-		if (bond_update_slave_arr(bond, NULL))
-			pr_err("Failed to build slave-array for TLB mode.\n");
-	}
-}
-
-/**
- * bond_alb_handle_active_change - assign new curr_active_slave
- * @bond: our bonding struct
- * @new_slave: new slave to assign
- *
- * Set the bond->curr_active_slave to @new_slave and handle
- * mac address swapping and promiscuity changes as needed.
- *
- * Caller must hold RTNL
- */
-void bond_alb_handle_active_change(struct bonding *bond, struct slave *new_slave)
-{
-	struct slave *swap_slave;
-	struct slave *curr_active;
-
-	curr_active = rtnl_dereference(bond->curr_active_slave);
-	if (curr_active == new_slave)
-		return;
-
-	if (curr_active && bond->alb_info.primary_is_promisc) {
-		dev_set_promiscuity(curr_active->dev, -1);
-		bond->alb_info.primary_is_promisc = 0;
-		bond->alb_info.rlb_promisc_timeout_counter = 0;
-	}
-
-	swap_slave = curr_active;
-	rcu_assign_pointer(bond->curr_active_slave, new_slave);
-
-	if (!new_slave || !bond_has_slaves(bond))
-		return;
-
-	/* set the new curr_active_slave to the bonds mac address
-	 * i.e. swap mac addresses of old curr_active_slave and new curr_active_slave
-	 */
-	if (!swap_slave)
-		swap_slave = bond_slave_has_mac(bond, bond->dev->dev_addr);
-
-	/* Arrange for swap_slave and new_slave to temporarily be
-	 * ignored so we can mess with their MAC addresses without
-	 * fear of interference from transmit activity.
-	 */
-	if (swap_slave)
-		tlb_clear_slave(bond, swap_slave, 1);
-	tlb_clear_slave(bond, new_slave, 1);
-
-	/* in TLB mode, the slave might flip down/up with the old dev_addr,
-	 * and thus filter bond->dev_addr's packets, so force bond's mac
-	 */
-	if (BOND_MODE(bond) == BOND_MODE_TLB) {
-		struct sockaddr_storage ss;
-		u8 tmp_addr[MAX_ADDR_LEN];
-
-		bond_hw_addr_copy(tmp_addr, new_slave->dev->dev_addr,
-				  new_slave->dev->addr_len);
-
-		bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
-				  bond->dev->addr_len);
-		ss.ss_family = bond->dev->type;
-		/* we don't care if it can't change its mac, best effort */
-		dev_set_mac_address(new_slave->dev, (struct sockaddr *)&ss,
-				    NULL);
-
-		bond_hw_addr_copy(new_slave->dev->dev_addr, tmp_addr,
-				  new_slave->dev->addr_len);
-	}
-
-	/* curr_active_slave must be set before calling alb_swap_mac_addr */
-	if (swap_slave) {
-		/* swap mac address */
-		alb_swap_mac_addr(swap_slave, new_slave);
-		alb_fasten_mac_swap(bond, swap_slave, new_slave);
-	} else {
-		/* set the new_slave to the bond mac address */
-		alb_set_slave_mac_addr(new_slave, bond->dev->dev_addr,
-				       bond->dev->addr_len);
-		alb_send_learning_packets(new_slave, bond->dev->dev_addr,
-					  false);
-	}
-}
-
-/* Called with RTNL */
-int bond_alb_set_mac_address(struct net_device *bond_dev, void *addr)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct sockaddr_storage *ss = addr;
-	struct slave *curr_active;
-	struct slave *swap_slave;
-	int res;
-
-	if (!is_valid_ether_addr(ss->__data))
-		return -EADDRNOTAVAIL;
-
-	res = alb_set_mac_address(bond, addr);
-	if (res)
-		return res;
-
-	bond_hw_addr_copy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
-
-	/* If there is no curr_active_slave there is nothing else to do.
-	 * Otherwise we'll need to pass the new address to it and handle
-	 * duplications.
-	 */
-	curr_active = rtnl_dereference(bond->curr_active_slave);
-	if (!curr_active)
-		return 0;
-
-	swap_slave = bond_slave_has_mac(bond, bond_dev->dev_addr);
-
-	if (swap_slave) {
-		alb_swap_mac_addr(swap_slave, curr_active);
-		alb_fasten_mac_swap(bond, swap_slave, curr_active);
-	} else {
-		alb_set_slave_mac_addr(curr_active, bond_dev->dev_addr,
-				       bond_dev->addr_len);
-
-		alb_send_learning_packets(curr_active,
-					  bond_dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform clients mac address has changed */
-			rlb_req_update_slave_clients(bond, curr_active);
-		}
-	}
-
-	return 0;
-}
-
-void bond_alb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
-{
-	if (bond->alb_info.rlb_enabled)
-		rlb_clear_vlan(bond, vlan_id);
-}
-
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.82/bond_debugfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.82/bond_debugfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,125 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/device.h>
-#include <linux/netdevice.h>
-
-#include <net/bonding.h>
-#include <net/bond_alb.h>
-
-#if defined(CONFIG_DEBUG_FS) && !defined(CONFIG_NET_NS)
-
-#include <linux/debugfs.h>
-#include <linux/seq_file.h>
-
-static struct dentry *bonding_debug_root;
-
-/* Show RLB hash table */
-static int bond_debug_rlb_hash_show(struct seq_file *m, void *v)
-{
-	struct bonding *bond = m->private;
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	if (BOND_MODE(bond) != BOND_MODE_ALB)
-		return 0;
-
-	seq_printf(m, "SourceIP        DestinationIP   "
-			"Destination MAC   DEV\n");
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		seq_printf(m, "%-15pI4 %-15pI4 %-17pM %s\n",
-			&client_info->ip_src,
-			&client_info->ip_dst,
-			&client_info->mac_dst,
-			client_info->slave->dev->name);
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	return 0;
-}
-DEFINE_SHOW_ATTRIBUTE(bond_debug_rlb_hash);
-
-void bond_debug_register(struct bonding *bond)
-{
-	if (!bonding_debug_root)
-		return;
-
-	bond->debug_dir =
-		debugfs_create_dir(bond->dev->name, bonding_debug_root);
-
-	debugfs_create_file("rlb_hash_table", 0400, bond->debug_dir,
-				bond, &bond_debug_rlb_hash_fops);
-}
-
-void bond_debug_unregister(struct bonding *bond)
-{
-	if (!bonding_debug_root)
-		return;
-
-	debugfs_remove_recursive(bond->debug_dir);
-}
-
-void bond_debug_reregister(struct bonding *bond)
-{
-	struct dentry *d;
-
-	if (!bonding_debug_root)
-		return;
-
-	d = debugfs_rename(bonding_debug_root, bond->debug_dir,
-			   bonding_debug_root, bond->dev->name);
-	if (d) {
-		bond->debug_dir = d;
-	} else {
-		netdev_warn(bond->dev, "failed to reregister, so just unregister old one\n");
-		bond_debug_unregister(bond);
-	}
-}
-
-void bond_create_debugfs(void)
-{
-	bonding_debug_root = debugfs_create_dir("bonding", NULL);
-
-	if (!bonding_debug_root) {
-		pr_warn("Warning: Cannot create bonding directory in debugfs\n");
-	}
-}
-
-void bond_destroy_debugfs(void)
-{
-	debugfs_remove_recursive(bonding_debug_root);
-	bonding_debug_root = NULL;
-}
-
-
-#else /* !CONFIG_DEBUG_FS */
-
-void bond_debug_register(struct bonding *bond)
-{
-}
-
-void bond_debug_unregister(struct bonding *bond)
-{
-}
-
-void bond_debug_reregister(struct bonding *bond)
-{
-}
-
-void bond_create_debugfs(void)
-{
-}
-
-void bond_destroy_debugfs(void)
-{
-}
-
-#endif /* CONFIG_DEBUG_FS */
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.82/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.82/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,5146 +0,0 @@
-/*
- * originally based on the dummy device.
- *
- * Copyright 1999, Thomas Davis, tadavis@lbl.gov.
- * Licensed under the GPL. Based on dummy.c, and eql.c devices.
- *
- * bonding.c: an Ethernet Bonding driver
- *
- * This is useful to talk to a Cisco EtherChannel compatible equipment:
- *	Cisco 5500
- *	Sun Trunking (Solaris)
- *	Alteon AceDirector Trunks
- *	Linux Bonding
- *	and probably many L2 switches ...
- *
- * How it works:
- *    ifconfig bond0 ipaddress netmask up
- *      will setup a network device, with an ip address.  No mac address
- *	will be assigned at this time.  The hw mac address will come from
- *	the first slave bonded to the channel.  All slaves will then use
- *	this hw mac address.
- *
- *    ifconfig bond0 down
- *         will release all slaves, marking them as down.
- *
- *    ifenslave bond0 eth0
- *	will attach eth0 to bond0 as a slave.  eth0 hw mac address will either
- *	a: be used as initial mac address
- *	b: if a hw mac address already is there, eth0's hw mac address
- *	   will then be set from bond0.
- *
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/types.h>
-#include <linux/fcntl.h>
-#include <linux/interrupt.h>
-#include <linux/ptrace.h>
-#include <linux/ioport.h>
-#include <linux/in.h>
-#include <net/ip.h>
-#include <linux/ip.h>
-#include <linux/tcp.h>
-#include <linux/udp.h>
-#include <linux/slab.h>
-#include <linux/string.h>
-#include <linux/init.h>
-#include <linux/timer.h>
-#include <linux/socket.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/bitops.h>
-#include <linux/io.h>
-#include <asm/dma.h>
-#include <linux/uaccess.h>
-#include <linux/errno.h>
-#include <linux/netdevice.h>
-#include <linux/inetdevice.h>
-#include <linux/igmp.h>
-#include <linux/etherdevice.h>
-#include <linux/skbuff.h>
-#include <net/sock.h>
-#include <linux/rtnetlink.h>
-#include <linux/smp.h>
-#include <linux/if_ether.h>
-#include <net/arp.h>
-#include <linux/mii.h>
-#include <linux/ethtool.h>
-#include <linux/if_vlan.h>
-#include <linux/if_bonding.h>
-#include <linux/jiffies.h>
-#include <linux/preempt.h>
-#include <net/route.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <net/pkt_sched.h>
-#include <linux/rculist.h>
-#include <linux/toedev.h>
-#include <net/flow_dissector.h>
-#include <net/bonding.h>
-#include <net/bond_3ad.h>
-#include <net/bond_alb.h>
-
-#include "bonding_priv.h"
-
-/*---------------------------- Module parameters ----------------------------*/
-
-/* monitor all links that often (in milliseconds). <=0 disables monitoring */
-
-static int max_bonds	= BOND_DEFAULT_MAX_BONDS;
-static int tx_queues	= BOND_DEFAULT_TX_QUEUES;
-static int num_peer_notif = 1;
-static int miimon;
-static int updelay;
-static int downdelay;
-static int use_carrier	= 1;
-static char *mode;
-static char *primary;
-static char *primary_reselect;
-static char *lacp_rate;
-static int min_links;
-static char *ad_select;
-static char *xmit_hash_policy;
-static int arp_interval;
-static char *arp_ip_target[BOND_MAX_ARP_TARGETS];
-static char *arp_validate;
-static char *arp_all_targets;
-static char *fail_over_mac;
-static int all_slaves_active;
-static struct bond_params bonding_defaults;
-static int resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-static int packets_per_slave = 1;
-static int lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-
-module_param(max_bonds, int, 0);
-MODULE_PARM_DESC(max_bonds, "Max number of bonded devices");
-module_param(tx_queues, int, 0);
-MODULE_PARM_DESC(tx_queues, "Max number of transmit queues (default = 16)");
-module_param_named(num_grat_arp, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_grat_arp, "Number of peer notifications to send on "
-			       "failover event (alias of num_unsol_na)");
-module_param_named(num_unsol_na, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_unsol_na, "Number of peer notifications to send on "
-			       "failover event (alias of num_grat_arp)");
-module_param(miimon, int, 0);
-MODULE_PARM_DESC(miimon, "Link check interval in milliseconds");
-module_param(updelay, int, 0);
-MODULE_PARM_DESC(updelay, "Delay before considering link up, in milliseconds");
-module_param(downdelay, int, 0);
-MODULE_PARM_DESC(downdelay, "Delay before considering link down, "
-			    "in milliseconds");
-module_param(use_carrier, int, 0);
-MODULE_PARM_DESC(use_carrier, "Use netif_carrier_ok (vs MII ioctls) in miimon; "
-			      "0 for off, 1 for on (default)");
-module_param(mode, charp, 0);
-MODULE_PARM_DESC(mode, "Mode of operation; 0 for balance-rr, "
-		       "1 for active-backup, 2 for balance-xor, "
-		       "3 for broadcast, 4 for 802.3ad, 5 for balance-tlb, "
-		       "6 for balance-alb");
-module_param(primary, charp, 0);
-MODULE_PARM_DESC(primary, "Primary network device to use");
-module_param(primary_reselect, charp, 0);
-MODULE_PARM_DESC(primary_reselect, "Reselect primary slave "
-				   "once it comes up; "
-				   "0 for always (default), "
-				   "1 for only if speed of primary is "
-				   "better, "
-				   "2 for only on active slave "
-				   "failure");
-module_param(lacp_rate, charp, 0);
-MODULE_PARM_DESC(lacp_rate, "LACPDU tx rate to request from 802.3ad partner; "
-			    "0 for slow, 1 for fast");
-module_param(ad_select, charp, 0);
-MODULE_PARM_DESC(ad_select, "802.3ad aggregation selection logic; "
-			    "0 for stable (default), 1 for bandwidth, "
-			    "2 for count");
-module_param(min_links, int, 0);
-MODULE_PARM_DESC(min_links, "Minimum number of available links before turning on carrier");
-
-module_param(xmit_hash_policy, charp, 0);
-MODULE_PARM_DESC(xmit_hash_policy, "balance-alb, balance-tlb, balance-xor, 802.3ad hashing method; "
-				   "0 for layer 2 (default), 1 for layer 3+4, "
-				   "2 for layer 2+3, 3 for encap layer 2+3, "
-				   "4 for encap layer 3+4");
-module_param(arp_interval, int, 0);
-MODULE_PARM_DESC(arp_interval, "arp interval in milliseconds");
-module_param_array(arp_ip_target, charp, NULL, 0);
-MODULE_PARM_DESC(arp_ip_target, "arp targets in n.n.n.n form");
-module_param(arp_validate, charp, 0);
-MODULE_PARM_DESC(arp_validate, "validate src/dst of ARP probes; "
-			       "0 for none (default), 1 for active, "
-			       "2 for backup, 3 for all");
-module_param(arp_all_targets, charp, 0);
-MODULE_PARM_DESC(arp_all_targets, "fail on any/all arp targets timeout; 0 for any (default), 1 for all");
-module_param(fail_over_mac, charp, 0);
-MODULE_PARM_DESC(fail_over_mac, "For active-backup, do not set all slaves to "
-				"the same MAC; 0 for none (default), "
-				"1 for active, 2 for follow");
-module_param(all_slaves_active, int, 0);
-MODULE_PARM_DESC(all_slaves_active, "Keep all frames received on an interface "
-				     "by setting active flag for all slaves; "
-				     "0 for never (default), 1 for always.");
-module_param(resend_igmp, int, 0);
-MODULE_PARM_DESC(resend_igmp, "Number of IGMP membership reports to send on "
-			      "link failure");
-module_param(packets_per_slave, int, 0);
-MODULE_PARM_DESC(packets_per_slave, "Packets to send per slave in balance-rr "
-				    "mode; 0 for a random slave, 1 packet per "
-				    "slave (default), >1 packets per slave.");
-module_param(lp_interval, uint, 0);
-MODULE_PARM_DESC(lp_interval, "The number of seconds between instances where "
-			      "the bonding driver sends learning packets to "
-			      "each slaves peer switch. The default is 1.");
-
-/*----------------------------- Global variables ----------------------------*/
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-atomic_t netpoll_block_tx = ATOMIC_INIT(0);
-#endif
-
-unsigned int bond_net_id __read_mostly;
-
-/*-------------------------- Forward declarations ---------------------------*/
-
-static int bond_init(struct net_device *bond_dev);
-static void bond_uninit(struct net_device *bond_dev);
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats);
-static void bond_slave_arr_handler(struct work_struct *work);
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod);
-static void bond_netdev_notify_work(struct work_struct *work);
-
-/*---------------------------- General routines -----------------------------*/
-
-const char *bond_mode_name(int mode)
-{
-	static const char *names[] = {
-		[BOND_MODE_ROUNDROBIN] = "load balancing (round-robin)",
-		[BOND_MODE_ACTIVEBACKUP] = "fault-tolerance (active-backup)",
-		[BOND_MODE_XOR] = "load balancing (xor)",
-		[BOND_MODE_BROADCAST] = "fault-tolerance (broadcast)",
-		[BOND_MODE_8023AD] = "IEEE 802.3ad Dynamic link aggregation",
-		[BOND_MODE_TLB] = "transmit load balancing",
-		[BOND_MODE_ALB] = "adaptive load balancing",
-	};
-
-	if (mode < BOND_MODE_ROUNDROBIN || mode > BOND_MODE_ALB)
-		return "unknown";
-
-	return names[mode];
-}
-
-/*---------------------------------- VLAN -----------------------------------*/
-
-/**
- * bond_dev_queue_xmit - Prepare skb for xmit.
- *
- * @bond: bond device that got this skb for tx.
- * @skb: hw accel VLAN tagged skb to transmit
- * @slave_dev: slave that is supposed to xmit this skbuff
- */
-void bond_dev_queue_xmit(struct bonding *bond, struct sk_buff *skb,
-			struct net_device *slave_dev)
-{
-	skb->dev = slave_dev;
-
-	BUILD_BUG_ON(sizeof(skb->queue_mapping) !=
-		     sizeof(qdisc_skb_cb(skb)->slave_dev_queue_mapping));
-	skb_set_queue_mapping(skb, qdisc_skb_cb(skb)->slave_dev_queue_mapping);
-
-	if (unlikely(netpoll_tx_running(bond->dev)))
-		bond_netpoll_send_skb(bond_get_slave_by_dev(bond, slave_dev), skb);
-	else
-		dev_queue_xmit(skb);
-}
-
-/* In the following 2 functions, bond_vlan_rx_add_vid and bond_vlan_rx_kill_vid,
- * We don't protect the slave list iteration with a lock because:
- * a. This operation is performed in IOCTL context,
- * b. The operation is protected by the RTNL semaphore in the 8021q code,
- * c. Holding a lock with BH disabled while directly calling a base driver
- *    entry point is generally a BAD idea.
- *
- * The design of synchronization/protection for this operation in the 8021q
- * module is good for one or more VLAN devices over a single physical device
- * and cannot be extended for a teaming solution like bonding, so there is a
- * potential race condition here where a net device from the vlan group might
- * be referenced (either by a base driver or the 8021q code) while it is being
- * removed from the system. However, it turns out we're not making matters
- * worse, and if it works for regular VLAN usage it will work here too.
-*/
-
-/**
- * bond_vlan_rx_add_vid - Propagates adding an id to slaves
- * @bond_dev: bonding net device that got called
- * @vid: vlan id being added
- */
-static int bond_vlan_rx_add_vid(struct net_device *bond_dev,
-				__be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res;
-
-	bond_for_each_slave(bond, slave, iter) {
-		res = vlan_vid_add(slave->dev, proto, vid);
-		if (res)
-			goto unwind;
-	}
-
-	return 0;
-
-unwind:
-	/* unwind to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		if (rollback_slave == slave)
-			break;
-
-		vlan_vid_del(rollback_slave->dev, proto, vid);
-	}
-
-	return res;
-}
-
-/**
- * bond_vlan_rx_kill_vid - Propagates deleting an id to slaves
- * @bond_dev: bonding net device that got called
- * @vid: vlan id being removed
- */
-static int bond_vlan_rx_kill_vid(struct net_device *bond_dev,
-				 __be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		vlan_vid_del(slave->dev, proto, vid);
-
-	if (bond_is_lb(bond))
-		bond_alb_clear_vlan(bond, vid);
-
-	return 0;
-}
-
-/*------------------------------- Link status -------------------------------*/
-
-/* Set the carrier state for the master according to the state of its
- * slaves.  If any slaves are up, the master is up.  In 802.3ad mode,
- * do special 802.3ad magic.
- *
- * Returns zero if carrier state does not change, nonzero if it does.
- */
-int bond_set_carrier(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (!bond_has_slaves(bond))
-		goto down;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		return bond_3ad_set_carrier(bond);
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP) {
-			if (!netif_carrier_ok(bond->dev)) {
-				netif_carrier_on(bond->dev);
-				return 1;
-			}
-			return 0;
-		}
-	}
-
-down:
-	if (netif_carrier_ok(bond->dev)) {
-		netif_carrier_off(bond->dev);
-		return 1;
-	}
-	return 0;
-}
-
-/* Get link speed and duplex from the slave's base driver
- * using ethtool. If for some reason the call fails or the
- * values are invalid, set speed and duplex to -1,
- * and return. Return 1 if speed or duplex settings are
- * UNKNOWN; 0 otherwise.
- */
-static int bond_update_speed_duplex(struct slave *slave)
-{
-	struct net_device *slave_dev = slave->dev;
-	struct ethtool_link_ksettings ecmd;
-	int res;
-
-	slave->speed = SPEED_UNKNOWN;
-	slave->duplex = DUPLEX_UNKNOWN;
-
-	res = __ethtool_get_link_ksettings(slave_dev, &ecmd);
-	if (res < 0)
-		return 1;
-	if (ecmd.base.speed == 0 || ecmd.base.speed == ((__u32)-1))
-		return 1;
-	switch (ecmd.base.duplex) {
-	case DUPLEX_FULL:
-	case DUPLEX_HALF:
-		break;
-	default:
-		return 1;
-	}
-
-	slave->speed = ecmd.base.speed;
-	slave->duplex = ecmd.base.duplex;
-
-	return 0;
-}
-
-const char *bond_slave_link_status(s8 link)
-{
-	switch (link) {
-	case BOND_LINK_UP:
-		return "up";
-	case BOND_LINK_FAIL:
-		return "going down";
-	case BOND_LINK_DOWN:
-		return "down";
-	case BOND_LINK_BACK:
-		return "going back";
-	default:
-		return "unknown";
-	}
-}
-
-/* if <dev> supports MII link status reporting, check its link status.
- *
- * We either do MII/ETHTOOL ioctls, or check netif_carrier_ok(),
- * depending upon the setting of the use_carrier parameter.
- *
- * Return either BMSR_LSTATUS, meaning that the link is up (or we
- * can't tell and just pretend it is), or 0, meaning that the link is
- * down.
- *
- * If reporting is non-zero, instead of faking link up, return -1 if
- * both ETHTOOL and MII ioctls fail (meaning the device does not
- * support them).  If use_carrier is set, return whatever it says.
- * It'd be nice if there was a good way to tell if a driver supports
- * netif_carrier, but there really isn't.
- */
-static int bond_check_dev_link(struct bonding *bond,
-			       struct net_device *slave_dev, int reporting)
-{
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	int (*ioctl)(struct net_device *, struct ifreq *, int);
-	struct ifreq ifr;
-	struct mii_ioctl_data *mii;
-
-	if (!reporting && !netif_running(slave_dev))
-		return 0;
-
-	if (bond->params.use_carrier)
-		return netif_carrier_ok(slave_dev) ? BMSR_LSTATUS : 0;
-
-	/* Try to get link status using Ethtool first. */
-	if (slave_dev->ethtool_ops->get_link)
-		return slave_dev->ethtool_ops->get_link(slave_dev) ?
-			BMSR_LSTATUS : 0;
-
-	/* Ethtool can't be used, fallback to MII ioctls. */
-	ioctl = slave_ops->ndo_do_ioctl;
-	if (ioctl) {
-		/* TODO: set pointer to correct ioctl on a per team member
-		 *       bases to make this more efficient. that is, once
-		 *       we determine the correct ioctl, we will always
-		 *       call it and not the others for that team
-		 *       member.
-		 */
-
-		/* We cannot assume that SIOCGMIIPHY will also read a
-		 * register; not all network drivers (e.g., e100)
-		 * support that.
-		 */
-
-		/* Yes, the mii is overlaid on the ifreq.ifr_ifru */
-		strncpy(ifr.ifr_name, slave_dev->name, IFNAMSIZ);
-		mii = if_mii(&ifr);
-		if (ioctl(slave_dev, &ifr, SIOCGMIIPHY) == 0) {
-			mii->reg_num = MII_BMSR;
-			if (ioctl(slave_dev, &ifr, SIOCGMIIREG) == 0)
-				return mii->val_out & BMSR_LSTATUS;
-		}
-	}
-
-	/* If reporting, report that either there's no dev->do_ioctl,
-	 * or both SIOCGMIIREG and get_link failed (meaning that we
-	 * cannot report link status).  If not reporting, pretend
-	 * we're ok.
-	 */
-	return reporting ? -1 : BMSR_LSTATUS;
-}
-
-/*----------------------------- Multicast list ------------------------------*/
-
-/* Push the promiscuity flag down to appropriate slaves */
-static int bond_set_promiscuity(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_promiscuity(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_promiscuity(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Push the allmulti flag down to all slaves */
-static int bond_set_allmulti(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_allmulti(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_allmulti(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Retrieve the list of registered multicast addresses for the bonding
- * device and retransmit an IGMP JOIN request to the current active
- * slave.
- */
-static void bond_resend_igmp_join_requests_delayed(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mcast_work.work);
-
-	if (!rtnl_trylock()) {
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-		return;
-	}
-	call_netdevice_notifiers(NETDEV_RESEND_IGMP, bond->dev);
-
-	if (bond->igmp_retrans > 1) {
-		bond->igmp_retrans--;
-		queue_delayed_work(bond->wq, &bond->mcast_work, HZ/5);
-	}
-	rtnl_unlock();
-}
-
-/* Flush bond's hardware addresses from slave */
-static void bond_hw_addr_flush(struct net_device *bond_dev,
-			       struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	dev_uc_unsync(slave_dev, bond_dev);
-	dev_mc_unsync(slave_dev, bond_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		/* del lacpdu mc addr from mc list */
-		u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-		dev_mc_del(slave_dev, lacpdu_multicast);
-	}
-}
-
-/*--------------------------- Active slave change ---------------------------*/
-
-/* Update the hardware address list and promisc/allmulti for the new and
- * old active slaves (if any).  Modes that are not using primary keep all
- * slaves up date at all times; only the modes that use primary need to call
- * this function to swap these settings during a failover.
- */
-static void bond_hw_addr_swap(struct bonding *bond, struct slave *new_active,
-			      struct slave *old_active)
-{
-	if (old_active) {
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(old_active->dev, -1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(old_active->dev, -1);
-
-		bond_hw_addr_flush(bond->dev, old_active->dev);
-	}
-
-	if (new_active) {
-		/* FIXME: Signal errors upstream. */
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(new_active->dev, 1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(new_active->dev, 1);
-
-		netif_addr_lock_bh(bond->dev);
-		dev_uc_sync(new_active->dev, bond->dev);
-		dev_mc_sync(new_active->dev, bond->dev);
-		netif_addr_unlock_bh(bond->dev);
-	}
-}
-
-/**
- * bond_set_dev_addr - clone slave's address to bond
- * @bond_dev: bond net device
- * @slave_dev: slave net device
- *
- * Should be called with RTNL held.
- */
-static int bond_set_dev_addr(struct net_device *bond_dev,
-			     struct net_device *slave_dev)
-{
-	int err;
-
-	slave_dbg(bond_dev, slave_dev, "bond_dev=%p slave_dev=%p slave_dev->addr_len=%d\n",
-		  bond_dev, slave_dev, slave_dev->addr_len);
-	err = dev_pre_changeaddr_notify(bond_dev, slave_dev->dev_addr, NULL);
-	if (err)
-		return err;
-
-	memcpy(bond_dev->dev_addr, slave_dev->dev_addr, slave_dev->addr_len);
-	bond_dev->addr_assign_type = NET_ADDR_STOLEN;
-	call_netdevice_notifiers(NETDEV_CHANGEADDR, bond_dev);
-	return 0;
-}
-
-static struct slave *bond_get_old_active(struct bonding *bond,
-					 struct slave *new_active)
-{
-	struct slave *slave;
-	struct list_head *iter;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave == new_active)
-			continue;
-
-		if (ether_addr_equal(bond->dev->dev_addr, slave->dev->dev_addr))
-			return slave;
-	}
-
-	return NULL;
-}
-
-/* bond_do_fail_over_mac
- *
- * Perform special MAC address swapping for fail_over_mac settings
- *
- * Called with RTNL
- */
-static void bond_do_fail_over_mac(struct bonding *bond,
-				  struct slave *new_active,
-				  struct slave *old_active)
-{
-	u8 tmp_mac[MAX_ADDR_LEN];
-	struct sockaddr_storage ss;
-	int rv;
-
-	switch (bond->params.fail_over_mac) {
-	case BOND_FOM_ACTIVE:
-		if (new_active) {
-			rv = bond_set_dev_addr(bond->dev, new_active->dev);
-			if (rv)
-				slave_err(bond->dev, new_active->dev, "Error %d setting bond MAC from slave\n",
-					  -rv);
-		}
-		break;
-	case BOND_FOM_FOLLOW:
-		/* if new_active && old_active, swap them
-		 * if just old_active, do nothing (going to no active slave)
-		 * if just new_active, set new_active to bond's MAC
-		 */
-		if (!new_active)
-			return;
-
-		if (!old_active)
-			old_active = bond_get_old_active(bond, new_active);
-
-		if (old_active) {
-			bond_hw_addr_copy(tmp_mac, new_active->dev->dev_addr,
-					  new_active->dev->addr_len);
-			bond_hw_addr_copy(ss.__data,
-					  old_active->dev->dev_addr,
-					  old_active->dev->addr_len);
-			ss.ss_family = new_active->dev->type;
-		} else {
-			bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
-					  bond->dev->addr_len);
-			ss.ss_family = bond->dev->type;
-		}
-
-		rv = dev_set_mac_address(new_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv) {
-			slave_err(bond->dev, new_active->dev, "Error %d setting MAC of new active slave\n",
-				  -rv);
-			goto out;
-		}
-
-		if (!old_active)
-			goto out;
-
-		bond_hw_addr_copy(ss.__data, tmp_mac,
-				  new_active->dev->addr_len);
-		ss.ss_family = old_active->dev->type;
-
-		rv = dev_set_mac_address(old_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv)
-			slave_err(bond->dev, old_active->dev, "Error %d setting MAC of old active slave\n",
-				  -rv);
-out:
-		break;
-	default:
-		netdev_err(bond->dev, "bond_do_fail_over_mac impossible: bad policy %d\n",
-			   bond->params.fail_over_mac);
-		break;
-	}
-
-}
-
-static struct slave *bond_choose_primary_or_current(struct bonding *bond)
-{
-	struct slave *prim = rtnl_dereference(bond->primary_slave);
-	struct slave *curr = rtnl_dereference(bond->curr_active_slave);
-
-	if (!prim || prim->link != BOND_LINK_UP) {
-		if (!curr || curr->link != BOND_LINK_UP)
-			return NULL;
-		return curr;
-	}
-
-	if (bond->force_primary) {
-		bond->force_primary = false;
-		return prim;
-	}
-
-	if (!curr || curr->link != BOND_LINK_UP)
-		return prim;
-
-	/* At this point, prim and curr are both up */
-	switch (bond->params.primary_reselect) {
-	case BOND_PRI_RESELECT_ALWAYS:
-		return prim;
-	case BOND_PRI_RESELECT_BETTER:
-		if (prim->speed < curr->speed)
-			return curr;
-		if (prim->speed == curr->speed && prim->duplex <= curr->duplex)
-			return curr;
-		return prim;
-	case BOND_PRI_RESELECT_FAILURE:
-		return curr;
-	default:
-		netdev_err(bond->dev, "impossible primary_reselect %d\n",
-			   bond->params.primary_reselect);
-		return curr;
-	}
-}
-
-/**
- * bond_find_best_slave - select the best available slave to be the active one
- * @bond: our bonding struct
- */
-static struct slave *bond_find_best_slave(struct bonding *bond)
-{
-	struct slave *slave, *bestslave = NULL;
-	struct list_head *iter;
-	int mintime = bond->params.updelay;
-
-	slave = bond_choose_primary_or_current(bond);
-	if (slave)
-		return slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP)
-			return slave;
-		if (slave->link == BOND_LINK_BACK && bond_slave_is_up(slave) &&
-		    slave->delay < mintime) {
-			mintime = slave->delay;
-			bestslave = slave;
-		}
-	}
-
-	return bestslave;
-}
-
-static bool bond_should_notify_peers(struct bonding *bond)
-{
-	struct slave *slave;
-
-	rcu_read_lock();
-	slave = rcu_dereference(bond->curr_active_slave);
-	rcu_read_unlock();
-
-	netdev_dbg(bond->dev, "bond_should_notify_peers: slave %s\n",
-		   slave ? slave->dev->name : "NULL");
-
-	if (!slave || !bond->send_peer_notif ||
-	    bond->send_peer_notif %
-	    max(1, bond->params.peer_notif_delay) != 0 ||
-	    !netif_carrier_ok(bond->dev) ||
-	    test_bit(__LINK_STATE_LINKWATCH_PENDING, &slave->dev->state))
-		return false;
-
-	return true;
-}
-
-/**
- * change_active_interface - change the active slave into the specified one
- * @bond: our bonding struct
- * @new: the new slave to make the active one
- *
- * Set the new slave to the bond's settings and unset them on the old
- * curr_active_slave.
- * Setting include flags, mc-list, promiscuity, allmulti, etc.
- *
- * If @new's link state is %BOND_LINK_BACK we'll set it to %BOND_LINK_UP,
- * because it is apparently the best available slave we have, even though its
- * updelay hasn't timed out yet.
- *
- * Caller must hold RTNL.
- */
-void bond_change_active_slave(struct bonding *bond, struct slave *new_active)
-{
-	struct slave *old_active;
-
-	ASSERT_RTNL();
-
-	old_active = rtnl_dereference(bond->curr_active_slave);
-
-	if (old_active == new_active)
-		return;
-
-	if (new_active) {
-		new_active->last_link_up = jiffies;
-
-		if (new_active->link == BOND_LINK_BACK) {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one %d ms earlier\n",
-					   (bond->params.updelay - new_active->delay) * bond->params.miimon);
-			}
-
-			new_active->delay = 0;
-			bond_set_slave_link_state(new_active, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_3ad_handle_link_change(new_active, BOND_LINK_UP);
-
-			if (bond_is_lb(bond))
-				bond_alb_handle_link_change(bond, new_active, BOND_LINK_UP);
-		} else {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one\n");
-			}
-		}
-	}
-
-	if (bond_uses_primary(bond))
-		bond_hw_addr_swap(bond, new_active, old_active);
-
-	if (bond_is_lb(bond)) {
-		bond_alb_handle_active_change(bond, new_active);
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-		if (new_active)
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		rcu_assign_pointer(bond->curr_active_slave, new_active);
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP) {
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-		if (new_active) {
-			bool should_notify_peers = false;
-
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-
-			if (bond->params.fail_over_mac)
-				bond_do_fail_over_mac(bond, new_active,
-						      old_active);
-
-			if (netif_running(bond->dev)) {
-				bond->send_peer_notif =
-					bond->params.num_peer_notif *
-					max(1, bond->params.peer_notif_delay);
-				should_notify_peers =
-					bond_should_notify_peers(bond);
-			}
-
-			call_netdevice_notifiers(NETDEV_BONDING_FAILOVER, bond->dev);
-			if (should_notify_peers) {
-				bond->send_peer_notif--;
-				call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-							 bond->dev);
-			}
-		}
-	}
-
-	/* resend IGMP joins since active slave has changed or
-	 * all were sent on curr_active_slave.
-	 * resend only if bond is brought up with the affected
-	 * bonding modes and the retransmission is enabled
-	 */
-	if (netif_running(bond->dev) && (bond->params.resend_igmp > 0) &&
-	    ((bond_uses_primary(bond) && new_active) ||
-	     BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)) {
-		bond->igmp_retrans = bond->params.resend_igmp;
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-	}
-}
-
-/**
- * bond_select_active_slave - select a new active slave, if needed
- * @bond: our bonding struct
- *
- * This functions should be called when one of the following occurs:
- * - The old curr_active_slave has been released or lost its link.
- * - The primary_slave has got its link back.
- * - A slave has got its link back and there's no old curr_active_slave.
- *
- * Caller must hold RTNL.
- */
-void bond_select_active_slave(struct bonding *bond)
-{
-	struct slave *best_slave;
-	int rv;
-
-	ASSERT_RTNL();
-
-	best_slave = bond_find_best_slave(bond);
-	if (best_slave != rtnl_dereference(bond->curr_active_slave)) {
-		struct slave *last_slave = bond->curr_active_slave;
-
-		bond_change_active_slave(bond, best_slave);
-		toe_failover(bond->dev,
-			     bond->curr_active_slave ?
-			     bond->curr_active_slave->dev : NULL,
-			     TOE_ACTIVE_SLAVE,
-			     last_slave ? last_slave->dev : NULL);
-
-		rv = bond_set_carrier(bond);
-		if (!rv)
-			return;
-
-		if (netif_carrier_ok(bond->dev))
-			netdev_info(bond->dev, "active interface up!\n");
-		else
-			netdev_info(bond->dev, "now running without any active interface!\n");
-	}
-}
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	struct netpoll *np;
-	int err = 0;
-
-	np = kzalloc(sizeof(*np), GFP_KERNEL);
-	err = -ENOMEM;
-	if (!np)
-		goto out;
-
-	err = __netpoll_setup(np, slave->dev);
-	if (err) {
-		kfree(np);
-		goto out;
-	}
-	slave->np = np;
-out:
-	return err;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-	struct netpoll *np = slave->np;
-
-	if (!np)
-		return;
-
-	slave->np = NULL;
-
-	__netpoll_free(np);
-}
-
-static void bond_poll_controller(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-	struct ad_info ad_info;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		if (bond_3ad_get_active_agg_info(bond, &ad_info))
-			return;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!bond_slave_is_up(slave))
-			continue;
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg =
-			    SLAVE_AD_INFO(slave)->port.aggregator;
-
-			if (agg &&
-			    agg->aggregator_identifier != ad_info.aggregator_id)
-				continue;
-		}
-
-		netpoll_poll_dev(slave->dev);
-	}
-}
-
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		if (bond_slave_is_up(slave))
-			slave_disable_netpoll(slave);
-}
-
-static int bond_netpoll_setup(struct net_device *dev, struct netpoll_info *ni)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	struct slave *slave;
-	int err = 0;
-
-	bond_for_each_slave(bond, slave, iter) {
-		err = slave_enable_netpoll(slave);
-		if (err) {
-			bond_netpoll_cleanup(dev);
-			break;
-		}
-	}
-	return err;
-}
-#else
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	return 0;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-}
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-}
-#endif
-
-/*---------------------------------- IOCTL ----------------------------------*/
-
-static netdev_features_t bond_fix_features(struct net_device *dev,
-					   netdev_features_t features)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	netdev_features_t mask;
-	struct slave *slave;
-
-	mask = features;
-
-	features &= ~NETIF_F_ONE_FOR_ALL;
-	features |= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		features = netdev_increment_features(features,
-						     slave->dev->features,
-						     mask);
-	}
-	features = netdev_add_tso_features(features, mask);
-
-	return features;
-}
-
-#define BOND_VLAN_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_FRAGLIST | NETIF_F_ALL_TSO | \
-				 NETIF_F_HIGHDMA | NETIF_F_LRO)
-
-#define BOND_ENC_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_RXCSUM | NETIF_F_ALL_TSO)
-
-#define BOND_MPLS_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_ALL_TSO)
-
-static void bond_compute_features(struct bonding *bond)
-{
-	unsigned int dst_release_flag = IFF_XMIT_DST_RELEASE |
-					IFF_XMIT_DST_RELEASE_PERM;
-	netdev_features_t vlan_features = BOND_VLAN_FEATURES;
-	netdev_features_t enc_features  = BOND_ENC_FEATURES;
-	netdev_features_t mpls_features  = BOND_MPLS_FEATURES;
-	struct net_device *bond_dev = bond->dev;
-	struct list_head *iter;
-	struct slave *slave;
-	unsigned short max_hard_header_len = ETH_HLEN;
-	unsigned int gso_max_size = GSO_MAX_SIZE;
-	u16 gso_max_segs = GSO_MAX_SEGS;
-
-	if (!bond_has_slaves(bond))
-		goto done;
-	vlan_features &= NETIF_F_ALL_FOR_ALL;
-	mpls_features &= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		vlan_features = netdev_increment_features(vlan_features,
-			slave->dev->vlan_features, BOND_VLAN_FEATURES);
-
-		enc_features = netdev_increment_features(enc_features,
-							 slave->dev->hw_enc_features,
-							 BOND_ENC_FEATURES);
-
-		mpls_features = netdev_increment_features(mpls_features,
-							  slave->dev->mpls_features,
-							  BOND_MPLS_FEATURES);
-
-		dst_release_flag &= slave->dev->priv_flags;
-		if (slave->dev->hard_header_len > max_hard_header_len)
-			max_hard_header_len = slave->dev->hard_header_len;
-
-		gso_max_size = min(gso_max_size, slave->dev->gso_max_size);
-		gso_max_segs = min(gso_max_segs, slave->dev->gso_max_segs);
-	}
-	bond_dev->hard_header_len = max_hard_header_len;
-
-done:
-	bond_dev->vlan_features = vlan_features;
-	bond_dev->hw_enc_features = enc_features | NETIF_F_GSO_ENCAP_ALL |
-				    NETIF_F_HW_VLAN_CTAG_TX |
-				    NETIF_F_HW_VLAN_STAG_TX |
-				    NETIF_F_GSO_UDP_L4;
-	bond_dev->mpls_features = mpls_features;
-	bond_dev->gso_max_segs = gso_max_segs;
-	netif_set_gso_max_size(bond_dev, gso_max_size);
-
-	bond_dev->priv_flags &= ~IFF_XMIT_DST_RELEASE;
-	if ((bond_dev->priv_flags & IFF_XMIT_DST_RELEASE_PERM) &&
-	    dst_release_flag == (IFF_XMIT_DST_RELEASE | IFF_XMIT_DST_RELEASE_PERM))
-		bond_dev->priv_flags |= IFF_XMIT_DST_RELEASE;
-
-	netdev_change_features(bond_dev);
-}
-
-static void bond_setup_by_slave(struct net_device *bond_dev,
-				struct net_device *slave_dev)
-{
-	bond_dev->header_ops	    = slave_dev->header_ops;
-
-	bond_dev->type		    = slave_dev->type;
-	bond_dev->hard_header_len   = slave_dev->hard_header_len;
-	bond_dev->needed_headroom   = slave_dev->needed_headroom;
-	bond_dev->addr_len	    = slave_dev->addr_len;
-
-	memcpy(bond_dev->broadcast, slave_dev->broadcast,
-		slave_dev->addr_len);
-}
-
-/* On bonding slaves other than the currently active slave, suppress
- * duplicates except for alb non-mcast/bcast.
- */
-static bool bond_should_deliver_exact_match(struct sk_buff *skb,
-					    struct slave *slave,
-					    struct bonding *bond)
-{
-	if (bond_is_slave_inactive(slave)) {
-		if (BOND_MODE(bond) == BOND_MODE_ALB &&
-		    skb->pkt_type != PACKET_BROADCAST &&
-		    skb->pkt_type != PACKET_MULTICAST)
-			return false;
-		return true;
-	}
-	return false;
-}
-
-static rx_handler_result_t bond_handle_frame(struct sk_buff **pskb)
-{
-	struct sk_buff *skb = *pskb;
-	struct slave *slave;
-	struct bonding *bond;
-	int (*recv_probe)(const struct sk_buff *, struct bonding *,
-			  struct slave *);
-	int ret = RX_HANDLER_ANOTHER;
-
-	skb = skb_share_check(skb, GFP_ATOMIC);
-	if (unlikely(!skb))
-		return RX_HANDLER_CONSUMED;
-
-	*pskb = skb;
-
-	slave = bond_slave_get_rcu(skb->dev);
-	bond = slave->bond;
-
-	recv_probe = READ_ONCE(bond->recv_probe);
-	if (recv_probe) {
-		ret = recv_probe(skb, bond, slave);
-		if (ret == RX_HANDLER_CONSUMED) {
-			consume_skb(skb);
-			return ret;
-		}
-	}
-
-	/*
-	 * For packets determined by bond_should_deliver_exact_match() call to
-	 * be suppressed we want to make an exception for link-local packets.
-	 * This is necessary for e.g. LLDP daemons to be able to monitor
-	 * inactive slave links without being forced to bind to them
-	 * explicitly.
-	 *
-	 * At the same time, packets that are passed to the bonding master
-	 * (including link-local ones) can have their originating interface
-	 * determined via PACKET_ORIGDEV socket option.
-	 */
-	if (bond_should_deliver_exact_match(skb, slave, bond)) {
-		if (is_link_local_ether_addr(eth_hdr(skb)->h_dest))
-			return RX_HANDLER_PASS;
-		return RX_HANDLER_EXACT;
-	}
-
-	skb->dev = bond->dev;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB &&
-	    bond->dev->priv_flags & IFF_BRIDGE_PORT &&
-	    skb->pkt_type == PACKET_HOST) {
-
-		if (unlikely(skb_cow_head(skb,
-					  skb->data - skb_mac_header(skb)))) {
-			kfree_skb(skb);
-			return RX_HANDLER_CONSUMED;
-		}
-		bond_hw_addr_copy(eth_hdr(skb)->h_dest, bond->dev->dev_addr,
-				  bond->dev->addr_len);
-	}
-
-	return ret;
-}
-
-static enum netdev_lag_tx_type bond_lag_tx_type(struct bonding *bond)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return NETDEV_LAG_TX_TYPE_ROUNDROBIN;
-	case BOND_MODE_ACTIVEBACKUP:
-		return NETDEV_LAG_TX_TYPE_ACTIVEBACKUP;
-	case BOND_MODE_BROADCAST:
-		return NETDEV_LAG_TX_TYPE_BROADCAST;
-	case BOND_MODE_XOR:
-	case BOND_MODE_8023AD:
-		return NETDEV_LAG_TX_TYPE_HASH;
-	default:
-		return NETDEV_LAG_TX_TYPE_UNKNOWN;
-	}
-}
-
-static enum netdev_lag_hash bond_lag_hash_type(struct bonding *bond,
-					       enum netdev_lag_tx_type type)
-{
-	if (type != NETDEV_LAG_TX_TYPE_HASH)
-		return NETDEV_LAG_HASH_NONE;
-
-	switch (bond->params.xmit_policy) {
-	case BOND_XMIT_POLICY_LAYER2:
-		return NETDEV_LAG_HASH_L2;
-	case BOND_XMIT_POLICY_LAYER34:
-		return NETDEV_LAG_HASH_L34;
-	case BOND_XMIT_POLICY_LAYER23:
-		return NETDEV_LAG_HASH_L23;
-	case BOND_XMIT_POLICY_ENCAP23:
-		return NETDEV_LAG_HASH_E23;
-	case BOND_XMIT_POLICY_ENCAP34:
-		return NETDEV_LAG_HASH_E34;
-	default:
-		return NETDEV_LAG_HASH_UNKNOWN;
-	}
-}
-
-static int bond_master_upper_dev_link(struct bonding *bond, struct slave *slave,
-				      struct netlink_ext_ack *extack)
-{
-	struct netdev_lag_upper_info lag_upper_info;
-	enum netdev_lag_tx_type type;
-
-	type = bond_lag_tx_type(bond);
-	lag_upper_info.tx_type = type;
-	lag_upper_info.hash_type = bond_lag_hash_type(bond, type);
-
-	return netdev_master_upper_dev_link(slave->dev, bond->dev, slave,
-					    &lag_upper_info, extack);
-}
-
-static void bond_upper_dev_unlink(struct bonding *bond, struct slave *slave)
-{
-	netdev_upper_dev_unlink(slave->dev, bond->dev);
-	slave->dev->flags &= ~IFF_SLAVE;
-}
-
-static void slave_kobj_release(struct kobject *kobj)
-{
-	struct slave *slave = to_slave(kobj);
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-
-	cancel_delayed_work_sync(&slave->notify_work);
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		kfree(SLAVE_AD_INFO(slave));
-
-	kfree(slave);
-}
-
-static struct kobj_type slave_ktype = {
-	.release = slave_kobj_release,
-#ifdef CONFIG_SYSFS
-	.sysfs_ops = &slave_sysfs_ops,
-#endif
-};
-
-static int bond_kobj_init(struct slave *slave)
-{
-	int err;
-
-	err = kobject_init_and_add(&slave->kobj, &slave_ktype,
-				   &(slave->dev->dev.kobj), "bonding_slave");
-	if (err)
-		kobject_put(&slave->kobj);
-
-	return err;
-}
-
-static struct slave *bond_alloc_slave(struct bonding *bond,
-				      struct net_device *slave_dev)
-{
-	struct slave *slave = NULL;
-
-	slave = kzalloc(sizeof(*slave), GFP_KERNEL);
-	if (!slave)
-		return NULL;
-
-	slave->bond = bond;
-	slave->dev = slave_dev;
-
-	if (bond_kobj_init(slave))
-		return NULL;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		SLAVE_AD_INFO(slave) = kzalloc(sizeof(struct ad_slave_info),
-					       GFP_KERNEL);
-		if (!SLAVE_AD_INFO(slave)) {
-			kobject_put(&slave->kobj);
-			return NULL;
-		}
-	}
-	INIT_DELAYED_WORK(&slave->notify_work, bond_netdev_notify_work);
-
-	return slave;
-}
-
-static void bond_fill_ifbond(struct bonding *bond, struct ifbond *info)
-{
-	info->bond_mode = BOND_MODE(bond);
-	info->miimon = bond->params.miimon;
-	info->num_slaves = bond->slave_cnt;
-}
-
-static void bond_fill_ifslave(struct slave *slave, struct ifslave *info)
-{
-	strcpy(info->slave_name, slave->dev->name);
-	info->link = slave->link;
-	info->state = bond_slave_state(slave);
-	info->link_failure_count = slave->link_failure_count;
-}
-
-static void bond_netdev_notify_work(struct work_struct *_work)
-{
-	struct slave *slave = container_of(_work, struct slave,
-					   notify_work.work);
-
-	if (rtnl_trylock()) {
-		struct netdev_bonding_info binfo;
-
-		bond_fill_ifslave(slave, &binfo.slave);
-		bond_fill_ifbond(slave->bond, &binfo.master);
-		netdev_bonding_info_change(slave->dev, &binfo);
-		rtnl_unlock();
-	} else {
-		queue_delayed_work(slave->bond->wq, &slave->notify_work, 1);
-	}
-}
-
-void bond_queue_slave_event(struct slave *slave)
-{
-	queue_delayed_work(slave->bond->wq, &slave->notify_work, 0);
-}
-
-void bond_lower_state_changed(struct slave *slave)
-{
-	struct netdev_lag_lower_state_info info;
-
-	info.link_up = slave->link == BOND_LINK_UP ||
-		       slave->link == BOND_LINK_FAIL;
-	info.tx_enabled = bond_is_active_slave(slave);
-	netdev_lower_state_changed(slave->dev, &info);
-}
-
-/* enslave device <slave> to bond device <master> */
-int bond_enslave(struct net_device *bond_dev, struct net_device *slave_dev,
-		 struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	struct slave *new_slave = NULL, *prev_slave;
-	struct sockaddr_storage ss;
-	int link_reporting;
-	int res = 0, i;
-
-	if (!bond->params.use_carrier &&
-	    slave_dev->ethtool_ops->get_link == NULL &&
-	    slave_ops->ndo_do_ioctl == NULL) {
-		slave_warn(bond_dev, slave_dev, "no link monitoring support\n");
-	}
-
-	/* already in-use? */
-	if (netdev_is_rx_handler_busy(slave_dev)) {
-		NL_SET_ERR_MSG(extack, "Device is in use and cannot be enslaved");
-		slave_err(bond_dev, slave_dev,
-			  "Error: Device is in use and cannot be enslaved\n");
-		return -EBUSY;
-	}
-
-	if (bond_dev == slave_dev) {
-		NL_SET_ERR_MSG(extack, "Cannot enslave bond to itself.");
-		netdev_err(bond_dev, "cannot enslave bond to itself.\n");
-		return -EPERM;
-	}
-
-	/* vlan challenged mutual exclusion */
-	/* no need to lock since we're protected by rtnl_lock */
-	if (slave_dev->features & NETIF_F_VLAN_CHALLENGED) {
-		slave_dbg(bond_dev, slave_dev, "is NETIF_F_VLAN_CHALLENGED\n");
-		if (vlan_uses_dev(bond_dev)) {
-			NL_SET_ERR_MSG(extack, "Can not enslave VLAN challenged device to VLAN enabled bond");
-			slave_err(bond_dev, slave_dev, "Error: cannot enslave VLAN challenged slave on VLAN enabled bond\n");
-			return -EPERM;
-		} else {
-			slave_warn(bond_dev, slave_dev, "enslaved VLAN challenged slave. Adding VLANs will be blocked as long as it is part of bond.\n");
-		}
-	} else {
-		slave_dbg(bond_dev, slave_dev, "is !NETIF_F_VLAN_CHALLENGED\n");
-	}
-
-	/* Old ifenslave binaries are no longer supported.  These can
-	 * be identified with moderate accuracy by the state of the slave:
-	 * the current ifenslave will set the interface down prior to
-	 * enslaving it; the old ifenslave will not.
-	 */
-	if (slave_dev->flags & IFF_UP) {
-		NL_SET_ERR_MSG(extack, "Device can not be enslaved while up");
-		slave_err(bond_dev, slave_dev, "slave is up - this may be due to an out of date ifenslave\n");
-		return -EPERM;
-	}
-
-	/* set bonding device ether type by slave - bonding netdevices are
-	 * created with ether_setup, so when the slave type is not ARPHRD_ETHER
-	 * there is a need to override some of the type dependent attribs/funcs.
-	 *
-	 * bond ether type mutual exclusion - don't allow slaves of dissimilar
-	 * ether type (eg ARPHRD_ETHER and ARPHRD_INFINIBAND) share the same bond
-	 */
-	if (!bond_has_slaves(bond)) {
-		if (bond_dev->type != slave_dev->type) {
-			slave_dbg(bond_dev, slave_dev, "change device type from %d to %d\n",
-				  bond_dev->type, slave_dev->type);
-
-			res = call_netdevice_notifiers(NETDEV_PRE_TYPE_CHANGE,
-						       bond_dev);
-			res = notifier_to_errno(res);
-			if (res) {
-				slave_err(bond_dev, slave_dev, "refused to change device type\n");
-				return -EBUSY;
-			}
-
-			/* Flush unicast and multicast addresses */
-			dev_uc_flush(bond_dev);
-			dev_mc_flush(bond_dev);
-
-			if (slave_dev->type != ARPHRD_ETHER)
-				bond_setup_by_slave(bond_dev, slave_dev);
-			else {
-				ether_setup(bond_dev);
-				bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-			}
-
-			call_netdevice_notifiers(NETDEV_POST_TYPE_CHANGE,
-						 bond_dev);
-		}
-	} else if (bond_dev->type != slave_dev->type) {
-		NL_SET_ERR_MSG(extack, "Device type is different from other slaves");
-		slave_err(bond_dev, slave_dev, "ether type (%d) is different from other slaves (%d), can not enslave it\n",
-			  slave_dev->type, bond_dev->type);
-		return -EINVAL;
-	}
-
-	if (slave_dev->type == ARPHRD_INFINIBAND &&
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		NL_SET_ERR_MSG(extack, "Only active-backup mode is supported for infiniband slaves");
-		slave_warn(bond_dev, slave_dev, "Type (%d) supports only active-backup mode\n",
-			   slave_dev->type);
-		res = -EOPNOTSUPP;
-		goto err_undo_flags;
-	}
-
-	if (!slave_ops->ndo_set_mac_address ||
-	    slave_dev->type == ARPHRD_INFINIBAND) {
-		slave_warn(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address\n");
-		if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
-		    bond->params.fail_over_mac != BOND_FOM_ACTIVE) {
-			if (!bond_has_slaves(bond)) {
-				bond->params.fail_over_mac = BOND_FOM_ACTIVE;
-				slave_warn(bond_dev, slave_dev, "Setting fail_over_mac to active for active-backup mode\n");
-			} else {
-				NL_SET_ERR_MSG(extack, "Slave device does not support setting the MAC address, but fail_over_mac is not set to active");
-				slave_err(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address, but fail_over_mac is not set to active\n");
-				res = -EOPNOTSUPP;
-				goto err_undo_flags;
-			}
-		}
-	}
-
-	call_netdevice_notifiers(NETDEV_JOIN, slave_dev);
-
-	/* If this is the first slave, then we need to set the master's hardware
-	 * address to be the same as the slave's.
-	 */
-	if (!bond_has_slaves(bond) &&
-	    bond->dev->addr_assign_type == NET_ADDR_RANDOM) {
-		res = bond_set_dev_addr(bond->dev, slave_dev);
-		if (res)
-			goto err_undo_flags;
-	}
-
-	new_slave = bond_alloc_slave(bond, slave_dev);
-	if (!new_slave) {
-		res = -ENOMEM;
-		goto err_undo_flags;
-	}
-
-	/* Set the new_slave's queue_id to be zero.  Queue ID mapping
-	 * is set via sysfs or module option if desired.
-	 */
-	new_slave->queue_id = 0;
-
-	/* Save slave's original mtu and then set it to match the bond */
-	new_slave->original_mtu = slave_dev->mtu;
-	res = dev_set_mtu(slave_dev, bond->dev->mtu);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Error %d calling dev_set_mtu\n", res);
-		goto err_free;
-	}
-
-	/* Save slave's original ("permanent") mac address for modes
-	 * that need it, and for restoring it upon release, and then
-	 * set it to the master's address
-	 */
-	bond_hw_addr_copy(new_slave->perm_hwaddr, slave_dev->dev_addr,
-			  slave_dev->addr_len);
-
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* Set slave to master's mac address.  The application already
-		 * set the master's mac address to that of the first slave
-		 */
-		memcpy(ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		res = dev_set_mac_address(slave_dev, (struct sockaddr *)&ss,
-					  extack);
-		if (res) {
-			slave_err(bond_dev, slave_dev, "Error %d calling set_mac_address\n", res);
-			goto err_restore_mtu;
-		}
-	}
-
-	/* set slave flag before open to prevent IPv6 addrconf */
-	slave_dev->flags |= IFF_SLAVE;
-
-	/* open the slave since the application closed it */
-	res = dev_open(slave_dev, extack);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Opening slave failed\n");
-		goto err_restore_mac;
-	}
-
-	slave_dev->priv_flags |= IFF_BONDING;
-	/* initialize slave stats */
-	dev_get_stats(new_slave->dev, &new_slave->slave_stats);
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_init_slave() must be called before all other stages since
-		 * it might fail and we do not want to have to undo everything
-		 */
-		res = bond_alb_init_slave(bond, new_slave);
-		if (res)
-			goto err_close;
-	}
-
-	res = vlan_vids_add_by_dev(slave_dev, bond_dev);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Couldn't add bond vlan ids\n");
-		goto err_close;
-	}
-
-	prev_slave = bond_last_slave(bond);
-
-	new_slave->delay = 0;
-	new_slave->link_failure_count = 0;
-
-	if (bond_update_speed_duplex(new_slave) &&
-	    bond_needs_speed_duplex(bond))
-		new_slave->link = BOND_LINK_DOWN;
-
-	new_slave->last_rx = jiffies -
-		(msecs_to_jiffies(bond->params.arp_interval) + 1);
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
-		new_slave->target_last_arp_rx[i] = new_slave->last_rx;
-
-	if (bond->params.miimon && !bond->params.use_carrier) {
-		link_reporting = bond_check_dev_link(bond, slave_dev, 1);
-
-		if ((link_reporting == -1) && !bond->params.arp_interval) {
-			/* miimon is set but a bonded network driver
-			 * does not support ETHTOOL/MII and
-			 * arp_interval is not set.  Note: if
-			 * use_carrier is enabled, we will never go
-			 * here (because netif_carrier is always
-			 * supported); thus, we don't need to change
-			 * the messages for netif_carrier.
-			 */
-			slave_warn(bond_dev, slave_dev, "MII and ETHTOOL support not available for slave, and arp_interval/arp_ip_target module parameters not specified, thus bonding will not detect link failures! see bonding.txt for details\n");
-		} else if (link_reporting == -1) {
-			/* unable get link status using mii/ethtool */
-			slave_warn(bond_dev, slave_dev, "can't get link status from slave; the network driver associated with this interface does not support MII or ETHTOOL link status reporting, thus miimon has no effect on this interface\n");
-		}
-	}
-
-	/* check for initial state */
-	new_slave->link = BOND_LINK_NOCHANGE;
-	if (bond->params.miimon) {
-		if (bond_check_dev_link(bond, slave_dev, 0) == BMSR_LSTATUS) {
-			if (bond->params.updelay) {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_BACK,
-							  BOND_SLAVE_NOTIFY_NOW);
-				new_slave->delay = bond->params.updelay;
-			} else {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-			}
-		} else {
-			bond_set_slave_link_state(new_slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-		}
-	} else if (bond->params.arp_interval) {
-		bond_set_slave_link_state(new_slave,
-					  (netif_carrier_ok(slave_dev) ?
-					  BOND_LINK_UP : BOND_LINK_DOWN),
-					  BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		bond_set_slave_link_state(new_slave, BOND_LINK_UP,
-					  BOND_SLAVE_NOTIFY_NOW);
-	}
-
-	if (new_slave->link != BOND_LINK_DOWN)
-		new_slave->last_link_up = jiffies;
-	slave_dbg(bond_dev, slave_dev, "Initial state of slave is BOND_LINK_%s\n",
-		  new_slave->link == BOND_LINK_DOWN ? "DOWN" :
-		  (new_slave->link == BOND_LINK_UP ? "UP" : "BACK"));
-
-	if (bond_uses_primary(bond) && bond->params.primary[0]) {
-		/* if there is a primary slave, remember it */
-		if (strcmp(bond->params.primary, new_slave->dev->name) == 0) {
-			rcu_assign_pointer(bond->primary_slave, new_slave);
-			bond->force_primary = true;
-		}
-	}
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ACTIVEBACKUP:
-		bond_set_slave_inactive_flags(new_slave,
-					      BOND_SLAVE_NOTIFY_NOW);
-		break;
-	case BOND_MODE_8023AD:
-		/* in 802.3ad mode, the internal mechanism
-		 * will activate the slaves in the selected
-		 * aggregator
-		 */
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		/* if this is the first slave */
-		if (!prev_slave) {
-			SLAVE_AD_INFO(new_slave)->id = 1;
-			/* Initialize AD with the number of times that the AD timer is called in 1 second
-			 * can be called only after the mac address of the bond is set
-			 */
-			bond_3ad_initialize(bond, 1000/AD_TIMER_INTERVAL);
-		} else {
-			SLAVE_AD_INFO(new_slave)->id =
-				SLAVE_AD_INFO(prev_slave)->id + 1;
-		}
-
-		bond_3ad_bind_slave(new_slave);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_set_active_slave(new_slave);
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		break;
-	default:
-		slave_dbg(bond_dev, slave_dev, "This slave is always active in trunk mode\n");
-
-		/* always active in trunk mode */
-		bond_set_active_slave(new_slave);
-
-		/* In trunking mode there is little meaning to curr_active_slave
-		 * anyway (it holds no special properties of the bond device),
-		 * so we can change it without calling change_active_interface()
-		 */
-		if (!rcu_access_pointer(bond->curr_active_slave) &&
-		    new_slave->link == BOND_LINK_UP)
-			rcu_assign_pointer(bond->curr_active_slave, new_slave);
-
-		break;
-	} /* switch(bond_mode) */
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	if (bond->dev->npinfo) {
-		if (slave_enable_netpoll(new_slave)) {
-			slave_info(bond_dev, slave_dev, "master_dev is using netpoll, but new slave device does not support netpoll\n");
-			res = -EBUSY;
-			goto err_detach;
-		}
-	}
-#endif
-
-	if (!(bond_dev->features & NETIF_F_LRO))
-		dev_disable_lro(slave_dev);
-
-	res = netdev_rx_handler_register(slave_dev, bond_handle_frame,
-					 new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling netdev_rx_handler_register\n", res);
-		goto err_detach;
-	}
-
-	res = bond_master_upper_dev_link(bond, new_slave, extack);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_master_upper_dev_link\n", res);
-		goto err_unregister;
-	}
-
-	res = bond_sysfs_slave_add(new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_sysfs_slave_add\n", res);
-		goto err_upper_unlink;
-	}
-
-	/* If the mode uses primary, then the following is handled by
-	 * bond_change_active_slave().
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* set promiscuity level to new slave */
-		if (bond_dev->flags & IFF_PROMISC) {
-			res = dev_set_promiscuity(slave_dev, 1);
-			if (res)
-				goto err_sysfs_del;
-		}
-
-		/* set allmulti level to new slave */
-		if (bond_dev->flags & IFF_ALLMULTI) {
-			res = dev_set_allmulti(slave_dev, 1);
-			if (res) {
-				if (bond_dev->flags & IFF_PROMISC)
-					dev_set_promiscuity(slave_dev, -1);
-				goto err_sysfs_del;
-			}
-		}
-
-		netif_addr_lock_bh(bond_dev);
-		dev_mc_sync_multiple(slave_dev, bond_dev);
-		dev_uc_sync_multiple(slave_dev, bond_dev);
-		netif_addr_unlock_bh(bond_dev);
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			/* add lacpdu mc addr to mc list */
-			u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-			dev_mc_add(slave_dev, lacpdu_multicast);
-		}
-	}
-
-	bond->slave_cnt++;
-	bond_compute_features(bond);
-	bond_set_carrier(bond);
-
-	if (bond_uses_primary(bond)) {
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-
-	slave_info(bond_dev, slave_dev, "Enslaving as %s interface with %s link\n",
-		   bond_is_active_slave(new_slave) ? "an active" : "a backup",
-		   new_slave->link != BOND_LINK_DOWN ? "an up" : "a down");
-
-	/* enslave is successful */
-	bond_queue_slave_event(new_slave);
-	return 0;
-
-/* Undo stages on error */
-err_sysfs_del:
-	bond_sysfs_slave_del(new_slave);
-
-err_upper_unlink:
-	bond_upper_dev_unlink(bond, new_slave);
-
-err_unregister:
-	netdev_rx_handler_unregister(slave_dev);
-
-err_detach:
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-	if (rcu_access_pointer(bond->primary_slave) == new_slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-	if (rcu_access_pointer(bond->curr_active_slave) == new_slave) {
-		block_netpoll_tx();
-		bond_change_active_slave(bond, NULL);
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-	/* either primary_slave or curr_active_slave might've changed */
-	synchronize_rcu();
-	slave_disable_netpoll(new_slave);
-
-err_close:
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-	dev_close(slave_dev);
-
-err_restore_mac:
-	slave_dev->flags &= ~IFF_SLAVE;
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* XXX TODO - fom follow mode needs to change master's
-		 * MAC if this slave's MAC is in use by the bond, or at
-		 * least print a warning.
-		 */
-		bond_hw_addr_copy(ss.__data, new_slave->perm_hwaddr,
-				  new_slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-err_restore_mtu:
-	dev_set_mtu(slave_dev, new_slave->original_mtu);
-
-err_free:
-	kobject_put(&new_slave->kobj);
-
-err_undo_flags:
-	/* Enslave of first slave has failed and we need to fix master's mac */
-	if (!bond_has_slaves(bond)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr,
-					    slave_dev->dev_addr))
-			eth_hw_addr_random(bond_dev);
-		if (bond_dev->type != ARPHRD_ETHER) {
-			dev_close(bond_dev);
-			ether_setup(bond_dev);
-			bond_dev->flags |= IFF_MASTER;
-			bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-		}
-	}
-
-	return res;
-}
-
-/* Try to release the slave device <slave> from the bond device <master>
- * It is legal to access curr_active_slave without a lock because all the function
- * is RTNL-locked. If "all" is true it means that the function is being called
- * while destroying a bond interface and all slaves are being released.
- *
- * The rules for slave state should be:
- *   for Active/Backup:
- *     Active stays on all backups go down
- *   for Bonded connections:
- *     The first up interface should be left on and all others downed.
- */
-static int __bond_release_one(struct net_device *bond_dev,
-			      struct net_device *slave_dev,
-			      bool all, bool unregister)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *oldcurrent;
-	struct sockaddr_storage ss;
-	int old_flags = bond_dev->flags;
-	netdev_features_t old_features = bond_dev->features;
-
-	/* slave is not a slave or master is not master of this slave */
-	if (!(slave_dev->flags & IFF_SLAVE) ||
-	    !netdev_has_upper_dev(slave_dev, bond_dev)) {
-		slave_dbg(bond_dev, slave_dev, "cannot release slave\n");
-		return -EINVAL;
-	}
-
-	block_netpoll_tx();
-
-	slave = bond_get_slave_by_dev(bond, slave_dev);
-	if (!slave) {
-		/* not a slave of this bond */
-		slave_info(bond_dev, slave_dev, "interface not enslaved\n");
-		unblock_netpoll_tx();
-		return -EINVAL;
-	}
-
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
-	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
-
-	bond_sysfs_slave_del(slave);
-
-	/* recompute stats just before removing the slave */
-	bond_get_stats(bond->dev, &bond->bond_stats);
-
-	bond_upper_dev_unlink(bond, slave);
-	/* unregister rx_handler early so bond_handle_frame wouldn't be called
-	 * for this slave anymore.
-	 */
-	netdev_rx_handler_unregister(slave_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		bond_3ad_unbind_slave(slave);
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, slave);
-
-	slave_info(bond_dev, slave_dev, "Releasing %s interface\n",
-		    bond_is_active_slave(slave) ? "active" : "backup");
-
-	oldcurrent = rcu_access_pointer(bond->curr_active_slave);
-
-	RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-
-	if (!all && (!bond->params.fail_over_mac ||
-		     BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr, slave->perm_hwaddr) &&
-		    bond_has_slaves(bond))
-			slave_warn(bond_dev, slave_dev, "the permanent HWaddr of slave - %pM - is still in use by bond - set the HWaddr of slave to a different address to avoid conflicts\n",
-				   slave->perm_hwaddr);
-	}
-
-	if (rtnl_dereference(bond->primary_slave) == slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-
-	if (oldcurrent == slave)
-		bond_change_active_slave(bond, NULL);
-
-	if (bond_is_lb(bond)) {
-		/* Must be called only after the slave has been
-		 * detached from the list and the curr_active_slave
-		 * has been cleared (if our_slave == old_current),
-		 * but before a new active slave is selected.
-		 */
-		bond_alb_deinit_slave(bond, slave);
-	}
-
-	if (all) {
-		toe_failover(bond_dev, NULL, TOE_RELEASE_ALL, NULL);
-		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
-	} else if (oldcurrent == slave) {
-		/* Note that we hold RTNL over this sequence, so there
-		 * is no concern that another slave add/remove event
-		 * will interfere.
-		 */
-		bond_select_active_slave(bond);
-	}
-
-	if (!bond_has_slaves(bond)) {
-		bond_set_carrier(bond);
-		eth_hw_addr_random(bond_dev);
-	}
-
-	unblock_netpoll_tx();
-	synchronize_rcu();
-	bond->slave_cnt--;
-
-	if (!bond_has_slaves(bond)) {
-		call_netdevice_notifiers(NETDEV_CHANGEADDR, bond->dev);
-		call_netdevice_notifiers(NETDEV_RELEASE, bond->dev);
-	}
-
-	bond_compute_features(bond);
-	if (!(bond_dev->features & NETIF_F_VLAN_CHALLENGED) &&
-	    (old_features & NETIF_F_VLAN_CHALLENGED))
-		slave_info(bond_dev, slave_dev, "last VLAN challenged slave left bond - VLAN blocking is removed\n");
-
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-
-	/* If the mode uses primary, then this case was handled above by
-	 * bond_change_active_slave(..., NULL)
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* unset promiscuity level from slave
-		 * NOTE: The NETDEV_CHANGEADDR call above may change the value
-		 * of the IFF_PROMISC flag in the bond_dev, but we need the
-		 * value of that flag before that change, as that was the value
-		 * when this slave was attached, so we cache at the start of the
-		 * function and use it here. Same goes for ALLMULTI below
-		 */
-		if (old_flags & IFF_PROMISC)
-			dev_set_promiscuity(slave_dev, -1);
-
-		/* unset allmulti level from slave */
-		if (old_flags & IFF_ALLMULTI)
-			dev_set_allmulti(slave_dev, -1);
-
-		bond_hw_addr_flush(bond_dev, slave_dev);
-	}
-
-	slave_disable_netpoll(slave);
-
-	/* close slave before restoring its mac address */
-	dev_close(slave_dev);
-
-	if (bond->params.fail_over_mac != BOND_FOM_ACTIVE ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* restore original ("permanent") mac address */
-		bond_hw_addr_copy(ss.__data, slave->perm_hwaddr,
-				  slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-	if (unregister)
-		__dev_set_mtu(slave_dev, slave->original_mtu);
-	else
-		dev_set_mtu(slave_dev, slave->original_mtu);
-
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-
-	kobject_put(&slave->kobj);
-
-	return 0;
-}
-
-/* A wrapper used because of ndo_del_link */
-int bond_release(struct net_device *bond_dev, struct net_device *slave_dev)
-{
-	return __bond_release_one(bond_dev, slave_dev, false, false);
-}
-
-/* First release a slave and then destroy the bond if no more slaves are left.
- * Must be under rtnl_lock when this function is called.
- */
-static int bond_release_and_destroy(struct net_device *bond_dev,
-				    struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	int ret;
-
-	ret = __bond_release_one(bond_dev, slave_dev, false, true);
-	if (ret == 0 && !bond_has_slaves(bond) &&
-	    bond_dev->reg_state != NETREG_UNREGISTERING) {
-		bond_dev->priv_flags |= IFF_DISABLE_NETPOLL;
-		netdev_info(bond_dev, "Destroying bond\n");
-		bond_remove_proc_entry(bond);
-		unregister_netdevice(bond_dev);
-	}
-	return ret;
-}
-
-static void bond_info_query(struct net_device *bond_dev, struct ifbond *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	bond_fill_ifbond(bond, info);
-}
-
-static int bond_slave_info_query(struct net_device *bond_dev, struct ifslave *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	int i = 0, res = -ENODEV;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (i++ == (int)info->slave_id) {
-			res = 0;
-			bond_fill_ifslave(slave, info);
-			break;
-		}
-	}
-
-	return res;
-}
-
-/*-------------------------------- Monitoring -------------------------------*/
-
-/* called with rcu_read_lock() */
-static int bond_miimon_inspect(struct bonding *bond)
-{
-	int link_state, commit = 0;
-	struct list_head *iter;
-	struct slave *slave;
-	bool ignore_updelay;
-
-	ignore_updelay = !rcu_dereference(bond->curr_active_slave);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		link_state = bond_check_dev_link(bond, slave->dev, 0);
-
-		switch (slave->link) {
-		case BOND_LINK_UP:
-			if (link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_FAIL);
-			commit++;
-			slave->delay = bond->params.downdelay;
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status down for %sinterface, disabling it in %d ms\n",
-					   (BOND_MODE(bond) ==
-					    BOND_MODE_ACTIVEBACKUP) ?
-					    (bond_is_active_slave(slave) ?
-					     "active " : "backup ") : "",
-					   bond->params.downdelay * bond->params.miimon);
-			}
-			/*FALLTHRU*/
-		case BOND_LINK_FAIL:
-			if (link_state) {
-				/* recovered before downdelay expired */
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave->last_link_up = jiffies;
-				slave_info(bond->dev, slave->dev, "link status up again after %d ms\n",
-					   (bond->params.downdelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				commit++;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-
-		case BOND_LINK_DOWN:
-			if (!link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_BACK);
-			commit++;
-			slave->delay = bond->params.updelay;
-
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status up, enabling it in %d ms\n",
-					   ignore_updelay ? 0 :
-					   bond->params.updelay *
-					   bond->params.miimon);
-			}
-			/*FALLTHRU*/
-		case BOND_LINK_BACK:
-			if (!link_state) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_info(bond->dev, slave->dev, "link status down again after %d ms\n",
-					   (bond->params.updelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (ignore_updelay)
-				slave->delay = 0;
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-				ignore_updelay = false;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-		}
-	}
-
-	return commit;
-}
-
-static void bond_miimon_link_change(struct bonding *bond,
-				    struct slave *slave,
-				    char link)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_8023AD:
-		bond_3ad_handle_link_change(slave, link);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_alb_handle_link_change(bond, slave, link);
-		break;
-	case BOND_MODE_XOR:
-		bond_update_slave_arr(bond, NULL);
-		break;
-	}
-}
-
-static void bond_miimon_commit(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave, *primary;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			/* For 802.3ad mode, check current slave speed and
-			 * duplex again in case its port was disabled after
-			 * invalid speed/duplex reporting but recovered before
-			 * link monitoring could make a decision on the actual
-			 * link status
-			 */
-			if (BOND_MODE(bond) == BOND_MODE_8023AD &&
-			    slave->link == BOND_LINK_UP)
-				bond_3ad_adapter_speed_duplex_changed(slave);
-			continue;
-
-		case BOND_LINK_UP:
-			if (bond_update_speed_duplex(slave) &&
-			    bond_needs_speed_duplex(bond)) {
-				slave->link = BOND_LINK_DOWN;
-				if (net_ratelimit())
-					slave_warn(bond->dev, slave->dev,
-						   "failed to get link speed/duplex\n");
-				continue;
-			}
-			bond_set_slave_link_state(slave, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-			slave->last_link_up = jiffies;
-
-			primary = rtnl_dereference(bond->primary_slave);
-			if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-				/* prevent it from being the active one */
-				bond_set_backup_slave(slave);
-			} else if (BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-				/* make it immediately active */
-				bond_set_active_slave(slave);
-			}
-
-			slave_info(bond->dev, slave->dev, "link status definitely up, %u Mbps %s duplex\n",
-				   slave->speed == SPEED_UNKNOWN ? 0 : slave->speed,
-				   slave->duplex ? "full" : "half");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_UP);
-
-			if (BOND_MODE(bond) == BOND_MODE_XOR ||
-			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
-				toe_failover(netdev_master_upper_dev_get(slave->dev),
-					     slave->dev, TOE_LINK_UP, NULL);
-
-			if (!bond->curr_active_slave || slave == primary)
-				goto do_failover;
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP ||
-			    BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_DOWN);
-
-			if (BOND_MODE(bond) == BOND_MODE_XOR ||
-			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
-				toe_failover(netdev_master_upper_dev_get(slave->dev),
-					     slave->dev, TOE_LINK_DOWN, NULL);
-
-			if (slave == rcu_access_pointer(bond->curr_active_slave))
-				goto do_failover;
-
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev, "invalid new link %d on slave\n",
-				  slave->link_new_state);
-			bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* bond_mii_monitor
- *
- * Really a wrapper that splits the mii monitor into two phases: an
- * inspection, then (if inspection indicates something needs to be done)
- * an acquisition of appropriate locks followed by a commit phase to
- * implement whatever link state changes are indicated.
- */
-static void bond_mii_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mii_work.work);
-	bool should_notify_peers = false;
-	bool commit;
-	unsigned long delay;
-	struct slave *slave;
-	struct list_head *iter;
-
-	delay = msecs_to_jiffies(bond->params.miimon);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-	should_notify_peers = bond_should_notify_peers(bond);
-	commit = !!bond_miimon_inspect(bond);
-	if (bond->send_peer_notif) {
-		rcu_read_unlock();
-		if (rtnl_trylock()) {
-			bond->send_peer_notif--;
-			rtnl_unlock();
-		}
-	} else {
-		rcu_read_unlock();
-	}
-
-	if (commit) {
-		/* Race avoidance with bond_close cancel of workqueue */
-		if (!rtnl_trylock()) {
-			delay = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_for_each_slave(bond, slave, iter) {
-			bond_commit_link_state(slave, BOND_SLAVE_NOTIFY_LATER);
-		}
-		bond_miimon_commit(bond);
-
-		rtnl_unlock();	/* might sleep, hold no other locks */
-	}
-
-re_arm:
-	if (bond->params.miimon)
-		queue_delayed_work(bond->wq, &bond->mii_work, delay);
-
-	if (should_notify_peers) {
-		if (!rtnl_trylock())
-			return;
-		call_netdevice_notifiers(NETDEV_NOTIFY_PEERS, bond->dev);
-		rtnl_unlock();
-	}
-}
-
-static int bond_upper_dev_walk(struct net_device *upper, void *data)
-{
-	__be32 ip = *((__be32 *)data);
-
-	return ip == bond_confirm_addr(upper, 0, ip);
-}
-
-static bool bond_has_this_ip(struct bonding *bond, __be32 ip)
-{
-	bool ret = false;
-
-	if (ip == bond_confirm_addr(bond->dev, 0, ip))
-		return true;
-
-	rcu_read_lock();
-	if (netdev_walk_all_upper_dev_rcu(bond->dev, bond_upper_dev_walk, &ip))
-		ret = true;
-	rcu_read_unlock();
-
-	return ret;
-}
-
-/* We go to the (large) trouble of VLAN tagging ARP frames because
- * switches in VLAN mode (especially if ports are configured as
- * "native" to a VLAN) might not pass non-tagged frames.
- */
-static void bond_arp_send(struct slave *slave, int arp_op, __be32 dest_ip,
-			  __be32 src_ip, struct bond_vlan_tag *tags)
-{
-	struct sk_buff *skb;
-	struct bond_vlan_tag *outer_tag = tags;
-	struct net_device *slave_dev = slave->dev;
-	struct net_device *bond_dev = slave->bond->dev;
-
-	slave_dbg(bond_dev, slave_dev, "arp %d on slave: dst %pI4 src %pI4\n",
-		  arp_op, &dest_ip, &src_ip);
-
-	skb = arp_create(arp_op, ETH_P_ARP, dest_ip, slave_dev, src_ip,
-			 NULL, slave_dev->dev_addr, NULL);
-
-	if (!skb) {
-		net_err_ratelimited("ARP packet allocation failed\n");
-		return;
-	}
-
-	if (!tags || tags->vlan_proto == VLAN_N_VID)
-		goto xmit;
-
-	tags++;
-
-	/* Go through all the tags backwards and add them to the packet */
-	while (tags->vlan_proto != VLAN_N_VID) {
-		if (!tags->vlan_id) {
-			tags++;
-			continue;
-		}
-
-		slave_dbg(bond_dev, slave_dev, "inner tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), tags->vlan_id);
-		skb = vlan_insert_tag_set_proto(skb, tags->vlan_proto,
-						tags->vlan_id);
-		if (!skb) {
-			net_err_ratelimited("failed to insert inner VLAN tag\n");
-			return;
-		}
-
-		tags++;
-	}
-	/* Set the outer tag */
-	if (outer_tag->vlan_id) {
-		slave_dbg(bond_dev, slave_dev, "outer tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), outer_tag->vlan_id);
-		__vlan_hwaccel_put_tag(skb, outer_tag->vlan_proto,
-				       outer_tag->vlan_id);
-	}
-
-xmit:
-	arp_xmit(skb);
-}
-
-/* Validate the device path between the @start_dev and the @end_dev.
- * The path is valid if the @end_dev is reachable through device
- * stacking.
- * When the path is validated, collect any vlan information in the
- * path.
- */
-struct bond_vlan_tag *bond_verify_device_path(struct net_device *start_dev,
-					      struct net_device *end_dev,
-					      int level)
-{
-	struct bond_vlan_tag *tags;
-	struct net_device *upper;
-	struct list_head  *iter;
-
-	if (start_dev == end_dev) {
-		tags = kcalloc(level + 1, sizeof(*tags), GFP_ATOMIC);
-		if (!tags)
-			return ERR_PTR(-ENOMEM);
-		tags[level].vlan_proto = VLAN_N_VID;
-		return tags;
-	}
-
-	netdev_for_each_upper_dev_rcu(start_dev, upper, iter) {
-		tags = bond_verify_device_path(upper, end_dev, level + 1);
-		if (IS_ERR_OR_NULL(tags)) {
-			if (IS_ERR(tags))
-				return tags;
-			continue;
-		}
-		if (is_vlan_dev(upper)) {
-			tags[level].vlan_proto = vlan_dev_vlan_proto(upper);
-			tags[level].vlan_id = vlan_dev_vlan_id(upper);
-		}
-
-		return tags;
-	}
-
-	return NULL;
-}
-
-static void bond_arp_send_all(struct bonding *bond, struct slave *slave)
-{
-	struct rtable *rt;
-	struct bond_vlan_tag *tags;
-	__be32 *targets = bond->params.arp_targets, addr;
-	int i;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS && targets[i]; i++) {
-		slave_dbg(bond->dev, slave->dev, "%s: target %pI4\n",
-			  __func__, &targets[i]);
-		tags = NULL;
-
-		/* Find out through which dev should the packet go */
-		rt = ip_route_output(dev_net(bond->dev), targets[i], 0,
-				     RTO_ONLINK, 0);
-		if (IS_ERR(rt)) {
-			/* there's no route to target - try to send arp
-			 * probe to generate any traffic (arp_validate=0)
-			 */
-			if (bond->params.arp_validate)
-				net_warn_ratelimited("%s: no route to arp_ip_target %pI4 and arp_validate is set\n",
-						     bond->dev->name,
-						     &targets[i]);
-			bond_arp_send(slave, ARPOP_REQUEST, targets[i],
-				      0, tags);
-			continue;
-		}
-
-		/* bond device itself */
-		if (rt->dst.dev == bond->dev)
-			goto found;
-
-		rcu_read_lock();
-		tags = bond_verify_device_path(bond->dev, rt->dst.dev, 0);
-		rcu_read_unlock();
-
-		if (!IS_ERR_OR_NULL(tags))
-			goto found;
-
-		/* Not our device - skip */
-		slave_dbg(bond->dev, slave->dev, "no path to arp_ip_target %pI4 via rt.dev %s\n",
-			   &targets[i], rt->dst.dev ? rt->dst.dev->name : "NULL");
-
-		ip_rt_put(rt);
-		continue;
-
-found:
-		addr = bond_confirm_addr(rt->dst.dev, targets[i], 0);
-		ip_rt_put(rt);
-		bond_arp_send(slave, ARPOP_REQUEST, targets[i], addr, tags);
-		kfree(tags);
-	}
-}
-
-static void bond_validate_arp(struct bonding *bond, struct slave *slave, __be32 sip, __be32 tip)
-{
-	int i;
-
-	if (!sip || !bond_has_this_ip(bond, tip)) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 tip %pI4 not found\n",
-			   __func__, &sip, &tip);
-		return;
-	}
-
-	i = bond_get_targets_ip(bond->params.arp_targets, sip);
-	if (i == -1) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 not found in targets\n",
-			   __func__, &sip);
-		return;
-	}
-	slave->last_rx = jiffies;
-	slave->target_last_arp_rx[i] = jiffies;
-}
-
-int bond_arp_rcv(const struct sk_buff *skb, struct bonding *bond,
-		 struct slave *slave)
-{
-	struct arphdr *arp = (struct arphdr *)skb->data;
-	struct slave *curr_active_slave, *curr_arp_slave;
-	unsigned char *arp_ptr;
-	__be32 sip, tip;
-	int is_arp = skb->protocol == __cpu_to_be16(ETH_P_ARP);
-	unsigned int alen;
-
-	if (!slave_do_arp_validate(bond, slave)) {
-		if ((slave_do_arp_validate_only(bond) && is_arp) ||
-		    !slave_do_arp_validate_only(bond))
-			slave->last_rx = jiffies;
-		return RX_HANDLER_ANOTHER;
-	} else if (!is_arp) {
-		return RX_HANDLER_ANOTHER;
-	}
-
-	alen = arp_hdr_len(bond->dev);
-
-	slave_dbg(bond->dev, slave->dev, "%s: skb->dev %s\n",
-		   __func__, skb->dev->name);
-
-	if (alen > skb_headlen(skb)) {
-		arp = kmalloc(alen, GFP_ATOMIC);
-		if (!arp)
-			goto out_unlock;
-		if (skb_copy_bits(skb, 0, arp, alen) < 0)
-			goto out_unlock;
-	}
-
-	if (arp->ar_hln != bond->dev->addr_len ||
-	    skb->pkt_type == PACKET_OTHERHOST ||
-	    skb->pkt_type == PACKET_LOOPBACK ||
-	    arp->ar_hrd != htons(ARPHRD_ETHER) ||
-	    arp->ar_pro != htons(ETH_P_IP) ||
-	    arp->ar_pln != 4)
-		goto out_unlock;
-
-	arp_ptr = (unsigned char *)(arp + 1);
-	arp_ptr += bond->dev->addr_len;
-	memcpy(&sip, arp_ptr, 4);
-	arp_ptr += 4 + bond->dev->addr_len;
-	memcpy(&tip, arp_ptr, 4);
-
-	slave_dbg(bond->dev, slave->dev, "%s: %s/%d av %d sv %d sip %pI4 tip %pI4\n",
-		  __func__, slave->dev->name, bond_slave_state(slave),
-		  bond->params.arp_validate, slave_do_arp_validate(bond, slave),
-		  &sip, &tip);
-
-	curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	curr_arp_slave = rcu_dereference(bond->current_arp_slave);
-
-	/* We 'trust' the received ARP enough to validate it if:
-	 *
-	 * (a) the slave receiving the ARP is active (which includes the
-	 * current ARP slave, if any), or
-	 *
-	 * (b) the receiving slave isn't active, but there is a currently
-	 * active slave and it received valid arp reply(s) after it became
-	 * the currently active slave, or
-	 *
-	 * (c) there is an ARP slave that sent an ARP during the prior ARP
-	 * interval, and we receive an ARP reply on any slave.  We accept
-	 * these because switch FDB update delays may deliver the ARP
-	 * reply to a slave other than the sender of the ARP request.
-	 *
-	 * Note: for (b), backup slaves are receiving the broadcast ARP
-	 * request, not a reply.  This request passes from the sending
-	 * slave through the L2 switch(es) to the receiving slave.  Since
-	 * this is checking the request, sip/tip are swapped for
-	 * validation.
-	 *
-	 * This is done to avoid endless looping when we can't reach the
-	 * arp_ip_target and fool ourselves with our own arp requests.
-	 */
-	if (bond_is_active_slave(slave))
-		bond_validate_arp(bond, slave, sip, tip);
-	else if (curr_active_slave &&
-		 time_after(slave_last_rx(bond, curr_active_slave),
-			    curr_active_slave->last_link_up))
-		bond_validate_arp(bond, slave, tip, sip);
-	else if (curr_arp_slave && (arp->ar_op == htons(ARPOP_REPLY)) &&
-		 bond_time_in_interval(bond,
-				       dev_trans_start(curr_arp_slave->dev), 1))
-		bond_validate_arp(bond, slave, sip, tip);
-
-out_unlock:
-	if (arp != (struct arphdr *)skb->data)
-		kfree(arp);
-	return RX_HANDLER_ANOTHER;
-}
-
-/* function to verify if we're in the arp_interval timeslice, returns true if
- * (last_act - arp_interval) <= jiffies <= (last_act + mod * arp_interval +
- * arp_interval/2) . the arp_interval/2 is needed for really fast networks.
- */
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod)
-{
-	int delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	return time_in_range(jiffies,
-			     last_act - delta_in_ticks,
-			     last_act + mod * delta_in_ticks + delta_in_ticks/2);
-}
-
-/* This function is called regularly to monitor each slave's link
- * ensuring that traffic is being sent and received when arp monitoring
- * is used in load-balancing mode. if the adapter has been dormant, then an
- * arp is transmitted to generate traffic. see activebackup_arp_monitor for
- * arp monitoring in active backup mode.
- */
-static void bond_loadbalance_arp_mon(struct bonding *bond)
-{
-	struct slave *slave, *oldcurrent;
-	struct list_head *iter;
-	int do_failover = 0, slave_state_changed = 0;
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	oldcurrent = rcu_dereference(bond->curr_active_slave);
-	/* see if any of the previous devices are up now (i.e. they have
-	 * xmt and rcv traffic). the curr_active_slave does not come into
-	 * the picture unless it is null. also, slave->last_link_up is not
-	 * needed here because we send an arp on each slave and give a slave
-	 * as long as it needs to get the tx/rx within the delta.
-	 * TODO: what about up/down delay in arp mode? it wasn't here before
-	 *       so it can wait
-	 */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		unsigned long trans_start = dev_trans_start(slave->dev);
-
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, trans_start, 1) &&
-			    bond_time_in_interval(bond, slave->last_rx, 1)) {
-
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave_state_changed = 1;
-
-				/* primary_slave has no meaning in round-robin
-				 * mode. the window of a slave being up and
-				 * curr_active_slave being null after enslaving
-				 * is closed.
-				 */
-				if (!oldcurrent) {
-					slave_info(bond->dev, slave->dev, "link status definitely up\n");
-					do_failover = 1;
-				} else {
-					slave_info(bond->dev, slave->dev, "interface is now up\n");
-				}
-			}
-		} else {
-			/* slave->link == BOND_LINK_UP */
-
-			/* not all switches will respond to an arp request
-			 * when the source ip is 0, so don't take the link down
-			 * if we don't know our ip yet
-			 */
-			if (!bond_time_in_interval(bond, trans_start, 2) ||
-			    !bond_time_in_interval(bond, slave->last_rx, 2)) {
-
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_state_changed = 1;
-
-				if (slave->link_failure_count < UINT_MAX)
-					slave->link_failure_count++;
-
-				slave_info(bond->dev, slave->dev, "interface is now down\n");
-
-				if (slave == oldcurrent)
-					do_failover = 1;
-			}
-		}
-
-		/* note: if switch is in round-robin mode, all links
-		 * must tx arp to ensure all links rx an arp - otherwise
-		 * links may oscillate or not come up at all; if switch is
-		 * in something like xor mode, there is nothing we can
-		 * do - all replies will be rx'ed on same link causing slaves
-		 * to be unstable during low/no traffic periods
-		 */
-		if (bond_slave_is_up(slave))
-			bond_arp_send_all(bond, slave);
-	}
-
-	rcu_read_unlock();
-
-	if (do_failover || slave_state_changed) {
-		if (!rtnl_trylock())
-			goto re_arm;
-
-		bond_for_each_slave(bond, slave, iter) {
-			if (slave->link_new_state != BOND_LINK_NOCHANGE)
-				slave->link = slave->link_new_state;
-		}
-
-		if (slave_state_changed) {
-			bond_slave_state_change(bond);
-			if (BOND_MODE(bond) == BOND_MODE_XOR)
-				bond_update_slave_arr(bond, NULL);
-		}
-		if (do_failover) {
-			block_netpoll_tx();
-			bond_select_active_slave(bond);
-			unblock_netpoll_tx();
-		}
-		rtnl_unlock();
-	}
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work,
-				   msecs_to_jiffies(bond->params.arp_interval));
-}
-
-/* Called to inspect slaves for active-backup mode ARP monitor link state
- * changes.  Sets proposed link state in slaves to specify what action
- * should take place for the slave.  Returns 0 if no changes are found, >0
- * if changes to link states must be committed.
- *
- * Called with rcu_read_lock held.
- */
-static int bond_ab_arp_inspect(struct bonding *bond)
-{
-	unsigned long trans_start, last_rx;
-	struct list_head *iter;
-	struct slave *slave;
-	int commit = 0;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-		last_rx = slave_last_rx(bond, slave);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, last_rx, 1)) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-			} else if (slave->link == BOND_LINK_BACK) {
-				bond_propose_link_state(slave, BOND_LINK_FAIL);
-				commit++;
-			}
-			continue;
-		}
-
-		/* Give slaves 2*delta after being enslaved or made
-		 * active.  This avoids bouncing, as the last receive
-		 * times need a full ARP monitor cycle to be updated.
-		 */
-		if (bond_time_in_interval(bond, slave->last_link_up, 2))
-			continue;
-
-		/* Backup slave is down if:
-		 * - No current_arp_slave AND
-		 * - more than 3*delta since last receive AND
-		 * - the bond has an IP address
-		 *
-		 * Note: a non-null current_arp_slave indicates
-		 * the curr_active_slave went down and we are
-		 * searching for a new one; under this condition
-		 * we only take the curr_active_slave down - this
-		 * gives each slave a chance to tx/rx traffic
-		 * before being taken out
-		 */
-		if (!bond_is_active_slave(slave) &&
-		    !rcu_access_pointer(bond->current_arp_slave) &&
-		    !bond_time_in_interval(bond, last_rx, 3)) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-
-		/* Active slave is down if:
-		 * - more than 2*delta since transmitting OR
-		 * - (more than 2*delta since receive AND
-		 *    the bond has an IP address)
-		 */
-		trans_start = dev_trans_start(slave->dev);
-		if (bond_is_active_slave(slave) &&
-		    (!bond_time_in_interval(bond, trans_start, 2) ||
-		     !bond_time_in_interval(bond, last_rx, 2))) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-	}
-
-	return commit;
-}
-
-/* Called to commit link state changes noted by inspection step of
- * active-backup mode ARP monitor.
- *
- * Called with RTNL hold.
- */
-static void bond_ab_arp_commit(struct bonding *bond)
-{
-	unsigned long trans_start;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			continue;
-
-		case BOND_LINK_UP:
-			trans_start = dev_trans_start(slave->dev);
-			if (rtnl_dereference(bond->curr_active_slave) != slave ||
-			    (!rtnl_dereference(bond->curr_active_slave) &&
-			     bond_time_in_interval(bond, trans_start, 1))) {
-				struct slave *current_arp_slave;
-
-				current_arp_slave = rtnl_dereference(bond->current_arp_slave);
-				bond_set_slave_link_state(slave, BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-				if (current_arp_slave) {
-					bond_set_slave_inactive_flags(
-						current_arp_slave,
-						BOND_SLAVE_NOTIFY_NOW);
-					RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				}
-
-				slave_info(bond->dev, slave->dev, "link status definitely up\n");
-
-				if (!rtnl_dereference(bond->curr_active_slave) ||
-				    slave == rtnl_dereference(bond->primary_slave))
-					goto do_failover;
-
-			}
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			if (slave == rtnl_dereference(bond->curr_active_slave)) {
-				RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				goto do_failover;
-			}
-
-			continue;
-
-		case BOND_LINK_FAIL:
-			bond_set_slave_link_state(slave, BOND_LINK_FAIL,
-						  BOND_SLAVE_NOTIFY_NOW);
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-			/* A slave has just been enslaved and has become
-			 * the current active slave.
-			 */
-			if (rtnl_dereference(bond->curr_active_slave))
-				RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev,
-				  "impossible: link_new_state %d on slave\n",
-				  slave->link_new_state);
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* Send ARP probes for active-backup mode ARP monitor.
- *
- * Called with rcu_read_lock held.
- */
-static bool bond_ab_arp_probe(struct bonding *bond)
-{
-	struct slave *slave, *before = NULL, *new_slave = NULL,
-		     *curr_arp_slave = rcu_dereference(bond->current_arp_slave),
-		     *curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	struct list_head *iter;
-	bool found = false;
-	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
-
-	if (curr_arp_slave && curr_active_slave)
-		netdev_info(bond->dev, "PROBE: c_arp %s && cas %s BAD\n",
-			    curr_arp_slave->dev->name,
-			    curr_active_slave->dev->name);
-
-	if (curr_active_slave) {
-		bond_arp_send_all(bond, curr_active_slave);
-		return should_notify_rtnl;
-	}
-
-	/* if we don't have a curr_active_slave, search for the next available
-	 * backup slave from the current_arp_slave and make it the candidate
-	 * for becoming the curr_active_slave
-	 */
-
-	if (!curr_arp_slave) {
-		curr_arp_slave = bond_first_slave_rcu(bond);
-		if (!curr_arp_slave)
-			return should_notify_rtnl;
-	}
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!found && !before && bond_slave_is_up(slave))
-			before = slave;
-
-		if (found && !new_slave && bond_slave_is_up(slave))
-			new_slave = slave;
-		/* if the link state is up at this point, we
-		 * mark it down - this can happen if we have
-		 * simultaneous link failures and
-		 * reselect_active_interface doesn't make this
-		 * one the current slave so it is still marked
-		 * up when it is actually down
-		 */
-		if (!bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_LATER);
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_LATER);
-
-			slave_info(bond->dev, slave->dev, "backup interface is now down\n");
-		}
-		if (slave == curr_arp_slave)
-			found = true;
-	}
-
-	if (!new_slave && before)
-		new_slave = before;
-
-	if (!new_slave)
-		goto check_state;
-
-	bond_set_slave_link_state(new_slave, BOND_LINK_BACK,
-				  BOND_SLAVE_NOTIFY_LATER);
-	bond_set_slave_active_flags(new_slave, BOND_SLAVE_NOTIFY_LATER);
-	bond_arp_send_all(bond, new_slave);
-	new_slave->last_link_up = jiffies;
-	rcu_assign_pointer(bond->current_arp_slave, new_slave);
-
-check_state:
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->should_notify || slave->should_notify_link) {
-			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
-			break;
-		}
-	}
-	return should_notify_rtnl;
-}
-
-static void bond_activebackup_arp_mon(struct bonding *bond)
-{
-	bool should_notify_peers = false;
-	bool should_notify_rtnl = false;
-	int delta_in_ticks;
-
-	delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	should_notify_peers = bond_should_notify_peers(bond);
-
-	if (bond_ab_arp_inspect(bond)) {
-		rcu_read_unlock();
-
-		/* Race avoidance with bond_close flush of workqueue */
-		if (!rtnl_trylock()) {
-			delta_in_ticks = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_ab_arp_commit(bond);
-
-		rtnl_unlock();
-		rcu_read_lock();
-	}
-
-	should_notify_rtnl = bond_ab_arp_probe(bond);
-	rcu_read_unlock();
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work, delta_in_ticks);
-
-	if (should_notify_peers || should_notify_rtnl) {
-		if (!rtnl_trylock())
-			return;
-
-		if (should_notify_peers)
-			call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-						 bond->dev);
-		if (should_notify_rtnl) {
-			bond_slave_state_notify(bond);
-			bond_slave_link_notify(bond);
-		}
-
-		rtnl_unlock();
-	}
-}
-
-static void bond_arp_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    arp_work.work);
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		bond_activebackup_arp_mon(bond);
-	else
-		bond_loadbalance_arp_mon(bond);
-}
-
-/*-------------------------- netdev event handling --------------------------*/
-
-/* Change device name */
-static int bond_event_changename(struct bonding *bond)
-{
-	bond_remove_proc_entry(bond);
-	bond_create_proc_entry(bond);
-
-	bond_debug_reregister(bond);
-
-	return NOTIFY_DONE;
-}
-
-static int bond_master_netdev_event(unsigned long event,
-				    struct net_device *bond_dev)
-{
-	struct bonding *event_bond = netdev_priv(bond_dev);
-
-	netdev_dbg(bond_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_CHANGENAME:
-		return bond_event_changename(event_bond);
-	case NETDEV_UNREGISTER:
-		bond_remove_proc_entry(event_bond);
-		break;
-	case NETDEV_REGISTER:
-		bond_create_proc_entry(event_bond);
-		break;
-	case NETDEV_DOWN: {
-		struct slave *slave = bond_first_slave(event_bond);
-
-		toe_failover(bond_dev, slave ? slave->dev : NULL,
-			     TOE_BOND_DOWN, NULL);
-		break;
-	}
-	case NETDEV_UP: {
-		struct slave *slave = bond_first_slave(event_bond);
-
-		toe_failover(bond_dev, slave ? slave->dev : NULL,
-		TOE_BOND_UP, NULL);
-		break;
-	}
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-static int bond_slave_netdev_event(unsigned long event,
-				   struct net_device *slave_dev)
-{
-	struct slave *slave = bond_slave_get_rtnl(slave_dev), *primary;
-	struct bonding *bond;
-	struct net_device *bond_dev;
-
-	/* A netdev event can be generated while enslaving a device
-	 * before netdev_rx_handler_register is called in which case
-	 * slave will be NULL
-	 */
-	if (!slave) {
-		netdev_dbg(slave_dev, "%s called on NULL slave\n", __func__);
-		return NOTIFY_DONE;
-	}
-
-	bond_dev = slave->bond->dev;
-	bond = slave->bond;
-	primary = rtnl_dereference(bond->primary_slave);
-
-	slave_dbg(bond_dev, slave_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_UNREGISTER:
-		if (bond_dev->type != ARPHRD_ETHER)
-			bond_release_and_destroy(bond_dev, slave_dev);
-		else
-			__bond_release_one(bond_dev, slave_dev, false, true);
-		break;
-	case NETDEV_UP:
-	case NETDEV_CHANGE:
-		/* For 802.3ad mode only:
-		 * Getting invalid Speed/Duplex values here will put slave
-		 * in weird state. Mark it as link-fail if the link was
-		 * previously up or link-down if it hasn't yet come up, and
-		 * let link-monitoring (miimon) set it right when correct
-		 * speeds/duplex are available.
-		 */
-		if (bond_update_speed_duplex(slave) &&
-		    BOND_MODE(bond) == BOND_MODE_8023AD) {
-			if (slave->last_link_up)
-				slave->link = BOND_LINK_FAIL;
-			else
-				slave->link = BOND_LINK_DOWN;
-		}
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD)
-			bond_3ad_adapter_speed_duplex_changed(slave);
-		/* Fallthrough */
-	case NETDEV_DOWN:
-		/* Refresh slave-array if applicable!
-		 * If the setup does not use miimon or arpmon (mode-specific!),
-		 * then these events will not cause the slave-array to be
-		 * refreshed. This will cause xmit to use a slave that is not
-		 * usable. Avoid such situation by refeshing the array at these
-		 * events. If these (miimon/arpmon) parameters are configured
-		 * then array gets refreshed twice and that should be fine!
-		 */
-		if (bond_mode_can_use_xmit_hash(bond))
-			bond_update_slave_arr(bond, NULL);
-		break;
-	case NETDEV_CHANGEMTU:
-		/* TODO: Should slaves be allowed to
-		 * independently alter their MTU?  For
-		 * an active-backup bond, slaves need
-		 * not be the same type of device, so
-		 * MTUs may vary.  For other modes,
-		 * slaves arguably should have the
-		 * same MTUs. To do this, we'd need to
-		 * take over the slave's change_mtu
-		 * function for the duration of their
-		 * servitude.
-		 */
-		break;
-	case NETDEV_CHANGENAME:
-		/* we don't care if we don't have primary set */
-		if (!bond_uses_primary(bond) ||
-		    !bond->params.primary[0])
-			break;
-
-		if (slave == primary) {
-			/* slave's name changed - he's no longer primary */
-			RCU_INIT_POINTER(bond->primary_slave, NULL);
-		} else if (!strcmp(slave_dev->name, bond->params.primary)) {
-			/* we have a new primary slave */
-			rcu_assign_pointer(bond->primary_slave, slave);
-		} else { /* we didn't change primary - exit */
-			break;
-		}
-
-		netdev_info(bond->dev, "Primary slave changed to %s, reselecting active slave\n",
-			    primary ? slave_dev->name : "none");
-
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-		break;
-	case NETDEV_FEAT_CHANGE:
-		bond_compute_features(bond);
-		break;
-	case NETDEV_RESEND_IGMP:
-		/* Propagate to master device */
-		call_netdevice_notifiers(event, slave->bond->dev);
-		break;
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-/* bond_netdev_event: handle netdev notifier chain events.
- *
- * This function receives events for the netdev chain.  The caller (an
- * ioctl handler calling blocking_notifier_call_chain) holds the necessary
- * locks for us to safely manipulate the slave devices (RTNL lock,
- * dev_probe_lock).
- */
-static int bond_netdev_event(struct notifier_block *this,
-			     unsigned long event, void *ptr)
-{
-	struct net_device *event_dev = netdev_notifier_info_to_dev(ptr);
-
-	netdev_dbg(event_dev, "%s received %s\n",
-		   __func__, netdev_cmd_to_name(event));
-
-	if (!(event_dev->priv_flags & IFF_BONDING))
-		return NOTIFY_DONE;
-
-	if (event_dev->flags & IFF_MASTER) {
-		int ret;
-
-		ret = bond_master_netdev_event(event, event_dev);
-		if (ret != NOTIFY_DONE)
-			return ret;
-	}
-
-	if (event_dev->flags & IFF_SLAVE)
-		return bond_slave_netdev_event(event, event_dev);
-
-	return NOTIFY_DONE;
-}
-
-static struct notifier_block bond_netdev_notifier = {
-	.notifier_call = bond_netdev_event,
-};
-
-/*---------------------------- Hashing Policies -----------------------------*/
-
-/* L2 hash helper */
-static inline u32 bond_eth_hash(struct sk_buff *skb)
-{
-	struct ethhdr *ep, hdr_tmp;
-
-	ep = skb_header_pointer(skb, 0, sizeof(hdr_tmp), &hdr_tmp);
-	if (ep)
-		return ep->h_dest[5] ^ ep->h_source[5] ^ ep->h_proto;
-	return 0;
-}
-
-/* Extract the appropriate headers based on bond's xmit policy */
-static bool bond_flow_dissect(struct bonding *bond, struct sk_buff *skb,
-			      struct flow_keys *fk)
-{
-	const struct ipv6hdr *iph6;
-	const struct iphdr *iph;
-	int noff, proto = -1;
-
-	if (bond->params.xmit_policy > BOND_XMIT_POLICY_LAYER23)
-		return skb_flow_dissect_flow_keys(skb, fk, 0);
-
-	fk->ports.ports = 0;
-	noff = skb_network_offset(skb);
-	if (skb->protocol == htons(ETH_P_IP)) {
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
-			return false;
-		iph = ip_hdr(skb);
-		iph_to_flow_copy_v4addrs(fk, iph);
-		noff += iph->ihl << 2;
-		if (!ip_is_fragment(iph))
-			proto = iph->protocol;
-	} else if (skb->protocol == htons(ETH_P_IPV6)) {
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph6))))
-			return false;
-		iph6 = ipv6_hdr(skb);
-		iph_to_flow_copy_v6addrs(fk, iph6);
-		noff += sizeof(*iph6);
-		proto = iph6->nexthdr;
-	} else {
-		return false;
-	}
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER34 && proto >= 0)
-		fk->ports.ports = skb_flow_get_ports(skb, noff, proto);
-
-	return true;
-}
-
-/**
- * bond_xmit_hash - generate a hash value based on the xmit policy
- * @bond: bonding device
- * @skb: buffer to use for headers
- *
- * This function will extract the necessary headers from the skb buffer and use
- * them to generate a hash based on the xmit_policy set in the bonding device
- */
-u32 bond_xmit_hash(struct bonding *bond, struct sk_buff *skb)
-{
-	struct flow_keys flow;
-	u32 hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP34 &&
-	    skb->l4_hash)
-		return skb->hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER2 ||
-	    !bond_flow_dissect(bond, skb, &flow))
-		return bond_eth_hash(skb);
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER23 ||
-	    bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP23)
-		hash = bond_eth_hash(skb);
-	else
-		hash = (__force u32)flow.ports.ports;
-	hash ^= (__force u32)flow_get_u32_dst(&flow) ^
-		(__force u32)flow_get_u32_src(&flow);
-	hash ^= (hash >> 16);
-	hash ^= (hash >> 8);
-
-	return hash >> 1;
-}
-
-/*-------------------------- Device entry points ----------------------------*/
-
-void bond_work_init_all(struct bonding *bond)
-{
-	INIT_DELAYED_WORK(&bond->mcast_work,
-			  bond_resend_igmp_join_requests_delayed);
-	INIT_DELAYED_WORK(&bond->alb_work, bond_alb_monitor);
-	INIT_DELAYED_WORK(&bond->mii_work, bond_mii_monitor);
-	INIT_DELAYED_WORK(&bond->arp_work, bond_arp_monitor);
-	INIT_DELAYED_WORK(&bond->ad_work, bond_3ad_state_machine_handler);
-	INIT_DELAYED_WORK(&bond->slave_arr_work, bond_slave_arr_handler);
-}
-
-static void bond_work_cancel_all(struct bonding *bond)
-{
-	cancel_delayed_work_sync(&bond->mii_work);
-	cancel_delayed_work_sync(&bond->arp_work);
-	cancel_delayed_work_sync(&bond->alb_work);
-	cancel_delayed_work_sync(&bond->ad_work);
-	cancel_delayed_work_sync(&bond->mcast_work);
-	cancel_delayed_work_sync(&bond->slave_arr_work);
-}
-
-static int bond_open(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	/* reset slave->backup and slave->inactive */
-	if (bond_has_slaves(bond)) {
-		bond_for_each_slave(bond, slave, iter) {
-			if (bond_uses_primary(bond) &&
-			    slave != rcu_access_pointer(bond->curr_active_slave)) {
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-			} else if (BOND_MODE(bond) != BOND_MODE_8023AD) {
-				bond_set_slave_active_flags(slave,
-							    BOND_SLAVE_NOTIFY_NOW);
-			}
-		}
-	}
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_initialize must be called before the timer
-		 * is started.
-		 */
-		if (bond_alb_initialize(bond, (BOND_MODE(bond) == BOND_MODE_ALB)))
-			return -ENOMEM;
-		if (bond->params.tlb_dynamic_lb || BOND_MODE(bond) == BOND_MODE_ALB)
-			queue_delayed_work(bond->wq, &bond->alb_work, 0);
-	}
-
-	if (bond->params.miimon)  /* link check interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->mii_work, 0);
-
-	if (bond->params.arp_interval) {  /* arp interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->arp_work, 0);
-		bond->recv_probe = bond_arp_rcv;
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		queue_delayed_work(bond->wq, &bond->ad_work, 0);
-		/* register to receive LACPDUs */
-		bond->recv_probe = bond_3ad_lacpdu_recv;
-		bond_3ad_initiate_agg_selection(bond, 1);
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-	return 0;
-}
-
-static int bond_close(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	bond_work_cancel_all(bond);
-	bond->send_peer_notif = 0;
-	if (bond_is_lb(bond))
-		bond_alb_deinitialize(bond);
-	bond->recv_probe = NULL;
-
-	return 0;
-}
-
-/* fold stats, assuming all rtnl_link_stats64 fields are u64, but
- * that some drivers can provide 32bit values only.
- */
-static void bond_fold_stats(struct rtnl_link_stats64 *_res,
-			    const struct rtnl_link_stats64 *_new,
-			    const struct rtnl_link_stats64 *_old)
-{
-	const u64 *new = (const u64 *)_new;
-	const u64 *old = (const u64 *)_old;
-	u64 *res = (u64 *)_res;
-	int i;
-
-	for (i = 0; i < sizeof(*_res) / sizeof(u64); i++) {
-		u64 nv = new[i];
-		u64 ov = old[i];
-		s64 delta = nv - ov;
-
-		/* detects if this particular field is 32bit only */
-		if (((nv | ov) >> 32) == 0)
-			delta = (s64)(s32)((u32)nv - (u32)ov);
-
-		/* filter anomalies, some drivers reset their stats
-		 * at down/up events.
-		 */
-		if (delta > 0)
-			res[i] += delta;
-	}
-}
-
-#ifdef CONFIG_LOCKDEP
-static int bond_get_lowest_level_rcu(struct net_device *dev)
-{
-	struct net_device *ldev, *next, *now, *dev_stack[MAX_NEST_DEV + 1];
-	struct list_head *niter, *iter, *iter_stack[MAX_NEST_DEV + 1];
-	int cur = 0, max = 0;
-
-	now = dev;
-	iter = &dev->adj_list.lower;
-
-	while (1) {
-		next = NULL;
-		while (1) {
-			ldev = netdev_next_lower_dev_rcu(now, &iter);
-			if (!ldev)
-				break;
-
-			next = ldev;
-			niter = &ldev->adj_list.lower;
-			dev_stack[cur] = now;
-			iter_stack[cur++] = iter;
-			if (max <= cur)
-				max = cur;
-			break;
-		}
-
-		if (!next) {
-			if (!cur)
-				return max;
-			next = dev_stack[--cur];
-			niter = iter_stack[cur];
-		}
-
-		now = next;
-		iter = niter;
-	}
-
-	return max;
-}
-#endif
-
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct rtnl_link_stats64 temp;
-	struct list_head *iter;
-	struct slave *slave;
-	int nest_level = 0;
-
-
-	rcu_read_lock();
-#ifdef CONFIG_LOCKDEP
-	nest_level = bond_get_lowest_level_rcu(bond_dev);
-#endif
-
-	spin_lock_nested(&bond->stats_lock, nest_level);
-	memcpy(stats, &bond->bond_stats, sizeof(*stats));
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		const struct rtnl_link_stats64 *new =
-			dev_get_stats(slave->dev, &temp);
-
-		bond_fold_stats(stats, new, &slave->slave_stats);
-
-		/* save off the slave stats for the next run */
-		memcpy(&slave->slave_stats, new, sizeof(*new));
-	}
-
-	memcpy(&bond->bond_stats, stats, sizeof(*stats));
-	spin_unlock(&bond->stats_lock);
-	rcu_read_unlock();
-}
-
-static int bond_do_ioctl(struct net_device *bond_dev, struct ifreq *ifr, int cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct ifbond k_binfo;
-	struct ifbond __user *u_binfo = NULL;
-	struct ifslave k_sinfo;
-	struct ifslave __user *u_sinfo = NULL;
-	struct mii_ioctl_data *mii = NULL;
-	struct bond_opt_value newval;
-	struct net *net;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond_ioctl: cmd=%d\n", cmd);
-
-	switch (cmd) {
-	case SIOCGMIIPHY:
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		mii->phy_id = 0;
-		/* Fall Through */
-	case SIOCGMIIREG:
-		/* We do this again just in case we were called by SIOCGMIIREG
-		 * instead of SIOCGMIIPHY.
-		 */
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		if (mii->reg_num == 1) {
-			mii->val_out = 0;
-			if (netif_carrier_ok(bond->dev))
-				mii->val_out = BMSR_LSTATUS;
-		}
-
-		return 0;
-	case BOND_INFO_QUERY_OLD:
-	case SIOCBONDINFOQUERY:
-		u_binfo = (struct ifbond __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_binfo, u_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		bond_info_query(bond_dev, &k_binfo);
-		if (copy_to_user(u_binfo, &k_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		return 0;
-	case BOND_SLAVE_INFO_QUERY_OLD:
-	case SIOCBONDSLAVEINFOQUERY:
-		u_sinfo = (struct ifslave __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_sinfo, u_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		res = bond_slave_info_query(bond_dev, &k_sinfo);
-		if (res == 0 &&
-		    copy_to_user(u_sinfo, &k_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		return res;
-	default:
-		break;
-	}
-
-	net = dev_net(bond_dev);
-
-	if (!ns_capable(net->user_ns, CAP_NET_ADMIN))
-		return -EPERM;
-
-	slave_dev = __dev_get_by_name(net, ifr->ifr_slave);
-
-	slave_dbg(bond_dev, slave_dev, "slave_dev=%p:\n", slave_dev);
-
-	if (!slave_dev)
-		return -ENODEV;
-
-	switch (cmd) {
-	case BOND_ENSLAVE_OLD:
-	case SIOCBONDENSLAVE:
-		res = bond_enslave(bond_dev, slave_dev, NULL);
-		break;
-	case BOND_RELEASE_OLD:
-	case SIOCBONDRELEASE:
-		res = bond_release(bond_dev, slave_dev);
-		if (!res)
-			netdev_update_lockdep_key(slave_dev);
-		break;
-	case BOND_SETHWADDR_OLD:
-	case SIOCBONDSETHWADDR:
-		res = bond_set_dev_addr(bond_dev, slave_dev);
-		break;
-	case BOND_CHANGE_ACTIVE_OLD:
-	case SIOCBONDCHANGEACTIVE:
-		bond_opt_initstr(&newval, slave_dev->name);
-		res = __bond_opt_set_notify(bond, BOND_OPT_ACTIVE_SLAVE,
-					    &newval);
-		break;
-	default:
-		res = -EOPNOTSUPP;
-	}
-
-	return res;
-}
-
-static void bond_change_rx_flags(struct net_device *bond_dev, int change)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	if (change & IFF_PROMISC)
-		bond_set_promiscuity(bond,
-				     bond_dev->flags & IFF_PROMISC ? 1 : -1);
-
-	if (change & IFF_ALLMULTI)
-		bond_set_allmulti(bond,
-				  bond_dev->flags & IFF_ALLMULTI ? 1 : -1);
-}
-
-static void bond_set_rx_mode(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	rcu_read_lock();
-	if (bond_uses_primary(bond)) {
-		slave = rcu_dereference(bond->curr_active_slave);
-		if (slave) {
-			dev_uc_sync(slave->dev, bond_dev);
-			dev_mc_sync(slave->dev, bond_dev);
-		}
-	} else {
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			dev_uc_sync_multiple(slave->dev, bond_dev);
-			dev_mc_sync_multiple(slave->dev, bond_dev);
-		}
-	}
-	rcu_read_unlock();
-}
-
-static int bond_neigh_init(struct neighbour *n)
-{
-	struct bonding *bond = netdev_priv(n->dev);
-	const struct net_device_ops *slave_ops;
-	struct neigh_parms parms;
-	struct slave *slave;
-	int ret = 0;
-
-	rcu_read_lock();
-	slave = bond_first_slave_rcu(bond);
-	if (!slave)
-		goto out;
-	slave_ops = slave->dev->netdev_ops;
-	if (!slave_ops->ndo_neigh_setup)
-		goto out;
-
-	/* TODO: find another way [1] to implement this.
-	 * Passing a zeroed structure is fragile,
-	 * but at least we do not pass garbage.
-	 *
-	 * [1] One way would be that ndo_neigh_setup() never touch
-	 *     struct neigh_parms, but propagate the new neigh_setup()
-	 *     back to ___neigh_create() / neigh_parms_alloc()
-	 */
-	memset(&parms, 0, sizeof(parms));
-	ret = slave_ops->ndo_neigh_setup(slave->dev, &parms);
-
-	if (ret)
-		goto out;
-
-	if (parms.neigh_setup)
-		ret = parms.neigh_setup(n);
-out:
-	rcu_read_unlock();
-	return ret;
-}
-
-/* The bonding ndo_neigh_setup is called at init time beofre any
- * slave exists. So we must declare proxy setup function which will
- * be used at run time to resolve the actual slave neigh param setup.
- *
- * It's also called by master devices (such as vlans) to setup their
- * underlying devices. In that case - do nothing, we're already set up from
- * our init.
- */
-static int bond_neigh_setup(struct net_device *dev,
-			    struct neigh_parms *parms)
-{
-	/* modify only our neigh_parms */
-	if (parms->dev == dev)
-		parms->neigh_setup = bond_neigh_init;
-
-	return 0;
-}
-
-/* Change the MTU of all of a master's slaves to match the master */
-static int bond_change_mtu(struct net_device *bond_dev, int new_mtu)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond=%p, new_mtu=%d\n", bond, new_mtu);
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "s %p c_m %p\n",
-			   slave, slave->dev->netdev_ops->ndo_change_mtu);
-
-		res = dev_set_mtu(slave->dev, new_mtu);
-
-		if (res) {
-			/* If we failed to set the slave's mtu to the new value
-			 * we must abort the operation even in ACTIVE_BACKUP
-			 * mode, because if we allow the backup slaves to have
-			 * different mtu values than the active slave we'll
-			 * need to change their mtu when doing a failover. That
-			 * means changing their mtu from timer context, which
-			 * is probably not a good idea.
-			 */
-			slave_dbg(bond_dev, slave->dev, "err %d setting mtu to %d\n",
-				  res, new_mtu);
-			goto unwind;
-		}
-	}
-
-	bond_dev->mtu = new_mtu;
-
-	return 0;
-
-unwind:
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mtu(rollback_slave->dev, bond_dev->mtu);
-		if (tmp_res)
-			slave_dbg(bond_dev, rollback_slave->dev, "unwind err %d\n",
-				  tmp_res);
-	}
-
-	return res;
-}
-
-/* Change HW address
- *
- * Note that many devices must be down to change the HW address, and
- * downing the master releases all slaves.  We can make bonds full of
- * bonding devices to test this, however.
- */
-static int bond_set_mac_address(struct net_device *bond_dev, void *addr)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct sockaddr_storage *ss = addr, tmp_ss;
-	struct list_head *iter;
-	int res = 0;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB)
-		return bond_alb_set_mac_address(bond_dev, addr);
-
-
-	netdev_dbg(bond_dev, "%s: bond=%p\n", __func__, bond);
-
-	/* If fail_over_mac is enabled, do nothing and return success.
-	 * Returning an error causes ifenslave to fail.
-	 */
-	if (bond->params.fail_over_mac &&
-	    BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		return 0;
-
-	if (!is_valid_ether_addr(ss->__data))
-		return -EADDRNOTAVAIL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "%s: slave=%p\n",
-			  __func__, slave);
-		res = dev_set_mac_address(slave->dev, addr, NULL);
-		if (res) {
-			/* TODO: consider downing the slave
-			 * and retry ?
-			 * User should expect communications
-			 * breakage anyway until ARP finish
-			 * updating, so...
-			 */
-			slave_dbg(bond_dev, slave->dev, "%s: err %d\n",
-				  __func__, res);
-			goto unwind;
-		}
-	}
-
-	/* success */
-	memcpy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
-	return 0;
-
-unwind:
-	memcpy(tmp_ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-	tmp_ss.ss_family = bond_dev->type;
-
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mac_address(rollback_slave->dev,
-					      (struct sockaddr *)&tmp_ss, NULL);
-		if (tmp_res) {
-			slave_dbg(bond_dev, rollback_slave->dev, "%s: unwind err %d\n",
-				   __func__, tmp_res);
-		}
-	}
-
-	return res;
-}
-
-static struct net_device *bond_xmit_slave_id_select(struct bonding *bond,
-						    int slave_id)
-{
-	struct net_device *slave_dev = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	int i = slave_id;
-
-	/* Here we start from the slave with slave_id */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0) {
-			if (bond_slave_can_tx(slave)) {
-				slave_dev = slave->dev;
-				return slave_dev;
-			}
-		}
-	}
-
-	/* Here we start from the first slave up to slave_id */
-	i = slave_id;
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0)
-			break;
-		if (bond_slave_can_tx(slave)) {
-			slave_dev = slave->dev;
-			return slave_dev;
-		}
-	}
-	return slave_dev;
-}
-
-/**
- * bond_xmit_slave_id - transmit skb through slave with slave_id
- * @bond: bonding device that is transmitting
- * @skb: buffer to transmit
- * @slave_id: slave id up to slave_cnt-1 through which to transmit
- *
- * This function tries to transmit through slave with slave_id but in case
- * it fails, it tries to find the first available slave for transmission.
- * The skb is consumed in all cases, thus the function is void.
- */
-static void bond_xmit_slave_id(struct bonding *bond, struct sk_buff *skb, int slave_id)
-{
-	struct list_head *iter;
-	struct slave *slave;
-	int i = slave_id;
-
-	/* Here we start from the slave with slave_id */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0) {
-			if (bond_slave_can_tx(slave)) {
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-				return;
-			}
-		}
-	}
-
-	/* Here we start from the first slave up to slave_id */
-	i = slave_id;
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0)
-			break;
-		if (bond_slave_can_tx(slave)) {
-			bond_dev_queue_xmit(bond, skb, slave->dev);
-			return;
-		}
-	}
-	/* no slave that can tx has been found */
-	bond_tx_drop(bond->dev, skb);
-}
-
-/**
- * bond_rr_gen_slave_id - generate slave id based on packets_per_slave
- * @bond: bonding device to use
- *
- * Based on the value of the bonding device's packets_per_slave parameter
- * this function generates a slave id, which is usually used as the next
- * slave to transmit through.
- */
-static u32 bond_rr_gen_slave_id(struct bonding *bond)
-{
-	u32 slave_id;
-	struct reciprocal_value reciprocal_packets_per_slave;
-	int packets_per_slave = bond->params.packets_per_slave;
-
-	switch (packets_per_slave) {
-	case 0:
-		slave_id = prandom_u32();
-		break;
-	case 1:
-		slave_id = bond->rr_tx_counter;
-		break;
-	default:
-		reciprocal_packets_per_slave =
-			bond->params.reciprocal_packets_per_slave;
-		slave_id = reciprocal_divide(bond->rr_tx_counter,
-					     reciprocal_packets_per_slave);
-		break;
-	}
-	bond->rr_tx_counter++;
-
-	return slave_id;
-}
-
-static struct net_device *bond_xmit_roundrobin_select(int slave_id,
-						      struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	return bond_xmit_slave_id_select(bond, slave_id);
-}
-
-static netdev_tx_t bond_xmit_roundrobin(struct sk_buff *skb,
-					struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-	int slave_cnt;
-	u32 slave_id;
-
-	/* Start with the curr_active_slave that joined the bond as the
-	 * default for sending IGMP traffic.  For failover purposes one
-	 * needs to maintain some consistency for the interface that will
-	 * send the join/membership reports.  The curr_active_slave found
-	 * will send all of this type of traffic.
-	 */
-	if (skb->protocol == htons(ETH_P_IP)) {
-		int noff = skb_network_offset(skb);
-		struct iphdr *iph;
-
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
-			goto non_igmp;
-
-		iph = ip_hdr(skb);
-		if (iph->protocol == IPPROTO_IGMP) {
-			slave = rcu_dereference(bond->curr_active_slave);
-			if (slave)
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-			else
-				bond_xmit_slave_id(bond, skb, 0);
-			return NETDEV_TX_OK;
-		}
-	}
-
-non_igmp:
-	slave_cnt = READ_ONCE(bond->slave_cnt);
-	if (likely(slave_cnt)) {
-		slave_id = bond_rr_gen_slave_id(bond);
-		bond_xmit_slave_id(bond, skb, slave_id % slave_cnt);
-	} else {
-		bond_tx_drop(bond_dev, skb);
-	}
-	return NETDEV_TX_OK;
-}
-
-static struct net_device *bond_xmit_activebackup_select(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct slave *slave;
-
-	slave = rcu_dereference(bond->curr_active_slave);
-	if (slave)
-		slave_dev = slave->dev;
-
-	return slave_dev;
-}
-
-/* In active-backup mode, we know that bond->curr_active_slave is always valid if
- * the bond has a usable interface.
- */
-static netdev_tx_t bond_xmit_activebackup(struct sk_buff *skb,
-					  struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-
-	slave = rcu_dereference(bond->curr_active_slave);
-	if (slave)
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	else
-		bond_tx_drop(bond_dev, skb);
-
-	return NETDEV_TX_OK;
-}
-
-/* Use this to update slave_array when (a) it's not appropriate to update
- * slave_array right away (note that update_slave_array() may sleep)
- * and / or (b) RTNL is not held.
- */
-void bond_slave_arr_work_rearm(struct bonding *bond, unsigned long delay)
-{
-	queue_delayed_work(bond->wq, &bond->slave_arr_work, delay);
-}
-
-/* Slave array work handler. Holds only RTNL */
-static void bond_slave_arr_handler(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    slave_arr_work.work);
-	int ret;
-
-	if (!rtnl_trylock())
-		goto err;
-
-	ret = bond_update_slave_arr(bond, NULL);
-	rtnl_unlock();
-	if (ret) {
-		pr_warn_ratelimited("Failed to update slave array from WT\n");
-		goto err;
-	}
-	return;
-
-err:
-	bond_slave_arr_work_rearm(bond, 1);
-}
-
-/* Build the usable slaves array in control path for modes that use xmit-hash
- * to determine the slave interface -
- * (a) BOND_MODE_8023AD
- * (b) BOND_MODE_XOR
- * (c) (BOND_MODE_TLB || BOND_MODE_ALB) && tlb_dynamic_lb == 0
- *
- * The caller is expected to hold RTNL only and NO other lock!
- */
-int bond_update_slave_arr(struct bonding *bond, struct slave *skipslave)
-{
-	struct slave *slave;
-	struct list_head *iter;
-	struct bond_up_slave *new_arr, *old_arr;
-	int agg_id = 0;
-	int ret = 0;
-
-#ifdef CONFIG_LOCKDEP
-	WARN_ON(lockdep_is_held(&bond->mode_lock));
-#endif
-
-	new_arr = kzalloc(offsetof(struct bond_up_slave, arr[bond->slave_cnt]),
-			  GFP_KERNEL);
-	if (!new_arr) {
-		ret = -ENOMEM;
-		pr_err("Failed to build slave-array.\n");
-		goto out;
-	}
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-
-		if (bond_3ad_get_active_agg_info(bond, &ad_info)) {
-			pr_debug("bond_3ad_get_active_agg_info failed\n");
-			kfree_rcu(new_arr, rcu);
-			/* No active aggragator means it's not safe to use
-			 * the previous array.
-			 */
-			old_arr = rtnl_dereference(bond->slave_arr);
-			if (old_arr) {
-				RCU_INIT_POINTER(bond->slave_arr, NULL);
-				kfree_rcu(old_arr, rcu);
-			}
-			goto out;
-		}
-		agg_id = ad_info.aggregator_id;
-	}
-	bond_for_each_slave(bond, slave, iter) {
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg;
-
-			agg = SLAVE_AD_INFO(slave)->port.aggregator;
-			if (!agg || agg->aggregator_identifier != agg_id)
-				continue;
-		}
-		if (!bond_slave_can_tx(slave))
-			continue;
-		if (skipslave == slave)
-			continue;
-
-		slave_dbg(bond->dev, slave->dev, "Adding slave to tx hash array[%d]\n",
-			  new_arr->count);
-
-		new_arr->arr[new_arr->count++] = slave;
-	}
-
-	old_arr = rtnl_dereference(bond->slave_arr);
-	rcu_assign_pointer(bond->slave_arr, new_arr);
-	if (old_arr)
-		kfree_rcu(old_arr, rcu);
-out:
-	if (ret != 0 && skipslave) {
-		int idx;
-
-		/* Rare situation where caller has asked to skip a specific
-		 * slave but allocation failed (most likely!). BTW this is
-		 * only possible when the call is initiated from
-		 * __bond_release_one(). In this situation; overwrite the
-		 * skipslave entry in the array with the last entry from the
-		 * array to avoid a situation where the xmit path may choose
-		 * this to-be-skipped slave to send a packet out.
-		 */
-		old_arr = rtnl_dereference(bond->slave_arr);
-		for (idx = 0; old_arr != NULL && idx < old_arr->count; idx++) {
-			if (skipslave == old_arr->arr[idx]) {
-				old_arr->arr[idx] =
-				    old_arr->arr[old_arr->count-1];
-				old_arr->count--;
-				break;
-			}
-		}
-	}
-	return ret;
-}
-
-static struct net_device *bond_xmit_xor_select(int slave_id,
-					       struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct bond_up_slave *slaves;
-	struct slave *slave;
-	unsigned int count;
-
-	slaves = rcu_dereference(bond->slave_arr);
-	count = slaves ? READ_ONCE(slaves->count) : 0;
-	if (likely(count)) {
-		slave = slaves->arr[slave_id];
-		if (slave)
-			slave_dev = slave->dev;
-	}
-	return slave_dev;
-}
-
-/* Use this Xmit function for 3AD as well as XOR modes. The current
- * usable slave array is formed in the control path. The xmit function
- * just calculates hash and sends the packet out.
- */
-static netdev_tx_t bond_3ad_xor_xmit(struct sk_buff *skb,
-				     struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct slave *slave;
-	struct bond_up_slave *slaves;
-	unsigned int count;
-
-	slaves = rcu_dereference(bond->slave_arr);
-	count = slaves ? READ_ONCE(slaves->count) : 0;
-	if (likely(count)) {
-		slave = slaves->arr[bond_xmit_hash(bond, skb) % count];
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	} else {
-		bond_tx_drop(dev, skb);
-	}
-
-	return NETDEV_TX_OK;
-}
-
-/* in broadcast mode, we send everything to all usable interfaces. */
-static netdev_tx_t bond_xmit_broadcast(struct sk_buff *skb,
-				       struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (bond_is_last_slave(bond, slave))
-			break;
-		if (bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
-
-			if (!skb2) {
-				net_err_ratelimited("%s: Error: %s: skb_clone() failed\n",
-						    bond_dev->name, __func__);
-				continue;
-			}
-			bond_dev_queue_xmit(bond, skb2, slave->dev);
-		}
-	}
-	if (slave && bond_slave_is_up(slave) && slave->link == BOND_LINK_UP)
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	else
-		bond_tx_drop(bond_dev, skb);
-
-	return NETDEV_TX_OK;
-}
-
-/*------------------------- Device initialization ---------------------------*/
-
-/* Lookup the slave that corresponds to a qid */
-static inline int bond_slave_override(struct bonding *bond,
-				      struct sk_buff *skb)
-{
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	if (!skb_rx_queue_recorded(skb))
-		return 1;
-
-	/* Find out if any slaves have the same mapping as this skb. */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->queue_id == skb_get_queue_mapping(skb)) {
-			if (bond_slave_is_up(slave) &&
-			    slave->link == BOND_LINK_UP) {
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-				return 0;
-			}
-			/* If the slave isn't UP, use default transmit policy. */
-			break;
-		}
-	}
-
-	return 1;
-}
-
-
-static u16 bond_select_queue(struct net_device *dev, struct sk_buff *skb,
-			     struct net_device *sb_dev)
-{
-	/* This helper function exists to help dev_pick_tx get the correct
-	 * destination queue.  Using a helper function skips a call to
-	 * skb_tx_hash and will put the skbs in the queue we expect on their
-	 * way down to the bonding driver.
-	 */
-	u16 txq = skb_rx_queue_recorded(skb) ? skb_get_rx_queue(skb) : 0;
-
-	/* Save the original txq to restore before passing to the driver */
-	qdisc_skb_cb(skb)->slave_dev_queue_mapping = skb_get_queue_mapping(skb);
-
-	if (unlikely(txq >= dev->real_num_tx_queues)) {
-		do {
-			txq -= dev->real_num_tx_queues;
-		} while (txq >= dev->real_num_tx_queues);
-	}
-	return txq;
-}
-
-static netdev_tx_t __bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-
-	if (bond_should_override_tx_queue(bond) &&
-	    !bond_slave_override(bond, skb))
-		return NETDEV_TX_OK;
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return bond_xmit_roundrobin(skb, dev);
-	case BOND_MODE_ACTIVEBACKUP:
-		return bond_xmit_activebackup(skb, dev);
-	case BOND_MODE_8023AD:
-	case BOND_MODE_XOR:
-		return bond_3ad_xor_xmit(skb, dev);
-	case BOND_MODE_BROADCAST:
-		return bond_xmit_broadcast(skb, dev);
-	case BOND_MODE_ALB:
-		return bond_alb_xmit(skb, dev);
-	case BOND_MODE_TLB:
-		return bond_tlb_xmit(skb, dev);
-	default:
-		/* Should never happen, mode already checked */
-		netdev_err(dev, "Unknown bonding mode %d\n", BOND_MODE(bond));
-		WARN_ON_ONCE(1);
-		bond_tx_drop(dev, skb);
-		return NETDEV_TX_OK;
-	}
-}
-
-static netdev_tx_t bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	netdev_tx_t ret = NETDEV_TX_OK;
-
-	/* If we risk deadlock from transmitting this in the
-	 * netpoll path, tell netpoll to queue the frame for later tx
-	 */
-	if (unlikely(is_netpoll_tx_blocked(dev)))
-		return NETDEV_TX_BUSY;
-
-	rcu_read_lock();
-	if (bond_has_slaves(bond))
-		ret = __bond_start_xmit(skb, dev);
-	else
-		bond_tx_drop(dev, skb);
-	rcu_read_unlock();
-
-	return ret;
-}
-
-static u32 bond_mode_bcast_speed(struct slave *slave, u32 speed)
-{
-	if (speed == 0 || speed == SPEED_UNKNOWN)
-		speed = slave->speed;
-	else
-		speed = min(speed, slave->speed);
-
-	return speed;
-}
-
-static int bond_ethtool_get_link_ksettings(struct net_device *bond_dev,
-					   struct ethtool_link_ksettings *cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-	u32 speed = 0;
-
-	cmd->base.duplex = DUPLEX_UNKNOWN;
-	cmd->base.port = PORT_OTHER;
-
-	/* Since bond_slave_can_tx returns false for all inactive or down slaves, we
-	 * do not need to check mode.  Though link speed might not represent
-	 * the true receive or transmit bandwidth (not all modes are symmetric)
-	 * this is an accurate maximum.
-	 */
-	bond_for_each_slave(bond, slave, iter) {
-		if (bond_slave_can_tx(slave)) {
-			if (slave->speed != SPEED_UNKNOWN) {
-				if (BOND_MODE(bond) == BOND_MODE_BROADCAST)
-					speed = bond_mode_bcast_speed(slave,
-								      speed);
-				else
-					speed += slave->speed;
-			}
-			if (cmd->base.duplex == DUPLEX_UNKNOWN &&
-			    slave->duplex != DUPLEX_UNKNOWN)
-				cmd->base.duplex = slave->duplex;
-		}
-	}
-	cmd->base.speed = speed ? : SPEED_UNKNOWN;
-
-	return 0;
-}
-
-static void bond_ethtool_get_drvinfo(struct net_device *bond_dev,
-				     struct ethtool_drvinfo *drvinfo)
-{
-	strlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));
-	strlcpy(drvinfo->version, DRV_VERSION, sizeof(drvinfo->version));
-	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version), "%d",
-		 BOND_ABI_VERSION);
-}
-
-static const struct ethtool_ops bond_ethtool_ops = {
-	.get_drvinfo		= bond_ethtool_get_drvinfo,
-	.get_link		= ethtool_op_get_link,
-	.get_link_ksettings	= bond_ethtool_get_link_ksettings,
-};
-
-static const struct net_device_ops bond_netdev_ops = {
-	.ndo_init		= bond_init,
-	.ndo_uninit		= bond_uninit,
-	.ndo_open		= bond_open,
-	.ndo_stop		= bond_close,
-	.ndo_start_xmit		= bond_start_xmit,
-	.ndo_select_queue	= bond_select_queue,
-	.ndo_get_stats64	= bond_get_stats,
-	.ndo_do_ioctl		= bond_do_ioctl,
-	.ndo_change_rx_flags	= bond_change_rx_flags,
-	.ndo_set_rx_mode	= bond_set_rx_mode,
-	.ndo_change_mtu		= bond_change_mtu,
-	.ndo_set_mac_address	= bond_set_mac_address,
-	.ndo_neigh_setup	= bond_neigh_setup,
-	.ndo_vlan_rx_add_vid	= bond_vlan_rx_add_vid,
-	.ndo_vlan_rx_kill_vid	= bond_vlan_rx_kill_vid,
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	.ndo_netpoll_setup	= bond_netpoll_setup,
-	.ndo_netpoll_cleanup	= bond_netpoll_cleanup,
-	.ndo_poll_controller	= bond_poll_controller,
-#endif
-	.ndo_add_slave		= bond_enslave,
-	.ndo_del_slave		= bond_release,
-	.ndo_fix_features	= bond_fix_features,
-	.ndo_features_check	= passthru_features_check,
-};
-
-static const struct device_type bond_type = {
-	.name = "bond",
-};
-
-static void bond_destructor(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	if (bond->wq)
-		destroy_workqueue(bond->wq);
-}
-
-void bond_setup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	spin_lock_init(&bond->mode_lock);
-	bond->params = bonding_defaults;
-
-	/* Initialize pointers */
-	bond->dev = bond_dev;
-
-	/* Initialize the device entry points */
-	ether_setup(bond_dev);
-	bond_dev->max_mtu = ETH_MAX_MTU;
-	bond_dev->netdev_ops = &bond_netdev_ops;
-	bond_dev->ethtool_ops = &bond_ethtool_ops;
-
-	bond_dev->needs_free_netdev = true;
-	bond_dev->priv_destructor = bond_destructor;
-
-	SET_NETDEV_DEVTYPE(bond_dev, &bond_type);
-
-	/* Initialize the device options */
-	bond_dev->flags |= IFF_MASTER;
-	bond_dev->priv_flags |= IFF_BONDING | IFF_UNICAST_FLT | IFF_NO_QUEUE;
-	bond_dev->priv_flags &= ~(IFF_XMIT_DST_RELEASE | IFF_TX_SKB_SHARING);
-
-	/* don't acquire bond device's netif_tx_lock when transmitting */
-	bond_dev->features |= NETIF_F_LLTX;
-
-	/* By default, we declare the bond to be fully
-	 * VLAN hardware accelerated capable. Special
-	 * care is taken in the various xmit functions
-	 * when there are slaves that are not hw accel
-	 * capable
-	 */
-
-	/* Don't allow bond devices to change network namespaces. */
-	bond_dev->features |= NETIF_F_NETNS_LOCAL;
-
-	bond_dev->hw_features = BOND_VLAN_FEATURES |
-				NETIF_F_HW_VLAN_CTAG_RX |
-				NETIF_F_HW_VLAN_CTAG_FILTER;
-
-	bond_dev->hw_features |= NETIF_F_GSO_ENCAP_ALL | NETIF_F_GSO_UDP_L4;
-	bond_dev->features |= bond_dev->hw_features;
-	bond_dev->features |= NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_STAG_TX;
-}
-
-/* Destroy a bonding device.
- * Must be under rtnl_lock when this function is called.
- */
-static void bond_uninit(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-	struct bond_up_slave *arr;
-
-	bond_netpoll_cleanup(bond_dev);
-
-	/* Release the bonded slaves */
-	bond_for_each_slave(bond, slave, iter)
-		__bond_release_one(bond_dev, slave->dev, true, true);
-	netdev_info(bond_dev, "Released all slaves\n");
-
-	arr = rtnl_dereference(bond->slave_arr);
-	if (arr) {
-		RCU_INIT_POINTER(bond->slave_arr, NULL);
-		kfree_rcu(arr, rcu);
-	}
-
-	list_del(&bond->bond_list);
-
-	lockdep_unregister_key(&bond->stats_lock_key);
-	bond_debug_unregister(bond);
-}
-
-/*------------------------- Module initialization ---------------------------*/
-
-static int bond_check_params(struct bond_params *params)
-{
-	int arp_validate_value, fail_over_mac_value, primary_reselect_value, i;
-	struct bond_opt_value newval;
-	const struct bond_opt_value *valptr;
-	int arp_all_targets_value = 0;
-	u16 ad_actor_sys_prio = 0;
-	u16 ad_user_port_key = 0;
-	__be32 arp_target[BOND_MAX_ARP_TARGETS] = { 0 };
-	int arp_ip_count;
-	int bond_mode	= BOND_MODE_ROUNDROBIN;
-	int xmit_hashtype = BOND_XMIT_POLICY_LAYER2;
-	int lacp_fast = 0;
-	int tlb_dynamic_lb;
-
-	/* Convert string parameters. */
-	if (mode) {
-		bond_opt_initstr(&newval, mode);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_MODE), &newval);
-		if (!valptr) {
-			pr_err("Error: Invalid bonding mode \"%s\"\n", mode);
-			return -EINVAL;
-		}
-		bond_mode = valptr->value;
-	}
-
-	if (xmit_hash_policy) {
-		if (bond_mode == BOND_MODE_ROUNDROBIN ||
-		    bond_mode == BOND_MODE_ACTIVEBACKUP ||
-		    bond_mode == BOND_MODE_BROADCAST) {
-			pr_info("xmit_hash_policy param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, xmit_hash_policy);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_XMIT_HASH),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid xmit_hash_policy \"%s\"\n",
-				       xmit_hash_policy);
-				return -EINVAL;
-			}
-			xmit_hashtype = valptr->value;
-		}
-	}
-
-	if (lacp_rate) {
-		if (bond_mode != BOND_MODE_8023AD) {
-			pr_info("lacp_rate param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, lacp_rate);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_LACP_RATE),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid lacp rate \"%s\"\n",
-				       lacp_rate);
-				return -EINVAL;
-			}
-			lacp_fast = valptr->value;
-		}
-	}
-
-	if (ad_select) {
-		bond_opt_initstr(&newval, ad_select);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_SELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid ad_select \"%s\"\n", ad_select);
-			return -EINVAL;
-		}
-		params->ad_select = valptr->value;
-		if (bond_mode != BOND_MODE_8023AD)
-			pr_warn("ad_select param only affects 802.3ad mode\n");
-	} else {
-		params->ad_select = BOND_AD_STABLE;
-	}
-
-	if (max_bonds < 0) {
-		pr_warn("Warning: max_bonds (%d) not in range %d-%d, so it was reset to BOND_DEFAULT_MAX_BONDS (%d)\n",
-			max_bonds, 0, INT_MAX, BOND_DEFAULT_MAX_BONDS);
-		max_bonds = BOND_DEFAULT_MAX_BONDS;
-	}
-
-	if (miimon < 0) {
-		pr_warn("Warning: miimon module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			miimon, INT_MAX);
-		miimon = 0;
-	}
-
-	if (updelay < 0) {
-		pr_warn("Warning: updelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			updelay, INT_MAX);
-		updelay = 0;
-	}
-
-	if (downdelay < 0) {
-		pr_warn("Warning: downdelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			downdelay, INT_MAX);
-		downdelay = 0;
-	}
-
-	if ((use_carrier != 0) && (use_carrier != 1)) {
-		pr_warn("Warning: use_carrier module parameter (%d), not of valid value (0/1), so it was set to 1\n",
-			use_carrier);
-		use_carrier = 1;
-	}
-
-	if (num_peer_notif < 0 || num_peer_notif > 255) {
-		pr_warn("Warning: num_grat_arp/num_unsol_na (%d) not in range 0-255 so it was reset to 1\n",
-			num_peer_notif);
-		num_peer_notif = 1;
-	}
-
-	/* reset values for 802.3ad/TLB/ALB */
-	if (!bond_mode_uses_arp(bond_mode)) {
-		if (!miimon) {
-			pr_warn("Warning: miimon must be specified, otherwise bonding will not detect link failure, speed and duplex which are essential for 802.3ad operation\n");
-			pr_warn("Forcing miimon to 100msec\n");
-			miimon = BOND_DEFAULT_MIIMON;
-		}
-	}
-
-	if (tx_queues < 1 || tx_queues > 255) {
-		pr_warn("Warning: tx_queues (%d) should be between 1 and 255, resetting to %d\n",
-			tx_queues, BOND_DEFAULT_TX_QUEUES);
-		tx_queues = BOND_DEFAULT_TX_QUEUES;
-	}
-
-	if ((all_slaves_active != 0) && (all_slaves_active != 1)) {
-		pr_warn("Warning: all_slaves_active module parameter (%d), not of valid value (0/1), so it was set to 0\n",
-			all_slaves_active);
-		all_slaves_active = 0;
-	}
-
-	if (resend_igmp < 0 || resend_igmp > 255) {
-		pr_warn("Warning: resend_igmp (%d) should be between 0 and 255, resetting to %d\n",
-			resend_igmp, BOND_DEFAULT_RESEND_IGMP);
-		resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-	}
-
-	bond_opt_initval(&newval, packets_per_slave);
-	if (!bond_opt_parse(bond_opt_get(BOND_OPT_PACKETS_PER_SLAVE), &newval)) {
-		pr_warn("Warning: packets_per_slave (%d) should be between 0 and %u resetting to 1\n",
-			packets_per_slave, USHRT_MAX);
-		packets_per_slave = 1;
-	}
-
-	if (bond_mode == BOND_MODE_ALB) {
-		pr_notice("In ALB mode you might experience client disconnections upon reconnection of a link if the bonding module updelay parameter (%d msec) is incompatible with the forwarding delay time of the switch\n",
-			  updelay);
-	}
-
-	if (!miimon) {
-		if (updelay || downdelay) {
-			/* just warn the user the up/down delay will have
-			 * no effect since miimon is zero...
-			 */
-			pr_warn("Warning: miimon module parameter not set and updelay (%d) or downdelay (%d) module parameter is set; updelay and downdelay have no effect unless miimon is set\n",
-				updelay, downdelay);
-		}
-	} else {
-		/* don't allow arp monitoring */
-		if (arp_interval) {
-			pr_warn("Warning: miimon (%d) and arp_interval (%d) can't be used simultaneously, disabling ARP monitoring\n",
-				miimon, arp_interval);
-			arp_interval = 0;
-		}
-
-		if ((updelay % miimon) != 0) {
-			pr_warn("Warning: updelay (%d) is not a multiple of miimon (%d), updelay rounded to %d ms\n",
-				updelay, miimon, (updelay / miimon) * miimon);
-		}
-
-		updelay /= miimon;
-
-		if ((downdelay % miimon) != 0) {
-			pr_warn("Warning: downdelay (%d) is not a multiple of miimon (%d), downdelay rounded to %d ms\n",
-				downdelay, miimon,
-				(downdelay / miimon) * miimon);
-		}
-
-		downdelay /= miimon;
-	}
-
-	if (arp_interval < 0) {
-		pr_warn("Warning: arp_interval module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			arp_interval, INT_MAX);
-		arp_interval = 0;
-	}
-
-	for (arp_ip_count = 0, i = 0;
-	     (arp_ip_count < BOND_MAX_ARP_TARGETS) && arp_ip_target[i]; i++) {
-		__be32 ip;
-
-		/* not a complete check, but good enough to catch mistakes */
-		if (!in4_pton(arp_ip_target[i], -1, (u8 *)&ip, -1, NULL) ||
-		    !bond_is_ip_target_ok(ip)) {
-			pr_warn("Warning: bad arp_ip_target module parameter (%s), ARP monitoring will not be performed\n",
-				arp_ip_target[i]);
-			arp_interval = 0;
-		} else {
-			if (bond_get_targets_ip(arp_target, ip) == -1)
-				arp_target[arp_ip_count++] = ip;
-			else
-				pr_warn("Warning: duplicate address %pI4 in arp_ip_target, skipping\n",
-					&ip);
-		}
-	}
-
-	if (arp_interval && !arp_ip_count) {
-		/* don't allow arping if no arp_ip_target given... */
-		pr_warn("Warning: arp_interval module parameter (%d) specified without providing an arp_ip_target parameter, arp_interval was reset to 0\n",
-			arp_interval);
-		arp_interval = 0;
-	}
-
-	if (arp_validate) {
-		if (!arp_interval) {
-			pr_err("arp_validate requires arp_interval\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initstr(&newval, arp_validate);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_VALIDATE),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_validate \"%s\"\n",
-			       arp_validate);
-			return -EINVAL;
-		}
-		arp_validate_value = valptr->value;
-	} else {
-		arp_validate_value = 0;
-	}
-
-	if (arp_all_targets) {
-		bond_opt_initstr(&newval, arp_all_targets);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_ALL_TARGETS),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_all_targets_value \"%s\"\n",
-			       arp_all_targets);
-			arp_all_targets_value = 0;
-		} else {
-			arp_all_targets_value = valptr->value;
-		}
-	}
-
-	if (miimon) {
-		pr_info("MII link monitoring set to %d ms\n", miimon);
-	} else if (arp_interval) {
-		valptr = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
-					  arp_validate_value);
-		pr_info("ARP monitoring set to %d ms, validate %s, with %d target(s):",
-			arp_interval, valptr->string, arp_ip_count);
-
-		for (i = 0; i < arp_ip_count; i++)
-			pr_cont(" %s", arp_ip_target[i]);
-
-		pr_cont("\n");
-
-	} else if (max_bonds) {
-		/* miimon and arp_interval not set, we need one so things
-		 * work as expected, see bonding.txt for details
-		 */
-		pr_debug("Warning: either miimon or arp_interval and arp_ip_target module parameters must be specified, otherwise bonding will not detect link failures! see bonding.txt for details\n");
-	}
-
-	if (primary && !bond_mode_uses_primary(bond_mode)) {
-		/* currently, using a primary only makes sense
-		 * in active backup, TLB or ALB modes
-		 */
-		pr_warn("Warning: %s primary device specified but has no effect in %s mode\n",
-			primary, bond_mode_name(bond_mode));
-		primary = NULL;
-	}
-
-	if (primary && primary_reselect) {
-		bond_opt_initstr(&newval, primary_reselect);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_PRIMARY_RESELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid primary_reselect \"%s\"\n",
-			       primary_reselect);
-			return -EINVAL;
-		}
-		primary_reselect_value = valptr->value;
-	} else {
-		primary_reselect_value = BOND_PRI_RESELECT_ALWAYS;
-	}
-
-	if (fail_over_mac) {
-		bond_opt_initstr(&newval, fail_over_mac);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_FAIL_OVER_MAC),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid fail_over_mac \"%s\"\n",
-			       fail_over_mac);
-			return -EINVAL;
-		}
-		fail_over_mac_value = valptr->value;
-		if (bond_mode != BOND_MODE_ACTIVEBACKUP)
-			pr_warn("Warning: fail_over_mac only affects active-backup mode\n");
-	} else {
-		fail_over_mac_value = BOND_FOM_NONE;
-	}
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(
-			bond_opt_get(BOND_OPT_AD_ACTOR_SYS_PRIO),
-				     &newval);
-	if (!valptr) {
-		pr_err("Error: No ad_actor_sys_prio default value");
-		return -EINVAL;
-	}
-	ad_actor_sys_prio = valptr->value;
-
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_USER_PORT_KEY),
-				&newval);
-	if (!valptr) {
-		pr_err("Error: No ad_user_port_key default value");
-		return -EINVAL;
-	}
-	ad_user_port_key = valptr->value;
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_TLB_DYNAMIC_LB), &newval);
-	if (!valptr) {
-		pr_err("Error: No tlb_dynamic_lb default value");
-		return -EINVAL;
-	}
-	tlb_dynamic_lb = valptr->value;
-
-	if (lp_interval == 0) {
-		pr_warn("Warning: ip_interval must be between 1 and %d, so it was reset to %d\n",
-			INT_MAX, BOND_ALB_DEFAULT_LP_INTERVAL);
-		lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-	}
-
-	/* fill params struct with the proper values */
-	params->mode = bond_mode;
-	params->xmit_policy = xmit_hashtype;
-	params->miimon = miimon;
-	params->num_peer_notif = num_peer_notif;
-	params->arp_interval = arp_interval;
-	params->arp_validate = arp_validate_value;
-	params->arp_all_targets = arp_all_targets_value;
-	params->updelay = updelay;
-	params->downdelay = downdelay;
-	params->peer_notif_delay = 0;
-	params->use_carrier = use_carrier;
-	params->lacp_fast = lacp_fast;
-	params->primary[0] = 0;
-	params->primary_reselect = primary_reselect_value;
-	params->fail_over_mac = fail_over_mac_value;
-	params->tx_queues = tx_queues;
-	params->all_slaves_active = all_slaves_active;
-	params->resend_igmp = resend_igmp;
-	params->min_links = min_links;
-	params->lp_interval = lp_interval;
-	params->packets_per_slave = packets_per_slave;
-	params->tlb_dynamic_lb = tlb_dynamic_lb;
-	params->ad_actor_sys_prio = ad_actor_sys_prio;
-	eth_zero_addr(params->ad_actor_system);
-	params->ad_user_port_key = ad_user_port_key;
-	if (packets_per_slave > 0) {
-		params->reciprocal_packets_per_slave =
-			reciprocal_value(packets_per_slave);
-	} else {
-		/* reciprocal_packets_per_slave is unused if
-		 * packets_per_slave is 0 or 1, just initialize it
-		 */
-		params->reciprocal_packets_per_slave =
-			(struct reciprocal_value) { 0 };
-	}
-
-	if (primary) {
-		strncpy(params->primary, primary, IFNAMSIZ);
-		params->primary[IFNAMSIZ - 1] = 0;
-	}
-
-	memcpy(params->arp_targets, arp_target, sizeof(arp_target));
-
-	return 0;
-}
-
-/* Called from registration process */
-static int bond_init(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	netdev_dbg(bond_dev, "Begin bond_init\n");
-
-	bond->wq = alloc_ordered_workqueue(bond_dev->name, WQ_MEM_RECLAIM);
-	if (!bond->wq)
-		return -ENOMEM;
-
-	spin_lock_init(&bond->stats_lock);
-	lockdep_register_key(&bond->stats_lock_key);
-	lockdep_set_class(&bond->stats_lock, &bond->stats_lock_key);
-
-	list_add_tail(&bond->bond_list, &bn->dev_list);
-
-	bond_prepare_sysfs_group(bond);
-
-	bond_debug_register(bond);
-
-	/* Ensure valid dev_addr */
-	if (is_zero_ether_addr(bond_dev->dev_addr) &&
-	    bond_dev->addr_assign_type == NET_ADDR_PERM)
-		eth_hw_addr_random(bond_dev);
-
-	return 0;
-}
-
-unsigned int bond_get_num_tx_queues(void)
-{
-	return tx_queues;
-}
-
-/* Create a new bond based on the specified name and bonding parameters.
- * If name is NULL, obtain a suitable "bond%d" name for us.
- * Caller must NOT hold rtnl_lock; we need to release it here before we
- * set up our sysfs entries.
- */
-int bond_create(struct net *net, const char *name)
-{
-	struct net_device *bond_dev;
-	struct bonding *bond;
-	struct alb_bond_info *bond_info;
-	int res;
-
-	rtnl_lock();
-
-	bond_dev = alloc_netdev_mq(sizeof(struct bonding),
-				   name ? name : "bond%d", NET_NAME_UNKNOWN,
-				   bond_setup, tx_queues);
-	if (!bond_dev) {
-		pr_err("%s: eek! can't alloc netdev!\n", name);
-		rtnl_unlock();
-		return -ENOMEM;
-	}
-
-	/*
-	 * Initialize rx_hashtbl_used_head to RLB_NULL_INDEX.
-	 * It is set to 0 by default which is wrong.
-	 */
-	bond = netdev_priv(bond_dev);
-	bond_info = &(BOND_ALB_INFO(bond));
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	dev_net_set(bond_dev, net);
-	bond_dev->rtnl_link_ops = &bond_link_ops;
-
-	res = register_netdevice(bond_dev);
-	if (res < 0) {
-		free_netdev(bond_dev);
-		rtnl_unlock();
-
-		return res;
-	}
-
-	netif_carrier_off(bond_dev);
-
-	bond_work_init_all(bond);
-
-	rtnl_unlock();
-	return 0;
-}
-
-static int __net_init bond_net_init(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-
-	bn->net = net;
-	INIT_LIST_HEAD(&bn->dev_list);
-
-	bond_create_proc_dir(bn);
-	bond_create_sysfs(bn);
-
-	return 0;
-}
-
-static void __net_exit bond_net_exit(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-	struct bonding *bond, *tmp_bond;
-	LIST_HEAD(list);
-
-	bond_destroy_sysfs(bn);
-
-	/* Kill off any bonds created after unregistering bond rtnl ops */
-	rtnl_lock();
-	list_for_each_entry_safe(bond, tmp_bond, &bn->dev_list, bond_list)
-		unregister_netdevice_queue(bond->dev, &list);
-	unregister_netdevice_many(&list);
-	rtnl_unlock();
-
-	bond_destroy_proc_dir(bn);
-}
-
-static struct pernet_operations bond_net_ops = {
-	.init = bond_net_init,
-	.exit = bond_net_exit,
-	.id   = &bond_net_id,
-	.size = sizeof(struct bond_net),
-};
-
-static int __init bonding_init(void)
-{
-	int i;
-	int res;
-
-	pr_info("%s", bond_version);
-
-	res = bond_check_params(&bonding_defaults);
-	if (res)
-		goto out;
-
-	res = register_pernet_subsys(&bond_net_ops);
-	if (res)
-		goto out;
-
-	res = bond_netlink_init();
-	if (res)
-		goto err_link;
-
-	bond_create_debugfs();
-
-	for (i = 0; i < max_bonds; i++) {
-		res = bond_create(&init_net, NULL);
-		if (res)
-			goto err;
-	}
-
-	register_netdevice_notifier(&bond_netdev_notifier);
-	register_toe_bond_rr_select_cb(bond_xmit_roundrobin_select);
-	register_toe_bond_acb_select_cb(bond_xmit_activebackup_select);
-	register_toe_bond_8023AD_select_cb(bond_xmit_xor_select);
-	register_toe_bond_xor_select_cb(bond_xmit_xor_select);
-out:
-	return res;
-err:
-	bond_destroy_debugfs();
-	bond_netlink_fini();
-err_link:
-	unregister_pernet_subsys(&bond_net_ops);
-	goto out;
-
-}
-
-static void __exit bonding_exit(void)
-{
-	unregister_netdevice_notifier(&bond_netdev_notifier);
-
-	bond_destroy_debugfs();
-
-	bond_netlink_fini();
-	unregister_pernet_subsys(&bond_net_ops);
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	/* Make sure we don't have an imbalance on our netpoll blocking */
-	WARN_ON(atomic_read(&netpoll_block_tx));
-#endif
-}
-
-module_init(bonding_init);
-module_exit(bonding_exit);
-MODULE_LICENSE("GPL");
-MODULE_VERSION(DRV_VERSION);
-MODULE_DESCRIPTION(DRV_DESCRIPTION ", v" DRV_VERSION);
-MODULE_AUTHOR("Thomas Davis, tadavis@lbl.gov and many others");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.82/bond_netlink.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.82/bond_netlink.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,785 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * drivers/net/bond/bond_netlink.c - Netlink interface for bonding
- * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
- * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/module.h>
-#include <linux/errno.h>
-#include <linux/netdevice.h>
-#include <linux/etherdevice.h>
-#include <linux/if_link.h>
-#include <linux/if_ether.h>
-#include <net/netlink.h>
-#include <net/rtnetlink.h>
-#include <net/bonding.h>
-
-static size_t bond_get_slave_size(const struct net_device *bond_dev,
-				  const struct net_device *slave_dev)
-{
-	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_STATE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_MII_STATUS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_SLAVE_LINK_FAILURE_COUNT */
-		nla_total_size(MAX_ADDR_LEN) +	/* IFLA_BOND_SLAVE_PERM_HWADDR */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_QUEUE_ID */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_AGGREGATOR_ID */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE */
-		0;
-}
-
-static int bond_fill_slave_info(struct sk_buff *skb,
-				const struct net_device *bond_dev,
-				const struct net_device *slave_dev)
-{
-	struct slave *slave = bond_slave_get_rtnl(slave_dev);
-
-	if (nla_put_u8(skb, IFLA_BOND_SLAVE_STATE, bond_slave_state(slave)))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_SLAVE_MII_STATUS, slave->link))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_SLAVE_LINK_FAILURE_COUNT,
-			slave->link_failure_count))
-		goto nla_put_failure;
-
-	if (nla_put(skb, IFLA_BOND_SLAVE_PERM_HWADDR,
-		    slave_dev->addr_len, slave->perm_hwaddr))
-		goto nla_put_failure;
-
-	if (nla_put_u16(skb, IFLA_BOND_SLAVE_QUEUE_ID, slave->queue_id))
-		goto nla_put_failure;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		const struct aggregator *agg;
-		const struct port *ad_port;
-
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		agg = SLAVE_AD_INFO(slave)->port.aggregator;
-		if (agg) {
-			if (nla_put_u16(skb, IFLA_BOND_SLAVE_AD_AGGREGATOR_ID,
-					agg->aggregator_identifier))
-				goto nla_put_failure;
-			if (nla_put_u8(skb,
-				       IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE,
-				       ad_port->actor_oper_port_state))
-				goto nla_put_failure;
-			if (nla_put_u16(skb,
-					IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE,
-					ad_port->partner_oper.port_state))
-				goto nla_put_failure;
-		}
-	}
-
-	return 0;
-
-nla_put_failure:
-	return -EMSGSIZE;
-}
-
-static const struct nla_policy bond_policy[IFLA_BOND_MAX + 1] = {
-	[IFLA_BOND_MODE]		= { .type = NLA_U8 },
-	[IFLA_BOND_ACTIVE_SLAVE]	= { .type = NLA_U32 },
-	[IFLA_BOND_MIIMON]		= { .type = NLA_U32 },
-	[IFLA_BOND_UPDELAY]		= { .type = NLA_U32 },
-	[IFLA_BOND_DOWNDELAY]		= { .type = NLA_U32 },
-	[IFLA_BOND_USE_CARRIER]		= { .type = NLA_U8 },
-	[IFLA_BOND_ARP_INTERVAL]	= { .type = NLA_U32 },
-	[IFLA_BOND_ARP_IP_TARGET]	= { .type = NLA_NESTED },
-	[IFLA_BOND_ARP_VALIDATE]	= { .type = NLA_U32 },
-	[IFLA_BOND_ARP_ALL_TARGETS]	= { .type = NLA_U32 },
-	[IFLA_BOND_PRIMARY]		= { .type = NLA_U32 },
-	[IFLA_BOND_PRIMARY_RESELECT]	= { .type = NLA_U8 },
-	[IFLA_BOND_FAIL_OVER_MAC]	= { .type = NLA_U8 },
-	[IFLA_BOND_XMIT_HASH_POLICY]	= { .type = NLA_U8 },
-	[IFLA_BOND_RESEND_IGMP]		= { .type = NLA_U32 },
-	[IFLA_BOND_NUM_PEER_NOTIF]	= { .type = NLA_U8 },
-	[IFLA_BOND_ALL_SLAVES_ACTIVE]	= { .type = NLA_U8 },
-	[IFLA_BOND_MIN_LINKS]		= { .type = NLA_U32 },
-	[IFLA_BOND_LP_INTERVAL]		= { .type = NLA_U32 },
-	[IFLA_BOND_PACKETS_PER_SLAVE]	= { .type = NLA_U32 },
-	[IFLA_BOND_AD_LACP_RATE]	= { .type = NLA_U8 },
-	[IFLA_BOND_AD_SELECT]		= { .type = NLA_U8 },
-	[IFLA_BOND_AD_INFO]		= { .type = NLA_NESTED },
-	[IFLA_BOND_AD_ACTOR_SYS_PRIO]	= { .type = NLA_U16 },
-	[IFLA_BOND_AD_USER_PORT_KEY]	= { .type = NLA_U16 },
-	[IFLA_BOND_AD_ACTOR_SYSTEM]	= { .type = NLA_BINARY,
-					    .len  = ETH_ALEN },
-	[IFLA_BOND_TLB_DYNAMIC_LB]	= { .type = NLA_U8 },
-	[IFLA_BOND_PEER_NOTIF_DELAY]    = { .type = NLA_U32 },
-};
-
-static const struct nla_policy bond_slave_policy[IFLA_BOND_SLAVE_MAX + 1] = {
-	[IFLA_BOND_SLAVE_QUEUE_ID]	= { .type = NLA_U16 },
-};
-
-static int bond_validate(struct nlattr *tb[], struct nlattr *data[],
-			 struct netlink_ext_ack *extack)
-{
-	if (tb[IFLA_ADDRESS]) {
-		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN)
-			return -EINVAL;
-		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS])))
-			return -EADDRNOTAVAIL;
-	}
-	return 0;
-}
-
-static int bond_slave_changelink(struct net_device *bond_dev,
-				 struct net_device *slave_dev,
-				 struct nlattr *tb[], struct nlattr *data[],
-				 struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_opt_value newval;
-	int err;
-
-	if (!data)
-		return 0;
-
-	if (data[IFLA_BOND_SLAVE_QUEUE_ID]) {
-		u16 queue_id = nla_get_u16(data[IFLA_BOND_SLAVE_QUEUE_ID]);
-		char queue_id_str[IFNAMSIZ + 7];
-
-		/* queue_id option setting expects slave_name:queue_id */
-		snprintf(queue_id_str, sizeof(queue_id_str), "%s:%u\n",
-			 slave_dev->name, queue_id);
-		bond_opt_initstr(&newval, queue_id_str);
-		err = __bond_opt_set(bond, BOND_OPT_QUEUE_ID, &newval);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int bond_changelink(struct net_device *bond_dev, struct nlattr *tb[],
-			   struct nlattr *data[],
-			   struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_opt_value newval;
-	int miimon = 0;
-	int err;
-
-	if (!data)
-		return 0;
-
-	if (data[IFLA_BOND_MODE]) {
-		int mode = nla_get_u8(data[IFLA_BOND_MODE]);
-
-		bond_opt_initval(&newval, mode);
-		err = __bond_opt_set(bond, BOND_OPT_MODE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ACTIVE_SLAVE]) {
-		int ifindex = nla_get_u32(data[IFLA_BOND_ACTIVE_SLAVE]);
-		struct net_device *slave_dev;
-		char *active_slave = "";
-
-		if (ifindex != 0) {
-			slave_dev = __dev_get_by_index(dev_net(bond_dev),
-						       ifindex);
-			if (!slave_dev)
-				return -ENODEV;
-			active_slave = slave_dev->name;
-		}
-		bond_opt_initstr(&newval, active_slave);
-		err = __bond_opt_set(bond, BOND_OPT_ACTIVE_SLAVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_MIIMON]) {
-		miimon = nla_get_u32(data[IFLA_BOND_MIIMON]);
-
-		bond_opt_initval(&newval, miimon);
-		err = __bond_opt_set(bond, BOND_OPT_MIIMON, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_UPDELAY]) {
-		int updelay = nla_get_u32(data[IFLA_BOND_UPDELAY]);
-
-		bond_opt_initval(&newval, updelay);
-		err = __bond_opt_set(bond, BOND_OPT_UPDELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_DOWNDELAY]) {
-		int downdelay = nla_get_u32(data[IFLA_BOND_DOWNDELAY]);
-
-		bond_opt_initval(&newval, downdelay);
-		err = __bond_opt_set(bond, BOND_OPT_DOWNDELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PEER_NOTIF_DELAY]) {
-		int delay = nla_get_u32(data[IFLA_BOND_PEER_NOTIF_DELAY]);
-
-		bond_opt_initval(&newval, delay);
-		err = __bond_opt_set(bond, BOND_OPT_PEER_NOTIF_DELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_USE_CARRIER]) {
-		int use_carrier = nla_get_u8(data[IFLA_BOND_USE_CARRIER]);
-
-		bond_opt_initval(&newval, use_carrier);
-		err = __bond_opt_set(bond, BOND_OPT_USE_CARRIER, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_INTERVAL]) {
-		int arp_interval = nla_get_u32(data[IFLA_BOND_ARP_INTERVAL]);
-
-		if (arp_interval && miimon) {
-			netdev_err(bond->dev, "ARP monitoring cannot be used with MII monitoring\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initval(&newval, arp_interval);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_INTERVAL, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_IP_TARGET]) {
-		struct nlattr *attr;
-		int i = 0, rem;
-
-		bond_option_arp_ip_targets_clear(bond);
-		nla_for_each_nested(attr, data[IFLA_BOND_ARP_IP_TARGET], rem) {
-			__be32 target;
-
-			if (nla_len(attr) < sizeof(target))
-				return -EINVAL;
-
-			target = nla_get_be32(attr);
-
-			bond_opt_initval(&newval, (__force u64)target);
-			err = __bond_opt_set(bond, BOND_OPT_ARP_TARGETS,
-					     &newval);
-			if (err)
-				break;
-			i++;
-		}
-		if (i == 0 && bond->params.arp_interval)
-			netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_VALIDATE]) {
-		int arp_validate = nla_get_u32(data[IFLA_BOND_ARP_VALIDATE]);
-
-		if (arp_validate && miimon) {
-			netdev_err(bond->dev, "ARP validating cannot be used with MII monitoring\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initval(&newval, arp_validate);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_VALIDATE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_ALL_TARGETS]) {
-		int arp_all_targets =
-			nla_get_u32(data[IFLA_BOND_ARP_ALL_TARGETS]);
-
-		bond_opt_initval(&newval, arp_all_targets);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_ALL_TARGETS, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PRIMARY]) {
-		int ifindex = nla_get_u32(data[IFLA_BOND_PRIMARY]);
-		struct net_device *dev;
-		char *primary = "";
-
-		dev = __dev_get_by_index(dev_net(bond_dev), ifindex);
-		if (dev)
-			primary = dev->name;
-
-		bond_opt_initstr(&newval, primary);
-		err = __bond_opt_set(bond, BOND_OPT_PRIMARY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PRIMARY_RESELECT]) {
-		int primary_reselect =
-			nla_get_u8(data[IFLA_BOND_PRIMARY_RESELECT]);
-
-		bond_opt_initval(&newval, primary_reselect);
-		err = __bond_opt_set(bond, BOND_OPT_PRIMARY_RESELECT, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_FAIL_OVER_MAC]) {
-		int fail_over_mac =
-			nla_get_u8(data[IFLA_BOND_FAIL_OVER_MAC]);
-
-		bond_opt_initval(&newval, fail_over_mac);
-		err = __bond_opt_set(bond, BOND_OPT_FAIL_OVER_MAC, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_XMIT_HASH_POLICY]) {
-		int xmit_hash_policy =
-			nla_get_u8(data[IFLA_BOND_XMIT_HASH_POLICY]);
-
-		bond_opt_initval(&newval, xmit_hash_policy);
-		err = __bond_opt_set(bond, BOND_OPT_XMIT_HASH, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_RESEND_IGMP]) {
-		int resend_igmp =
-			nla_get_u32(data[IFLA_BOND_RESEND_IGMP]);
-
-		bond_opt_initval(&newval, resend_igmp);
-		err = __bond_opt_set(bond, BOND_OPT_RESEND_IGMP, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_NUM_PEER_NOTIF]) {
-		int num_peer_notif =
-			nla_get_u8(data[IFLA_BOND_NUM_PEER_NOTIF]);
-
-		bond_opt_initval(&newval, num_peer_notif);
-		err = __bond_opt_set(bond, BOND_OPT_NUM_PEER_NOTIF, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ALL_SLAVES_ACTIVE]) {
-		int all_slaves_active =
-			nla_get_u8(data[IFLA_BOND_ALL_SLAVES_ACTIVE]);
-
-		bond_opt_initval(&newval, all_slaves_active);
-		err = __bond_opt_set(bond, BOND_OPT_ALL_SLAVES_ACTIVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_MIN_LINKS]) {
-		int min_links =
-			nla_get_u32(data[IFLA_BOND_MIN_LINKS]);
-
-		bond_opt_initval(&newval, min_links);
-		err = __bond_opt_set(bond, BOND_OPT_MINLINKS, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_LP_INTERVAL]) {
-		int lp_interval =
-			nla_get_u32(data[IFLA_BOND_LP_INTERVAL]);
-
-		bond_opt_initval(&newval, lp_interval);
-		err = __bond_opt_set(bond, BOND_OPT_LP_INTERVAL, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PACKETS_PER_SLAVE]) {
-		int packets_per_slave =
-			nla_get_u32(data[IFLA_BOND_PACKETS_PER_SLAVE]);
-
-		bond_opt_initval(&newval, packets_per_slave);
-		err = __bond_opt_set(bond, BOND_OPT_PACKETS_PER_SLAVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_LACP_RATE]) {
-		int lacp_rate =
-			nla_get_u8(data[IFLA_BOND_AD_LACP_RATE]);
-
-		bond_opt_initval(&newval, lacp_rate);
-		err = __bond_opt_set(bond, BOND_OPT_LACP_RATE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_SELECT]) {
-		int ad_select =
-			nla_get_u8(data[IFLA_BOND_AD_SELECT]);
-
-		bond_opt_initval(&newval, ad_select);
-		err = __bond_opt_set(bond, BOND_OPT_AD_SELECT, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_ACTOR_SYS_PRIO]) {
-		int actor_sys_prio =
-			nla_get_u16(data[IFLA_BOND_AD_ACTOR_SYS_PRIO]);
-
-		bond_opt_initval(&newval, actor_sys_prio);
-		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYS_PRIO, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_USER_PORT_KEY]) {
-		int port_key =
-			nla_get_u16(data[IFLA_BOND_AD_USER_PORT_KEY]);
-
-		bond_opt_initval(&newval, port_key);
-		err = __bond_opt_set(bond, BOND_OPT_AD_USER_PORT_KEY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_ACTOR_SYSTEM]) {
-		if (nla_len(data[IFLA_BOND_AD_ACTOR_SYSTEM]) != ETH_ALEN)
-			return -EINVAL;
-
-		bond_opt_initval(&newval,
-				 nla_get_u64(data[IFLA_BOND_AD_ACTOR_SYSTEM]));
-		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYSTEM, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_TLB_DYNAMIC_LB]) {
-		int dynamic_lb = nla_get_u8(data[IFLA_BOND_TLB_DYNAMIC_LB]);
-
-		bond_opt_initval(&newval, dynamic_lb);
-		err = __bond_opt_set(bond, BOND_OPT_TLB_DYNAMIC_LB, &newval);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int bond_newlink(struct net *src_net, struct net_device *bond_dev,
-			struct nlattr *tb[], struct nlattr *data[],
-			struct netlink_ext_ack *extack)
-{
-	int err;
-
-	err = bond_changelink(bond_dev, tb, data, extack);
-	if (err < 0)
-		return err;
-
-	err = register_netdevice(bond_dev);
-	if (!err) {
-		struct bonding *bond = netdev_priv(bond_dev);
-
-		netif_carrier_off(bond_dev);
-		bond_work_init_all(bond);
-	}
-
-	return err;
-}
-
-static size_t bond_get_size(const struct net_device *bond_dev)
-{
-	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_MODE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ACTIVE_SLAVE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIIMON */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_UPDELAY */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_DOWNDELAY */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_USE_CARRIER */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_INTERVAL */
-						/* IFLA_BOND_ARP_IP_TARGET */
-		nla_total_size(sizeof(struct nlattr)) +
-		nla_total_size(sizeof(u32)) * BOND_MAX_ARP_TARGETS +
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_VALIDATE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_ALL_TARGETS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PRIMARY */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_PRIMARY_RESELECT */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_FAIL_OVER_MAC */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_XMIT_HASH_POLICY */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_RESEND_IGMP */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_NUM_PEER_NOTIF */
-		nla_total_size(sizeof(u8)) +   /* IFLA_BOND_ALL_SLAVES_ACTIVE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIN_LINKS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_LP_INTERVAL */
-		nla_total_size(sizeof(u32)) +  /* IFLA_BOND_PACKETS_PER_SLAVE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_LACP_RATE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_SELECT */
-		nla_total_size(sizeof(struct nlattr)) + /* IFLA_BOND_AD_INFO */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_AGGREGATOR */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_NUM_PORTS */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_ACTOR_KEY */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_PARTNER_KEY*/
-		nla_total_size(ETH_ALEN) +    /* IFLA_BOND_AD_INFO_PARTNER_MAC*/
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_ACTOR_SYS_PRIO */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_USER_PORT_KEY */
-		nla_total_size(ETH_ALEN) + /* IFLA_BOND_AD_ACTOR_SYSTEM */
-		nla_total_size(sizeof(u8)) + /* IFLA_BOND_TLB_DYNAMIC_LB */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PEER_NOTIF_DELAY */
-		0;
-}
-
-static int bond_option_active_slave_get_ifindex(struct bonding *bond)
-{
-	const struct net_device *slave;
-	int ifindex;
-
-	rcu_read_lock();
-	slave = bond_option_active_slave_get_rcu(bond);
-	ifindex = slave ? slave->ifindex : 0;
-	rcu_read_unlock();
-	return ifindex;
-}
-
-static int bond_fill_info(struct sk_buff *skb,
-			  const struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	unsigned int packets_per_slave;
-	int ifindex, i, targets_added;
-	struct nlattr *targets;
-	struct slave *primary;
-
-	if (nla_put_u8(skb, IFLA_BOND_MODE, BOND_MODE(bond)))
-		goto nla_put_failure;
-
-	ifindex = bond_option_active_slave_get_ifindex(bond);
-	if (ifindex && nla_put_u32(skb, IFLA_BOND_ACTIVE_SLAVE, ifindex))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_MIIMON, bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_UPDELAY,
-			bond->params.updelay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_DOWNDELAY,
-			bond->params.downdelay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_PEER_NOTIF_DELAY,
-			bond->params.peer_notif_delay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_USE_CARRIER, bond->params.use_carrier))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_INTERVAL, bond->params.arp_interval))
-		goto nla_put_failure;
-
-	targets = nla_nest_start_noflag(skb, IFLA_BOND_ARP_IP_TARGET);
-	if (!targets)
-		goto nla_put_failure;
-
-	targets_added = 0;
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
-		if (bond->params.arp_targets[i]) {
-			if (nla_put_be32(skb, i, bond->params.arp_targets[i]))
-				goto nla_put_failure;
-			targets_added = 1;
-		}
-	}
-
-	if (targets_added)
-		nla_nest_end(skb, targets);
-	else
-		nla_nest_cancel(skb, targets);
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_VALIDATE, bond->params.arp_validate))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_ALL_TARGETS,
-			bond->params.arp_all_targets))
-		goto nla_put_failure;
-
-	primary = rtnl_dereference(bond->primary_slave);
-	if (primary &&
-	    nla_put_u32(skb, IFLA_BOND_PRIMARY, primary->dev->ifindex))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_PRIMARY_RESELECT,
-		       bond->params.primary_reselect))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_FAIL_OVER_MAC,
-		       bond->params.fail_over_mac))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_XMIT_HASH_POLICY,
-		       bond->params.xmit_policy))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_RESEND_IGMP,
-		        bond->params.resend_igmp))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_NUM_PEER_NOTIF,
-		       bond->params.num_peer_notif))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_ALL_SLAVES_ACTIVE,
-		       bond->params.all_slaves_active))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_MIN_LINKS,
-			bond->params.min_links))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_LP_INTERVAL,
-			bond->params.lp_interval))
-		goto nla_put_failure;
-
-	packets_per_slave = bond->params.packets_per_slave;
-	if (nla_put_u32(skb, IFLA_BOND_PACKETS_PER_SLAVE,
-			packets_per_slave))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_AD_LACP_RATE,
-		       bond->params.lacp_fast))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_AD_SELECT,
-		       bond->params.ad_select))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_TLB_DYNAMIC_LB,
-		       bond->params.tlb_dynamic_lb))
-		goto nla_put_failure;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info info;
-
-		if (capable(CAP_NET_ADMIN)) {
-			if (nla_put_u16(skb, IFLA_BOND_AD_ACTOR_SYS_PRIO,
-					bond->params.ad_actor_sys_prio))
-				goto nla_put_failure;
-
-			if (nla_put_u16(skb, IFLA_BOND_AD_USER_PORT_KEY,
-					bond->params.ad_user_port_key))
-				goto nla_put_failure;
-
-			if (nla_put(skb, IFLA_BOND_AD_ACTOR_SYSTEM,
-				    ETH_ALEN, &bond->params.ad_actor_system))
-				goto nla_put_failure;
-		}
-		if (!bond_3ad_get_active_agg_info(bond, &info)) {
-			struct nlattr *nest;
-
-			nest = nla_nest_start_noflag(skb, IFLA_BOND_AD_INFO);
-			if (!nest)
-				goto nla_put_failure;
-
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_AGGREGATOR,
-					info.aggregator_id))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_NUM_PORTS,
-					info.ports))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_ACTOR_KEY,
-					info.actor_key))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_PARTNER_KEY,
-					info.partner_key))
-				goto nla_put_failure;
-			if (nla_put(skb, IFLA_BOND_AD_INFO_PARTNER_MAC,
-				    sizeof(info.partner_system),
-				    &info.partner_system))
-				goto nla_put_failure;
-
-			nla_nest_end(skb, nest);
-		}
-	}
-
-	return 0;
-
-nla_put_failure:
-	return -EMSGSIZE;
-}
-
-static size_t bond_get_linkxstats_size(const struct net_device *dev, int attr)
-{
-	switch (attr) {
-	case IFLA_STATS_LINK_XSTATS:
-	case IFLA_STATS_LINK_XSTATS_SLAVE:
-		break;
-	default:
-		return 0;
-	}
-
-	return bond_3ad_stats_size() + nla_total_size(0);
-}
-
-static int bond_fill_linkxstats(struct sk_buff *skb,
-				const struct net_device *dev,
-				int *prividx, int attr)
-{
-	struct nlattr *nla __maybe_unused;
-	struct slave *slave = NULL;
-	struct nlattr *nest, *nest2;
-	struct bonding *bond;
-
-	switch (attr) {
-	case IFLA_STATS_LINK_XSTATS:
-		bond = netdev_priv(dev);
-		break;
-	case IFLA_STATS_LINK_XSTATS_SLAVE:
-		slave = bond_slave_get_rtnl(dev);
-		if (!slave)
-			return 0;
-		bond = slave->bond;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	nest = nla_nest_start_noflag(skb, LINK_XSTATS_TYPE_BOND);
-	if (!nest)
-		return -EMSGSIZE;
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct bond_3ad_stats *stats;
-
-		if (slave)
-			stats = &SLAVE_AD_INFO(slave)->stats;
-		else
-			stats = &BOND_AD_INFO(bond).stats;
-
-		nest2 = nla_nest_start_noflag(skb, BOND_XSTATS_3AD);
-		if (!nest2) {
-			nla_nest_end(skb, nest);
-			return -EMSGSIZE;
-		}
-
-		if (bond_3ad_stats_fill(skb, stats)) {
-			nla_nest_cancel(skb, nest2);
-			nla_nest_end(skb, nest);
-			return -EMSGSIZE;
-		}
-		nla_nest_end(skb, nest2);
-	}
-	nla_nest_end(skb, nest);
-
-	return 0;
-}
-
-struct rtnl_link_ops bond_link_ops __read_mostly = {
-	.kind			= "bond",
-	.priv_size		= sizeof(struct bonding),
-	.setup			= bond_setup,
-	.maxtype		= IFLA_BOND_MAX,
-	.policy			= bond_policy,
-	.validate		= bond_validate,
-	.newlink		= bond_newlink,
-	.changelink		= bond_changelink,
-	.get_size		= bond_get_size,
-	.fill_info		= bond_fill_info,
-	.get_num_tx_queues	= bond_get_num_tx_queues,
-	.get_num_rx_queues	= bond_get_num_tx_queues, /* Use the same number
-							     as for TX queues */
-	.fill_linkxstats        = bond_fill_linkxstats,
-	.get_linkxstats_size    = bond_get_linkxstats_size,
-	.slave_maxtype		= IFLA_BOND_SLAVE_MAX,
-	.slave_policy		= bond_slave_policy,
-	.slave_changelink	= bond_slave_changelink,
-	.get_slave_size		= bond_get_slave_size,
-	.fill_slave_info	= bond_fill_slave_info,
-};
-
-int __init bond_netlink_init(void)
-{
-	return rtnl_link_register(&bond_link_ops);
-}
-
-void bond_netlink_fini(void)
-{
-	rtnl_link_unregister(&bond_link_ops);
-}
-
-MODULE_ALIAS_RTNL_LINK("bond");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.82/bond_options.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.82/bond_options.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1477 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * drivers/net/bond/bond_options.c - bonding options
- * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
- * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/errno.h>
-#include <linux/if.h>
-#include <linux/netdevice.h>
-#include <linux/spinlock.h>
-#include <linux/rcupdate.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/sched/signal.h>
-
-#include <net/bonding.h>
-
-static int bond_option_active_slave_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_miimon_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_updelay_set(struct bonding *bond,
-				   const struct bond_opt_value *newval);
-static int bond_option_downdelay_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_peer_notif_delay_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_use_carrier_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_arp_interval_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target);
-static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target);
-static int bond_option_arp_ip_targets_set(struct bonding *bond,
-					  const struct bond_opt_value *newval);
-static int bond_option_arp_validate_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_arp_all_targets_set(struct bonding *bond,
-					   const struct bond_opt_value *newval);
-static int bond_option_primary_set(struct bonding *bond,
-				   const struct bond_opt_value *newval);
-static int bond_option_primary_reselect_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_fail_over_mac_set(struct bonding *bond,
-					 const struct bond_opt_value *newval);
-static int bond_option_xmit_hash_policy_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_resend_igmp_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_num_peer_notif_set(struct bonding *bond,
-					  const struct bond_opt_value *newval);
-static int bond_option_all_slaves_active_set(struct bonding *bond,
-					     const struct bond_opt_value *newval);
-static int bond_option_min_links_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_lp_interval_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_pps_set(struct bonding *bond,
-			       const struct bond_opt_value *newval);
-static int bond_option_lacp_rate_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_ad_select_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_queue_id_set(struct bonding *bond,
-				    const struct bond_opt_value *newval);
-static int bond_option_mode_set(struct bonding *bond,
-				const struct bond_opt_value *newval);
-static int bond_option_slaves_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
-					     const struct bond_opt_value *newval);
-static int bond_option_ad_actor_system_set(struct bonding *bond,
-					   const struct bond_opt_value *newval);
-static int bond_option_ad_user_port_key_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-
-
-static const struct bond_opt_value bond_mode_tbl[] = {
-	{ "balance-rr",    BOND_MODE_ROUNDROBIN,   BOND_VALFLAG_DEFAULT},
-	{ "active-backup", BOND_MODE_ACTIVEBACKUP, 0},
-	{ "balance-xor",   BOND_MODE_XOR,          0},
-	{ "broadcast",     BOND_MODE_BROADCAST,    0},
-	{ "802.3ad",       BOND_MODE_8023AD,       0},
-	{ "balance-tlb",   BOND_MODE_TLB,          0},
-	{ "balance-alb",   BOND_MODE_ALB,          0},
-	{ NULL,            -1,                     0},
-};
-
-static const struct bond_opt_value bond_pps_tbl[] = {
-	{ "default", 1,         BOND_VALFLAG_DEFAULT},
-	{ "maxval",  USHRT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,        0},
-};
-
-static const struct bond_opt_value bond_xmit_hashtype_tbl[] = {
-	{ "layer2",   BOND_XMIT_POLICY_LAYER2, BOND_VALFLAG_DEFAULT},
-	{ "layer3+4", BOND_XMIT_POLICY_LAYER34, 0},
-	{ "layer2+3", BOND_XMIT_POLICY_LAYER23, 0},
-	{ "encap2+3", BOND_XMIT_POLICY_ENCAP23, 0},
-	{ "encap3+4", BOND_XMIT_POLICY_ENCAP34, 0},
-	{ NULL,       -1,                       0},
-};
-
-static const struct bond_opt_value bond_arp_validate_tbl[] = {
-	{ "none",		BOND_ARP_VALIDATE_NONE,		BOND_VALFLAG_DEFAULT},
-	{ "active",		BOND_ARP_VALIDATE_ACTIVE,	0},
-	{ "backup",		BOND_ARP_VALIDATE_BACKUP,	0},
-	{ "all",		BOND_ARP_VALIDATE_ALL,		0},
-	{ "filter",		BOND_ARP_FILTER,		0},
-	{ "filter_active",	BOND_ARP_FILTER_ACTIVE,		0},
-	{ "filter_backup",	BOND_ARP_FILTER_BACKUP,		0},
-	{ NULL,			-1,				0},
-};
-
-static const struct bond_opt_value bond_arp_all_targets_tbl[] = {
-	{ "any", BOND_ARP_TARGETS_ANY, BOND_VALFLAG_DEFAULT},
-	{ "all", BOND_ARP_TARGETS_ALL, 0},
-	{ NULL,  -1,                   0},
-};
-
-static const struct bond_opt_value bond_fail_over_mac_tbl[] = {
-	{ "none",   BOND_FOM_NONE,   BOND_VALFLAG_DEFAULT},
-	{ "active", BOND_FOM_ACTIVE, 0},
-	{ "follow", BOND_FOM_FOLLOW, 0},
-	{ NULL,     -1,              0},
-};
-
-static const struct bond_opt_value bond_intmax_tbl[] = {
-	{ "off",     0,       BOND_VALFLAG_DEFAULT},
-	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,      0}
-};
-
-static const struct bond_opt_value bond_lacp_rate_tbl[] = {
-	{ "slow", AD_LACP_SLOW, 0},
-	{ "fast", AD_LACP_FAST, 0},
-	{ NULL,   -1,           0},
-};
-
-static const struct bond_opt_value bond_ad_select_tbl[] = {
-	{ "stable",    BOND_AD_STABLE,    BOND_VALFLAG_DEFAULT},
-	{ "bandwidth", BOND_AD_BANDWIDTH, 0},
-	{ "count",     BOND_AD_COUNT,     0},
-	{ NULL,        -1,                0},
-};
-
-static const struct bond_opt_value bond_num_peer_notif_tbl[] = {
-	{ "off",     0,   0},
-	{ "maxval",  255, BOND_VALFLAG_MAX},
-	{ "default", 1,   BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,  0}
-};
-
-static const struct bond_opt_value bond_primary_reselect_tbl[] = {
-	{ "always",  BOND_PRI_RESELECT_ALWAYS,  BOND_VALFLAG_DEFAULT},
-	{ "better",  BOND_PRI_RESELECT_BETTER,  0},
-	{ "failure", BOND_PRI_RESELECT_FAILURE, 0},
-	{ NULL,      -1},
-};
-
-static const struct bond_opt_value bond_use_carrier_tbl[] = {
-	{ "off", 0,  0},
-	{ "on",  1,  BOND_VALFLAG_DEFAULT},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_all_slaves_active_tbl[] = {
-	{ "off", 0,  BOND_VALFLAG_DEFAULT},
-	{ "on",  1,  0},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_resend_igmp_tbl[] = {
-	{ "off",     0,   0},
-	{ "maxval",  255, BOND_VALFLAG_MAX},
-	{ "default", 1,   BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,  0}
-};
-
-static const struct bond_opt_value bond_lp_interval_tbl[] = {
-	{ "minval",  1,       BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
-	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,      0},
-};
-
-static const struct bond_opt_value bond_tlb_dynamic_lb_tbl[] = {
-	{ "off", 0,  0},
-	{ "on",  1,  BOND_VALFLAG_DEFAULT},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_ad_actor_sys_prio_tbl[] = {
-	{ "minval",  1,     BOND_VALFLAG_MIN},
-	{ "maxval",  65535, BOND_VALFLAG_MAX | BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,    0},
-};
-
-static const struct bond_opt_value bond_ad_user_port_key_tbl[] = {
-	{ "minval",  0,     BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
-	{ "maxval",  1023,  BOND_VALFLAG_MAX},
-	{ NULL,      -1,    0},
-};
-
-static const struct bond_option bond_opts[BOND_OPT_LAST] = {
-	[BOND_OPT_MODE] = {
-		.id = BOND_OPT_MODE,
-		.name = "mode",
-		.desc = "bond device mode",
-		.flags = BOND_OPTFLAG_NOSLAVES | BOND_OPTFLAG_IFDOWN,
-		.values = bond_mode_tbl,
-		.set = bond_option_mode_set
-	},
-	[BOND_OPT_PACKETS_PER_SLAVE] = {
-		.id = BOND_OPT_PACKETS_PER_SLAVE,
-		.name = "packets_per_slave",
-		.desc = "Packets to send per slave in RR mode",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ROUNDROBIN)),
-		.values = bond_pps_tbl,
-		.set = bond_option_pps_set
-	},
-	[BOND_OPT_XMIT_HASH] = {
-		.id = BOND_OPT_XMIT_HASH,
-		.name = "xmit_hash_policy",
-		.desc = "balance-xor, 802.3ad, and tlb hashing method",
-		.values = bond_xmit_hashtype_tbl,
-		.set = bond_option_xmit_hash_policy_set
-	},
-	[BOND_OPT_ARP_VALIDATE] = {
-		.id = BOND_OPT_ARP_VALIDATE,
-		.name = "arp_validate",
-		.desc = "validate src/dst of ARP probes",
-		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
-			       BIT(BOND_MODE_ALB),
-		.values = bond_arp_validate_tbl,
-		.set = bond_option_arp_validate_set
-	},
-	[BOND_OPT_ARP_ALL_TARGETS] = {
-		.id = BOND_OPT_ARP_ALL_TARGETS,
-		.name = "arp_all_targets",
-		.desc = "fail on any/all arp targets timeout",
-		.values = bond_arp_all_targets_tbl,
-		.set = bond_option_arp_all_targets_set
-	},
-	[BOND_OPT_FAIL_OVER_MAC] = {
-		.id = BOND_OPT_FAIL_OVER_MAC,
-		.name = "fail_over_mac",
-		.desc = "For active-backup, do not set all slaves to the same MAC",
-		.flags = BOND_OPTFLAG_NOSLAVES,
-		.values = bond_fail_over_mac_tbl,
-		.set = bond_option_fail_over_mac_set
-	},
-	[BOND_OPT_ARP_INTERVAL] = {
-		.id = BOND_OPT_ARP_INTERVAL,
-		.name = "arp_interval",
-		.desc = "arp interval in milliseconds",
-		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
-			       BIT(BOND_MODE_ALB),
-		.values = bond_intmax_tbl,
-		.set = bond_option_arp_interval_set
-	},
-	[BOND_OPT_ARP_TARGETS] = {
-		.id = BOND_OPT_ARP_TARGETS,
-		.name = "arp_ip_target",
-		.desc = "arp targets in n.n.n.n form",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_arp_ip_targets_set
-	},
-	[BOND_OPT_DOWNDELAY] = {
-		.id = BOND_OPT_DOWNDELAY,
-		.name = "downdelay",
-		.desc = "Delay before considering link down, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_downdelay_set
-	},
-	[BOND_OPT_UPDELAY] = {
-		.id = BOND_OPT_UPDELAY,
-		.name = "updelay",
-		.desc = "Delay before considering link up, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_updelay_set
-	},
-	[BOND_OPT_LACP_RATE] = {
-		.id = BOND_OPT_LACP_RATE,
-		.name = "lacp_rate",
-		.desc = "LACPDU tx rate to request from 802.3ad partner",
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.values = bond_lacp_rate_tbl,
-		.set = bond_option_lacp_rate_set
-	},
-	[BOND_OPT_MINLINKS] = {
-		.id = BOND_OPT_MINLINKS,
-		.name = "min_links",
-		.desc = "Minimum number of available links before turning on carrier",
-		.values = bond_intmax_tbl,
-		.set = bond_option_min_links_set
-	},
-	[BOND_OPT_AD_SELECT] = {
-		.id = BOND_OPT_AD_SELECT,
-		.name = "ad_select",
-		.desc = "802.3ad aggregation selection logic",
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.values = bond_ad_select_tbl,
-		.set = bond_option_ad_select_set
-	},
-	[BOND_OPT_NUM_PEER_NOTIF] = {
-		.id = BOND_OPT_NUM_PEER_NOTIF,
-		.name = "num_unsol_na",
-		.desc = "Number of peer notifications to send on failover event",
-		.values = bond_num_peer_notif_tbl,
-		.set = bond_option_num_peer_notif_set
-	},
-	[BOND_OPT_MIIMON] = {
-		.id = BOND_OPT_MIIMON,
-		.name = "miimon",
-		.desc = "Link check interval in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_miimon_set
-	},
-	[BOND_OPT_PRIMARY] = {
-		.id = BOND_OPT_PRIMARY,
-		.name = "primary",
-		.desc = "Primary network device to use",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
-						BIT(BOND_MODE_TLB) |
-						BIT(BOND_MODE_ALB)),
-		.set = bond_option_primary_set
-	},
-	[BOND_OPT_PRIMARY_RESELECT] = {
-		.id = BOND_OPT_PRIMARY_RESELECT,
-		.name = "primary_reselect",
-		.desc = "Reselect primary slave once it comes up",
-		.values = bond_primary_reselect_tbl,
-		.set = bond_option_primary_reselect_set
-	},
-	[BOND_OPT_USE_CARRIER] = {
-		.id = BOND_OPT_USE_CARRIER,
-		.name = "use_carrier",
-		.desc = "Use netif_carrier_ok (vs MII ioctls) in miimon",
-		.values = bond_use_carrier_tbl,
-		.set = bond_option_use_carrier_set
-	},
-	[BOND_OPT_ACTIVE_SLAVE] = {
-		.id = BOND_OPT_ACTIVE_SLAVE,
-		.name = "active_slave",
-		.desc = "Currently active slave",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
-						BIT(BOND_MODE_TLB) |
-						BIT(BOND_MODE_ALB)),
-		.set = bond_option_active_slave_set
-	},
-	[BOND_OPT_QUEUE_ID] = {
-		.id = BOND_OPT_QUEUE_ID,
-		.name = "queue_id",
-		.desc = "Set queue id of a slave",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_queue_id_set
-	},
-	[BOND_OPT_ALL_SLAVES_ACTIVE] = {
-		.id = BOND_OPT_ALL_SLAVES_ACTIVE,
-		.name = "all_slaves_active",
-		.desc = "Keep all frames received on an interface by setting active flag for all slaves",
-		.values = bond_all_slaves_active_tbl,
-		.set = bond_option_all_slaves_active_set
-	},
-	[BOND_OPT_RESEND_IGMP] = {
-		.id = BOND_OPT_RESEND_IGMP,
-		.name = "resend_igmp",
-		.desc = "Number of IGMP membership reports to send on link failure",
-		.values = bond_resend_igmp_tbl,
-		.set = bond_option_resend_igmp_set
-	},
-	[BOND_OPT_LP_INTERVAL] = {
-		.id = BOND_OPT_LP_INTERVAL,
-		.name = "lp_interval",
-		.desc = "The number of seconds between instances where the bonding driver sends learning packets to each slave's peer switch",
-		.values = bond_lp_interval_tbl,
-		.set = bond_option_lp_interval_set
-	},
-	[BOND_OPT_SLAVES] = {
-		.id = BOND_OPT_SLAVES,
-		.name = "slaves",
-		.desc = "Slave membership management",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_slaves_set
-	},
-	[BOND_OPT_TLB_DYNAMIC_LB] = {
-		.id = BOND_OPT_TLB_DYNAMIC_LB,
-		.name = "tlb_dynamic_lb",
-		.desc = "Enable dynamic flow shuffling",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_TLB) | BIT(BOND_MODE_ALB)),
-		.values = bond_tlb_dynamic_lb_tbl,
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.set = bond_option_tlb_dynamic_lb_set,
-	},
-	[BOND_OPT_AD_ACTOR_SYS_PRIO] = {
-		.id = BOND_OPT_AD_ACTOR_SYS_PRIO,
-		.name = "ad_actor_sys_prio",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.values = bond_ad_actor_sys_prio_tbl,
-		.set = bond_option_ad_actor_sys_prio_set,
-	},
-	[BOND_OPT_AD_ACTOR_SYSTEM] = {
-		.id = BOND_OPT_AD_ACTOR_SYSTEM,
-		.name = "ad_actor_system",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_ad_actor_system_set,
-	},
-	[BOND_OPT_AD_USER_PORT_KEY] = {
-		.id = BOND_OPT_AD_USER_PORT_KEY,
-		.name = "ad_user_port_key",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.values = bond_ad_user_port_key_tbl,
-		.set = bond_option_ad_user_port_key_set,
-	},
-	[BOND_OPT_NUM_PEER_NOTIF_ALIAS] = {
-		.id = BOND_OPT_NUM_PEER_NOTIF_ALIAS,
-		.name = "num_grat_arp",
-		.desc = "Number of peer notifications to send on failover event",
-		.values = bond_num_peer_notif_tbl,
-		.set = bond_option_num_peer_notif_set
-	},
-	[BOND_OPT_PEER_NOTIF_DELAY] = {
-		.id = BOND_OPT_PEER_NOTIF_DELAY,
-		.name = "peer_notif_delay",
-		.desc = "Delay between each peer notification on failover event, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_peer_notif_delay_set
-	}
-};
-
-/* Searches for an option by name */
-const struct bond_option *bond_opt_get_by_name(const char *name)
-{
-	const struct bond_option *opt;
-	int option;
-
-	for (option = 0; option < BOND_OPT_LAST; option++) {
-		opt = bond_opt_get(option);
-		if (opt && !strcmp(opt->name, name))
-			return opt;
-	}
-
-	return NULL;
-}
-
-/* Searches for a value in opt's values[] table */
-const struct bond_opt_value *bond_opt_get_val(unsigned int option, u64 val)
-{
-	const struct bond_option *opt;
-	int i;
-
-	opt = bond_opt_get(option);
-	if (WARN_ON(!opt))
-		return NULL;
-	for (i = 0; opt->values && opt->values[i].string; i++)
-		if (opt->values[i].value == val)
-			return &opt->values[i];
-
-	return NULL;
-}
-
-/* Searches for a value in opt's values[] table which matches the flagmask */
-static const struct bond_opt_value *bond_opt_get_flags(const struct bond_option *opt,
-						       u32 flagmask)
-{
-	int i;
-
-	for (i = 0; opt->values && opt->values[i].string; i++)
-		if (opt->values[i].flags & flagmask)
-			return &opt->values[i];
-
-	return NULL;
-}
-
-/* If maxval is missing then there's no range to check. In case minval is
- * missing then it's considered to be 0.
- */
-static bool bond_opt_check_range(const struct bond_option *opt, u64 val)
-{
-	const struct bond_opt_value *minval, *maxval;
-
-	minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
-	maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
-	if (!maxval || (minval && val < minval->value) || val > maxval->value)
-		return false;
-
-	return true;
-}
-
-/**
- * bond_opt_parse - parse option value
- * @opt: the option to parse against
- * @val: value to parse
- *
- * This function tries to extract the value from @val and check if it's
- * a possible match for the option and returns NULL if a match isn't found,
- * or the struct_opt_value that matched. It also strips the new line from
- * @val->string if it's present.
- */
-const struct bond_opt_value *bond_opt_parse(const struct bond_option *opt,
-					    struct bond_opt_value *val)
-{
-	char *p, valstr[BOND_OPT_MAX_NAMELEN + 1] = { 0, };
-	const struct bond_opt_value *tbl;
-	const struct bond_opt_value *ret = NULL;
-	bool checkval;
-	int i, rv;
-
-	/* No parsing if the option wants a raw val */
-	if (opt->flags & BOND_OPTFLAG_RAWVAL)
-		return val;
-
-	tbl = opt->values;
-	if (!tbl)
-		goto out;
-
-	/* ULLONG_MAX is used to bypass string processing */
-	checkval = val->value != ULLONG_MAX;
-	if (!checkval) {
-		if (!val->string)
-			goto out;
-		p = strchr(val->string, '\n');
-		if (p)
-			*p = '\0';
-		for (p = val->string; *p; p++)
-			if (!(isdigit(*p) || isspace(*p)))
-				break;
-		/* The following code extracts the string to match or the value
-		 * and sets checkval appropriately
-		 */
-		if (*p) {
-			rv = sscanf(val->string, "%32s", valstr);
-		} else {
-			rv = sscanf(val->string, "%llu", &val->value);
-			checkval = true;
-		}
-		if (!rv)
-			goto out;
-	}
-
-	for (i = 0; tbl[i].string; i++) {
-		/* Check for exact match */
-		if (checkval) {
-			if (val->value == tbl[i].value)
-				ret = &tbl[i];
-		} else {
-			if (!strcmp(valstr, "default") &&
-			    (tbl[i].flags & BOND_VALFLAG_DEFAULT))
-				ret = &tbl[i];
-
-			if (!strcmp(valstr, tbl[i].string))
-				ret = &tbl[i];
-		}
-		/* Found an exact match */
-		if (ret)
-			goto out;
-	}
-	/* Possible range match */
-	if (checkval && bond_opt_check_range(opt, val->value))
-		ret = val;
-out:
-	return ret;
-}
-
-/* Check opt's dependencies against bond mode and currently set options */
-static int bond_opt_check_deps(struct bonding *bond,
-			       const struct bond_option *opt)
-{
-	struct bond_params *params = &bond->params;
-
-	if (test_bit(params->mode, &opt->unsuppmodes))
-		return -EACCES;
-	if ((opt->flags & BOND_OPTFLAG_NOSLAVES) && bond_has_slaves(bond))
-		return -ENOTEMPTY;
-	if ((opt->flags & BOND_OPTFLAG_IFDOWN) && (bond->dev->flags & IFF_UP))
-		return -EBUSY;
-
-	return 0;
-}
-
-static void bond_opt_dep_print(struct bonding *bond,
-			       const struct bond_option *opt)
-{
-	const struct bond_opt_value *modeval;
-	struct bond_params *params;
-
-	params = &bond->params;
-	modeval = bond_opt_get_val(BOND_OPT_MODE, params->mode);
-	if (test_bit(params->mode, &opt->unsuppmodes))
-		netdev_err(bond->dev, "option %s: mode dependency failed, not supported in mode %s(%llu)\n",
-			   opt->name, modeval->string, modeval->value);
-}
-
-static void bond_opt_error_interpret(struct bonding *bond,
-				     const struct bond_option *opt,
-				     int error, const struct bond_opt_value *val)
-{
-	const struct bond_opt_value *minval, *maxval;
-	char *p;
-
-	switch (error) {
-	case -EINVAL:
-		if (val) {
-			if (val->string) {
-				/* sometimes RAWVAL opts may have new lines */
-				p = strchr(val->string, '\n');
-				if (p)
-					*p = '\0';
-				netdev_err(bond->dev, "option %s: invalid value (%s)\n",
-					   opt->name, val->string);
-			} else {
-				netdev_err(bond->dev, "option %s: invalid value (%llu)\n",
-					   opt->name, val->value);
-			}
-		}
-		minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
-		maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
-		if (!maxval)
-			break;
-		netdev_err(bond->dev, "option %s: allowed values %llu - %llu\n",
-			   opt->name, minval ? minval->value : 0, maxval->value);
-		break;
-	case -EACCES:
-		bond_opt_dep_print(bond, opt);
-		break;
-	case -ENOTEMPTY:
-		netdev_err(bond->dev, "option %s: unable to set because the bond device has slaves\n",
-			   opt->name);
-		break;
-	case -EBUSY:
-		netdev_err(bond->dev, "option %s: unable to set because the bond device is up\n",
-			   opt->name);
-		break;
-	default:
-		break;
-	}
-}
-
-/**
- * __bond_opt_set - set a bonding option
- * @bond: target bond device
- * @option: option to set
- * @val: value to set it to
- *
- * This function is used to change the bond's option value, it can be
- * used for both enabling/changing an option and for disabling it. RTNL lock
- * must be obtained before calling this function.
- */
-int __bond_opt_set(struct bonding *bond,
-		   unsigned int option, struct bond_opt_value *val)
-{
-	const struct bond_opt_value *retval = NULL;
-	const struct bond_option *opt;
-	int ret = -ENOENT;
-
-	ASSERT_RTNL();
-
-	opt = bond_opt_get(option);
-	if (WARN_ON(!val) || WARN_ON(!opt))
-		goto out;
-	ret = bond_opt_check_deps(bond, opt);
-	if (ret)
-		goto out;
-	retval = bond_opt_parse(opt, val);
-	if (!retval) {
-		ret = -EINVAL;
-		goto out;
-	}
-	ret = opt->set(bond, retval);
-out:
-	if (ret)
-		bond_opt_error_interpret(bond, opt, ret, val);
-
-	return ret;
-}
-/**
- * __bond_opt_set_notify - set a bonding option
- * @bond: target bond device
- * @option: option to set
- * @val: value to set it to
- *
- * This function is used to change the bond's option value and trigger
- * a notification to user sapce. It can be used for both enabling/changing
- * an option and for disabling it. RTNL lock must be obtained before calling
- * this function.
- */
-int __bond_opt_set_notify(struct bonding *bond,
-			  unsigned int option, struct bond_opt_value *val)
-{
-	int ret = -ENOENT;
-
-	ASSERT_RTNL();
-
-	ret = __bond_opt_set(bond, option, val);
-
-	if (!ret && (bond->dev->reg_state == NETREG_REGISTERED))
-		call_netdevice_notifiers(NETDEV_CHANGEINFODATA, bond->dev);
-
-	return ret;
-}
-
-/**
- * bond_opt_tryset_rtnl - try to acquire rtnl and call __bond_opt_set
- * @bond: target bond device
- * @option: option to set
- * @buf: value to set it to
- *
- * This function tries to acquire RTNL without blocking and if successful
- * calls __bond_opt_set. It is mainly used for sysfs option manipulation.
- */
-int bond_opt_tryset_rtnl(struct bonding *bond, unsigned int option, char *buf)
-{
-	struct bond_opt_value optval;
-	int ret;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-	bond_opt_initstr(&optval, buf);
-	ret = __bond_opt_set_notify(bond, option, &optval);
-	rtnl_unlock();
-
-	return ret;
-}
-
-/**
- * bond_opt_get - get a pointer to an option
- * @option: option for which to return a pointer
- *
- * This function checks if option is valid and if so returns a pointer
- * to its entry in the bond_opts[] option array.
- */
-const struct bond_option *bond_opt_get(unsigned int option)
-{
-	if (!BOND_OPT_VALID(option))
-		return NULL;
-
-	return &bond_opts[option];
-}
-
-static int bond_option_mode_set(struct bonding *bond,
-				const struct bond_opt_value *newval)
-{
-	if (!bond_mode_uses_arp(newval->value)) {
-		if (bond->params.arp_interval) {
-			netdev_dbg(bond->dev, "%s mode is incompatible with arp monitoring, start mii monitoring\n",
-				   newval->string);
-			/* disable arp monitoring */
-			bond->params.arp_interval = 0;
-		}
-
-		if (!bond->params.miimon) {
-			/* set miimon to default value */
-			bond->params.miimon = BOND_DEFAULT_MIIMON;
-			netdev_dbg(bond->dev, "Setting MII monitoring interval to %d\n",
-				   bond->params.miimon);
-		}
-	}
-
-	if (newval->value == BOND_MODE_ALB)
-		bond->params.tlb_dynamic_lb = 1;
-
-	/* don't cache arp_validate between modes */
-	bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
-	bond->params.mode = newval->value;
-
-	return 0;
-}
-
-static int bond_option_active_slave_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	char ifname[IFNAMSIZ] = { 0, };
-	struct net_device *slave_dev;
-	int ret = 0;
-
-	sscanf(newval->string, "%15s", ifname); /* IFNAMSIZ */
-	if (!strlen(ifname) || newval->string[0] == '\n') {
-		slave_dev = NULL;
-	} else {
-		slave_dev = __dev_get_by_name(dev_net(bond->dev), ifname);
-		if (!slave_dev)
-			return -ENODEV;
-	}
-
-	if (slave_dev) {
-		if (!netif_is_bond_slave(slave_dev)) {
-			slave_err(bond->dev, slave_dev, "Device is not bonding slave\n");
-			return -EINVAL;
-		}
-
-		if (bond->dev != netdev_master_upper_dev_get(slave_dev)) {
-			slave_err(bond->dev, slave_dev, "Device is not our slave\n");
-			return -EINVAL;
-		}
-	}
-
-	block_netpoll_tx();
-	/* check to see if we are clearing active */
-	if (!slave_dev) {
-		netdev_dbg(bond->dev, "Clearing current active slave\n");
-		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
-		bond_select_active_slave(bond);
-	} else {
-		struct slave *old_active = rtnl_dereference(bond->curr_active_slave);
-		struct slave *new_active = bond_slave_get_rtnl(slave_dev);
-
-		BUG_ON(!new_active);
-
-		if (new_active == old_active) {
-			/* do nothing */
-			slave_dbg(bond->dev, new_active->dev, "is already the current active slave\n");
-		} else {
-			if (old_active && (new_active->link == BOND_LINK_UP) &&
-			    bond_slave_is_up(new_active)) {
-				slave_dbg(bond->dev, new_active->dev, "Setting as active slave\n");
-				bond_change_active_slave(bond, new_active);
-			} else {
-				slave_err(bond->dev, new_active->dev, "Could not set as active slave; either %s is down or the link is down\n",
-					  new_active->dev->name);
-				ret = -EINVAL;
-			}
-		}
-	}
-	unblock_netpoll_tx();
-
-	return ret;
-}
-
-/* There are two tricky bits here.  First, if MII monitoring is activated, then
- * we must disable ARP monitoring.  Second, if the timer isn't running, we must
- * start it.
- */
-static int bond_option_miimon_set(struct bonding *bond,
-				  const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting MII monitoring interval to %llu\n",
-		   newval->value);
-	bond->params.miimon = newval->value;
-	if (bond->params.updelay)
-		netdev_dbg(bond->dev, "Note: Updating updelay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.updelay * bond->params.miimon);
-	if (bond->params.downdelay)
-		netdev_dbg(bond->dev, "Note: Updating downdelay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.downdelay * bond->params.miimon);
-	if (bond->params.peer_notif_delay)
-		netdev_dbg(bond->dev, "Note: Updating peer_notif_delay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.peer_notif_delay * bond->params.miimon);
-	if (newval->value && bond->params.arp_interval) {
-		netdev_dbg(bond->dev, "MII monitoring cannot be used with ARP monitoring - disabling ARP monitoring...\n");
-		bond->params.arp_interval = 0;
-		if (bond->params.arp_validate)
-			bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
-	}
-	if (bond->dev->flags & IFF_UP) {
-		/* If the interface is up, we may need to fire off
-		 * the MII timer. If the interface is down, the
-		 * timer will get fired off when the open function
-		 * is called.
-		 */
-		if (!newval->value) {
-			cancel_delayed_work_sync(&bond->mii_work);
-		} else {
-			cancel_delayed_work_sync(&bond->arp_work);
-			queue_delayed_work(bond->wq, &bond->mii_work, 0);
-		}
-	}
-
-	return 0;
-}
-
-/* Set up, down and peer notification delays. These must be multiples
- * of the MII monitoring value, and are stored internally as the
- * multiplier. Thus, we must translate to MS for the real world.
- */
-static int _bond_option_delay_set(struct bonding *bond,
-				  const struct bond_opt_value *newval,
-				  const char *name,
-				  int *target)
-{
-	int value = newval->value;
-
-	if (!bond->params.miimon) {
-		netdev_err(bond->dev, "Unable to set %s as MII monitoring is disabled\n",
-			   name);
-		return -EPERM;
-	}
-	if ((value % bond->params.miimon) != 0) {
-		netdev_warn(bond->dev,
-			    "%s (%d) is not a multiple of miimon (%d), value rounded to %d ms\n",
-			    name,
-			    value, bond->params.miimon,
-			    (value / bond->params.miimon) *
-			    bond->params.miimon);
-	}
-	*target = value / bond->params.miimon;
-	netdev_dbg(bond->dev, "Setting %s to %d\n",
-		   name,
-		   *target * bond->params.miimon);
-
-	return 0;
-}
-
-static int bond_option_updelay_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	return _bond_option_delay_set(bond, newval, "up delay",
-				      &bond->params.updelay);
-}
-
-static int bond_option_downdelay_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	return _bond_option_delay_set(bond, newval, "down delay",
-				      &bond->params.downdelay);
-}
-
-static int bond_option_peer_notif_delay_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	int ret = _bond_option_delay_set(bond, newval,
-					 "peer notification delay",
-					 &bond->params.peer_notif_delay);
-	return ret;
-}
-
-static int bond_option_use_carrier_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting use_carrier to %llu\n",
-		   newval->value);
-	bond->params.use_carrier = newval->value;
-
-	return 0;
-}
-
-/* There are two tricky bits here.  First, if ARP monitoring is activated, then
- * we must disable MII monitoring.  Second, if the ARP timer isn't running,
- * we must start it.
- */
-static int bond_option_arp_interval_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ARP monitoring interval to %llu\n",
-		   newval->value);
-	bond->params.arp_interval = newval->value;
-	if (newval->value) {
-		if (bond->params.miimon) {
-			netdev_dbg(bond->dev, "ARP monitoring cannot be used with MII monitoring. Disabling MII monitoring\n");
-			bond->params.miimon = 0;
-		}
-		if (!bond->params.arp_targets[0])
-			netdev_dbg(bond->dev, "ARP monitoring has been set up, but no ARP targets have been specified\n");
-	}
-	if (bond->dev->flags & IFF_UP) {
-		/* If the interface is up, we may need to fire off
-		 * the ARP timer.  If the interface is down, the
-		 * timer will get fired off when the open function
-		 * is called.
-		 */
-		if (!newval->value) {
-			if (bond->params.arp_validate)
-				bond->recv_probe = NULL;
-			cancel_delayed_work_sync(&bond->arp_work);
-		} else {
-			/* arp_validate can be set only in active-backup mode */
-			bond->recv_probe = bond_arp_rcv;
-			cancel_delayed_work_sync(&bond->mii_work);
-			queue_delayed_work(bond->wq, &bond->arp_work, 0);
-		}
-	}
-
-	return 0;
-}
-
-static void _bond_options_arp_ip_target_set(struct bonding *bond, int slot,
-					    __be32 target,
-					    unsigned long last_rx)
-{
-	__be32 *targets = bond->params.arp_targets;
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (slot >= 0 && slot < BOND_MAX_ARP_TARGETS) {
-		bond_for_each_slave(bond, slave, iter)
-			slave->target_last_arp_rx[slot] = last_rx;
-		targets[slot] = target;
-	}
-}
-
-static int _bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
-{
-	__be32 *targets = bond->params.arp_targets;
-	int ind;
-
-	if (!bond_is_ip_target_ok(target)) {
-		netdev_err(bond->dev, "invalid ARP target %pI4 specified for addition\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	if (bond_get_targets_ip(targets, target) != -1) { /* dup */
-		netdev_err(bond->dev, "ARP target %pI4 is already present\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	ind = bond_get_targets_ip(targets, 0); /* first free slot */
-	if (ind == -1) {
-		netdev_err(bond->dev, "ARP target table is full!\n");
-		return -EINVAL;
-	}
-
-	netdev_dbg(bond->dev, "Adding ARP target %pI4\n", &target);
-
-	_bond_options_arp_ip_target_set(bond, ind, target, jiffies);
-
-	return 0;
-}
-
-static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
-{
-	return _bond_option_arp_ip_target_add(bond, target);
-}
-
-static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target)
-{
-	__be32 *targets = bond->params.arp_targets;
-	struct list_head *iter;
-	struct slave *slave;
-	unsigned long *targets_rx;
-	int ind, i;
-
-	if (!bond_is_ip_target_ok(target)) {
-		netdev_err(bond->dev, "invalid ARP target %pI4 specified for removal\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	ind = bond_get_targets_ip(targets, target);
-	if (ind == -1) {
-		netdev_err(bond->dev, "unable to remove nonexistent ARP target %pI4\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	if (ind == 0 && !targets[1] && bond->params.arp_interval)
-		netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
-
-	netdev_dbg(bond->dev, "Removing ARP target %pI4\n", &target);
-
-	bond_for_each_slave(bond, slave, iter) {
-		targets_rx = slave->target_last_arp_rx;
-		for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
-			targets_rx[i] = targets_rx[i+1];
-		targets_rx[i] = 0;
-	}
-	for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
-		targets[i] = targets[i+1];
-	targets[i] = 0;
-
-	return 0;
-}
-
-void bond_option_arp_ip_targets_clear(struct bonding *bond)
-{
-	int i;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
-		_bond_options_arp_ip_target_set(bond, i, 0, 0);
-}
-
-static int bond_option_arp_ip_targets_set(struct bonding *bond,
-					  const struct bond_opt_value *newval)
-{
-	int ret = -EPERM;
-	__be32 target;
-
-	if (newval->string) {
-		if (!in4_pton(newval->string+1, -1, (u8 *)&target, -1, NULL)) {
-			netdev_err(bond->dev, "invalid ARP target %pI4 specified\n",
-				   &target);
-			return ret;
-		}
-		if (newval->string[0] == '+')
-			ret = bond_option_arp_ip_target_add(bond, target);
-		else if (newval->string[0] == '-')
-			ret = bond_option_arp_ip_target_rem(bond, target);
-		else
-			netdev_err(bond->dev, "no command found in arp_ip_targets file - use +<addr> or -<addr>\n");
-	} else {
-		target = newval->value;
-		ret = bond_option_arp_ip_target_add(bond, target);
-	}
-
-	return ret;
-}
-
-static int bond_option_arp_validate_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting arp_validate to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.arp_validate = newval->value;
-
-	return 0;
-}
-
-static int bond_option_arp_all_targets_set(struct bonding *bond,
-					   const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting arp_all_targets to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.arp_all_targets = newval->value;
-
-	return 0;
-}
-
-static int bond_option_primary_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	char *p, *primary = newval->string;
-	struct list_head *iter;
-	struct slave *slave;
-
-	block_netpoll_tx();
-
-	p = strchr(primary, '\n');
-	if (p)
-		*p = '\0';
-	/* check to see if we are clearing primary */
-	if (!strlen(primary)) {
-		netdev_dbg(bond->dev, "Setting primary slave to None\n");
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-		memset(bond->params.primary, 0, sizeof(bond->params.primary));
-		bond_select_active_slave(bond);
-		goto out;
-	}
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (strncmp(slave->dev->name, primary, IFNAMSIZ) == 0) {
-			slave_dbg(bond->dev, slave->dev, "Setting as primary slave\n");
-			rcu_assign_pointer(bond->primary_slave, slave);
-			strcpy(bond->params.primary, slave->dev->name);
-			bond->force_primary = true;
-			bond_select_active_slave(bond);
-			goto out;
-		}
-	}
-
-	if (rtnl_dereference(bond->primary_slave)) {
-		netdev_dbg(bond->dev, "Setting primary slave to None\n");
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-		bond_select_active_slave(bond);
-	}
-	strncpy(bond->params.primary, primary, IFNAMSIZ);
-	bond->params.primary[IFNAMSIZ - 1] = 0;
-
-	netdev_dbg(bond->dev, "Recording %s as primary, but it has not been enslaved yet\n",
-		   primary);
-
-out:
-	unblock_netpoll_tx();
-
-	return 0;
-}
-
-static int bond_option_primary_reselect_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting primary_reselect to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.primary_reselect = newval->value;
-
-	block_netpoll_tx();
-	bond_select_active_slave(bond);
-	unblock_netpoll_tx();
-
-	return 0;
-}
-
-static int bond_option_fail_over_mac_set(struct bonding *bond,
-					 const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting fail_over_mac to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.fail_over_mac = newval->value;
-
-	return 0;
-}
-
-static int bond_option_xmit_hash_policy_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting xmit hash policy to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.xmit_policy = newval->value;
-
-	return 0;
-}
-
-static int bond_option_resend_igmp_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting resend_igmp to %llu\n",
-		   newval->value);
-	bond->params.resend_igmp = newval->value;
-
-	return 0;
-}
-
-static int bond_option_num_peer_notif_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	bond->params.num_peer_notif = newval->value;
-
-	return 0;
-}
-
-static int bond_option_all_slaves_active_set(struct bonding *bond,
-					     const struct bond_opt_value *newval)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (newval->value == bond->params.all_slaves_active)
-		return 0;
-	bond->params.all_slaves_active = newval->value;
-	bond_for_each_slave(bond, slave, iter) {
-		if (!bond_is_active_slave(slave)) {
-			if (newval->value)
-				slave->inactive = 0;
-			else
-				slave->inactive = 1;
-		}
-	}
-
-	return 0;
-}
-
-static int bond_option_min_links_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting min links value to %llu\n",
-		   newval->value);
-	bond->params.min_links = newval->value;
-	bond_set_carrier(bond);
-
-	return 0;
-}
-
-static int bond_option_lp_interval_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	bond->params.lp_interval = newval->value;
-
-	return 0;
-}
-
-static int bond_option_pps_set(struct bonding *bond,
-			       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting packets per slave to %llu\n",
-		   newval->value);
-	bond->params.packets_per_slave = newval->value;
-	if (newval->value > 0) {
-		bond->params.reciprocal_packets_per_slave =
-			reciprocal_value(newval->value);
-	} else {
-		/* reciprocal_packets_per_slave is unused if
-		 * packets_per_slave is 0 or 1, just initialize it
-		 */
-		bond->params.reciprocal_packets_per_slave =
-			(struct reciprocal_value) { 0 };
-	}
-
-	return 0;
-}
-
-static int bond_option_lacp_rate_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting LACP rate to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.lacp_fast = newval->value;
-	bond_3ad_update_lacp_rate(bond);
-
-	return 0;
-}
-
-static int bond_option_ad_select_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_select to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.ad_select = newval->value;
-
-	return 0;
-}
-
-static int bond_option_queue_id_set(struct bonding *bond,
-				    const struct bond_opt_value *newval)
-{
-	struct slave *slave, *update_slave;
-	struct net_device *sdev;
-	struct list_head *iter;
-	char *delim;
-	int ret = 0;
-	u16 qid;
-
-	/* delim will point to queue id if successful */
-	delim = strchr(newval->string, ':');
-	if (!delim)
-		goto err_no_cmd;
-
-	/* Terminate string that points to device name and bump it
-	 * up one, so we can read the queue id there.
-	 */
-	*delim = '\0';
-	if (sscanf(++delim, "%hd\n", &qid) != 1)
-		goto err_no_cmd;
-
-	/* Check buffer length, valid ifname and queue id */
-	if (!dev_valid_name(newval->string) ||
-	    qid > bond->dev->real_num_tx_queues)
-		goto err_no_cmd;
-
-	/* Get the pointer to that interface if it exists */
-	sdev = __dev_get_by_name(dev_net(bond->dev), newval->string);
-	if (!sdev)
-		goto err_no_cmd;
-
-	/* Search for thes slave and check for duplicate qids */
-	update_slave = NULL;
-	bond_for_each_slave(bond, slave, iter) {
-		if (sdev == slave->dev)
-			/* We don't need to check the matching
-			 * slave for dups, since we're overwriting it
-			 */
-			update_slave = slave;
-		else if (qid && qid == slave->queue_id) {
-			goto err_no_cmd;
-		}
-	}
-
-	if (!update_slave)
-		goto err_no_cmd;
-
-	/* Actually set the qids for the slave */
-	update_slave->queue_id = qid;
-
-out:
-	return ret;
-
-err_no_cmd:
-	netdev_dbg(bond->dev, "invalid input for queue_id set\n");
-	ret = -EPERM;
-	goto out;
-
-}
-
-static int bond_option_slaves_set(struct bonding *bond,
-				  const struct bond_opt_value *newval)
-{
-	char command[IFNAMSIZ + 1] = { 0, };
-	struct net_device *dev;
-	char *ifname;
-	int ret;
-
-	sscanf(newval->string, "%16s", command); /* IFNAMSIZ*/
-	ifname = command + 1;
-	if ((strlen(command) <= 1) ||
-	    (command[0] != '+' && command[0] != '-') ||
-	    !dev_valid_name(ifname))
-		goto err_no_cmd;
-
-	dev = __dev_get_by_name(dev_net(bond->dev), ifname);
-	if (!dev) {
-		netdev_dbg(bond->dev, "interface %s does not exist!\n",
-			   ifname);
-		ret = -ENODEV;
-		goto out;
-	}
-
-	switch (command[0]) {
-	case '+':
-		slave_dbg(bond->dev, dev, "Enslaving interface\n");
-		ret = bond_enslave(bond->dev, dev, NULL);
-		break;
-
-	case '-':
-		slave_dbg(bond->dev, dev, "Releasing interface\n");
-		ret = bond_release(bond->dev, dev);
-		if (!ret)
-			netdev_update_lockdep_key(dev);
-		break;
-
-	default:
-		/* should not run here. */
-		goto err_no_cmd;
-	}
-
-out:
-	return ret;
-
-err_no_cmd:
-	netdev_err(bond->dev, "no command found in slaves file - use +ifname or -ifname\n");
-	ret = -EPERM;
-	goto out;
-}
-
-static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
-					  const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting dynamic-lb to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.tlb_dynamic_lb = newval->value;
-
-	return 0;
-}
-
-static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
-					     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_actor_sys_prio to %llu\n",
-		   newval->value);
-
-	bond->params.ad_actor_sys_prio = newval->value;
-	bond_3ad_update_ad_actor_settings(bond);
-
-	return 0;
-}
-
-static int bond_option_ad_actor_system_set(struct bonding *bond,
-					   const struct bond_opt_value *newval)
-{
-	u8 macaddr[ETH_ALEN];
-	u8 *mac;
-
-	if (newval->string) {
-		if (!mac_pton(newval->string, macaddr))
-			goto err;
-		mac = macaddr;
-	} else {
-		mac = (u8 *)&newval->value;
-	}
-
-	if (!is_valid_ether_addr(mac))
-		goto err;
-
-	netdev_dbg(bond->dev, "Setting ad_actor_system to %pM\n", mac);
-	ether_addr_copy(bond->params.ad_actor_system, mac);
-	bond_3ad_update_ad_actor_settings(bond);
-
-	return 0;
-
-err:
-	netdev_err(bond->dev, "Invalid ad_actor_system MAC address.\n");
-	return -EINVAL;
-}
-
-static int bond_option_ad_user_port_key_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_user_port_key to %llu\n",
-		   newval->value);
-
-	bond->params.ad_user_port_key = newval->value;
-	return 0;
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.82/bond_procfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.82/bond_procfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,312 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-#include <linux/proc_fs.h>
-#include <linux/export.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <net/bonding.h>
-
-#include "bonding_priv.h"
-
-static void *bond_info_seq_start(struct seq_file *seq, loff_t *pos)
-	__acquires(RCU)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	struct list_head *iter;
-	struct slave *slave;
-	loff_t off = 0;
-
-	rcu_read_lock();
-
-	if (*pos == 0)
-		return SEQ_START_TOKEN;
-
-	bond_for_each_slave_rcu(bond, slave, iter)
-		if (++off == *pos)
-			return slave;
-
-	return NULL;
-}
-
-static void *bond_info_seq_next(struct seq_file *seq, void *v, loff_t *pos)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	struct list_head *iter;
-	struct slave *slave;
-	bool found = false;
-
-	++*pos;
-	if (v == SEQ_START_TOKEN)
-		return bond_first_slave_rcu(bond);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (found)
-			return slave;
-		if (slave == v)
-			found = true;
-	}
-
-	return NULL;
-}
-
-static void bond_info_seq_stop(struct seq_file *seq, void *v)
-	__releases(RCU)
-{
-	rcu_read_unlock();
-}
-
-static void bond_info_show_master(struct seq_file *seq)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	const struct bond_opt_value *optval;
-	struct slave *curr, *primary;
-	int i;
-
-	curr = rcu_dereference(bond->curr_active_slave);
-
-	seq_printf(seq, "Bonding Mode: %s",
-		   bond_mode_name(BOND_MODE(bond)));
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
-	    bond->params.fail_over_mac) {
-		optval = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
-					  bond->params.fail_over_mac);
-		seq_printf(seq, " (fail_over_mac %s)", optval->string);
-	}
-
-	seq_printf(seq, "\n");
-
-	if (bond_mode_uses_xmit_hash(bond)) {
-		optval = bond_opt_get_val(BOND_OPT_XMIT_HASH,
-					  bond->params.xmit_policy);
-		seq_printf(seq, "Transmit Hash Policy: %s (%d)\n",
-			   optval->string, bond->params.xmit_policy);
-	}
-
-	if (bond_uses_primary(bond)) {
-		primary = rcu_dereference(bond->primary_slave);
-		seq_printf(seq, "Primary Slave: %s",
-			   primary ? primary->dev->name : "None");
-		if (primary) {
-			optval = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
-						  bond->params.primary_reselect);
-			seq_printf(seq, " (primary_reselect %s)",
-				   optval->string);
-		}
-
-		seq_printf(seq, "\nCurrently Active Slave: %s\n",
-			   (curr) ? curr->dev->name : "None");
-	}
-
-	seq_printf(seq, "MII Status: %s\n", netif_carrier_ok(bond->dev) ?
-		   "up" : "down");
-	seq_printf(seq, "MII Polling Interval (ms): %d\n", bond->params.miimon);
-	seq_printf(seq, "Up Delay (ms): %d\n",
-		   bond->params.updelay * bond->params.miimon);
-	seq_printf(seq, "Down Delay (ms): %d\n",
-		   bond->params.downdelay * bond->params.miimon);
-	seq_printf(seq, "Peer Notification Delay (ms): %d\n",
-		   bond->params.peer_notif_delay * bond->params.miimon);
-
-
-	/* ARP information */
-	if (bond->params.arp_interval > 0) {
-		int printed = 0;
-		seq_printf(seq, "ARP Polling Interval (ms): %d\n",
-				bond->params.arp_interval);
-
-		seq_printf(seq, "ARP IP target/s (n.n.n.n form):");
-
-		for (i = 0; (i < BOND_MAX_ARP_TARGETS); i++) {
-			if (!bond->params.arp_targets[i])
-				break;
-			if (printed)
-				seq_printf(seq, ",");
-			seq_printf(seq, " %pI4", &bond->params.arp_targets[i]);
-			printed = 1;
-		}
-		seq_printf(seq, "\n");
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-
-		seq_puts(seq, "\n802.3ad info\n");
-		seq_printf(seq, "LACP rate: %s\n",
-			   (bond->params.lacp_fast) ? "fast" : "slow");
-		seq_printf(seq, "Min links: %d\n", bond->params.min_links);
-		optval = bond_opt_get_val(BOND_OPT_AD_SELECT,
-					  bond->params.ad_select);
-		seq_printf(seq, "Aggregator selection policy (ad_select): %s\n",
-			   optval->string);
-		if (capable(CAP_NET_ADMIN)) {
-			seq_printf(seq, "System priority: %d\n",
-				   BOND_AD_INFO(bond).system.sys_priority);
-			seq_printf(seq, "System MAC address: %pM\n",
-				   &BOND_AD_INFO(bond).system.sys_mac_addr);
-
-			if (__bond_3ad_get_active_agg_info(bond, &ad_info)) {
-				seq_printf(seq,
-					   "bond %s has no active aggregator\n",
-					   bond->dev->name);
-			} else {
-				seq_printf(seq, "Active Aggregator Info:\n");
-
-				seq_printf(seq, "\tAggregator ID: %d\n",
-					   ad_info.aggregator_id);
-				seq_printf(seq, "\tNumber of ports: %d\n",
-					   ad_info.ports);
-				seq_printf(seq, "\tActor Key: %d\n",
-					   ad_info.actor_key);
-				seq_printf(seq, "\tPartner Key: %d\n",
-					   ad_info.partner_key);
-				seq_printf(seq, "\tPartner Mac Address: %pM\n",
-					   ad_info.partner_system);
-			}
-		}
-	}
-}
-
-static void bond_info_show_slave(struct seq_file *seq,
-				 const struct slave *slave)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-
-	seq_printf(seq, "\nSlave Interface: %s\n", slave->dev->name);
-	seq_printf(seq, "MII Status: %s\n", bond_slave_link_status(slave->link));
-	if (slave->speed == SPEED_UNKNOWN)
-		seq_printf(seq, "Speed: %s\n", "Unknown");
-	else
-		seq_printf(seq, "Speed: %d Mbps\n", slave->speed);
-
-	if (slave->duplex == DUPLEX_UNKNOWN)
-		seq_printf(seq, "Duplex: %s\n", "Unknown");
-	else
-		seq_printf(seq, "Duplex: %s\n", slave->duplex ? "full" : "half");
-
-	seq_printf(seq, "Link Failure Count: %u\n",
-		   slave->link_failure_count);
-
-	seq_printf(seq, "Permanent HW addr: %*phC\n",
-		   slave->dev->addr_len, slave->perm_hwaddr);
-	seq_printf(seq, "Slave queue ID: %d\n", slave->queue_id);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		const struct port *port = &SLAVE_AD_INFO(slave)->port;
-		const struct aggregator *agg = port->aggregator;
-
-		if (agg) {
-			seq_printf(seq, "Aggregator ID: %d\n",
-				   agg->aggregator_identifier);
-			seq_printf(seq, "Actor Churn State: %s\n",
-				   bond_3ad_churn_desc(port->sm_churn_actor_state));
-			seq_printf(seq, "Partner Churn State: %s\n",
-				   bond_3ad_churn_desc(port->sm_churn_partner_state));
-			seq_printf(seq, "Actor Churned Count: %d\n",
-				   port->churn_actor_count);
-			seq_printf(seq, "Partner Churned Count: %d\n",
-				   port->churn_partner_count);
-
-			if (capable(CAP_NET_ADMIN)) {
-				seq_puts(seq, "details actor lacp pdu:\n");
-				seq_printf(seq, "    system priority: %d\n",
-					   port->actor_system_priority);
-				seq_printf(seq, "    system mac address: %pM\n",
-					   &port->actor_system);
-				seq_printf(seq, "    port key: %d\n",
-					   port->actor_oper_port_key);
-				seq_printf(seq, "    port priority: %d\n",
-					   port->actor_port_priority);
-				seq_printf(seq, "    port number: %d\n",
-					   port->actor_port_number);
-				seq_printf(seq, "    port state: %d\n",
-					   port->actor_oper_port_state);
-
-				seq_puts(seq, "details partner lacp pdu:\n");
-				seq_printf(seq, "    system priority: %d\n",
-					   port->partner_oper.system_priority);
-				seq_printf(seq, "    system mac address: %pM\n",
-					   &port->partner_oper.system);
-				seq_printf(seq, "    oper key: %d\n",
-					   port->partner_oper.key);
-				seq_printf(seq, "    port priority: %d\n",
-					   port->partner_oper.port_priority);
-				seq_printf(seq, "    port number: %d\n",
-					   port->partner_oper.port_number);
-				seq_printf(seq, "    port state: %d\n",
-					   port->partner_oper.port_state);
-			}
-		} else {
-			seq_puts(seq, "Aggregator ID: N/A\n");
-		}
-	}
-}
-
-static int bond_info_seq_show(struct seq_file *seq, void *v)
-{
-	if (v == SEQ_START_TOKEN) {
-		seq_printf(seq, "%s\n", bond_version);
-		bond_info_show_master(seq);
-	} else
-		bond_info_show_slave(seq, v);
-
-	return 0;
-}
-
-static const struct seq_operations bond_info_seq_ops = {
-	.start = bond_info_seq_start,
-	.next  = bond_info_seq_next,
-	.stop  = bond_info_seq_stop,
-	.show  = bond_info_seq_show,
-};
-
-void bond_create_proc_entry(struct bonding *bond)
-{
-	struct net_device *bond_dev = bond->dev;
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	if (bn->proc_dir) {
-		bond->proc_entry = proc_create_seq_data(bond_dev->name, 0444,
-				bn->proc_dir, &bond_info_seq_ops, bond);
-		if (bond->proc_entry == NULL)
-			netdev_warn(bond_dev, "Cannot create /proc/net/%s/%s\n",
-				    DRV_NAME, bond_dev->name);
-		else
-			memcpy(bond->proc_file_name, bond_dev->name, IFNAMSIZ);
-	}
-}
-
-void bond_remove_proc_entry(struct bonding *bond)
-{
-	struct net_device *bond_dev = bond->dev;
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	if (bn->proc_dir && bond->proc_entry) {
-		remove_proc_entry(bond->proc_file_name, bn->proc_dir);
-		memset(bond->proc_file_name, 0, IFNAMSIZ);
-		bond->proc_entry = NULL;
-	}
-}
-
-/* Create the bonding directory under /proc/net, if doesn't exist yet.
- * Caller must hold rtnl_lock.
- */
-void __net_init bond_create_proc_dir(struct bond_net *bn)
-{
-	if (!bn->proc_dir) {
-		bn->proc_dir = proc_mkdir(DRV_NAME, bn->net->proc_net);
-		if (!bn->proc_dir)
-			pr_warn("Warning: Cannot create /proc/net/%s\n",
-				DRV_NAME);
-	}
-}
-
-/* Destroy the bonding directory under /proc/net, if empty.
- * Caller must hold rtnl_lock.
- */
-void __net_exit bond_destroy_proc_dir(struct bond_net *bn)
-{
-	if (bn->proc_dir) {
-		remove_proc_entry(DRV_NAME, bn->net->proc_net);
-		bn->proc_dir = NULL;
-	}
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.82/bond_sysfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.82/bond_sysfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,816 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 2004-2005 Intel Corporation. All rights reserved.
- */
-
-#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/device.h>
-#include <linux/sched/signal.h>
-#include <linux/fs.h>
-#include <linux/types.h>
-#include <linux/string.h>
-#include <linux/netdevice.h>
-#include <linux/inetdevice.h>
-#include <linux/in.h>
-#include <linux/sysfs.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/rtnetlink.h>
-#include <linux/etherdevice.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <linux/nsproxy.h>
-
-#include <net/bonding.h>
-
-#define to_bond(cd)	((struct bonding *)(netdev_priv(to_net_dev(cd))))
-
-/* "show" function for the bond_masters attribute.
- * The class parameter is ignored.
- */
-static ssize_t bonding_show_bonds(struct class *cls,
-				  struct class_attribute *attr,
-				  char *buf)
-{
-	struct bond_net *bn =
-		container_of(attr, struct bond_net, class_attr_bonding_masters);
-	int res = 0;
-	struct bonding *bond;
-
-	rtnl_lock();
-
-	list_for_each_entry(bond, &bn->dev_list, bond_list) {
-		if (res > (PAGE_SIZE - IFNAMSIZ)) {
-			/* not enough space for another interface name */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s ", bond->dev->name);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	rtnl_unlock();
-	return res;
-}
-
-static struct net_device *bond_get_by_name(struct bond_net *bn, const char *ifname)
-{
-	struct bonding *bond;
-
-	list_for_each_entry(bond, &bn->dev_list, bond_list) {
-		if (strncmp(bond->dev->name, ifname, IFNAMSIZ) == 0)
-			return bond->dev;
-	}
-	return NULL;
-}
-
-/* "store" function for the bond_masters attribute.  This is what
- * creates and deletes entire bonds.
- *
- * The class parameter is ignored.
- */
-static ssize_t bonding_store_bonds(struct class *cls,
-				   struct class_attribute *attr,
-				   const char *buffer, size_t count)
-{
-	struct bond_net *bn =
-		container_of(attr, struct bond_net, class_attr_bonding_masters);
-	char command[IFNAMSIZ + 1] = {0, };
-	char *ifname;
-	int rv, res = count;
-
-	sscanf(buffer, "%16s", command); /* IFNAMSIZ*/
-	ifname = command + 1;
-	if ((strlen(command) <= 1) ||
-	    !dev_valid_name(ifname))
-		goto err_no_cmd;
-
-	if (command[0] == '+') {
-		pr_info("%s is being created...\n", ifname);
-		rv = bond_create(bn->net, ifname);
-		if (rv) {
-			if (rv == -EEXIST)
-				pr_info("%s already exists\n", ifname);
-			else
-				pr_info("%s creation failed\n", ifname);
-			res = rv;
-		}
-	} else if (command[0] == '-') {
-		struct net_device *bond_dev;
-
-		rtnl_lock();
-		bond_dev = bond_get_by_name(bn, ifname);
-		if (bond_dev) {
-			pr_info("%s is being deleted...\n", ifname);
-			unregister_netdevice(bond_dev);
-		} else {
-			pr_err("unable to delete non-existent %s\n", ifname);
-			res = -ENODEV;
-		}
-		rtnl_unlock();
-	} else
-		goto err_no_cmd;
-
-	/* Always return either count or an error.  If you return 0, you'll
-	 * get called forever, which is bad.
-	 */
-	return res;
-
-err_no_cmd:
-	pr_err("no command found in bonding_masters - use +ifname or -ifname\n");
-	return -EPERM;
-}
-
-/* class attribute for bond_masters file.  This ends up in /sys/class/net */
-static const struct class_attribute class_attr_bonding_masters = {
-	.attr = {
-		.name = "bonding_masters",
-		.mode = 0644,
-	},
-	.show = bonding_show_bonds,
-	.store = bonding_store_bonds,
-};
-
-/* Generic "store" method for bonding sysfs option setting */
-static ssize_t bonding_sysfs_store_option(struct device *d,
-					  struct device_attribute *attr,
-					  const char *buffer, size_t count)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_option *opt;
-	char *buffer_clone;
-	int ret;
-
-	opt = bond_opt_get_by_name(attr->attr.name);
-	if (WARN_ON(!opt))
-		return -ENOENT;
-	buffer_clone = kstrndup(buffer, count, GFP_KERNEL);
-	if (!buffer_clone)
-		return -ENOMEM;
-	ret = bond_opt_tryset_rtnl(bond, opt->id, buffer_clone);
-	if (!ret)
-		ret = count;
-	kfree(buffer_clone);
-
-	return ret;
-}
-
-/* Show the slaves in the current bond. */
-static ssize_t bonding_show_slaves(struct device *d,
-				   struct device_attribute *attr, char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct list_head *iter;
-	struct slave *slave;
-	int res = 0;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (res > (PAGE_SIZE - IFNAMSIZ)) {
-			/* not enough space for another interface name */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s ", slave->dev->name);
-	}
-
-	rtnl_unlock();
-
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	return res;
-}
-static DEVICE_ATTR(slaves, 0644, bonding_show_slaves,
-		   bonding_sysfs_store_option);
-
-/* Show the bonding mode. */
-static ssize_t bonding_show_mode(struct device *d,
-				 struct device_attribute *attr, char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_MODE, BOND_MODE(bond));
-
-	return sprintf(buf, "%s %d\n", val->string, BOND_MODE(bond));
-}
-static DEVICE_ATTR(mode, 0644, bonding_show_mode, bonding_sysfs_store_option);
-
-/* Show the bonding transmit hash method. */
-static ssize_t bonding_show_xmit_hash(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_XMIT_HASH, bond->params.xmit_policy);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.xmit_policy);
-}
-static DEVICE_ATTR(xmit_hash_policy, 0644,
-		   bonding_show_xmit_hash, bonding_sysfs_store_option);
-
-/* Show arp_validate. */
-static ssize_t bonding_show_arp_validate(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
-			       bond->params.arp_validate);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.arp_validate);
-}
-static DEVICE_ATTR(arp_validate, 0644, bonding_show_arp_validate,
-		   bonding_sysfs_store_option);
-
-/* Show arp_all_targets. */
-static ssize_t bonding_show_arp_all_targets(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_ARP_ALL_TARGETS,
-			       bond->params.arp_all_targets);
-	return sprintf(buf, "%s %d\n",
-		       val->string, bond->params.arp_all_targets);
-}
-static DEVICE_ATTR(arp_all_targets, 0644,
-		   bonding_show_arp_all_targets, bonding_sysfs_store_option);
-
-/* Show fail_over_mac. */
-static ssize_t bonding_show_fail_over_mac(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
-			       bond->params.fail_over_mac);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.fail_over_mac);
-}
-static DEVICE_ATTR(fail_over_mac, 0644,
-		   bonding_show_fail_over_mac, bonding_sysfs_store_option);
-
-/* Show the arp timer interval. */
-static ssize_t bonding_show_arp_interval(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.arp_interval);
-}
-static DEVICE_ATTR(arp_interval, 0644,
-		   bonding_show_arp_interval, bonding_sysfs_store_option);
-
-/* Show the arp targets. */
-static ssize_t bonding_show_arp_targets(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	int i, res = 0;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
-		if (bond->params.arp_targets[i])
-			res += sprintf(buf + res, "%pI4 ",
-				       &bond->params.arp_targets[i]);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	return res;
-}
-static DEVICE_ATTR(arp_ip_target, 0644,
-		   bonding_show_arp_targets, bonding_sysfs_store_option);
-
-/* Show the up and down delays. */
-static ssize_t bonding_show_downdelay(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.downdelay * bond->params.miimon);
-}
-static DEVICE_ATTR(downdelay, 0644,
-		   bonding_show_downdelay, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_updelay(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.updelay * bond->params.miimon);
-
-}
-static DEVICE_ATTR(updelay, 0644,
-		   bonding_show_updelay, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_peer_notif_delay(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n",
-		       bond->params.peer_notif_delay * bond->params.miimon);
-}
-static DEVICE_ATTR(peer_notif_delay, 0644,
-		   bonding_show_peer_notif_delay, bonding_sysfs_store_option);
-
-/* Show the LACP interval. */
-static ssize_t bonding_show_lacp(struct device *d,
-				 struct device_attribute *attr,
-				 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_LACP_RATE, bond->params.lacp_fast);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.lacp_fast);
-}
-static DEVICE_ATTR(lacp_rate, 0644,
-		   bonding_show_lacp, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_min_links(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%u\n", bond->params.min_links);
-}
-static DEVICE_ATTR(min_links, 0644,
-		   bonding_show_min_links, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_select(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_AD_SELECT, bond->params.ad_select);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.ad_select);
-}
-static DEVICE_ATTR(ad_select, 0644,
-		   bonding_show_ad_select, bonding_sysfs_store_option);
-
-/* Show the number of peer notifications to send after a failover event. */
-static ssize_t bonding_show_num_peer_notif(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	return sprintf(buf, "%d\n", bond->params.num_peer_notif);
-}
-static DEVICE_ATTR(num_grat_arp, 0644,
-		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
-static DEVICE_ATTR(num_unsol_na, 0644,
-		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
-
-/* Show the MII monitor interval. */
-static ssize_t bonding_show_miimon(struct device *d,
-				   struct device_attribute *attr,
-				   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.miimon);
-}
-static DEVICE_ATTR(miimon, 0644,
-		   bonding_show_miimon, bonding_sysfs_store_option);
-
-/* Show the primary slave. */
-static ssize_t bonding_show_primary(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct slave *primary;
-	int count = 0;
-
-	rcu_read_lock();
-	primary = rcu_dereference(bond->primary_slave);
-	if (primary)
-		count = sprintf(buf, "%s\n", primary->dev->name);
-	rcu_read_unlock();
-
-	return count;
-}
-static DEVICE_ATTR(primary, 0644,
-		   bonding_show_primary, bonding_sysfs_store_option);
-
-/* Show the primary_reselect flag. */
-static ssize_t bonding_show_primary_reselect(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
-			       bond->params.primary_reselect);
-
-	return sprintf(buf, "%s %d\n",
-		       val->string, bond->params.primary_reselect);
-}
-static DEVICE_ATTR(primary_reselect, 0644,
-		   bonding_show_primary_reselect, bonding_sysfs_store_option);
-
-/* Show the use_carrier flag. */
-static ssize_t bonding_show_carrier(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.use_carrier);
-}
-static DEVICE_ATTR(use_carrier, 0644,
-		   bonding_show_carrier, bonding_sysfs_store_option);
-
-
-/* Show currently active_slave. */
-static ssize_t bonding_show_active_slave(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct net_device *slave_dev;
-	int count = 0;
-
-	rcu_read_lock();
-	slave_dev = bond_option_active_slave_get_rcu(bond);
-	if (slave_dev)
-		count = sprintf(buf, "%s\n", slave_dev->name);
-	rcu_read_unlock();
-
-	return count;
-}
-static DEVICE_ATTR(active_slave, 0644,
-		   bonding_show_active_slave, bonding_sysfs_store_option);
-
-/* Show link status of the bond interface. */
-static ssize_t bonding_show_mii_status(struct device *d,
-				       struct device_attribute *attr,
-				       char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	bool active = netif_carrier_ok(bond->dev);
-
-	return sprintf(buf, "%s\n", active ? "up" : "down");
-}
-static DEVICE_ATTR(mii_status, 0444, bonding_show_mii_status, NULL);
-
-/* Show current 802.3ad aggregator ID. */
-static ssize_t bonding_show_ad_aggregator(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.aggregator_id);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_aggregator, 0444, bonding_show_ad_aggregator, NULL);
-
-
-/* Show number of active 802.3ad ports. */
-static ssize_t bonding_show_ad_num_ports(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.ports);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_num_ports, 0444, bonding_show_ad_num_ports, NULL);
-
-
-/* Show current 802.3ad actor key. */
-static ssize_t bonding_show_ad_actor_key(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.actor_key);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_actor_key, 0444, bonding_show_ad_actor_key, NULL);
-
-
-/* Show current 802.3ad partner key. */
-static ssize_t bonding_show_ad_partner_key(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.partner_key);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_partner_key, 0444, bonding_show_ad_partner_key, NULL);
-
-
-/* Show current 802.3ad partner mac. */
-static ssize_t bonding_show_ad_partner_mac(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		if (!bond_3ad_get_active_agg_info(bond, &ad_info))
-			count = sprintf(buf, "%pM\n", ad_info.partner_system);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_partner_mac, 0444, bonding_show_ad_partner_mac, NULL);
-
-/* Show the queue_ids of the slaves in the current bond. */
-static ssize_t bonding_show_queue_id(struct device *d,
-				     struct device_attribute *attr,
-				     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct list_head *iter;
-	struct slave *slave;
-	int res = 0;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (res > (PAGE_SIZE - IFNAMSIZ - 6)) {
-			/* not enough space for another interface_name:queue_id pair */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s:%d ",
-			       slave->dev->name, slave->queue_id);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	rtnl_unlock();
-
-	return res;
-}
-static DEVICE_ATTR(queue_id, 0644, bonding_show_queue_id,
-		   bonding_sysfs_store_option);
-
-
-/* Show the all_slaves_active flag. */
-static ssize_t bonding_show_slaves_active(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.all_slaves_active);
-}
-static DEVICE_ATTR(all_slaves_active, 0644,
-		   bonding_show_slaves_active, bonding_sysfs_store_option);
-
-/* Show the number of IGMP membership reports to send on link failure */
-static ssize_t bonding_show_resend_igmp(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.resend_igmp);
-}
-static DEVICE_ATTR(resend_igmp, 0644,
-		   bonding_show_resend_igmp, bonding_sysfs_store_option);
-
-
-static ssize_t bonding_show_lp_interval(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.lp_interval);
-}
-static DEVICE_ATTR(lp_interval, 0644,
-		   bonding_show_lp_interval, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_tlb_dynamic_lb(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	return sprintf(buf, "%d\n", bond->params.tlb_dynamic_lb);
-}
-static DEVICE_ATTR(tlb_dynamic_lb, 0644,
-		   bonding_show_tlb_dynamic_lb, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_packets_per_slave(struct device *d,
-					      struct device_attribute *attr,
-					      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	unsigned int packets_per_slave = bond->params.packets_per_slave;
-
-	return sprintf(buf, "%u\n", packets_per_slave);
-}
-static DEVICE_ATTR(packets_per_slave, 0644,
-		   bonding_show_packets_per_slave, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_actor_sys_prio(struct device *d,
-					      struct device_attribute *attr,
-					      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%hu\n", bond->params.ad_actor_sys_prio);
-
-	return 0;
-}
-static DEVICE_ATTR(ad_actor_sys_prio, 0644,
-		   bonding_show_ad_actor_sys_prio, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_actor_system(struct device *d,
-					    struct device_attribute *attr,
-					    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%pM\n", bond->params.ad_actor_system);
-
-	return 0;
-}
-
-static DEVICE_ATTR(ad_actor_system, 0644,
-		   bonding_show_ad_actor_system, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_user_port_key(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%hu\n", bond->params.ad_user_port_key);
-
-	return 0;
-}
-static DEVICE_ATTR(ad_user_port_key, 0644,
-		   bonding_show_ad_user_port_key, bonding_sysfs_store_option);
-
-static struct attribute *per_bond_attrs[] = {
-	&dev_attr_slaves.attr,
-	&dev_attr_mode.attr,
-	&dev_attr_fail_over_mac.attr,
-	&dev_attr_arp_validate.attr,
-	&dev_attr_arp_all_targets.attr,
-	&dev_attr_arp_interval.attr,
-	&dev_attr_arp_ip_target.attr,
-	&dev_attr_downdelay.attr,
-	&dev_attr_updelay.attr,
-	&dev_attr_peer_notif_delay.attr,
-	&dev_attr_lacp_rate.attr,
-	&dev_attr_ad_select.attr,
-	&dev_attr_xmit_hash_policy.attr,
-	&dev_attr_num_grat_arp.attr,
-	&dev_attr_num_unsol_na.attr,
-	&dev_attr_miimon.attr,
-	&dev_attr_primary.attr,
-	&dev_attr_primary_reselect.attr,
-	&dev_attr_use_carrier.attr,
-	&dev_attr_active_slave.attr,
-	&dev_attr_mii_status.attr,
-	&dev_attr_ad_aggregator.attr,
-	&dev_attr_ad_num_ports.attr,
-	&dev_attr_ad_actor_key.attr,
-	&dev_attr_ad_partner_key.attr,
-	&dev_attr_ad_partner_mac.attr,
-	&dev_attr_queue_id.attr,
-	&dev_attr_all_slaves_active.attr,
-	&dev_attr_resend_igmp.attr,
-	&dev_attr_min_links.attr,
-	&dev_attr_lp_interval.attr,
-	&dev_attr_packets_per_slave.attr,
-	&dev_attr_tlb_dynamic_lb.attr,
-	&dev_attr_ad_actor_sys_prio.attr,
-	&dev_attr_ad_actor_system.attr,
-	&dev_attr_ad_user_port_key.attr,
-	NULL,
-};
-
-static const struct attribute_group bonding_group = {
-	.name = "bonding",
-	.attrs = per_bond_attrs,
-};
-
-/* Initialize sysfs.  This sets up the bonding_masters file in
- * /sys/class/net.
- */
-int bond_create_sysfs(struct bond_net *bn)
-{
-	int ret;
-
-	bn->class_attr_bonding_masters = class_attr_bonding_masters;
-	sysfs_attr_init(&bn->class_attr_bonding_masters.attr);
-
-	ret = netdev_class_create_file_ns(&bn->class_attr_bonding_masters,
-					  bn->net);
-	/* Permit multiple loads of the module by ignoring failures to
-	 * create the bonding_masters sysfs file.  Bonding devices
-	 * created by second or subsequent loads of the module will
-	 * not be listed in, or controllable by, bonding_masters, but
-	 * will have the usual "bonding" sysfs directory.
-	 *
-	 * This is done to preserve backwards compatibility for
-	 * initscripts/sysconfig, which load bonding multiple times to
-	 * configure multiple bonding devices.
-	 */
-	if (ret == -EEXIST) {
-		/* Is someone being kinky and naming a device bonding_master? */
-		if (__dev_get_by_name(bn->net,
-				      class_attr_bonding_masters.attr.name))
-			pr_err("network device named %s already exists in sysfs\n",
-			       class_attr_bonding_masters.attr.name);
-		ret = 0;
-	}
-
-	return ret;
-
-}
-
-/* Remove /sys/class/net/bonding_masters. */
-void bond_destroy_sysfs(struct bond_net *bn)
-{
-	netdev_class_remove_file_ns(&bn->class_attr_bonding_masters, bn->net);
-}
-
-/* Initialize sysfs for each bond.  This sets up and registers
- * the 'bondctl' directory for each individual bond under /sys/class/net.
- */
-void bond_prepare_sysfs_group(struct bonding *bond)
-{
-	bond->dev->sysfs_groups[0] = &bonding_group;
-}
-
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.82/bond_sysfs_slave.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.82/bond_sysfs_slave.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,160 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*	Sysfs attributes of bond slaves
- *
- *      Copyright (c) 2014 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/capability.h>
-#include <linux/kernel.h>
-#include <linux/netdevice.h>
-
-#include <net/bonding.h>
-
-struct slave_attribute {
-	struct attribute attr;
-	ssize_t (*show)(struct slave *, char *);
-};
-
-#define SLAVE_ATTR(_name, _mode, _show)				\
-const struct slave_attribute slave_attr_##_name = {		\
-	.attr = {.name = __stringify(_name),			\
-		 .mode = _mode },				\
-	.show	= _show,					\
-};
-#define SLAVE_ATTR_RO(_name)					\
-	SLAVE_ATTR(_name, 0444, _name##_show)
-
-static ssize_t state_show(struct slave *slave, char *buf)
-{
-	switch (bond_slave_state(slave)) {
-	case BOND_STATE_ACTIVE:
-		return sprintf(buf, "active\n");
-	case BOND_STATE_BACKUP:
-		return sprintf(buf, "backup\n");
-	default:
-		return sprintf(buf, "UNKNOWN\n");
-	}
-}
-static SLAVE_ATTR_RO(state);
-
-static ssize_t mii_status_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%s\n", bond_slave_link_status(slave->link));
-}
-static SLAVE_ATTR_RO(mii_status);
-
-static ssize_t link_failure_count_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%d\n", slave->link_failure_count);
-}
-static SLAVE_ATTR_RO(link_failure_count);
-
-static ssize_t perm_hwaddr_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%*phC\n",
-		       slave->dev->addr_len,
-		       slave->perm_hwaddr);
-}
-static SLAVE_ATTR_RO(perm_hwaddr);
-
-static ssize_t queue_id_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%d\n", slave->queue_id);
-}
-static SLAVE_ATTR_RO(queue_id);
-
-static ssize_t ad_aggregator_id_show(struct slave *slave, char *buf)
-{
-	const struct aggregator *agg;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		agg = SLAVE_AD_INFO(slave)->port.aggregator;
-		if (agg)
-			return sprintf(buf, "%d\n",
-				       agg->aggregator_identifier);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_aggregator_id);
-
-static ssize_t ad_actor_oper_port_state_show(struct slave *slave, char *buf)
-{
-	const struct port *ad_port;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		if (ad_port->aggregator)
-			return sprintf(buf, "%u\n",
-				       ad_port->actor_oper_port_state);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_actor_oper_port_state);
-
-static ssize_t ad_partner_oper_port_state_show(struct slave *slave, char *buf)
-{
-	const struct port *ad_port;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		if (ad_port->aggregator)
-			return sprintf(buf, "%u\n",
-				       ad_port->partner_oper.port_state);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_partner_oper_port_state);
-
-static const struct slave_attribute *slave_attrs[] = {
-	&slave_attr_state,
-	&slave_attr_mii_status,
-	&slave_attr_link_failure_count,
-	&slave_attr_perm_hwaddr,
-	&slave_attr_queue_id,
-	&slave_attr_ad_aggregator_id,
-	&slave_attr_ad_actor_oper_port_state,
-	&slave_attr_ad_partner_oper_port_state,
-	NULL
-};
-
-#define to_slave_attr(_at) container_of(_at, struct slave_attribute, attr)
-
-static ssize_t slave_show(struct kobject *kobj,
-			  struct attribute *attr, char *buf)
-{
-	struct slave_attribute *slave_attr = to_slave_attr(attr);
-	struct slave *slave = to_slave(kobj);
-
-	return slave_attr->show(slave, buf);
-}
-
-const struct sysfs_ops slave_sysfs_ops = {
-	.show = slave_show,
-};
-
-int bond_sysfs_slave_add(struct slave *slave)
-{
-	const struct slave_attribute **a;
-	int err;
-
-	for (a = slave_attrs; *a; ++a) {
-		err = sysfs_create_file(&slave->kobj, &((*a)->attr));
-		if (err) {
-			kobject_put(&slave->kobj);
-			return err;
-		}
-	}
-
-	return 0;
-}
-
-void bond_sysfs_slave_del(struct slave *slave)
-{
-	const struct slave_attribute **a;
-
-	for (a = slave_attrs; *a; ++a)
-		sysfs_remove_file(&slave->kobj, &((*a)->attr));
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.82/bonding.mod.c
--- a/src/network/bonding/BONDING_KDIRS/5.4.82/bonding.mod.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,213 +0,0 @@
-#include <linux/build-salt.h>
-#include <linux/module.h>
-#include <linux/vermagic.h>
-#include <linux/compiler.h>
-
-BUILD_SALT;
-
-MODULE_INFO(vermagic, VERMAGIC_STRING);
-MODULE_INFO(name, KBUILD_MODNAME);
-
-__visible struct module __this_module
-__section(.gnu.linkonce.this_module) = {
-	.name = KBUILD_MODNAME,
-	.init = init_module,
-#ifdef CONFIG_MODULE_UNLOAD
-	.exit = cleanup_module,
-#endif
-	.arch = MODULE_ARCH_INIT,
-};
-
-MODULE_INFO(intree, "Y");
-
-#ifdef CONFIG_RETPOLINE
-MODULE_INFO(retpoline, "Y");
-#endif
-
-static const struct modversion_info ____versions[]
-__used __section(__versions) = {
-	{ 0x7e6ace96, "module_layout" },
-	{ 0xf88022ca, "register_netdevice" },
-	{ 0x546f3e19, "dev_mc_sync_multiple" },
-	{ 0xe7750f8, "kobject_put" },
-	{ 0xd82d7766, "netdev_info" },
-	{ 0x590c1ccd, "kmalloc_caches" },
-	{ 0xeb233a45, "__kmalloc" },
-	{ 0x2e30512d, "dev_mc_unsync" },
-	{ 0x349cba85, "strchr" },
-	{ 0x19b311bb, "proc_create_seq_private" },
-	{ 0xc65324b7, "param_ops_int" },
-	{ 0xb7536e19, "dev_disable_lro" },
-	{ 0x19f462ab, "kfree_call_rcu" },
-	{ 0xa630db18, "vlan_dev_vlan_id" },
-	{ 0x4efb6e91, "__skb_flow_dissect" },
-	{ 0x79aa04a2, "get_random_bytes" },
-	{ 0x36b1ec50, "seq_puts" },
-	{ 0x52f88ba0, "netdev_rx_handler_register" },
-	{ 0xc7a4fbed, "rtnl_lock" },
-	{ 0xcf4898e9, "vlan_uses_dev" },
-	{ 0xfa690589, "netdev_cmd_to_name" },
-	{ 0xf46f21e7, "netif_carrier_on" },
-	{ 0xa71c50ce, "dst_release" },
-	{ 0xb3635b01, "_raw_spin_lock_bh" },
-	{ 0x203c0969, "skb_clone" },
-	{ 0xffeedf6a, "delayed_work_timer_fn" },
-	{ 0xbc3bdc7f, "flow_get_u32_src" },
-	{ 0xbda21aea, "seq_printf" },
-	{ 0xd2da1048, "register_netdevice_notifier" },
-	{ 0x36d826cf, "netif_carrier_off" },
-	{ 0x56470118, "__warn_printk" },
-	{ 0x2beb619c, "netdev_master_upper_dev_get" },
-	{ 0x412c2c5c, "remove_proc_entry" },
-	{ 0x837b7b09, "__dynamic_pr_debug" },
-	{ 0xdab94385, "dev_set_allmulti" },
-	{ 0xb50a9602, "vlan_vid_del" },
-	{ 0xe017e243, "netpoll_poll_dev" },
-	{ 0xe807b70c, "call_netdevice_notifiers" },
-	{ 0x8890e974, "__dev_kfree_skb_any" },
-	{ 0xc6f46339, "init_timer_key" },
-	{ 0x9fa7184a, "cancel_delayed_work_sync" },
-	{ 0xfe9490f8, "vlan_vid_add" },
-	{ 0x45bfdce4, "__netpoll_setup" },
-	{ 0xa01932a3, "vlan_vids_del_by_dev" },
-	{ 0x3c3ff9fd, "sprintf" },
-	{ 0xae463ca6, "pv_ops" },
-	{ 0xd7ba1111, "netdev_walk_all_upper_dev_rcu" },
-	{ 0x15ba50a6, "jiffies" },
-	{ 0x73380832, "__dynamic_netdev_dbg" },
-	{ 0x9d0d6206, "unregister_netdevice_notifier" },
-	{ 0x21913d59, "skb_trim" },
-	{ 0xe2d5255a, "strcmp" },
-	{ 0x5fd0fdc4, "vlan_vids_add_by_dev" },
-	{ 0xe7da64ec, "netdev_master_upper_dev_link" },
-	{ 0xe900abd2, "dev_mc_add" },
-	{ 0x7375051e, "__netdev_alloc_skb" },
-	{ 0x535f0544, "netdev_lower_get_next_private_rcu" },
-	{ 0x8678ac46, "netdev_lower_state_changed" },
-	{ 0x374258fd, "__pskb_pull_tail" },
-	{ 0x7cd87a06, "netdev_change_features" },
-	{ 0xd4d981e6, "netpoll_send_skb_on_dev" },
-	{ 0x6b10bee1, "_copy_to_user" },
-	{ 0xecb96228, "PDE_DATA" },
-	{ 0x396506fc, "netdev_has_upper_dev" },
-	{ 0xf1db1704, "nla_memcpy" },
-	{ 0xe42bda89, "param_ops_charp" },
-	{ 0xc4ca52be, "dev_set_mac_address" },
-	{ 0xf905d8d5, "unregister_pernet_subsys" },
-	{ 0xdb0c76e7, "proc_mkdir" },
-	{ 0x9fdecc31, "unregister_netdevice_many" },
-	{ 0x11089ac7, "_ctype" },
-	{ 0xc025016c, "flow_keys_dissector" },
-	{ 0x3c31783d, "current_task" },
-	{ 0x63ba09cc, "__ethtool_get_link_ksettings" },
-	{ 0x78dc817e, "arp_create" },
-	{ 0xc5850110, "printk" },
-	{ 0xb2991241, "ethtool_op_get_link" },
-	{ 0xbcab6ee6, "sscanf" },
-	{ 0xe1537255, "__list_del_entry_valid" },
-	{ 0xa965ca81, "reciprocal_value" },
-	{ 0xe0e3cea6, "ns_capable" },
-	{ 0xcccf7597, "kobject_init_and_add" },
-	{ 0x62849ac7, "dev_valid_name" },
-	{ 0x2a152f71, "netdev_class_remove_file_ns" },
-	{ 0x95e9cb12, "free_netdev" },
-	{ 0xe7b00dfb, "__x86_indirect_thunk_r13" },
-	{ 0x9166fada, "strncpy" },
-	{ 0x242436b6, "dev_mc_del" },
-	{ 0xd2c03fac, "nla_put" },
-	{ 0x1103bb5c, "netdev_upper_dev_unlink" },
-	{ 0x5a921311, "strncmp" },
-	{ 0xe8d053f2, "skb_push" },
-	{ 0x652032cb, "mac_pton" },
-	{ 0x8c03d20c, "destroy_workqueue" },
-	{ 0x58297ec2, "dev_close" },
-	{ 0xf4f14de6, "rtnl_trylock" },
-	{ 0x582effeb, "netdev_bonding_info_change" },
-	{ 0xd66609dd, "dev_mc_flush" },
-	{ 0xfda9581f, "prandom_u32" },
-	{ 0x6091797f, "synchronize_rcu" },
-	{ 0x76eb0a27, "inet_confirm_addr" },
-	{ 0xa8a04fea, "init_net" },
-	{ 0x82240ee2, "rtnl_link_unregister" },
-	{ 0xde2db52c, "__dev_get_by_index" },
-	{ 0x68f31cbd, "__list_add_valid" },
-	{ 0x255699f, "netdev_lower_dev_get_private" },
-	{ 0x9eacf8a5, "kstrndup" },
-	{ 0x477d89e5, "dev_open" },
-	{ 0x98f0caf0, "dev_uc_flush" },
-	{ 0xc6cbbc89, "capable" },
-	{ 0xb601be4c, "__x86_indirect_thunk_rdx" },
-	{ 0xa916b694, "strnlen" },
-	{ 0xa45d361d, "netdev_upper_get_next_dev_rcu" },
-	{ 0xb1729dc9, "sysfs_remove_file_ns" },
-	{ 0x49c41a57, "_raw_spin_unlock_bh" },
-	{ 0xb2fcb56d, "queue_delayed_work_on" },
-	{ 0xdecd0b29, "__stack_chk_fail" },
-	{ 0x11a33bd4, "vlan_dev_vlan_proto" },
-	{ 0x8ff86d95, "netdev_rx_handler_unregister" },
-	{ 0x1d24c881, "___ratelimit" },
-	{ 0xb8b9f817, "kmalloc_order_trace" },
-	{ 0x610cca6a, "kfree_skb" },
-	{ 0xac5fcec0, "in4_pton" },
-	{ 0xe94c6909, "passthru_features_check" },
-	{ 0x7b32ffee, "alloc_netdev_mqs" },
-	{ 0x2ea2c95c, "__x86_indirect_thunk_rax" },
-	{ 0x3cf47b77, "arp_xmit" },
-	{ 0x3d1c67b, "netdev_lower_get_next_private" },
-	{ 0x9b39a32e, "register_pernet_subsys" },
-	{ 0x77ef4dee, "pskb_expand_head" },
-	{ 0xbdfb6dbb, "__fentry__" },
-	{ 0x2317cc5e, "netdev_err" },
-	{ 0xcbd4898c, "fortify_panic" },
-	{ 0x97b58a3c, "ether_setup" },
-	{ 0xa8f2fb64, "dev_uc_unsync" },
-	{ 0x3cf03f3c, "__dev_get_by_name" },
-	{ 0x9062e4c1, "kmem_cache_alloc_trace" },
-	{ 0xdbf17652, "_raw_spin_lock" },
-	{ 0xe8c6176b, "unregister_netdevice_queue" },
-	{ 0xe2d4f2f3, "ip_route_output_flow" },
-	{ 0xf6ebc03b, "net_ratelimit" },
-	{ 0x76e299fb, "netdev_warn" },
-	{ 0xb5d23e8a, "__skb_flow_get_ports" },
-	{ 0x7e024733, "dev_set_promiscuity" },
-	{ 0x8516c14a, "flow_get_u32_dst" },
-	{ 0x37a0cba, "kfree" },
-	{ 0x669c6e67, "dev_uc_sync_multiple" },
-	{ 0x69acdf38, "memcpy" },
-	{ 0x99d8a9d8, "param_array_ops" },
-	{ 0x6d013ed2, "dev_trans_start" },
-	{ 0x8d43ffb8, "__dev_set_mtu" },
-	{ 0xf730bbc9, "rtnl_link_register" },
-	{ 0x255a2813, "dev_uc_sync" },
-	{ 0x8c95a9e7, "netdev_lower_get_first_private_rcu" },
-	{ 0xa0dad88e, "netdev_adjacent_get_private" },
-	{ 0x127dcaf3, "nla_put_64bit" },
-	{ 0xc1b22744, "__netpoll_free" },
-	{ 0x656e4a6e, "snprintf" },
-	{ 0xb0e602eb, "memmove" },
-	{ 0x75af9d6a, "consume_skb" },
-	{ 0x85670f1d, "rtnl_is_locked" },
-	{ 0x347572b, "netdev_update_lockdep_key" },
-	{ 0x7f02188f, "__msecs_to_jiffies" },
-	{ 0xfe4641c5, "sysfs_create_file_ns" },
-	{ 0xcf5cf9e0, "dev_queue_xmit" },
-	{ 0xb88869bd, "netdev_is_rx_handler_busy" },
-	{ 0x6a29462, "skb_put" },
-	{ 0x13c49cc2, "_copy_from_user" },
-	{ 0x4b0e4682, "param_ops_uint" },
-	{ 0x6c635754, "skb_copy_bits" },
-	{ 0x5ccca4c8, "dev_mc_sync" },
-	{ 0xdf9208c0, "alloc_workqueue" },
-	{ 0x24a961f2, "dev_pre_changeaddr_notify" },
-	{ 0x6e720ff2, "rtnl_unlock" },
-	{ 0x69668826, "netdev_increment_features" },
-	{ 0x55b495ea, "dev_get_stats" },
-	{ 0xb0077a55, "netdev_class_create_file_ns" },
-	{ 0x3b225adb, "dev_set_mtu" },
-	{ 0xe914e41e, "strcpy" },
-};
-
-MODULE_INFO(depends, "");
-
-
-MODULE_INFO(srcversion, "71D04F15582E5771FDB4D3A");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.4.82/bonding_priv.h
--- a/src/network/bonding/BONDING_KDIRS/5.4.82/bonding_priv.h	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,25 +0,0 @@
-/*
- * Bond several ethernet interfaces into a Cisco, running 'Etherchannel'.
- *
- * Portions are (c) Copyright 1995 Simon "Guru Aleph-Null" Janes
- * NCM: Network and Communications Management, Inc.
- *
- * BUT, I'm the one who modified it for ethernet, so:
- * (c) Copyright 1999, Thomas Davis, tadavis@lbl.gov
- *
- *	This software may be used and distributed according to the terms
- *	of the GNU Public License, incorporated herein by reference.
- *
- */
-
-#ifndef _BONDING_PRIV_H
-#define _BONDING_PRIV_H
-
-#define DRV_VERSION	"3.7.1-chelsio"
-#define DRV_RELDATE	"April 27, 2011"
-#define DRV_NAME	"bonding"
-#define DRV_DESCRIPTION	"Ethernet Channel Bonding Driver with Offload"
-
-#define bond_version DRV_DESCRIPTION ": v" DRV_VERSION " (" DRV_RELDATE ")\n"
-
-#endif
diff -r 30 src/network/bonding/BONDING_KDIRS/5.6.0/bond_3ad.c
--- a/src/network/bonding/BONDING_KDIRS/5.6.0/bond_3ad.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,2757 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
- */
-
-#include <linux/skbuff.h>
-#include <linux/if_ether.h>
-#include <linux/netdevice.h>
-#include <linux/spinlock.h>
-#include <linux/ethtool.h>
-#include <linux/etherdevice.h>
-#include <linux/if_bonding.h>
-#include <linux/pkt_sched.h>
-#include <linux/toedev.h>
-#include <net/net_namespace.h>
-#include <net/bonding.h>
-#include <net/bond_3ad.h>
-#include <net/netlink.h>
-
-/* General definitions */
-#define AD_SHORT_TIMEOUT           1
-#define AD_LONG_TIMEOUT            0
-#define AD_STANDBY                 0x2
-#define AD_MAX_TX_IN_SECOND        3
-#define AD_COLLECTOR_MAX_DELAY     0
-
-/* Timer definitions (43.4.4 in the 802.3ad standard) */
-#define AD_FAST_PERIODIC_TIME      1
-#define AD_SLOW_PERIODIC_TIME      30
-#define AD_SHORT_TIMEOUT_TIME      (3*AD_FAST_PERIODIC_TIME)
-#define AD_LONG_TIMEOUT_TIME       (3*AD_SLOW_PERIODIC_TIME)
-#define AD_CHURN_DETECTION_TIME    60
-#define AD_AGGREGATE_WAIT_TIME     2
-
-/* Port Variables definitions used by the State Machines (43.4.7 in the
- * 802.3ad standard)
- */
-#define AD_PORT_BEGIN           0x1
-#define AD_PORT_LACP_ENABLED    0x2
-#define AD_PORT_ACTOR_CHURN     0x4
-#define AD_PORT_PARTNER_CHURN   0x8
-#define AD_PORT_READY           0x10
-#define AD_PORT_READY_N         0x20
-#define AD_PORT_MATCHED         0x40
-#define AD_PORT_STANDBY         0x80
-#define AD_PORT_SELECTED        0x100
-#define AD_PORT_MOVED           0x200
-#define AD_PORT_CHURNED         (AD_PORT_ACTOR_CHURN | AD_PORT_PARTNER_CHURN)
-
-/* Port Key definitions
- * key is determined according to the link speed, duplex and
- * user key (which is yet not supported)
- *           --------------------------------------------------------------
- * Port key  | User key (10 bits)           | Speed (5 bits)      | Duplex|
- *           --------------------------------------------------------------
- *           |15                           6|5                   1|0
- */
-#define  AD_DUPLEX_KEY_MASKS    0x1
-#define  AD_SPEED_KEY_MASKS     0x3E
-#define  AD_USER_KEY_MASKS      0xFFC0
-
-enum ad_link_speed_type {
-	AD_LINK_SPEED_1MBPS = 1,
-	AD_LINK_SPEED_10MBPS,
-	AD_LINK_SPEED_100MBPS,
-	AD_LINK_SPEED_1000MBPS,
-	AD_LINK_SPEED_2500MBPS,
-	AD_LINK_SPEED_5000MBPS,
-	AD_LINK_SPEED_10000MBPS,
-	AD_LINK_SPEED_14000MBPS,
-	AD_LINK_SPEED_20000MBPS,
-	AD_LINK_SPEED_25000MBPS,
-	AD_LINK_SPEED_40000MBPS,
-	AD_LINK_SPEED_50000MBPS,
-	AD_LINK_SPEED_56000MBPS,
-	AD_LINK_SPEED_100000MBPS,
-};
-
-/* compare MAC addresses */
-#define MAC_ADDRESS_EQUAL(A, B)	\
-	ether_addr_equal_64bits((const u8 *)A, (const u8 *)B)
-
-static const u8 null_mac_addr[ETH_ALEN + 2] __long_aligned = {
-	0, 0, 0, 0, 0, 0
-};
-static u16 ad_ticks_per_sec;
-static const int ad_delta_in_ticks = (AD_TIMER_INTERVAL * HZ) / 1000;
-
-static const u8 lacpdu_mcast_addr[ETH_ALEN + 2] __long_aligned =
-	MULTICAST_LACPDU_ADDR;
-
-/* ================= main 802.3ad protocol functions ================== */
-static int ad_lacpdu_send(struct port *port);
-static int ad_marker_send(struct port *port, struct bond_marker *marker);
-static void ad_mux_machine(struct port *port, bool *update_slave_arr);
-static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port);
-static void ad_tx_machine(struct port *port);
-static void ad_periodic_machine(struct port *port);
-static void ad_port_selection_logic(struct port *port, bool *update_slave_arr);
-static void ad_agg_selection_logic(struct aggregator *aggregator,
-				   bool *update_slave_arr);
-static void ad_clear_agg(struct aggregator *aggregator);
-static void ad_initialize_agg(struct aggregator *aggregator);
-static void ad_initialize_port(struct port *port, int lacp_fast);
-static void ad_enable_collecting_distributing(struct port *port,
-					      bool *update_slave_arr);
-static void ad_disable_collecting_distributing(struct port *port,
-					       bool *update_slave_arr);
-static void ad_marker_info_received(struct bond_marker *marker_info,
-				    struct port *port);
-static void ad_marker_response_received(struct bond_marker *marker,
-					struct port *port);
-static void ad_update_actor_keys(struct port *port, bool reset);
-
-
-/* ================= api to bonding and kernel code ================== */
-
-/**
- * __get_bond_by_port - get the port's bonding struct
- * @port: the port we're looking at
- *
- * Return @port's bonding struct, or %NULL if it can't be found.
- */
-static inline struct bonding *__get_bond_by_port(struct port *port)
-{
-	if (port->slave == NULL)
-		return NULL;
-
-	return bond_get_bond_by_slave(port->slave);
-}
-
-/**
- * __get_first_agg - get the first aggregator in the bond
- * @bond: the bond we're looking at
- *
- * Return the aggregator of the first slave in @bond, or %NULL if it can't be
- * found.
- * The caller must hold RCU or RTNL lock.
- */
-static inline struct aggregator *__get_first_agg(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-	struct slave *first_slave;
-	struct aggregator *agg;
-
-	/* If there's no bond for this port, or bond has no slaves */
-	if (bond == NULL)
-		return NULL;
-
-	rcu_read_lock();
-	first_slave = bond_first_slave_rcu(bond);
-	agg = first_slave ? &(SLAVE_AD_INFO(first_slave)->aggregator) : NULL;
-	rcu_read_unlock();
-
-	return agg;
-}
-
-/**
- * __agg_has_partner - see if we have a partner
- * @agg: the agregator we're looking at
- *
- * Return nonzero if aggregator has a partner (denoted by a non-zero ether
- * address for the partner). Return 0 if not.
- */
-static inline int __agg_has_partner(struct aggregator *agg)
-{
-	return !is_zero_ether_addr(agg->partner_system.mac_addr_value);
-}
-
-/**
- * __disable_port - disable the port's slave
- * @port: the port we're looking at
- */
-static inline void __disable_port(struct port *port)
-{
-	bond_set_slave_inactive_flags(port->slave, BOND_SLAVE_NOTIFY_LATER);
-}
-
-/**
- * __enable_port - enable the port's slave, if it's up
- * @port: the port we're looking at
- */
-static inline void __enable_port(struct port *port)
-{
-	struct slave *slave = port->slave;
-
-	if ((slave->link == BOND_LINK_UP) && bond_slave_is_up(slave)) {
-		bond_set_slave_active_flags(slave, BOND_SLAVE_NOTIFY_LATER);
-		toe_failover(netdev_master_upper_dev_get_rcu(port->slave->dev),
-			     port->slave->dev, TOE_LINK_UP, NULL);
-	}
-}
-
-/**
- * __port_is_enabled - check if the port's slave is in active state
- * @port: the port we're looking at
- */
-static inline int __port_is_enabled(struct port *port)
-{
-	return bond_is_active_slave(port->slave);
-}
-
-/**
- * __get_agg_selection_mode - get the aggregator selection mode
- * @port: the port we're looking at
- *
- * Get the aggregator selection mode. Can be %STABLE, %BANDWIDTH or %COUNT.
- */
-static inline u32 __get_agg_selection_mode(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-
-	if (bond == NULL)
-		return BOND_AD_STABLE;
-
-	return bond->params.ad_select;
-}
-
-/**
- * __check_agg_selection_timer - check if the selection timer has expired
- * @port: the port we're looking at
- */
-static inline int __check_agg_selection_timer(struct port *port)
-{
-	struct bonding *bond = __get_bond_by_port(port);
-
-	if (bond == NULL)
-		return 0;
-
-	return BOND_AD_INFO(bond).agg_select_timer ? 1 : 0;
-}
-
-/**
- * __get_link_speed - get a port's speed
- * @port: the port we're looking at
- *
- * Return @port's speed in 802.3ad enum format. i.e. one of:
- *     0,
- *     %AD_LINK_SPEED_10MBPS,
- *     %AD_LINK_SPEED_100MBPS,
- *     %AD_LINK_SPEED_1000MBPS,
- *     %AD_LINK_SPEED_2500MBPS,
- *     %AD_LINK_SPEED_5000MBPS,
- *     %AD_LINK_SPEED_10000MBPS
- *     %AD_LINK_SPEED_14000MBPS,
- *     %AD_LINK_SPEED_20000MBPS
- *     %AD_LINK_SPEED_25000MBPS
- *     %AD_LINK_SPEED_40000MBPS
- *     %AD_LINK_SPEED_50000MBPS
- *     %AD_LINK_SPEED_56000MBPS
- *     %AD_LINK_SPEED_100000MBPS
- */
-static u16 __get_link_speed(struct port *port)
-{
-	struct slave *slave = port->slave;
-	u16 speed;
-
-	/* this if covers only a special case: when the configuration starts
-	 * with link down, it sets the speed to 0.
-	 * This is done in spite of the fact that the e100 driver reports 0
-	 * to be compatible with MVT in the future.
-	 */
-	if (slave->link != BOND_LINK_UP)
-		speed = 0;
-	else {
-		switch (slave->speed) {
-		case SPEED_10:
-			speed = AD_LINK_SPEED_10MBPS;
-			break;
-
-		case SPEED_100:
-			speed = AD_LINK_SPEED_100MBPS;
-			break;
-
-		case SPEED_1000:
-			speed = AD_LINK_SPEED_1000MBPS;
-			break;
-
-		case SPEED_2500:
-			speed = AD_LINK_SPEED_2500MBPS;
-			break;
-
-		case SPEED_5000:
-			speed = AD_LINK_SPEED_5000MBPS;
-			break;
-
-		case SPEED_10000:
-			speed = AD_LINK_SPEED_10000MBPS;
-			break;
-
-		case SPEED_14000:
-			speed = AD_LINK_SPEED_14000MBPS;
-			break;
-
-		case SPEED_20000:
-			speed = AD_LINK_SPEED_20000MBPS;
-			break;
-
-		case SPEED_25000:
-			speed = AD_LINK_SPEED_25000MBPS;
-			break;
-
-		case SPEED_40000:
-			speed = AD_LINK_SPEED_40000MBPS;
-			break;
-
-		case SPEED_50000:
-			speed = AD_LINK_SPEED_50000MBPS;
-			break;
-
-		case SPEED_56000:
-			speed = AD_LINK_SPEED_56000MBPS;
-			break;
-
-		case SPEED_100000:
-			speed = AD_LINK_SPEED_100000MBPS;
-			break;
-
-		default:
-			/* unknown speed value from ethtool. shouldn't happen */
-			if (slave->speed != SPEED_UNKNOWN)
-				pr_warn_once("%s: (slave %s): unknown ethtool speed (%d) for port %d (set it to 0)\n",
-					     slave->bond->dev->name,
-					     slave->dev->name, slave->speed,
-					     port->actor_port_number);
-			speed = 0;
-			break;
-		}
-	}
-
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d Received link speed %d update from adapter\n",
-		  port->actor_port_number, speed);
-	return speed;
-}
-
-/**
- * __get_duplex - get a port's duplex
- * @port: the port we're looking at
- *
- * Return @port's duplex in 802.3ad bitmask format. i.e.:
- *     0x01 if in full duplex
- *     0x00 otherwise
- */
-static u8 __get_duplex(struct port *port)
-{
-	struct slave *slave = port->slave;
-	u8 retval = 0x0;
-
-	/* handling a special case: when the configuration starts with
-	 * link down, it sets the duplex to 0.
-	 */
-	if (slave->link == BOND_LINK_UP) {
-		switch (slave->duplex) {
-		case DUPLEX_FULL:
-			retval = 0x1;
-			slave_dbg(slave->bond->dev, slave->dev, "Port %d Received status full duplex update from adapter\n",
-				  port->actor_port_number);
-			break;
-		case DUPLEX_HALF:
-		default:
-			retval = 0x0;
-			slave_dbg(slave->bond->dev, slave->dev, "Port %d Received status NOT full duplex update from adapter\n",
-				  port->actor_port_number);
-			break;
-		}
-	}
-	return retval;
-}
-
-static void __ad_actor_update_port(struct port *port)
-{
-	const struct bonding *bond = bond_get_bond_by_slave(port->slave);
-
-	port->actor_system = BOND_AD_INFO(bond).system.sys_mac_addr;
-	port->actor_system_priority = BOND_AD_INFO(bond).system.sys_priority;
-}
-
-/* Conversions */
-
-/**
- * __ad_timer_to_ticks - convert a given timer type to AD module ticks
- * @timer_type:	which timer to operate
- * @par: timer parameter. see below
- *
- * If @timer_type is %current_while_timer, @par indicates long/short timer.
- * If @timer_type is %periodic_timer, @par is one of %FAST_PERIODIC_TIME,
- *						     %SLOW_PERIODIC_TIME.
- */
-static u16 __ad_timer_to_ticks(u16 timer_type, u16 par)
-{
-	u16 retval = 0; /* to silence the compiler */
-
-	switch (timer_type) {
-	case AD_CURRENT_WHILE_TIMER:	/* for rx machine usage */
-		if (par)
-			retval = (AD_SHORT_TIMEOUT_TIME*ad_ticks_per_sec);
-		else
-			retval = (AD_LONG_TIMEOUT_TIME*ad_ticks_per_sec);
-		break;
-	case AD_ACTOR_CHURN_TIMER:	/* for local churn machine */
-		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
-		break;
-	case AD_PERIODIC_TIMER:		/* for periodic machine */
-		retval = (par*ad_ticks_per_sec); /* long timeout */
-		break;
-	case AD_PARTNER_CHURN_TIMER:	/* for remote churn machine */
-		retval = (AD_CHURN_DETECTION_TIME*ad_ticks_per_sec);
-		break;
-	case AD_WAIT_WHILE_TIMER:	/* for selection machine */
-		retval = (AD_AGGREGATE_WAIT_TIME*ad_ticks_per_sec);
-		break;
-	}
-
-	return retval;
-}
-
-
-/* ================= ad_rx_machine helper functions ================== */
-
-/**
- * __choose_matched - update a port's matched variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Update the value of the matched variable, using parameter values from a
- * newly received lacpdu. Parameter values for the partner carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the actor. Matched is set to TRUE if all of these parameters
- * match and the PDU parameter partner_state.aggregation has the same value as
- * actor_oper_port_state.aggregation and lacp will actively maintain the link
- * in the aggregation. Matched is also set to TRUE if the value of
- * actor_state.aggregation in the received PDU is set to FALSE, i.e., indicates
- * an individual link and lacp will actively maintain the link. Otherwise,
- * matched is set to FALSE. LACP is considered to be actively maintaining the
- * link if either the PDU's actor_state.lacp_activity variable is TRUE or both
- * the actor's actor_oper_port_state.lacp_activity and the PDU's
- * partner_state.lacp_activity variables are TRUE.
- *
- * Note: the AD_PORT_MATCHED "variable" is not specified by 802.3ad; it is
- * used here to implement the language from 802.3ad 43.4.9 that requires
- * recordPDU to "match" the LACPDU parameters to the stored values.
- */
-static void __choose_matched(struct lacpdu *lacpdu, struct port *port)
-{
-	/* check if all parameters are alike
-	 * or this is individual link(aggregation == FALSE)
-	 * then update the state machine Matched variable.
-	 */
-	if (((ntohs(lacpdu->partner_port) == port->actor_port_number) &&
-	     (ntohs(lacpdu->partner_port_priority) == port->actor_port_priority) &&
-	     MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) &&
-	     (ntohs(lacpdu->partner_system_priority) == port->actor_system_priority) &&
-	     (ntohs(lacpdu->partner_key) == port->actor_oper_port_key) &&
-	     ((lacpdu->partner_state & LACP_STATE_AGGREGATION) == (port->actor_oper_port_state & LACP_STATE_AGGREGATION))) ||
-	    ((lacpdu->actor_state & LACP_STATE_AGGREGATION) == 0)
-		) {
-		port->sm_vars |= AD_PORT_MATCHED;
-	} else {
-		port->sm_vars &= ~AD_PORT_MATCHED;
-	}
-}
-
-/**
- * __record_pdu - record parameters from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Record the parameter values for the Actor carried in a received lacpdu as
- * the current partner operational parameter values and sets
- * actor_oper_port_state.defaulted to FALSE.
- */
-static void __record_pdu(struct lacpdu *lacpdu, struct port *port)
-{
-	if (lacpdu && port) {
-		struct port_params *partner = &port->partner_oper;
-
-		__choose_matched(lacpdu, port);
-		/* record the new parameter values for the partner
-		 * operational
-		 */
-		partner->port_number = ntohs(lacpdu->actor_port);
-		partner->port_priority = ntohs(lacpdu->actor_port_priority);
-		partner->system = lacpdu->actor_system;
-		partner->system_priority = ntohs(lacpdu->actor_system_priority);
-		partner->key = ntohs(lacpdu->actor_key);
-		partner->port_state = lacpdu->actor_state;
-
-		/* set actor_oper_port_state.defaulted to FALSE */
-		port->actor_oper_port_state &= ~LACP_STATE_DEFAULTED;
-
-		/* set the partner sync. to on if the partner is sync,
-		 * and the port is matched
-		 */
-		if ((port->sm_vars & AD_PORT_MATCHED) &&
-		    (lacpdu->actor_state & LACP_STATE_SYNCHRONIZATION)) {
-			partner->port_state |= LACP_STATE_SYNCHRONIZATION;
-			slave_dbg(port->slave->bond->dev, port->slave->dev,
-				  "partner sync=1\n");
-		} else {
-			partner->port_state &= ~LACP_STATE_SYNCHRONIZATION;
-			slave_dbg(port->slave->bond->dev, port->slave->dev,
-				  "partner sync=0\n");
-		}
-	}
-}
-
-/**
- * __record_default - record default parameters
- * @port: the port we're looking at
- *
- * This function records the default parameter values for the partner carried
- * in the Partner Admin parameters as the current partner operational parameter
- * values and sets actor_oper_port_state.defaulted to TRUE.
- */
-static void __record_default(struct port *port)
-{
-	if (port) {
-		/* record the partner admin parameters */
-		memcpy(&port->partner_oper, &port->partner_admin,
-		       sizeof(struct port_params));
-
-		/* set actor_oper_port_state.defaulted to true */
-		port->actor_oper_port_state |= LACP_STATE_DEFAULTED;
-	}
-}
-
-/**
- * __update_selected - update a port's Selected variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Update the value of the selected variable, using parameter values from a
- * newly received lacpdu. The parameter values for the Actor carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the ports partner. If one or more of the comparisons shows that
- * the value(s) received in the PDU differ from the current operational values,
- * then selected is set to FALSE and actor_oper_port_state.synchronization is
- * set to out_of_sync. Otherwise, selected remains unchanged.
- */
-static void __update_selected(struct lacpdu *lacpdu, struct port *port)
-{
-	if (lacpdu && port) {
-		const struct port_params *partner = &port->partner_oper;
-
-		/* check if any parameter is different then
-		 * update the state machine selected variable.
-		 */
-		if (ntohs(lacpdu->actor_port) != partner->port_number ||
-		    ntohs(lacpdu->actor_port_priority) != partner->port_priority ||
-		    !MAC_ADDRESS_EQUAL(&lacpdu->actor_system, &partner->system) ||
-		    ntohs(lacpdu->actor_system_priority) != partner->system_priority ||
-		    ntohs(lacpdu->actor_key) != partner->key ||
-		    (lacpdu->actor_state & LACP_STATE_AGGREGATION) != (partner->port_state & LACP_STATE_AGGREGATION)) {
-			port->sm_vars &= ~AD_PORT_SELECTED;
-		}
-	}
-}
-
-/**
- * __update_default_selected - update a port's Selected variable from Partner
- * @port: the port we're looking at
- *
- * This function updates the value of the selected variable, using the partner
- * administrative parameter values. The administrative values are compared with
- * the corresponding operational parameter values for the partner. If one or
- * more of the comparisons shows that the administrative value(s) differ from
- * the current operational values, then Selected is set to FALSE and
- * actor_oper_port_state.synchronization is set to OUT_OF_SYNC. Otherwise,
- * Selected remains unchanged.
- */
-static void __update_default_selected(struct port *port)
-{
-	if (port) {
-		const struct port_params *admin = &port->partner_admin;
-		const struct port_params *oper = &port->partner_oper;
-
-		/* check if any parameter is different then
-		 * update the state machine selected variable.
-		 */
-		if (admin->port_number != oper->port_number ||
-		    admin->port_priority != oper->port_priority ||
-		    !MAC_ADDRESS_EQUAL(&admin->system, &oper->system) ||
-		    admin->system_priority != oper->system_priority ||
-		    admin->key != oper->key ||
-		    (admin->port_state & LACP_STATE_AGGREGATION)
-			!= (oper->port_state & LACP_STATE_AGGREGATION)) {
-			port->sm_vars &= ~AD_PORT_SELECTED;
-		}
-	}
-}
-
-/**
- * __update_ntt - update a port's ntt variable from a received lacpdu
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * Updates the value of the ntt variable, using parameter values from a newly
- * received lacpdu. The parameter values for the partner carried in the
- * received PDU are compared with the corresponding operational parameter
- * values for the Actor. If one or more of the comparisons shows that the
- * value(s) received in the PDU differ from the current operational values,
- * then ntt is set to TRUE. Otherwise, ntt remains unchanged.
- */
-static void __update_ntt(struct lacpdu *lacpdu, struct port *port)
-{
-	/* validate lacpdu and port */
-	if (lacpdu && port) {
-		/* check if any parameter is different then
-		 * update the port->ntt.
-		 */
-		if ((ntohs(lacpdu->partner_port) != port->actor_port_number) ||
-		    (ntohs(lacpdu->partner_port_priority) != port->actor_port_priority) ||
-		    !MAC_ADDRESS_EQUAL(&(lacpdu->partner_system), &(port->actor_system)) ||
-		    (ntohs(lacpdu->partner_system_priority) != port->actor_system_priority) ||
-		    (ntohs(lacpdu->partner_key) != port->actor_oper_port_key) ||
-		    ((lacpdu->partner_state & LACP_STATE_LACP_ACTIVITY) != (port->actor_oper_port_state & LACP_STATE_LACP_ACTIVITY)) ||
-		    ((lacpdu->partner_state & LACP_STATE_LACP_TIMEOUT) != (port->actor_oper_port_state & LACP_STATE_LACP_TIMEOUT)) ||
-		    ((lacpdu->partner_state & LACP_STATE_SYNCHRONIZATION) != (port->actor_oper_port_state & LACP_STATE_SYNCHRONIZATION)) ||
-		    ((lacpdu->partner_state & LACP_STATE_AGGREGATION) != (port->actor_oper_port_state & LACP_STATE_AGGREGATION))
-		   ) {
-			port->ntt = true;
-		}
-	}
-}
-
-/**
- * __agg_ports_are_ready - check if all ports in an aggregator are ready
- * @aggregator: the aggregator we're looking at
- *
- */
-static int __agg_ports_are_ready(struct aggregator *aggregator)
-{
-	struct port *port;
-	int retval = 1;
-
-	if (aggregator) {
-		/* scan all ports in this aggregator to verfy if they are
-		 * all ready.
-		 */
-		for (port = aggregator->lag_ports;
-		     port;
-		     port = port->next_port_in_aggregator) {
-			if (!(port->sm_vars & AD_PORT_READY_N)) {
-				retval = 0;
-				break;
-			}
-		}
-	}
-
-	return retval;
-}
-
-/**
- * __set_agg_ports_ready - set value of Ready bit in all ports of an aggregator
- * @aggregator: the aggregator we're looking at
- * @val: Should the ports' ready bit be set on or off
- *
- */
-static void __set_agg_ports_ready(struct aggregator *aggregator, int val)
-{
-	struct port *port;
-
-	for (port = aggregator->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (val)
-			port->sm_vars |= AD_PORT_READY;
-		else
-			port->sm_vars &= ~AD_PORT_READY;
-	}
-}
-
-static int __agg_active_ports(struct aggregator *agg)
-{
-	struct port *port;
-	int active = 0;
-
-	for (port = agg->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (port->is_enabled)
-			active++;
-	}
-
-	return active;
-}
-
-/**
- * __get_agg_bandwidth - get the total bandwidth of an aggregator
- * @aggregator: the aggregator we're looking at
- *
- */
-static u32 __get_agg_bandwidth(struct aggregator *aggregator)
-{
-	int nports = __agg_active_ports(aggregator);
-	u32 bandwidth = 0;
-
-	if (nports) {
-		switch (__get_link_speed(aggregator->lag_ports)) {
-		case AD_LINK_SPEED_1MBPS:
-			bandwidth = nports;
-			break;
-		case AD_LINK_SPEED_10MBPS:
-			bandwidth = nports * 10;
-			break;
-		case AD_LINK_SPEED_100MBPS:
-			bandwidth = nports * 100;
-			break;
-		case AD_LINK_SPEED_1000MBPS:
-			bandwidth = nports * 1000;
-			break;
-		case AD_LINK_SPEED_2500MBPS:
-			bandwidth = nports * 2500;
-			break;
-		case AD_LINK_SPEED_5000MBPS:
-			bandwidth = nports * 5000;
-			break;
-		case AD_LINK_SPEED_10000MBPS:
-			bandwidth = nports * 10000;
-			break;
-		case AD_LINK_SPEED_14000MBPS:
-			bandwidth = nports * 14000;
-			break;
-		case AD_LINK_SPEED_20000MBPS:
-			bandwidth = nports * 20000;
-			break;
-		case AD_LINK_SPEED_25000MBPS:
-			bandwidth = nports * 25000;
-			break;
-		case AD_LINK_SPEED_40000MBPS:
-			bandwidth = nports * 40000;
-			break;
-		case AD_LINK_SPEED_50000MBPS:
-			bandwidth = nports * 50000;
-			break;
-		case AD_LINK_SPEED_56000MBPS:
-			bandwidth = nports * 56000;
-			break;
-		case AD_LINK_SPEED_100000MBPS:
-			bandwidth = nports * 100000;
-			break;
-		default:
-			bandwidth = 0; /* to silence the compiler */
-		}
-	}
-	return bandwidth;
-}
-
-/**
- * __get_active_agg - get the current active aggregator
- * @aggregator: the aggregator we're looking at
- *
- * Caller must hold RCU lock.
- */
-static struct aggregator *__get_active_agg(struct aggregator *aggregator)
-{
-	struct bonding *bond = aggregator->slave->bond;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave_rcu(bond, slave, iter)
-		if (SLAVE_AD_INFO(slave)->aggregator.is_active)
-			return &(SLAVE_AD_INFO(slave)->aggregator);
-
-	return NULL;
-}
-
-/**
- * __update_lacpdu_from_port - update a port's lacpdu fields
- * @port: the port we're looking at
- */
-static inline void __update_lacpdu_from_port(struct port *port)
-{
-	struct lacpdu *lacpdu = &port->lacpdu;
-	const struct port_params *partner = &port->partner_oper;
-
-	/* update current actual Actor parameters
-	 * lacpdu->subtype                   initialized
-	 * lacpdu->version_number            initialized
-	 * lacpdu->tlv_type_actor_info       initialized
-	 * lacpdu->actor_information_length  initialized
-	 */
-
-	lacpdu->actor_system_priority = htons(port->actor_system_priority);
-	lacpdu->actor_system = port->actor_system;
-	lacpdu->actor_key = htons(port->actor_oper_port_key);
-	lacpdu->actor_port_priority = htons(port->actor_port_priority);
-	lacpdu->actor_port = htons(port->actor_port_number);
-	lacpdu->actor_state = port->actor_oper_port_state;
-	slave_dbg(port->slave->bond->dev, port->slave->dev,
-		  "update lacpdu: actor port state %x\n",
-		  port->actor_oper_port_state);
-
-	/* lacpdu->reserved_3_1              initialized
-	 * lacpdu->tlv_type_partner_info     initialized
-	 * lacpdu->partner_information_length initialized
-	 */
-
-	lacpdu->partner_system_priority = htons(partner->system_priority);
-	lacpdu->partner_system = partner->system;
-	lacpdu->partner_key = htons(partner->key);
-	lacpdu->partner_port_priority = htons(partner->port_priority);
-	lacpdu->partner_port = htons(partner->port_number);
-	lacpdu->partner_state = partner->port_state;
-
-	/* lacpdu->reserved_3_2              initialized
-	 * lacpdu->tlv_type_collector_info   initialized
-	 * lacpdu->collector_information_length initialized
-	 * collector_max_delay                initialized
-	 * reserved_12[12]                   initialized
-	 * tlv_type_terminator               initialized
-	 * terminator_length                 initialized
-	 * reserved_50[50]                   initialized
-	 */
-}
-
-/* ================= main 802.3ad protocol code ========================= */
-
-/**
- * ad_lacpdu_send - send out a lacpdu packet on a given port
- * @port: the port we're looking at
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-static int ad_lacpdu_send(struct port *port)
-{
-	struct slave *slave = port->slave;
-	struct sk_buff *skb;
-	struct lacpdu_header *lacpdu_header;
-	int length = sizeof(struct lacpdu_header);
-
-	skb = dev_alloc_skb(length);
-	if (!skb)
-		return -ENOMEM;
-
-	atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_tx);
-	atomic64_inc(&BOND_AD_INFO(slave->bond).stats.lacpdu_tx);
-
-	skb->dev = slave->dev;
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = PKT_TYPE_LACPDU;
-	skb->priority = TC_PRIO_CONTROL;
-
-	lacpdu_header = skb_put(skb, length);
-
-	ether_addr_copy(lacpdu_header->hdr.h_dest, lacpdu_mcast_addr);
-	/* Note: source address is set to be the member's PERMANENT address,
-	 * because we use it to identify loopback lacpdus in receive.
-	 */
-	ether_addr_copy(lacpdu_header->hdr.h_source, slave->perm_hwaddr);
-	lacpdu_header->hdr.h_proto = PKT_TYPE_LACPDU;
-
-	lacpdu_header->lacpdu = port->lacpdu;
-
-	dev_queue_xmit(skb);
-
-	return 0;
-}
-
-/**
- * ad_marker_send - send marker information/response on a given port
- * @port: the port we're looking at
- * @marker: marker data to send
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-static int ad_marker_send(struct port *port, struct bond_marker *marker)
-{
-	struct slave *slave = port->slave;
-	struct sk_buff *skb;
-	struct bond_marker_header *marker_header;
-	int length = sizeof(struct bond_marker_header);
-
-	skb = dev_alloc_skb(length + 16);
-	if (!skb)
-		return -ENOMEM;
-
-	switch (marker->tlv_type) {
-	case AD_MARKER_INFORMATION_SUBTYPE:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.marker_tx);
-		atomic64_inc(&BOND_AD_INFO(slave->bond).stats.marker_tx);
-		break;
-	case AD_MARKER_RESPONSE_SUBTYPE:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.marker_resp_tx);
-		atomic64_inc(&BOND_AD_INFO(slave->bond).stats.marker_resp_tx);
-		break;
-	}
-
-	skb_reserve(skb, 16);
-
-	skb->dev = slave->dev;
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = PKT_TYPE_LACPDU;
-
-	marker_header = skb_put(skb, length);
-
-	ether_addr_copy(marker_header->hdr.h_dest, lacpdu_mcast_addr);
-	/* Note: source address is set to be the member's PERMANENT address,
-	 * because we use it to identify loopback MARKERs in receive.
-	 */
-	ether_addr_copy(marker_header->hdr.h_source, slave->perm_hwaddr);
-	marker_header->hdr.h_proto = PKT_TYPE_LACPDU;
-
-	marker_header->marker = *marker;
-
-	dev_queue_xmit(skb);
-
-	return 0;
-}
-
-/**
- * ad_mux_machine - handle a port's mux state machine
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- */
-static void ad_mux_machine(struct port *port, bool *update_slave_arr)
-{
-	mux_states_t last_state;
-
-	/* keep current State Machine state to compare later if it was
-	 * changed
-	 */
-	last_state = port->sm_mux_state;
-
-	if (port->sm_vars & AD_PORT_BEGIN) {
-		port->sm_mux_state = AD_MUX_DETACHED;
-	} else {
-		switch (port->sm_mux_state) {
-		case AD_MUX_DETACHED:
-			if ((port->sm_vars & AD_PORT_SELECTED)
-			    || (port->sm_vars & AD_PORT_STANDBY))
-				/* if SELECTED or STANDBY */
-				port->sm_mux_state = AD_MUX_WAITING;
-			break;
-		case AD_MUX_WAITING:
-			/* if SELECTED == FALSE return to DETACH state */
-			if (!(port->sm_vars & AD_PORT_SELECTED)) {
-				port->sm_vars &= ~AD_PORT_READY_N;
-				/* in order to withhold the Selection Logic to
-				 * check all ports READY_N value every callback
-				 * cycle to update ready variable, we check
-				 * READY_N and update READY here
-				 */
-				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-				port->sm_mux_state = AD_MUX_DETACHED;
-				break;
-			}
-
-			/* check if the wait_while_timer expired */
-			if (port->sm_mux_timer_counter
-			    && !(--port->sm_mux_timer_counter))
-				port->sm_vars |= AD_PORT_READY_N;
-
-			/* in order to withhold the selection logic to check
-			 * all ports READY_N value every callback cycle to
-			 * update ready variable, we check READY_N and update
-			 * READY here
-			 */
-			__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-
-			/* if the wait_while_timer expired, and the port is
-			 * in READY state, move to ATTACHED state
-			 */
-			if ((port->sm_vars & AD_PORT_READY)
-			    && !port->sm_mux_timer_counter)
-				port->sm_mux_state = AD_MUX_ATTACHED;
-			break;
-		case AD_MUX_ATTACHED:
-			/* check also if agg_select_timer expired (so the
-			 * edable port will take place only after this timer)
-			 */
-			if ((port->sm_vars & AD_PORT_SELECTED) &&
-			    (port->partner_oper.port_state & LACP_STATE_SYNCHRONIZATION) &&
-			    !__check_agg_selection_timer(port)) {
-				if (port->aggregator->is_active)
-					port->sm_mux_state =
-					    AD_MUX_COLLECTING_DISTRIBUTING;
-			} else if (!(port->sm_vars & AD_PORT_SELECTED) ||
-				   (port->sm_vars & AD_PORT_STANDBY)) {
-				/* if UNSELECTED or STANDBY */
-				port->sm_vars &= ~AD_PORT_READY_N;
-				/* in order to withhold the selection logic to
-				 * check all ports READY_N value every callback
-				 * cycle to update ready variable, we check
-				 * READY_N and update READY here
-				 */
-				__set_agg_ports_ready(port->aggregator, __agg_ports_are_ready(port->aggregator));
-				port->sm_mux_state = AD_MUX_DETACHED;
-			} else if (port->aggregator->is_active) {
-				port->actor_oper_port_state |=
-				    LACP_STATE_SYNCHRONIZATION;
-			}
-			break;
-		case AD_MUX_COLLECTING_DISTRIBUTING:
-			if (!(port->sm_vars & AD_PORT_SELECTED) ||
-			    (port->sm_vars & AD_PORT_STANDBY) ||
-			    !(port->partner_oper.port_state & LACP_STATE_SYNCHRONIZATION) ||
-			    !(port->actor_oper_port_state & LACP_STATE_SYNCHRONIZATION)) {
-				port->sm_mux_state = AD_MUX_ATTACHED;
-			} else {
-				/* if port state hasn't changed make
-				 * sure that a collecting distributing
-				 * port in an active aggregator is enabled
-				 */
-				if (port->aggregator &&
-				    port->aggregator->is_active &&
-				    !__port_is_enabled(port)) {
-
-					__enable_port(port);
-				}
-			}
-			break;
-		default:
-			break;
-		}
-	}
-
-	/* check if the state machine was changed */
-	if (port->sm_mux_state != last_state) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Mux Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number,
-			  last_state,
-			  port->sm_mux_state);
-		switch (port->sm_mux_state) {
-		case AD_MUX_DETACHED:
-			port->actor_oper_port_state &= ~LACP_STATE_SYNCHRONIZATION;
-			ad_disable_collecting_distributing(port,
-							   update_slave_arr);
-			port->actor_oper_port_state &= ~LACP_STATE_COLLECTING;
-			port->actor_oper_port_state &= ~LACP_STATE_DISTRIBUTING;
-			port->ntt = true;
-			break;
-		case AD_MUX_WAITING:
-			port->sm_mux_timer_counter = __ad_timer_to_ticks(AD_WAIT_WHILE_TIMER, 0);
-			break;
-		case AD_MUX_ATTACHED:
-			if (port->aggregator->is_active)
-				port->actor_oper_port_state |=
-				    LACP_STATE_SYNCHRONIZATION;
-			else
-				port->actor_oper_port_state &=
-				    ~LACP_STATE_SYNCHRONIZATION;
-			port->actor_oper_port_state &= ~LACP_STATE_COLLECTING;
-			port->actor_oper_port_state &= ~LACP_STATE_DISTRIBUTING;
-			ad_disable_collecting_distributing(port,
-							   update_slave_arr);
-			port->ntt = true;
-			break;
-		case AD_MUX_COLLECTING_DISTRIBUTING:
-			port->actor_oper_port_state |= LACP_STATE_COLLECTING;
-			port->actor_oper_port_state |= LACP_STATE_DISTRIBUTING;
-			port->actor_oper_port_state |= LACP_STATE_SYNCHRONIZATION;
-			ad_enable_collecting_distributing(port,
-							  update_slave_arr);
-			port->ntt = true;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_rx_machine - handle a port's rx State Machine
- * @lacpdu: the lacpdu we've received
- * @port: the port we're looking at
- *
- * If lacpdu arrived, stop previous timer (if exists) and set the next state as
- * CURRENT. If timer expired set the state machine in the proper state.
- * In other cases, this function checks if we need to switch to other state.
- */
-static void ad_rx_machine(struct lacpdu *lacpdu, struct port *port)
-{
-	rx_states_t last_state;
-
-	/* keep current State Machine state to compare later if it was
-	 * changed
-	 */
-	last_state = port->sm_rx_state;
-
-	if (lacpdu) {
-		atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.lacpdu_rx);
-		atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.lacpdu_rx);
-	}
-	/* check if state machine should change state */
-
-	/* first, check if port was reinitialized */
-	if (port->sm_vars & AD_PORT_BEGIN) {
-		port->sm_rx_state = AD_RX_INITIALIZE;
-		port->sm_vars |= AD_PORT_CHURNED;
-	/* check if port is not enabled */
-	} else if (!(port->sm_vars & AD_PORT_BEGIN) && !port->is_enabled)
-		port->sm_rx_state = AD_RX_PORT_DISABLED;
-	/* check if new lacpdu arrived */
-	else if (lacpdu && ((port->sm_rx_state == AD_RX_EXPIRED) ||
-		 (port->sm_rx_state == AD_RX_DEFAULTED) ||
-		 (port->sm_rx_state == AD_RX_CURRENT))) {
-		if (port->sm_rx_state != AD_RX_CURRENT)
-			port->sm_vars |= AD_PORT_CHURNED;
-		port->sm_rx_timer_counter = 0;
-		port->sm_rx_state = AD_RX_CURRENT;
-	} else {
-		/* if timer is on, and if it is expired */
-		if (port->sm_rx_timer_counter &&
-		    !(--port->sm_rx_timer_counter)) {
-			switch (port->sm_rx_state) {
-			case AD_RX_EXPIRED:
-				port->sm_rx_state = AD_RX_DEFAULTED;
-				break;
-			case AD_RX_CURRENT:
-				port->sm_rx_state = AD_RX_EXPIRED;
-				break;
-			default:
-				break;
-			}
-		} else {
-			/* if no lacpdu arrived and no timer is on */
-			switch (port->sm_rx_state) {
-			case AD_RX_PORT_DISABLED:
-				if (port->is_enabled &&
-				    (port->sm_vars & AD_PORT_LACP_ENABLED))
-					port->sm_rx_state = AD_RX_EXPIRED;
-				else if (port->is_enabled
-					 && ((port->sm_vars
-					      & AD_PORT_LACP_ENABLED) == 0))
-					port->sm_rx_state = AD_RX_LACP_DISABLED;
-				break;
-			default:
-				break;
-
-			}
-		}
-	}
-
-	/* check if the State machine was changed or new lacpdu arrived */
-	if ((port->sm_rx_state != last_state) || (lacpdu)) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Rx Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number,
-			  last_state,
-			  port->sm_rx_state);
-		switch (port->sm_rx_state) {
-		case AD_RX_INITIALIZE:
-			if (!(port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS))
-				port->sm_vars &= ~AD_PORT_LACP_ENABLED;
-			else
-				port->sm_vars |= AD_PORT_LACP_ENABLED;
-			port->sm_vars &= ~AD_PORT_SELECTED;
-			__record_default(port);
-			port->actor_oper_port_state &= ~LACP_STATE_EXPIRED;
-			port->sm_rx_state = AD_RX_PORT_DISABLED;
-
-			/* Fall Through */
-		case AD_RX_PORT_DISABLED:
-			port->sm_vars &= ~AD_PORT_MATCHED;
-			break;
-		case AD_RX_LACP_DISABLED:
-			port->sm_vars &= ~AD_PORT_SELECTED;
-			__record_default(port);
-			port->partner_oper.port_state &= ~LACP_STATE_AGGREGATION;
-			port->sm_vars |= AD_PORT_MATCHED;
-			port->actor_oper_port_state &= ~LACP_STATE_EXPIRED;
-			break;
-		case AD_RX_EXPIRED:
-			/* Reset of the Synchronization flag (Standard 43.4.12)
-			 * This reset cause to disable this port in the
-			 * COLLECTING_DISTRIBUTING state of the mux machine in
-			 * case of EXPIRED even if LINK_DOWN didn't arrive for
-			 * the port.
-			 */
-			port->partner_oper.port_state &= ~LACP_STATE_SYNCHRONIZATION;
-			port->sm_vars &= ~AD_PORT_MATCHED;
-			port->partner_oper.port_state |= LACP_STATE_LACP_TIMEOUT;
-			port->partner_oper.port_state |= LACP_STATE_LACP_ACTIVITY;
-			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(AD_SHORT_TIMEOUT));
-			port->actor_oper_port_state |= LACP_STATE_EXPIRED;
-			port->sm_vars |= AD_PORT_CHURNED;
-			break;
-		case AD_RX_DEFAULTED:
-			__update_default_selected(port);
-			__record_default(port);
-			port->sm_vars |= AD_PORT_MATCHED;
-			port->actor_oper_port_state &= ~LACP_STATE_EXPIRED;
-			break;
-		case AD_RX_CURRENT:
-			/* detect loopback situation */
-			if (MAC_ADDRESS_EQUAL(&(lacpdu->actor_system),
-					      &(port->actor_system))) {
-				slave_err(port->slave->bond->dev, port->slave->dev, "An illegal loopback occurred on slave\n"
-					  "Check the configuration to verify that all adapters are connected to 802.3ad compliant switch ports\n");
-				return;
-			}
-			__update_selected(lacpdu, port);
-			__update_ntt(lacpdu, port);
-			__record_pdu(lacpdu, port);
-			port->sm_rx_timer_counter = __ad_timer_to_ticks(AD_CURRENT_WHILE_TIMER, (u16)(port->actor_oper_port_state & LACP_STATE_LACP_TIMEOUT));
-			port->actor_oper_port_state &= ~LACP_STATE_EXPIRED;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_churn_machine - handle port churn's state machine
- * @port: the port we're looking at
- *
- */
-static void ad_churn_machine(struct port *port)
-{
-	if (port->sm_vars & AD_PORT_CHURNED) {
-		port->sm_vars &= ~AD_PORT_CHURNED;
-		port->sm_churn_actor_state = AD_CHURN_MONITOR;
-		port->sm_churn_partner_state = AD_CHURN_MONITOR;
-		port->sm_churn_actor_timer_counter =
-			__ad_timer_to_ticks(AD_ACTOR_CHURN_TIMER, 0);
-		port->sm_churn_partner_timer_counter =
-			 __ad_timer_to_ticks(AD_PARTNER_CHURN_TIMER, 0);
-		return;
-	}
-	if (port->sm_churn_actor_timer_counter &&
-	    !(--port->sm_churn_actor_timer_counter) &&
-	    port->sm_churn_actor_state == AD_CHURN_MONITOR) {
-		if (port->actor_oper_port_state & LACP_STATE_SYNCHRONIZATION) {
-			port->sm_churn_actor_state = AD_NO_CHURN;
-		} else {
-			port->churn_actor_count++;
-			port->sm_churn_actor_state = AD_CHURN;
-		}
-	}
-	if (port->sm_churn_partner_timer_counter &&
-	    !(--port->sm_churn_partner_timer_counter) &&
-	    port->sm_churn_partner_state == AD_CHURN_MONITOR) {
-		if (port->partner_oper.port_state & LACP_STATE_SYNCHRONIZATION) {
-			port->sm_churn_partner_state = AD_NO_CHURN;
-		} else {
-			port->churn_partner_count++;
-			port->sm_churn_partner_state = AD_CHURN;
-		}
-	}
-}
-
-/**
- * ad_tx_machine - handle a port's tx state machine
- * @port: the port we're looking at
- */
-static void ad_tx_machine(struct port *port)
-{
-	/* check if tx timer expired, to verify that we do not send more than
-	 * 3 packets per second
-	 */
-	if (port->sm_tx_timer_counter && !(--port->sm_tx_timer_counter)) {
-		/* check if there is something to send */
-		if (port->ntt && (port->sm_vars & AD_PORT_LACP_ENABLED)) {
-			__update_lacpdu_from_port(port);
-
-			if (ad_lacpdu_send(port) >= 0) {
-				slave_dbg(port->slave->bond->dev,
-					  port->slave->dev,
-					  "Sent LACPDU on port %d\n",
-					  port->actor_port_number);
-
-				/* mark ntt as false, so it will not be sent
-				 * again until demanded
-				 */
-				port->ntt = false;
-			}
-		}
-		/* restart tx timer(to verify that we will not exceed
-		 * AD_MAX_TX_IN_SECOND
-		 */
-		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
-	}
-}
-
-/**
- * ad_periodic_machine - handle a port's periodic state machine
- * @port: the port we're looking at
- *
- * Turn ntt flag on priodically to perform periodic transmission of lacpdu's.
- */
-static void ad_periodic_machine(struct port *port)
-{
-	periodic_states_t last_state;
-
-	/* keep current state machine state to compare later if it was changed */
-	last_state = port->sm_periodic_state;
-
-	/* check if port was reinitialized */
-	if (((port->sm_vars & AD_PORT_BEGIN) || !(port->sm_vars & AD_PORT_LACP_ENABLED) || !port->is_enabled) ||
-	    (!(port->actor_oper_port_state & LACP_STATE_LACP_ACTIVITY) && !(port->partner_oper.port_state & LACP_STATE_LACP_ACTIVITY))
-	   ) {
-		port->sm_periodic_state = AD_NO_PERIODIC;
-	}
-	/* check if state machine should change state */
-	else if (port->sm_periodic_timer_counter) {
-		/* check if periodic state machine expired */
-		if (!(--port->sm_periodic_timer_counter)) {
-			/* if expired then do tx */
-			port->sm_periodic_state = AD_PERIODIC_TX;
-		} else {
-			/* If not expired, check if there is some new timeout
-			 * parameter from the partner state
-			 */
-			switch (port->sm_periodic_state) {
-			case AD_FAST_PERIODIC:
-				if (!(port->partner_oper.port_state
-				      & LACP_STATE_LACP_TIMEOUT))
-					port->sm_periodic_state = AD_SLOW_PERIODIC;
-				break;
-			case AD_SLOW_PERIODIC:
-				if ((port->partner_oper.port_state & LACP_STATE_LACP_TIMEOUT)) {
-					port->sm_periodic_timer_counter = 0;
-					port->sm_periodic_state = AD_PERIODIC_TX;
-				}
-				break;
-			default:
-				break;
-			}
-		}
-	} else {
-		switch (port->sm_periodic_state) {
-		case AD_NO_PERIODIC:
-			port->sm_periodic_state = AD_FAST_PERIODIC;
-			break;
-		case AD_PERIODIC_TX:
-			if (!(port->partner_oper.port_state &
-			    LACP_STATE_LACP_TIMEOUT))
-				port->sm_periodic_state = AD_SLOW_PERIODIC;
-			else
-				port->sm_periodic_state = AD_FAST_PERIODIC;
-			break;
-		default:
-			break;
-		}
-	}
-
-	/* check if the state machine was changed */
-	if (port->sm_periodic_state != last_state) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Periodic Machine: Port=%d, Last State=%d, Curr State=%d\n",
-			  port->actor_port_number, last_state,
-			  port->sm_periodic_state);
-		switch (port->sm_periodic_state) {
-		case AD_NO_PERIODIC:
-			port->sm_periodic_timer_counter = 0;
-			break;
-		case AD_FAST_PERIODIC:
-			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
-			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_FAST_PERIODIC_TIME))-1;
-			break;
-		case AD_SLOW_PERIODIC:
-			/* decrement 1 tick we lost in the PERIODIC_TX cycle */
-			port->sm_periodic_timer_counter = __ad_timer_to_ticks(AD_PERIODIC_TIMER, (u16)(AD_SLOW_PERIODIC_TIME))-1;
-			break;
-		case AD_PERIODIC_TX:
-			port->ntt = true;
-			break;
-		default:
-			break;
-		}
-	}
-}
-
-/**
- * ad_port_selection_logic - select aggregation groups
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * Select aggregation groups, and assign each port for it's aggregetor. The
- * selection logic is called in the inititalization (after all the handshkes),
- * and after every lacpdu receive (if selected is off).
- */
-static void ad_port_selection_logic(struct port *port, bool *update_slave_arr)
-{
-	struct aggregator *aggregator, *free_aggregator = NULL, *temp_aggregator;
-	struct port *last_port = NULL, *curr_port;
-	struct list_head *iter;
-	struct bonding *bond;
-	struct slave *slave;
-	int found = 0;
-
-	/* if the port is already Selected, do nothing */
-	if (port->sm_vars & AD_PORT_SELECTED)
-		return;
-
-	bond = __get_bond_by_port(port);
-
-	/* if the port is connected to other aggregator, detach it */
-	if (port->aggregator) {
-		/* detach the port from its former aggregator */
-		temp_aggregator = port->aggregator;
-		for (curr_port = temp_aggregator->lag_ports; curr_port;
-		     last_port = curr_port,
-		     curr_port = curr_port->next_port_in_aggregator) {
-			if (curr_port == port) {
-				temp_aggregator->num_of_ports--;
-				/* if it is the first port attached to the
-				 * aggregator
-				 */
-				if (!last_port) {
-					temp_aggregator->lag_ports =
-						port->next_port_in_aggregator;
-				} else {
-					/* not the first port attached to the
-					 * aggregator
-					 */
-					last_port->next_port_in_aggregator =
-						port->next_port_in_aggregator;
-				}
-
-				/* clear the port's relations to this
-				 * aggregator
-				 */
-				port->aggregator = NULL;
-				port->next_port_in_aggregator = NULL;
-				port->actor_port_aggregator_identifier = 0;
-
-				slave_dbg(bond->dev, port->slave->dev, "Port %d left LAG %d\n",
-					  port->actor_port_number,
-					  temp_aggregator->aggregator_identifier);
-				/* if the aggregator is empty, clear its
-				 * parameters, and set it ready to be attached
-				 */
-				if (!temp_aggregator->lag_ports)
-					ad_clear_agg(temp_aggregator);
-				break;
-			}
-		}
-		if (!curr_port) {
-			/* meaning: the port was related to an aggregator
-			 * but was not on the aggregator port list
-			 */
-			net_warn_ratelimited("%s: (slave %s): Warning: Port %d was related to aggregator %d but was not on its port list\n",
-					     port->slave->bond->dev->name,
-					     port->slave->dev->name,
-					     port->actor_port_number,
-					     port->aggregator->aggregator_identifier);
-		}
-	}
-	/* search on all aggregators for a suitable aggregator for this port */
-	bond_for_each_slave(bond, slave, iter) {
-		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		/* keep a free aggregator for later use(if needed) */
-		if (!aggregator->lag_ports) {
-			if (!free_aggregator)
-				free_aggregator = aggregator;
-			continue;
-		}
-		/* check if current aggregator suits us */
-		if (((aggregator->actor_oper_aggregator_key == port->actor_oper_port_key) && /* if all parameters match AND */
-		     MAC_ADDRESS_EQUAL(&(aggregator->partner_system), &(port->partner_oper.system)) &&
-		     (aggregator->partner_system_priority == port->partner_oper.system_priority) &&
-		     (aggregator->partner_oper_aggregator_key == port->partner_oper.key)
-		    ) &&
-		    ((!MAC_ADDRESS_EQUAL(&(port->partner_oper.system), &(null_mac_addr)) && /* partner answers */
-		      !aggregator->is_individual)  /* but is not individual OR */
-		    )
-		   ) {
-			/* attach to the founded aggregator */
-			port->aggregator = aggregator;
-			port->actor_port_aggregator_identifier =
-				port->aggregator->aggregator_identifier;
-			port->next_port_in_aggregator = aggregator->lag_ports;
-			port->aggregator->num_of_ports++;
-			aggregator->lag_ports = port;
-			slave_dbg(bond->dev, slave->dev, "Port %d joined LAG %d (existing LAG)\n",
-				  port->actor_port_number,
-				  port->aggregator->aggregator_identifier);
-
-			/* mark this port as selected */
-			port->sm_vars |= AD_PORT_SELECTED;
-			found = 1;
-			break;
-		}
-	}
-
-	/* the port couldn't find an aggregator - attach it to a new
-	 * aggregator
-	 */
-	if (!found) {
-		if (free_aggregator) {
-			/* assign port a new aggregator */
-			port->aggregator = free_aggregator;
-			port->actor_port_aggregator_identifier =
-				port->aggregator->aggregator_identifier;
-
-			/* update the new aggregator's parameters
-			 * if port was responsed from the end-user
-			 */
-			if (port->actor_oper_port_key & AD_DUPLEX_KEY_MASKS)
-				/* if port is full duplex */
-				port->aggregator->is_individual = false;
-			else
-				port->aggregator->is_individual = true;
-
-			port->aggregator->actor_admin_aggregator_key =
-				port->actor_admin_port_key;
-			port->aggregator->actor_oper_aggregator_key =
-				port->actor_oper_port_key;
-			port->aggregator->partner_system =
-				port->partner_oper.system;
-			port->aggregator->partner_system_priority =
-				port->partner_oper.system_priority;
-			port->aggregator->partner_oper_aggregator_key = port->partner_oper.key;
-			port->aggregator->receive_state = 1;
-			port->aggregator->transmit_state = 1;
-			port->aggregator->lag_ports = port;
-			port->aggregator->num_of_ports++;
-
-			/* mark this port as selected */
-			port->sm_vars |= AD_PORT_SELECTED;
-
-			slave_dbg(bond->dev, port->slave->dev, "Port %d joined LAG %d (new LAG)\n",
-				  port->actor_port_number,
-				  port->aggregator->aggregator_identifier);
-		} else {
-			slave_err(bond->dev, port->slave->dev,
-				  "Port %d did not find a suitable aggregator\n",
-				  port->actor_port_number);
-		}
-	}
-	/* if all aggregator's ports are READY_N == TRUE, set ready=TRUE
-	 * in all aggregator's ports, else set ready=FALSE in all
-	 * aggregator's ports
-	 */
-	__set_agg_ports_ready(port->aggregator,
-			      __agg_ports_are_ready(port->aggregator));
-
-	aggregator = __get_first_agg(port);
-	ad_agg_selection_logic(aggregator, update_slave_arr);
-
-	if (!port->aggregator->is_active)
-		port->actor_oper_port_state &= ~LACP_STATE_SYNCHRONIZATION;
-}
-
-/* Decide if "agg" is a better choice for the new active aggregator that
- * the current best, according to the ad_select policy.
- */
-static struct aggregator *ad_agg_selection_test(struct aggregator *best,
-						struct aggregator *curr)
-{
-	/* 0. If no best, select current.
-	 *
-	 * 1. If the current agg is not individual, and the best is
-	 *    individual, select current.
-	 *
-	 * 2. If current agg is individual and the best is not, keep best.
-	 *
-	 * 3. Therefore, current and best are both individual or both not
-	 *    individual, so:
-	 *
-	 * 3a. If current agg partner replied, and best agg partner did not,
-	 *     select current.
-	 *
-	 * 3b. If current agg partner did not reply and best agg partner
-	 *     did reply, keep best.
-	 *
-	 * 4.  Therefore, current and best both have partner replies or
-	 *     both do not, so perform selection policy:
-	 *
-	 * BOND_AD_COUNT: Select by count of ports.  If count is equal,
-	 *     select by bandwidth.
-	 *
-	 * BOND_AD_STABLE, BOND_AD_BANDWIDTH: Select by bandwidth.
-	 */
-	if (!best)
-		return curr;
-
-	if (!curr->is_individual && best->is_individual)
-		return curr;
-
-	if (curr->is_individual && !best->is_individual)
-		return best;
-
-	if (__agg_has_partner(curr) && !__agg_has_partner(best))
-		return curr;
-
-	if (!__agg_has_partner(curr) && __agg_has_partner(best))
-		return best;
-
-	switch (__get_agg_selection_mode(curr->lag_ports)) {
-	case BOND_AD_COUNT:
-		if (__agg_active_ports(curr) > __agg_active_ports(best))
-			return curr;
-
-		if (__agg_active_ports(curr) < __agg_active_ports(best))
-			return best;
-
-		/*FALLTHROUGH*/
-	case BOND_AD_STABLE:
-	case BOND_AD_BANDWIDTH:
-		if (__get_agg_bandwidth(curr) > __get_agg_bandwidth(best))
-			return curr;
-
-		break;
-
-	default:
-		net_warn_ratelimited("%s: (slave %s): Impossible agg select mode %d\n",
-				     curr->slave->bond->dev->name,
-				     curr->slave->dev->name,
-				     __get_agg_selection_mode(curr->lag_ports));
-		break;
-	}
-
-	return best;
-}
-
-static int agg_device_up(const struct aggregator *agg)
-{
-	struct port *port = agg->lag_ports;
-
-	if (!port)
-		return 0;
-
-	for (port = agg->lag_ports; port;
-	     port = port->next_port_in_aggregator) {
-		if (netif_running(port->slave->dev) &&
-		    netif_carrier_ok(port->slave->dev))
-			return 1;
-	}
-
-	return 0;
-}
-
-/**
- * ad_agg_selection_logic - select an aggregation group for a team
- * @aggregator: the aggregator we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * It is assumed that only one aggregator may be selected for a team.
- *
- * The logic of this function is to select the aggregator according to
- * the ad_select policy:
- *
- * BOND_AD_STABLE: select the aggregator with the most ports attached to
- * it, and to reselect the active aggregator only if the previous
- * aggregator has no more ports related to it.
- *
- * BOND_AD_BANDWIDTH: select the aggregator with the highest total
- * bandwidth, and reselect whenever a link state change takes place or the
- * set of slaves in the bond changes.
- *
- * BOND_AD_COUNT: select the aggregator with largest number of ports
- * (slaves), and reselect whenever a link state change takes place or the
- * set of slaves in the bond changes.
- *
- * FIXME: this function MUST be called with the first agg in the bond, or
- * __get_active_agg() won't work correctly. This function should be better
- * called with the bond itself, and retrieve the first agg from it.
- */
-static void ad_agg_selection_logic(struct aggregator *agg,
-				   bool *update_slave_arr)
-{
-	struct aggregator *best, *active, *origin;
-	struct bonding *bond = agg->slave->bond;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-
-	rcu_read_lock();
-	origin = agg;
-	active = __get_active_agg(agg);
-	best = (active && agg_device_up(active)) ? active : NULL;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		agg = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		agg->is_active = 0;
-
-		if (__agg_active_ports(agg) && agg_device_up(agg))
-			best = ad_agg_selection_test(best, agg);
-	}
-
-	if (best &&
-	    __get_agg_selection_mode(best->lag_ports) == BOND_AD_STABLE) {
-		/* For the STABLE policy, don't replace the old active
-		 * aggregator if it's still active (it has an answering
-		 * partner) or if both the best and active don't have an
-		 * answering partner.
-		 */
-		if (active && active->lag_ports &&
-		    __agg_active_ports(active) &&
-		    (__agg_has_partner(active) ||
-		     (!__agg_has_partner(active) &&
-		     !__agg_has_partner(best)))) {
-			if (!(!active->actor_oper_aggregator_key &&
-			      best->actor_oper_aggregator_key)) {
-				best = NULL;
-				active->is_active = 1;
-			}
-		}
-	}
-
-	if (best && (best == active)) {
-		best = NULL;
-		active->is_active = 1;
-	}
-
-	/* if there is new best aggregator, activate it */
-	if (best) {
-		netdev_dbg(bond->dev, "(slave %s): best Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier, best->num_of_ports,
-			   best->actor_oper_aggregator_key,
-			   best->partner_oper_aggregator_key,
-			   best->is_individual, best->is_active);
-		netdev_dbg(bond->dev, "(slave %s): best ports %p slave %p\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->lag_ports, best->slave);
-
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			agg = &(SLAVE_AD_INFO(slave)->aggregator);
-
-			slave_dbg(bond->dev, slave->dev, "Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-				  agg->aggregator_identifier, agg->num_of_ports,
-				  agg->actor_oper_aggregator_key,
-				  agg->partner_oper_aggregator_key,
-				  agg->is_individual, agg->is_active);
-		}
-
-		/* check if any partner replies */
-		if (best->is_individual)
-			net_warn_ratelimited("%s: Warning: No 802.3ad response from the link partner for any adapters in the bond\n",
-					     bond->dev->name);
-
-		best->is_active = 1;
-		netdev_dbg(bond->dev, "(slave %s): LAG %d chosen as the active LAG\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier);
-		netdev_dbg(bond->dev, "(slave %s): Agg=%d; P=%d; a k=%d; p k=%d; Ind=%d; Act=%d\n",
-			   best->slave ? best->slave->dev->name : "NULL",
-			   best->aggregator_identifier, best->num_of_ports,
-			   best->actor_oper_aggregator_key,
-			   best->partner_oper_aggregator_key,
-			   best->is_individual, best->is_active);
-
-		/* disable the ports that were related to the former
-		 * active_aggregator
-		 */
-		if (active) {
-			for (port = active->lag_ports; port;
-			     port = port->next_port_in_aggregator) {
-				__disable_port(port);
-			}
-		}
-		/* Slave array needs update. */
-		*update_slave_arr = true;
-	}
-
-	/* if the selected aggregator is of join individuals
-	 * (partner_system is NULL), enable their ports
-	 */
-	active = __get_active_agg(origin);
-
-	if (active) {
-		if (!__agg_has_partner(active)) {
-			for (port = active->lag_ports; port;
-			     port = port->next_port_in_aggregator) {
-				__enable_port(port);
-			}
-		}
-	}
-
-	rcu_read_unlock();
-
-	bond_3ad_set_carrier(bond);
-}
-
-/**
- * ad_clear_agg - clear a given aggregator's parameters
- * @aggregator: the aggregator we're looking at
- */
-static void ad_clear_agg(struct aggregator *aggregator)
-{
-	if (aggregator) {
-		aggregator->is_individual = false;
-		aggregator->actor_admin_aggregator_key = 0;
-		aggregator->actor_oper_aggregator_key = 0;
-		eth_zero_addr(aggregator->partner_system.mac_addr_value);
-		aggregator->partner_system_priority = 0;
-		aggregator->partner_oper_aggregator_key = 0;
-		aggregator->receive_state = 0;
-		aggregator->transmit_state = 0;
-		aggregator->lag_ports = NULL;
-		aggregator->is_active = 0;
-		aggregator->num_of_ports = 0;
-		pr_debug("%s: LAG %d was cleared\n",
-			 aggregator->slave ?
-			 aggregator->slave->dev->name : "NULL",
-			 aggregator->aggregator_identifier);
-	}
-}
-
-/**
- * ad_initialize_agg - initialize a given aggregator's parameters
- * @aggregator: the aggregator we're looking at
- */
-static void ad_initialize_agg(struct aggregator *aggregator)
-{
-	if (aggregator) {
-		ad_clear_agg(aggregator);
-
-		eth_zero_addr(aggregator->aggregator_mac_address.mac_addr_value);
-		aggregator->aggregator_identifier = 0;
-		aggregator->slave = NULL;
-	}
-}
-
-/**
- * ad_initialize_port - initialize a given port's parameters
- * @aggregator: the aggregator we're looking at
- * @lacp_fast: boolean. whether fast periodic should be used
- */
-static void ad_initialize_port(struct port *port, int lacp_fast)
-{
-	static const struct port_params tmpl = {
-		.system_priority = 0xffff,
-		.key             = 1,
-		.port_number     = 1,
-		.port_priority   = 0xff,
-		.port_state      = 1,
-	};
-	static const struct lacpdu lacpdu = {
-		.subtype		= 0x01,
-		.version_number = 0x01,
-		.tlv_type_actor_info = 0x01,
-		.actor_information_length = 0x14,
-		.tlv_type_partner_info = 0x02,
-		.partner_information_length = 0x14,
-		.tlv_type_collector_info = 0x03,
-		.collector_information_length = 0x10,
-		.collector_max_delay = htons(AD_COLLECTOR_MAX_DELAY),
-	};
-
-	if (port) {
-		port->actor_port_priority = 0xff;
-		port->actor_port_aggregator_identifier = 0;
-		port->ntt = false;
-		port->actor_admin_port_state = LACP_STATE_AGGREGATION |
-					       LACP_STATE_LACP_ACTIVITY;
-		port->actor_oper_port_state  = LACP_STATE_AGGREGATION |
-					       LACP_STATE_LACP_ACTIVITY;
-
-		if (lacp_fast)
-			port->actor_oper_port_state |= LACP_STATE_LACP_TIMEOUT;
-
-		memcpy(&port->partner_admin, &tmpl, sizeof(tmpl));
-		memcpy(&port->partner_oper, &tmpl, sizeof(tmpl));
-
-		port->is_enabled = true;
-		/* private parameters */
-		port->sm_vars = AD_PORT_BEGIN | AD_PORT_LACP_ENABLED;
-		port->sm_rx_state = 0;
-		port->sm_rx_timer_counter = 0;
-		port->sm_periodic_state = 0;
-		port->sm_periodic_timer_counter = 0;
-		port->sm_mux_state = 0;
-		port->sm_mux_timer_counter = 0;
-		port->sm_tx_state = 0;
-		port->aggregator = NULL;
-		port->next_port_in_aggregator = NULL;
-		port->transaction_id = 0;
-
-		port->sm_churn_actor_timer_counter = 0;
-		port->sm_churn_actor_state = 0;
-		port->churn_actor_count = 0;
-		port->sm_churn_partner_timer_counter = 0;
-		port->sm_churn_partner_state = 0;
-		port->churn_partner_count = 0;
-
-		memcpy(&port->lacpdu, &lacpdu, sizeof(lacpdu));
-	}
-}
-
-/**
- * ad_enable_collecting_distributing - enable a port's transmit/receive
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- *
- * Enable @port if it's in an active aggregator
- */
-static void ad_enable_collecting_distributing(struct port *port,
-					      bool *update_slave_arr)
-{
-	if (port->aggregator->is_active) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Enabling port %d (LAG %d)\n",
-			  port->actor_port_number,
-			  port->aggregator->aggregator_identifier);
-		__enable_port(port);
-		/* Slave array needs update */
-		*update_slave_arr = true;
-	}
-}
-
-/**
- * ad_disable_collecting_distributing - disable a port's transmit/receive
- * @port: the port we're looking at
- * @update_slave_arr: Does slave array need update?
- */
-static void ad_disable_collecting_distributing(struct port *port,
-					       bool *update_slave_arr)
-{
-	if (port->aggregator &&
-	    !MAC_ADDRESS_EQUAL(&(port->aggregator->partner_system),
-			       &(null_mac_addr))) {
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Disabling port %d (LAG %d)\n",
-			  port->actor_port_number,
-			  port->aggregator->aggregator_identifier);
-		__disable_port(port);
-		/* Slave array needs an update */
-		*update_slave_arr = true;
-	}
-}
-
-/**
- * ad_marker_info_received - handle receive of a Marker information frame
- * @marker_info: Marker info received
- * @port: the port we're looking at
- */
-static void ad_marker_info_received(struct bond_marker *marker_info,
-				    struct port *port)
-{
-	struct bond_marker marker;
-
-	atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.marker_rx);
-	atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.marker_rx);
-
-	/* copy the received marker data to the response marker */
-	memcpy(&marker, marker_info, sizeof(struct bond_marker));
-	/* change the marker subtype to marker response */
-	marker.tlv_type = AD_MARKER_RESPONSE_SUBTYPE;
-
-	/* send the marker response */
-	if (ad_marker_send(port, &marker) >= 0)
-		slave_dbg(port->slave->bond->dev, port->slave->dev,
-			  "Sent Marker Response on port %d\n",
-			  port->actor_port_number);
-}
-
-/**
- * ad_marker_response_received - handle receive of a marker response frame
- * @marker: marker PDU received
- * @port: the port we're looking at
- *
- * This function does nothing since we decided not to implement send and handle
- * response for marker PDU's, in this stage, but only to respond to marker
- * information.
- */
-static void ad_marker_response_received(struct bond_marker *marker,
-					struct port *port)
-{
-	atomic64_inc(&SLAVE_AD_INFO(port->slave)->stats.marker_resp_rx);
-	atomic64_inc(&BOND_AD_INFO(port->slave->bond).stats.marker_resp_rx);
-
-	/* DO NOTHING, SINCE WE DECIDED NOT TO IMPLEMENT THIS FEATURE FOR NOW */
-}
-
-/* ========= AD exported functions to the main bonding code ========= */
-
-/* Check aggregators status in team every T seconds */
-#define AD_AGGREGATOR_SELECTION_TIMER  8
-
-/**
- * bond_3ad_initiate_agg_selection - initate aggregator selection
- * @bond: bonding struct
- *
- * Set the aggregation selection timer, to initiate an agg selection in
- * the very near future.  Called during first initialization, and during
- * any down to up transitions of the bond.
- */
-void bond_3ad_initiate_agg_selection(struct bonding *bond, int timeout)
-{
-	BOND_AD_INFO(bond).agg_select_timer = timeout;
-}
-
-/**
- * bond_3ad_initialize - initialize a bond's 802.3ad parameters and structures
- * @bond: bonding struct to work on
- * @tick_resolution: tick duration (millisecond resolution)
- *
- * Can be called only after the mac address of the bond is set.
- */
-void bond_3ad_initialize(struct bonding *bond, u16 tick_resolution)
-{
-	/* check that the bond is not initialized yet */
-	if (!MAC_ADDRESS_EQUAL(&(BOND_AD_INFO(bond).system.sys_mac_addr),
-				bond->dev->dev_addr)) {
-
-		BOND_AD_INFO(bond).aggregator_identifier = 0;
-
-		BOND_AD_INFO(bond).system.sys_priority =
-			bond->params.ad_actor_sys_prio;
-		if (is_zero_ether_addr(bond->params.ad_actor_system))
-			BOND_AD_INFO(bond).system.sys_mac_addr =
-			    *((struct mac_addr *)bond->dev->dev_addr);
-		else
-			BOND_AD_INFO(bond).system.sys_mac_addr =
-			    *((struct mac_addr *)bond->params.ad_actor_system);
-
-		/* initialize how many times this module is called in one
-		 * second (should be about every 100ms)
-		 */
-		ad_ticks_per_sec = tick_resolution;
-
-		bond_3ad_initiate_agg_selection(bond,
-						AD_AGGREGATOR_SELECTION_TIMER *
-						ad_ticks_per_sec);
-	}
-}
-
-/**
- * bond_3ad_bind_slave - initialize a slave's port
- * @slave: slave struct to work on
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-void bond_3ad_bind_slave(struct slave *slave)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-	struct port *port;
-	struct aggregator *aggregator;
-
-	/* check that the slave has not been initialized yet. */
-	if (SLAVE_AD_INFO(slave)->port.slave != slave) {
-
-		/* port initialization */
-		port = &(SLAVE_AD_INFO(slave)->port);
-
-		ad_initialize_port(port, bond->params.lacp_fast);
-
-		port->slave = slave;
-		port->actor_port_number = SLAVE_AD_INFO(slave)->id;
-		/* key is determined according to the link speed, duplex and
-		 * user key
-		 */
-		port->actor_admin_port_key = bond->params.ad_user_port_key << 6;
-		ad_update_actor_keys(port, false);
-		/* actor system is the bond's system */
-		__ad_actor_update_port(port);
-		/* tx timer(to verify that no more than MAX_TX_IN_SECOND
-		 * lacpdu's are sent in one second)
-		 */
-		port->sm_tx_timer_counter = ad_ticks_per_sec/AD_MAX_TX_IN_SECOND;
-
-		__disable_port(port);
-
-		/* aggregator initialization */
-		aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-
-		ad_initialize_agg(aggregator);
-
-		aggregator->aggregator_mac_address = *((struct mac_addr *)bond->dev->dev_addr);
-		aggregator->aggregator_identifier = ++BOND_AD_INFO(bond).aggregator_identifier;
-		aggregator->slave = slave;
-		aggregator->is_active = 0;
-		aggregator->num_of_ports = 0;
-	}
-}
-
-/**
- * bond_3ad_unbind_slave - deinitialize a slave's port
- * @slave: slave struct to work on
- *
- * Search for the aggregator that is related to this port, remove the
- * aggregator and assign another aggregator for other port related to it
- * (if any), and remove the port.
- */
-void bond_3ad_unbind_slave(struct slave *slave)
-{
-	struct port *port, *prev_port, *temp_port;
-	struct aggregator *aggregator, *new_aggregator, *temp_aggregator;
-	int select_new_active_agg = 0;
-	struct bonding *bond = slave->bond;
-	struct slave *slave_iter;
-	struct list_head *iter;
-	bool dummy_slave_update; /* Ignore this value as caller updates array */
-
-	/* Sync against bond_3ad_state_machine_handler() */
-	spin_lock_bh(&bond->mode_lock);
-	aggregator = &(SLAVE_AD_INFO(slave)->aggregator);
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(bond->dev, slave->dev, "Trying to unbind an uninitialized port\n");
-		goto out;
-	}
-
-	slave_dbg(bond->dev, slave->dev, "Unbinding Link Aggregation Group %d\n",
-		  aggregator->aggregator_identifier);
-
-	/* Tell the partner that this port is not suitable for aggregation */
-	port->actor_oper_port_state &= ~LACP_STATE_SYNCHRONIZATION;
-	port->actor_oper_port_state &= ~LACP_STATE_COLLECTING;
-	port->actor_oper_port_state &= ~LACP_STATE_DISTRIBUTING;
-	port->actor_oper_port_state &= ~LACP_STATE_AGGREGATION;
-	__update_lacpdu_from_port(port);
-	ad_lacpdu_send(port);
-
-	/* check if this aggregator is occupied */
-	if (aggregator->lag_ports) {
-		/* check if there are other ports related to this aggregator
-		 * except the port related to this slave(thats ensure us that
-		 * there is a reason to search for new aggregator, and that we
-		 * will find one
-		 */
-		if ((aggregator->lag_ports != port) ||
-		    (aggregator->lag_ports->next_port_in_aggregator)) {
-			/* find new aggregator for the related port(s) */
-			bond_for_each_slave(bond, slave_iter, iter) {
-				new_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
-				/* if the new aggregator is empty, or it is
-				 * connected to our port only
-				 */
-				if (!new_aggregator->lag_ports ||
-				    ((new_aggregator->lag_ports == port) &&
-				     !new_aggregator->lag_ports->next_port_in_aggregator))
-					break;
-			}
-			if (!slave_iter)
-				new_aggregator = NULL;
-
-			/* if new aggregator found, copy the aggregator's
-			 * parameters and connect the related lag_ports to the
-			 * new aggregator
-			 */
-			if ((new_aggregator) && ((!new_aggregator->lag_ports) || ((new_aggregator->lag_ports == port) && !new_aggregator->lag_ports->next_port_in_aggregator))) {
-				slave_dbg(bond->dev, slave->dev, "Some port(s) related to LAG %d - replacing with LAG %d\n",
-					  aggregator->aggregator_identifier,
-					  new_aggregator->aggregator_identifier);
-
-				if ((new_aggregator->lag_ports == port) &&
-				    new_aggregator->is_active) {
-					slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-					select_new_active_agg = 1;
-				}
-
-				new_aggregator->is_individual = aggregator->is_individual;
-				new_aggregator->actor_admin_aggregator_key = aggregator->actor_admin_aggregator_key;
-				new_aggregator->actor_oper_aggregator_key = aggregator->actor_oper_aggregator_key;
-				new_aggregator->partner_system = aggregator->partner_system;
-				new_aggregator->partner_system_priority = aggregator->partner_system_priority;
-				new_aggregator->partner_oper_aggregator_key = aggregator->partner_oper_aggregator_key;
-				new_aggregator->receive_state = aggregator->receive_state;
-				new_aggregator->transmit_state = aggregator->transmit_state;
-				new_aggregator->lag_ports = aggregator->lag_ports;
-				new_aggregator->is_active = aggregator->is_active;
-				new_aggregator->num_of_ports = aggregator->num_of_ports;
-
-				/* update the information that is written on
-				 * the ports about the aggregator
-				 */
-				for (temp_port = aggregator->lag_ports; temp_port;
-				     temp_port = temp_port->next_port_in_aggregator) {
-					temp_port->aggregator = new_aggregator;
-					temp_port->actor_port_aggregator_identifier = new_aggregator->aggregator_identifier;
-				}
-
-				ad_clear_agg(aggregator);
-
-				if (select_new_active_agg)
-					ad_agg_selection_logic(__get_first_agg(port),
-							       &dummy_slave_update);
-			} else {
-				slave_warn(bond->dev, slave->dev, "unbinding aggregator, and could not find a new aggregator for its ports\n");
-			}
-		} else {
-			/* in case that the only port related to this
-			 * aggregator is the one we want to remove
-			 */
-			select_new_active_agg = aggregator->is_active;
-			ad_clear_agg(aggregator);
-			if (select_new_active_agg) {
-				slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-				/* select new active aggregator */
-				temp_aggregator = __get_first_agg(port);
-				if (temp_aggregator)
-					ad_agg_selection_logic(temp_aggregator,
-							       &dummy_slave_update);
-			}
-		}
-	}
-
-	slave_dbg(bond->dev, slave->dev, "Unbinding port %d\n", port->actor_port_number);
-
-	/* find the aggregator that this port is connected to */
-	bond_for_each_slave(bond, slave_iter, iter) {
-		temp_aggregator = &(SLAVE_AD_INFO(slave_iter)->aggregator);
-		prev_port = NULL;
-		/* search the port in the aggregator's related ports */
-		for (temp_port = temp_aggregator->lag_ports; temp_port;
-		     prev_port = temp_port,
-		     temp_port = temp_port->next_port_in_aggregator) {
-			if (temp_port == port) {
-				/* the aggregator found - detach the port from
-				 * this aggregator
-				 */
-				if (prev_port)
-					prev_port->next_port_in_aggregator = temp_port->next_port_in_aggregator;
-				else
-					temp_aggregator->lag_ports = temp_port->next_port_in_aggregator;
-				temp_aggregator->num_of_ports--;
-				if (__agg_active_ports(temp_aggregator) == 0) {
-					select_new_active_agg = temp_aggregator->is_active;
-					ad_clear_agg(temp_aggregator);
-					if (select_new_active_agg) {
-						slave_info(bond->dev, slave->dev, "Removing an active aggregator\n");
-						/* select new active aggregator */
-						ad_agg_selection_logic(__get_first_agg(port),
-							               &dummy_slave_update);
-					}
-				}
-				break;
-			}
-		}
-	}
-	port->slave = NULL;
-
-out:
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/**
- * bond_3ad_update_ad_actor_settings - reflect change of actor settings to ports
- * @bond: bonding struct to work on
- *
- * If an ad_actor setting gets changed we need to update the individual port
- * settings so the bond device will use the new values when it gets upped.
- */
-void bond_3ad_update_ad_actor_settings(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	ASSERT_RTNL();
-
-	BOND_AD_INFO(bond).system.sys_priority = bond->params.ad_actor_sys_prio;
-	if (is_zero_ether_addr(bond->params.ad_actor_system))
-		BOND_AD_INFO(bond).system.sys_mac_addr =
-		    *((struct mac_addr *)bond->dev->dev_addr);
-	else
-		BOND_AD_INFO(bond).system.sys_mac_addr =
-		    *((struct mac_addr *)bond->params.ad_actor_system);
-
-	spin_lock_bh(&bond->mode_lock);
-	bond_for_each_slave(bond, slave, iter) {
-		struct port *port = &(SLAVE_AD_INFO(slave))->port;
-
-		__ad_actor_update_port(port);
-		port->ntt = true;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/**
- * bond_3ad_state_machine_handler - handle state machines timeout
- * @bond: bonding struct to work on
- *
- * The state machine handling concept in this module is to check every tick
- * which state machine should operate any function. The execution order is
- * round robin, so when we have an interaction between state machines, the
- * reply of one to each other might be delayed until next tick.
- *
- * This function also complete the initialization when the agg_select_timer
- * times out, and it selects an aggregator for the ports that are yet not
- * related to any aggregator, and selects the active aggregator for a bond.
- */
-void bond_3ad_state_machine_handler(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    ad_work.work);
-	struct aggregator *aggregator;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
-	bool update_slave_arr = false;
-
-	/* Lock to protect data accessed by all (e.g., port->sm_vars) and
-	 * against running with bond_3ad_unbind_slave. ad_rx_machine may run
-	 * concurrently due to incoming LACPDU as well.
-	 */
-	spin_lock_bh(&bond->mode_lock);
-	rcu_read_lock();
-
-	/* check if there are any slaves */
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	/* check if agg_select_timer timer after initialize is timed out */
-	if (BOND_AD_INFO(bond).agg_select_timer &&
-	    !(--BOND_AD_INFO(bond).agg_select_timer)) {
-		slave = bond_first_slave_rcu(bond);
-		port = slave ? &(SLAVE_AD_INFO(slave)->port) : NULL;
-
-		/* select the active aggregator for the bond */
-		if (port) {
-			if (!port->slave) {
-				net_warn_ratelimited("%s: Warning: bond's first port is uninitialized\n",
-						     bond->dev->name);
-				goto re_arm;
-			}
-
-			aggregator = __get_first_agg(port);
-			ad_agg_selection_logic(aggregator, &update_slave_arr);
-		}
-		bond_3ad_set_carrier(bond);
-	}
-
-	/* for each port run the state machines */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (!port->slave) {
-			net_warn_ratelimited("%s: Warning: Found an uninitialized port\n",
-					    bond->dev->name);
-			goto re_arm;
-		}
-
-		ad_rx_machine(NULL, port);
-		ad_periodic_machine(port);
-		ad_port_selection_logic(port, &update_slave_arr);
-		ad_mux_machine(port, &update_slave_arr);
-		ad_tx_machine(port);
-		ad_churn_machine(port);
-
-		/* turn off the BEGIN bit, since we already handled it */
-		if (port->sm_vars & AD_PORT_BEGIN)
-			port->sm_vars &= ~AD_PORT_BEGIN;
-	}
-
-re_arm:
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->should_notify) {
-			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
-			break;
-		}
-	}
-	rcu_read_unlock();
-	spin_unlock_bh(&bond->mode_lock);
-
-	if (update_slave_arr)
-		bond_slave_arr_work_rearm(bond, 0);
-
-	if (should_notify_rtnl && rtnl_trylock()) {
-		bond_slave_state_notify(bond);
-		rtnl_unlock();
-	}
-	queue_delayed_work(bond->wq, &bond->ad_work, ad_delta_in_ticks);
-}
-
-/**
- * bond_3ad_rx_indication - handle a received frame
- * @lacpdu: received lacpdu
- * @slave: slave struct to work on
- *
- * It is assumed that frames that were sent on this NIC don't returned as new
- * received frames (loopback). Since only the payload is given to this
- * function, it check for loopback.
- */
-static int bond_3ad_rx_indication(struct lacpdu *lacpdu, struct slave *slave)
-{
-	struct bonding *bond = slave->bond;
-	int ret = RX_HANDLER_ANOTHER;
-	struct bond_marker *marker;
-	struct port *port;
-	atomic64_t *stat;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-	if (!port->slave) {
-		net_warn_ratelimited("%s: Warning: port of slave %s is uninitialized\n",
-				     slave->dev->name, slave->bond->dev->name);
-		return ret;
-	}
-
-	switch (lacpdu->subtype) {
-	case AD_TYPE_LACPDU:
-		ret = RX_HANDLER_CONSUMED;
-		slave_dbg(slave->bond->dev, slave->dev,
-			  "Received LACPDU on port %d\n",
-			  port->actor_port_number);
-		/* Protect against concurrent state machines */
-		spin_lock(&slave->bond->mode_lock);
-		ad_rx_machine(lacpdu, port);
-		spin_unlock(&slave->bond->mode_lock);
-		break;
-	case AD_TYPE_MARKER:
-		ret = RX_HANDLER_CONSUMED;
-		/* No need to convert fields to Little Endian since we
-		 * don't use the marker's fields.
-		 */
-		marker = (struct bond_marker *)lacpdu;
-		switch (marker->tlv_type) {
-		case AD_MARKER_INFORMATION_SUBTYPE:
-			slave_dbg(slave->bond->dev, slave->dev, "Received Marker Information on port %d\n",
-				  port->actor_port_number);
-			ad_marker_info_received(marker, port);
-			break;
-		case AD_MARKER_RESPONSE_SUBTYPE:
-			slave_dbg(slave->bond->dev, slave->dev, "Received Marker Response on port %d\n",
-				  port->actor_port_number);
-			ad_marker_response_received(marker, port);
-			break;
-		default:
-			slave_dbg(slave->bond->dev, slave->dev, "Received an unknown Marker subtype on port %d\n",
-				  port->actor_port_number);
-			stat = &SLAVE_AD_INFO(slave)->stats.marker_unknown_rx;
-			atomic64_inc(stat);
-			stat = &BOND_AD_INFO(bond).stats.marker_unknown_rx;
-			atomic64_inc(stat);
-		}
-		break;
-	default:
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_unknown_rx);
-		atomic64_inc(&BOND_AD_INFO(bond).stats.lacpdu_unknown_rx);
-	}
-
-	return ret;
-}
-
-/**
- * ad_update_actor_keys - Update the oper / admin keys for a port based on
- * its current speed and duplex settings.
- *
- * @port: the port we'are looking at
- * @reset: Boolean to just reset the speed and the duplex part of the key
- *
- * The logic to change the oper / admin keys is:
- * (a) A full duplex port can participate in LACP with partner.
- * (b) When the speed is changed, LACP need to be reinitiated.
- */
-static void ad_update_actor_keys(struct port *port, bool reset)
-{
-	u8 duplex = 0;
-	u16 ospeed = 0, speed = 0;
-	u16 old_oper_key = port->actor_oper_port_key;
-
-	port->actor_admin_port_key &= ~(AD_SPEED_KEY_MASKS|AD_DUPLEX_KEY_MASKS);
-	if (!reset) {
-		speed = __get_link_speed(port);
-		ospeed = (old_oper_key & AD_SPEED_KEY_MASKS) >> 1;
-		duplex = __get_duplex(port);
-		port->actor_admin_port_key |= (speed << 1) | duplex;
-	}
-	port->actor_oper_port_key = port->actor_admin_port_key;
-
-	if (old_oper_key != port->actor_oper_port_key) {
-		/* Only 'duplex' port participates in LACP */
-		if (duplex)
-			port->sm_vars |= AD_PORT_LACP_ENABLED;
-		else
-			port->sm_vars &= ~AD_PORT_LACP_ENABLED;
-
-		if (!reset) {
-			if (!speed) {
-				slave_err(port->slave->bond->dev,
-					  port->slave->dev,
-					  "speed changed to 0 on port %d\n",
-					  port->actor_port_number);
-			} else if (duplex && ospeed != speed) {
-				/* Speed change restarts LACP state-machine */
-				port->sm_vars |= AD_PORT_BEGIN;
-			}
-		}
-	}
-}
-
-/**
- * bond_3ad_adapter_speed_duplex_changed - handle a slave's speed / duplex
- * change indication
- *
- * @slave: slave struct to work on
- *
- * Handle reselection of aggregator (if needed) for this port.
- */
-void bond_3ad_adapter_speed_duplex_changed(struct slave *slave)
-{
-	struct port *port;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(slave->bond->dev, slave->dev,
-			   "speed/duplex changed for uninitialized port\n");
-		return;
-	}
-
-	spin_lock_bh(&slave->bond->mode_lock);
-	ad_update_actor_keys(port, false);
-	spin_unlock_bh(&slave->bond->mode_lock);
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d changed speed/duplex\n",
-		  port->actor_port_number);
-}
-
-/**
- * bond_3ad_handle_link_change - handle a slave's link status change indication
- * @slave: slave struct to work on
- * @status: whether the link is now up or down
- *
- * Handle reselection of aggregator (if needed) for this port.
- */
-void bond_3ad_handle_link_change(struct slave *slave, char link)
-{
-	struct aggregator *agg;
-	struct port *port;
-	bool dummy;
-
-	port = &(SLAVE_AD_INFO(slave)->port);
-
-	/* if slave is null, the whole port is not initialized */
-	if (!port->slave) {
-		slave_warn(slave->bond->dev, slave->dev, "link status changed for uninitialized port\n");
-		return;
-	}
-
-	spin_lock_bh(&slave->bond->mode_lock);
-	/* on link down we are zeroing duplex and speed since
-	 * some of the adaptors(ce1000.lan) report full duplex/speed
-	 * instead of N/A(duplex) / 0(speed).
-	 *
-	 * on link up we are forcing recheck on the duplex and speed since
-	 * some of he adaptors(ce1000.lan) report.
-	 */
-	if (link == BOND_LINK_UP) {
-		port->is_enabled = true;
-		ad_update_actor_keys(port, false);
-	} else {
-		/* link has failed */
-		port->is_enabled = false;
-		ad_update_actor_keys(port, true);
-		toe_failover(netdev_master_upper_dev_get(slave->dev),
-			     slave->dev, TOE_LINK_DOWN, NULL);
-	}
-	agg = __get_first_agg(port);
-	ad_agg_selection_logic(agg, &dummy);
-
-	spin_unlock_bh(&slave->bond->mode_lock);
-
-	slave_dbg(slave->bond->dev, slave->dev, "Port %d changed link status to %s\n",
-		  port->actor_port_number,
-		  link == BOND_LINK_UP ? "UP" : "DOWN");
-
-	/* RTNL is held and mode_lock is released so it's safe
-	 * to update slave_array here.
-	 */
-	bond_update_slave_arr(slave->bond, NULL);
-}
-
-/**
- * bond_3ad_set_carrier - set link state for bonding master
- * @bond - bonding structure
- *
- * if we have an active aggregator, we're up, if not, we're down.
- * Presumes that we cannot have an active aggregator if there are
- * no slaves with link up.
- *
- * This behavior complies with IEEE 802.3 section 43.3.9.
- *
- * Called by bond_set_carrier(). Return zero if carrier state does not
- * change, nonzero if it does.
- */
-int bond_3ad_set_carrier(struct bonding *bond)
-{
-	struct aggregator *active;
-	struct slave *first_slave;
-	int ret = 1;
-
-	rcu_read_lock();
-	first_slave = bond_first_slave_rcu(bond);
-	if (!first_slave) {
-		ret = 0;
-		goto out;
-	}
-	active = __get_active_agg(&(SLAVE_AD_INFO(first_slave)->aggregator));
-	if (active) {
-		/* are enough slaves available to consider link up? */
-		if (__agg_active_ports(active) < bond->params.min_links) {
-			if (netif_carrier_ok(bond->dev)) {
-				netif_carrier_off(bond->dev);
-				goto out;
-			}
-		} else if (!netif_carrier_ok(bond->dev)) {
-			netif_carrier_on(bond->dev);
-			goto out;
-		}
-	} else if (netif_carrier_ok(bond->dev)) {
-		netif_carrier_off(bond->dev);
-	}
-out:
-	rcu_read_unlock();
-	return ret;
-}
-
-/**
- * __bond_3ad_get_active_agg_info - get information of the active aggregator
- * @bond: bonding struct to work on
- * @ad_info: ad_info struct to fill with the bond's info
- *
- * Returns:   0 on success
- *          < 0 on error
- */
-int __bond_3ad_get_active_agg_info(struct bonding *bond,
-				   struct ad_info *ad_info)
-{
-	struct aggregator *aggregator = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	struct port *port;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (port->aggregator && port->aggregator->is_active) {
-			aggregator = port->aggregator;
-			break;
-		}
-	}
-
-	if (!aggregator)
-		return -1;
-
-	ad_info->aggregator_id = aggregator->aggregator_identifier;
-	ad_info->ports = __agg_active_ports(aggregator);
-	ad_info->actor_key = aggregator->actor_oper_aggregator_key;
-	ad_info->partner_key = aggregator->partner_oper_aggregator_key;
-	ether_addr_copy(ad_info->partner_system,
-			aggregator->partner_system.mac_addr_value);
-	return 0;
-}
-
-int bond_3ad_get_active_agg_info(struct bonding *bond, struct ad_info *ad_info)
-{
-	int ret;
-
-	rcu_read_lock();
-	ret = __bond_3ad_get_active_agg_info(bond, ad_info);
-	rcu_read_unlock();
-
-	return ret;
-}
-
-int bond_3ad_lacpdu_recv(const struct sk_buff *skb, struct bonding *bond,
-			 struct slave *slave)
-{
-	struct lacpdu *lacpdu, _lacpdu;
-
-	if (skb->protocol != PKT_TYPE_LACPDU)
-		return RX_HANDLER_ANOTHER;
-
-	if (!MAC_ADDRESS_EQUAL(eth_hdr(skb)->h_dest, lacpdu_mcast_addr))
-		return RX_HANDLER_ANOTHER;
-
-	lacpdu = skb_header_pointer(skb, 0, sizeof(_lacpdu), &_lacpdu);
-	if (!lacpdu) {
-		atomic64_inc(&SLAVE_AD_INFO(slave)->stats.lacpdu_illegal_rx);
-		atomic64_inc(&BOND_AD_INFO(bond).stats.lacpdu_illegal_rx);
-		return RX_HANDLER_ANOTHER;
-	}
-
-	return bond_3ad_rx_indication(lacpdu, slave);
-}
-
-/**
- * bond_3ad_update_lacp_rate - change the lacp rate
- * @bond - bonding struct
- *
- * When modify lacp_rate parameter via sysfs,
- * update actor_oper_port_state of each port.
- *
- * Hold bond->mode_lock,
- * so we can modify port->actor_oper_port_state,
- * no matter bond is up or down.
- */
-void bond_3ad_update_lacp_rate(struct bonding *bond)
-{
-	struct port *port = NULL;
-	struct list_head *iter;
-	struct slave *slave;
-	int lacp_fast;
-
-	lacp_fast = bond->params.lacp_fast;
-	spin_lock_bh(&bond->mode_lock);
-	bond_for_each_slave(bond, slave, iter) {
-		port = &(SLAVE_AD_INFO(slave)->port);
-		if (lacp_fast)
-			port->actor_oper_port_state |= LACP_STATE_LACP_TIMEOUT;
-		else
-			port->actor_oper_port_state &= ~LACP_STATE_LACP_TIMEOUT;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-size_t bond_3ad_stats_size(void)
-{
-	return nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_TX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_UNKNOWN_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_LACPDU_ILLEGAL_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_TX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RESP_RX */
-	       nla_total_size_64bit(sizeof(u64)) + /* BOND_3AD_STAT_MARKER_RESP_TX */
-	       nla_total_size_64bit(sizeof(u64)); /* BOND_3AD_STAT_MARKER_UNKNOWN_RX */
-}
-
-int bond_3ad_stats_fill(struct sk_buff *skb, struct bond_3ad_stats *stats)
-{
-	u64 val;
-
-	val = atomic64_read(&stats->lacpdu_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_unknown_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_UNKNOWN_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->lacpdu_illegal_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_LACPDU_ILLEGAL_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-
-	val = atomic64_read(&stats->marker_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_resp_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RESP_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_resp_tx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_RESP_TX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-	val = atomic64_read(&stats->marker_unknown_rx);
-	if (nla_put_u64_64bit(skb, BOND_3AD_STAT_MARKER_UNKNOWN_RX, val,
-			      BOND_3AD_STAT_PAD))
-		return -EMSGSIZE;
-
-	return 0;
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.6.0/bond_alb.c
--- a/src/network/bonding/BONDING_KDIRS/5.6.0/bond_alb.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1811 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 1999 - 2004 Intel Corporation. All rights reserved.
- */
-
-#include <linux/skbuff.h>
-#include <linux/netdevice.h>
-#include <linux/etherdevice.h>
-#include <linux/pkt_sched.h>
-#include <linux/spinlock.h>
-#include <linux/slab.h>
-#include <linux/timer.h>
-#include <linux/ip.h>
-#include <linux/ipv6.h>
-#include <linux/if_arp.h>
-#include <linux/if_ether.h>
-#include <linux/if_bonding.h>
-#include <linux/if_vlan.h>
-#include <linux/in.h>
-#include <net/ipx.h>
-#include <net/arp.h>
-#include <net/ipv6.h>
-#include <asm/byteorder.h>
-#include <net/bonding.h>
-#include <net/bond_alb.h>
-
-static const u8 mac_v6_allmcast[ETH_ALEN + 2] __long_aligned = {
-	0x33, 0x33, 0x00, 0x00, 0x00, 0x01
-};
-static const int alb_delta_in_ticks = HZ / ALB_TIMER_TICKS_PER_SEC;
-
-#pragma pack(1)
-struct learning_pkt {
-	u8 mac_dst[ETH_ALEN];
-	u8 mac_src[ETH_ALEN];
-	__be16 type;
-	u8 padding[ETH_ZLEN - ETH_HLEN];
-};
-
-struct arp_pkt {
-	__be16  hw_addr_space;
-	__be16  prot_addr_space;
-	u8      hw_addr_len;
-	u8      prot_addr_len;
-	__be16  op_code;
-	u8      mac_src[ETH_ALEN];	/* sender hardware address */
-	__be32  ip_src;			/* sender IP address */
-	u8      mac_dst[ETH_ALEN];	/* target hardware address */
-	__be32  ip_dst;			/* target IP address */
-};
-#pragma pack()
-
-/* Forward declaration */
-static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
-				      bool strict_match);
-static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp);
-static void rlb_src_unlink(struct bonding *bond, u32 index);
-static void rlb_src_link(struct bonding *bond, u32 ip_src_hash,
-			 u32 ip_dst_hash);
-
-static inline u8 _simple_hash(const u8 *hash_start, int hash_size)
-{
-	int i;
-	u8 hash = 0;
-
-	for (i = 0; i < hash_size; i++)
-		hash ^= hash_start[i];
-
-	return hash;
-}
-
-/*********************** tlb specific functions ***************************/
-
-static inline void tlb_init_table_entry(struct tlb_client_info *entry, int save_load)
-{
-	if (save_load) {
-		entry->load_history = 1 + entry->tx_bytes /
-				      BOND_TLB_REBALANCE_INTERVAL;
-		entry->tx_bytes = 0;
-	}
-
-	entry->tx_slave = NULL;
-	entry->next = TLB_NULL_INDEX;
-	entry->prev = TLB_NULL_INDEX;
-}
-
-static inline void tlb_init_slave(struct slave *slave)
-{
-	SLAVE_TLB_INFO(slave).load = 0;
-	SLAVE_TLB_INFO(slave).head = TLB_NULL_INDEX;
-}
-
-static void __tlb_clear_slave(struct bonding *bond, struct slave *slave,
-			 int save_load)
-{
-	struct tlb_client_info *tx_hash_table;
-	u32 index;
-
-	/* clear slave from tx_hashtbl */
-	tx_hash_table = BOND_ALB_INFO(bond).tx_hashtbl;
-
-	/* skip this if we've already freed the tx hash table */
-	if (tx_hash_table) {
-		index = SLAVE_TLB_INFO(slave).head;
-		while (index != TLB_NULL_INDEX) {
-			u32 next_index = tx_hash_table[index].next;
-			tlb_init_table_entry(&tx_hash_table[index], save_load);
-			index = next_index;
-		}
-	}
-
-	tlb_init_slave(slave);
-}
-
-static void tlb_clear_slave(struct bonding *bond, struct slave *slave,
-			 int save_load)
-{
-	spin_lock_bh(&bond->mode_lock);
-	__tlb_clear_slave(bond, slave, save_load);
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* Must be called before starting the monitor timer */
-static int tlb_initialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	int size = TLB_HASH_TABLE_SIZE * sizeof(struct tlb_client_info);
-	struct tlb_client_info *new_hashtbl;
-	int i;
-
-	new_hashtbl = kzalloc(size, GFP_KERNEL);
-	if (!new_hashtbl)
-		return -ENOMEM;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	bond_info->tx_hashtbl = new_hashtbl;
-
-	for (i = 0; i < TLB_HASH_TABLE_SIZE; i++)
-		tlb_init_table_entry(&bond_info->tx_hashtbl[i], 0);
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	return 0;
-}
-
-/* Must be called only after all slaves have been released */
-static void tlb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	spin_lock_bh(&bond->mode_lock);
-
-	kfree(bond_info->tx_hashtbl);
-	bond_info->tx_hashtbl = NULL;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static long long compute_gap(struct slave *slave)
-{
-	return (s64) (slave->speed << 20) - /* Convert to Megabit per sec */
-	       (s64) (SLAVE_TLB_INFO(slave).load << 3); /* Bytes to bits */
-}
-
-static struct slave *tlb_get_least_loaded_slave(struct bonding *bond)
-{
-	struct slave *slave, *least_loaded;
-	struct list_head *iter;
-	long long max_gap;
-
-	least_loaded = NULL;
-	max_gap = LLONG_MIN;
-
-	/* Find the slave with the largest gap */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (bond_slave_can_tx(slave)) {
-			long long gap = compute_gap(slave);
-
-			if (max_gap < gap) {
-				least_loaded = slave;
-				max_gap = gap;
-			}
-		}
-	}
-
-	return least_loaded;
-}
-
-static struct slave *__tlb_choose_channel(struct bonding *bond, u32 hash_index,
-						u32 skb_len)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct tlb_client_info *hash_table;
-	struct slave *assigned_slave;
-
-	hash_table = bond_info->tx_hashtbl;
-	assigned_slave = hash_table[hash_index].tx_slave;
-	if (!assigned_slave) {
-		assigned_slave = tlb_get_least_loaded_slave(bond);
-
-		if (assigned_slave) {
-			struct tlb_slave_info *slave_info =
-				&(SLAVE_TLB_INFO(assigned_slave));
-			u32 next_index = slave_info->head;
-
-			hash_table[hash_index].tx_slave = assigned_slave;
-			hash_table[hash_index].next = next_index;
-			hash_table[hash_index].prev = TLB_NULL_INDEX;
-
-			if (next_index != TLB_NULL_INDEX)
-				hash_table[next_index].prev = hash_index;
-
-			slave_info->head = hash_index;
-			slave_info->load +=
-				hash_table[hash_index].load_history;
-		}
-	}
-
-	if (assigned_slave)
-		hash_table[hash_index].tx_bytes += skb_len;
-
-	return assigned_slave;
-}
-
-static struct slave *tlb_choose_channel(struct bonding *bond, u32 hash_index,
-					u32 skb_len)
-{
-	struct slave *tx_slave;
-
-	/* We don't need to disable softirq here, becase
-	 * tlb_choose_channel() is only called by bond_alb_xmit()
-	 * which already has softirq disabled.
-	 */
-	spin_lock(&bond->mode_lock);
-	tx_slave = __tlb_choose_channel(bond, hash_index, skb_len);
-	spin_unlock(&bond->mode_lock);
-
-	return tx_slave;
-}
-
-/*********************** rlb specific functions ***************************/
-
-/* when an ARP REPLY is received from a client update its info
- * in the rx_hashtbl
- */
-static void rlb_update_entry_from_arp(struct bonding *bond, struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
-	client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-	if ((client_info->assigned) &&
-	    (client_info->ip_src == arp->ip_dst) &&
-	    (client_info->ip_dst == arp->ip_src) &&
-	    (!ether_addr_equal_64bits(client_info->mac_dst, arp->mac_src))) {
-		/* update the clients MAC address */
-		ether_addr_copy(client_info->mac_dst, arp->mac_src);
-		client_info->ntt = 1;
-		bond_info->rx_ntt = 1;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static int rlb_arp_recv(const struct sk_buff *skb, struct bonding *bond,
-			struct slave *slave)
-{
-	struct arp_pkt *arp, _arp;
-
-	if (skb->protocol != cpu_to_be16(ETH_P_ARP))
-		goto out;
-
-	arp = skb_header_pointer(skb, 0, sizeof(_arp), &_arp);
-	if (!arp)
-		goto out;
-
-	/* We received an ARP from arp->ip_src.
-	 * We might have used this IP address previously (on the bonding host
-	 * itself or on a system that is bridged together with the bond).
-	 * However, if arp->mac_src is different than what is stored in
-	 * rx_hashtbl, some other host is now using the IP and we must prevent
-	 * sending out client updates with this IP address and the old MAC
-	 * address.
-	 * Clean up all hash table entries that have this address as ip_src but
-	 * have a different mac_src.
-	 */
-	rlb_purge_src_ip(bond, arp);
-
-	if (arp->op_code == htons(ARPOP_REPLY)) {
-		/* update rx hash table for this ARP */
-		rlb_update_entry_from_arp(bond, arp);
-		slave_dbg(bond->dev, slave->dev, "Server received an ARP Reply from client\n");
-	}
-out:
-	return RX_HANDLER_ANOTHER;
-}
-
-/* Caller must hold rcu_read_lock() */
-static struct slave *__rlb_next_rx_slave(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *before = NULL, *rx_slave = NULL, *slave;
-	struct list_head *iter;
-	bool found = false;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!bond_slave_can_tx(slave))
-			continue;
-		if (!found) {
-			if (!before || before->speed < slave->speed)
-				before = slave;
-		} else {
-			if (!rx_slave || rx_slave->speed < slave->speed)
-				rx_slave = slave;
-		}
-		if (slave == bond_info->rx_slave)
-			found = true;
-	}
-	/* we didn't find anything after the current or we have something
-	 * better before and up to the current slave
-	 */
-	if (!rx_slave || (before && rx_slave->speed < before->speed))
-		rx_slave = before;
-
-	if (rx_slave)
-		bond_info->rx_slave = rx_slave;
-
-	return rx_slave;
-}
-
-/* Caller must hold RTNL, rcu_read_lock is obtained only to silence checkers */
-static struct slave *rlb_next_rx_slave(struct bonding *bond)
-{
-	struct slave *rx_slave;
-
-	ASSERT_RTNL();
-
-	rcu_read_lock();
-	rx_slave = __rlb_next_rx_slave(bond);
-	rcu_read_unlock();
-
-	return rx_slave;
-}
-
-/* teach the switch the mac of a disabled slave
- * on the primary for fault tolerance
- *
- * Caller must hold RTNL
- */
-static void rlb_teach_disabled_mac_on_primary(struct bonding *bond, u8 addr[])
-{
-	struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-	if (!curr_active)
-		return;
-
-	if (!bond->alb_info.primary_is_promisc) {
-		if (!dev_set_promiscuity(curr_active->dev, 1))
-			bond->alb_info.primary_is_promisc = 1;
-		else
-			bond->alb_info.primary_is_promisc = 0;
-	}
-
-	bond->alb_info.rlb_promisc_timeout_counter = 0;
-
-	alb_send_learning_packets(curr_active, addr, true);
-}
-
-/* slave being removed should not be active at this point
- *
- * Caller must hold rtnl.
- */
-static void rlb_clear_slave(struct bonding *bond, struct slave *slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *rx_hash_table;
-	u32 index, next_index;
-
-	/* clear slave from rx_hashtbl */
-	spin_lock_bh(&bond->mode_lock);
-
-	rx_hash_table = bond_info->rx_hashtbl;
-	index = bond_info->rx_hashtbl_used_head;
-	for (; index != RLB_NULL_INDEX; index = next_index) {
-		next_index = rx_hash_table[index].used_next;
-		if (rx_hash_table[index].slave == slave) {
-			struct slave *assigned_slave = rlb_next_rx_slave(bond);
-
-			if (assigned_slave) {
-				rx_hash_table[index].slave = assigned_slave;
-				if (is_valid_ether_addr(rx_hash_table[index].mac_dst)) {
-					bond_info->rx_hashtbl[index].ntt = 1;
-					bond_info->rx_ntt = 1;
-					/* A slave has been removed from the
-					 * table because it is either disabled
-					 * or being released. We must retry the
-					 * update to avoid clients from not
-					 * being updated & disconnecting when
-					 * there is stress
-					 */
-					bond_info->rlb_update_retry_counter =
-						RLB_UPDATE_RETRY;
-				}
-			} else {  /* there is no active slave */
-				rx_hash_table[index].slave = NULL;
-			}
-		}
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	if (slave != rtnl_dereference(bond->curr_active_slave))
-		rlb_teach_disabled_mac_on_primary(bond, slave->dev->dev_addr);
-}
-
-static void rlb_update_client(struct rlb_client_info *client_info)
-{
-	int i;
-
-	if (!client_info->slave || !is_valid_ether_addr(client_info->mac_dst))
-		return;
-
-	for (i = 0; i < RLB_ARP_BURST_SIZE; i++) {
-		struct sk_buff *skb;
-
-		skb = arp_create(ARPOP_REPLY, ETH_P_ARP,
-				 client_info->ip_dst,
-				 client_info->slave->dev,
-				 client_info->ip_src,
-				 client_info->mac_dst,
-				 client_info->slave->dev->dev_addr,
-				 client_info->mac_dst);
-		if (!skb) {
-			slave_err(client_info->slave->bond->dev,
-				  client_info->slave->dev,
-				  "failed to create an ARP packet\n");
-			continue;
-		}
-
-		skb->dev = client_info->slave->dev;
-
-		if (client_info->vlan_id) {
-			__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),
-					       client_info->vlan_id);
-		}
-
-		arp_xmit(skb);
-	}
-}
-
-/* sends ARP REPLIES that update the clients that need updating */
-static void rlb_update_rx_clients(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		if (client_info->ntt) {
-			rlb_update_client(client_info);
-			if (bond_info->rlb_update_retry_counter == 0)
-				client_info->ntt = 0;
-		}
-	}
-
-	/* do not update the entries again until this counter is zero so that
-	 * not to confuse the clients.
-	 */
-	bond_info->rlb_update_delay_counter = RLB_UPDATE_DELAY;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* The slave was assigned a new mac address - update the clients */
-static void rlb_req_update_slave_clients(struct bonding *bond, struct slave *slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	int ntt = 0;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-		if ((client_info->slave == slave) &&
-		    is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			ntt = 1;
-		}
-	}
-
-	/* update the team's flag only after the whole iteration */
-	if (ntt) {
-		bond_info->rx_ntt = 1;
-		/* fasten the change */
-		bond_info->rlb_update_retry_counter = RLB_UPDATE_RETRY;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* mark all clients using src_ip to be updated */
-static void rlb_req_update_subnet_clients(struct bonding *bond, __be32 src_ip)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	spin_lock(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-		if (!client_info->slave) {
-			netdev_err(bond->dev, "found a client with no channel in the client's hash table\n");
-			continue;
-		}
-		/* update all clients using this src_ip, that are not assigned
-		 * to the team's address (curr_active_slave) and have a known
-		 * unicast mac address.
-		 */
-		if ((client_info->ip_src == src_ip) &&
-		    !ether_addr_equal_64bits(client_info->slave->dev->dev_addr,
-					     bond->dev->dev_addr) &&
-		    is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			bond_info->rx_ntt = 1;
-		}
-	}
-
-	spin_unlock(&bond->mode_lock);
-}
-
-static struct slave *rlb_choose_channel(struct sk_buff *skb,
-					struct bonding *bond,
-					const struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *assigned_slave, *curr_active_slave;
-	struct rlb_client_info *client_info;
-	u32 hash_index = 0;
-
-	spin_lock(&bond->mode_lock);
-
-	curr_active_slave = rcu_dereference(bond->curr_active_slave);
-
-	hash_index = _simple_hash((u8 *)&arp->ip_dst, sizeof(arp->ip_dst));
-	client_info = &(bond_info->rx_hashtbl[hash_index]);
-
-	if (client_info->assigned) {
-		if ((client_info->ip_src == arp->ip_src) &&
-		    (client_info->ip_dst == arp->ip_dst)) {
-			/* the entry is already assigned to this client */
-			if (!is_broadcast_ether_addr(arp->mac_dst)) {
-				/* update mac address from arp */
-				ether_addr_copy(client_info->mac_dst, arp->mac_dst);
-			}
-			ether_addr_copy(client_info->mac_src, arp->mac_src);
-
-			assigned_slave = client_info->slave;
-			if (assigned_slave) {
-				spin_unlock(&bond->mode_lock);
-				return assigned_slave;
-			}
-		} else {
-			/* the entry is already assigned to some other client,
-			 * move the old client to primary (curr_active_slave) so
-			 * that the new client can be assigned to this entry.
-			 */
-			if (curr_active_slave &&
-			    client_info->slave != curr_active_slave) {
-				client_info->slave = curr_active_slave;
-				rlb_update_client(client_info);
-			}
-		}
-	}
-	/* assign a new slave */
-	assigned_slave = __rlb_next_rx_slave(bond);
-
-	if (assigned_slave) {
-		if (!(client_info->assigned &&
-		      client_info->ip_src == arp->ip_src)) {
-			/* ip_src is going to be updated,
-			 * fix the src hash list
-			 */
-			u32 hash_src = _simple_hash((u8 *)&arp->ip_src,
-						    sizeof(arp->ip_src));
-			rlb_src_unlink(bond, hash_index);
-			rlb_src_link(bond, hash_src, hash_index);
-		}
-
-		client_info->ip_src = arp->ip_src;
-		client_info->ip_dst = arp->ip_dst;
-		/* arp->mac_dst is broadcast for arp reqeusts.
-		 * will be updated with clients actual unicast mac address
-		 * upon receiving an arp reply.
-		 */
-		ether_addr_copy(client_info->mac_dst, arp->mac_dst);
-		ether_addr_copy(client_info->mac_src, arp->mac_src);
-		client_info->slave = assigned_slave;
-
-		if (is_valid_ether_addr(client_info->mac_dst)) {
-			client_info->ntt = 1;
-			bond->alb_info.rx_ntt = 1;
-		} else {
-			client_info->ntt = 0;
-		}
-
-		if (vlan_get_tag(skb, &client_info->vlan_id))
-			client_info->vlan_id = 0;
-
-		if (!client_info->assigned) {
-			u32 prev_tbl_head = bond_info->rx_hashtbl_used_head;
-			bond_info->rx_hashtbl_used_head = hash_index;
-			client_info->used_next = prev_tbl_head;
-			if (prev_tbl_head != RLB_NULL_INDEX) {
-				bond_info->rx_hashtbl[prev_tbl_head].used_prev =
-					hash_index;
-			}
-			client_info->assigned = 1;
-		}
-	}
-
-	spin_unlock(&bond->mode_lock);
-
-	return assigned_slave;
-}
-
-/* chooses (and returns) transmit channel for arp reply
- * does not choose channel for other arp types since they are
- * sent on the curr_active_slave
- */
-static struct slave *rlb_arp_xmit(struct sk_buff *skb, struct bonding *bond)
-{
-	struct slave *tx_slave = NULL;
-	struct arp_pkt *arp;
-
-	if (!pskb_network_may_pull(skb, sizeof(*arp)))
-		return NULL;
-	arp = (struct arp_pkt *)skb_network_header(skb);
-
-	/* Don't modify or load balance ARPs that do not originate locally
-	 * (e.g.,arrive via a bridge).
-	 */
-	if (!bond_slave_has_mac_rx(bond, arp->mac_src))
-		return NULL;
-
-	if (arp->op_code == htons(ARPOP_REPLY)) {
-		/* the arp must be sent on the selected rx channel */
-		tx_slave = rlb_choose_channel(skb, bond, arp);
-		if (tx_slave)
-			bond_hw_addr_copy(arp->mac_src, tx_slave->dev->dev_addr,
-					  tx_slave->dev->addr_len);
-		netdev_dbg(bond->dev, "(slave %s): Server sent ARP Reply packet\n",
-			   tx_slave ? tx_slave->dev->name : "NULL");
-	} else if (arp->op_code == htons(ARPOP_REQUEST)) {
-		/* Create an entry in the rx_hashtbl for this client as a
-		 * place holder.
-		 * When the arp reply is received the entry will be updated
-		 * with the correct unicast address of the client.
-		 */
-		tx_slave = rlb_choose_channel(skb, bond, arp);
-
-		/* The ARP reply packets must be delayed so that
-		 * they can cancel out the influence of the ARP request.
-		 */
-		bond->alb_info.rlb_update_delay_counter = RLB_UPDATE_DELAY;
-
-		/* arp requests are broadcast and are sent on the primary
-		 * the arp request will collapse all clients on the subnet to
-		 * the primary slave. We must register these clients to be
-		 * updated with their assigned mac.
-		 */
-		rlb_req_update_subnet_clients(bond, arp->ip_src);
-		netdev_dbg(bond->dev, "(slave %s): Server sent ARP Request packet\n",
-			   tx_slave ? tx_slave->dev->name : "NULL");
-	}
-
-	return tx_slave;
-}
-
-static void rlb_rebalance(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *assigned_slave;
-	struct rlb_client_info *client_info;
-	int ntt;
-	u32 hash_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	ntt = 0;
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		assigned_slave = __rlb_next_rx_slave(bond);
-		if (assigned_slave && (client_info->slave != assigned_slave)) {
-			client_info->slave = assigned_slave;
-			if (!is_zero_ether_addr(client_info->mac_dst)) {
-				client_info->ntt = 1;
-				ntt = 1;
-			}
-		}
-	}
-
-	/* update the team's flag only after the whole iteration */
-	if (ntt)
-		bond_info->rx_ntt = 1;
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/* Caller must hold mode_lock */
-static void rlb_init_table_entry_dst(struct rlb_client_info *entry)
-{
-	entry->used_next = RLB_NULL_INDEX;
-	entry->used_prev = RLB_NULL_INDEX;
-	entry->assigned = 0;
-	entry->slave = NULL;
-	entry->vlan_id = 0;
-}
-static void rlb_init_table_entry_src(struct rlb_client_info *entry)
-{
-	entry->src_first = RLB_NULL_INDEX;
-	entry->src_prev = RLB_NULL_INDEX;
-	entry->src_next = RLB_NULL_INDEX;
-}
-
-static void rlb_init_table_entry(struct rlb_client_info *entry)
-{
-	memset(entry, 0, sizeof(struct rlb_client_info));
-	rlb_init_table_entry_dst(entry);
-	rlb_init_table_entry_src(entry);
-}
-
-static void rlb_delete_table_entry_dst(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next_index = bond_info->rx_hashtbl[index].used_next;
-	u32 prev_index = bond_info->rx_hashtbl[index].used_prev;
-
-	if (index == bond_info->rx_hashtbl_used_head)
-		bond_info->rx_hashtbl_used_head = next_index;
-	if (prev_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[prev_index].used_next = next_index;
-	if (next_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next_index].used_prev = prev_index;
-}
-
-/* unlink a rlb hash table entry from the src list */
-static void rlb_src_unlink(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next_index = bond_info->rx_hashtbl[index].src_next;
-	u32 prev_index = bond_info->rx_hashtbl[index].src_prev;
-
-	bond_info->rx_hashtbl[index].src_next = RLB_NULL_INDEX;
-	bond_info->rx_hashtbl[index].src_prev = RLB_NULL_INDEX;
-
-	if (next_index != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next_index].src_prev = prev_index;
-
-	if (prev_index == RLB_NULL_INDEX)
-		return;
-
-	/* is prev_index pointing to the head of this list? */
-	if (bond_info->rx_hashtbl[prev_index].src_first == index)
-		bond_info->rx_hashtbl[prev_index].src_first = next_index;
-	else
-		bond_info->rx_hashtbl[prev_index].src_next = next_index;
-
-}
-
-static void rlb_delete_table_entry(struct bonding *bond, u32 index)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
-
-	rlb_delete_table_entry_dst(bond, index);
-	rlb_init_table_entry_dst(entry);
-
-	rlb_src_unlink(bond, index);
-}
-
-/* add the rx_hashtbl[ip_dst_hash] entry to the list
- * of entries with identical ip_src_hash
- */
-static void rlb_src_link(struct bonding *bond, u32 ip_src_hash, u32 ip_dst_hash)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 next;
-
-	bond_info->rx_hashtbl[ip_dst_hash].src_prev = ip_src_hash;
-	next = bond_info->rx_hashtbl[ip_src_hash].src_first;
-	bond_info->rx_hashtbl[ip_dst_hash].src_next = next;
-	if (next != RLB_NULL_INDEX)
-		bond_info->rx_hashtbl[next].src_prev = ip_dst_hash;
-	bond_info->rx_hashtbl[ip_src_hash].src_first = ip_dst_hash;
-}
-
-/* deletes all rx_hashtbl entries with arp->ip_src if their mac_src does
- * not match arp->mac_src
- */
-static void rlb_purge_src_ip(struct bonding *bond, struct arp_pkt *arp)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 ip_src_hash = _simple_hash((u8 *)&(arp->ip_src), sizeof(arp->ip_src));
-	u32 index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	index = bond_info->rx_hashtbl[ip_src_hash].src_first;
-	while (index != RLB_NULL_INDEX) {
-		struct rlb_client_info *entry = &(bond_info->rx_hashtbl[index]);
-		u32 next_index = entry->src_next;
-		if (entry->ip_src == arp->ip_src &&
-		    !ether_addr_equal_64bits(arp->mac_src, entry->mac_src))
-				rlb_delete_table_entry(bond, index);
-		index = next_index;
-	}
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static int rlb_initialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info	*new_hashtbl;
-	int size = RLB_HASH_TABLE_SIZE * sizeof(struct rlb_client_info);
-	int i;
-
-	new_hashtbl = kmalloc(size, GFP_KERNEL);
-	if (!new_hashtbl)
-		return -1;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	bond_info->rx_hashtbl = new_hashtbl;
-
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	for (i = 0; i < RLB_HASH_TABLE_SIZE; i++)
-		rlb_init_table_entry(bond_info->rx_hashtbl + i);
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	/* register to receive ARPs */
-	bond->recv_probe = rlb_arp_recv;
-
-	return 0;
-}
-
-static void rlb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	spin_lock_bh(&bond->mode_lock);
-
-	kfree(bond_info->rx_hashtbl);
-	bond_info->rx_hashtbl = NULL;
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-static void rlb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	u32 curr_index;
-
-	spin_lock_bh(&bond->mode_lock);
-
-	curr_index = bond_info->rx_hashtbl_used_head;
-	while (curr_index != RLB_NULL_INDEX) {
-		struct rlb_client_info *curr = &(bond_info->rx_hashtbl[curr_index]);
-		u32 next_index = bond_info->rx_hashtbl[curr_index].used_next;
-
-		if (curr->vlan_id == vlan_id)
-			rlb_delete_table_entry(bond, curr_index);
-
-		curr_index = next_index;
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-}
-
-/*********************** tlb/rlb shared functions *********************/
-
-static void alb_send_lp_vid(struct slave *slave, u8 mac_addr[],
-			    __be16 vlan_proto, u16 vid)
-{
-	struct learning_pkt pkt;
-	struct sk_buff *skb;
-	int size = sizeof(struct learning_pkt);
-
-	memset(&pkt, 0, size);
-	ether_addr_copy(pkt.mac_dst, mac_addr);
-	ether_addr_copy(pkt.mac_src, mac_addr);
-	pkt.type = cpu_to_be16(ETH_P_LOOPBACK);
-
-	skb = dev_alloc_skb(size);
-	if (!skb)
-		return;
-
-	skb_put_data(skb, &pkt, size);
-
-	skb_reset_mac_header(skb);
-	skb->network_header = skb->mac_header + ETH_HLEN;
-	skb->protocol = pkt.type;
-	skb->priority = TC_PRIO_CONTROL;
-	skb->dev = slave->dev;
-
-	slave_dbg(slave->bond->dev, slave->dev,
-		  "Send learning packet: mac %pM vlan %d\n", mac_addr, vid);
-
-	if (vid)
-		__vlan_hwaccel_put_tag(skb, vlan_proto, vid);
-
-	dev_queue_xmit(skb);
-}
-
-struct alb_walk_data {
-	struct bonding *bond;
-	struct slave *slave;
-	u8 *mac_addr;
-	bool strict_match;
-};
-
-static int alb_upper_dev_walk(struct net_device *upper, void *_data)
-{
-	struct alb_walk_data *data = _data;
-	bool strict_match = data->strict_match;
-	struct bonding *bond = data->bond;
-	struct slave *slave = data->slave;
-	u8 *mac_addr = data->mac_addr;
-	struct bond_vlan_tag *tags;
-
-	if (is_vlan_dev(upper) &&
-	    bond->dev->lower_level == upper->lower_level - 1) {
-		if (upper->addr_assign_type == NET_ADDR_STOLEN) {
-			alb_send_lp_vid(slave, mac_addr,
-					vlan_dev_vlan_proto(upper),
-					vlan_dev_vlan_id(upper));
-		} else {
-			alb_send_lp_vid(slave, upper->dev_addr,
-					vlan_dev_vlan_proto(upper),
-					vlan_dev_vlan_id(upper));
-		}
-	}
-
-	/* If this is a macvlan device, then only send updates
-	 * when strict_match is turned off.
-	 */
-	if (netif_is_macvlan(upper) && !strict_match) {
-		tags = bond_verify_device_path(bond->dev, upper, 0);
-		if (IS_ERR_OR_NULL(tags))
-			BUG();
-		alb_send_lp_vid(slave, upper->dev_addr,
-				tags[0].vlan_proto, tags[0].vlan_id);
-		kfree(tags);
-	}
-
-	return 0;
-}
-
-static void alb_send_learning_packets(struct slave *slave, u8 mac_addr[],
-				      bool strict_match)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-	struct alb_walk_data data = {
-		.strict_match = strict_match,
-		.mac_addr = mac_addr,
-		.slave = slave,
-		.bond = bond,
-	};
-
-	/* send untagged */
-	alb_send_lp_vid(slave, mac_addr, 0, 0);
-
-	/* loop through all devices and see if we need to send a packet
-	 * for that device.
-	 */
-	rcu_read_lock();
-	netdev_walk_all_upper_dev_rcu(bond->dev, alb_upper_dev_walk, &data);
-	rcu_read_unlock();
-}
-
-static int alb_set_slave_mac_addr(struct slave *slave, u8 addr[],
-				  unsigned int len)
-{
-	struct net_device *dev = slave->dev;
-	struct sockaddr_storage ss;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_TLB) {
-		memcpy(dev->dev_addr, addr, len);
-		return 0;
-	}
-
-	/* for rlb each slave must have a unique hw mac addresses so that
-	 * each slave will receive packets destined to a different mac
-	 */
-	memcpy(ss.__data, addr, len);
-	ss.ss_family = dev->type;
-	if (dev_set_mac_address(dev, (struct sockaddr *)&ss, NULL)) {
-		slave_err(slave->bond->dev, dev, "dev_set_mac_address on slave failed! ALB mode requires that the base driver support setting the hw address also when the network device's interface is open\n");
-		return -EOPNOTSUPP;
-	}
-	return 0;
-}
-
-/* Swap MAC addresses between two slaves.
- *
- * Called with RTNL held, and no other locks.
- */
-static void alb_swap_mac_addr(struct slave *slave1, struct slave *slave2)
-{
-	u8 tmp_mac_addr[MAX_ADDR_LEN];
-
-	bond_hw_addr_copy(tmp_mac_addr, slave1->dev->dev_addr,
-			  slave1->dev->addr_len);
-	alb_set_slave_mac_addr(slave1, slave2->dev->dev_addr,
-			       slave2->dev->addr_len);
-	alb_set_slave_mac_addr(slave2, tmp_mac_addr,
-			       slave1->dev->addr_len);
-
-}
-
-/* Send learning packets after MAC address swap.
- *
- * Called with RTNL and no other locks
- */
-static void alb_fasten_mac_swap(struct bonding *bond, struct slave *slave1,
-				struct slave *slave2)
-{
-	int slaves_state_differ = (bond_slave_can_tx(slave1) != bond_slave_can_tx(slave2));
-	struct slave *disabled_slave = NULL;
-
-	ASSERT_RTNL();
-
-	/* fasten the change in the switch */
-	if (bond_slave_can_tx(slave1)) {
-		alb_send_learning_packets(slave1, slave1->dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform the clients that the mac address
-			 * has changed
-			 */
-			rlb_req_update_slave_clients(bond, slave1);
-		}
-	} else {
-		disabled_slave = slave1;
-	}
-
-	if (bond_slave_can_tx(slave2)) {
-		alb_send_learning_packets(slave2, slave2->dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform the clients that the mac address
-			 * has changed
-			 */
-			rlb_req_update_slave_clients(bond, slave2);
-		}
-	} else {
-		disabled_slave = slave2;
-	}
-
-	if (bond->alb_info.rlb_enabled && slaves_state_differ) {
-		/* A disabled slave was assigned an active mac addr */
-		rlb_teach_disabled_mac_on_primary(bond,
-						  disabled_slave->dev->dev_addr);
-	}
-}
-
-/**
- * alb_change_hw_addr_on_detach
- * @bond: bonding we're working on
- * @slave: the slave that was just detached
- *
- * We assume that @slave was already detached from the slave list.
- *
- * If @slave's permanent hw address is different both from its current
- * address and from @bond's address, then somewhere in the bond there's
- * a slave that has @slave's permanet address as its current address.
- * We'll make sure that that slave no longer uses @slave's permanent address.
- *
- * Caller must hold RTNL and no other locks
- */
-static void alb_change_hw_addr_on_detach(struct bonding *bond, struct slave *slave)
-{
-	int perm_curr_diff;
-	int perm_bond_diff;
-	struct slave *found_slave;
-
-	perm_curr_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
-						  slave->dev->dev_addr);
-	perm_bond_diff = !ether_addr_equal_64bits(slave->perm_hwaddr,
-						  bond->dev->dev_addr);
-
-	if (perm_curr_diff && perm_bond_diff) {
-		found_slave = bond_slave_has_mac(bond, slave->perm_hwaddr);
-
-		if (found_slave) {
-			alb_swap_mac_addr(slave, found_slave);
-			alb_fasten_mac_swap(bond, slave, found_slave);
-		}
-	}
-}
-
-/**
- * alb_handle_addr_collision_on_attach
- * @bond: bonding we're working on
- * @slave: the slave that was just attached
- *
- * checks uniqueness of slave's mac address and handles the case the
- * new slave uses the bonds mac address.
- *
- * If the permanent hw address of @slave is @bond's hw address, we need to
- * find a different hw address to give @slave, that isn't in use by any other
- * slave in the bond. This address must be, of course, one of the permanent
- * addresses of the other slaves.
- *
- * We go over the slave list, and for each slave there we compare its
- * permanent hw address with the current address of all the other slaves.
- * If no match was found, then we've found a slave with a permanent address
- * that isn't used by any other slave in the bond, so we can assign it to
- * @slave.
- *
- * assumption: this function is called before @slave is attached to the
- *	       bond slave list.
- */
-static int alb_handle_addr_collision_on_attach(struct bonding *bond, struct slave *slave)
-{
-	struct slave *has_bond_addr = rcu_access_pointer(bond->curr_active_slave);
-	struct slave *tmp_slave1, *free_mac_slave = NULL;
-	struct list_head *iter;
-
-	if (!bond_has_slaves(bond)) {
-		/* this is the first slave */
-		return 0;
-	}
-
-	/* if slave's mac address differs from bond's mac address
-	 * check uniqueness of slave's mac address against the other
-	 * slaves in the bond.
-	 */
-	if (!ether_addr_equal_64bits(slave->perm_hwaddr, bond->dev->dev_addr)) {
-		if (!bond_slave_has_mac(bond, slave->dev->dev_addr))
-			return 0;
-
-		/* Try setting slave mac to bond address and fall-through
-		 * to code handling that situation below...
-		 */
-		alb_set_slave_mac_addr(slave, bond->dev->dev_addr,
-				       bond->dev->addr_len);
-	}
-
-	/* The slave's address is equal to the address of the bond.
-	 * Search for a spare address in the bond for this slave.
-	 */
-	bond_for_each_slave(bond, tmp_slave1, iter) {
-		if (!bond_slave_has_mac(bond, tmp_slave1->perm_hwaddr)) {
-			/* no slave has tmp_slave1's perm addr
-			 * as its curr addr
-			 */
-			free_mac_slave = tmp_slave1;
-			break;
-		}
-
-		if (!has_bond_addr) {
-			if (ether_addr_equal_64bits(tmp_slave1->dev->dev_addr,
-						    bond->dev->dev_addr)) {
-
-				has_bond_addr = tmp_slave1;
-			}
-		}
-	}
-
-	if (free_mac_slave) {
-		alb_set_slave_mac_addr(slave, free_mac_slave->perm_hwaddr,
-				       free_mac_slave->dev->addr_len);
-
-		slave_warn(bond->dev, slave->dev, "the slave hw address is in use by the bond; giving it the hw address of %s\n",
-			   free_mac_slave->dev->name);
-
-	} else if (has_bond_addr) {
-		slave_err(bond->dev, slave->dev, "the slave hw address is in use by the bond; couldn't find a slave with a free hw address to give it (this should not have happened)\n");
-		return -EFAULT;
-	}
-
-	return 0;
-}
-
-/**
- * alb_set_mac_address
- * @bond:
- * @addr:
- *
- * In TLB mode all slaves are configured to the bond's hw address, but set
- * their dev_addr field to different addresses (based on their permanent hw
- * addresses).
- *
- * For each slave, this function sets the interface to the new address and then
- * changes its dev_addr field to its previous value.
- *
- * Unwinding assumes bond's mac address has not yet changed.
- */
-static int alb_set_mac_address(struct bonding *bond, void *addr)
-{
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	struct sockaddr_storage ss;
-	char tmp_addr[MAX_ADDR_LEN];
-	int res;
-
-	if (bond->alb_info.rlb_enabled)
-		return 0;
-
-	bond_for_each_slave(bond, slave, iter) {
-		/* save net_device's current hw address */
-		bond_hw_addr_copy(tmp_addr, slave->dev->dev_addr,
-				  slave->dev->addr_len);
-
-		res = dev_set_mac_address(slave->dev, addr, NULL);
-
-		/* restore net_device's hw address */
-		bond_hw_addr_copy(slave->dev->dev_addr, tmp_addr,
-				  slave->dev->addr_len);
-
-		if (res)
-			goto unwind;
-	}
-
-	return 0;
-
-unwind:
-	memcpy(ss.__data, bond->dev->dev_addr, bond->dev->addr_len);
-	ss.ss_family = bond->dev->type;
-
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		if (rollback_slave == slave)
-			break;
-		bond_hw_addr_copy(tmp_addr, rollback_slave->dev->dev_addr,
-				  rollback_slave->dev->addr_len);
-		dev_set_mac_address(rollback_slave->dev,
-				    (struct sockaddr *)&ss, NULL);
-		bond_hw_addr_copy(rollback_slave->dev->dev_addr, tmp_addr,
-				  rollback_slave->dev->addr_len);
-	}
-
-	return res;
-}
-
-/************************ exported alb funcions ************************/
-
-int bond_alb_initialize(struct bonding *bond, int rlb_enabled)
-{
-	int res;
-
-	res = tlb_initialize(bond);
-	if (res)
-		return res;
-
-	if (rlb_enabled) {
-		bond->alb_info.rlb_enabled = 1;
-		res = rlb_initialize(bond);
-		if (res) {
-			tlb_deinitialize(bond);
-			return res;
-		}
-	} else {
-		bond->alb_info.rlb_enabled = 0;
-	}
-
-	return 0;
-}
-
-void bond_alb_deinitialize(struct bonding *bond)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	tlb_deinitialize(bond);
-
-	if (bond_info->rlb_enabled)
-		rlb_deinitialize(bond);
-}
-
-static netdev_tx_t bond_do_alb_xmit(struct sk_buff *skb, struct bonding *bond,
-				    struct slave *tx_slave)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct ethhdr *eth_data = eth_hdr(skb);
-
-	if (!tx_slave) {
-		/* unbalanced or unassigned, send through primary */
-		tx_slave = rcu_dereference(bond->curr_active_slave);
-		if (bond->params.tlb_dynamic_lb)
-			bond_info->unbalanced_load += skb->len;
-	}
-
-	if (tx_slave && bond_slave_can_tx(tx_slave)) {
-		if (tx_slave != rcu_access_pointer(bond->curr_active_slave)) {
-			ether_addr_copy(eth_data->h_source,
-					tx_slave->dev->dev_addr);
-		}
-
-		bond_dev_queue_xmit(bond, skb, tx_slave->dev);
-		goto out;
-	}
-
-	if (tx_slave && bond->params.tlb_dynamic_lb) {
-		spin_lock(&bond->mode_lock);
-		__tlb_clear_slave(bond, tx_slave, 0);
-		spin_unlock(&bond->mode_lock);
-	}
-
-	/* no suitable interface, frame not sent */
-	bond_tx_drop(bond->dev, skb);
-out:
-	return NETDEV_TX_OK;
-}
-
-netdev_tx_t bond_tlb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct ethhdr *eth_data;
-	struct slave *tx_slave = NULL;
-	u32 hash_index;
-
-	skb_reset_mac_header(skb);
-	eth_data = eth_hdr(skb);
-
-	/* Do not TX balance any multicast or broadcast */
-	if (!is_multicast_ether_addr(eth_data->h_dest)) {
-		switch (skb->protocol) {
-		case htons(ETH_P_IP):
-		case htons(ETH_P_IPX):
-		    /* In case of IPX, it will falback to L2 hash */
-		case htons(ETH_P_IPV6):
-			hash_index = bond_xmit_hash(bond, skb);
-			if (bond->params.tlb_dynamic_lb) {
-				tx_slave = tlb_choose_channel(bond,
-							      hash_index & 0xFF,
-							      skb->len);
-			} else {
-				struct bond_up_slave *slaves;
-				unsigned int count;
-
-				slaves = rcu_dereference(bond->slave_arr);
-				count = slaves ? READ_ONCE(slaves->count) : 0;
-				if (likely(count))
-					tx_slave = slaves->arr[hash_index %
-							       count];
-			}
-			break;
-		}
-	}
-	return bond_do_alb_xmit(skb, bond, tx_slave);
-}
-
-netdev_tx_t bond_alb_xmit(struct sk_buff *skb, struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct ethhdr *eth_data;
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct slave *tx_slave = NULL;
-	static const __be32 ip_bcast = htonl(0xffffffff);
-	int hash_size = 0;
-	bool do_tx_balance = true;
-	u32 hash_index = 0;
-	const u8 *hash_start = NULL;
-
-	skb_reset_mac_header(skb);
-	eth_data = eth_hdr(skb);
-
-	switch (ntohs(skb->protocol)) {
-	case ETH_P_IP: {
-		const struct iphdr *iph;
-
-		if (is_broadcast_ether_addr(eth_data->h_dest) ||
-		    !pskb_network_may_pull(skb, sizeof(*iph))) {
-			do_tx_balance = false;
-			break;
-		}
-		iph = ip_hdr(skb);
-		if (iph->daddr == ip_bcast || iph->protocol == IPPROTO_IGMP) {
-			do_tx_balance = false;
-			break;
-		}
-		hash_start = (char *)&(iph->daddr);
-		hash_size = sizeof(iph->daddr);
-		break;
-	}
-	case ETH_P_IPV6: {
-		const struct ipv6hdr *ip6hdr;
-
-		/* IPv6 doesn't really use broadcast mac address, but leave
-		 * that here just in case.
-		 */
-		if (is_broadcast_ether_addr(eth_data->h_dest)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		/* IPv6 uses all-nodes multicast as an equivalent to
-		 * broadcasts in IPv4.
-		 */
-		if (ether_addr_equal_64bits(eth_data->h_dest, mac_v6_allmcast)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		if (!pskb_network_may_pull(skb, sizeof(*ip6hdr))) {
-			do_tx_balance = false;
-			break;
-		}
-		/* Additionally, DAD probes should not be tx-balanced as that
-		 * will lead to false positives for duplicate addresses and
-		 * prevent address configuration from working.
-		 */
-		ip6hdr = ipv6_hdr(skb);
-		if (ipv6_addr_any(&ip6hdr->saddr)) {
-			do_tx_balance = false;
-			break;
-		}
-
-		hash_start = (char *)&ip6hdr->daddr;
-		hash_size = sizeof(ip6hdr->daddr);
-		break;
-	}
-	case ETH_P_IPX: {
-		const struct ipxhdr *ipxhdr;
-
-		if (pskb_network_may_pull(skb, sizeof(*ipxhdr))) {
-			do_tx_balance = false;
-			break;
-		}
-		ipxhdr = (struct ipxhdr *)skb_network_header(skb);
-
-		if (ipxhdr->ipx_checksum != IPX_NO_CHECKSUM) {
-			/* something is wrong with this packet */
-			do_tx_balance = false;
-			break;
-		}
-
-		if (ipxhdr->ipx_type != IPX_TYPE_NCP) {
-			/* The only protocol worth balancing in
-			 * this family since it has an "ARP" like
-			 * mechanism
-			 */
-			do_tx_balance = false;
-			break;
-		}
-
-		eth_data = eth_hdr(skb);
-		hash_start = (char *)eth_data->h_dest;
-		hash_size = ETH_ALEN;
-		break;
-	}
-	case ETH_P_ARP:
-		do_tx_balance = false;
-		if (bond_info->rlb_enabled)
-			tx_slave = rlb_arp_xmit(skb, bond);
-		break;
-	default:
-		do_tx_balance = false;
-		break;
-	}
-
-	if (do_tx_balance) {
-		if (bond->params.tlb_dynamic_lb) {
-			hash_index = _simple_hash(hash_start, hash_size);
-			tx_slave = tlb_choose_channel(bond, hash_index, skb->len);
-		} else {
-			/*
-			 * do_tx_balance means we are free to select the tx_slave
-			 * So we do exactly what tlb would do for hash selection
-			 */
-
-			struct bond_up_slave *slaves;
-			unsigned int count;
-
-			slaves = rcu_dereference(bond->slave_arr);
-			count = slaves ? READ_ONCE(slaves->count) : 0;
-			if (likely(count))
-				tx_slave = slaves->arr[bond_xmit_hash(bond, skb) %
-						       count];
-		}
-	}
-
-	return bond_do_alb_xmit(skb, bond, tx_slave);
-}
-
-void bond_alb_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    alb_work.work);
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (!bond_has_slaves(bond)) {
-		bond_info->tx_rebalance_counter = 0;
-		bond_info->lp_counter = 0;
-		goto re_arm;
-	}
-
-	rcu_read_lock();
-
-	bond_info->tx_rebalance_counter++;
-	bond_info->lp_counter++;
-
-	/* send learning packets */
-	if (bond_info->lp_counter >= BOND_ALB_LP_TICKS(bond)) {
-		bool strict_match;
-
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			/* If updating current_active, use all currently
-			 * user mac addreses (!strict_match).  Otherwise, only
-			 * use mac of the slave device.
-			 * In RLB mode, we always use strict matches.
-			 */
-			strict_match = (slave != rcu_access_pointer(bond->curr_active_slave) ||
-					bond_info->rlb_enabled);
-			alb_send_learning_packets(slave, slave->dev->dev_addr,
-						  strict_match);
-		}
-		bond_info->lp_counter = 0;
-	}
-
-	/* rebalance tx traffic */
-	if (bond_info->tx_rebalance_counter >= BOND_TLB_REBALANCE_TICKS) {
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			tlb_clear_slave(bond, slave, 1);
-			if (slave == rcu_access_pointer(bond->curr_active_slave)) {
-				SLAVE_TLB_INFO(slave).load =
-					bond_info->unbalanced_load /
-						BOND_TLB_REBALANCE_INTERVAL;
-				bond_info->unbalanced_load = 0;
-			}
-		}
-		bond_info->tx_rebalance_counter = 0;
-	}
-
-	if (bond_info->rlb_enabled) {
-		if (bond_info->primary_is_promisc &&
-		    (++bond_info->rlb_promisc_timeout_counter >= RLB_PROMISC_TIMEOUT)) {
-
-			/* dev_set_promiscuity requires rtnl and
-			 * nothing else.  Avoid race with bond_close.
-			 */
-			rcu_read_unlock();
-			if (!rtnl_trylock())
-				goto re_arm;
-
-			bond_info->rlb_promisc_timeout_counter = 0;
-
-			/* If the primary was set to promiscuous mode
-			 * because a slave was disabled then
-			 * it can now leave promiscuous mode.
-			 */
-			dev_set_promiscuity(rtnl_dereference(bond->curr_active_slave)->dev,
-					    -1);
-			bond_info->primary_is_promisc = 0;
-
-			rtnl_unlock();
-			rcu_read_lock();
-		}
-
-		if (bond_info->rlb_rebalance) {
-			bond_info->rlb_rebalance = 0;
-			rlb_rebalance(bond);
-		}
-
-		/* check if clients need updating */
-		if (bond_info->rx_ntt) {
-			if (bond_info->rlb_update_delay_counter) {
-				--bond_info->rlb_update_delay_counter;
-			} else {
-				rlb_update_rx_clients(bond);
-				if (bond_info->rlb_update_retry_counter)
-					--bond_info->rlb_update_retry_counter;
-				else
-					bond_info->rx_ntt = 0;
-			}
-		}
-	}
-	rcu_read_unlock();
-re_arm:
-	queue_delayed_work(bond->wq, &bond->alb_work, alb_delta_in_ticks);
-}
-
-/* assumption: called before the slave is attached to the bond
- * and not locked by the bond lock
- */
-int bond_alb_init_slave(struct bonding *bond, struct slave *slave)
-{
-	int res;
-
-	res = alb_set_slave_mac_addr(slave, slave->perm_hwaddr,
-				     slave->dev->addr_len);
-	if (res)
-		return res;
-
-	res = alb_handle_addr_collision_on_attach(bond, slave);
-	if (res)
-		return res;
-
-	tlb_init_slave(slave);
-
-	/* order a rebalance ASAP */
-	bond->alb_info.tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
-
-	if (bond->alb_info.rlb_enabled)
-		bond->alb_info.rlb_rebalance = 1;
-
-	return 0;
-}
-
-/* Remove slave from tlb and rlb hash tables, and fix up MAC addresses
- * if necessary.
- *
- * Caller must hold RTNL and no other locks
- */
-void bond_alb_deinit_slave(struct bonding *bond, struct slave *slave)
-{
-	if (bond_has_slaves(bond))
-		alb_change_hw_addr_on_detach(bond, slave);
-
-	tlb_clear_slave(bond, slave, 0);
-
-	if (bond->alb_info.rlb_enabled) {
-		bond->alb_info.rx_slave = NULL;
-		rlb_clear_slave(bond, slave);
-	}
-
-}
-
-void bond_alb_handle_link_change(struct bonding *bond, struct slave *slave, char link)
-{
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-
-	if (link == BOND_LINK_DOWN) {
-		tlb_clear_slave(bond, slave, 0);
-		if (bond->alb_info.rlb_enabled)
-			rlb_clear_slave(bond, slave);
-	} else if (link == BOND_LINK_UP) {
-		/* order a rebalance ASAP */
-		bond_info->tx_rebalance_counter = BOND_TLB_REBALANCE_TICKS;
-		if (bond->alb_info.rlb_enabled) {
-			bond->alb_info.rlb_rebalance = 1;
-			/* If the updelay module parameter is smaller than the
-			 * forwarding delay of the switch the rebalance will
-			 * not work because the rebalance arp replies will
-			 * not be forwarded to the clients..
-			 */
-		}
-	}
-
-	if (bond_is_nondyn_tlb(bond)) {
-		if (bond_update_slave_arr(bond, NULL))
-			pr_err("Failed to build slave-array for TLB mode.\n");
-	}
-}
-
-/**
- * bond_alb_handle_active_change - assign new curr_active_slave
- * @bond: our bonding struct
- * @new_slave: new slave to assign
- *
- * Set the bond->curr_active_slave to @new_slave and handle
- * mac address swapping and promiscuity changes as needed.
- *
- * Caller must hold RTNL
- */
-void bond_alb_handle_active_change(struct bonding *bond, struct slave *new_slave)
-{
-	struct slave *swap_slave;
-	struct slave *curr_active;
-
-	curr_active = rtnl_dereference(bond->curr_active_slave);
-	if (curr_active == new_slave)
-		return;
-
-	if (curr_active && bond->alb_info.primary_is_promisc) {
-		dev_set_promiscuity(curr_active->dev, -1);
-		bond->alb_info.primary_is_promisc = 0;
-		bond->alb_info.rlb_promisc_timeout_counter = 0;
-	}
-
-	swap_slave = curr_active;
-	rcu_assign_pointer(bond->curr_active_slave, new_slave);
-
-	if (!new_slave || !bond_has_slaves(bond))
-		return;
-
-	/* set the new curr_active_slave to the bonds mac address
-	 * i.e. swap mac addresses of old curr_active_slave and new curr_active_slave
-	 */
-	if (!swap_slave)
-		swap_slave = bond_slave_has_mac(bond, bond->dev->dev_addr);
-
-	/* Arrange for swap_slave and new_slave to temporarily be
-	 * ignored so we can mess with their MAC addresses without
-	 * fear of interference from transmit activity.
-	 */
-	if (swap_slave)
-		tlb_clear_slave(bond, swap_slave, 1);
-	tlb_clear_slave(bond, new_slave, 1);
-
-	/* in TLB mode, the slave might flip down/up with the old dev_addr,
-	 * and thus filter bond->dev_addr's packets, so force bond's mac
-	 */
-	if (BOND_MODE(bond) == BOND_MODE_TLB) {
-		struct sockaddr_storage ss;
-		u8 tmp_addr[MAX_ADDR_LEN];
-
-		bond_hw_addr_copy(tmp_addr, new_slave->dev->dev_addr,
-				  new_slave->dev->addr_len);
-
-		bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
-				  bond->dev->addr_len);
-		ss.ss_family = bond->dev->type;
-		/* we don't care if it can't change its mac, best effort */
-		dev_set_mac_address(new_slave->dev, (struct sockaddr *)&ss,
-				    NULL);
-
-		bond_hw_addr_copy(new_slave->dev->dev_addr, tmp_addr,
-				  new_slave->dev->addr_len);
-	}
-
-	/* curr_active_slave must be set before calling alb_swap_mac_addr */
-	if (swap_slave) {
-		/* swap mac address */
-		alb_swap_mac_addr(swap_slave, new_slave);
-		alb_fasten_mac_swap(bond, swap_slave, new_slave);
-	} else {
-		/* set the new_slave to the bond mac address */
-		alb_set_slave_mac_addr(new_slave, bond->dev->dev_addr,
-				       bond->dev->addr_len);
-		alb_send_learning_packets(new_slave, bond->dev->dev_addr,
-					  false);
-	}
-}
-
-/* Called with RTNL */
-int bond_alb_set_mac_address(struct net_device *bond_dev, void *addr)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct sockaddr_storage *ss = addr;
-	struct slave *curr_active;
-	struct slave *swap_slave;
-	int res;
-
-	if (!is_valid_ether_addr(ss->__data))
-		return -EADDRNOTAVAIL;
-
-	res = alb_set_mac_address(bond, addr);
-	if (res)
-		return res;
-
-	bond_hw_addr_copy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
-
-	/* If there is no curr_active_slave there is nothing else to do.
-	 * Otherwise we'll need to pass the new address to it and handle
-	 * duplications.
-	 */
-	curr_active = rtnl_dereference(bond->curr_active_slave);
-	if (!curr_active)
-		return 0;
-
-	swap_slave = bond_slave_has_mac(bond, bond_dev->dev_addr);
-
-	if (swap_slave) {
-		alb_swap_mac_addr(swap_slave, curr_active);
-		alb_fasten_mac_swap(bond, swap_slave, curr_active);
-	} else {
-		alb_set_slave_mac_addr(curr_active, bond_dev->dev_addr,
-				       bond_dev->addr_len);
-
-		alb_send_learning_packets(curr_active,
-					  bond_dev->dev_addr, false);
-		if (bond->alb_info.rlb_enabled) {
-			/* inform clients mac address has changed */
-			rlb_req_update_slave_clients(bond, curr_active);
-		}
-	}
-
-	return 0;
-}
-
-void bond_alb_clear_vlan(struct bonding *bond, unsigned short vlan_id)
-{
-	if (bond->alb_info.rlb_enabled)
-		rlb_clear_vlan(bond, vlan_id);
-}
-
diff -r 30 src/network/bonding/BONDING_KDIRS/5.6.0/bond_debugfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.6.0/bond_debugfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,125 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/device.h>
-#include <linux/netdevice.h>
-
-#include <net/bonding.h>
-#include <net/bond_alb.h>
-
-#if defined(CONFIG_DEBUG_FS) && !defined(CONFIG_NET_NS)
-
-#include <linux/debugfs.h>
-#include <linux/seq_file.h>
-
-static struct dentry *bonding_debug_root;
-
-/* Show RLB hash table */
-static int bond_debug_rlb_hash_show(struct seq_file *m, void *v)
-{
-	struct bonding *bond = m->private;
-	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));
-	struct rlb_client_info *client_info;
-	u32 hash_index;
-
-	if (BOND_MODE(bond) != BOND_MODE_ALB)
-		return 0;
-
-	seq_printf(m, "SourceIP        DestinationIP   "
-			"Destination MAC   DEV\n");
-
-	spin_lock_bh(&bond->mode_lock);
-
-	hash_index = bond_info->rx_hashtbl_used_head;
-	for (; hash_index != RLB_NULL_INDEX;
-	     hash_index = client_info->used_next) {
-		client_info = &(bond_info->rx_hashtbl[hash_index]);
-		seq_printf(m, "%-15pI4 %-15pI4 %-17pM %s\n",
-			&client_info->ip_src,
-			&client_info->ip_dst,
-			&client_info->mac_dst,
-			client_info->slave->dev->name);
-	}
-
-	spin_unlock_bh(&bond->mode_lock);
-
-	return 0;
-}
-DEFINE_SHOW_ATTRIBUTE(bond_debug_rlb_hash);
-
-void bond_debug_register(struct bonding *bond)
-{
-	if (!bonding_debug_root)
-		return;
-
-	bond->debug_dir =
-		debugfs_create_dir(bond->dev->name, bonding_debug_root);
-
-	debugfs_create_file("rlb_hash_table", 0400, bond->debug_dir,
-				bond, &bond_debug_rlb_hash_fops);
-}
-
-void bond_debug_unregister(struct bonding *bond)
-{
-	if (!bonding_debug_root)
-		return;
-
-	debugfs_remove_recursive(bond->debug_dir);
-}
-
-void bond_debug_reregister(struct bonding *bond)
-{
-	struct dentry *d;
-
-	if (!bonding_debug_root)
-		return;
-
-	d = debugfs_rename(bonding_debug_root, bond->debug_dir,
-			   bonding_debug_root, bond->dev->name);
-	if (d) {
-		bond->debug_dir = d;
-	} else {
-		netdev_warn(bond->dev, "failed to reregister, so just unregister old one\n");
-		bond_debug_unregister(bond);
-	}
-}
-
-void bond_create_debugfs(void)
-{
-	bonding_debug_root = debugfs_create_dir("bonding", NULL);
-
-	if (!bonding_debug_root) {
-		pr_warn("Warning: Cannot create bonding directory in debugfs\n");
-	}
-}
-
-void bond_destroy_debugfs(void)
-{
-	debugfs_remove_recursive(bonding_debug_root);
-	bonding_debug_root = NULL;
-}
-
-
-#else /* !CONFIG_DEBUG_FS */
-
-void bond_debug_register(struct bonding *bond)
-{
-}
-
-void bond_debug_unregister(struct bonding *bond)
-{
-}
-
-void bond_debug_reregister(struct bonding *bond)
-{
-}
-
-void bond_create_debugfs(void)
-{
-}
-
-void bond_destroy_debugfs(void)
-{
-}
-
-#endif /* CONFIG_DEBUG_FS */
diff -r 30 src/network/bonding/BONDING_KDIRS/5.6.0/bond_main.c
--- a/src/network/bonding/BONDING_KDIRS/5.6.0/bond_main.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,5178 +0,0 @@
-/*
- * originally based on the dummy device.
- *
- * Copyright 1999, Thomas Davis, tadavis@lbl.gov.
- * Licensed under the GPL. Based on dummy.c, and eql.c devices.
- *
- * bonding.c: an Ethernet Bonding driver
- *
- * This is useful to talk to a Cisco EtherChannel compatible equipment:
- *	Cisco 5500
- *	Sun Trunking (Solaris)
- *	Alteon AceDirector Trunks
- *	Linux Bonding
- *	and probably many L2 switches ...
- *
- * How it works:
- *    ifconfig bond0 ipaddress netmask up
- *      will setup a network device, with an ip address.  No mac address
- *	will be assigned at this time.  The hw mac address will come from
- *	the first slave bonded to the channel.  All slaves will then use
- *	this hw mac address.
- *
- *    ifconfig bond0 down
- *         will release all slaves, marking them as down.
- *
- *    ifenslave bond0 eth0
- *	will attach eth0 to bond0 as a slave.  eth0 hw mac address will either
- *	a: be used as initial mac address
- *	b: if a hw mac address already is there, eth0's hw mac address
- *	   will then be set from bond0.
- *
- */
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/types.h>
-#include <linux/fcntl.h>
-#include <linux/interrupt.h>
-#include <linux/ptrace.h>
-#include <linux/ioport.h>
-#include <linux/in.h>
-#include <net/ip.h>
-#include <linux/ip.h>
-#include <linux/icmp.h>
-#include <linux/icmpv6.h>
-#include <linux/tcp.h>
-#include <linux/udp.h>
-#include <linux/slab.h>
-#include <linux/string.h>
-#include <linux/init.h>
-#include <linux/timer.h>
-#include <linux/socket.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/bitops.h>
-#include <linux/io.h>
-#include <asm/dma.h>
-#include <linux/uaccess.h>
-#include <linux/errno.h>
-#include <linux/netdevice.h>
-#include <linux/inetdevice.h>
-#include <linux/igmp.h>
-#include <linux/etherdevice.h>
-#include <linux/skbuff.h>
-#include <net/sock.h>
-#include <linux/rtnetlink.h>
-#include <linux/smp.h>
-#include <linux/if_ether.h>
-#include <net/arp.h>
-#include <linux/mii.h>
-#include <linux/ethtool.h>
-#include <linux/if_vlan.h>
-#include <linux/if_bonding.h>
-#include <linux/jiffies.h>
-#include <linux/preempt.h>
-#include <net/route.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <net/pkt_sched.h>
-#include <linux/rculist.h>
-#include <linux/toedev.h>
-#include <net/flow_dissector.h>
-#include <net/bonding.h>
-#include <net/bond_3ad.h>
-#include <net/bond_alb.h>
-
-#include "bonding_priv.h"
-
-/*---------------------------- Module parameters ----------------------------*/
-
-/* monitor all links that often (in milliseconds). <=0 disables monitoring */
-
-static int max_bonds	= BOND_DEFAULT_MAX_BONDS;
-static int tx_queues	= BOND_DEFAULT_TX_QUEUES;
-static int num_peer_notif = 1;
-static int miimon;
-static int updelay;
-static int downdelay;
-static int use_carrier	= 1;
-static char *mode;
-static char *primary;
-static char *primary_reselect;
-static char *lacp_rate;
-static int min_links;
-static char *ad_select;
-static char *xmit_hash_policy;
-static int arp_interval;
-static char *arp_ip_target[BOND_MAX_ARP_TARGETS];
-static char *arp_validate;
-static char *arp_all_targets;
-static char *fail_over_mac;
-static int all_slaves_active;
-static struct bond_params bonding_defaults;
-static int resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-static int packets_per_slave = 1;
-static int lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-
-module_param(max_bonds, int, 0);
-MODULE_PARM_DESC(max_bonds, "Max number of bonded devices");
-module_param(tx_queues, int, 0);
-MODULE_PARM_DESC(tx_queues, "Max number of transmit queues (default = 16)");
-module_param_named(num_grat_arp, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_grat_arp, "Number of peer notifications to send on "
-			       "failover event (alias of num_unsol_na)");
-module_param_named(num_unsol_na, num_peer_notif, int, 0644);
-MODULE_PARM_DESC(num_unsol_na, "Number of peer notifications to send on "
-			       "failover event (alias of num_grat_arp)");
-module_param(miimon, int, 0);
-MODULE_PARM_DESC(miimon, "Link check interval in milliseconds");
-module_param(updelay, int, 0);
-MODULE_PARM_DESC(updelay, "Delay before considering link up, in milliseconds");
-module_param(downdelay, int, 0);
-MODULE_PARM_DESC(downdelay, "Delay before considering link down, "
-			    "in milliseconds");
-module_param(use_carrier, int, 0);
-MODULE_PARM_DESC(use_carrier, "Use netif_carrier_ok (vs MII ioctls) in miimon; "
-			      "0 for off, 1 for on (default)");
-module_param(mode, charp, 0);
-MODULE_PARM_DESC(mode, "Mode of operation; 0 for balance-rr, "
-		       "1 for active-backup, 2 for balance-xor, "
-		       "3 for broadcast, 4 for 802.3ad, 5 for balance-tlb, "
-		       "6 for balance-alb");
-module_param(primary, charp, 0);
-MODULE_PARM_DESC(primary, "Primary network device to use");
-module_param(primary_reselect, charp, 0);
-MODULE_PARM_DESC(primary_reselect, "Reselect primary slave "
-				   "once it comes up; "
-				   "0 for always (default), "
-				   "1 for only if speed of primary is "
-				   "better, "
-				   "2 for only on active slave "
-				   "failure");
-module_param(lacp_rate, charp, 0);
-MODULE_PARM_DESC(lacp_rate, "LACPDU tx rate to request from 802.3ad partner; "
-			    "0 for slow, 1 for fast");
-module_param(ad_select, charp, 0);
-MODULE_PARM_DESC(ad_select, "802.3ad aggregation selection logic; "
-			    "0 for stable (default), 1 for bandwidth, "
-			    "2 for count");
-module_param(min_links, int, 0);
-MODULE_PARM_DESC(min_links, "Minimum number of available links before turning on carrier");
-
-module_param(xmit_hash_policy, charp, 0);
-MODULE_PARM_DESC(xmit_hash_policy, "balance-alb, balance-tlb, balance-xor, 802.3ad hashing method; "
-				   "0 for layer 2 (default), 1 for layer 3+4, "
-				   "2 for layer 2+3, 3 for encap layer 2+3, "
-				   "4 for encap layer 3+4");
-module_param(arp_interval, int, 0);
-MODULE_PARM_DESC(arp_interval, "arp interval in milliseconds");
-module_param_array(arp_ip_target, charp, NULL, 0);
-MODULE_PARM_DESC(arp_ip_target, "arp targets in n.n.n.n form");
-module_param(arp_validate, charp, 0);
-MODULE_PARM_DESC(arp_validate, "validate src/dst of ARP probes; "
-			       "0 for none (default), 1 for active, "
-			       "2 for backup, 3 for all");
-module_param(arp_all_targets, charp, 0);
-MODULE_PARM_DESC(arp_all_targets, "fail on any/all arp targets timeout; 0 for any (default), 1 for all");
-module_param(fail_over_mac, charp, 0);
-MODULE_PARM_DESC(fail_over_mac, "For active-backup, do not set all slaves to "
-				"the same MAC; 0 for none (default), "
-				"1 for active, 2 for follow");
-module_param(all_slaves_active, int, 0);
-MODULE_PARM_DESC(all_slaves_active, "Keep all frames received on an interface "
-				     "by setting active flag for all slaves; "
-				     "0 for never (default), 1 for always.");
-module_param(resend_igmp, int, 0);
-MODULE_PARM_DESC(resend_igmp, "Number of IGMP membership reports to send on "
-			      "link failure");
-module_param(packets_per_slave, int, 0);
-MODULE_PARM_DESC(packets_per_slave, "Packets to send per slave in balance-rr "
-				    "mode; 0 for a random slave, 1 packet per "
-				    "slave (default), >1 packets per slave.");
-module_param(lp_interval, uint, 0);
-MODULE_PARM_DESC(lp_interval, "The number of seconds between instances where "
-			      "the bonding driver sends learning packets to "
-			      "each slaves peer switch. The default is 1.");
-
-/*----------------------------- Global variables ----------------------------*/
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-atomic_t netpoll_block_tx = ATOMIC_INIT(0);
-#endif
-
-unsigned int bond_net_id __read_mostly;
-
-static const struct flow_dissector_key flow_keys_bonding_keys[] = {
-	{
-		.key_id = FLOW_DISSECTOR_KEY_CONTROL,
-		.offset = offsetof(struct flow_keys, control),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_BASIC,
-		.offset = offsetof(struct flow_keys, basic),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_IPV4_ADDRS,
-		.offset = offsetof(struct flow_keys, addrs.v4addrs),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_IPV6_ADDRS,
-		.offset = offsetof(struct flow_keys, addrs.v6addrs),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_TIPC,
-		.offset = offsetof(struct flow_keys, addrs.tipckey),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_PORTS,
-		.offset = offsetof(struct flow_keys, ports),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_ICMP,
-		.offset = offsetof(struct flow_keys, icmp),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_VLAN,
-		.offset = offsetof(struct flow_keys, vlan),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_FLOW_LABEL,
-		.offset = offsetof(struct flow_keys, tags),
-	},
-	{
-		.key_id = FLOW_DISSECTOR_KEY_GRE_KEYID,
-		.offset = offsetof(struct flow_keys, keyid),
-	},
-};
-
-static struct flow_dissector flow_keys_bonding __read_mostly;
-
-/*-------------------------- Forward declarations ---------------------------*/
-
-static int bond_init(struct net_device *bond_dev);
-static void bond_uninit(struct net_device *bond_dev);
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats);
-static void bond_slave_arr_handler(struct work_struct *work);
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod);
-static void bond_netdev_notify_work(struct work_struct *work);
-
-/*---------------------------- General routines -----------------------------*/
-
-const char *bond_mode_name(int mode)
-{
-	static const char *names[] = {
-		[BOND_MODE_ROUNDROBIN] = "load balancing (round-robin)",
-		[BOND_MODE_ACTIVEBACKUP] = "fault-tolerance (active-backup)",
-		[BOND_MODE_XOR] = "load balancing (xor)",
-		[BOND_MODE_BROADCAST] = "fault-tolerance (broadcast)",
-		[BOND_MODE_8023AD] = "IEEE 802.3ad Dynamic link aggregation",
-		[BOND_MODE_TLB] = "transmit load balancing",
-		[BOND_MODE_ALB] = "adaptive load balancing",
-	};
-
-	if (mode < BOND_MODE_ROUNDROBIN || mode > BOND_MODE_ALB)
-		return "unknown";
-
-	return names[mode];
-}
-
-/*---------------------------------- VLAN -----------------------------------*/
-
-/**
- * bond_dev_queue_xmit - Prepare skb for xmit.
- *
- * @bond: bond device that got this skb for tx.
- * @skb: hw accel VLAN tagged skb to transmit
- * @slave_dev: slave that is supposed to xmit this skbuff
- */
-void bond_dev_queue_xmit(struct bonding *bond, struct sk_buff *skb,
-			struct net_device *slave_dev)
-{
-	skb->dev = slave_dev;
-
-	BUILD_BUG_ON(sizeof(skb->queue_mapping) !=
-		     sizeof(qdisc_skb_cb(skb)->slave_dev_queue_mapping));
-	skb_set_queue_mapping(skb, qdisc_skb_cb(skb)->slave_dev_queue_mapping);
-
-	if (unlikely(netpoll_tx_running(bond->dev)))
-		bond_netpoll_send_skb(bond_get_slave_by_dev(bond, slave_dev), skb);
-	else
-		dev_queue_xmit(skb);
-}
-
-/* In the following 2 functions, bond_vlan_rx_add_vid and bond_vlan_rx_kill_vid,
- * We don't protect the slave list iteration with a lock because:
- * a. This operation is performed in IOCTL context,
- * b. The operation is protected by the RTNL semaphore in the 8021q code,
- * c. Holding a lock with BH disabled while directly calling a base driver
- *    entry point is generally a BAD idea.
- *
- * The design of synchronization/protection for this operation in the 8021q
- * module is good for one or more VLAN devices over a single physical device
- * and cannot be extended for a teaming solution like bonding, so there is a
- * potential race condition here where a net device from the vlan group might
- * be referenced (either by a base driver or the 8021q code) while it is being
- * removed from the system. However, it turns out we're not making matters
- * worse, and if it works for regular VLAN usage it will work here too.
-*/
-
-/**
- * bond_vlan_rx_add_vid - Propagates adding an id to slaves
- * @bond_dev: bonding net device that got called
- * @vid: vlan id being added
- */
-static int bond_vlan_rx_add_vid(struct net_device *bond_dev,
-				__be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res;
-
-	bond_for_each_slave(bond, slave, iter) {
-		res = vlan_vid_add(slave->dev, proto, vid);
-		if (res)
-			goto unwind;
-	}
-
-	return 0;
-
-unwind:
-	/* unwind to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		if (rollback_slave == slave)
-			break;
-
-		vlan_vid_del(rollback_slave->dev, proto, vid);
-	}
-
-	return res;
-}
-
-/**
- * bond_vlan_rx_kill_vid - Propagates deleting an id to slaves
- * @bond_dev: bonding net device that got called
- * @vid: vlan id being removed
- */
-static int bond_vlan_rx_kill_vid(struct net_device *bond_dev,
-				 __be16 proto, u16 vid)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		vlan_vid_del(slave->dev, proto, vid);
-
-	if (bond_is_lb(bond))
-		bond_alb_clear_vlan(bond, vid);
-
-	return 0;
-}
-
-/*------------------------------- Link status -------------------------------*/
-
-/* Set the carrier state for the master according to the state of its
- * slaves.  If any slaves are up, the master is up.  In 802.3ad mode,
- * do special 802.3ad magic.
- *
- * Returns zero if carrier state does not change, nonzero if it does.
- */
-int bond_set_carrier(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (!bond_has_slaves(bond))
-		goto down;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		return bond_3ad_set_carrier(bond);
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP) {
-			if (!netif_carrier_ok(bond->dev)) {
-				netif_carrier_on(bond->dev);
-				return 1;
-			}
-			return 0;
-		}
-	}
-
-down:
-	if (netif_carrier_ok(bond->dev)) {
-		netif_carrier_off(bond->dev);
-		return 1;
-	}
-	return 0;
-}
-
-/* Get link speed and duplex from the slave's base driver
- * using ethtool. If for some reason the call fails or the
- * values are invalid, set speed and duplex to -1,
- * and return. Return 1 if speed or duplex settings are
- * UNKNOWN; 0 otherwise.
- */
-static int bond_update_speed_duplex(struct slave *slave)
-{
-	struct net_device *slave_dev = slave->dev;
-	struct ethtool_link_ksettings ecmd;
-	int res;
-
-	slave->speed = SPEED_UNKNOWN;
-	slave->duplex = DUPLEX_UNKNOWN;
-
-	res = __ethtool_get_link_ksettings(slave_dev, &ecmd);
-	if (res < 0)
-		return 1;
-	if (ecmd.base.speed == 0 || ecmd.base.speed == ((__u32)-1))
-		return 1;
-	switch (ecmd.base.duplex) {
-	case DUPLEX_FULL:
-	case DUPLEX_HALF:
-		break;
-	default:
-		return 1;
-	}
-
-	slave->speed = ecmd.base.speed;
-	slave->duplex = ecmd.base.duplex;
-
-	return 0;
-}
-
-const char *bond_slave_link_status(s8 link)
-{
-	switch (link) {
-	case BOND_LINK_UP:
-		return "up";
-	case BOND_LINK_FAIL:
-		return "going down";
-	case BOND_LINK_DOWN:
-		return "down";
-	case BOND_LINK_BACK:
-		return "going back";
-	default:
-		return "unknown";
-	}
-}
-
-/* if <dev> supports MII link status reporting, check its link status.
- *
- * We either do MII/ETHTOOL ioctls, or check netif_carrier_ok(),
- * depending upon the setting of the use_carrier parameter.
- *
- * Return either BMSR_LSTATUS, meaning that the link is up (or we
- * can't tell and just pretend it is), or 0, meaning that the link is
- * down.
- *
- * If reporting is non-zero, instead of faking link up, return -1 if
- * both ETHTOOL and MII ioctls fail (meaning the device does not
- * support them).  If use_carrier is set, return whatever it says.
- * It'd be nice if there was a good way to tell if a driver supports
- * netif_carrier, but there really isn't.
- */
-static int bond_check_dev_link(struct bonding *bond,
-			       struct net_device *slave_dev, int reporting)
-{
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	int (*ioctl)(struct net_device *, struct ifreq *, int);
-	struct ifreq ifr;
-	struct mii_ioctl_data *mii;
-
-	if (!reporting && !netif_running(slave_dev))
-		return 0;
-
-	if (bond->params.use_carrier)
-		return netif_carrier_ok(slave_dev) ? BMSR_LSTATUS : 0;
-
-	/* Try to get link status using Ethtool first. */
-	if (slave_dev->ethtool_ops->get_link)
-		return slave_dev->ethtool_ops->get_link(slave_dev) ?
-			BMSR_LSTATUS : 0;
-
-	/* Ethtool can't be used, fallback to MII ioctls. */
-	ioctl = slave_ops->ndo_do_ioctl;
-	if (ioctl) {
-		/* TODO: set pointer to correct ioctl on a per team member
-		 *       bases to make this more efficient. that is, once
-		 *       we determine the correct ioctl, we will always
-		 *       call it and not the others for that team
-		 *       member.
-		 */
-
-		/* We cannot assume that SIOCGMIIPHY will also read a
-		 * register; not all network drivers (e.g., e100)
-		 * support that.
-		 */
-
-		/* Yes, the mii is overlaid on the ifreq.ifr_ifru */
-		strncpy(ifr.ifr_name, slave_dev->name, IFNAMSIZ);
-		mii = if_mii(&ifr);
-		if (ioctl(slave_dev, &ifr, SIOCGMIIPHY) == 0) {
-			mii->reg_num = MII_BMSR;
-			if (ioctl(slave_dev, &ifr, SIOCGMIIREG) == 0)
-				return mii->val_out & BMSR_LSTATUS;
-		}
-	}
-
-	/* If reporting, report that either there's no dev->do_ioctl,
-	 * or both SIOCGMIIREG and get_link failed (meaning that we
-	 * cannot report link status).  If not reporting, pretend
-	 * we're ok.
-	 */
-	return reporting ? -1 : BMSR_LSTATUS;
-}
-
-/*----------------------------- Multicast list ------------------------------*/
-
-/* Push the promiscuity flag down to appropriate slaves */
-static int bond_set_promiscuity(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_promiscuity(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_promiscuity(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Push the allmulti flag down to all slaves */
-static int bond_set_allmulti(struct bonding *bond, int inc)
-{
-	struct list_head *iter;
-	int err = 0;
-
-	if (bond_uses_primary(bond)) {
-		struct slave *curr_active = rtnl_dereference(bond->curr_active_slave);
-
-		if (curr_active)
-			err = dev_set_allmulti(curr_active->dev, inc);
-	} else {
-		struct slave *slave;
-
-		bond_for_each_slave(bond, slave, iter) {
-			err = dev_set_allmulti(slave->dev, inc);
-			if (err)
-				return err;
-		}
-	}
-	return err;
-}
-
-/* Retrieve the list of registered multicast addresses for the bonding
- * device and retransmit an IGMP JOIN request to the current active
- * slave.
- */
-static void bond_resend_igmp_join_requests_delayed(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mcast_work.work);
-
-	if (!rtnl_trylock()) {
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-		return;
-	}
-	call_netdevice_notifiers(NETDEV_RESEND_IGMP, bond->dev);
-
-	if (bond->igmp_retrans > 1) {
-		bond->igmp_retrans--;
-		queue_delayed_work(bond->wq, &bond->mcast_work, HZ/5);
-	}
-	rtnl_unlock();
-}
-
-/* Flush bond's hardware addresses from slave */
-static void bond_hw_addr_flush(struct net_device *bond_dev,
-			       struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	dev_uc_unsync(slave_dev, bond_dev);
-	dev_mc_unsync(slave_dev, bond_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		/* del lacpdu mc addr from mc list */
-		u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-		dev_mc_del(slave_dev, lacpdu_multicast);
-	}
-}
-
-/*--------------------------- Active slave change ---------------------------*/
-
-/* Update the hardware address list and promisc/allmulti for the new and
- * old active slaves (if any).  Modes that are not using primary keep all
- * slaves up date at all times; only the modes that use primary need to call
- * this function to swap these settings during a failover.
- */
-static void bond_hw_addr_swap(struct bonding *bond, struct slave *new_active,
-			      struct slave *old_active)
-{
-	if (old_active) {
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(old_active->dev, -1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(old_active->dev, -1);
-
-		bond_hw_addr_flush(bond->dev, old_active->dev);
-	}
-
-	if (new_active) {
-		/* FIXME: Signal errors upstream. */
-		if (bond->dev->flags & IFF_PROMISC)
-			dev_set_promiscuity(new_active->dev, 1);
-
-		if (bond->dev->flags & IFF_ALLMULTI)
-			dev_set_allmulti(new_active->dev, 1);
-
-		netif_addr_lock_bh(bond->dev);
-		dev_uc_sync(new_active->dev, bond->dev);
-		dev_mc_sync(new_active->dev, bond->dev);
-		netif_addr_unlock_bh(bond->dev);
-	}
-}
-
-/**
- * bond_set_dev_addr - clone slave's address to bond
- * @bond_dev: bond net device
- * @slave_dev: slave net device
- *
- * Should be called with RTNL held.
- */
-static int bond_set_dev_addr(struct net_device *bond_dev,
-			     struct net_device *slave_dev)
-{
-	int err;
-
-	slave_dbg(bond_dev, slave_dev, "bond_dev=%p slave_dev=%p slave_dev->addr_len=%d\n",
-		  bond_dev, slave_dev, slave_dev->addr_len);
-	err = dev_pre_changeaddr_notify(bond_dev, slave_dev->dev_addr, NULL);
-	if (err)
-		return err;
-
-	memcpy(bond_dev->dev_addr, slave_dev->dev_addr, slave_dev->addr_len);
-	bond_dev->addr_assign_type = NET_ADDR_STOLEN;
-	call_netdevice_notifiers(NETDEV_CHANGEADDR, bond_dev);
-	return 0;
-}
-
-static struct slave *bond_get_old_active(struct bonding *bond,
-					 struct slave *new_active)
-{
-	struct slave *slave;
-	struct list_head *iter;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave == new_active)
-			continue;
-
-		if (ether_addr_equal(bond->dev->dev_addr, slave->dev->dev_addr))
-			return slave;
-	}
-
-	return NULL;
-}
-
-/* bond_do_fail_over_mac
- *
- * Perform special MAC address swapping for fail_over_mac settings
- *
- * Called with RTNL
- */
-static void bond_do_fail_over_mac(struct bonding *bond,
-				  struct slave *new_active,
-				  struct slave *old_active)
-{
-	u8 tmp_mac[MAX_ADDR_LEN];
-	struct sockaddr_storage ss;
-	int rv;
-
-	switch (bond->params.fail_over_mac) {
-	case BOND_FOM_ACTIVE:
-		if (new_active) {
-			rv = bond_set_dev_addr(bond->dev, new_active->dev);
-			if (rv)
-				slave_err(bond->dev, new_active->dev, "Error %d setting bond MAC from slave\n",
-					  -rv);
-		}
-		break;
-	case BOND_FOM_FOLLOW:
-		/* if new_active && old_active, swap them
-		 * if just old_active, do nothing (going to no active slave)
-		 * if just new_active, set new_active to bond's MAC
-		 */
-		if (!new_active)
-			return;
-
-		if (!old_active)
-			old_active = bond_get_old_active(bond, new_active);
-
-		if (old_active) {
-			bond_hw_addr_copy(tmp_mac, new_active->dev->dev_addr,
-					  new_active->dev->addr_len);
-			bond_hw_addr_copy(ss.__data,
-					  old_active->dev->dev_addr,
-					  old_active->dev->addr_len);
-			ss.ss_family = new_active->dev->type;
-		} else {
-			bond_hw_addr_copy(ss.__data, bond->dev->dev_addr,
-					  bond->dev->addr_len);
-			ss.ss_family = bond->dev->type;
-		}
-
-		rv = dev_set_mac_address(new_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv) {
-			slave_err(bond->dev, new_active->dev, "Error %d setting MAC of new active slave\n",
-				  -rv);
-			goto out;
-		}
-
-		if (!old_active)
-			goto out;
-
-		bond_hw_addr_copy(ss.__data, tmp_mac,
-				  new_active->dev->addr_len);
-		ss.ss_family = old_active->dev->type;
-
-		rv = dev_set_mac_address(old_active->dev,
-					 (struct sockaddr *)&ss, NULL);
-		if (rv)
-			slave_err(bond->dev, old_active->dev, "Error %d setting MAC of old active slave\n",
-				  -rv);
-out:
-		break;
-	default:
-		netdev_err(bond->dev, "bond_do_fail_over_mac impossible: bad policy %d\n",
-			   bond->params.fail_over_mac);
-		break;
-	}
-
-}
-
-static struct slave *bond_choose_primary_or_current(struct bonding *bond)
-{
-	struct slave *prim = rtnl_dereference(bond->primary_slave);
-	struct slave *curr = rtnl_dereference(bond->curr_active_slave);
-
-	if (!prim || prim->link != BOND_LINK_UP) {
-		if (!curr || curr->link != BOND_LINK_UP)
-			return NULL;
-		return curr;
-	}
-
-	if (bond->force_primary) {
-		bond->force_primary = false;
-		return prim;
-	}
-
-	if (!curr || curr->link != BOND_LINK_UP)
-		return prim;
-
-	/* At this point, prim and curr are both up */
-	switch (bond->params.primary_reselect) {
-	case BOND_PRI_RESELECT_ALWAYS:
-		return prim;
-	case BOND_PRI_RESELECT_BETTER:
-		if (prim->speed < curr->speed)
-			return curr;
-		if (prim->speed == curr->speed && prim->duplex <= curr->duplex)
-			return curr;
-		return prim;
-	case BOND_PRI_RESELECT_FAILURE:
-		return curr;
-	default:
-		netdev_err(bond->dev, "impossible primary_reselect %d\n",
-			   bond->params.primary_reselect);
-		return curr;
-	}
-}
-
-/**
- * bond_find_best_slave - select the best available slave to be the active one
- * @bond: our bonding struct
- */
-static struct slave *bond_find_best_slave(struct bonding *bond)
-{
-	struct slave *slave, *bestslave = NULL;
-	struct list_head *iter;
-	int mintime = bond->params.updelay;
-
-	slave = bond_choose_primary_or_current(bond);
-	if (slave)
-		return slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (slave->link == BOND_LINK_UP)
-			return slave;
-		if (slave->link == BOND_LINK_BACK && bond_slave_is_up(slave) &&
-		    slave->delay < mintime) {
-			mintime = slave->delay;
-			bestslave = slave;
-		}
-	}
-
-	return bestslave;
-}
-
-static bool bond_should_notify_peers(struct bonding *bond)
-{
-	struct slave *slave;
-
-	rcu_read_lock();
-	slave = rcu_dereference(bond->curr_active_slave);
-	rcu_read_unlock();
-
-	netdev_dbg(bond->dev, "bond_should_notify_peers: slave %s\n",
-		   slave ? slave->dev->name : "NULL");
-
-	if (!slave || !bond->send_peer_notif ||
-	    bond->send_peer_notif %
-	    max(1, bond->params.peer_notif_delay) != 0 ||
-	    !netif_carrier_ok(bond->dev) ||
-	    test_bit(__LINK_STATE_LINKWATCH_PENDING, &slave->dev->state))
-		return false;
-
-	return true;
-}
-
-/**
- * change_active_interface - change the active slave into the specified one
- * @bond: our bonding struct
- * @new: the new slave to make the active one
- *
- * Set the new slave to the bond's settings and unset them on the old
- * curr_active_slave.
- * Setting include flags, mc-list, promiscuity, allmulti, etc.
- *
- * If @new's link state is %BOND_LINK_BACK we'll set it to %BOND_LINK_UP,
- * because it is apparently the best available slave we have, even though its
- * updelay hasn't timed out yet.
- *
- * Caller must hold RTNL.
- */
-void bond_change_active_slave(struct bonding *bond, struct slave *new_active)
-{
-	struct slave *old_active;
-
-	ASSERT_RTNL();
-
-	old_active = rtnl_dereference(bond->curr_active_slave);
-
-	if (old_active == new_active)
-		return;
-
-	if (new_active) {
-		new_active->last_link_up = jiffies;
-
-		if (new_active->link == BOND_LINK_BACK) {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one %d ms earlier\n",
-					   (bond->params.updelay - new_active->delay) * bond->params.miimon);
-			}
-
-			new_active->delay = 0;
-			bond_set_slave_link_state(new_active, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_3ad_handle_link_change(new_active, BOND_LINK_UP);
-
-			if (bond_is_lb(bond))
-				bond_alb_handle_link_change(bond, new_active, BOND_LINK_UP);
-		} else {
-			if (bond_uses_primary(bond)) {
-				slave_info(bond->dev, new_active->dev, "making interface the new active one\n");
-			}
-		}
-	}
-
-	if (bond_uses_primary(bond))
-		bond_hw_addr_swap(bond, new_active, old_active);
-
-	if (bond_is_lb(bond)) {
-		bond_alb_handle_active_change(bond, new_active);
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-		if (new_active)
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		rcu_assign_pointer(bond->curr_active_slave, new_active);
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP) {
-		if (old_active)
-			bond_set_slave_inactive_flags(old_active,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-		if (new_active) {
-			bool should_notify_peers = false;
-
-			bond_set_slave_active_flags(new_active,
-						    BOND_SLAVE_NOTIFY_NOW);
-
-			if (bond->params.fail_over_mac)
-				bond_do_fail_over_mac(bond, new_active,
-						      old_active);
-
-			if (netif_running(bond->dev)) {
-				bond->send_peer_notif =
-					bond->params.num_peer_notif *
-					max(1, bond->params.peer_notif_delay);
-				should_notify_peers =
-					bond_should_notify_peers(bond);
-			}
-
-			call_netdevice_notifiers(NETDEV_BONDING_FAILOVER, bond->dev);
-			if (should_notify_peers) {
-				bond->send_peer_notif--;
-				call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-							 bond->dev);
-			}
-		}
-	}
-
-	/* resend IGMP joins since active slave has changed or
-	 * all were sent on curr_active_slave.
-	 * resend only if bond is brought up with the affected
-	 * bonding modes and the retransmission is enabled
-	 */
-	if (netif_running(bond->dev) && (bond->params.resend_igmp > 0) &&
-	    ((bond_uses_primary(bond) && new_active) ||
-	     BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)) {
-		bond->igmp_retrans = bond->params.resend_igmp;
-		queue_delayed_work(bond->wq, &bond->mcast_work, 1);
-	}
-}
-
-/**
- * bond_select_active_slave - select a new active slave, if needed
- * @bond: our bonding struct
- *
- * This functions should be called when one of the following occurs:
- * - The old curr_active_slave has been released or lost its link.
- * - The primary_slave has got its link back.
- * - A slave has got its link back and there's no old curr_active_slave.
- *
- * Caller must hold RTNL.
- */
-void bond_select_active_slave(struct bonding *bond)
-{
-	struct slave *best_slave;
-	int rv;
-
-	ASSERT_RTNL();
-
-	best_slave = bond_find_best_slave(bond);
-	if (best_slave != rtnl_dereference(bond->curr_active_slave)) {
-		struct slave *last_slave = bond->curr_active_slave;
-
-		bond_change_active_slave(bond, best_slave);
-		toe_failover(bond->dev,
-			     bond->curr_active_slave ?
-			     bond->curr_active_slave->dev : NULL,
-			     TOE_ACTIVE_SLAVE,
-			     last_slave ? last_slave->dev : NULL);
-
-		rv = bond_set_carrier(bond);
-		if (!rv)
-			return;
-
-		if (netif_carrier_ok(bond->dev))
-			netdev_info(bond->dev, "active interface up!\n");
-		else
-			netdev_info(bond->dev, "now running without any active interface!\n");
-	}
-}
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	struct netpoll *np;
-	int err = 0;
-
-	np = kzalloc(sizeof(*np), GFP_KERNEL);
-	err = -ENOMEM;
-	if (!np)
-		goto out;
-
-	err = __netpoll_setup(np, slave->dev);
-	if (err) {
-		kfree(np);
-		goto out;
-	}
-	slave->np = np;
-out:
-	return err;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-	struct netpoll *np = slave->np;
-
-	if (!np)
-		return;
-
-	slave->np = NULL;
-
-	__netpoll_free(np);
-}
-
-static void bond_poll_controller(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-	struct ad_info ad_info;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		if (bond_3ad_get_active_agg_info(bond, &ad_info))
-			return;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!bond_slave_is_up(slave))
-			continue;
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg =
-			    SLAVE_AD_INFO(slave)->port.aggregator;
-
-			if (agg &&
-			    agg->aggregator_identifier != ad_info.aggregator_id)
-				continue;
-		}
-
-		netpoll_poll_dev(slave->dev);
-	}
-}
-
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter)
-		if (bond_slave_is_up(slave))
-			slave_disable_netpoll(slave);
-}
-
-static int bond_netpoll_setup(struct net_device *dev, struct netpoll_info *ni)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	struct slave *slave;
-	int err = 0;
-
-	bond_for_each_slave(bond, slave, iter) {
-		err = slave_enable_netpoll(slave);
-		if (err) {
-			bond_netpoll_cleanup(dev);
-			break;
-		}
-	}
-	return err;
-}
-#else
-static inline int slave_enable_netpoll(struct slave *slave)
-{
-	return 0;
-}
-static inline void slave_disable_netpoll(struct slave *slave)
-{
-}
-static void bond_netpoll_cleanup(struct net_device *bond_dev)
-{
-}
-#endif
-
-/*---------------------------------- IOCTL ----------------------------------*/
-
-static netdev_features_t bond_fix_features(struct net_device *dev,
-					   netdev_features_t features)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct list_head *iter;
-	netdev_features_t mask;
-	struct slave *slave;
-
-	mask = features;
-
-	features &= ~NETIF_F_ONE_FOR_ALL;
-	features |= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		features = netdev_increment_features(features,
-						     slave->dev->features,
-						     mask);
-	}
-	features = netdev_add_tso_features(features, mask);
-
-	return features;
-}
-
-#define BOND_VLAN_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_FRAGLIST | NETIF_F_ALL_TSO | \
-				 NETIF_F_HIGHDMA | NETIF_F_LRO)
-
-#define BOND_ENC_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_RXCSUM | NETIF_F_ALL_TSO)
-
-#define BOND_MPLS_FEATURES	(NETIF_F_HW_CSUM | NETIF_F_SG | \
-				 NETIF_F_ALL_TSO)
-
-static void bond_compute_features(struct bonding *bond)
-{
-	unsigned int dst_release_flag = IFF_XMIT_DST_RELEASE |
-					IFF_XMIT_DST_RELEASE_PERM;
-	netdev_features_t vlan_features = BOND_VLAN_FEATURES;
-	netdev_features_t enc_features  = BOND_ENC_FEATURES;
-	netdev_features_t mpls_features  = BOND_MPLS_FEATURES;
-	struct net_device *bond_dev = bond->dev;
-	struct list_head *iter;
-	struct slave *slave;
-	unsigned short max_hard_header_len = ETH_HLEN;
-	unsigned int gso_max_size = GSO_MAX_SIZE;
-	u16 gso_max_segs = GSO_MAX_SEGS;
-
-	if (!bond_has_slaves(bond))
-		goto done;
-	vlan_features &= NETIF_F_ALL_FOR_ALL;
-	mpls_features &= NETIF_F_ALL_FOR_ALL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		vlan_features = netdev_increment_features(vlan_features,
-			slave->dev->vlan_features, BOND_VLAN_FEATURES);
-
-		enc_features = netdev_increment_features(enc_features,
-							 slave->dev->hw_enc_features,
-							 BOND_ENC_FEATURES);
-
-		mpls_features = netdev_increment_features(mpls_features,
-							  slave->dev->mpls_features,
-							  BOND_MPLS_FEATURES);
-
-		dst_release_flag &= slave->dev->priv_flags;
-		if (slave->dev->hard_header_len > max_hard_header_len)
-			max_hard_header_len = slave->dev->hard_header_len;
-
-		gso_max_size = min(gso_max_size, slave->dev->gso_max_size);
-		gso_max_segs = min(gso_max_segs, slave->dev->gso_max_segs);
-	}
-	bond_dev->hard_header_len = max_hard_header_len;
-
-done:
-	bond_dev->vlan_features = vlan_features;
-	bond_dev->hw_enc_features = enc_features | NETIF_F_GSO_ENCAP_ALL |
-				    NETIF_F_HW_VLAN_CTAG_TX |
-				    NETIF_F_HW_VLAN_STAG_TX |
-				    NETIF_F_GSO_UDP_L4;
-	bond_dev->mpls_features = mpls_features;
-	bond_dev->gso_max_segs = gso_max_segs;
-	netif_set_gso_max_size(bond_dev, gso_max_size);
-
-	bond_dev->priv_flags &= ~IFF_XMIT_DST_RELEASE;
-	if ((bond_dev->priv_flags & IFF_XMIT_DST_RELEASE_PERM) &&
-	    dst_release_flag == (IFF_XMIT_DST_RELEASE | IFF_XMIT_DST_RELEASE_PERM))
-		bond_dev->priv_flags |= IFF_XMIT_DST_RELEASE;
-
-	netdev_change_features(bond_dev);
-}
-
-static void bond_setup_by_slave(struct net_device *bond_dev,
-				struct net_device *slave_dev)
-{
-	bond_dev->header_ops	    = slave_dev->header_ops;
-
-	bond_dev->type		    = slave_dev->type;
-	bond_dev->hard_header_len   = slave_dev->hard_header_len;
-	bond_dev->addr_len	    = slave_dev->addr_len;
-
-	memcpy(bond_dev->broadcast, slave_dev->broadcast,
-		slave_dev->addr_len);
-}
-
-/* On bonding slaves other than the currently active slave, suppress
- * duplicates except for alb non-mcast/bcast.
- */
-static bool bond_should_deliver_exact_match(struct sk_buff *skb,
-					    struct slave *slave,
-					    struct bonding *bond)
-{
-	if (bond_is_slave_inactive(slave)) {
-		if (BOND_MODE(bond) == BOND_MODE_ALB &&
-		    skb->pkt_type != PACKET_BROADCAST &&
-		    skb->pkt_type != PACKET_MULTICAST)
-			return false;
-		return true;
-	}
-	return false;
-}
-
-static rx_handler_result_t bond_handle_frame(struct sk_buff **pskb)
-{
-	struct sk_buff *skb = *pskb;
-	struct slave *slave;
-	struct bonding *bond;
-	int (*recv_probe)(const struct sk_buff *, struct bonding *,
-			  struct slave *);
-	int ret = RX_HANDLER_ANOTHER;
-
-	skb = skb_share_check(skb, GFP_ATOMIC);
-	if (unlikely(!skb))
-		return RX_HANDLER_CONSUMED;
-
-	*pskb = skb;
-
-	slave = bond_slave_get_rcu(skb->dev);
-	bond = slave->bond;
-
-	recv_probe = READ_ONCE(bond->recv_probe);
-	if (recv_probe) {
-		ret = recv_probe(skb, bond, slave);
-		if (ret == RX_HANDLER_CONSUMED) {
-			consume_skb(skb);
-			return ret;
-		}
-	}
-
-	/*
-	 * For packets determined by bond_should_deliver_exact_match() call to
-	 * be suppressed we want to make an exception for link-local packets.
-	 * This is necessary for e.g. LLDP daemons to be able to monitor
-	 * inactive slave links without being forced to bind to them
-	 * explicitly.
-	 *
-	 * At the same time, packets that are passed to the bonding master
-	 * (including link-local ones) can have their originating interface
-	 * determined via PACKET_ORIGDEV socket option.
-	 */
-	if (bond_should_deliver_exact_match(skb, slave, bond)) {
-		if (is_link_local_ether_addr(eth_hdr(skb)->h_dest))
-			return RX_HANDLER_PASS;
-		return RX_HANDLER_EXACT;
-	}
-
-	skb->dev = bond->dev;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB &&
-	    bond->dev->priv_flags & IFF_BRIDGE_PORT &&
-	    skb->pkt_type == PACKET_HOST) {
-
-		if (unlikely(skb_cow_head(skb,
-					  skb->data - skb_mac_header(skb)))) {
-			kfree_skb(skb);
-			return RX_HANDLER_CONSUMED;
-		}
-		bond_hw_addr_copy(eth_hdr(skb)->h_dest, bond->dev->dev_addr,
-				  bond->dev->addr_len);
-	}
-
-	return ret;
-}
-
-static enum netdev_lag_tx_type bond_lag_tx_type(struct bonding *bond)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return NETDEV_LAG_TX_TYPE_ROUNDROBIN;
-	case BOND_MODE_ACTIVEBACKUP:
-		return NETDEV_LAG_TX_TYPE_ACTIVEBACKUP;
-	case BOND_MODE_BROADCAST:
-		return NETDEV_LAG_TX_TYPE_BROADCAST;
-	case BOND_MODE_XOR:
-	case BOND_MODE_8023AD:
-		return NETDEV_LAG_TX_TYPE_HASH;
-	default:
-		return NETDEV_LAG_TX_TYPE_UNKNOWN;
-	}
-}
-
-static enum netdev_lag_hash bond_lag_hash_type(struct bonding *bond,
-					       enum netdev_lag_tx_type type)
-{
-	if (type != NETDEV_LAG_TX_TYPE_HASH)
-		return NETDEV_LAG_HASH_NONE;
-
-	switch (bond->params.xmit_policy) {
-	case BOND_XMIT_POLICY_LAYER2:
-		return NETDEV_LAG_HASH_L2;
-	case BOND_XMIT_POLICY_LAYER34:
-		return NETDEV_LAG_HASH_L34;
-	case BOND_XMIT_POLICY_LAYER23:
-		return NETDEV_LAG_HASH_L23;
-	case BOND_XMIT_POLICY_ENCAP23:
-		return NETDEV_LAG_HASH_E23;
-	case BOND_XMIT_POLICY_ENCAP34:
-		return NETDEV_LAG_HASH_E34;
-	default:
-		return NETDEV_LAG_HASH_UNKNOWN;
-	}
-}
-
-static int bond_master_upper_dev_link(struct bonding *bond, struct slave *slave,
-				      struct netlink_ext_ack *extack)
-{
-	struct netdev_lag_upper_info lag_upper_info;
-	enum netdev_lag_tx_type type;
-
-	type = bond_lag_tx_type(bond);
-	lag_upper_info.tx_type = type;
-	lag_upper_info.hash_type = bond_lag_hash_type(bond, type);
-
-	return netdev_master_upper_dev_link(slave->dev, bond->dev, slave,
-					    &lag_upper_info, extack);
-}
-
-static void bond_upper_dev_unlink(struct bonding *bond, struct slave *slave)
-{
-	netdev_upper_dev_unlink(slave->dev, bond->dev);
-	slave->dev->flags &= ~IFF_SLAVE;
-}
-
-static struct slave *bond_alloc_slave(struct bonding *bond)
-{
-	struct slave *slave = NULL;
-
-	slave = kzalloc(sizeof(*slave), GFP_KERNEL);
-	if (!slave)
-		return NULL;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		SLAVE_AD_INFO(slave) = kzalloc(sizeof(struct ad_slave_info),
-					       GFP_KERNEL);
-		if (!SLAVE_AD_INFO(slave)) {
-			kfree(slave);
-			return NULL;
-		}
-	}
-	INIT_DELAYED_WORK(&slave->notify_work, bond_netdev_notify_work);
-
-	return slave;
-}
-
-static void bond_free_slave(struct slave *slave)
-{
-	struct bonding *bond = bond_get_bond_by_slave(slave);
-
-	cancel_delayed_work_sync(&slave->notify_work);
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		kfree(SLAVE_AD_INFO(slave));
-
-	kfree(slave);
-}
-
-static void bond_fill_ifbond(struct bonding *bond, struct ifbond *info)
-{
-	info->bond_mode = BOND_MODE(bond);
-	info->miimon = bond->params.miimon;
-	info->num_slaves = bond->slave_cnt;
-}
-
-static void bond_fill_ifslave(struct slave *slave, struct ifslave *info)
-{
-	strcpy(info->slave_name, slave->dev->name);
-	info->link = slave->link;
-	info->state = bond_slave_state(slave);
-	info->link_failure_count = slave->link_failure_count;
-}
-
-static void bond_netdev_notify_work(struct work_struct *_work)
-{
-	struct slave *slave = container_of(_work, struct slave,
-					   notify_work.work);
-
-	if (rtnl_trylock()) {
-		struct netdev_bonding_info binfo;
-
-		bond_fill_ifslave(slave, &binfo.slave);
-		bond_fill_ifbond(slave->bond, &binfo.master);
-		netdev_bonding_info_change(slave->dev, &binfo);
-		rtnl_unlock();
-	} else {
-		queue_delayed_work(slave->bond->wq, &slave->notify_work, 1);
-	}
-}
-
-void bond_queue_slave_event(struct slave *slave)
-{
-	queue_delayed_work(slave->bond->wq, &slave->notify_work, 0);
-}
-
-void bond_lower_state_changed(struct slave *slave)
-{
-	struct netdev_lag_lower_state_info info;
-
-	info.link_up = slave->link == BOND_LINK_UP ||
-		       slave->link == BOND_LINK_FAIL;
-	info.tx_enabled = bond_is_active_slave(slave);
-	netdev_lower_state_changed(slave->dev, &info);
-}
-
-/* enslave device <slave> to bond device <master> */
-int bond_enslave(struct net_device *bond_dev, struct net_device *slave_dev,
-		 struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	const struct net_device_ops *slave_ops = slave_dev->netdev_ops;
-	struct slave *new_slave = NULL, *prev_slave;
-	struct sockaddr_storage ss;
-	int link_reporting;
-	int res = 0, i;
-
-	if (!bond->params.use_carrier &&
-	    slave_dev->ethtool_ops->get_link == NULL &&
-	    slave_ops->ndo_do_ioctl == NULL) {
-		slave_warn(bond_dev, slave_dev, "no link monitoring support\n");
-	}
-
-	/* already in-use? */
-	if (netdev_is_rx_handler_busy(slave_dev)) {
-		NL_SET_ERR_MSG(extack, "Device is in use and cannot be enslaved");
-		slave_err(bond_dev, slave_dev,
-			  "Error: Device is in use and cannot be enslaved\n");
-		return -EBUSY;
-	}
-
-	if (bond_dev == slave_dev) {
-		NL_SET_ERR_MSG(extack, "Cannot enslave bond to itself.");
-		netdev_err(bond_dev, "cannot enslave bond to itself.\n");
-		return -EPERM;
-	}
-
-	/* vlan challenged mutual exclusion */
-	/* no need to lock since we're protected by rtnl_lock */
-	if (slave_dev->features & NETIF_F_VLAN_CHALLENGED) {
-		slave_dbg(bond_dev, slave_dev, "is NETIF_F_VLAN_CHALLENGED\n");
-		if (vlan_uses_dev(bond_dev)) {
-			NL_SET_ERR_MSG(extack, "Can not enslave VLAN challenged device to VLAN enabled bond");
-			slave_err(bond_dev, slave_dev, "Error: cannot enslave VLAN challenged slave on VLAN enabled bond\n");
-			return -EPERM;
-		} else {
-			slave_warn(bond_dev, slave_dev, "enslaved VLAN challenged slave. Adding VLANs will be blocked as long as it is part of bond.\n");
-		}
-	} else {
-		slave_dbg(bond_dev, slave_dev, "is !NETIF_F_VLAN_CHALLENGED\n");
-	}
-
-	/* Old ifenslave binaries are no longer supported.  These can
-	 * be identified with moderate accuracy by the state of the slave:
-	 * the current ifenslave will set the interface down prior to
-	 * enslaving it; the old ifenslave will not.
-	 */
-	if (slave_dev->flags & IFF_UP) {
-		NL_SET_ERR_MSG(extack, "Device can not be enslaved while up");
-		slave_err(bond_dev, slave_dev, "slave is up - this may be due to an out of date ifenslave\n");
-		return -EPERM;
-	}
-
-	/* set bonding device ether type by slave - bonding netdevices are
-	 * created with ether_setup, so when the slave type is not ARPHRD_ETHER
-	 * there is a need to override some of the type dependent attribs/funcs.
-	 *
-	 * bond ether type mutual exclusion - don't allow slaves of dissimilar
-	 * ether type (eg ARPHRD_ETHER and ARPHRD_INFINIBAND) share the same bond
-	 */
-	if (!bond_has_slaves(bond)) {
-		if (bond_dev->type != slave_dev->type) {
-			slave_dbg(bond_dev, slave_dev, "change device type from %d to %d\n",
-				  bond_dev->type, slave_dev->type);
-
-			res = call_netdevice_notifiers(NETDEV_PRE_TYPE_CHANGE,
-						       bond_dev);
-			res = notifier_to_errno(res);
-			if (res) {
-				slave_err(bond_dev, slave_dev, "refused to change device type\n");
-				return -EBUSY;
-			}
-
-			/* Flush unicast and multicast addresses */
-			dev_uc_flush(bond_dev);
-			dev_mc_flush(bond_dev);
-
-			if (slave_dev->type != ARPHRD_ETHER)
-				bond_setup_by_slave(bond_dev, slave_dev);
-			else {
-				ether_setup(bond_dev);
-				bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-			}
-
-			call_netdevice_notifiers(NETDEV_POST_TYPE_CHANGE,
-						 bond_dev);
-		}
-	} else if (bond_dev->type != slave_dev->type) {
-		NL_SET_ERR_MSG(extack, "Device type is different from other slaves");
-		slave_err(bond_dev, slave_dev, "ether type (%d) is different from other slaves (%d), can not enslave it\n",
-			  slave_dev->type, bond_dev->type);
-		return -EINVAL;
-	}
-
-	if (slave_dev->type == ARPHRD_INFINIBAND &&
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		NL_SET_ERR_MSG(extack, "Only active-backup mode is supported for infiniband slaves");
-		slave_warn(bond_dev, slave_dev, "Type (%d) supports only active-backup mode\n",
-			   slave_dev->type);
-		res = -EOPNOTSUPP;
-		goto err_undo_flags;
-	}
-
-	if (!slave_ops->ndo_set_mac_address ||
-	    slave_dev->type == ARPHRD_INFINIBAND) {
-		slave_warn(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address\n");
-		if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
-		    bond->params.fail_over_mac != BOND_FOM_ACTIVE) {
-			if (!bond_has_slaves(bond)) {
-				bond->params.fail_over_mac = BOND_FOM_ACTIVE;
-				slave_warn(bond_dev, slave_dev, "Setting fail_over_mac to active for active-backup mode\n");
-			} else {
-				NL_SET_ERR_MSG(extack, "Slave device does not support setting the MAC address, but fail_over_mac is not set to active");
-				slave_err(bond_dev, slave_dev, "The slave device specified does not support setting the MAC address, but fail_over_mac is not set to active\n");
-				res = -EOPNOTSUPP;
-				goto err_undo_flags;
-			}
-		}
-	}
-
-	call_netdevice_notifiers(NETDEV_JOIN, slave_dev);
-
-	/* If this is the first slave, then we need to set the master's hardware
-	 * address to be the same as the slave's.
-	 */
-	if (!bond_has_slaves(bond) &&
-	    bond->dev->addr_assign_type == NET_ADDR_RANDOM) {
-		res = bond_set_dev_addr(bond->dev, slave_dev);
-		if (res)
-			goto err_undo_flags;
-	}
-
-	new_slave = bond_alloc_slave(bond);
-	if (!new_slave) {
-		res = -ENOMEM;
-		goto err_undo_flags;
-	}
-
-	new_slave->bond = bond;
-	new_slave->dev = slave_dev;
-	/* Set the new_slave's queue_id to be zero.  Queue ID mapping
-	 * is set via sysfs or module option if desired.
-	 */
-	new_slave->queue_id = 0;
-
-	/* Save slave's original mtu and then set it to match the bond */
-	new_slave->original_mtu = slave_dev->mtu;
-	res = dev_set_mtu(slave_dev, bond->dev->mtu);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Error %d calling dev_set_mtu\n", res);
-		goto err_free;
-	}
-
-	/* Save slave's original ("permanent") mac address for modes
-	 * that need it, and for restoring it upon release, and then
-	 * set it to the master's address
-	 */
-	bond_hw_addr_copy(new_slave->perm_hwaddr, slave_dev->dev_addr,
-			  slave_dev->addr_len);
-
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* Set slave to master's mac address.  The application already
-		 * set the master's mac address to that of the first slave
-		 */
-		memcpy(ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		res = dev_set_mac_address(slave_dev, (struct sockaddr *)&ss,
-					  extack);
-		if (res) {
-			slave_err(bond_dev, slave_dev, "Error %d calling set_mac_address\n", res);
-			goto err_restore_mtu;
-		}
-	}
-
-	/* set slave flag before open to prevent IPv6 addrconf */
-	slave_dev->flags |= IFF_SLAVE;
-
-	/* open the slave since the application closed it */
-	res = dev_open(slave_dev, extack);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Opening slave failed\n");
-		goto err_restore_mac;
-	}
-
-	slave_dev->priv_flags |= IFF_BONDING;
-	/* initialize slave stats */
-	dev_get_stats(new_slave->dev, &new_slave->slave_stats);
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_init_slave() must be called before all other stages since
-		 * it might fail and we do not want to have to undo everything
-		 */
-		res = bond_alb_init_slave(bond, new_slave);
-		if (res)
-			goto err_close;
-	}
-
-	res = vlan_vids_add_by_dev(slave_dev, bond_dev);
-	if (res) {
-		slave_err(bond_dev, slave_dev, "Couldn't add bond vlan ids\n");
-		goto err_close;
-	}
-
-	prev_slave = bond_last_slave(bond);
-
-	new_slave->delay = 0;
-	new_slave->link_failure_count = 0;
-
-	if (bond_update_speed_duplex(new_slave) &&
-	    bond_needs_speed_duplex(bond))
-		new_slave->link = BOND_LINK_DOWN;
-
-	new_slave->last_rx = jiffies -
-		(msecs_to_jiffies(bond->params.arp_interval) + 1);
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
-		new_slave->target_last_arp_rx[i] = new_slave->last_rx;
-
-	if (bond->params.miimon && !bond->params.use_carrier) {
-		link_reporting = bond_check_dev_link(bond, slave_dev, 1);
-
-		if ((link_reporting == -1) && !bond->params.arp_interval) {
-			/* miimon is set but a bonded network driver
-			 * does not support ETHTOOL/MII and
-			 * arp_interval is not set.  Note: if
-			 * use_carrier is enabled, we will never go
-			 * here (because netif_carrier is always
-			 * supported); thus, we don't need to change
-			 * the messages for netif_carrier.
-			 */
-			slave_warn(bond_dev, slave_dev, "MII and ETHTOOL support not available for slave, and arp_interval/arp_ip_target module parameters not specified, thus bonding will not detect link failures! see bonding.txt for details\n");
-		} else if (link_reporting == -1) {
-			/* unable get link status using mii/ethtool */
-			slave_warn(bond_dev, slave_dev, "can't get link status from slave; the network driver associated with this interface does not support MII or ETHTOOL link status reporting, thus miimon has no effect on this interface\n");
-		}
-	}
-
-	/* check for initial state */
-	new_slave->link = BOND_LINK_NOCHANGE;
-	if (bond->params.miimon) {
-		if (bond_check_dev_link(bond, slave_dev, 0) == BMSR_LSTATUS) {
-			if (bond->params.updelay) {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_BACK,
-							  BOND_SLAVE_NOTIFY_NOW);
-				new_slave->delay = bond->params.updelay;
-			} else {
-				bond_set_slave_link_state(new_slave,
-							  BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-			}
-		} else {
-			bond_set_slave_link_state(new_slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-		}
-	} else if (bond->params.arp_interval) {
-		bond_set_slave_link_state(new_slave,
-					  (netif_carrier_ok(slave_dev) ?
-					  BOND_LINK_UP : BOND_LINK_DOWN),
-					  BOND_SLAVE_NOTIFY_NOW);
-	} else {
-		bond_set_slave_link_state(new_slave, BOND_LINK_UP,
-					  BOND_SLAVE_NOTIFY_NOW);
-	}
-
-	if (new_slave->link != BOND_LINK_DOWN)
-		new_slave->last_link_up = jiffies;
-	slave_dbg(bond_dev, slave_dev, "Initial state of slave is BOND_LINK_%s\n",
-		  new_slave->link == BOND_LINK_DOWN ? "DOWN" :
-		  (new_slave->link == BOND_LINK_UP ? "UP" : "BACK"));
-
-	if (bond_uses_primary(bond) && bond->params.primary[0]) {
-		/* if there is a primary slave, remember it */
-		if (strcmp(bond->params.primary, new_slave->dev->name) == 0) {
-			rcu_assign_pointer(bond->primary_slave, new_slave);
-			bond->force_primary = true;
-		}
-	}
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ACTIVEBACKUP:
-		bond_set_slave_inactive_flags(new_slave,
-					      BOND_SLAVE_NOTIFY_NOW);
-		break;
-	case BOND_MODE_8023AD:
-		/* in 802.3ad mode, the internal mechanism
-		 * will activate the slaves in the selected
-		 * aggregator
-		 */
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		/* if this is the first slave */
-		if (!prev_slave) {
-			SLAVE_AD_INFO(new_slave)->id = 1;
-			/* Initialize AD with the number of times that the AD timer is called in 1 second
-			 * can be called only after the mac address of the bond is set
-			 */
-			bond_3ad_initialize(bond, 1000/AD_TIMER_INTERVAL);
-		} else {
-			SLAVE_AD_INFO(new_slave)->id =
-				SLAVE_AD_INFO(prev_slave)->id + 1;
-		}
-
-		bond_3ad_bind_slave(new_slave);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_set_active_slave(new_slave);
-		bond_set_slave_inactive_flags(new_slave, BOND_SLAVE_NOTIFY_NOW);
-		break;
-	default:
-		slave_dbg(bond_dev, slave_dev, "This slave is always active in trunk mode\n");
-
-		/* always active in trunk mode */
-		bond_set_active_slave(new_slave);
-
-		/* In trunking mode there is little meaning to curr_active_slave
-		 * anyway (it holds no special properties of the bond device),
-		 * so we can change it without calling change_active_interface()
-		 */
-		if (!rcu_access_pointer(bond->curr_active_slave) &&
-		    new_slave->link == BOND_LINK_UP)
-			rcu_assign_pointer(bond->curr_active_slave, new_slave);
-
-		break;
-	} /* switch(bond_mode) */
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	if (bond->dev->npinfo) {
-		if (slave_enable_netpoll(new_slave)) {
-			slave_info(bond_dev, slave_dev, "master_dev is using netpoll, but new slave device does not support netpoll\n");
-			res = -EBUSY;
-			goto err_detach;
-		}
-	}
-#endif
-
-	if (!(bond_dev->features & NETIF_F_LRO))
-		dev_disable_lro(slave_dev);
-
-	res = netdev_rx_handler_register(slave_dev, bond_handle_frame,
-					 new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling netdev_rx_handler_register\n", res);
-		goto err_detach;
-	}
-
-	res = bond_master_upper_dev_link(bond, new_slave, extack);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_master_upper_dev_link\n", res);
-		goto err_unregister;
-	}
-
-	res = bond_sysfs_slave_add(new_slave);
-	if (res) {
-		slave_dbg(bond_dev, slave_dev, "Error %d calling bond_sysfs_slave_add\n", res);
-		goto err_upper_unlink;
-	}
-
-	/* If the mode uses primary, then the following is handled by
-	 * bond_change_active_slave().
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* set promiscuity level to new slave */
-		if (bond_dev->flags & IFF_PROMISC) {
-			res = dev_set_promiscuity(slave_dev, 1);
-			if (res)
-				goto err_sysfs_del;
-		}
-
-		/* set allmulti level to new slave */
-		if (bond_dev->flags & IFF_ALLMULTI) {
-			res = dev_set_allmulti(slave_dev, 1);
-			if (res) {
-				if (bond_dev->flags & IFF_PROMISC)
-					dev_set_promiscuity(slave_dev, -1);
-				goto err_sysfs_del;
-			}
-		}
-
-		netif_addr_lock_bh(bond_dev);
-		dev_mc_sync_multiple(slave_dev, bond_dev);
-		dev_uc_sync_multiple(slave_dev, bond_dev);
-		netif_addr_unlock_bh(bond_dev);
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			/* add lacpdu mc addr to mc list */
-			u8 lacpdu_multicast[ETH_ALEN] = MULTICAST_LACPDU_ADDR;
-
-			dev_mc_add(slave_dev, lacpdu_multicast);
-		}
-	}
-
-	bond->slave_cnt++;
-	bond_compute_features(bond);
-	bond_set_carrier(bond);
-
-	if (bond_uses_primary(bond)) {
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-
-	slave_info(bond_dev, slave_dev, "Enslaving as %s interface with %s link\n",
-		   bond_is_active_slave(new_slave) ? "an active" : "a backup",
-		   new_slave->link != BOND_LINK_DOWN ? "an up" : "a down");
-
-	/* enslave is successful */
-	bond_queue_slave_event(new_slave);
-	return 0;
-
-/* Undo stages on error */
-err_sysfs_del:
-	bond_sysfs_slave_del(new_slave);
-
-err_upper_unlink:
-	bond_upper_dev_unlink(bond, new_slave);
-
-err_unregister:
-	netdev_rx_handler_unregister(slave_dev);
-
-err_detach:
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-	if (rcu_access_pointer(bond->primary_slave) == new_slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-	if (rcu_access_pointer(bond->curr_active_slave) == new_slave) {
-		block_netpoll_tx();
-		bond_change_active_slave(bond, NULL);
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-	/* either primary_slave or curr_active_slave might've changed */
-	synchronize_rcu();
-	slave_disable_netpoll(new_slave);
-
-err_close:
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-	dev_close(slave_dev);
-
-err_restore_mac:
-	slave_dev->flags &= ~IFF_SLAVE;
-	if (!bond->params.fail_over_mac ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* XXX TODO - fom follow mode needs to change master's
-		 * MAC if this slave's MAC is in use by the bond, or at
-		 * least print a warning.
-		 */
-		bond_hw_addr_copy(ss.__data, new_slave->perm_hwaddr,
-				  new_slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-err_restore_mtu:
-	dev_set_mtu(slave_dev, new_slave->original_mtu);
-
-err_free:
-	bond_free_slave(new_slave);
-
-err_undo_flags:
-	/* Enslave of first slave has failed and we need to fix master's mac */
-	if (!bond_has_slaves(bond)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr,
-					    slave_dev->dev_addr))
-			eth_hw_addr_random(bond_dev);
-		if (bond_dev->type != ARPHRD_ETHER) {
-			dev_close(bond_dev);
-			ether_setup(bond_dev);
-			bond_dev->flags |= IFF_MASTER;
-			bond_dev->priv_flags &= ~IFF_TX_SKB_SHARING;
-		}
-	}
-
-	return res;
-}
-
-/* Try to release the slave device <slave> from the bond device <master>
- * It is legal to access curr_active_slave without a lock because all the function
- * is RTNL-locked. If "all" is true it means that the function is being called
- * while destroying a bond interface and all slaves are being released.
- *
- * The rules for slave state should be:
- *   for Active/Backup:
- *     Active stays on all backups go down
- *   for Bonded connections:
- *     The first up interface should be left on and all others downed.
- */
-static int __bond_release_one(struct net_device *bond_dev,
-			      struct net_device *slave_dev,
-			      bool all, bool unregister)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *oldcurrent;
-	struct sockaddr_storage ss;
-	int old_flags = bond_dev->flags;
-	netdev_features_t old_features = bond_dev->features;
-
-	/* slave is not a slave or master is not master of this slave */
-	if (!(slave_dev->flags & IFF_SLAVE) ||
-	    !netdev_has_upper_dev(slave_dev, bond_dev)) {
-		slave_dbg(bond_dev, slave_dev, "cannot release slave\n");
-		return -EINVAL;
-	}
-
-	block_netpoll_tx();
-
-	slave = bond_get_slave_by_dev(bond, slave_dev);
-	if (!slave) {
-		/* not a slave of this bond */
-		slave_info(bond_dev, slave_dev, "interface not enslaved\n");
-		unblock_netpoll_tx();
-		return -EINVAL;
-	}
-
-	toe_failover(bond_dev, slave_dev, TOE_RELEASE, NULL);
-
-	bond_set_slave_inactive_flags(slave, BOND_SLAVE_NOTIFY_NOW);
-
-	bond_sysfs_slave_del(slave);
-
-	/* recompute stats just before removing the slave */
-	bond_get_stats(bond->dev, &bond->bond_stats);
-
-	bond_upper_dev_unlink(bond, slave);
-	/* unregister rx_handler early so bond_handle_frame wouldn't be called
-	 * for this slave anymore.
-	 */
-	netdev_rx_handler_unregister(slave_dev);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD)
-		bond_3ad_unbind_slave(slave);
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, slave);
-
-	slave_info(bond_dev, slave_dev, "Releasing %s interface\n",
-		    bond_is_active_slave(slave) ? "active" : "backup");
-
-	oldcurrent = rcu_access_pointer(bond->curr_active_slave);
-
-	RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-
-	if (!all && (!bond->params.fail_over_mac ||
-		     BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP)) {
-		if (ether_addr_equal_64bits(bond_dev->dev_addr, slave->perm_hwaddr) &&
-		    bond_has_slaves(bond))
-			slave_warn(bond_dev, slave_dev, "the permanent HWaddr of slave - %pM - is still in use by bond - set the HWaddr of slave to a different address to avoid conflicts\n",
-				   slave->perm_hwaddr);
-	}
-
-	if (rtnl_dereference(bond->primary_slave) == slave)
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-
-	if (oldcurrent == slave)
-		bond_change_active_slave(bond, NULL);
-
-	if (bond_is_lb(bond)) {
-		/* Must be called only after the slave has been
-		 * detached from the list and the curr_active_slave
-		 * has been cleared (if our_slave == old_current),
-		 * but before a new active slave is selected.
-		 */
-		bond_alb_deinit_slave(bond, slave);
-	}
-
-	if (all) {
-		toe_failover(bond_dev, NULL, TOE_RELEASE_ALL, NULL);
-		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
-	} else if (oldcurrent == slave) {
-		/* Note that we hold RTNL over this sequence, so there
-		 * is no concern that another slave add/remove event
-		 * will interfere.
-		 */
-		bond_select_active_slave(bond);
-	}
-
-	if (!bond_has_slaves(bond)) {
-		bond_set_carrier(bond);
-		eth_hw_addr_random(bond_dev);
-	}
-
-	unblock_netpoll_tx();
-	synchronize_rcu();
-	bond->slave_cnt--;
-
-	if (!bond_has_slaves(bond)) {
-		call_netdevice_notifiers(NETDEV_CHANGEADDR, bond->dev);
-		call_netdevice_notifiers(NETDEV_RELEASE, bond->dev);
-	}
-
-	bond_compute_features(bond);
-	if (!(bond_dev->features & NETIF_F_VLAN_CHALLENGED) &&
-	    (old_features & NETIF_F_VLAN_CHALLENGED))
-		slave_info(bond_dev, slave_dev, "last VLAN challenged slave left bond - VLAN blocking is removed\n");
-
-	vlan_vids_del_by_dev(slave_dev, bond_dev);
-
-	/* If the mode uses primary, then this case was handled above by
-	 * bond_change_active_slave(..., NULL)
-	 */
-	if (!bond_uses_primary(bond)) {
-		/* unset promiscuity level from slave
-		 * NOTE: The NETDEV_CHANGEADDR call above may change the value
-		 * of the IFF_PROMISC flag in the bond_dev, but we need the
-		 * value of that flag before that change, as that was the value
-		 * when this slave was attached, so we cache at the start of the
-		 * function and use it here. Same goes for ALLMULTI below
-		 */
-		if (old_flags & IFF_PROMISC)
-			dev_set_promiscuity(slave_dev, -1);
-
-		/* unset allmulti level from slave */
-		if (old_flags & IFF_ALLMULTI)
-			dev_set_allmulti(slave_dev, -1);
-
-		bond_hw_addr_flush(bond_dev, slave_dev);
-	}
-
-	slave_disable_netpoll(slave);
-
-	/* close slave before restoring its mac address */
-	dev_close(slave_dev);
-
-	if (bond->params.fail_over_mac != BOND_FOM_ACTIVE ||
-	    BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-		/* restore original ("permanent") mac address */
-		bond_hw_addr_copy(ss.__data, slave->perm_hwaddr,
-				  slave->dev->addr_len);
-		ss.ss_family = slave_dev->type;
-		dev_set_mac_address(slave_dev, (struct sockaddr *)&ss, NULL);
-	}
-
-	if (unregister)
-		__dev_set_mtu(slave_dev, slave->original_mtu);
-	else
-		dev_set_mtu(slave_dev, slave->original_mtu);
-
-	if (!netif_is_bond_master(slave_dev))
-		slave_dev->priv_flags &= ~IFF_BONDING;
-
-	bond_free_slave(slave);
-
-	return 0;
-}
-
-/* A wrapper used because of ndo_del_link */
-int bond_release(struct net_device *bond_dev, struct net_device *slave_dev)
-{
-	return __bond_release_one(bond_dev, slave_dev, false, false);
-}
-
-/* First release a slave and then destroy the bond if no more slaves are left.
- * Must be under rtnl_lock when this function is called.
- */
-static int bond_release_and_destroy(struct net_device *bond_dev,
-				    struct net_device *slave_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	int ret;
-
-	ret = __bond_release_one(bond_dev, slave_dev, false, true);
-	if (ret == 0 && !bond_has_slaves(bond)) {
-		bond_dev->priv_flags |= IFF_DISABLE_NETPOLL;
-		netdev_info(bond_dev, "Destroying bond\n");
-		bond_remove_proc_entry(bond);
-		unregister_netdevice(bond_dev);
-	}
-	return ret;
-}
-
-static void bond_info_query(struct net_device *bond_dev, struct ifbond *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	bond_fill_ifbond(bond, info);
-}
-
-static int bond_slave_info_query(struct net_device *bond_dev, struct ifslave *info)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	int i = 0, res = -ENODEV;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (i++ == (int)info->slave_id) {
-			res = 0;
-			bond_fill_ifslave(slave, info);
-			break;
-		}
-	}
-
-	return res;
-}
-
-/*-------------------------------- Monitoring -------------------------------*/
-
-/* called with rcu_read_lock() */
-static int bond_miimon_inspect(struct bonding *bond)
-{
-	int link_state, commit = 0;
-	struct list_head *iter;
-	struct slave *slave;
-	bool ignore_updelay;
-
-	ignore_updelay = !rcu_dereference(bond->curr_active_slave);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		link_state = bond_check_dev_link(bond, slave->dev, 0);
-
-		switch (slave->link) {
-		case BOND_LINK_UP:
-			if (link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_FAIL);
-			commit++;
-			slave->delay = bond->params.downdelay;
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status down for %sinterface, disabling it in %d ms\n",
-					   (BOND_MODE(bond) ==
-					    BOND_MODE_ACTIVEBACKUP) ?
-					    (bond_is_active_slave(slave) ?
-					     "active " : "backup ") : "",
-					   bond->params.downdelay * bond->params.miimon);
-			}
-			/*FALLTHRU*/
-		case BOND_LINK_FAIL:
-			if (link_state) {
-				/* recovered before downdelay expired */
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave->last_link_up = jiffies;
-				slave_info(bond->dev, slave->dev, "link status up again after %d ms\n",
-					   (bond->params.downdelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				commit++;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-
-		case BOND_LINK_DOWN:
-			if (!link_state)
-				continue;
-
-			bond_propose_link_state(slave, BOND_LINK_BACK);
-			commit++;
-			slave->delay = bond->params.updelay;
-
-			if (slave->delay) {
-				slave_info(bond->dev, slave->dev, "link status up, enabling it in %d ms\n",
-					   ignore_updelay ? 0 :
-					   bond->params.updelay *
-					   bond->params.miimon);
-			}
-			/*FALLTHRU*/
-		case BOND_LINK_BACK:
-			if (!link_state) {
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_info(bond->dev, slave->dev, "link status down again after %d ms\n",
-					   (bond->params.updelay - slave->delay) *
-					   bond->params.miimon);
-				commit++;
-				continue;
-			}
-
-			if (ignore_updelay)
-				slave->delay = 0;
-
-			if (slave->delay <= 0) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-				ignore_updelay = false;
-				continue;
-			}
-
-			slave->delay--;
-			break;
-		}
-	}
-
-	return commit;
-}
-
-static void bond_miimon_link_change(struct bonding *bond,
-				    struct slave *slave,
-				    char link)
-{
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_8023AD:
-		bond_3ad_handle_link_change(slave, link);
-		break;
-	case BOND_MODE_TLB:
-	case BOND_MODE_ALB:
-		bond_alb_handle_link_change(bond, slave, link);
-		break;
-	case BOND_MODE_XOR:
-		bond_update_slave_arr(bond, NULL);
-		break;
-	}
-}
-
-static void bond_miimon_commit(struct bonding *bond)
-{
-	struct list_head *iter;
-	struct slave *slave, *primary;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			/* For 802.3ad mode, check current slave speed and
-			 * duplex again in case its port was disabled after
-			 * invalid speed/duplex reporting but recovered before
-			 * link monitoring could make a decision on the actual
-			 * link status
-			 */
-			if (BOND_MODE(bond) == BOND_MODE_8023AD &&
-			    slave->link == BOND_LINK_UP)
-				bond_3ad_adapter_speed_duplex_changed(slave);
-			continue;
-
-		case BOND_LINK_UP:
-			if (bond_update_speed_duplex(slave) &&
-			    bond_needs_speed_duplex(bond)) {
-				slave->link = BOND_LINK_DOWN;
-				if (net_ratelimit())
-					slave_warn(bond->dev, slave->dev,
-						   "failed to get link speed/duplex\n");
-				continue;
-			}
-			bond_set_slave_link_state(slave, BOND_LINK_UP,
-						  BOND_SLAVE_NOTIFY_NOW);
-			slave->last_link_up = jiffies;
-
-			primary = rtnl_dereference(bond->primary_slave);
-			if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-				/* prevent it from being the active one */
-				bond_set_backup_slave(slave);
-			} else if (BOND_MODE(bond) != BOND_MODE_ACTIVEBACKUP) {
-				/* make it immediately active */
-				bond_set_active_slave(slave);
-			}
-
-			slave_info(bond->dev, slave->dev, "link status definitely up, %u Mbps %s duplex\n",
-				   slave->speed == SPEED_UNKNOWN ? 0 : slave->speed,
-				   slave->duplex ? "full" : "half");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_UP);
-
-			if (BOND_MODE(bond) == BOND_MODE_XOR ||
-			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
-				toe_failover(netdev_master_upper_dev_get(slave->dev),
-					     slave->dev, TOE_LINK_UP, NULL);
-			if (!bond->curr_active_slave || slave == primary)
-				goto do_failover;
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-
-			if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP ||
-			    BOND_MODE(bond) == BOND_MODE_8023AD)
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			bond_miimon_link_change(bond, slave, BOND_LINK_DOWN);
-
-			if (BOND_MODE(bond) == BOND_MODE_XOR ||
-			    BOND_MODE(bond) == BOND_MODE_ROUNDROBIN)
-				toe_failover(netdev_master_upper_dev_get(slave->dev),
-					     slave->dev, TOE_LINK_DOWN, NULL);
-			if (slave == rcu_access_pointer(bond->curr_active_slave))
-				goto do_failover;
-
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev, "invalid new link %d on slave\n",
-				  slave->link_new_state);
-			bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* bond_mii_monitor
- *
- * Really a wrapper that splits the mii monitor into two phases: an
- * inspection, then (if inspection indicates something needs to be done)
- * an acquisition of appropriate locks followed by a commit phase to
- * implement whatever link state changes are indicated.
- */
-static void bond_mii_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    mii_work.work);
-	bool should_notify_peers = false;
-	bool commit;
-	unsigned long delay;
-	struct slave *slave;
-	struct list_head *iter;
-
-	delay = msecs_to_jiffies(bond->params.miimon);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-	should_notify_peers = bond_should_notify_peers(bond);
-	commit = !!bond_miimon_inspect(bond);
-	if (bond->send_peer_notif) {
-		rcu_read_unlock();
-		if (rtnl_trylock()) {
-			bond->send_peer_notif--;
-			rtnl_unlock();
-		}
-	} else {
-		rcu_read_unlock();
-	}
-
-	if (commit) {
-		/* Race avoidance with bond_close cancel of workqueue */
-		if (!rtnl_trylock()) {
-			delay = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_for_each_slave(bond, slave, iter) {
-			bond_commit_link_state(slave, BOND_SLAVE_NOTIFY_LATER);
-		}
-		bond_miimon_commit(bond);
-
-		rtnl_unlock();	/* might sleep, hold no other locks */
-	}
-
-re_arm:
-	if (bond->params.miimon)
-		queue_delayed_work(bond->wq, &bond->mii_work, delay);
-
-	if (should_notify_peers) {
-		if (!rtnl_trylock())
-			return;
-		call_netdevice_notifiers(NETDEV_NOTIFY_PEERS, bond->dev);
-		rtnl_unlock();
-	}
-}
-
-static int bond_upper_dev_walk(struct net_device *upper, void *data)
-{
-	__be32 ip = *((__be32 *)data);
-
-	return ip == bond_confirm_addr(upper, 0, ip);
-}
-
-static bool bond_has_this_ip(struct bonding *bond, __be32 ip)
-{
-	bool ret = false;
-
-	if (ip == bond_confirm_addr(bond->dev, 0, ip))
-		return true;
-
-	rcu_read_lock();
-	if (netdev_walk_all_upper_dev_rcu(bond->dev, bond_upper_dev_walk, &ip))
-		ret = true;
-	rcu_read_unlock();
-
-	return ret;
-}
-
-/* We go to the (large) trouble of VLAN tagging ARP frames because
- * switches in VLAN mode (especially if ports are configured as
- * "native" to a VLAN) might not pass non-tagged frames.
- */
-static void bond_arp_send(struct slave *slave, int arp_op, __be32 dest_ip,
-			  __be32 src_ip, struct bond_vlan_tag *tags)
-{
-	struct sk_buff *skb;
-	struct bond_vlan_tag *outer_tag = tags;
-	struct net_device *slave_dev = slave->dev;
-	struct net_device *bond_dev = slave->bond->dev;
-
-	slave_dbg(bond_dev, slave_dev, "arp %d on slave: dst %pI4 src %pI4\n",
-		  arp_op, &dest_ip, &src_ip);
-
-	skb = arp_create(arp_op, ETH_P_ARP, dest_ip, slave_dev, src_ip,
-			 NULL, slave_dev->dev_addr, NULL);
-
-	if (!skb) {
-		net_err_ratelimited("ARP packet allocation failed\n");
-		return;
-	}
-
-	if (!tags || tags->vlan_proto == VLAN_N_VID)
-		goto xmit;
-
-	tags++;
-
-	/* Go through all the tags backwards and add them to the packet */
-	while (tags->vlan_proto != VLAN_N_VID) {
-		if (!tags->vlan_id) {
-			tags++;
-			continue;
-		}
-
-		slave_dbg(bond_dev, slave_dev, "inner tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), tags->vlan_id);
-		skb = vlan_insert_tag_set_proto(skb, tags->vlan_proto,
-						tags->vlan_id);
-		if (!skb) {
-			net_err_ratelimited("failed to insert inner VLAN tag\n");
-			return;
-		}
-
-		tags++;
-	}
-	/* Set the outer tag */
-	if (outer_tag->vlan_id) {
-		slave_dbg(bond_dev, slave_dev, "outer tag: proto %X vid %X\n",
-			  ntohs(outer_tag->vlan_proto), outer_tag->vlan_id);
-		__vlan_hwaccel_put_tag(skb, outer_tag->vlan_proto,
-				       outer_tag->vlan_id);
-	}
-
-xmit:
-	arp_xmit(skb);
-}
-
-/* Validate the device path between the @start_dev and the @end_dev.
- * The path is valid if the @end_dev is reachable through device
- * stacking.
- * When the path is validated, collect any vlan information in the
- * path.
- */
-struct bond_vlan_tag *bond_verify_device_path(struct net_device *start_dev,
-					      struct net_device *end_dev,
-					      int level)
-{
-	struct bond_vlan_tag *tags;
-	struct net_device *upper;
-	struct list_head  *iter;
-
-	if (start_dev == end_dev) {
-		tags = kcalloc(level + 1, sizeof(*tags), GFP_ATOMIC);
-		if (!tags)
-			return ERR_PTR(-ENOMEM);
-		tags[level].vlan_proto = VLAN_N_VID;
-		return tags;
-	}
-
-	netdev_for_each_upper_dev_rcu(start_dev, upper, iter) {
-		tags = bond_verify_device_path(upper, end_dev, level + 1);
-		if (IS_ERR_OR_NULL(tags)) {
-			if (IS_ERR(tags))
-				return tags;
-			continue;
-		}
-		if (is_vlan_dev(upper)) {
-			tags[level].vlan_proto = vlan_dev_vlan_proto(upper);
-			tags[level].vlan_id = vlan_dev_vlan_id(upper);
-		}
-
-		return tags;
-	}
-
-	return NULL;
-}
-
-static void bond_arp_send_all(struct bonding *bond, struct slave *slave)
-{
-	struct rtable *rt;
-	struct bond_vlan_tag *tags;
-	__be32 *targets = bond->params.arp_targets, addr;
-	int i;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS && targets[i]; i++) {
-		slave_dbg(bond->dev, slave->dev, "%s: target %pI4\n",
-			  __func__, &targets[i]);
-		tags = NULL;
-
-		/* Find out through which dev should the packet go */
-		rt = ip_route_output(dev_net(bond->dev), targets[i], 0,
-				     RTO_ONLINK, 0);
-		if (IS_ERR(rt)) {
-			/* there's no route to target - try to send arp
-			 * probe to generate any traffic (arp_validate=0)
-			 */
-			if (bond->params.arp_validate)
-				net_warn_ratelimited("%s: no route to arp_ip_target %pI4 and arp_validate is set\n",
-						     bond->dev->name,
-						     &targets[i]);
-			bond_arp_send(slave, ARPOP_REQUEST, targets[i],
-				      0, tags);
-			continue;
-		}
-
-		/* bond device itself */
-		if (rt->dst.dev == bond->dev)
-			goto found;
-
-		rcu_read_lock();
-		tags = bond_verify_device_path(bond->dev, rt->dst.dev, 0);
-		rcu_read_unlock();
-
-		if (!IS_ERR_OR_NULL(tags))
-			goto found;
-
-		/* Not our device - skip */
-		slave_dbg(bond->dev, slave->dev, "no path to arp_ip_target %pI4 via rt.dev %s\n",
-			   &targets[i], rt->dst.dev ? rt->dst.dev->name : "NULL");
-
-		ip_rt_put(rt);
-		continue;
-
-found:
-		addr = bond_confirm_addr(rt->dst.dev, targets[i], 0);
-		ip_rt_put(rt);
-		bond_arp_send(slave, ARPOP_REQUEST, targets[i], addr, tags);
-		kfree(tags);
-	}
-}
-
-static void bond_validate_arp(struct bonding *bond, struct slave *slave, __be32 sip, __be32 tip)
-{
-	int i;
-
-	if (!sip || !bond_has_this_ip(bond, tip)) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 tip %pI4 not found\n",
-			   __func__, &sip, &tip);
-		return;
-	}
-
-	i = bond_get_targets_ip(bond->params.arp_targets, sip);
-	if (i == -1) {
-		slave_dbg(bond->dev, slave->dev, "%s: sip %pI4 not found in targets\n",
-			   __func__, &sip);
-		return;
-	}
-	slave->last_rx = jiffies;
-	slave->target_last_arp_rx[i] = jiffies;
-}
-
-int bond_arp_rcv(const struct sk_buff *skb, struct bonding *bond,
-		 struct slave *slave)
-{
-	struct arphdr *arp = (struct arphdr *)skb->data;
-	struct slave *curr_active_slave, *curr_arp_slave;
-	unsigned char *arp_ptr;
-	__be32 sip, tip;
-	int is_arp = skb->protocol == __cpu_to_be16(ETH_P_ARP);
-	unsigned int alen;
-
-	if (!slave_do_arp_validate(bond, slave)) {
-		if ((slave_do_arp_validate_only(bond) && is_arp) ||
-		    !slave_do_arp_validate_only(bond))
-			slave->last_rx = jiffies;
-		return RX_HANDLER_ANOTHER;
-	} else if (!is_arp) {
-		return RX_HANDLER_ANOTHER;
-	}
-
-	alen = arp_hdr_len(bond->dev);
-
-	slave_dbg(bond->dev, slave->dev, "%s: skb->dev %s\n",
-		   __func__, skb->dev->name);
-
-	if (alen > skb_headlen(skb)) {
-		arp = kmalloc(alen, GFP_ATOMIC);
-		if (!arp)
-			goto out_unlock;
-		if (skb_copy_bits(skb, 0, arp, alen) < 0)
-			goto out_unlock;
-	}
-
-	if (arp->ar_hln != bond->dev->addr_len ||
-	    skb->pkt_type == PACKET_OTHERHOST ||
-	    skb->pkt_type == PACKET_LOOPBACK ||
-	    arp->ar_hrd != htons(ARPHRD_ETHER) ||
-	    arp->ar_pro != htons(ETH_P_IP) ||
-	    arp->ar_pln != 4)
-		goto out_unlock;
-
-	arp_ptr = (unsigned char *)(arp + 1);
-	arp_ptr += bond->dev->addr_len;
-	memcpy(&sip, arp_ptr, 4);
-	arp_ptr += 4 + bond->dev->addr_len;
-	memcpy(&tip, arp_ptr, 4);
-
-	slave_dbg(bond->dev, slave->dev, "%s: %s/%d av %d sv %d sip %pI4 tip %pI4\n",
-		  __func__, slave->dev->name, bond_slave_state(slave),
-		  bond->params.arp_validate, slave_do_arp_validate(bond, slave),
-		  &sip, &tip);
-
-	curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	curr_arp_slave = rcu_dereference(bond->current_arp_slave);
-
-	/* We 'trust' the received ARP enough to validate it if:
-	 *
-	 * (a) the slave receiving the ARP is active (which includes the
-	 * current ARP slave, if any), or
-	 *
-	 * (b) the receiving slave isn't active, but there is a currently
-	 * active slave and it received valid arp reply(s) after it became
-	 * the currently active slave, or
-	 *
-	 * (c) there is an ARP slave that sent an ARP during the prior ARP
-	 * interval, and we receive an ARP reply on any slave.  We accept
-	 * these because switch FDB update delays may deliver the ARP
-	 * reply to a slave other than the sender of the ARP request.
-	 *
-	 * Note: for (b), backup slaves are receiving the broadcast ARP
-	 * request, not a reply.  This request passes from the sending
-	 * slave through the L2 switch(es) to the receiving slave.  Since
-	 * this is checking the request, sip/tip are swapped for
-	 * validation.
-	 *
-	 * This is done to avoid endless looping when we can't reach the
-	 * arp_ip_target and fool ourselves with our own arp requests.
-	 */
-	if (bond_is_active_slave(slave))
-		bond_validate_arp(bond, slave, sip, tip);
-	else if (curr_active_slave &&
-		 time_after(slave_last_rx(bond, curr_active_slave),
-			    curr_active_slave->last_link_up))
-		bond_validate_arp(bond, slave, tip, sip);
-	else if (curr_arp_slave && (arp->ar_op == htons(ARPOP_REPLY)) &&
-		 bond_time_in_interval(bond,
-				       dev_trans_start(curr_arp_slave->dev), 1))
-		bond_validate_arp(bond, slave, sip, tip);
-
-out_unlock:
-	if (arp != (struct arphdr *)skb->data)
-		kfree(arp);
-	return RX_HANDLER_ANOTHER;
-}
-
-/* function to verify if we're in the arp_interval timeslice, returns true if
- * (last_act - arp_interval) <= jiffies <= (last_act + mod * arp_interval +
- * arp_interval/2) . the arp_interval/2 is needed for really fast networks.
- */
-static bool bond_time_in_interval(struct bonding *bond, unsigned long last_act,
-				  int mod)
-{
-	int delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	return time_in_range(jiffies,
-			     last_act - delta_in_ticks,
-			     last_act + mod * delta_in_ticks + delta_in_ticks/2);
-}
-
-/* This function is called regularly to monitor each slave's link
- * ensuring that traffic is being sent and received when arp monitoring
- * is used in load-balancing mode. if the adapter has been dormant, then an
- * arp is transmitted to generate traffic. see activebackup_arp_monitor for
- * arp monitoring in active backup mode.
- */
-static void bond_loadbalance_arp_mon(struct bonding *bond)
-{
-	struct slave *slave, *oldcurrent;
-	struct list_head *iter;
-	int do_failover = 0, slave_state_changed = 0;
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	oldcurrent = rcu_dereference(bond->curr_active_slave);
-	/* see if any of the previous devices are up now (i.e. they have
-	 * xmt and rcv traffic). the curr_active_slave does not come into
-	 * the picture unless it is null. also, slave->last_link_up is not
-	 * needed here because we send an arp on each slave and give a slave
-	 * as long as it needs to get the tx/rx within the delta.
-	 * TODO: what about up/down delay in arp mode? it wasn't here before
-	 *       so it can wait
-	 */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		unsigned long trans_start = dev_trans_start(slave->dev);
-
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, trans_start, 1) &&
-			    bond_time_in_interval(bond, slave->last_rx, 1)) {
-
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				slave_state_changed = 1;
-
-				/* primary_slave has no meaning in round-robin
-				 * mode. the window of a slave being up and
-				 * curr_active_slave being null after enslaving
-				 * is closed.
-				 */
-				if (!oldcurrent) {
-					slave_info(bond->dev, slave->dev, "link status definitely up\n");
-					do_failover = 1;
-				} else {
-					slave_info(bond->dev, slave->dev, "interface is now up\n");
-				}
-			}
-		} else {
-			/* slave->link == BOND_LINK_UP */
-
-			/* not all switches will respond to an arp request
-			 * when the source ip is 0, so don't take the link down
-			 * if we don't know our ip yet
-			 */
-			if (!bond_time_in_interval(bond, trans_start, 2) ||
-			    !bond_time_in_interval(bond, slave->last_rx, 2)) {
-
-				bond_propose_link_state(slave, BOND_LINK_DOWN);
-				slave_state_changed = 1;
-
-				if (slave->link_failure_count < UINT_MAX)
-					slave->link_failure_count++;
-
-				slave_info(bond->dev, slave->dev, "interface is now down\n");
-
-				if (slave == oldcurrent)
-					do_failover = 1;
-			}
-		}
-
-		/* note: if switch is in round-robin mode, all links
-		 * must tx arp to ensure all links rx an arp - otherwise
-		 * links may oscillate or not come up at all; if switch is
-		 * in something like xor mode, there is nothing we can
-		 * do - all replies will be rx'ed on same link causing slaves
-		 * to be unstable during low/no traffic periods
-		 */
-		if (bond_slave_is_up(slave))
-			bond_arp_send_all(bond, slave);
-	}
-
-	rcu_read_unlock();
-
-	if (do_failover || slave_state_changed) {
-		if (!rtnl_trylock())
-			goto re_arm;
-
-		bond_for_each_slave(bond, slave, iter) {
-			if (slave->link_new_state != BOND_LINK_NOCHANGE)
-				slave->link = slave->link_new_state;
-		}
-
-		if (slave_state_changed) {
-			bond_slave_state_change(bond);
-			if (BOND_MODE(bond) == BOND_MODE_XOR)
-				bond_update_slave_arr(bond, NULL);
-		}
-		if (do_failover) {
-			block_netpoll_tx();
-			bond_select_active_slave(bond);
-			unblock_netpoll_tx();
-		}
-		rtnl_unlock();
-	}
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work,
-				   msecs_to_jiffies(bond->params.arp_interval));
-}
-
-/* Called to inspect slaves for active-backup mode ARP monitor link state
- * changes.  Sets proposed link state in slaves to specify what action
- * should take place for the slave.  Returns 0 if no changes are found, >0
- * if changes to link states must be committed.
- *
- * Called with rcu_read_lock held.
- */
-static int bond_ab_arp_inspect(struct bonding *bond)
-{
-	unsigned long trans_start, last_rx;
-	struct list_head *iter;
-	struct slave *slave;
-	int commit = 0;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		bond_propose_link_state(slave, BOND_LINK_NOCHANGE);
-		last_rx = slave_last_rx(bond, slave);
-
-		if (slave->link != BOND_LINK_UP) {
-			if (bond_time_in_interval(bond, last_rx, 1)) {
-				bond_propose_link_state(slave, BOND_LINK_UP);
-				commit++;
-			}
-			continue;
-		}
-
-		/* Give slaves 2*delta after being enslaved or made
-		 * active.  This avoids bouncing, as the last receive
-		 * times need a full ARP monitor cycle to be updated.
-		 */
-		if (bond_time_in_interval(bond, slave->last_link_up, 2))
-			continue;
-
-		/* Backup slave is down if:
-		 * - No current_arp_slave AND
-		 * - more than 3*delta since last receive AND
-		 * - the bond has an IP address
-		 *
-		 * Note: a non-null current_arp_slave indicates
-		 * the curr_active_slave went down and we are
-		 * searching for a new one; under this condition
-		 * we only take the curr_active_slave down - this
-		 * gives each slave a chance to tx/rx traffic
-		 * before being taken out
-		 */
-		if (!bond_is_active_slave(slave) &&
-		    !rcu_access_pointer(bond->current_arp_slave) &&
-		    !bond_time_in_interval(bond, last_rx, 3)) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-
-		/* Active slave is down if:
-		 * - more than 2*delta since transmitting OR
-		 * - (more than 2*delta since receive AND
-		 *    the bond has an IP address)
-		 */
-		trans_start = dev_trans_start(slave->dev);
-		if (bond_is_active_slave(slave) &&
-		    (!bond_time_in_interval(bond, trans_start, 2) ||
-		     !bond_time_in_interval(bond, last_rx, 2))) {
-			bond_propose_link_state(slave, BOND_LINK_DOWN);
-			commit++;
-		}
-	}
-
-	return commit;
-}
-
-/* Called to commit link state changes noted by inspection step of
- * active-backup mode ARP monitor.
- *
- * Called with RTNL hold.
- */
-static void bond_ab_arp_commit(struct bonding *bond)
-{
-	unsigned long trans_start;
-	struct list_head *iter;
-	struct slave *slave;
-
-	bond_for_each_slave(bond, slave, iter) {
-		switch (slave->link_new_state) {
-		case BOND_LINK_NOCHANGE:
-			continue;
-
-		case BOND_LINK_UP:
-			trans_start = dev_trans_start(slave->dev);
-			if (rtnl_dereference(bond->curr_active_slave) != slave ||
-			    (!rtnl_dereference(bond->curr_active_slave) &&
-			     bond_time_in_interval(bond, trans_start, 1))) {
-				struct slave *current_arp_slave;
-
-				current_arp_slave = rtnl_dereference(bond->current_arp_slave);
-				bond_set_slave_link_state(slave, BOND_LINK_UP,
-							  BOND_SLAVE_NOTIFY_NOW);
-				if (current_arp_slave) {
-					bond_set_slave_inactive_flags(
-						current_arp_slave,
-						BOND_SLAVE_NOTIFY_NOW);
-					RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				}
-
-				slave_info(bond->dev, slave->dev, "link status definitely up\n");
-
-				if (!rtnl_dereference(bond->curr_active_slave) ||
-				    slave == rtnl_dereference(bond->primary_slave))
-					goto do_failover;
-
-			}
-
-			continue;
-
-		case BOND_LINK_DOWN:
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_NOW);
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_NOW);
-
-			slave_info(bond->dev, slave->dev, "link status definitely down, disabling slave\n");
-
-			if (slave == rtnl_dereference(bond->curr_active_slave)) {
-				RCU_INIT_POINTER(bond->current_arp_slave, NULL);
-				goto do_failover;
-			}
-
-			continue;
-
-		default:
-			slave_err(bond->dev, slave->dev,
-				  "impossible: link_new_state %d on slave\n",
-				  slave->link_new_state);
-			continue;
-		}
-
-do_failover:
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-	}
-
-	bond_set_carrier(bond);
-}
-
-/* Send ARP probes for active-backup mode ARP monitor.
- *
- * Called with rcu_read_lock held.
- */
-static bool bond_ab_arp_probe(struct bonding *bond)
-{
-	struct slave *slave, *before = NULL, *new_slave = NULL,
-		     *curr_arp_slave = rcu_dereference(bond->current_arp_slave),
-		     *curr_active_slave = rcu_dereference(bond->curr_active_slave);
-	struct list_head *iter;
-	bool found = false;
-	bool should_notify_rtnl = BOND_SLAVE_NOTIFY_LATER;
-
-	if (curr_arp_slave && curr_active_slave)
-		netdev_info(bond->dev, "PROBE: c_arp %s && cas %s BAD\n",
-			    curr_arp_slave->dev->name,
-			    curr_active_slave->dev->name);
-
-	if (curr_active_slave) {
-		bond_arp_send_all(bond, curr_active_slave);
-		return should_notify_rtnl;
-	}
-
-	/* if we don't have a curr_active_slave, search for the next available
-	 * backup slave from the current_arp_slave and make it the candidate
-	 * for becoming the curr_active_slave
-	 */
-
-	if (!curr_arp_slave) {
-		curr_arp_slave = bond_first_slave_rcu(bond);
-		if (!curr_arp_slave)
-			return should_notify_rtnl;
-	}
-
-	bond_set_slave_inactive_flags(curr_arp_slave, BOND_SLAVE_NOTIFY_LATER);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (!found && !before && bond_slave_is_up(slave))
-			before = slave;
-
-		if (found && !new_slave && bond_slave_is_up(slave))
-			new_slave = slave;
-		/* if the link state is up at this point, we
-		 * mark it down - this can happen if we have
-		 * simultaneous link failures and
-		 * reselect_active_interface doesn't make this
-		 * one the current slave so it is still marked
-		 * up when it is actually down
-		 */
-		if (!bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			bond_set_slave_link_state(slave, BOND_LINK_DOWN,
-						  BOND_SLAVE_NOTIFY_LATER);
-			if (slave->link_failure_count < UINT_MAX)
-				slave->link_failure_count++;
-
-			bond_set_slave_inactive_flags(slave,
-						      BOND_SLAVE_NOTIFY_LATER);
-
-			slave_info(bond->dev, slave->dev, "backup interface is now down\n");
-		}
-		if (slave == curr_arp_slave)
-			found = true;
-	}
-
-	if (!new_slave && before)
-		new_slave = before;
-
-	if (!new_slave)
-		goto check_state;
-
-	bond_set_slave_link_state(new_slave, BOND_LINK_BACK,
-				  BOND_SLAVE_NOTIFY_LATER);
-	bond_set_slave_active_flags(new_slave, BOND_SLAVE_NOTIFY_LATER);
-	bond_arp_send_all(bond, new_slave);
-	new_slave->last_link_up = jiffies;
-	rcu_assign_pointer(bond->current_arp_slave, new_slave);
-
-check_state:
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->should_notify || slave->should_notify_link) {
-			should_notify_rtnl = BOND_SLAVE_NOTIFY_NOW;
-			break;
-		}
-	}
-	return should_notify_rtnl;
-}
-
-static void bond_activebackup_arp_mon(struct bonding *bond)
-{
-	bool should_notify_peers = false;
-	bool should_notify_rtnl = false;
-	int delta_in_ticks;
-
-	delta_in_ticks = msecs_to_jiffies(bond->params.arp_interval);
-
-	if (!bond_has_slaves(bond))
-		goto re_arm;
-
-	rcu_read_lock();
-
-	should_notify_peers = bond_should_notify_peers(bond);
-
-	if (bond_ab_arp_inspect(bond)) {
-		rcu_read_unlock();
-
-		/* Race avoidance with bond_close flush of workqueue */
-		if (!rtnl_trylock()) {
-			delta_in_ticks = 1;
-			should_notify_peers = false;
-			goto re_arm;
-		}
-
-		bond_ab_arp_commit(bond);
-
-		rtnl_unlock();
-		rcu_read_lock();
-	}
-
-	should_notify_rtnl = bond_ab_arp_probe(bond);
-	rcu_read_unlock();
-
-re_arm:
-	if (bond->params.arp_interval)
-		queue_delayed_work(bond->wq, &bond->arp_work, delta_in_ticks);
-
-	if (should_notify_peers || should_notify_rtnl) {
-		if (!rtnl_trylock())
-			return;
-
-		if (should_notify_peers)
-			call_netdevice_notifiers(NETDEV_NOTIFY_PEERS,
-						 bond->dev);
-		if (should_notify_rtnl) {
-			bond_slave_state_notify(bond);
-			bond_slave_link_notify(bond);
-		}
-
-		rtnl_unlock();
-	}
-}
-
-static void bond_arp_monitor(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    arp_work.work);
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		bond_activebackup_arp_mon(bond);
-	else
-		bond_loadbalance_arp_mon(bond);
-}
-
-/*-------------------------- netdev event handling --------------------------*/
-
-/* Change device name */
-static int bond_event_changename(struct bonding *bond)
-{
-	bond_remove_proc_entry(bond);
-	bond_create_proc_entry(bond);
-
-	bond_debug_reregister(bond);
-
-	return NOTIFY_DONE;
-}
-
-static int bond_master_netdev_event(unsigned long event,
-				    struct net_device *bond_dev)
-{
-	struct bonding *event_bond = netdev_priv(bond_dev);
-
-	netdev_dbg(bond_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_CHANGENAME:
-		return bond_event_changename(event_bond);
-	case NETDEV_UNREGISTER:
-		bond_remove_proc_entry(event_bond);
-		break;
-	case NETDEV_REGISTER:
-		bond_create_proc_entry(event_bond);
-		break;
-	case NETDEV_DOWN: {
-		struct slave *slave = bond_first_slave(event_bond);
-
-		toe_failover(bond_dev, slave ? slave->dev : NULL,
-			     TOE_BOND_DOWN, NULL);
-		break;
-	}
-	case NETDEV_UP: {
-		struct slave *slave = bond_first_slave(event_bond);
-
-		toe_failover(bond_dev, slave ? slave->dev : NULL,
-			     TOE_BOND_UP, NULL);
-		break;
-	}
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-static int bond_slave_netdev_event(unsigned long event,
-				   struct net_device *slave_dev)
-{
-	struct slave *slave = bond_slave_get_rtnl(slave_dev), *primary;
-	struct bonding *bond;
-	struct net_device *bond_dev;
-
-	/* A netdev event can be generated while enslaving a device
-	 * before netdev_rx_handler_register is called in which case
-	 * slave will be NULL
-	 */
-	if (!slave) {
-		netdev_dbg(slave_dev, "%s called on NULL slave\n", __func__);
-		return NOTIFY_DONE;
-	}
-
-	bond_dev = slave->bond->dev;
-	bond = slave->bond;
-	primary = rtnl_dereference(bond->primary_slave);
-
-	slave_dbg(bond_dev, slave_dev, "%s called\n", __func__);
-
-	switch (event) {
-	case NETDEV_UNREGISTER:
-		if (bond_dev->type != ARPHRD_ETHER)
-			bond_release_and_destroy(bond_dev, slave_dev);
-		else
-			__bond_release_one(bond_dev, slave_dev, false, true);
-		break;
-	case NETDEV_UP:
-	case NETDEV_CHANGE:
-		/* For 802.3ad mode only:
-		 * Getting invalid Speed/Duplex values here will put slave
-		 * in weird state. Mark it as link-fail if the link was
-		 * previously up or link-down if it hasn't yet come up, and
-		 * let link-monitoring (miimon) set it right when correct
-		 * speeds/duplex are available.
-		 */
-		if (bond_update_speed_duplex(slave) &&
-		    BOND_MODE(bond) == BOND_MODE_8023AD) {
-			if (slave->last_link_up)
-				slave->link = BOND_LINK_FAIL;
-			else
-				slave->link = BOND_LINK_DOWN;
-		}
-
-		if (BOND_MODE(bond) == BOND_MODE_8023AD)
-			bond_3ad_adapter_speed_duplex_changed(slave);
-		/* Fallthrough */
-	case NETDEV_DOWN:
-		/* Refresh slave-array if applicable!
-		 * If the setup does not use miimon or arpmon (mode-specific!),
-		 * then these events will not cause the slave-array to be
-		 * refreshed. This will cause xmit to use a slave that is not
-		 * usable. Avoid such situation by refeshing the array at these
-		 * events. If these (miimon/arpmon) parameters are configured
-		 * then array gets refreshed twice and that should be fine!
-		 */
-		if (bond_mode_can_use_xmit_hash(bond))
-			bond_update_slave_arr(bond, NULL);
-		break;
-	case NETDEV_CHANGEMTU:
-		/* TODO: Should slaves be allowed to
-		 * independently alter their MTU?  For
-		 * an active-backup bond, slaves need
-		 * not be the same type of device, so
-		 * MTUs may vary.  For other modes,
-		 * slaves arguably should have the
-		 * same MTUs. To do this, we'd need to
-		 * take over the slave's change_mtu
-		 * function for the duration of their
-		 * servitude.
-		 */
-		break;
-	case NETDEV_CHANGENAME:
-		/* we don't care if we don't have primary set */
-		if (!bond_uses_primary(bond) ||
-		    !bond->params.primary[0])
-			break;
-
-		if (slave == primary) {
-			/* slave's name changed - he's no longer primary */
-			RCU_INIT_POINTER(bond->primary_slave, NULL);
-		} else if (!strcmp(slave_dev->name, bond->params.primary)) {
-			/* we have a new primary slave */
-			rcu_assign_pointer(bond->primary_slave, slave);
-		} else { /* we didn't change primary - exit */
-			break;
-		}
-
-		netdev_info(bond->dev, "Primary slave changed to %s, reselecting active slave\n",
-			    primary ? slave_dev->name : "none");
-
-		block_netpoll_tx();
-		bond_select_active_slave(bond);
-		unblock_netpoll_tx();
-		break;
-	case NETDEV_FEAT_CHANGE:
-		bond_compute_features(bond);
-		break;
-	case NETDEV_RESEND_IGMP:
-		/* Propagate to master device */
-		call_netdevice_notifiers(event, slave->bond->dev);
-		break;
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-/* bond_netdev_event: handle netdev notifier chain events.
- *
- * This function receives events for the netdev chain.  The caller (an
- * ioctl handler calling blocking_notifier_call_chain) holds the necessary
- * locks for us to safely manipulate the slave devices (RTNL lock,
- * dev_probe_lock).
- */
-static int bond_netdev_event(struct notifier_block *this,
-			     unsigned long event, void *ptr)
-{
-	struct net_device *event_dev = netdev_notifier_info_to_dev(ptr);
-
-	netdev_dbg(event_dev, "%s received %s\n",
-		   __func__, netdev_cmd_to_name(event));
-
-	if (!(event_dev->priv_flags & IFF_BONDING))
-		return NOTIFY_DONE;
-
-	if (event_dev->flags & IFF_MASTER) {
-		int ret;
-
-		ret = bond_master_netdev_event(event, event_dev);
-		if (ret != NOTIFY_DONE)
-			return ret;
-	}
-
-	if (event_dev->flags & IFF_SLAVE)
-		return bond_slave_netdev_event(event, event_dev);
-
-	return NOTIFY_DONE;
-}
-
-static struct notifier_block bond_netdev_notifier = {
-	.notifier_call = bond_netdev_event,
-};
-
-/*---------------------------- Hashing Policies -----------------------------*/
-
-/* L2 hash helper */
-static inline u32 bond_eth_hash(struct sk_buff *skb)
-{
-	struct ethhdr *ep, hdr_tmp;
-
-	ep = skb_header_pointer(skb, 0, sizeof(hdr_tmp), &hdr_tmp);
-	if (ep)
-		return ep->h_dest[5] ^ ep->h_source[5] ^ ep->h_proto;
-	return 0;
-}
-
-static bool bond_flow_ip(struct sk_buff *skb, struct flow_keys *fk,
-			 int *noff, int *proto, bool l34)
-{
-	const struct ipv6hdr *iph6;
-	const struct iphdr *iph;
-
-	if (skb->protocol == htons(ETH_P_IP)) {
-		if (unlikely(!pskb_may_pull(skb, *noff + sizeof(*iph))))
-			return false;
-		iph = (const struct iphdr *)(skb->data + *noff);
-		iph_to_flow_copy_v4addrs(fk, iph);
-		*noff += iph->ihl << 2;
-		if (!ip_is_fragment(iph))
-			*proto = iph->protocol;
-	} else if (skb->protocol == htons(ETH_P_IPV6)) {
-		if (unlikely(!pskb_may_pull(skb, *noff + sizeof(*iph6))))
-			return false;
-		iph6 = (const struct ipv6hdr *)(skb->data + *noff);
-		iph_to_flow_copy_v6addrs(fk, iph6);
-		*noff += sizeof(*iph6);
-		*proto = iph6->nexthdr;
-	} else {
-		return false;
-	}
-
-	if (l34 && *proto >= 0)
-		fk->ports.ports = skb_flow_get_ports(skb, *noff, *proto);
-
-	return true;
-}
-
-/* Extract the appropriate headers based on bond's xmit policy */
-static bool bond_flow_dissect(struct bonding *bond, struct sk_buff *skb,
-			      struct flow_keys *fk)
-{
-	bool l34 = bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER34;
-	int noff, proto = -1;
-
-	if (bond->params.xmit_policy > BOND_XMIT_POLICY_LAYER23) {
-		memset(fk, 0, sizeof(*fk));
-		return __skb_flow_dissect(NULL, skb, &flow_keys_bonding,
-					  fk, NULL, 0, 0, 0, 0);
-	}
-
-	fk->ports.ports = 0;
-	memset(&fk->icmp, 0, sizeof(fk->icmp));
-	noff = skb_network_offset(skb);
-	if (!bond_flow_ip(skb, fk, &noff, &proto, l34))
-		return false;
-
-	/* ICMP error packets contains at least 8 bytes of the header
-	 * of the packet which generated the error. Use this information
-	 * to correlate ICMP error packets within the same flow which
-	 * generated the error.
-	 */
-	if (proto == IPPROTO_ICMP || proto == IPPROTO_ICMPV6) {
-		skb_flow_get_icmp_tci(skb, &fk->icmp, skb->data,
-				      skb_transport_offset(skb),
-				      skb_headlen(skb));
-		if (proto == IPPROTO_ICMP) {
-			if (!icmp_is_err(fk->icmp.type))
-				return true;
-
-			noff += sizeof(struct icmphdr);
-		} else if (proto == IPPROTO_ICMPV6) {
-			if (!icmpv6_is_err(fk->icmp.type))
-				return true;
-
-			noff += sizeof(struct icmp6hdr);
-		}
-		return bond_flow_ip(skb, fk, &noff, &proto, l34);
-	}
-
-	return true;
-}
-
-/**
- * bond_xmit_hash - generate a hash value based on the xmit policy
- * @bond: bonding device
- * @skb: buffer to use for headers
- *
- * This function will extract the necessary headers from the skb buffer and use
- * them to generate a hash based on the xmit_policy set in the bonding device
- */
-u32 bond_xmit_hash(struct bonding *bond, struct sk_buff *skb)
-{
-	struct flow_keys flow;
-	u32 hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP34 &&
-	    skb->l4_hash)
-		return skb->hash;
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER2 ||
-	    !bond_flow_dissect(bond, skb, &flow))
-		return bond_eth_hash(skb);
-
-	if (bond->params.xmit_policy == BOND_XMIT_POLICY_LAYER23 ||
-	    bond->params.xmit_policy == BOND_XMIT_POLICY_ENCAP23) {
-		hash = bond_eth_hash(skb);
-	} else {
-		if (flow.icmp.id)
-			memcpy(&hash, &flow.icmp, sizeof(hash));
-		else
-			memcpy(&hash, &flow.ports.ports, sizeof(hash));
-	}
-	hash ^= (__force u32)flow_get_u32_dst(&flow) ^
-		(__force u32)flow_get_u32_src(&flow);
-	hash ^= (hash >> 16);
-	hash ^= (hash >> 8);
-
-	return hash >> 1;
-}
-
-/*-------------------------- Device entry points ----------------------------*/
-
-void bond_work_init_all(struct bonding *bond)
-{
-	INIT_DELAYED_WORK(&bond->mcast_work,
-			  bond_resend_igmp_join_requests_delayed);
-	INIT_DELAYED_WORK(&bond->alb_work, bond_alb_monitor);
-	INIT_DELAYED_WORK(&bond->mii_work, bond_mii_monitor);
-	INIT_DELAYED_WORK(&bond->arp_work, bond_arp_monitor);
-	INIT_DELAYED_WORK(&bond->ad_work, bond_3ad_state_machine_handler);
-	INIT_DELAYED_WORK(&bond->slave_arr_work, bond_slave_arr_handler);
-}
-
-static void bond_work_cancel_all(struct bonding *bond)
-{
-	cancel_delayed_work_sync(&bond->mii_work);
-	cancel_delayed_work_sync(&bond->arp_work);
-	cancel_delayed_work_sync(&bond->alb_work);
-	cancel_delayed_work_sync(&bond->ad_work);
-	cancel_delayed_work_sync(&bond->mcast_work);
-	cancel_delayed_work_sync(&bond->slave_arr_work);
-}
-
-static int bond_open(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	/* reset slave->backup and slave->inactive */
-	if (bond_has_slaves(bond)) {
-		bond_for_each_slave(bond, slave, iter) {
-			if (bond_uses_primary(bond) &&
-			    slave != rcu_access_pointer(bond->curr_active_slave)) {
-				bond_set_slave_inactive_flags(slave,
-							      BOND_SLAVE_NOTIFY_NOW);
-			} else if (BOND_MODE(bond) != BOND_MODE_8023AD) {
-				bond_set_slave_active_flags(slave,
-							    BOND_SLAVE_NOTIFY_NOW);
-			}
-		}
-	}
-
-	if (bond_is_lb(bond)) {
-		/* bond_alb_initialize must be called before the timer
-		 * is started.
-		 */
-		if (bond_alb_initialize(bond, (BOND_MODE(bond) == BOND_MODE_ALB)))
-			return -ENOMEM;
-		if (bond->params.tlb_dynamic_lb || BOND_MODE(bond) == BOND_MODE_ALB)
-			queue_delayed_work(bond->wq, &bond->alb_work, 0);
-	}
-
-	if (bond->params.miimon)  /* link check interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->mii_work, 0);
-
-	if (bond->params.arp_interval) {  /* arp interval, in milliseconds. */
-		queue_delayed_work(bond->wq, &bond->arp_work, 0);
-		bond->recv_probe = bond_arp_rcv;
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		queue_delayed_work(bond->wq, &bond->ad_work, 0);
-		/* register to receive LACPDUs */
-		bond->recv_probe = bond_3ad_lacpdu_recv;
-		bond_3ad_initiate_agg_selection(bond, 1);
-	}
-
-	if (bond_mode_can_use_xmit_hash(bond))
-		bond_update_slave_arr(bond, NULL);
-
-	return 0;
-}
-
-static int bond_close(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	bond_work_cancel_all(bond);
-	bond->send_peer_notif = 0;
-	if (bond_is_lb(bond))
-		bond_alb_deinitialize(bond);
-	bond->recv_probe = NULL;
-
-	return 0;
-}
-
-/* fold stats, assuming all rtnl_link_stats64 fields are u64, but
- * that some drivers can provide 32bit values only.
- */
-static void bond_fold_stats(struct rtnl_link_stats64 *_res,
-			    const struct rtnl_link_stats64 *_new,
-			    const struct rtnl_link_stats64 *_old)
-{
-	const u64 *new = (const u64 *)_new;
-	const u64 *old = (const u64 *)_old;
-	u64 *res = (u64 *)_res;
-	int i;
-
-	for (i = 0; i < sizeof(*_res) / sizeof(u64); i++) {
-		u64 nv = new[i];
-		u64 ov = old[i];
-		s64 delta = nv - ov;
-
-		/* detects if this particular field is 32bit only */
-		if (((nv | ov) >> 32) == 0)
-			delta = (s64)(s32)((u32)nv - (u32)ov);
-
-		/* filter anomalies, some drivers reset their stats
-		 * at down/up events.
-		 */
-		if (delta > 0)
-			res[i] += delta;
-	}
-}
-
-#ifdef CONFIG_LOCKDEP
-static int bond_get_lowest_level_rcu(struct net_device *dev)
-{
-	struct net_device *ldev, *next, *now, *dev_stack[MAX_NEST_DEV + 1];
-	struct list_head *niter, *iter, *iter_stack[MAX_NEST_DEV + 1];
-	int cur = 0, max = 0;
-
-	now = dev;
-	iter = &dev->adj_list.lower;
-
-	while (1) {
-		next = NULL;
-		while (1) {
-			ldev = netdev_next_lower_dev_rcu(now, &iter);
-			if (!ldev)
-				break;
-
-			next = ldev;
-			niter = &ldev->adj_list.lower;
-			dev_stack[cur] = now;
-			iter_stack[cur++] = iter;
-			if (max <= cur)
-				max = cur;
-			break;
-		}
-
-		if (!next) {
-			if (!cur)
-				return max;
-			next = dev_stack[--cur];
-			niter = iter_stack[cur];
-		}
-
-		now = next;
-		iter = niter;
-	}
-
-	return max;
-}
-#endif
-
-static void bond_get_stats(struct net_device *bond_dev,
-			   struct rtnl_link_stats64 *stats)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct rtnl_link_stats64 temp;
-	struct list_head *iter;
-	struct slave *slave;
-	int nest_level = 0;
-
-
-	rcu_read_lock();
-#ifdef CONFIG_LOCKDEP
-	nest_level = bond_get_lowest_level_rcu(bond_dev);
-#endif
-
-	spin_lock_nested(&bond->stats_lock, nest_level);
-	memcpy(stats, &bond->bond_stats, sizeof(*stats));
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		const struct rtnl_link_stats64 *new =
-			dev_get_stats(slave->dev, &temp);
-
-		bond_fold_stats(stats, new, &slave->slave_stats);
-
-		/* save off the slave stats for the next run */
-		memcpy(&slave->slave_stats, new, sizeof(*new));
-	}
-
-	memcpy(&bond->bond_stats, stats, sizeof(*stats));
-	spin_unlock(&bond->stats_lock);
-	rcu_read_unlock();
-}
-
-static int bond_do_ioctl(struct net_device *bond_dev, struct ifreq *ifr, int cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct ifbond k_binfo;
-	struct ifbond __user *u_binfo = NULL;
-	struct ifslave k_sinfo;
-	struct ifslave __user *u_sinfo = NULL;
-	struct mii_ioctl_data *mii = NULL;
-	struct bond_opt_value newval;
-	struct net *net;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond_ioctl: cmd=%d\n", cmd);
-
-	switch (cmd) {
-	case SIOCGMIIPHY:
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		mii->phy_id = 0;
-		/* Fall Through */
-	case SIOCGMIIREG:
-		/* We do this again just in case we were called by SIOCGMIIREG
-		 * instead of SIOCGMIIPHY.
-		 */
-		mii = if_mii(ifr);
-		if (!mii)
-			return -EINVAL;
-
-		if (mii->reg_num == 1) {
-			mii->val_out = 0;
-			if (netif_carrier_ok(bond->dev))
-				mii->val_out = BMSR_LSTATUS;
-		}
-
-		return 0;
-	case BOND_INFO_QUERY_OLD:
-	case SIOCBONDINFOQUERY:
-		u_binfo = (struct ifbond __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_binfo, u_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		bond_info_query(bond_dev, &k_binfo);
-		if (copy_to_user(u_binfo, &k_binfo, sizeof(ifbond)))
-			return -EFAULT;
-
-		return 0;
-	case BOND_SLAVE_INFO_QUERY_OLD:
-	case SIOCBONDSLAVEINFOQUERY:
-		u_sinfo = (struct ifslave __user *)ifr->ifr_data;
-
-		if (copy_from_user(&k_sinfo, u_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		res = bond_slave_info_query(bond_dev, &k_sinfo);
-		if (res == 0 &&
-		    copy_to_user(u_sinfo, &k_sinfo, sizeof(ifslave)))
-			return -EFAULT;
-
-		return res;
-	default:
-		break;
-	}
-
-	net = dev_net(bond_dev);
-
-	if (!ns_capable(net->user_ns, CAP_NET_ADMIN))
-		return -EPERM;
-
-	slave_dev = __dev_get_by_name(net, ifr->ifr_slave);
-
-	slave_dbg(bond_dev, slave_dev, "slave_dev=%p:\n", slave_dev);
-
-	if (!slave_dev)
-		return -ENODEV;
-
-	switch (cmd) {
-	case BOND_ENSLAVE_OLD:
-	case SIOCBONDENSLAVE:
-		res = bond_enslave(bond_dev, slave_dev, NULL);
-		break;
-	case BOND_RELEASE_OLD:
-	case SIOCBONDRELEASE:
-		res = bond_release(bond_dev, slave_dev);
-		if (!res)
-			netdev_update_lockdep_key(slave_dev);
-		break;
-	case BOND_SETHWADDR_OLD:
-	case SIOCBONDSETHWADDR:
-		res = bond_set_dev_addr(bond_dev, slave_dev);
-		break;
-	case BOND_CHANGE_ACTIVE_OLD:
-	case SIOCBONDCHANGEACTIVE:
-		bond_opt_initstr(&newval, slave_dev->name);
-		res = __bond_opt_set_notify(bond, BOND_OPT_ACTIVE_SLAVE,
-					    &newval);
-		break;
-	default:
-		res = -EOPNOTSUPP;
-	}
-
-	return res;
-}
-
-static void bond_change_rx_flags(struct net_device *bond_dev, int change)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	if (change & IFF_PROMISC)
-		bond_set_promiscuity(bond,
-				     bond_dev->flags & IFF_PROMISC ? 1 : -1);
-
-	if (change & IFF_ALLMULTI)
-		bond_set_allmulti(bond,
-				  bond_dev->flags & IFF_ALLMULTI ? 1 : -1);
-}
-
-static void bond_set_rx_mode(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-
-	rcu_read_lock();
-	if (bond_uses_primary(bond)) {
-		slave = rcu_dereference(bond->curr_active_slave);
-		if (slave) {
-			dev_uc_sync(slave->dev, bond_dev);
-			dev_mc_sync(slave->dev, bond_dev);
-		}
-	} else {
-		bond_for_each_slave_rcu(bond, slave, iter) {
-			dev_uc_sync_multiple(slave->dev, bond_dev);
-			dev_mc_sync_multiple(slave->dev, bond_dev);
-		}
-	}
-	rcu_read_unlock();
-}
-
-static int bond_neigh_init(struct neighbour *n)
-{
-	struct bonding *bond = netdev_priv(n->dev);
-	const struct net_device_ops *slave_ops;
-	struct neigh_parms parms;
-	struct slave *slave;
-	int ret = 0;
-
-	rcu_read_lock();
-	slave = bond_first_slave_rcu(bond);
-	if (!slave)
-		goto out;
-	slave_ops = slave->dev->netdev_ops;
-	if (!slave_ops->ndo_neigh_setup)
-		goto out;
-
-	/* TODO: find another way [1] to implement this.
-	 * Passing a zeroed structure is fragile,
-	 * but at least we do not pass garbage.
-	 *
-	 * [1] One way would be that ndo_neigh_setup() never touch
-	 *     struct neigh_parms, but propagate the new neigh_setup()
-	 *     back to ___neigh_create() / neigh_parms_alloc()
-	 */
-	memset(&parms, 0, sizeof(parms));
-	ret = slave_ops->ndo_neigh_setup(slave->dev, &parms);
-
-	if (ret)
-		goto out;
-
-	if (parms.neigh_setup)
-		ret = parms.neigh_setup(n);
-out:
-	rcu_read_unlock();
-	return ret;
-}
-
-/* The bonding ndo_neigh_setup is called at init time beofre any
- * slave exists. So we must declare proxy setup function which will
- * be used at run time to resolve the actual slave neigh param setup.
- *
- * It's also called by master devices (such as vlans) to setup their
- * underlying devices. In that case - do nothing, we're already set up from
- * our init.
- */
-static int bond_neigh_setup(struct net_device *dev,
-			    struct neigh_parms *parms)
-{
-	/* modify only our neigh_parms */
-	if (parms->dev == dev)
-		parms->neigh_setup = bond_neigh_init;
-
-	return 0;
-}
-
-/* Change the MTU of all of a master's slaves to match the master */
-static int bond_change_mtu(struct net_device *bond_dev, int new_mtu)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct list_head *iter;
-	int res = 0;
-
-	netdev_dbg(bond_dev, "bond=%p, new_mtu=%d\n", bond, new_mtu);
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "s %p c_m %p\n",
-			   slave, slave->dev->netdev_ops->ndo_change_mtu);
-
-		res = dev_set_mtu(slave->dev, new_mtu);
-
-		if (res) {
-			/* If we failed to set the slave's mtu to the new value
-			 * we must abort the operation even in ACTIVE_BACKUP
-			 * mode, because if we allow the backup slaves to have
-			 * different mtu values than the active slave we'll
-			 * need to change their mtu when doing a failover. That
-			 * means changing their mtu from timer context, which
-			 * is probably not a good idea.
-			 */
-			slave_dbg(bond_dev, slave->dev, "err %d setting mtu to %d\n",
-				  res, new_mtu);
-			goto unwind;
-		}
-	}
-
-	bond_dev->mtu = new_mtu;
-
-	return 0;
-
-unwind:
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mtu(rollback_slave->dev, bond_dev->mtu);
-		if (tmp_res)
-			slave_dbg(bond_dev, rollback_slave->dev, "unwind err %d\n",
-				  tmp_res);
-	}
-
-	return res;
-}
-
-/* Change HW address
- *
- * Note that many devices must be down to change the HW address, and
- * downing the master releases all slaves.  We can make bonds full of
- * bonding devices to test this, however.
- */
-static int bond_set_mac_address(struct net_device *bond_dev, void *addr)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave, *rollback_slave;
-	struct sockaddr_storage *ss = addr, tmp_ss;
-	struct list_head *iter;
-	int res = 0;
-
-	if (BOND_MODE(bond) == BOND_MODE_ALB)
-		return bond_alb_set_mac_address(bond_dev, addr);
-
-
-	netdev_dbg(bond_dev, "%s: bond=%p\n", __func__, bond);
-
-	/* If fail_over_mac is enabled, do nothing and return success.
-	 * Returning an error causes ifenslave to fail.
-	 */
-	if (bond->params.fail_over_mac &&
-	    BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP)
-		return 0;
-
-	if (!is_valid_ether_addr(ss->__data))
-		return -EADDRNOTAVAIL;
-
-	bond_for_each_slave(bond, slave, iter) {
-		slave_dbg(bond_dev, slave->dev, "%s: slave=%p\n",
-			  __func__, slave);
-		res = dev_set_mac_address(slave->dev, addr, NULL);
-		if (res) {
-			/* TODO: consider downing the slave
-			 * and retry ?
-			 * User should expect communications
-			 * breakage anyway until ARP finish
-			 * updating, so...
-			 */
-			slave_dbg(bond_dev, slave->dev, "%s: err %d\n",
-				  __func__, res);
-			goto unwind;
-		}
-	}
-
-	/* success */
-	memcpy(bond_dev->dev_addr, ss->__data, bond_dev->addr_len);
-	return 0;
-
-unwind:
-	memcpy(tmp_ss.__data, bond_dev->dev_addr, bond_dev->addr_len);
-	tmp_ss.ss_family = bond_dev->type;
-
-	/* unwind from head to the slave that failed */
-	bond_for_each_slave(bond, rollback_slave, iter) {
-		int tmp_res;
-
-		if (rollback_slave == slave)
-			break;
-
-		tmp_res = dev_set_mac_address(rollback_slave->dev,
-					      (struct sockaddr *)&tmp_ss, NULL);
-		if (tmp_res) {
-			slave_dbg(bond_dev, rollback_slave->dev, "%s: unwind err %d\n",
-				   __func__, tmp_res);
-		}
-	}
-
-	return res;
-}
-
-static struct net_device *bond_xmit_slave_id_select(struct bonding *bond, int slave_id)
-{
-	struct list_head *iter;
-	struct slave *slave;
-	struct net_device *slave_dev = NULL;
-	int i = slave_id;
-
-	/* Here we start from the slave with slave_id */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0) {
-			if (bond_slave_can_tx(slave)) {
-				slave_dev = slave->dev;
-				return slave_dev;
-			}
-		}
-	}
-
-	/* Here we start from the first slave up to slave_id */
-	i = slave_id;
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0)
-			break;
-		if (bond_slave_can_tx(slave)) {
-			slave_dev = slave->dev;
-			return slave_dev;
-		}
-	}
-	return slave_dev;
-}
-
-/**
- * bond_xmit_slave_id - transmit skb through slave with slave_id
- * @bond: bonding device that is transmitting
- * @skb: buffer to transmit
- * @slave_id: slave id up to slave_cnt-1 through which to transmit
- *
- * This function tries to transmit through slave with slave_id but in case
- * it fails, it tries to find the first available slave for transmission.
- * The skb is consumed in all cases, thus the function is void.
- */
-static void bond_xmit_slave_id(struct bonding *bond, struct sk_buff *skb, int slave_id)
-{
-	struct list_head *iter;
-	struct slave *slave;
-	int i = slave_id;
-
-	/* Here we start from the slave with slave_id */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0) {
-			if (bond_slave_can_tx(slave)) {
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-				return;
-			}
-		}
-	}
-
-	/* Here we start from the first slave up to slave_id */
-	i = slave_id;
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (--i < 0)
-			break;
-		if (bond_slave_can_tx(slave)) {
-			bond_dev_queue_xmit(bond, skb, slave->dev);
-			return;
-		}
-	}
-	/* no slave that can tx has been found */
-	bond_tx_drop(bond->dev, skb);
-}
-
-/**
- * bond_rr_gen_slave_id - generate slave id based on packets_per_slave
- * @bond: bonding device to use
- *
- * Based on the value of the bonding device's packets_per_slave parameter
- * this function generates a slave id, which is usually used as the next
- * slave to transmit through.
- */
-static u32 bond_rr_gen_slave_id(struct bonding *bond)
-{
-	u32 slave_id;
-	struct reciprocal_value reciprocal_packets_per_slave;
-	int packets_per_slave = bond->params.packets_per_slave;
-
-	switch (packets_per_slave) {
-	case 0:
-		slave_id = prandom_u32();
-		break;
-	case 1:
-		slave_id = bond->rr_tx_counter;
-		break;
-	default:
-		reciprocal_packets_per_slave =
-			bond->params.reciprocal_packets_per_slave;
-		slave_id = reciprocal_divide(bond->rr_tx_counter,
-					     reciprocal_packets_per_slave);
-		break;
-	}
-	bond->rr_tx_counter++;
-
-	return slave_id;
-}
-
-static struct net_device *bond_xmit_roundrobin_select(int slave_id,
-						      struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	return bond_xmit_slave_id_select(bond, slave_id);
-}
-
-static netdev_tx_t bond_xmit_roundrobin(struct sk_buff *skb,
-					struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-	int slave_cnt;
-	u32 slave_id;
-
-	/* Start with the curr_active_slave that joined the bond as the
-	 * default for sending IGMP traffic.  For failover purposes one
-	 * needs to maintain some consistency for the interface that will
-	 * send the join/membership reports.  The curr_active_slave found
-	 * will send all of this type of traffic.
-	 */
-	if (skb->protocol == htons(ETH_P_IP)) {
-		int noff = skb_network_offset(skb);
-		struct iphdr *iph;
-
-		if (unlikely(!pskb_may_pull(skb, noff + sizeof(*iph))))
-			goto non_igmp;
-
-		iph = ip_hdr(skb);
-		if (iph->protocol == IPPROTO_IGMP) {
-			slave = rcu_dereference(bond->curr_active_slave);
-			if (slave)
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-			else
-				bond_xmit_slave_id(bond, skb, 0);
-			return NETDEV_TX_OK;
-		}
-	}
-
-non_igmp:
-	slave_cnt = READ_ONCE(bond->slave_cnt);
-	if (likely(slave_cnt)) {
-		slave_id = bond_rr_gen_slave_id(bond);
-		bond_xmit_slave_id(bond, skb, slave_id % slave_cnt);
-	} else {
-		bond_tx_drop(bond_dev, skb);
-	}
-	return NETDEV_TX_OK;
-}
-
-static struct net_device *bond_xmit_activebackup_select(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct net_device *slave_dev = NULL;
-	struct slave *slave;
-
-	slave = rcu_dereference(bond->curr_active_slave);
-	if (slave)
-		slave_dev = slave->dev;
-
-	return slave_dev;
-}
-
-/* In active-backup mode, we know that bond->curr_active_slave is always valid if
- * the bond has a usable interface.
- */
-static netdev_tx_t bond_xmit_activebackup(struct sk_buff *skb,
-					  struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave;
-
-	slave = rcu_dereference(bond->curr_active_slave);
-	if (slave)
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	else
-		bond_tx_drop(bond_dev, skb);
-
-	return NETDEV_TX_OK;
-}
-
-/* Use this to update slave_array when (a) it's not appropriate to update
- * slave_array right away (note that update_slave_array() may sleep)
- * and / or (b) RTNL is not held.
- */
-void bond_slave_arr_work_rearm(struct bonding *bond, unsigned long delay)
-{
-	queue_delayed_work(bond->wq, &bond->slave_arr_work, delay);
-}
-
-/* Slave array work handler. Holds only RTNL */
-static void bond_slave_arr_handler(struct work_struct *work)
-{
-	struct bonding *bond = container_of(work, struct bonding,
-					    slave_arr_work.work);
-	int ret;
-
-	if (!rtnl_trylock())
-		goto err;
-
-	ret = bond_update_slave_arr(bond, NULL);
-	rtnl_unlock();
-	if (ret) {
-		pr_warn_ratelimited("Failed to update slave array from WT\n");
-		goto err;
-	}
-	return;
-
-err:
-	bond_slave_arr_work_rearm(bond, 1);
-}
-
-/* Build the usable slaves array in control path for modes that use xmit-hash
- * to determine the slave interface -
- * (a) BOND_MODE_8023AD
- * (b) BOND_MODE_XOR
- * (c) (BOND_MODE_TLB || BOND_MODE_ALB) && tlb_dynamic_lb == 0
- *
- * The caller is expected to hold RTNL only and NO other lock!
- */
-int bond_update_slave_arr(struct bonding *bond, struct slave *skipslave)
-{
-	struct slave *slave;
-	struct list_head *iter;
-	struct bond_up_slave *new_arr, *old_arr;
-	int agg_id = 0;
-	int ret = 0;
-
-#ifdef CONFIG_LOCKDEP
-	WARN_ON(lockdep_is_held(&bond->mode_lock));
-#endif
-
-	new_arr = kzalloc(offsetof(struct bond_up_slave, arr[bond->slave_cnt]),
-			  GFP_KERNEL);
-	if (!new_arr) {
-		ret = -ENOMEM;
-		pr_err("Failed to build slave-array.\n");
-		goto out;
-	}
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-
-		if (bond_3ad_get_active_agg_info(bond, &ad_info)) {
-			pr_debug("bond_3ad_get_active_agg_info failed\n");
-			kfree_rcu(new_arr, rcu);
-			/* No active aggragator means it's not safe to use
-			 * the previous array.
-			 */
-			old_arr = rtnl_dereference(bond->slave_arr);
-			if (old_arr) {
-				RCU_INIT_POINTER(bond->slave_arr, NULL);
-				kfree_rcu(old_arr, rcu);
-			}
-			goto out;
-		}
-		agg_id = ad_info.aggregator_id;
-	}
-	bond_for_each_slave(bond, slave, iter) {
-		if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-			struct aggregator *agg;
-
-			agg = SLAVE_AD_INFO(slave)->port.aggregator;
-			if (!agg || agg->aggregator_identifier != agg_id)
-				continue;
-		}
-		if (!bond_slave_can_tx(slave))
-			continue;
-		if (skipslave == slave)
-			continue;
-
-		slave_dbg(bond->dev, slave->dev, "Adding slave to tx hash array[%d]\n",
-			  new_arr->count);
-
-		new_arr->arr[new_arr->count++] = slave;
-	}
-
-	old_arr = rtnl_dereference(bond->slave_arr);
-	rcu_assign_pointer(bond->slave_arr, new_arr);
-	if (old_arr)
-		kfree_rcu(old_arr, rcu);
-out:
-	if (ret != 0 && skipslave) {
-		int idx;
-
-		/* Rare situation where caller has asked to skip a specific
-		 * slave but allocation failed (most likely!). BTW this is
-		 * only possible when the call is initiated from
-		 * __bond_release_one(). In this situation; overwrite the
-		 * skipslave entry in the array with the last entry from the
-		 * array to avoid a situation where the xmit path may choose
-		 * this to-be-skipped slave to send a packet out.
-		 */
-		old_arr = rtnl_dereference(bond->slave_arr);
-		for (idx = 0; old_arr != NULL && idx < old_arr->count; idx++) {
-			if (skipslave == old_arr->arr[idx]) {
-				old_arr->arr[idx] =
-				    old_arr->arr[old_arr->count-1];
-				old_arr->count--;
-				break;
-			}
-		}
-	}
-	return ret;
-}
-
-static struct net_device *bond_xmit_xor_select(int slave_id,
-					       struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_up_slave *slaves;
-	struct slave *slave;
-	struct net_device *slave_dev = NULL;
-	unsigned int count;
-
-	slaves = rcu_dereference(bond->slave_arr);
-	count = slaves ? READ_ONCE(slaves->count) : 0;
-	if (likely(count)) {
-		slave = slaves->arr[slave_id];
-		if (slave)
-			slave_dev = slave->dev;
-	}
-	return slave_dev;
-}
-
-/* Use this Xmit function for 3AD as well as XOR modes. The current
- * usable slave array is formed in the control path. The xmit function
- * just calculates hash and sends the packet out.
- */
-static netdev_tx_t bond_3ad_xor_xmit(struct sk_buff *skb,
-				     struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	struct slave *slave;
-	struct bond_up_slave *slaves;
-	unsigned int count;
-
-	slaves = rcu_dereference(bond->slave_arr);
-	count = slaves ? READ_ONCE(slaves->count) : 0;
-	if (likely(count)) {
-		slave = slaves->arr[bond_xmit_hash(bond, skb) % count];
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	} else {
-		bond_tx_drop(dev, skb);
-	}
-
-	return NETDEV_TX_OK;
-}
-
-/* in broadcast mode, we send everything to all usable interfaces. */
-static netdev_tx_t bond_xmit_broadcast(struct sk_buff *skb,
-				       struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (bond_is_last_slave(bond, slave))
-			break;
-		if (bond_slave_is_up(slave) && slave->link == BOND_LINK_UP) {
-			struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
-
-			if (!skb2) {
-				net_err_ratelimited("%s: Error: %s: skb_clone() failed\n",
-						    bond_dev->name, __func__);
-				continue;
-			}
-			bond_dev_queue_xmit(bond, skb2, slave->dev);
-		}
-	}
-	if (slave && bond_slave_is_up(slave) && slave->link == BOND_LINK_UP)
-		bond_dev_queue_xmit(bond, skb, slave->dev);
-	else
-		bond_tx_drop(bond_dev, skb);
-
-	return NETDEV_TX_OK;
-}
-
-/*------------------------- Device initialization ---------------------------*/
-
-/* Lookup the slave that corresponds to a qid */
-static inline int bond_slave_override(struct bonding *bond,
-				      struct sk_buff *skb)
-{
-	struct slave *slave = NULL;
-	struct list_head *iter;
-
-	if (!skb_rx_queue_recorded(skb))
-		return 1;
-
-	/* Find out if any slaves have the same mapping as this skb. */
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (slave->queue_id == skb_get_queue_mapping(skb)) {
-			if (bond_slave_is_up(slave) &&
-			    slave->link == BOND_LINK_UP) {
-				bond_dev_queue_xmit(bond, skb, slave->dev);
-				return 0;
-			}
-			/* If the slave isn't UP, use default transmit policy. */
-			break;
-		}
-	}
-
-	return 1;
-}
-
-
-static u16 bond_select_queue(struct net_device *dev, struct sk_buff *skb,
-			     struct net_device *sb_dev)
-{
-	/* This helper function exists to help dev_pick_tx get the correct
-	 * destination queue.  Using a helper function skips a call to
-	 * skb_tx_hash and will put the skbs in the queue we expect on their
-	 * way down to the bonding driver.
-	 */
-	u16 txq = skb_rx_queue_recorded(skb) ? skb_get_rx_queue(skb) : 0;
-
-	/* Save the original txq to restore before passing to the driver */
-	qdisc_skb_cb(skb)->slave_dev_queue_mapping = skb_get_queue_mapping(skb);
-
-	if (unlikely(txq >= dev->real_num_tx_queues)) {
-		do {
-			txq -= dev->real_num_tx_queues;
-		} while (txq >= dev->real_num_tx_queues);
-	}
-	return txq;
-}
-
-static netdev_tx_t __bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-
-	if (bond_should_override_tx_queue(bond) &&
-	    !bond_slave_override(bond, skb))
-		return NETDEV_TX_OK;
-
-	switch (BOND_MODE(bond)) {
-	case BOND_MODE_ROUNDROBIN:
-		return bond_xmit_roundrobin(skb, dev);
-	case BOND_MODE_ACTIVEBACKUP:
-		return bond_xmit_activebackup(skb, dev);
-	case BOND_MODE_8023AD:
-	case BOND_MODE_XOR:
-		return bond_3ad_xor_xmit(skb, dev);
-	case BOND_MODE_BROADCAST:
-		return bond_xmit_broadcast(skb, dev);
-	case BOND_MODE_ALB:
-		return bond_alb_xmit(skb, dev);
-	case BOND_MODE_TLB:
-		return bond_tlb_xmit(skb, dev);
-	default:
-		/* Should never happen, mode already checked */
-		netdev_err(dev, "Unknown bonding mode %d\n", BOND_MODE(bond));
-		WARN_ON_ONCE(1);
-		bond_tx_drop(dev, skb);
-		return NETDEV_TX_OK;
-	}
-}
-
-static netdev_tx_t bond_start_xmit(struct sk_buff *skb, struct net_device *dev)
-{
-	struct bonding *bond = netdev_priv(dev);
-	netdev_tx_t ret = NETDEV_TX_OK;
-
-	/* If we risk deadlock from transmitting this in the
-	 * netpoll path, tell netpoll to queue the frame for later tx
-	 */
-	if (unlikely(is_netpoll_tx_blocked(dev)))
-		return NETDEV_TX_BUSY;
-
-	rcu_read_lock();
-	if (bond_has_slaves(bond))
-		ret = __bond_start_xmit(skb, dev);
-	else
-		bond_tx_drop(dev, skb);
-	rcu_read_unlock();
-
-	return ret;
-}
-
-static int bond_ethtool_get_link_ksettings(struct net_device *bond_dev,
-					   struct ethtool_link_ksettings *cmd)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	unsigned long speed = 0;
-	struct list_head *iter;
-	struct slave *slave;
-
-	cmd->base.duplex = DUPLEX_UNKNOWN;
-	cmd->base.port = PORT_OTHER;
-
-	/* Since bond_slave_can_tx returns false for all inactive or down slaves, we
-	 * do not need to check mode.  Though link speed might not represent
-	 * the true receive or transmit bandwidth (not all modes are symmetric)
-	 * this is an accurate maximum.
-	 */
-	bond_for_each_slave(bond, slave, iter) {
-		if (bond_slave_can_tx(slave)) {
-			if (slave->speed != SPEED_UNKNOWN)
-				speed += slave->speed;
-			if (cmd->base.duplex == DUPLEX_UNKNOWN &&
-			    slave->duplex != DUPLEX_UNKNOWN)
-				cmd->base.duplex = slave->duplex;
-		}
-	}
-	cmd->base.speed = speed ? : SPEED_UNKNOWN;
-
-	return 0;
-}
-
-static void bond_ethtool_get_drvinfo(struct net_device *bond_dev,
-				     struct ethtool_drvinfo *drvinfo)
-{
-	strlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));
-	strlcpy(drvinfo->version, DRV_VERSION, sizeof(drvinfo->version));
-	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version), "%d",
-		 BOND_ABI_VERSION);
-}
-
-static const struct ethtool_ops bond_ethtool_ops = {
-	.get_drvinfo		= bond_ethtool_get_drvinfo,
-	.get_link		= ethtool_op_get_link,
-	.get_link_ksettings	= bond_ethtool_get_link_ksettings,
-};
-
-static const struct net_device_ops bond_netdev_ops = {
-	.ndo_init		= bond_init,
-	.ndo_uninit		= bond_uninit,
-	.ndo_open		= bond_open,
-	.ndo_stop		= bond_close,
-	.ndo_start_xmit		= bond_start_xmit,
-	.ndo_select_queue	= bond_select_queue,
-	.ndo_get_stats64	= bond_get_stats,
-	.ndo_do_ioctl		= bond_do_ioctl,
-	.ndo_change_rx_flags	= bond_change_rx_flags,
-	.ndo_set_rx_mode	= bond_set_rx_mode,
-	.ndo_change_mtu		= bond_change_mtu,
-	.ndo_set_mac_address	= bond_set_mac_address,
-	.ndo_neigh_setup	= bond_neigh_setup,
-	.ndo_vlan_rx_add_vid	= bond_vlan_rx_add_vid,
-	.ndo_vlan_rx_kill_vid	= bond_vlan_rx_kill_vid,
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	.ndo_netpoll_setup	= bond_netpoll_setup,
-	.ndo_netpoll_cleanup	= bond_netpoll_cleanup,
-	.ndo_poll_controller	= bond_poll_controller,
-#endif
-	.ndo_add_slave		= bond_enslave,
-	.ndo_del_slave		= bond_release,
-	.ndo_fix_features	= bond_fix_features,
-	.ndo_features_check	= passthru_features_check,
-};
-
-static const struct device_type bond_type = {
-	.name = "bond",
-};
-
-static void bond_destructor(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	if (bond->wq)
-		destroy_workqueue(bond->wq);
-}
-
-void bond_setup(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-
-	spin_lock_init(&bond->mode_lock);
-	bond->params = bonding_defaults;
-
-	/* Initialize pointers */
-	bond->dev = bond_dev;
-
-	/* Initialize the device entry points */
-	ether_setup(bond_dev);
-	bond_dev->max_mtu = ETH_MAX_MTU;
-	bond_dev->netdev_ops = &bond_netdev_ops;
-	bond_dev->ethtool_ops = &bond_ethtool_ops;
-
-	bond_dev->needs_free_netdev = true;
-	bond_dev->priv_destructor = bond_destructor;
-
-	SET_NETDEV_DEVTYPE(bond_dev, &bond_type);
-
-	/* Initialize the device options */
-	bond_dev->flags |= IFF_MASTER;
-	bond_dev->priv_flags |= IFF_BONDING | IFF_UNICAST_FLT | IFF_NO_QUEUE;
-	bond_dev->priv_flags &= ~(IFF_XMIT_DST_RELEASE | IFF_TX_SKB_SHARING);
-
-	/* don't acquire bond device's netif_tx_lock when transmitting */
-	bond_dev->features |= NETIF_F_LLTX;
-
-	/* By default, we declare the bond to be fully
-	 * VLAN hardware accelerated capable. Special
-	 * care is taken in the various xmit functions
-	 * when there are slaves that are not hw accel
-	 * capable
-	 */
-
-	/* Don't allow bond devices to change network namespaces. */
-	bond_dev->features |= NETIF_F_NETNS_LOCAL;
-
-	bond_dev->hw_features = BOND_VLAN_FEATURES |
-				NETIF_F_HW_VLAN_CTAG_RX |
-				NETIF_F_HW_VLAN_CTAG_FILTER;
-
-	bond_dev->hw_features |= NETIF_F_GSO_ENCAP_ALL | NETIF_F_GSO_UDP_L4;
-	bond_dev->features |= bond_dev->hw_features;
-	bond_dev->features |= NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_STAG_TX;
-}
-
-/* Destroy a bonding device.
- * Must be under rtnl_lock when this function is called.
- */
-static void bond_uninit(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct list_head *iter;
-	struct slave *slave;
-	struct bond_up_slave *arr;
-
-	bond_netpoll_cleanup(bond_dev);
-
-	/* Release the bonded slaves */
-	bond_for_each_slave(bond, slave, iter)
-		__bond_release_one(bond_dev, slave->dev, true, true);
-	netdev_info(bond_dev, "Released all slaves\n");
-
-	arr = rtnl_dereference(bond->slave_arr);
-	if (arr) {
-		RCU_INIT_POINTER(bond->slave_arr, NULL);
-		kfree_rcu(arr, rcu);
-	}
-
-	list_del(&bond->bond_list);
-
-	lockdep_unregister_key(&bond->stats_lock_key);
-	bond_debug_unregister(bond);
-}
-
-/*------------------------- Module initialization ---------------------------*/
-
-static int bond_check_params(struct bond_params *params)
-{
-	int arp_validate_value, fail_over_mac_value, primary_reselect_value, i;
-	struct bond_opt_value newval;
-	const struct bond_opt_value *valptr;
-	int arp_all_targets_value = 0;
-	u16 ad_actor_sys_prio = 0;
-	u16 ad_user_port_key = 0;
-	__be32 arp_target[BOND_MAX_ARP_TARGETS] = { 0 };
-	int arp_ip_count;
-	int bond_mode	= BOND_MODE_ROUNDROBIN;
-	int xmit_hashtype = BOND_XMIT_POLICY_LAYER2;
-	int lacp_fast = 0;
-	int tlb_dynamic_lb;
-
-	/* Convert string parameters. */
-	if (mode) {
-		bond_opt_initstr(&newval, mode);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_MODE), &newval);
-		if (!valptr) {
-			pr_err("Error: Invalid bonding mode \"%s\"\n", mode);
-			return -EINVAL;
-		}
-		bond_mode = valptr->value;
-	}
-
-	if (xmit_hash_policy) {
-		if (bond_mode == BOND_MODE_ROUNDROBIN ||
-		    bond_mode == BOND_MODE_ACTIVEBACKUP ||
-		    bond_mode == BOND_MODE_BROADCAST) {
-			pr_info("xmit_hash_policy param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, xmit_hash_policy);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_XMIT_HASH),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid xmit_hash_policy \"%s\"\n",
-				       xmit_hash_policy);
-				return -EINVAL;
-			}
-			xmit_hashtype = valptr->value;
-		}
-	}
-
-	if (lacp_rate) {
-		if (bond_mode != BOND_MODE_8023AD) {
-			pr_info("lacp_rate param is irrelevant in mode %s\n",
-				bond_mode_name(bond_mode));
-		} else {
-			bond_opt_initstr(&newval, lacp_rate);
-			valptr = bond_opt_parse(bond_opt_get(BOND_OPT_LACP_RATE),
-						&newval);
-			if (!valptr) {
-				pr_err("Error: Invalid lacp rate \"%s\"\n",
-				       lacp_rate);
-				return -EINVAL;
-			}
-			lacp_fast = valptr->value;
-		}
-	}
-
-	if (ad_select) {
-		bond_opt_initstr(&newval, ad_select);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_SELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid ad_select \"%s\"\n", ad_select);
-			return -EINVAL;
-		}
-		params->ad_select = valptr->value;
-		if (bond_mode != BOND_MODE_8023AD)
-			pr_warn("ad_select param only affects 802.3ad mode\n");
-	} else {
-		params->ad_select = BOND_AD_STABLE;
-	}
-
-	if (max_bonds < 0) {
-		pr_warn("Warning: max_bonds (%d) not in range %d-%d, so it was reset to BOND_DEFAULT_MAX_BONDS (%d)\n",
-			max_bonds, 0, INT_MAX, BOND_DEFAULT_MAX_BONDS);
-		max_bonds = BOND_DEFAULT_MAX_BONDS;
-	}
-
-	if (miimon < 0) {
-		pr_warn("Warning: miimon module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			miimon, INT_MAX);
-		miimon = 0;
-	}
-
-	if (updelay < 0) {
-		pr_warn("Warning: updelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			updelay, INT_MAX);
-		updelay = 0;
-	}
-
-	if (downdelay < 0) {
-		pr_warn("Warning: downdelay module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			downdelay, INT_MAX);
-		downdelay = 0;
-	}
-
-	if ((use_carrier != 0) && (use_carrier != 1)) {
-		pr_warn("Warning: use_carrier module parameter (%d), not of valid value (0/1), so it was set to 1\n",
-			use_carrier);
-		use_carrier = 1;
-	}
-
-	if (num_peer_notif < 0 || num_peer_notif > 255) {
-		pr_warn("Warning: num_grat_arp/num_unsol_na (%d) not in range 0-255 so it was reset to 1\n",
-			num_peer_notif);
-		num_peer_notif = 1;
-	}
-
-	/* reset values for 802.3ad/TLB/ALB */
-	if (!bond_mode_uses_arp(bond_mode)) {
-		if (!miimon) {
-			pr_warn("Warning: miimon must be specified, otherwise bonding will not detect link failure, speed and duplex which are essential for 802.3ad operation\n");
-			pr_warn("Forcing miimon to 100msec\n");
-			miimon = BOND_DEFAULT_MIIMON;
-		}
-	}
-
-	if (tx_queues < 1 || tx_queues > 255) {
-		pr_warn("Warning: tx_queues (%d) should be between 1 and 255, resetting to %d\n",
-			tx_queues, BOND_DEFAULT_TX_QUEUES);
-		tx_queues = BOND_DEFAULT_TX_QUEUES;
-	}
-
-	if ((all_slaves_active != 0) && (all_slaves_active != 1)) {
-		pr_warn("Warning: all_slaves_active module parameter (%d), not of valid value (0/1), so it was set to 0\n",
-			all_slaves_active);
-		all_slaves_active = 0;
-	}
-
-	if (resend_igmp < 0 || resend_igmp > 255) {
-		pr_warn("Warning: resend_igmp (%d) should be between 0 and 255, resetting to %d\n",
-			resend_igmp, BOND_DEFAULT_RESEND_IGMP);
-		resend_igmp = BOND_DEFAULT_RESEND_IGMP;
-	}
-
-	bond_opt_initval(&newval, packets_per_slave);
-	if (!bond_opt_parse(bond_opt_get(BOND_OPT_PACKETS_PER_SLAVE), &newval)) {
-		pr_warn("Warning: packets_per_slave (%d) should be between 0 and %u resetting to 1\n",
-			packets_per_slave, USHRT_MAX);
-		packets_per_slave = 1;
-	}
-
-	if (bond_mode == BOND_MODE_ALB) {
-		pr_notice("In ALB mode you might experience client disconnections upon reconnection of a link if the bonding module updelay parameter (%d msec) is incompatible with the forwarding delay time of the switch\n",
-			  updelay);
-	}
-
-	if (!miimon) {
-		if (updelay || downdelay) {
-			/* just warn the user the up/down delay will have
-			 * no effect since miimon is zero...
-			 */
-			pr_warn("Warning: miimon module parameter not set and updelay (%d) or downdelay (%d) module parameter is set; updelay and downdelay have no effect unless miimon is set\n",
-				updelay, downdelay);
-		}
-	} else {
-		/* don't allow arp monitoring */
-		if (arp_interval) {
-			pr_warn("Warning: miimon (%d) and arp_interval (%d) can't be used simultaneously, disabling ARP monitoring\n",
-				miimon, arp_interval);
-			arp_interval = 0;
-		}
-
-		if ((updelay % miimon) != 0) {
-			pr_warn("Warning: updelay (%d) is not a multiple of miimon (%d), updelay rounded to %d ms\n",
-				updelay, miimon, (updelay / miimon) * miimon);
-		}
-
-		updelay /= miimon;
-
-		if ((downdelay % miimon) != 0) {
-			pr_warn("Warning: downdelay (%d) is not a multiple of miimon (%d), downdelay rounded to %d ms\n",
-				downdelay, miimon,
-				(downdelay / miimon) * miimon);
-		}
-
-		downdelay /= miimon;
-	}
-
-	if (arp_interval < 0) {
-		pr_warn("Warning: arp_interval module parameter (%d), not in range 0-%d, so it was reset to 0\n",
-			arp_interval, INT_MAX);
-		arp_interval = 0;
-	}
-
-	for (arp_ip_count = 0, i = 0;
-	     (arp_ip_count < BOND_MAX_ARP_TARGETS) && arp_ip_target[i]; i++) {
-		__be32 ip;
-
-		/* not a complete check, but good enough to catch mistakes */
-		if (!in4_pton(arp_ip_target[i], -1, (u8 *)&ip, -1, NULL) ||
-		    !bond_is_ip_target_ok(ip)) {
-			pr_warn("Warning: bad arp_ip_target module parameter (%s), ARP monitoring will not be performed\n",
-				arp_ip_target[i]);
-			arp_interval = 0;
-		} else {
-			if (bond_get_targets_ip(arp_target, ip) == -1)
-				arp_target[arp_ip_count++] = ip;
-			else
-				pr_warn("Warning: duplicate address %pI4 in arp_ip_target, skipping\n",
-					&ip);
-		}
-	}
-
-	if (arp_interval && !arp_ip_count) {
-		/* don't allow arping if no arp_ip_target given... */
-		pr_warn("Warning: arp_interval module parameter (%d) specified without providing an arp_ip_target parameter, arp_interval was reset to 0\n",
-			arp_interval);
-		arp_interval = 0;
-	}
-
-	if (arp_validate) {
-		if (!arp_interval) {
-			pr_err("arp_validate requires arp_interval\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initstr(&newval, arp_validate);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_VALIDATE),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_validate \"%s\"\n",
-			       arp_validate);
-			return -EINVAL;
-		}
-		arp_validate_value = valptr->value;
-	} else {
-		arp_validate_value = 0;
-	}
-
-	if (arp_all_targets) {
-		bond_opt_initstr(&newval, arp_all_targets);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_ARP_ALL_TARGETS),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid arp_all_targets_value \"%s\"\n",
-			       arp_all_targets);
-			arp_all_targets_value = 0;
-		} else {
-			arp_all_targets_value = valptr->value;
-		}
-	}
-
-	if (miimon) {
-		pr_info("MII link monitoring set to %d ms\n", miimon);
-	} else if (arp_interval) {
-		valptr = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
-					  arp_validate_value);
-		pr_info("ARP monitoring set to %d ms, validate %s, with %d target(s):",
-			arp_interval, valptr->string, arp_ip_count);
-
-		for (i = 0; i < arp_ip_count; i++)
-			pr_cont(" %s", arp_ip_target[i]);
-
-		pr_cont("\n");
-
-	} else if (max_bonds) {
-		/* miimon and arp_interval not set, we need one so things
-		 * work as expected, see bonding.txt for details
-		 */
-		pr_debug("Warning: either miimon or arp_interval and arp_ip_target module parameters must be specified, otherwise bonding will not detect link failures! see bonding.txt for details\n");
-	}
-
-	if (primary && !bond_mode_uses_primary(bond_mode)) {
-		/* currently, using a primary only makes sense
-		 * in active backup, TLB or ALB modes
-		 */
-		pr_warn("Warning: %s primary device specified but has no effect in %s mode\n",
-			primary, bond_mode_name(bond_mode));
-		primary = NULL;
-	}
-
-	if (primary && primary_reselect) {
-		bond_opt_initstr(&newval, primary_reselect);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_PRIMARY_RESELECT),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: Invalid primary_reselect \"%s\"\n",
-			       primary_reselect);
-			return -EINVAL;
-		}
-		primary_reselect_value = valptr->value;
-	} else {
-		primary_reselect_value = BOND_PRI_RESELECT_ALWAYS;
-	}
-
-	if (fail_over_mac) {
-		bond_opt_initstr(&newval, fail_over_mac);
-		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_FAIL_OVER_MAC),
-					&newval);
-		if (!valptr) {
-			pr_err("Error: invalid fail_over_mac \"%s\"\n",
-			       fail_over_mac);
-			return -EINVAL;
-		}
-		fail_over_mac_value = valptr->value;
-		if (bond_mode != BOND_MODE_ACTIVEBACKUP)
-			pr_warn("Warning: fail_over_mac only affects active-backup mode\n");
-	} else {
-		fail_over_mac_value = BOND_FOM_NONE;
-	}
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(
-			bond_opt_get(BOND_OPT_AD_ACTOR_SYS_PRIO),
-				     &newval);
-	if (!valptr) {
-		pr_err("Error: No ad_actor_sys_prio default value");
-		return -EINVAL;
-	}
-	ad_actor_sys_prio = valptr->value;
-
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_AD_USER_PORT_KEY),
-				&newval);
-	if (!valptr) {
-		pr_err("Error: No ad_user_port_key default value");
-		return -EINVAL;
-	}
-	ad_user_port_key = valptr->value;
-
-	bond_opt_initstr(&newval, "default");
-	valptr = bond_opt_parse(bond_opt_get(BOND_OPT_TLB_DYNAMIC_LB), &newval);
-	if (!valptr) {
-		pr_err("Error: No tlb_dynamic_lb default value");
-		return -EINVAL;
-	}
-	tlb_dynamic_lb = valptr->value;
-
-	if (lp_interval == 0) {
-		pr_warn("Warning: ip_interval must be between 1 and %d, so it was reset to %d\n",
-			INT_MAX, BOND_ALB_DEFAULT_LP_INTERVAL);
-		lp_interval = BOND_ALB_DEFAULT_LP_INTERVAL;
-	}
-
-	/* fill params struct with the proper values */
-	params->mode = bond_mode;
-	params->xmit_policy = xmit_hashtype;
-	params->miimon = miimon;
-	params->num_peer_notif = num_peer_notif;
-	params->arp_interval = arp_interval;
-	params->arp_validate = arp_validate_value;
-	params->arp_all_targets = arp_all_targets_value;
-	params->updelay = updelay;
-	params->downdelay = downdelay;
-	params->peer_notif_delay = 0;
-	params->use_carrier = use_carrier;
-	params->lacp_fast = lacp_fast;
-	params->primary[0] = 0;
-	params->primary_reselect = primary_reselect_value;
-	params->fail_over_mac = fail_over_mac_value;
-	params->tx_queues = tx_queues;
-	params->all_slaves_active = all_slaves_active;
-	params->resend_igmp = resend_igmp;
-	params->min_links = min_links;
-	params->lp_interval = lp_interval;
-	params->packets_per_slave = packets_per_slave;
-	params->tlb_dynamic_lb = tlb_dynamic_lb;
-	params->ad_actor_sys_prio = ad_actor_sys_prio;
-	eth_zero_addr(params->ad_actor_system);
-	params->ad_user_port_key = ad_user_port_key;
-	if (packets_per_slave > 0) {
-		params->reciprocal_packets_per_slave =
-			reciprocal_value(packets_per_slave);
-	} else {
-		/* reciprocal_packets_per_slave is unused if
-		 * packets_per_slave is 0 or 1, just initialize it
-		 */
-		params->reciprocal_packets_per_slave =
-			(struct reciprocal_value) { 0 };
-	}
-
-	if (primary) {
-		strncpy(params->primary, primary, IFNAMSIZ);
-		params->primary[IFNAMSIZ - 1] = 0;
-	}
-
-	memcpy(params->arp_targets, arp_target, sizeof(arp_target));
-
-	return 0;
-}
-
-/* Called from registration process */
-static int bond_init(struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	netdev_dbg(bond_dev, "Begin bond_init\n");
-
-	bond->wq = alloc_ordered_workqueue(bond_dev->name, WQ_MEM_RECLAIM);
-	if (!bond->wq)
-		return -ENOMEM;
-
-	spin_lock_init(&bond->stats_lock);
-	lockdep_register_key(&bond->stats_lock_key);
-	lockdep_set_class(&bond->stats_lock, &bond->stats_lock_key);
-
-	list_add_tail(&bond->bond_list, &bn->dev_list);
-
-	bond_prepare_sysfs_group(bond);
-
-	bond_debug_register(bond);
-
-	/* Ensure valid dev_addr */
-	if (is_zero_ether_addr(bond_dev->dev_addr) &&
-	    bond_dev->addr_assign_type == NET_ADDR_PERM)
-		eth_hw_addr_random(bond_dev);
-
-	return 0;
-}
-
-unsigned int bond_get_num_tx_queues(void)
-{
-	return tx_queues;
-}
-
-/* Create a new bond based on the specified name and bonding parameters.
- * If name is NULL, obtain a suitable "bond%d" name for us.
- * Caller must NOT hold rtnl_lock; we need to release it here before we
- * set up our sysfs entries.
- */
-int bond_create(struct net *net, const char *name)
-{
-	struct net_device *bond_dev;
-	struct bonding *bond;
-	struct alb_bond_info *bond_info;
-	int res;
-
-	rtnl_lock();
-
-	bond_dev = alloc_netdev_mq(sizeof(struct bonding),
-				   name ? name : "bond%d", NET_NAME_UNKNOWN,
-				   bond_setup, tx_queues);
-	if (!bond_dev) {
-		pr_err("%s: eek! can't alloc netdev!\n", name);
-		rtnl_unlock();
-		return -ENOMEM;
-	}
-
-	/*
-	 * Initialize rx_hashtbl_used_head to RLB_NULL_INDEX.
-	 * It is set to 0 by default which is wrong.
-	 */
-	bond = netdev_priv(bond_dev);
-	bond_info = &(BOND_ALB_INFO(bond));
-	bond_info->rx_hashtbl_used_head = RLB_NULL_INDEX;
-
-	dev_net_set(bond_dev, net);
-	bond_dev->rtnl_link_ops = &bond_link_ops;
-
-	res = register_netdevice(bond_dev);
-
-	netif_carrier_off(bond_dev);
-
-	bond_work_init_all(bond);
-
-	rtnl_unlock();
-	if (res < 0)
-		free_netdev(bond_dev);
-	return res;
-}
-
-static int __net_init bond_net_init(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-
-	bn->net = net;
-	INIT_LIST_HEAD(&bn->dev_list);
-
-	bond_create_proc_dir(bn);
-	bond_create_sysfs(bn);
-
-	return 0;
-}
-
-static void __net_exit bond_net_exit(struct net *net)
-{
-	struct bond_net *bn = net_generic(net, bond_net_id);
-	struct bonding *bond, *tmp_bond;
-	LIST_HEAD(list);
-
-	bond_destroy_sysfs(bn);
-
-	/* Kill off any bonds created after unregistering bond rtnl ops */
-	rtnl_lock();
-	list_for_each_entry_safe(bond, tmp_bond, &bn->dev_list, bond_list)
-		unregister_netdevice_queue(bond->dev, &list);
-	unregister_netdevice_many(&list);
-	rtnl_unlock();
-
-	bond_destroy_proc_dir(bn);
-}
-
-static struct pernet_operations bond_net_ops = {
-	.init = bond_net_init,
-	.exit = bond_net_exit,
-	.id   = &bond_net_id,
-	.size = sizeof(struct bond_net),
-};
-
-static int __init bonding_init(void)
-{
-	int i;
-	int res;
-
-	pr_info("%s", bond_version);
-
-	res = bond_check_params(&bonding_defaults);
-	if (res)
-		goto out;
-
-	res = register_pernet_subsys(&bond_net_ops);
-	if (res)
-		goto out;
-
-	res = bond_netlink_init();
-	if (res)
-		goto err_link;
-
-	bond_create_debugfs();
-
-	for (i = 0; i < max_bonds; i++) {
-		res = bond_create(&init_net, NULL);
-		if (res)
-			goto err;
-	}
-
-	skb_flow_dissector_init(&flow_keys_bonding,
-				flow_keys_bonding_keys,
-				ARRAY_SIZE(flow_keys_bonding_keys));
-
-	register_netdevice_notifier(&bond_netdev_notifier);
-
-	register_toe_bond_rr_select_cb(bond_xmit_roundrobin_select);
-	register_toe_bond_acb_select_cb(bond_xmit_activebackup_select);
-	register_toe_bond_8023AD_select_cb(bond_xmit_xor_select);
-	register_toe_bond_xor_select_cb(bond_xmit_xor_select);
-out:
-	return res;
-err:
-	bond_destroy_debugfs();
-	bond_netlink_fini();
-err_link:
-	unregister_pernet_subsys(&bond_net_ops);
-	goto out;
-
-}
-
-static void __exit bonding_exit(void)
-{
-	unregister_netdevice_notifier(&bond_netdev_notifier);
-
-	bond_destroy_debugfs();
-
-	bond_netlink_fini();
-	unregister_pernet_subsys(&bond_net_ops);
-
-#ifdef CONFIG_NET_POLL_CONTROLLER
-	/* Make sure we don't have an imbalance on our netpoll blocking */
-	WARN_ON(atomic_read(&netpoll_block_tx));
-#endif
-}
-
-module_init(bonding_init);
-module_exit(bonding_exit);
-MODULE_LICENSE("GPL");
-MODULE_VERSION(DRV_VERSION);
-MODULE_DESCRIPTION(DRV_DESCRIPTION ", v" DRV_VERSION);
-MODULE_AUTHOR("Thomas Davis, tadavis@lbl.gov and many others");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.6.0/bond_netlink.c
--- a/src/network/bonding/BONDING_KDIRS/5.6.0/bond_netlink.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,786 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * drivers/net/bond/bond_netlink.c - Netlink interface for bonding
- * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
- * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/module.h>
-#include <linux/errno.h>
-#include <linux/netdevice.h>
-#include <linux/etherdevice.h>
-#include <linux/if_link.h>
-#include <linux/if_ether.h>
-#include <net/netlink.h>
-#include <net/rtnetlink.h>
-#include <net/bonding.h>
-
-static size_t bond_get_slave_size(const struct net_device *bond_dev,
-				  const struct net_device *slave_dev)
-{
-	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_STATE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_MII_STATUS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_SLAVE_LINK_FAILURE_COUNT */
-		nla_total_size(MAX_ADDR_LEN) +	/* IFLA_BOND_SLAVE_PERM_HWADDR */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_QUEUE_ID */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_AGGREGATOR_ID */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE */
-		nla_total_size(sizeof(u16)) +	/* IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE */
-		0;
-}
-
-static int bond_fill_slave_info(struct sk_buff *skb,
-				const struct net_device *bond_dev,
-				const struct net_device *slave_dev)
-{
-	struct slave *slave = bond_slave_get_rtnl(slave_dev);
-
-	if (nla_put_u8(skb, IFLA_BOND_SLAVE_STATE, bond_slave_state(slave)))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_SLAVE_MII_STATUS, slave->link))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_SLAVE_LINK_FAILURE_COUNT,
-			slave->link_failure_count))
-		goto nla_put_failure;
-
-	if (nla_put(skb, IFLA_BOND_SLAVE_PERM_HWADDR,
-		    slave_dev->addr_len, slave->perm_hwaddr))
-		goto nla_put_failure;
-
-	if (nla_put_u16(skb, IFLA_BOND_SLAVE_QUEUE_ID, slave->queue_id))
-		goto nla_put_failure;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		const struct aggregator *agg;
-		const struct port *ad_port;
-
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		agg = SLAVE_AD_INFO(slave)->port.aggregator;
-		if (agg) {
-			if (nla_put_u16(skb, IFLA_BOND_SLAVE_AD_AGGREGATOR_ID,
-					agg->aggregator_identifier))
-				goto nla_put_failure;
-			if (nla_put_u8(skb,
-				       IFLA_BOND_SLAVE_AD_ACTOR_OPER_PORT_STATE,
-				       ad_port->actor_oper_port_state))
-				goto nla_put_failure;
-			if (nla_put_u16(skb,
-					IFLA_BOND_SLAVE_AD_PARTNER_OPER_PORT_STATE,
-					ad_port->partner_oper.port_state))
-				goto nla_put_failure;
-		}
-	}
-
-	return 0;
-
-nla_put_failure:
-	return -EMSGSIZE;
-}
-
-static const struct nla_policy bond_policy[IFLA_BOND_MAX + 1] = {
-	[IFLA_BOND_MODE]		= { .type = NLA_U8 },
-	[IFLA_BOND_ACTIVE_SLAVE]	= { .type = NLA_U32 },
-	[IFLA_BOND_MIIMON]		= { .type = NLA_U32 },
-	[IFLA_BOND_UPDELAY]		= { .type = NLA_U32 },
-	[IFLA_BOND_DOWNDELAY]		= { .type = NLA_U32 },
-	[IFLA_BOND_USE_CARRIER]		= { .type = NLA_U8 },
-	[IFLA_BOND_ARP_INTERVAL]	= { .type = NLA_U32 },
-	[IFLA_BOND_ARP_IP_TARGET]	= { .type = NLA_NESTED },
-	[IFLA_BOND_ARP_VALIDATE]	= { .type = NLA_U32 },
-	[IFLA_BOND_ARP_ALL_TARGETS]	= { .type = NLA_U32 },
-	[IFLA_BOND_PRIMARY]		= { .type = NLA_U32 },
-	[IFLA_BOND_PRIMARY_RESELECT]	= { .type = NLA_U8 },
-	[IFLA_BOND_FAIL_OVER_MAC]	= { .type = NLA_U8 },
-	[IFLA_BOND_XMIT_HASH_POLICY]	= { .type = NLA_U8 },
-	[IFLA_BOND_RESEND_IGMP]		= { .type = NLA_U32 },
-	[IFLA_BOND_NUM_PEER_NOTIF]	= { .type = NLA_U8 },
-	[IFLA_BOND_ALL_SLAVES_ACTIVE]	= { .type = NLA_U8 },
-	[IFLA_BOND_MIN_LINKS]		= { .type = NLA_U32 },
-	[IFLA_BOND_LP_INTERVAL]		= { .type = NLA_U32 },
-	[IFLA_BOND_PACKETS_PER_SLAVE]	= { .type = NLA_U32 },
-	[IFLA_BOND_AD_LACP_RATE]	= { .type = NLA_U8 },
-	[IFLA_BOND_AD_SELECT]		= { .type = NLA_U8 },
-	[IFLA_BOND_AD_INFO]		= { .type = NLA_NESTED },
-	[IFLA_BOND_AD_ACTOR_SYS_PRIO]	= { .type = NLA_U16 },
-	[IFLA_BOND_AD_USER_PORT_KEY]	= { .type = NLA_U16 },
-	[IFLA_BOND_AD_ACTOR_SYSTEM]	= { .type = NLA_BINARY,
-					    .len  = ETH_ALEN },
-	[IFLA_BOND_TLB_DYNAMIC_LB]	= { .type = NLA_U8 },
-	[IFLA_BOND_PEER_NOTIF_DELAY]    = { .type = NLA_U32 },
-};
-
-static const struct nla_policy bond_slave_policy[IFLA_BOND_SLAVE_MAX + 1] = {
-	[IFLA_BOND_SLAVE_QUEUE_ID]	= { .type = NLA_U16 },
-};
-
-static int bond_validate(struct nlattr *tb[], struct nlattr *data[],
-			 struct netlink_ext_ack *extack)
-{
-	if (tb[IFLA_ADDRESS]) {
-		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN)
-			return -EINVAL;
-		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS])))
-			return -EADDRNOTAVAIL;
-	}
-	return 0;
-}
-
-static int bond_slave_changelink(struct net_device *bond_dev,
-				 struct net_device *slave_dev,
-				 struct nlattr *tb[], struct nlattr *data[],
-				 struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_opt_value newval;
-	int err;
-
-	if (!data)
-		return 0;
-
-	if (data[IFLA_BOND_SLAVE_QUEUE_ID]) {
-		u16 queue_id = nla_get_u16(data[IFLA_BOND_SLAVE_QUEUE_ID]);
-		char queue_id_str[IFNAMSIZ + 7];
-
-		/* queue_id option setting expects slave_name:queue_id */
-		snprintf(queue_id_str, sizeof(queue_id_str), "%s:%u\n",
-			 slave_dev->name, queue_id);
-		bond_opt_initstr(&newval, queue_id_str);
-		err = __bond_opt_set(bond, BOND_OPT_QUEUE_ID, &newval);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int bond_changelink(struct net_device *bond_dev, struct nlattr *tb[],
-			   struct nlattr *data[],
-			   struct netlink_ext_ack *extack)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	struct bond_opt_value newval;
-	int miimon = 0;
-	int err;
-
-	if (!data)
-		return 0;
-
-	if (data[IFLA_BOND_MODE]) {
-		int mode = nla_get_u8(data[IFLA_BOND_MODE]);
-
-		bond_opt_initval(&newval, mode);
-		err = __bond_opt_set(bond, BOND_OPT_MODE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ACTIVE_SLAVE]) {
-		int ifindex = nla_get_u32(data[IFLA_BOND_ACTIVE_SLAVE]);
-		struct net_device *slave_dev;
-		char *active_slave = "";
-
-		if (ifindex != 0) {
-			slave_dev = __dev_get_by_index(dev_net(bond_dev),
-						       ifindex);
-			if (!slave_dev)
-				return -ENODEV;
-			active_slave = slave_dev->name;
-		}
-		bond_opt_initstr(&newval, active_slave);
-		err = __bond_opt_set(bond, BOND_OPT_ACTIVE_SLAVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_MIIMON]) {
-		miimon = nla_get_u32(data[IFLA_BOND_MIIMON]);
-
-		bond_opt_initval(&newval, miimon);
-		err = __bond_opt_set(bond, BOND_OPT_MIIMON, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_UPDELAY]) {
-		int updelay = nla_get_u32(data[IFLA_BOND_UPDELAY]);
-
-		bond_opt_initval(&newval, updelay);
-		err = __bond_opt_set(bond, BOND_OPT_UPDELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_DOWNDELAY]) {
-		int downdelay = nla_get_u32(data[IFLA_BOND_DOWNDELAY]);
-
-		bond_opt_initval(&newval, downdelay);
-		err = __bond_opt_set(bond, BOND_OPT_DOWNDELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PEER_NOTIF_DELAY]) {
-		int delay = nla_get_u32(data[IFLA_BOND_PEER_NOTIF_DELAY]);
-
-		bond_opt_initval(&newval, delay);
-		err = __bond_opt_set(bond, BOND_OPT_PEER_NOTIF_DELAY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_USE_CARRIER]) {
-		int use_carrier = nla_get_u8(data[IFLA_BOND_USE_CARRIER]);
-
-		bond_opt_initval(&newval, use_carrier);
-		err = __bond_opt_set(bond, BOND_OPT_USE_CARRIER, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_INTERVAL]) {
-		int arp_interval = nla_get_u32(data[IFLA_BOND_ARP_INTERVAL]);
-
-		if (arp_interval && miimon) {
-			netdev_err(bond->dev, "ARP monitoring cannot be used with MII monitoring\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initval(&newval, arp_interval);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_INTERVAL, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_IP_TARGET]) {
-		struct nlattr *attr;
-		int i = 0, rem;
-
-		bond_option_arp_ip_targets_clear(bond);
-		nla_for_each_nested(attr, data[IFLA_BOND_ARP_IP_TARGET], rem) {
-			__be32 target;
-
-			if (nla_len(attr) < sizeof(target))
-				return -EINVAL;
-
-			target = nla_get_be32(attr);
-
-			bond_opt_initval(&newval, (__force u64)target);
-			err = __bond_opt_set(bond, BOND_OPT_ARP_TARGETS,
-					     &newval);
-			if (err)
-				break;
-			i++;
-		}
-		if (i == 0 && bond->params.arp_interval)
-			netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_VALIDATE]) {
-		int arp_validate = nla_get_u32(data[IFLA_BOND_ARP_VALIDATE]);
-
-		if (arp_validate && miimon) {
-			netdev_err(bond->dev, "ARP validating cannot be used with MII monitoring\n");
-			return -EINVAL;
-		}
-
-		bond_opt_initval(&newval, arp_validate);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_VALIDATE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ARP_ALL_TARGETS]) {
-		int arp_all_targets =
-			nla_get_u32(data[IFLA_BOND_ARP_ALL_TARGETS]);
-
-		bond_opt_initval(&newval, arp_all_targets);
-		err = __bond_opt_set(bond, BOND_OPT_ARP_ALL_TARGETS, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PRIMARY]) {
-		int ifindex = nla_get_u32(data[IFLA_BOND_PRIMARY]);
-		struct net_device *dev;
-		char *primary = "";
-
-		dev = __dev_get_by_index(dev_net(bond_dev), ifindex);
-		if (dev)
-			primary = dev->name;
-
-		bond_opt_initstr(&newval, primary);
-		err = __bond_opt_set(bond, BOND_OPT_PRIMARY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PRIMARY_RESELECT]) {
-		int primary_reselect =
-			nla_get_u8(data[IFLA_BOND_PRIMARY_RESELECT]);
-
-		bond_opt_initval(&newval, primary_reselect);
-		err = __bond_opt_set(bond, BOND_OPT_PRIMARY_RESELECT, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_FAIL_OVER_MAC]) {
-		int fail_over_mac =
-			nla_get_u8(data[IFLA_BOND_FAIL_OVER_MAC]);
-
-		bond_opt_initval(&newval, fail_over_mac);
-		err = __bond_opt_set(bond, BOND_OPT_FAIL_OVER_MAC, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_XMIT_HASH_POLICY]) {
-		int xmit_hash_policy =
-			nla_get_u8(data[IFLA_BOND_XMIT_HASH_POLICY]);
-
-		bond_opt_initval(&newval, xmit_hash_policy);
-		err = __bond_opt_set(bond, BOND_OPT_XMIT_HASH, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_RESEND_IGMP]) {
-		int resend_igmp =
-			nla_get_u32(data[IFLA_BOND_RESEND_IGMP]);
-
-		bond_opt_initval(&newval, resend_igmp);
-		err = __bond_opt_set(bond, BOND_OPT_RESEND_IGMP, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_NUM_PEER_NOTIF]) {
-		int num_peer_notif =
-			nla_get_u8(data[IFLA_BOND_NUM_PEER_NOTIF]);
-
-		bond_opt_initval(&newval, num_peer_notif);
-		err = __bond_opt_set(bond, BOND_OPT_NUM_PEER_NOTIF, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_ALL_SLAVES_ACTIVE]) {
-		int all_slaves_active =
-			nla_get_u8(data[IFLA_BOND_ALL_SLAVES_ACTIVE]);
-
-		bond_opt_initval(&newval, all_slaves_active);
-		err = __bond_opt_set(bond, BOND_OPT_ALL_SLAVES_ACTIVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_MIN_LINKS]) {
-		int min_links =
-			nla_get_u32(data[IFLA_BOND_MIN_LINKS]);
-
-		bond_opt_initval(&newval, min_links);
-		err = __bond_opt_set(bond, BOND_OPT_MINLINKS, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_LP_INTERVAL]) {
-		int lp_interval =
-			nla_get_u32(data[IFLA_BOND_LP_INTERVAL]);
-
-		bond_opt_initval(&newval, lp_interval);
-		err = __bond_opt_set(bond, BOND_OPT_LP_INTERVAL, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_PACKETS_PER_SLAVE]) {
-		int packets_per_slave =
-			nla_get_u32(data[IFLA_BOND_PACKETS_PER_SLAVE]);
-
-		bond_opt_initval(&newval, packets_per_slave);
-		err = __bond_opt_set(bond, BOND_OPT_PACKETS_PER_SLAVE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_LACP_RATE]) {
-		int lacp_rate =
-			nla_get_u8(data[IFLA_BOND_AD_LACP_RATE]);
-
-		bond_opt_initval(&newval, lacp_rate);
-		err = __bond_opt_set(bond, BOND_OPT_LACP_RATE, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_SELECT]) {
-		int ad_select =
-			nla_get_u8(data[IFLA_BOND_AD_SELECT]);
-
-		bond_opt_initval(&newval, ad_select);
-		err = __bond_opt_set(bond, BOND_OPT_AD_SELECT, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_ACTOR_SYS_PRIO]) {
-		int actor_sys_prio =
-			nla_get_u16(data[IFLA_BOND_AD_ACTOR_SYS_PRIO]);
-
-		bond_opt_initval(&newval, actor_sys_prio);
-		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYS_PRIO, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_USER_PORT_KEY]) {
-		int port_key =
-			nla_get_u16(data[IFLA_BOND_AD_USER_PORT_KEY]);
-
-		bond_opt_initval(&newval, port_key);
-		err = __bond_opt_set(bond, BOND_OPT_AD_USER_PORT_KEY, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_AD_ACTOR_SYSTEM]) {
-		if (nla_len(data[IFLA_BOND_AD_ACTOR_SYSTEM]) != ETH_ALEN)
-			return -EINVAL;
-
-		bond_opt_initval(&newval,
-				 nla_get_u64(data[IFLA_BOND_AD_ACTOR_SYSTEM]));
-		err = __bond_opt_set(bond, BOND_OPT_AD_ACTOR_SYSTEM, &newval);
-		if (err)
-			return err;
-	}
-	if (data[IFLA_BOND_TLB_DYNAMIC_LB]) {
-		int dynamic_lb = nla_get_u8(data[IFLA_BOND_TLB_DYNAMIC_LB]);
-
-		bond_opt_initval(&newval, dynamic_lb);
-		err = __bond_opt_set(bond, BOND_OPT_TLB_DYNAMIC_LB, &newval);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int bond_newlink(struct net *src_net, struct net_device *bond_dev,
-			struct nlattr *tb[], struct nlattr *data[],
-			struct netlink_ext_ack *extack)
-{
-	int err;
-
-	err = bond_changelink(bond_dev, tb, data, extack);
-	if (err < 0)
-		return err;
-
-	err = register_netdevice(bond_dev);
-
-	netif_carrier_off(bond_dev);
-	if (!err) {
-		struct bonding *bond = netdev_priv(bond_dev);
-
-		bond_work_init_all(bond);
-	}
-
-	return err;
-}
-
-static size_t bond_get_size(const struct net_device *bond_dev)
-{
-	return nla_total_size(sizeof(u8)) +	/* IFLA_BOND_MODE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ACTIVE_SLAVE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIIMON */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_UPDELAY */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_DOWNDELAY */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_USE_CARRIER */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_INTERVAL */
-						/* IFLA_BOND_ARP_IP_TARGET */
-		nla_total_size(sizeof(struct nlattr)) +
-		nla_total_size(sizeof(u32)) * BOND_MAX_ARP_TARGETS +
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_VALIDATE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_ARP_ALL_TARGETS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PRIMARY */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_PRIMARY_RESELECT */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_FAIL_OVER_MAC */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_XMIT_HASH_POLICY */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_RESEND_IGMP */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_NUM_PEER_NOTIF */
-		nla_total_size(sizeof(u8)) +   /* IFLA_BOND_ALL_SLAVES_ACTIVE */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_MIN_LINKS */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_LP_INTERVAL */
-		nla_total_size(sizeof(u32)) +  /* IFLA_BOND_PACKETS_PER_SLAVE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_LACP_RATE */
-		nla_total_size(sizeof(u8)) +	/* IFLA_BOND_AD_SELECT */
-		nla_total_size(sizeof(struct nlattr)) + /* IFLA_BOND_AD_INFO */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_AGGREGATOR */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_NUM_PORTS */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_ACTOR_KEY */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_INFO_PARTNER_KEY*/
-		nla_total_size(ETH_ALEN) +    /* IFLA_BOND_AD_INFO_PARTNER_MAC*/
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_ACTOR_SYS_PRIO */
-		nla_total_size(sizeof(u16)) + /* IFLA_BOND_AD_USER_PORT_KEY */
-		nla_total_size(ETH_ALEN) + /* IFLA_BOND_AD_ACTOR_SYSTEM */
-		nla_total_size(sizeof(u8)) + /* IFLA_BOND_TLB_DYNAMIC_LB */
-		nla_total_size(sizeof(u32)) +	/* IFLA_BOND_PEER_NOTIF_DELAY */
-		0;
-}
-
-static int bond_option_active_slave_get_ifindex(struct bonding *bond)
-{
-	const struct net_device *slave;
-	int ifindex;
-
-	rcu_read_lock();
-	slave = bond_option_active_slave_get_rcu(bond);
-	ifindex = slave ? slave->ifindex : 0;
-	rcu_read_unlock();
-	return ifindex;
-}
-
-static int bond_fill_info(struct sk_buff *skb,
-			  const struct net_device *bond_dev)
-{
-	struct bonding *bond = netdev_priv(bond_dev);
-	unsigned int packets_per_slave;
-	int ifindex, i, targets_added;
-	struct nlattr *targets;
-	struct slave *primary;
-
-	if (nla_put_u8(skb, IFLA_BOND_MODE, BOND_MODE(bond)))
-		goto nla_put_failure;
-
-	ifindex = bond_option_active_slave_get_ifindex(bond);
-	if (ifindex && nla_put_u32(skb, IFLA_BOND_ACTIVE_SLAVE, ifindex))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_MIIMON, bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_UPDELAY,
-			bond->params.updelay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_DOWNDELAY,
-			bond->params.downdelay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_PEER_NOTIF_DELAY,
-			bond->params.peer_notif_delay * bond->params.miimon))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_USE_CARRIER, bond->params.use_carrier))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_INTERVAL, bond->params.arp_interval))
-		goto nla_put_failure;
-
-	targets = nla_nest_start_noflag(skb, IFLA_BOND_ARP_IP_TARGET);
-	if (!targets)
-		goto nla_put_failure;
-
-	targets_added = 0;
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
-		if (bond->params.arp_targets[i]) {
-			if (nla_put_be32(skb, i, bond->params.arp_targets[i]))
-				goto nla_put_failure;
-			targets_added = 1;
-		}
-	}
-
-	if (targets_added)
-		nla_nest_end(skb, targets);
-	else
-		nla_nest_cancel(skb, targets);
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_VALIDATE, bond->params.arp_validate))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_ARP_ALL_TARGETS,
-			bond->params.arp_all_targets))
-		goto nla_put_failure;
-
-	primary = rtnl_dereference(bond->primary_slave);
-	if (primary &&
-	    nla_put_u32(skb, IFLA_BOND_PRIMARY, primary->dev->ifindex))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_PRIMARY_RESELECT,
-		       bond->params.primary_reselect))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_FAIL_OVER_MAC,
-		       bond->params.fail_over_mac))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_XMIT_HASH_POLICY,
-		       bond->params.xmit_policy))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_RESEND_IGMP,
-		        bond->params.resend_igmp))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_NUM_PEER_NOTIF,
-		       bond->params.num_peer_notif))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_ALL_SLAVES_ACTIVE,
-		       bond->params.all_slaves_active))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_MIN_LINKS,
-			bond->params.min_links))
-		goto nla_put_failure;
-
-	if (nla_put_u32(skb, IFLA_BOND_LP_INTERVAL,
-			bond->params.lp_interval))
-		goto nla_put_failure;
-
-	packets_per_slave = bond->params.packets_per_slave;
-	if (nla_put_u32(skb, IFLA_BOND_PACKETS_PER_SLAVE,
-			packets_per_slave))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_AD_LACP_RATE,
-		       bond->params.lacp_fast))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_AD_SELECT,
-		       bond->params.ad_select))
-		goto nla_put_failure;
-
-	if (nla_put_u8(skb, IFLA_BOND_TLB_DYNAMIC_LB,
-		       bond->params.tlb_dynamic_lb))
-		goto nla_put_failure;
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info info;
-
-		if (capable(CAP_NET_ADMIN)) {
-			if (nla_put_u16(skb, IFLA_BOND_AD_ACTOR_SYS_PRIO,
-					bond->params.ad_actor_sys_prio))
-				goto nla_put_failure;
-
-			if (nla_put_u16(skb, IFLA_BOND_AD_USER_PORT_KEY,
-					bond->params.ad_user_port_key))
-				goto nla_put_failure;
-
-			if (nla_put(skb, IFLA_BOND_AD_ACTOR_SYSTEM,
-				    ETH_ALEN, &bond->params.ad_actor_system))
-				goto nla_put_failure;
-		}
-		if (!bond_3ad_get_active_agg_info(bond, &info)) {
-			struct nlattr *nest;
-
-			nest = nla_nest_start_noflag(skb, IFLA_BOND_AD_INFO);
-			if (!nest)
-				goto nla_put_failure;
-
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_AGGREGATOR,
-					info.aggregator_id))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_NUM_PORTS,
-					info.ports))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_ACTOR_KEY,
-					info.actor_key))
-				goto nla_put_failure;
-			if (nla_put_u16(skb, IFLA_BOND_AD_INFO_PARTNER_KEY,
-					info.partner_key))
-				goto nla_put_failure;
-			if (nla_put(skb, IFLA_BOND_AD_INFO_PARTNER_MAC,
-				    sizeof(info.partner_system),
-				    &info.partner_system))
-				goto nla_put_failure;
-
-			nla_nest_end(skb, nest);
-		}
-	}
-
-	return 0;
-
-nla_put_failure:
-	return -EMSGSIZE;
-}
-
-static size_t bond_get_linkxstats_size(const struct net_device *dev, int attr)
-{
-	switch (attr) {
-	case IFLA_STATS_LINK_XSTATS:
-	case IFLA_STATS_LINK_XSTATS_SLAVE:
-		break;
-	default:
-		return 0;
-	}
-
-	return bond_3ad_stats_size() + nla_total_size(0);
-}
-
-static int bond_fill_linkxstats(struct sk_buff *skb,
-				const struct net_device *dev,
-				int *prividx, int attr)
-{
-	struct nlattr *nla __maybe_unused;
-	struct slave *slave = NULL;
-	struct nlattr *nest, *nest2;
-	struct bonding *bond;
-
-	switch (attr) {
-	case IFLA_STATS_LINK_XSTATS:
-		bond = netdev_priv(dev);
-		break;
-	case IFLA_STATS_LINK_XSTATS_SLAVE:
-		slave = bond_slave_get_rtnl(dev);
-		if (!slave)
-			return 0;
-		bond = slave->bond;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	nest = nla_nest_start_noflag(skb, LINK_XSTATS_TYPE_BOND);
-	if (!nest)
-		return -EMSGSIZE;
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct bond_3ad_stats *stats;
-
-		if (slave)
-			stats = &SLAVE_AD_INFO(slave)->stats;
-		else
-			stats = &BOND_AD_INFO(bond).stats;
-
-		nest2 = nla_nest_start_noflag(skb, BOND_XSTATS_3AD);
-		if (!nest2) {
-			nla_nest_end(skb, nest);
-			return -EMSGSIZE;
-		}
-
-		if (bond_3ad_stats_fill(skb, stats)) {
-			nla_nest_cancel(skb, nest2);
-			nla_nest_end(skb, nest);
-			return -EMSGSIZE;
-		}
-		nla_nest_end(skb, nest2);
-	}
-	nla_nest_end(skb, nest);
-
-	return 0;
-}
-
-struct rtnl_link_ops bond_link_ops __read_mostly = {
-	.kind			= "bond",
-	.priv_size		= sizeof(struct bonding),
-	.setup			= bond_setup,
-	.maxtype		= IFLA_BOND_MAX,
-	.policy			= bond_policy,
-	.validate		= bond_validate,
-	.newlink		= bond_newlink,
-	.changelink		= bond_changelink,
-	.get_size		= bond_get_size,
-	.fill_info		= bond_fill_info,
-	.get_num_tx_queues	= bond_get_num_tx_queues,
-	.get_num_rx_queues	= bond_get_num_tx_queues, /* Use the same number
-							     as for TX queues */
-	.fill_linkxstats        = bond_fill_linkxstats,
-	.get_linkxstats_size    = bond_get_linkxstats_size,
-	.slave_maxtype		= IFLA_BOND_SLAVE_MAX,
-	.slave_policy		= bond_slave_policy,
-	.slave_changelink	= bond_slave_changelink,
-	.get_slave_size		= bond_get_slave_size,
-	.fill_slave_info	= bond_fill_slave_info,
-};
-
-int __init bond_netlink_init(void)
-{
-	return rtnl_link_register(&bond_link_ops);
-}
-
-void bond_netlink_fini(void)
-{
-	rtnl_link_unregister(&bond_link_ops);
-}
-
-MODULE_ALIAS_RTNL_LINK("bond");
diff -r 30 src/network/bonding/BONDING_KDIRS/5.6.0/bond_options.c
--- a/src/network/bonding/BONDING_KDIRS/5.6.0/bond_options.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1477 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * drivers/net/bond/bond_options.c - bonding options
- * Copyright (c) 2013 Jiri Pirko <jiri@resnulli.us>
- * Copyright (c) 2013 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/errno.h>
-#include <linux/if.h>
-#include <linux/netdevice.h>
-#include <linux/spinlock.h>
-#include <linux/rcupdate.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/sched/signal.h>
-
-#include <net/bonding.h>
-
-static int bond_option_active_slave_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_miimon_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_updelay_set(struct bonding *bond,
-				   const struct bond_opt_value *newval);
-static int bond_option_downdelay_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_peer_notif_delay_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_use_carrier_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_arp_interval_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target);
-static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target);
-static int bond_option_arp_ip_targets_set(struct bonding *bond,
-					  const struct bond_opt_value *newval);
-static int bond_option_arp_validate_set(struct bonding *bond,
-					const struct bond_opt_value *newval);
-static int bond_option_arp_all_targets_set(struct bonding *bond,
-					   const struct bond_opt_value *newval);
-static int bond_option_primary_set(struct bonding *bond,
-				   const struct bond_opt_value *newval);
-static int bond_option_primary_reselect_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_fail_over_mac_set(struct bonding *bond,
-					 const struct bond_opt_value *newval);
-static int bond_option_xmit_hash_policy_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-static int bond_option_resend_igmp_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_num_peer_notif_set(struct bonding *bond,
-					  const struct bond_opt_value *newval);
-static int bond_option_all_slaves_active_set(struct bonding *bond,
-					     const struct bond_opt_value *newval);
-static int bond_option_min_links_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_lp_interval_set(struct bonding *bond,
-				       const struct bond_opt_value *newval);
-static int bond_option_pps_set(struct bonding *bond,
-			       const struct bond_opt_value *newval);
-static int bond_option_lacp_rate_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_ad_select_set(struct bonding *bond,
-				     const struct bond_opt_value *newval);
-static int bond_option_queue_id_set(struct bonding *bond,
-				    const struct bond_opt_value *newval);
-static int bond_option_mode_set(struct bonding *bond,
-				const struct bond_opt_value *newval);
-static int bond_option_slaves_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
-				  const struct bond_opt_value *newval);
-static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
-					     const struct bond_opt_value *newval);
-static int bond_option_ad_actor_system_set(struct bonding *bond,
-					   const struct bond_opt_value *newval);
-static int bond_option_ad_user_port_key_set(struct bonding *bond,
-					    const struct bond_opt_value *newval);
-
-
-static const struct bond_opt_value bond_mode_tbl[] = {
-	{ "balance-rr",    BOND_MODE_ROUNDROBIN,   BOND_VALFLAG_DEFAULT},
-	{ "active-backup", BOND_MODE_ACTIVEBACKUP, 0},
-	{ "balance-xor",   BOND_MODE_XOR,          0},
-	{ "broadcast",     BOND_MODE_BROADCAST,    0},
-	{ "802.3ad",       BOND_MODE_8023AD,       0},
-	{ "balance-tlb",   BOND_MODE_TLB,          0},
-	{ "balance-alb",   BOND_MODE_ALB,          0},
-	{ NULL,            -1,                     0},
-};
-
-static const struct bond_opt_value bond_pps_tbl[] = {
-	{ "default", 1,         BOND_VALFLAG_DEFAULT},
-	{ "maxval",  USHRT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,        0},
-};
-
-static const struct bond_opt_value bond_xmit_hashtype_tbl[] = {
-	{ "layer2",   BOND_XMIT_POLICY_LAYER2, BOND_VALFLAG_DEFAULT},
-	{ "layer3+4", BOND_XMIT_POLICY_LAYER34, 0},
-	{ "layer2+3", BOND_XMIT_POLICY_LAYER23, 0},
-	{ "encap2+3", BOND_XMIT_POLICY_ENCAP23, 0},
-	{ "encap3+4", BOND_XMIT_POLICY_ENCAP34, 0},
-	{ NULL,       -1,                       0},
-};
-
-static const struct bond_opt_value bond_arp_validate_tbl[] = {
-	{ "none",		BOND_ARP_VALIDATE_NONE,		BOND_VALFLAG_DEFAULT},
-	{ "active",		BOND_ARP_VALIDATE_ACTIVE,	0},
-	{ "backup",		BOND_ARP_VALIDATE_BACKUP,	0},
-	{ "all",		BOND_ARP_VALIDATE_ALL,		0},
-	{ "filter",		BOND_ARP_FILTER,		0},
-	{ "filter_active",	BOND_ARP_FILTER_ACTIVE,		0},
-	{ "filter_backup",	BOND_ARP_FILTER_BACKUP,		0},
-	{ NULL,			-1,				0},
-};
-
-static const struct bond_opt_value bond_arp_all_targets_tbl[] = {
-	{ "any", BOND_ARP_TARGETS_ANY, BOND_VALFLAG_DEFAULT},
-	{ "all", BOND_ARP_TARGETS_ALL, 0},
-	{ NULL,  -1,                   0},
-};
-
-static const struct bond_opt_value bond_fail_over_mac_tbl[] = {
-	{ "none",   BOND_FOM_NONE,   BOND_VALFLAG_DEFAULT},
-	{ "active", BOND_FOM_ACTIVE, 0},
-	{ "follow", BOND_FOM_FOLLOW, 0},
-	{ NULL,     -1,              0},
-};
-
-static const struct bond_opt_value bond_intmax_tbl[] = {
-	{ "off",     0,       BOND_VALFLAG_DEFAULT},
-	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,      0}
-};
-
-static const struct bond_opt_value bond_lacp_rate_tbl[] = {
-	{ "slow", AD_LACP_SLOW, 0},
-	{ "fast", AD_LACP_FAST, 0},
-	{ NULL,   -1,           0},
-};
-
-static const struct bond_opt_value bond_ad_select_tbl[] = {
-	{ "stable",    BOND_AD_STABLE,    BOND_VALFLAG_DEFAULT},
-	{ "bandwidth", BOND_AD_BANDWIDTH, 0},
-	{ "count",     BOND_AD_COUNT,     0},
-	{ NULL,        -1,                0},
-};
-
-static const struct bond_opt_value bond_num_peer_notif_tbl[] = {
-	{ "off",     0,   0},
-	{ "maxval",  255, BOND_VALFLAG_MAX},
-	{ "default", 1,   BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,  0}
-};
-
-static const struct bond_opt_value bond_primary_reselect_tbl[] = {
-	{ "always",  BOND_PRI_RESELECT_ALWAYS,  BOND_VALFLAG_DEFAULT},
-	{ "better",  BOND_PRI_RESELECT_BETTER,  0},
-	{ "failure", BOND_PRI_RESELECT_FAILURE, 0},
-	{ NULL,      -1},
-};
-
-static const struct bond_opt_value bond_use_carrier_tbl[] = {
-	{ "off", 0,  0},
-	{ "on",  1,  BOND_VALFLAG_DEFAULT},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_all_slaves_active_tbl[] = {
-	{ "off", 0,  BOND_VALFLAG_DEFAULT},
-	{ "on",  1,  0},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_resend_igmp_tbl[] = {
-	{ "off",     0,   0},
-	{ "maxval",  255, BOND_VALFLAG_MAX},
-	{ "default", 1,   BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,  0}
-};
-
-static const struct bond_opt_value bond_lp_interval_tbl[] = {
-	{ "minval",  1,       BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
-	{ "maxval",  INT_MAX, BOND_VALFLAG_MAX},
-	{ NULL,      -1,      0},
-};
-
-static const struct bond_opt_value bond_tlb_dynamic_lb_tbl[] = {
-	{ "off", 0,  0},
-	{ "on",  1,  BOND_VALFLAG_DEFAULT},
-	{ NULL,  -1, 0}
-};
-
-static const struct bond_opt_value bond_ad_actor_sys_prio_tbl[] = {
-	{ "minval",  1,     BOND_VALFLAG_MIN},
-	{ "maxval",  65535, BOND_VALFLAG_MAX | BOND_VALFLAG_DEFAULT},
-	{ NULL,      -1,    0},
-};
-
-static const struct bond_opt_value bond_ad_user_port_key_tbl[] = {
-	{ "minval",  0,     BOND_VALFLAG_MIN | BOND_VALFLAG_DEFAULT},
-	{ "maxval",  1023,  BOND_VALFLAG_MAX},
-	{ NULL,      -1,    0},
-};
-
-static const struct bond_option bond_opts[BOND_OPT_LAST] = {
-	[BOND_OPT_MODE] = {
-		.id = BOND_OPT_MODE,
-		.name = "mode",
-		.desc = "bond device mode",
-		.flags = BOND_OPTFLAG_NOSLAVES | BOND_OPTFLAG_IFDOWN,
-		.values = bond_mode_tbl,
-		.set = bond_option_mode_set
-	},
-	[BOND_OPT_PACKETS_PER_SLAVE] = {
-		.id = BOND_OPT_PACKETS_PER_SLAVE,
-		.name = "packets_per_slave",
-		.desc = "Packets to send per slave in RR mode",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ROUNDROBIN)),
-		.values = bond_pps_tbl,
-		.set = bond_option_pps_set
-	},
-	[BOND_OPT_XMIT_HASH] = {
-		.id = BOND_OPT_XMIT_HASH,
-		.name = "xmit_hash_policy",
-		.desc = "balance-xor, 802.3ad, and tlb hashing method",
-		.values = bond_xmit_hashtype_tbl,
-		.set = bond_option_xmit_hash_policy_set
-	},
-	[BOND_OPT_ARP_VALIDATE] = {
-		.id = BOND_OPT_ARP_VALIDATE,
-		.name = "arp_validate",
-		.desc = "validate src/dst of ARP probes",
-		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
-			       BIT(BOND_MODE_ALB),
-		.values = bond_arp_validate_tbl,
-		.set = bond_option_arp_validate_set
-	},
-	[BOND_OPT_ARP_ALL_TARGETS] = {
-		.id = BOND_OPT_ARP_ALL_TARGETS,
-		.name = "arp_all_targets",
-		.desc = "fail on any/all arp targets timeout",
-		.values = bond_arp_all_targets_tbl,
-		.set = bond_option_arp_all_targets_set
-	},
-	[BOND_OPT_FAIL_OVER_MAC] = {
-		.id = BOND_OPT_FAIL_OVER_MAC,
-		.name = "fail_over_mac",
-		.desc = "For active-backup, do not set all slaves to the same MAC",
-		.flags = BOND_OPTFLAG_NOSLAVES,
-		.values = bond_fail_over_mac_tbl,
-		.set = bond_option_fail_over_mac_set
-	},
-	[BOND_OPT_ARP_INTERVAL] = {
-		.id = BOND_OPT_ARP_INTERVAL,
-		.name = "arp_interval",
-		.desc = "arp interval in milliseconds",
-		.unsuppmodes = BIT(BOND_MODE_8023AD) | BIT(BOND_MODE_TLB) |
-			       BIT(BOND_MODE_ALB),
-		.values = bond_intmax_tbl,
-		.set = bond_option_arp_interval_set
-	},
-	[BOND_OPT_ARP_TARGETS] = {
-		.id = BOND_OPT_ARP_TARGETS,
-		.name = "arp_ip_target",
-		.desc = "arp targets in n.n.n.n form",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_arp_ip_targets_set
-	},
-	[BOND_OPT_DOWNDELAY] = {
-		.id = BOND_OPT_DOWNDELAY,
-		.name = "downdelay",
-		.desc = "Delay before considering link down, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_downdelay_set
-	},
-	[BOND_OPT_UPDELAY] = {
-		.id = BOND_OPT_UPDELAY,
-		.name = "updelay",
-		.desc = "Delay before considering link up, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_updelay_set
-	},
-	[BOND_OPT_LACP_RATE] = {
-		.id = BOND_OPT_LACP_RATE,
-		.name = "lacp_rate",
-		.desc = "LACPDU tx rate to request from 802.3ad partner",
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.values = bond_lacp_rate_tbl,
-		.set = bond_option_lacp_rate_set
-	},
-	[BOND_OPT_MINLINKS] = {
-		.id = BOND_OPT_MINLINKS,
-		.name = "min_links",
-		.desc = "Minimum number of available links before turning on carrier",
-		.values = bond_intmax_tbl,
-		.set = bond_option_min_links_set
-	},
-	[BOND_OPT_AD_SELECT] = {
-		.id = BOND_OPT_AD_SELECT,
-		.name = "ad_select",
-		.desc = "802.3ad aggregation selection logic",
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.values = bond_ad_select_tbl,
-		.set = bond_option_ad_select_set
-	},
-	[BOND_OPT_NUM_PEER_NOTIF] = {
-		.id = BOND_OPT_NUM_PEER_NOTIF,
-		.name = "num_unsol_na",
-		.desc = "Number of peer notifications to send on failover event",
-		.values = bond_num_peer_notif_tbl,
-		.set = bond_option_num_peer_notif_set
-	},
-	[BOND_OPT_MIIMON] = {
-		.id = BOND_OPT_MIIMON,
-		.name = "miimon",
-		.desc = "Link check interval in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_miimon_set
-	},
-	[BOND_OPT_PRIMARY] = {
-		.id = BOND_OPT_PRIMARY,
-		.name = "primary",
-		.desc = "Primary network device to use",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
-						BIT(BOND_MODE_TLB) |
-						BIT(BOND_MODE_ALB)),
-		.set = bond_option_primary_set
-	},
-	[BOND_OPT_PRIMARY_RESELECT] = {
-		.id = BOND_OPT_PRIMARY_RESELECT,
-		.name = "primary_reselect",
-		.desc = "Reselect primary slave once it comes up",
-		.values = bond_primary_reselect_tbl,
-		.set = bond_option_primary_reselect_set
-	},
-	[BOND_OPT_USE_CARRIER] = {
-		.id = BOND_OPT_USE_CARRIER,
-		.name = "use_carrier",
-		.desc = "Use netif_carrier_ok (vs MII ioctls) in miimon",
-		.values = bond_use_carrier_tbl,
-		.set = bond_option_use_carrier_set
-	},
-	[BOND_OPT_ACTIVE_SLAVE] = {
-		.id = BOND_OPT_ACTIVE_SLAVE,
-		.name = "active_slave",
-		.desc = "Currently active slave",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_ACTIVEBACKUP) |
-						BIT(BOND_MODE_TLB) |
-						BIT(BOND_MODE_ALB)),
-		.set = bond_option_active_slave_set
-	},
-	[BOND_OPT_QUEUE_ID] = {
-		.id = BOND_OPT_QUEUE_ID,
-		.name = "queue_id",
-		.desc = "Set queue id of a slave",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_queue_id_set
-	},
-	[BOND_OPT_ALL_SLAVES_ACTIVE] = {
-		.id = BOND_OPT_ALL_SLAVES_ACTIVE,
-		.name = "all_slaves_active",
-		.desc = "Keep all frames received on an interface by setting active flag for all slaves",
-		.values = bond_all_slaves_active_tbl,
-		.set = bond_option_all_slaves_active_set
-	},
-	[BOND_OPT_RESEND_IGMP] = {
-		.id = BOND_OPT_RESEND_IGMP,
-		.name = "resend_igmp",
-		.desc = "Number of IGMP membership reports to send on link failure",
-		.values = bond_resend_igmp_tbl,
-		.set = bond_option_resend_igmp_set
-	},
-	[BOND_OPT_LP_INTERVAL] = {
-		.id = BOND_OPT_LP_INTERVAL,
-		.name = "lp_interval",
-		.desc = "The number of seconds between instances where the bonding driver sends learning packets to each slave's peer switch",
-		.values = bond_lp_interval_tbl,
-		.set = bond_option_lp_interval_set
-	},
-	[BOND_OPT_SLAVES] = {
-		.id = BOND_OPT_SLAVES,
-		.name = "slaves",
-		.desc = "Slave membership management",
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_slaves_set
-	},
-	[BOND_OPT_TLB_DYNAMIC_LB] = {
-		.id = BOND_OPT_TLB_DYNAMIC_LB,
-		.name = "tlb_dynamic_lb",
-		.desc = "Enable dynamic flow shuffling",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_TLB) | BIT(BOND_MODE_ALB)),
-		.values = bond_tlb_dynamic_lb_tbl,
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.set = bond_option_tlb_dynamic_lb_set,
-	},
-	[BOND_OPT_AD_ACTOR_SYS_PRIO] = {
-		.id = BOND_OPT_AD_ACTOR_SYS_PRIO,
-		.name = "ad_actor_sys_prio",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.values = bond_ad_actor_sys_prio_tbl,
-		.set = bond_option_ad_actor_sys_prio_set,
-	},
-	[BOND_OPT_AD_ACTOR_SYSTEM] = {
-		.id = BOND_OPT_AD_ACTOR_SYSTEM,
-		.name = "ad_actor_system",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.flags = BOND_OPTFLAG_RAWVAL,
-		.set = bond_option_ad_actor_system_set,
-	},
-	[BOND_OPT_AD_USER_PORT_KEY] = {
-		.id = BOND_OPT_AD_USER_PORT_KEY,
-		.name = "ad_user_port_key",
-		.unsuppmodes = BOND_MODE_ALL_EX(BIT(BOND_MODE_8023AD)),
-		.flags = BOND_OPTFLAG_IFDOWN,
-		.values = bond_ad_user_port_key_tbl,
-		.set = bond_option_ad_user_port_key_set,
-	},
-	[BOND_OPT_NUM_PEER_NOTIF_ALIAS] = {
-		.id = BOND_OPT_NUM_PEER_NOTIF_ALIAS,
-		.name = "num_grat_arp",
-		.desc = "Number of peer notifications to send on failover event",
-		.values = bond_num_peer_notif_tbl,
-		.set = bond_option_num_peer_notif_set
-	},
-	[BOND_OPT_PEER_NOTIF_DELAY] = {
-		.id = BOND_OPT_PEER_NOTIF_DELAY,
-		.name = "peer_notif_delay",
-		.desc = "Delay between each peer notification on failover event, in milliseconds",
-		.values = bond_intmax_tbl,
-		.set = bond_option_peer_notif_delay_set
-	}
-};
-
-/* Searches for an option by name */
-const struct bond_option *bond_opt_get_by_name(const char *name)
-{
-	const struct bond_option *opt;
-	int option;
-
-	for (option = 0; option < BOND_OPT_LAST; option++) {
-		opt = bond_opt_get(option);
-		if (opt && !strcmp(opt->name, name))
-			return opt;
-	}
-
-	return NULL;
-}
-
-/* Searches for a value in opt's values[] table */
-const struct bond_opt_value *bond_opt_get_val(unsigned int option, u64 val)
-{
-	const struct bond_option *opt;
-	int i;
-
-	opt = bond_opt_get(option);
-	if (WARN_ON(!opt))
-		return NULL;
-	for (i = 0; opt->values && opt->values[i].string; i++)
-		if (opt->values[i].value == val)
-			return &opt->values[i];
-
-	return NULL;
-}
-
-/* Searches for a value in opt's values[] table which matches the flagmask */
-static const struct bond_opt_value *bond_opt_get_flags(const struct bond_option *opt,
-						       u32 flagmask)
-{
-	int i;
-
-	for (i = 0; opt->values && opt->values[i].string; i++)
-		if (opt->values[i].flags & flagmask)
-			return &opt->values[i];
-
-	return NULL;
-}
-
-/* If maxval is missing then there's no range to check. In case minval is
- * missing then it's considered to be 0.
- */
-static bool bond_opt_check_range(const struct bond_option *opt, u64 val)
-{
-	const struct bond_opt_value *minval, *maxval;
-
-	minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
-	maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
-	if (!maxval || (minval && val < minval->value) || val > maxval->value)
-		return false;
-
-	return true;
-}
-
-/**
- * bond_opt_parse - parse option value
- * @opt: the option to parse against
- * @val: value to parse
- *
- * This function tries to extract the value from @val and check if it's
- * a possible match for the option and returns NULL if a match isn't found,
- * or the struct_opt_value that matched. It also strips the new line from
- * @val->string if it's present.
- */
-const struct bond_opt_value *bond_opt_parse(const struct bond_option *opt,
-					    struct bond_opt_value *val)
-{
-	char *p, valstr[BOND_OPT_MAX_NAMELEN + 1] = { 0, };
-	const struct bond_opt_value *tbl;
-	const struct bond_opt_value *ret = NULL;
-	bool checkval;
-	int i, rv;
-
-	/* No parsing if the option wants a raw val */
-	if (opt->flags & BOND_OPTFLAG_RAWVAL)
-		return val;
-
-	tbl = opt->values;
-	if (!tbl)
-		goto out;
-
-	/* ULLONG_MAX is used to bypass string processing */
-	checkval = val->value != ULLONG_MAX;
-	if (!checkval) {
-		if (!val->string)
-			goto out;
-		p = strchr(val->string, '\n');
-		if (p)
-			*p = '\0';
-		for (p = val->string; *p; p++)
-			if (!(isdigit(*p) || isspace(*p)))
-				break;
-		/* The following code extracts the string to match or the value
-		 * and sets checkval appropriately
-		 */
-		if (*p) {
-			rv = sscanf(val->string, "%32s", valstr);
-		} else {
-			rv = sscanf(val->string, "%llu", &val->value);
-			checkval = true;
-		}
-		if (!rv)
-			goto out;
-	}
-
-	for (i = 0; tbl[i].string; i++) {
-		/* Check for exact match */
-		if (checkval) {
-			if (val->value == tbl[i].value)
-				ret = &tbl[i];
-		} else {
-			if (!strcmp(valstr, "default") &&
-			    (tbl[i].flags & BOND_VALFLAG_DEFAULT))
-				ret = &tbl[i];
-
-			if (!strcmp(valstr, tbl[i].string))
-				ret = &tbl[i];
-		}
-		/* Found an exact match */
-		if (ret)
-			goto out;
-	}
-	/* Possible range match */
-	if (checkval && bond_opt_check_range(opt, val->value))
-		ret = val;
-out:
-	return ret;
-}
-
-/* Check opt's dependencies against bond mode and currently set options */
-static int bond_opt_check_deps(struct bonding *bond,
-			       const struct bond_option *opt)
-{
-	struct bond_params *params = &bond->params;
-
-	if (test_bit(params->mode, &opt->unsuppmodes))
-		return -EACCES;
-	if ((opt->flags & BOND_OPTFLAG_NOSLAVES) && bond_has_slaves(bond))
-		return -ENOTEMPTY;
-	if ((opt->flags & BOND_OPTFLAG_IFDOWN) && (bond->dev->flags & IFF_UP))
-		return -EBUSY;
-
-	return 0;
-}
-
-static void bond_opt_dep_print(struct bonding *bond,
-			       const struct bond_option *opt)
-{
-	const struct bond_opt_value *modeval;
-	struct bond_params *params;
-
-	params = &bond->params;
-	modeval = bond_opt_get_val(BOND_OPT_MODE, params->mode);
-	if (test_bit(params->mode, &opt->unsuppmodes))
-		netdev_err(bond->dev, "option %s: mode dependency failed, not supported in mode %s(%llu)\n",
-			   opt->name, modeval->string, modeval->value);
-}
-
-static void bond_opt_error_interpret(struct bonding *bond,
-				     const struct bond_option *opt,
-				     int error, const struct bond_opt_value *val)
-{
-	const struct bond_opt_value *minval, *maxval;
-	char *p;
-
-	switch (error) {
-	case -EINVAL:
-		if (val) {
-			if (val->string) {
-				/* sometimes RAWVAL opts may have new lines */
-				p = strchr(val->string, '\n');
-				if (p)
-					*p = '\0';
-				netdev_err(bond->dev, "option %s: invalid value (%s)\n",
-					   opt->name, val->string);
-			} else {
-				netdev_err(bond->dev, "option %s: invalid value (%llu)\n",
-					   opt->name, val->value);
-			}
-		}
-		minval = bond_opt_get_flags(opt, BOND_VALFLAG_MIN);
-		maxval = bond_opt_get_flags(opt, BOND_VALFLAG_MAX);
-		if (!maxval)
-			break;
-		netdev_err(bond->dev, "option %s: allowed values %llu - %llu\n",
-			   opt->name, minval ? minval->value : 0, maxval->value);
-		break;
-	case -EACCES:
-		bond_opt_dep_print(bond, opt);
-		break;
-	case -ENOTEMPTY:
-		netdev_err(bond->dev, "option %s: unable to set because the bond device has slaves\n",
-			   opt->name);
-		break;
-	case -EBUSY:
-		netdev_err(bond->dev, "option %s: unable to set because the bond device is up\n",
-			   opt->name);
-		break;
-	default:
-		break;
-	}
-}
-
-/**
- * __bond_opt_set - set a bonding option
- * @bond: target bond device
- * @option: option to set
- * @val: value to set it to
- *
- * This function is used to change the bond's option value, it can be
- * used for both enabling/changing an option and for disabling it. RTNL lock
- * must be obtained before calling this function.
- */
-int __bond_opt_set(struct bonding *bond,
-		   unsigned int option, struct bond_opt_value *val)
-{
-	const struct bond_opt_value *retval = NULL;
-	const struct bond_option *opt;
-	int ret = -ENOENT;
-
-	ASSERT_RTNL();
-
-	opt = bond_opt_get(option);
-	if (WARN_ON(!val) || WARN_ON(!opt))
-		goto out;
-	ret = bond_opt_check_deps(bond, opt);
-	if (ret)
-		goto out;
-	retval = bond_opt_parse(opt, val);
-	if (!retval) {
-		ret = -EINVAL;
-		goto out;
-	}
-	ret = opt->set(bond, retval);
-out:
-	if (ret)
-		bond_opt_error_interpret(bond, opt, ret, val);
-
-	return ret;
-}
-/**
- * __bond_opt_set_notify - set a bonding option
- * @bond: target bond device
- * @option: option to set
- * @val: value to set it to
- *
- * This function is used to change the bond's option value and trigger
- * a notification to user sapce. It can be used for both enabling/changing
- * an option and for disabling it. RTNL lock must be obtained before calling
- * this function.
- */
-int __bond_opt_set_notify(struct bonding *bond,
-			  unsigned int option, struct bond_opt_value *val)
-{
-	int ret = -ENOENT;
-
-	ASSERT_RTNL();
-
-	ret = __bond_opt_set(bond, option, val);
-
-	if (!ret && (bond->dev->reg_state == NETREG_REGISTERED))
-		call_netdevice_notifiers(NETDEV_CHANGEINFODATA, bond->dev);
-
-	return ret;
-}
-
-/**
- * bond_opt_tryset_rtnl - try to acquire rtnl and call __bond_opt_set
- * @bond: target bond device
- * @option: option to set
- * @buf: value to set it to
- *
- * This function tries to acquire RTNL without blocking and if successful
- * calls __bond_opt_set. It is mainly used for sysfs option manipulation.
- */
-int bond_opt_tryset_rtnl(struct bonding *bond, unsigned int option, char *buf)
-{
-	struct bond_opt_value optval;
-	int ret;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-	bond_opt_initstr(&optval, buf);
-	ret = __bond_opt_set_notify(bond, option, &optval);
-	rtnl_unlock();
-
-	return ret;
-}
-
-/**
- * bond_opt_get - get a pointer to an option
- * @option: option for which to return a pointer
- *
- * This function checks if option is valid and if so returns a pointer
- * to its entry in the bond_opts[] option array.
- */
-const struct bond_option *bond_opt_get(unsigned int option)
-{
-	if (!BOND_OPT_VALID(option))
-		return NULL;
-
-	return &bond_opts[option];
-}
-
-static int bond_option_mode_set(struct bonding *bond,
-				const struct bond_opt_value *newval)
-{
-	if (!bond_mode_uses_arp(newval->value)) {
-		if (bond->params.arp_interval) {
-			netdev_dbg(bond->dev, "%s mode is incompatible with arp monitoring, start mii monitoring\n",
-				   newval->string);
-			/* disable arp monitoring */
-			bond->params.arp_interval = 0;
-		}
-
-		if (!bond->params.miimon) {
-			/* set miimon to default value */
-			bond->params.miimon = BOND_DEFAULT_MIIMON;
-			netdev_dbg(bond->dev, "Setting MII monitoring interval to %d\n",
-				   bond->params.miimon);
-		}
-	}
-
-	if (newval->value == BOND_MODE_ALB)
-		bond->params.tlb_dynamic_lb = 1;
-
-	/* don't cache arp_validate between modes */
-	bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
-	bond->params.mode = newval->value;
-
-	return 0;
-}
-
-static int bond_option_active_slave_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	char ifname[IFNAMSIZ] = { 0, };
-	struct net_device *slave_dev;
-	int ret = 0;
-
-	sscanf(newval->string, "%15s", ifname); /* IFNAMSIZ */
-	if (!strlen(ifname) || newval->string[0] == '\n') {
-		slave_dev = NULL;
-	} else {
-		slave_dev = __dev_get_by_name(dev_net(bond->dev), ifname);
-		if (!slave_dev)
-			return -ENODEV;
-	}
-
-	if (slave_dev) {
-		if (!netif_is_bond_slave(slave_dev)) {
-			slave_err(bond->dev, slave_dev, "Device is not bonding slave\n");
-			return -EINVAL;
-		}
-
-		if (bond->dev != netdev_master_upper_dev_get(slave_dev)) {
-			slave_err(bond->dev, slave_dev, "Device is not our slave\n");
-			return -EINVAL;
-		}
-	}
-
-	block_netpoll_tx();
-	/* check to see if we are clearing active */
-	if (!slave_dev) {
-		netdev_dbg(bond->dev, "Clearing current active slave\n");
-		RCU_INIT_POINTER(bond->curr_active_slave, NULL);
-		bond_select_active_slave(bond);
-	} else {
-		struct slave *old_active = rtnl_dereference(bond->curr_active_slave);
-		struct slave *new_active = bond_slave_get_rtnl(slave_dev);
-
-		BUG_ON(!new_active);
-
-		if (new_active == old_active) {
-			/* do nothing */
-			slave_dbg(bond->dev, new_active->dev, "is already the current active slave\n");
-		} else {
-			if (old_active && (new_active->link == BOND_LINK_UP) &&
-			    bond_slave_is_up(new_active)) {
-				slave_dbg(bond->dev, new_active->dev, "Setting as active slave\n");
-				bond_change_active_slave(bond, new_active);
-			} else {
-				slave_err(bond->dev, new_active->dev, "Could not set as active slave; either %s is down or the link is down\n",
-					  new_active->dev->name);
-				ret = -EINVAL;
-			}
-		}
-	}
-	unblock_netpoll_tx();
-
-	return ret;
-}
-
-/* There are two tricky bits here.  First, if MII monitoring is activated, then
- * we must disable ARP monitoring.  Second, if the timer isn't running, we must
- * start it.
- */
-static int bond_option_miimon_set(struct bonding *bond,
-				  const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting MII monitoring interval to %llu\n",
-		   newval->value);
-	bond->params.miimon = newval->value;
-	if (bond->params.updelay)
-		netdev_dbg(bond->dev, "Note: Updating updelay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.updelay * bond->params.miimon);
-	if (bond->params.downdelay)
-		netdev_dbg(bond->dev, "Note: Updating downdelay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.downdelay * bond->params.miimon);
-	if (bond->params.peer_notif_delay)
-		netdev_dbg(bond->dev, "Note: Updating peer_notif_delay (to %d) since it is a multiple of the miimon value\n",
-			   bond->params.peer_notif_delay * bond->params.miimon);
-	if (newval->value && bond->params.arp_interval) {
-		netdev_dbg(bond->dev, "MII monitoring cannot be used with ARP monitoring - disabling ARP monitoring...\n");
-		bond->params.arp_interval = 0;
-		if (bond->params.arp_validate)
-			bond->params.arp_validate = BOND_ARP_VALIDATE_NONE;
-	}
-	if (bond->dev->flags & IFF_UP) {
-		/* If the interface is up, we may need to fire off
-		 * the MII timer. If the interface is down, the
-		 * timer will get fired off when the open function
-		 * is called.
-		 */
-		if (!newval->value) {
-			cancel_delayed_work_sync(&bond->mii_work);
-		} else {
-			cancel_delayed_work_sync(&bond->arp_work);
-			queue_delayed_work(bond->wq, &bond->mii_work, 0);
-		}
-	}
-
-	return 0;
-}
-
-/* Set up, down and peer notification delays. These must be multiples
- * of the MII monitoring value, and are stored internally as the
- * multiplier. Thus, we must translate to MS for the real world.
- */
-static int _bond_option_delay_set(struct bonding *bond,
-				  const struct bond_opt_value *newval,
-				  const char *name,
-				  int *target)
-{
-	int value = newval->value;
-
-	if (!bond->params.miimon) {
-		netdev_err(bond->dev, "Unable to set %s as MII monitoring is disabled\n",
-			   name);
-		return -EPERM;
-	}
-	if ((value % bond->params.miimon) != 0) {
-		netdev_warn(bond->dev,
-			    "%s (%d) is not a multiple of miimon (%d), value rounded to %d ms\n",
-			    name,
-			    value, bond->params.miimon,
-			    (value / bond->params.miimon) *
-			    bond->params.miimon);
-	}
-	*target = value / bond->params.miimon;
-	netdev_dbg(bond->dev, "Setting %s to %d\n",
-		   name,
-		   *target * bond->params.miimon);
-
-	return 0;
-}
-
-static int bond_option_updelay_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	return _bond_option_delay_set(bond, newval, "up delay",
-				      &bond->params.updelay);
-}
-
-static int bond_option_downdelay_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	return _bond_option_delay_set(bond, newval, "down delay",
-				      &bond->params.downdelay);
-}
-
-static int bond_option_peer_notif_delay_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	int ret = _bond_option_delay_set(bond, newval,
-					 "peer notification delay",
-					 &bond->params.peer_notif_delay);
-	return ret;
-}
-
-static int bond_option_use_carrier_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting use_carrier to %llu\n",
-		   newval->value);
-	bond->params.use_carrier = newval->value;
-
-	return 0;
-}
-
-/* There are two tricky bits here.  First, if ARP monitoring is activated, then
- * we must disable MII monitoring.  Second, if the ARP timer isn't running,
- * we must start it.
- */
-static int bond_option_arp_interval_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ARP monitoring interval to %llu\n",
-		   newval->value);
-	bond->params.arp_interval = newval->value;
-	if (newval->value) {
-		if (bond->params.miimon) {
-			netdev_dbg(bond->dev, "ARP monitoring cannot be used with MII monitoring. Disabling MII monitoring\n");
-			bond->params.miimon = 0;
-		}
-		if (!bond->params.arp_targets[0])
-			netdev_dbg(bond->dev, "ARP monitoring has been set up, but no ARP targets have been specified\n");
-	}
-	if (bond->dev->flags & IFF_UP) {
-		/* If the interface is up, we may need to fire off
-		 * the ARP timer.  If the interface is down, the
-		 * timer will get fired off when the open function
-		 * is called.
-		 */
-		if (!newval->value) {
-			if (bond->params.arp_validate)
-				bond->recv_probe = NULL;
-			cancel_delayed_work_sync(&bond->arp_work);
-		} else {
-			/* arp_validate can be set only in active-backup mode */
-			bond->recv_probe = bond_arp_rcv;
-			cancel_delayed_work_sync(&bond->mii_work);
-			queue_delayed_work(bond->wq, &bond->arp_work, 0);
-		}
-	}
-
-	return 0;
-}
-
-static void _bond_options_arp_ip_target_set(struct bonding *bond, int slot,
-					    __be32 target,
-					    unsigned long last_rx)
-{
-	__be32 *targets = bond->params.arp_targets;
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (slot >= 0 && slot < BOND_MAX_ARP_TARGETS) {
-		bond_for_each_slave(bond, slave, iter)
-			slave->target_last_arp_rx[slot] = last_rx;
-		targets[slot] = target;
-	}
-}
-
-static int _bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
-{
-	__be32 *targets = bond->params.arp_targets;
-	int ind;
-
-	if (!bond_is_ip_target_ok(target)) {
-		netdev_err(bond->dev, "invalid ARP target %pI4 specified for addition\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	if (bond_get_targets_ip(targets, target) != -1) { /* dup */
-		netdev_err(bond->dev, "ARP target %pI4 is already present\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	ind = bond_get_targets_ip(targets, 0); /* first free slot */
-	if (ind == -1) {
-		netdev_err(bond->dev, "ARP target table is full!\n");
-		return -EINVAL;
-	}
-
-	netdev_dbg(bond->dev, "Adding ARP target %pI4\n", &target);
-
-	_bond_options_arp_ip_target_set(bond, ind, target, jiffies);
-
-	return 0;
-}
-
-static int bond_option_arp_ip_target_add(struct bonding *bond, __be32 target)
-{
-	return _bond_option_arp_ip_target_add(bond, target);
-}
-
-static int bond_option_arp_ip_target_rem(struct bonding *bond, __be32 target)
-{
-	__be32 *targets = bond->params.arp_targets;
-	struct list_head *iter;
-	struct slave *slave;
-	unsigned long *targets_rx;
-	int ind, i;
-
-	if (!bond_is_ip_target_ok(target)) {
-		netdev_err(bond->dev, "invalid ARP target %pI4 specified for removal\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	ind = bond_get_targets_ip(targets, target);
-	if (ind == -1) {
-		netdev_err(bond->dev, "unable to remove nonexistent ARP target %pI4\n",
-			   &target);
-		return -EINVAL;
-	}
-
-	if (ind == 0 && !targets[1] && bond->params.arp_interval)
-		netdev_warn(bond->dev, "Removing last arp target with arp_interval on\n");
-
-	netdev_dbg(bond->dev, "Removing ARP target %pI4\n", &target);
-
-	bond_for_each_slave(bond, slave, iter) {
-		targets_rx = slave->target_last_arp_rx;
-		for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
-			targets_rx[i] = targets_rx[i+1];
-		targets_rx[i] = 0;
-	}
-	for (i = ind; (i < BOND_MAX_ARP_TARGETS-1) && targets[i+1]; i++)
-		targets[i] = targets[i+1];
-	targets[i] = 0;
-
-	return 0;
-}
-
-void bond_option_arp_ip_targets_clear(struct bonding *bond)
-{
-	int i;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++)
-		_bond_options_arp_ip_target_set(bond, i, 0, 0);
-}
-
-static int bond_option_arp_ip_targets_set(struct bonding *bond,
-					  const struct bond_opt_value *newval)
-{
-	int ret = -EPERM;
-	__be32 target;
-
-	if (newval->string) {
-		if (!in4_pton(newval->string+1, -1, (u8 *)&target, -1, NULL)) {
-			netdev_err(bond->dev, "invalid ARP target %pI4 specified\n",
-				   &target);
-			return ret;
-		}
-		if (newval->string[0] == '+')
-			ret = bond_option_arp_ip_target_add(bond, target);
-		else if (newval->string[0] == '-')
-			ret = bond_option_arp_ip_target_rem(bond, target);
-		else
-			netdev_err(bond->dev, "no command found in arp_ip_targets file - use +<addr> or -<addr>\n");
-	} else {
-		target = newval->value;
-		ret = bond_option_arp_ip_target_add(bond, target);
-	}
-
-	return ret;
-}
-
-static int bond_option_arp_validate_set(struct bonding *bond,
-					const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting arp_validate to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.arp_validate = newval->value;
-
-	return 0;
-}
-
-static int bond_option_arp_all_targets_set(struct bonding *bond,
-					   const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting arp_all_targets to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.arp_all_targets = newval->value;
-
-	return 0;
-}
-
-static int bond_option_primary_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	char *p, *primary = newval->string;
-	struct list_head *iter;
-	struct slave *slave;
-
-	block_netpoll_tx();
-
-	p = strchr(primary, '\n');
-	if (p)
-		*p = '\0';
-	/* check to see if we are clearing primary */
-	if (!strlen(primary)) {
-		netdev_dbg(bond->dev, "Setting primary slave to None\n");
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-		memset(bond->params.primary, 0, sizeof(bond->params.primary));
-		bond_select_active_slave(bond);
-		goto out;
-	}
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (strncmp(slave->dev->name, primary, IFNAMSIZ) == 0) {
-			slave_dbg(bond->dev, slave->dev, "Setting as primary slave\n");
-			rcu_assign_pointer(bond->primary_slave, slave);
-			strcpy(bond->params.primary, slave->dev->name);
-			bond->force_primary = true;
-			bond_select_active_slave(bond);
-			goto out;
-		}
-	}
-
-	if (rtnl_dereference(bond->primary_slave)) {
-		netdev_dbg(bond->dev, "Setting primary slave to None\n");
-		RCU_INIT_POINTER(bond->primary_slave, NULL);
-		bond_select_active_slave(bond);
-	}
-	strncpy(bond->params.primary, primary, IFNAMSIZ);
-	bond->params.primary[IFNAMSIZ - 1] = 0;
-
-	netdev_dbg(bond->dev, "Recording %s as primary, but it has not been enslaved yet\n",
-		   primary);
-
-out:
-	unblock_netpoll_tx();
-
-	return 0;
-}
-
-static int bond_option_primary_reselect_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting primary_reselect to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.primary_reselect = newval->value;
-
-	block_netpoll_tx();
-	bond_select_active_slave(bond);
-	unblock_netpoll_tx();
-
-	return 0;
-}
-
-static int bond_option_fail_over_mac_set(struct bonding *bond,
-					 const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting fail_over_mac to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.fail_over_mac = newval->value;
-
-	return 0;
-}
-
-static int bond_option_xmit_hash_policy_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting xmit hash policy to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.xmit_policy = newval->value;
-
-	return 0;
-}
-
-static int bond_option_resend_igmp_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting resend_igmp to %llu\n",
-		   newval->value);
-	bond->params.resend_igmp = newval->value;
-
-	return 0;
-}
-
-static int bond_option_num_peer_notif_set(struct bonding *bond,
-				   const struct bond_opt_value *newval)
-{
-	bond->params.num_peer_notif = newval->value;
-
-	return 0;
-}
-
-static int bond_option_all_slaves_active_set(struct bonding *bond,
-					     const struct bond_opt_value *newval)
-{
-	struct list_head *iter;
-	struct slave *slave;
-
-	if (newval->value == bond->params.all_slaves_active)
-		return 0;
-	bond->params.all_slaves_active = newval->value;
-	bond_for_each_slave(bond, slave, iter) {
-		if (!bond_is_active_slave(slave)) {
-			if (newval->value)
-				slave->inactive = 0;
-			else
-				slave->inactive = 1;
-		}
-	}
-
-	return 0;
-}
-
-static int bond_option_min_links_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting min links value to %llu\n",
-		   newval->value);
-	bond->params.min_links = newval->value;
-	bond_set_carrier(bond);
-
-	return 0;
-}
-
-static int bond_option_lp_interval_set(struct bonding *bond,
-				       const struct bond_opt_value *newval)
-{
-	bond->params.lp_interval = newval->value;
-
-	return 0;
-}
-
-static int bond_option_pps_set(struct bonding *bond,
-			       const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting packets per slave to %llu\n",
-		   newval->value);
-	bond->params.packets_per_slave = newval->value;
-	if (newval->value > 0) {
-		bond->params.reciprocal_packets_per_slave =
-			reciprocal_value(newval->value);
-	} else {
-		/* reciprocal_packets_per_slave is unused if
-		 * packets_per_slave is 0 or 1, just initialize it
-		 */
-		bond->params.reciprocal_packets_per_slave =
-			(struct reciprocal_value) { 0 };
-	}
-
-	return 0;
-}
-
-static int bond_option_lacp_rate_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting LACP rate to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.lacp_fast = newval->value;
-	bond_3ad_update_lacp_rate(bond);
-
-	return 0;
-}
-
-static int bond_option_ad_select_set(struct bonding *bond,
-				     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_select to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.ad_select = newval->value;
-
-	return 0;
-}
-
-static int bond_option_queue_id_set(struct bonding *bond,
-				    const struct bond_opt_value *newval)
-{
-	struct slave *slave, *update_slave;
-	struct net_device *sdev;
-	struct list_head *iter;
-	char *delim;
-	int ret = 0;
-	u16 qid;
-
-	/* delim will point to queue id if successful */
-	delim = strchr(newval->string, ':');
-	if (!delim)
-		goto err_no_cmd;
-
-	/* Terminate string that points to device name and bump it
-	 * up one, so we can read the queue id there.
-	 */
-	*delim = '\0';
-	if (sscanf(++delim, "%hd\n", &qid) != 1)
-		goto err_no_cmd;
-
-	/* Check buffer length, valid ifname and queue id */
-	if (!dev_valid_name(newval->string) ||
-	    qid > bond->dev->real_num_tx_queues)
-		goto err_no_cmd;
-
-	/* Get the pointer to that interface if it exists */
-	sdev = __dev_get_by_name(dev_net(bond->dev), newval->string);
-	if (!sdev)
-		goto err_no_cmd;
-
-	/* Search for thes slave and check for duplicate qids */
-	update_slave = NULL;
-	bond_for_each_slave(bond, slave, iter) {
-		if (sdev == slave->dev)
-			/* We don't need to check the matching
-			 * slave for dups, since we're overwriting it
-			 */
-			update_slave = slave;
-		else if (qid && qid == slave->queue_id) {
-			goto err_no_cmd;
-		}
-	}
-
-	if (!update_slave)
-		goto err_no_cmd;
-
-	/* Actually set the qids for the slave */
-	update_slave->queue_id = qid;
-
-out:
-	return ret;
-
-err_no_cmd:
-	netdev_dbg(bond->dev, "invalid input for queue_id set\n");
-	ret = -EPERM;
-	goto out;
-
-}
-
-static int bond_option_slaves_set(struct bonding *bond,
-				  const struct bond_opt_value *newval)
-{
-	char command[IFNAMSIZ + 1] = { 0, };
-	struct net_device *dev;
-	char *ifname;
-	int ret;
-
-	sscanf(newval->string, "%16s", command); /* IFNAMSIZ*/
-	ifname = command + 1;
-	if ((strlen(command) <= 1) ||
-	    (command[0] != '+' && command[0] != '-') ||
-	    !dev_valid_name(ifname))
-		goto err_no_cmd;
-
-	dev = __dev_get_by_name(dev_net(bond->dev), ifname);
-	if (!dev) {
-		netdev_dbg(bond->dev, "interface %s does not exist!\n",
-			   ifname);
-		ret = -ENODEV;
-		goto out;
-	}
-
-	switch (command[0]) {
-	case '+':
-		slave_dbg(bond->dev, dev, "Enslaving interface\n");
-		ret = bond_enslave(bond->dev, dev, NULL);
-		break;
-
-	case '-':
-		slave_dbg(bond->dev, dev, "Releasing interface\n");
-		ret = bond_release(bond->dev, dev);
-		if (!ret)
-			netdev_update_lockdep_key(dev);
-		break;
-
-	default:
-		/* should not run here. */
-		goto err_no_cmd;
-	}
-
-out:
-	return ret;
-
-err_no_cmd:
-	netdev_err(bond->dev, "no command found in slaves file - use +ifname or -ifname\n");
-	ret = -EPERM;
-	goto out;
-}
-
-static int bond_option_tlb_dynamic_lb_set(struct bonding *bond,
-					  const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting dynamic-lb to %s (%llu)\n",
-		   newval->string, newval->value);
-	bond->params.tlb_dynamic_lb = newval->value;
-
-	return 0;
-}
-
-static int bond_option_ad_actor_sys_prio_set(struct bonding *bond,
-					     const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_actor_sys_prio to %llu\n",
-		   newval->value);
-
-	bond->params.ad_actor_sys_prio = newval->value;
-	bond_3ad_update_ad_actor_settings(bond);
-
-	return 0;
-}
-
-static int bond_option_ad_actor_system_set(struct bonding *bond,
-					   const struct bond_opt_value *newval)
-{
-	u8 macaddr[ETH_ALEN];
-	u8 *mac;
-
-	if (newval->string) {
-		if (!mac_pton(newval->string, macaddr))
-			goto err;
-		mac = macaddr;
-	} else {
-		mac = (u8 *)&newval->value;
-	}
-
-	if (!is_valid_ether_addr(mac))
-		goto err;
-
-	netdev_dbg(bond->dev, "Setting ad_actor_system to %pM\n", mac);
-	ether_addr_copy(bond->params.ad_actor_system, mac);
-	bond_3ad_update_ad_actor_settings(bond);
-
-	return 0;
-
-err:
-	netdev_err(bond->dev, "Invalid ad_actor_system MAC address.\n");
-	return -EINVAL;
-}
-
-static int bond_option_ad_user_port_key_set(struct bonding *bond,
-					    const struct bond_opt_value *newval)
-{
-	netdev_dbg(bond->dev, "Setting ad_user_port_key to %llu\n",
-		   newval->value);
-
-	bond->params.ad_user_port_key = newval->value;
-	return 0;
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.6.0/bond_procfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.6.0/bond_procfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,312 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-#include <linux/proc_fs.h>
-#include <linux/export.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <net/bonding.h>
-
-#include "bonding_priv.h"
-
-static void *bond_info_seq_start(struct seq_file *seq, loff_t *pos)
-	__acquires(RCU)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	struct list_head *iter;
-	struct slave *slave;
-	loff_t off = 0;
-
-	rcu_read_lock();
-
-	if (*pos == 0)
-		return SEQ_START_TOKEN;
-
-	bond_for_each_slave_rcu(bond, slave, iter)
-		if (++off == *pos)
-			return slave;
-
-	return NULL;
-}
-
-static void *bond_info_seq_next(struct seq_file *seq, void *v, loff_t *pos)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	struct list_head *iter;
-	struct slave *slave;
-	bool found = false;
-
-	++*pos;
-	if (v == SEQ_START_TOKEN)
-		return bond_first_slave_rcu(bond);
-
-	bond_for_each_slave_rcu(bond, slave, iter) {
-		if (found)
-			return slave;
-		if (slave == v)
-			found = true;
-	}
-
-	return NULL;
-}
-
-static void bond_info_seq_stop(struct seq_file *seq, void *v)
-	__releases(RCU)
-{
-	rcu_read_unlock();
-}
-
-static void bond_info_show_master(struct seq_file *seq)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-	const struct bond_opt_value *optval;
-	struct slave *curr, *primary;
-	int i;
-
-	curr = rcu_dereference(bond->curr_active_slave);
-
-	seq_printf(seq, "Bonding Mode: %s",
-		   bond_mode_name(BOND_MODE(bond)));
-
-	if (BOND_MODE(bond) == BOND_MODE_ACTIVEBACKUP &&
-	    bond->params.fail_over_mac) {
-		optval = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
-					  bond->params.fail_over_mac);
-		seq_printf(seq, " (fail_over_mac %s)", optval->string);
-	}
-
-	seq_printf(seq, "\n");
-
-	if (bond_mode_uses_xmit_hash(bond)) {
-		optval = bond_opt_get_val(BOND_OPT_XMIT_HASH,
-					  bond->params.xmit_policy);
-		seq_printf(seq, "Transmit Hash Policy: %s (%d)\n",
-			   optval->string, bond->params.xmit_policy);
-	}
-
-	if (bond_uses_primary(bond)) {
-		primary = rcu_dereference(bond->primary_slave);
-		seq_printf(seq, "Primary Slave: %s",
-			   primary ? primary->dev->name : "None");
-		if (primary) {
-			optval = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
-						  bond->params.primary_reselect);
-			seq_printf(seq, " (primary_reselect %s)",
-				   optval->string);
-		}
-
-		seq_printf(seq, "\nCurrently Active Slave: %s\n",
-			   (curr) ? curr->dev->name : "None");
-	}
-
-	seq_printf(seq, "MII Status: %s\n", netif_carrier_ok(bond->dev) ?
-		   "up" : "down");
-	seq_printf(seq, "MII Polling Interval (ms): %d\n", bond->params.miimon);
-	seq_printf(seq, "Up Delay (ms): %d\n",
-		   bond->params.updelay * bond->params.miimon);
-	seq_printf(seq, "Down Delay (ms): %d\n",
-		   bond->params.downdelay * bond->params.miimon);
-	seq_printf(seq, "Peer Notification Delay (ms): %d\n",
-		   bond->params.peer_notif_delay * bond->params.miimon);
-
-
-	/* ARP information */
-	if (bond->params.arp_interval > 0) {
-		int printed = 0;
-		seq_printf(seq, "ARP Polling Interval (ms): %d\n",
-				bond->params.arp_interval);
-
-		seq_printf(seq, "ARP IP target/s (n.n.n.n form):");
-
-		for (i = 0; (i < BOND_MAX_ARP_TARGETS); i++) {
-			if (!bond->params.arp_targets[i])
-				break;
-			if (printed)
-				seq_printf(seq, ",");
-			seq_printf(seq, " %pI4", &bond->params.arp_targets[i]);
-			printed = 1;
-		}
-		seq_printf(seq, "\n");
-	}
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-
-		seq_puts(seq, "\n802.3ad info\n");
-		seq_printf(seq, "LACP rate: %s\n",
-			   (bond->params.lacp_fast) ? "fast" : "slow");
-		seq_printf(seq, "Min links: %d\n", bond->params.min_links);
-		optval = bond_opt_get_val(BOND_OPT_AD_SELECT,
-					  bond->params.ad_select);
-		seq_printf(seq, "Aggregator selection policy (ad_select): %s\n",
-			   optval->string);
-		if (capable(CAP_NET_ADMIN)) {
-			seq_printf(seq, "System priority: %d\n",
-				   BOND_AD_INFO(bond).system.sys_priority);
-			seq_printf(seq, "System MAC address: %pM\n",
-				   &BOND_AD_INFO(bond).system.sys_mac_addr);
-
-			if (__bond_3ad_get_active_agg_info(bond, &ad_info)) {
-				seq_printf(seq,
-					   "bond %s has no active aggregator\n",
-					   bond->dev->name);
-			} else {
-				seq_printf(seq, "Active Aggregator Info:\n");
-
-				seq_printf(seq, "\tAggregator ID: %d\n",
-					   ad_info.aggregator_id);
-				seq_printf(seq, "\tNumber of ports: %d\n",
-					   ad_info.ports);
-				seq_printf(seq, "\tActor Key: %d\n",
-					   ad_info.actor_key);
-				seq_printf(seq, "\tPartner Key: %d\n",
-					   ad_info.partner_key);
-				seq_printf(seq, "\tPartner Mac Address: %pM\n",
-					   ad_info.partner_system);
-			}
-		}
-	}
-}
-
-static void bond_info_show_slave(struct seq_file *seq,
-				 const struct slave *slave)
-{
-	struct bonding *bond = PDE_DATA(file_inode(seq->file));
-
-	seq_printf(seq, "\nSlave Interface: %s\n", slave->dev->name);
-	seq_printf(seq, "MII Status: %s\n", bond_slave_link_status(slave->link));
-	if (slave->speed == SPEED_UNKNOWN)
-		seq_printf(seq, "Speed: %s\n", "Unknown");
-	else
-		seq_printf(seq, "Speed: %d Mbps\n", slave->speed);
-
-	if (slave->duplex == DUPLEX_UNKNOWN)
-		seq_printf(seq, "Duplex: %s\n", "Unknown");
-	else
-		seq_printf(seq, "Duplex: %s\n", slave->duplex ? "full" : "half");
-
-	seq_printf(seq, "Link Failure Count: %u\n",
-		   slave->link_failure_count);
-
-	seq_printf(seq, "Permanent HW addr: %*phC\n",
-		   slave->dev->addr_len, slave->perm_hwaddr);
-	seq_printf(seq, "Slave queue ID: %d\n", slave->queue_id);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		const struct port *port = &SLAVE_AD_INFO(slave)->port;
-		const struct aggregator *agg = port->aggregator;
-
-		if (agg) {
-			seq_printf(seq, "Aggregator ID: %d\n",
-				   agg->aggregator_identifier);
-			seq_printf(seq, "Actor Churn State: %s\n",
-				   bond_3ad_churn_desc(port->sm_churn_actor_state));
-			seq_printf(seq, "Partner Churn State: %s\n",
-				   bond_3ad_churn_desc(port->sm_churn_partner_state));
-			seq_printf(seq, "Actor Churned Count: %d\n",
-				   port->churn_actor_count);
-			seq_printf(seq, "Partner Churned Count: %d\n",
-				   port->churn_partner_count);
-
-			if (capable(CAP_NET_ADMIN)) {
-				seq_puts(seq, "details actor lacp pdu:\n");
-				seq_printf(seq, "    system priority: %d\n",
-					   port->actor_system_priority);
-				seq_printf(seq, "    system mac address: %pM\n",
-					   &port->actor_system);
-				seq_printf(seq, "    port key: %d\n",
-					   port->actor_oper_port_key);
-				seq_printf(seq, "    port priority: %d\n",
-					   port->actor_port_priority);
-				seq_printf(seq, "    port number: %d\n",
-					   port->actor_port_number);
-				seq_printf(seq, "    port state: %d\n",
-					   port->actor_oper_port_state);
-
-				seq_puts(seq, "details partner lacp pdu:\n");
-				seq_printf(seq, "    system priority: %d\n",
-					   port->partner_oper.system_priority);
-				seq_printf(seq, "    system mac address: %pM\n",
-					   &port->partner_oper.system);
-				seq_printf(seq, "    oper key: %d\n",
-					   port->partner_oper.key);
-				seq_printf(seq, "    port priority: %d\n",
-					   port->partner_oper.port_priority);
-				seq_printf(seq, "    port number: %d\n",
-					   port->partner_oper.port_number);
-				seq_printf(seq, "    port state: %d\n",
-					   port->partner_oper.port_state);
-			}
-		} else {
-			seq_puts(seq, "Aggregator ID: N/A\n");
-		}
-	}
-}
-
-static int bond_info_seq_show(struct seq_file *seq, void *v)
-{
-	if (v == SEQ_START_TOKEN) {
-		seq_printf(seq, "%s\n", bond_version);
-		bond_info_show_master(seq);
-	} else
-		bond_info_show_slave(seq, v);
-
-	return 0;
-}
-
-static const struct seq_operations bond_info_seq_ops = {
-	.start = bond_info_seq_start,
-	.next  = bond_info_seq_next,
-	.stop  = bond_info_seq_stop,
-	.show  = bond_info_seq_show,
-};
-
-void bond_create_proc_entry(struct bonding *bond)
-{
-	struct net_device *bond_dev = bond->dev;
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	if (bn->proc_dir) {
-		bond->proc_entry = proc_create_seq_data(bond_dev->name, 0444,
-				bn->proc_dir, &bond_info_seq_ops, bond);
-		if (bond->proc_entry == NULL)
-			netdev_warn(bond_dev, "Cannot create /proc/net/%s/%s\n",
-				    DRV_NAME, bond_dev->name);
-		else
-			memcpy(bond->proc_file_name, bond_dev->name, IFNAMSIZ);
-	}
-}
-
-void bond_remove_proc_entry(struct bonding *bond)
-{
-	struct net_device *bond_dev = bond->dev;
-	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);
-
-	if (bn->proc_dir && bond->proc_entry) {
-		remove_proc_entry(bond->proc_file_name, bn->proc_dir);
-		memset(bond->proc_file_name, 0, IFNAMSIZ);
-		bond->proc_entry = NULL;
-	}
-}
-
-/* Create the bonding directory under /proc/net, if doesn't exist yet.
- * Caller must hold rtnl_lock.
- */
-void __net_init bond_create_proc_dir(struct bond_net *bn)
-{
-	if (!bn->proc_dir) {
-		bn->proc_dir = proc_mkdir(DRV_NAME, bn->net->proc_net);
-		if (!bn->proc_dir)
-			pr_warn("Warning: Cannot create /proc/net/%s\n",
-				DRV_NAME);
-	}
-}
-
-/* Destroy the bonding directory under /proc/net, if empty.
- * Caller must hold rtnl_lock.
- */
-void __net_exit bond_destroy_proc_dir(struct bond_net *bn)
-{
-	if (bn->proc_dir) {
-		remove_proc_entry(DRV_NAME, bn->net->proc_net);
-		bn->proc_dir = NULL;
-	}
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.6.0/bond_sysfs.c
--- a/src/network/bonding/BONDING_KDIRS/5.6.0/bond_sysfs.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,816 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*
- * Copyright(c) 2004-2005 Intel Corporation. All rights reserved.
- */
-
-#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/device.h>
-#include <linux/sched/signal.h>
-#include <linux/fs.h>
-#include <linux/types.h>
-#include <linux/string.h>
-#include <linux/netdevice.h>
-#include <linux/inetdevice.h>
-#include <linux/in.h>
-#include <linux/sysfs.h>
-#include <linux/ctype.h>
-#include <linux/inet.h>
-#include <linux/rtnetlink.h>
-#include <linux/etherdevice.h>
-#include <net/net_namespace.h>
-#include <net/netns/generic.h>
-#include <linux/nsproxy.h>
-
-#include <net/bonding.h>
-
-#define to_bond(cd)	((struct bonding *)(netdev_priv(to_net_dev(cd))))
-
-/* "show" function for the bond_masters attribute.
- * The class parameter is ignored.
- */
-static ssize_t bonding_show_bonds(struct class *cls,
-				  struct class_attribute *attr,
-				  char *buf)
-{
-	struct bond_net *bn =
-		container_of(attr, struct bond_net, class_attr_bonding_masters);
-	int res = 0;
-	struct bonding *bond;
-
-	rtnl_lock();
-
-	list_for_each_entry(bond, &bn->dev_list, bond_list) {
-		if (res > (PAGE_SIZE - IFNAMSIZ)) {
-			/* not enough space for another interface name */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s ", bond->dev->name);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	rtnl_unlock();
-	return res;
-}
-
-static struct net_device *bond_get_by_name(struct bond_net *bn, const char *ifname)
-{
-	struct bonding *bond;
-
-	list_for_each_entry(bond, &bn->dev_list, bond_list) {
-		if (strncmp(bond->dev->name, ifname, IFNAMSIZ) == 0)
-			return bond->dev;
-	}
-	return NULL;
-}
-
-/* "store" function for the bond_masters attribute.  This is what
- * creates and deletes entire bonds.
- *
- * The class parameter is ignored.
- */
-static ssize_t bonding_store_bonds(struct class *cls,
-				   struct class_attribute *attr,
-				   const char *buffer, size_t count)
-{
-	struct bond_net *bn =
-		container_of(attr, struct bond_net, class_attr_bonding_masters);
-	char command[IFNAMSIZ + 1] = {0, };
-	char *ifname;
-	int rv, res = count;
-
-	sscanf(buffer, "%16s", command); /* IFNAMSIZ*/
-	ifname = command + 1;
-	if ((strlen(command) <= 1) ||
-	    !dev_valid_name(ifname))
-		goto err_no_cmd;
-
-	if (command[0] == '+') {
-		pr_info("%s is being created...\n", ifname);
-		rv = bond_create(bn->net, ifname);
-		if (rv) {
-			if (rv == -EEXIST)
-				pr_info("%s already exists\n", ifname);
-			else
-				pr_info("%s creation failed\n", ifname);
-			res = rv;
-		}
-	} else if (command[0] == '-') {
-		struct net_device *bond_dev;
-
-		rtnl_lock();
-		bond_dev = bond_get_by_name(bn, ifname);
-		if (bond_dev) {
-			pr_info("%s is being deleted...\n", ifname);
-			unregister_netdevice(bond_dev);
-		} else {
-			pr_err("unable to delete non-existent %s\n", ifname);
-			res = -ENODEV;
-		}
-		rtnl_unlock();
-	} else
-		goto err_no_cmd;
-
-	/* Always return either count or an error.  If you return 0, you'll
-	 * get called forever, which is bad.
-	 */
-	return res;
-
-err_no_cmd:
-	pr_err("no command found in bonding_masters - use +ifname or -ifname\n");
-	return -EPERM;
-}
-
-/* class attribute for bond_masters file.  This ends up in /sys/class/net */
-static const struct class_attribute class_attr_bonding_masters = {
-	.attr = {
-		.name = "bonding_masters",
-		.mode = 0644,
-	},
-	.show = bonding_show_bonds,
-	.store = bonding_store_bonds,
-};
-
-/* Generic "store" method for bonding sysfs option setting */
-static ssize_t bonding_sysfs_store_option(struct device *d,
-					  struct device_attribute *attr,
-					  const char *buffer, size_t count)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_option *opt;
-	char *buffer_clone;
-	int ret;
-
-	opt = bond_opt_get_by_name(attr->attr.name);
-	if (WARN_ON(!opt))
-		return -ENOENT;
-	buffer_clone = kstrndup(buffer, count, GFP_KERNEL);
-	if (!buffer_clone)
-		return -ENOMEM;
-	ret = bond_opt_tryset_rtnl(bond, opt->id, buffer_clone);
-	if (!ret)
-		ret = count;
-	kfree(buffer_clone);
-
-	return ret;
-}
-
-/* Show the slaves in the current bond. */
-static ssize_t bonding_show_slaves(struct device *d,
-				   struct device_attribute *attr, char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct list_head *iter;
-	struct slave *slave;
-	int res = 0;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (res > (PAGE_SIZE - IFNAMSIZ)) {
-			/* not enough space for another interface name */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s ", slave->dev->name);
-	}
-
-	rtnl_unlock();
-
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	return res;
-}
-static DEVICE_ATTR(slaves, 0644, bonding_show_slaves,
-		   bonding_sysfs_store_option);
-
-/* Show the bonding mode. */
-static ssize_t bonding_show_mode(struct device *d,
-				 struct device_attribute *attr, char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_MODE, BOND_MODE(bond));
-
-	return sprintf(buf, "%s %d\n", val->string, BOND_MODE(bond));
-}
-static DEVICE_ATTR(mode, 0644, bonding_show_mode, bonding_sysfs_store_option);
-
-/* Show the bonding transmit hash method. */
-static ssize_t bonding_show_xmit_hash(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_XMIT_HASH, bond->params.xmit_policy);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.xmit_policy);
-}
-static DEVICE_ATTR(xmit_hash_policy, 0644,
-		   bonding_show_xmit_hash, bonding_sysfs_store_option);
-
-/* Show arp_validate. */
-static ssize_t bonding_show_arp_validate(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_ARP_VALIDATE,
-			       bond->params.arp_validate);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.arp_validate);
-}
-static DEVICE_ATTR(arp_validate, 0644, bonding_show_arp_validate,
-		   bonding_sysfs_store_option);
-
-/* Show arp_all_targets. */
-static ssize_t bonding_show_arp_all_targets(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_ARP_ALL_TARGETS,
-			       bond->params.arp_all_targets);
-	return sprintf(buf, "%s %d\n",
-		       val->string, bond->params.arp_all_targets);
-}
-static DEVICE_ATTR(arp_all_targets, 0644,
-		   bonding_show_arp_all_targets, bonding_sysfs_store_option);
-
-/* Show fail_over_mac. */
-static ssize_t bonding_show_fail_over_mac(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_FAIL_OVER_MAC,
-			       bond->params.fail_over_mac);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.fail_over_mac);
-}
-static DEVICE_ATTR(fail_over_mac, 0644,
-		   bonding_show_fail_over_mac, bonding_sysfs_store_option);
-
-/* Show the arp timer interval. */
-static ssize_t bonding_show_arp_interval(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.arp_interval);
-}
-static DEVICE_ATTR(arp_interval, 0644,
-		   bonding_show_arp_interval, bonding_sysfs_store_option);
-
-/* Show the arp targets. */
-static ssize_t bonding_show_arp_targets(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	int i, res = 0;
-
-	for (i = 0; i < BOND_MAX_ARP_TARGETS; i++) {
-		if (bond->params.arp_targets[i])
-			res += sprintf(buf + res, "%pI4 ",
-				       &bond->params.arp_targets[i]);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	return res;
-}
-static DEVICE_ATTR(arp_ip_target, 0644,
-		   bonding_show_arp_targets, bonding_sysfs_store_option);
-
-/* Show the up and down delays. */
-static ssize_t bonding_show_downdelay(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.downdelay * bond->params.miimon);
-}
-static DEVICE_ATTR(downdelay, 0644,
-		   bonding_show_downdelay, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_updelay(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.updelay * bond->params.miimon);
-
-}
-static DEVICE_ATTR(updelay, 0644,
-		   bonding_show_updelay, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_peer_notif_delay(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n",
-		       bond->params.peer_notif_delay * bond->params.miimon);
-}
-static DEVICE_ATTR(peer_notif_delay, 0644,
-		   bonding_show_peer_notif_delay, bonding_sysfs_store_option);
-
-/* Show the LACP interval. */
-static ssize_t bonding_show_lacp(struct device *d,
-				 struct device_attribute *attr,
-				 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_LACP_RATE, bond->params.lacp_fast);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.lacp_fast);
-}
-static DEVICE_ATTR(lacp_rate, 0644,
-		   bonding_show_lacp, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_min_links(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%u\n", bond->params.min_links);
-}
-static DEVICE_ATTR(min_links, 0644,
-		   bonding_show_min_links, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_select(struct device *d,
-				      struct device_attribute *attr,
-				      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_AD_SELECT, bond->params.ad_select);
-
-	return sprintf(buf, "%s %d\n", val->string, bond->params.ad_select);
-}
-static DEVICE_ATTR(ad_select, 0644,
-		   bonding_show_ad_select, bonding_sysfs_store_option);
-
-/* Show the number of peer notifications to send after a failover event. */
-static ssize_t bonding_show_num_peer_notif(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	return sprintf(buf, "%d\n", bond->params.num_peer_notif);
-}
-static DEVICE_ATTR(num_grat_arp, 0644,
-		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
-static DEVICE_ATTR(num_unsol_na, 0644,
-		   bonding_show_num_peer_notif, bonding_sysfs_store_option);
-
-/* Show the MII monitor interval. */
-static ssize_t bonding_show_miimon(struct device *d,
-				   struct device_attribute *attr,
-				   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.miimon);
-}
-static DEVICE_ATTR(miimon, 0644,
-		   bonding_show_miimon, bonding_sysfs_store_option);
-
-/* Show the primary slave. */
-static ssize_t bonding_show_primary(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct slave *primary;
-	int count = 0;
-
-	rcu_read_lock();
-	primary = rcu_dereference(bond->primary_slave);
-	if (primary)
-		count = sprintf(buf, "%s\n", primary->dev->name);
-	rcu_read_unlock();
-
-	return count;
-}
-static DEVICE_ATTR(primary, 0644,
-		   bonding_show_primary, bonding_sysfs_store_option);
-
-/* Show the primary_reselect flag. */
-static ssize_t bonding_show_primary_reselect(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	const struct bond_opt_value *val;
-
-	val = bond_opt_get_val(BOND_OPT_PRIMARY_RESELECT,
-			       bond->params.primary_reselect);
-
-	return sprintf(buf, "%s %d\n",
-		       val->string, bond->params.primary_reselect);
-}
-static DEVICE_ATTR(primary_reselect, 0644,
-		   bonding_show_primary_reselect, bonding_sysfs_store_option);
-
-/* Show the use_carrier flag. */
-static ssize_t bonding_show_carrier(struct device *d,
-				    struct device_attribute *attr,
-				    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.use_carrier);
-}
-static DEVICE_ATTR(use_carrier, 0644,
-		   bonding_show_carrier, bonding_sysfs_store_option);
-
-
-/* Show currently active_slave. */
-static ssize_t bonding_show_active_slave(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct net_device *slave_dev;
-	int count = 0;
-
-	rcu_read_lock();
-	slave_dev = bond_option_active_slave_get_rcu(bond);
-	if (slave_dev)
-		count = sprintf(buf, "%s\n", slave_dev->name);
-	rcu_read_unlock();
-
-	return count;
-}
-static DEVICE_ATTR(active_slave, 0644,
-		   bonding_show_active_slave, bonding_sysfs_store_option);
-
-/* Show link status of the bond interface. */
-static ssize_t bonding_show_mii_status(struct device *d,
-				       struct device_attribute *attr,
-				       char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	bool active = netif_carrier_ok(bond->dev);
-
-	return sprintf(buf, "%s\n", active ? "up" : "down");
-}
-static DEVICE_ATTR(mii_status, 0444, bonding_show_mii_status, NULL);
-
-/* Show current 802.3ad aggregator ID. */
-static ssize_t bonding_show_ad_aggregator(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.aggregator_id);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_aggregator, 0444, bonding_show_ad_aggregator, NULL);
-
-
-/* Show number of active 802.3ad ports. */
-static ssize_t bonding_show_ad_num_ports(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.ports);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_num_ports, 0444, bonding_show_ad_num_ports, NULL);
-
-
-/* Show current 802.3ad actor key. */
-static ssize_t bonding_show_ad_actor_key(struct device *d,
-					 struct device_attribute *attr,
-					 char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.actor_key);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_actor_key, 0444, bonding_show_ad_actor_key, NULL);
-
-
-/* Show current 802.3ad partner key. */
-static ssize_t bonding_show_ad_partner_key(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		count = sprintf(buf, "%d\n",
-				bond_3ad_get_active_agg_info(bond, &ad_info)
-				?  0 : ad_info.partner_key);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_partner_key, 0444, bonding_show_ad_partner_key, NULL);
-
-
-/* Show current 802.3ad partner mac. */
-static ssize_t bonding_show_ad_partner_mac(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	int count = 0;
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN)) {
-		struct ad_info ad_info;
-		if (!bond_3ad_get_active_agg_info(bond, &ad_info))
-			count = sprintf(buf, "%pM\n", ad_info.partner_system);
-	}
-
-	return count;
-}
-static DEVICE_ATTR(ad_partner_mac, 0444, bonding_show_ad_partner_mac, NULL);
-
-/* Show the queue_ids of the slaves in the current bond. */
-static ssize_t bonding_show_queue_id(struct device *d,
-				     struct device_attribute *attr,
-				     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	struct list_head *iter;
-	struct slave *slave;
-	int res = 0;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	bond_for_each_slave(bond, slave, iter) {
-		if (res > (PAGE_SIZE - IFNAMSIZ - 6)) {
-			/* not enough space for another interface_name:queue_id pair */
-			if ((PAGE_SIZE - res) > 10)
-				res = PAGE_SIZE - 10;
-			res += sprintf(buf + res, "++more++ ");
-			break;
-		}
-		res += sprintf(buf + res, "%s:%d ",
-			       slave->dev->name, slave->queue_id);
-	}
-	if (res)
-		buf[res-1] = '\n'; /* eat the leftover space */
-
-	rtnl_unlock();
-
-	return res;
-}
-static DEVICE_ATTR(queue_id, 0644, bonding_show_queue_id,
-		   bonding_sysfs_store_option);
-
-
-/* Show the all_slaves_active flag. */
-static ssize_t bonding_show_slaves_active(struct device *d,
-					  struct device_attribute *attr,
-					  char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.all_slaves_active);
-}
-static DEVICE_ATTR(all_slaves_active, 0644,
-		   bonding_show_slaves_active, bonding_sysfs_store_option);
-
-/* Show the number of IGMP membership reports to send on link failure */
-static ssize_t bonding_show_resend_igmp(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.resend_igmp);
-}
-static DEVICE_ATTR(resend_igmp, 0644,
-		   bonding_show_resend_igmp, bonding_sysfs_store_option);
-
-
-static ssize_t bonding_show_lp_interval(struct device *d,
-					struct device_attribute *attr,
-					char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	return sprintf(buf, "%d\n", bond->params.lp_interval);
-}
-static DEVICE_ATTR(lp_interval, 0644,
-		   bonding_show_lp_interval, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_tlb_dynamic_lb(struct device *d,
-					   struct device_attribute *attr,
-					   char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	return sprintf(buf, "%d\n", bond->params.tlb_dynamic_lb);
-}
-static DEVICE_ATTR(tlb_dynamic_lb, 0644,
-		   bonding_show_tlb_dynamic_lb, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_packets_per_slave(struct device *d,
-					      struct device_attribute *attr,
-					      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-	unsigned int packets_per_slave = bond->params.packets_per_slave;
-
-	return sprintf(buf, "%u\n", packets_per_slave);
-}
-static DEVICE_ATTR(packets_per_slave, 0644,
-		   bonding_show_packets_per_slave, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_actor_sys_prio(struct device *d,
-					      struct device_attribute *attr,
-					      char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%hu\n", bond->params.ad_actor_sys_prio);
-
-	return 0;
-}
-static DEVICE_ATTR(ad_actor_sys_prio, 0644,
-		   bonding_show_ad_actor_sys_prio, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_actor_system(struct device *d,
-					    struct device_attribute *attr,
-					    char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%pM\n", bond->params.ad_actor_system);
-
-	return 0;
-}
-
-static DEVICE_ATTR(ad_actor_system, 0644,
-		   bonding_show_ad_actor_system, bonding_sysfs_store_option);
-
-static ssize_t bonding_show_ad_user_port_key(struct device *d,
-					     struct device_attribute *attr,
-					     char *buf)
-{
-	struct bonding *bond = to_bond(d);
-
-	if (BOND_MODE(bond) == BOND_MODE_8023AD && capable(CAP_NET_ADMIN))
-		return sprintf(buf, "%hu\n", bond->params.ad_user_port_key);
-
-	return 0;
-}
-static DEVICE_ATTR(ad_user_port_key, 0644,
-		   bonding_show_ad_user_port_key, bonding_sysfs_store_option);
-
-static struct attribute *per_bond_attrs[] = {
-	&dev_attr_slaves.attr,
-	&dev_attr_mode.attr,
-	&dev_attr_fail_over_mac.attr,
-	&dev_attr_arp_validate.attr,
-	&dev_attr_arp_all_targets.attr,
-	&dev_attr_arp_interval.attr,
-	&dev_attr_arp_ip_target.attr,
-	&dev_attr_downdelay.attr,
-	&dev_attr_updelay.attr,
-	&dev_attr_peer_notif_delay.attr,
-	&dev_attr_lacp_rate.attr,
-	&dev_attr_ad_select.attr,
-	&dev_attr_xmit_hash_policy.attr,
-	&dev_attr_num_grat_arp.attr,
-	&dev_attr_num_unsol_na.attr,
-	&dev_attr_miimon.attr,
-	&dev_attr_primary.attr,
-	&dev_attr_primary_reselect.attr,
-	&dev_attr_use_carrier.attr,
-	&dev_attr_active_slave.attr,
-	&dev_attr_mii_status.attr,
-	&dev_attr_ad_aggregator.attr,
-	&dev_attr_ad_num_ports.attr,
-	&dev_attr_ad_actor_key.attr,
-	&dev_attr_ad_partner_key.attr,
-	&dev_attr_ad_partner_mac.attr,
-	&dev_attr_queue_id.attr,
-	&dev_attr_all_slaves_active.attr,
-	&dev_attr_resend_igmp.attr,
-	&dev_attr_min_links.attr,
-	&dev_attr_lp_interval.attr,
-	&dev_attr_packets_per_slave.attr,
-	&dev_attr_tlb_dynamic_lb.attr,
-	&dev_attr_ad_actor_sys_prio.attr,
-	&dev_attr_ad_actor_system.attr,
-	&dev_attr_ad_user_port_key.attr,
-	NULL,
-};
-
-static const struct attribute_group bonding_group = {
-	.name = "bonding",
-	.attrs = per_bond_attrs,
-};
-
-/* Initialize sysfs.  This sets up the bonding_masters file in
- * /sys/class/net.
- */
-int bond_create_sysfs(struct bond_net *bn)
-{
-	int ret;
-
-	bn->class_attr_bonding_masters = class_attr_bonding_masters;
-	sysfs_attr_init(&bn->class_attr_bonding_masters.attr);
-
-	ret = netdev_class_create_file_ns(&bn->class_attr_bonding_masters,
-					  bn->net);
-	/* Permit multiple loads of the module by ignoring failures to
-	 * create the bonding_masters sysfs file.  Bonding devices
-	 * created by second or subsequent loads of the module will
-	 * not be listed in, or controllable by, bonding_masters, but
-	 * will have the usual "bonding" sysfs directory.
-	 *
-	 * This is done to preserve backwards compatibility for
-	 * initscripts/sysconfig, which load bonding multiple times to
-	 * configure multiple bonding devices.
-	 */
-	if (ret == -EEXIST) {
-		/* Is someone being kinky and naming a device bonding_master? */
-		if (__dev_get_by_name(bn->net,
-				      class_attr_bonding_masters.attr.name))
-			pr_err("network device named %s already exists in sysfs\n",
-			       class_attr_bonding_masters.attr.name);
-		ret = 0;
-	}
-
-	return ret;
-
-}
-
-/* Remove /sys/class/net/bonding_masters. */
-void bond_destroy_sysfs(struct bond_net *bn)
-{
-	netdev_class_remove_file_ns(&bn->class_attr_bonding_masters, bn->net);
-}
-
-/* Initialize sysfs for each bond.  This sets up and registers
- * the 'bondctl' directory for each individual bond under /sys/class/net.
- */
-void bond_prepare_sysfs_group(struct bonding *bond)
-{
-	bond->dev->sysfs_groups[0] = &bonding_group;
-}
-
diff -r 30 src/network/bonding/BONDING_KDIRS/5.6.0/bond_sysfs_slave.c
--- a/src/network/bonding/BONDING_KDIRS/5.6.0/bond_sysfs_slave.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,174 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0-or-later
-/*	Sysfs attributes of bond slaves
- *
- *      Copyright (c) 2014 Scott Feldman <sfeldma@cumulusnetworks.com>
- */
-
-#include <linux/capability.h>
-#include <linux/kernel.h>
-#include <linux/netdevice.h>
-
-#include <net/bonding.h>
-
-struct slave_attribute {
-	struct attribute attr;
-	ssize_t (*show)(struct slave *, char *);
-};
-
-#define SLAVE_ATTR(_name, _mode, _show)				\
-const struct slave_attribute slave_attr_##_name = {		\
-	.attr = {.name = __stringify(_name),			\
-		 .mode = _mode },				\
-	.show	= _show,					\
-};
-#define SLAVE_ATTR_RO(_name)					\
-	SLAVE_ATTR(_name, 0444, _name##_show)
-
-static ssize_t state_show(struct slave *slave, char *buf)
-{
-	switch (bond_slave_state(slave)) {
-	case BOND_STATE_ACTIVE:
-		return sprintf(buf, "active\n");
-	case BOND_STATE_BACKUP:
-		return sprintf(buf, "backup\n");
-	default:
-		return sprintf(buf, "UNKNOWN\n");
-	}
-}
-static SLAVE_ATTR_RO(state);
-
-static ssize_t mii_status_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%s\n", bond_slave_link_status(slave->link));
-}
-static SLAVE_ATTR_RO(mii_status);
-
-static ssize_t link_failure_count_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%d\n", slave->link_failure_count);
-}
-static SLAVE_ATTR_RO(link_failure_count);
-
-static ssize_t perm_hwaddr_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%*phC\n",
-		       slave->dev->addr_len,
-		       slave->perm_hwaddr);
-}
-static SLAVE_ATTR_RO(perm_hwaddr);
-
-static ssize_t queue_id_show(struct slave *slave, char *buf)
-{
-	return sprintf(buf, "%d\n", slave->queue_id);
-}
-static SLAVE_ATTR_RO(queue_id);
-
-static ssize_t ad_aggregator_id_show(struct slave *slave, char *buf)
-{
-	const struct aggregator *agg;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		agg = SLAVE_AD_INFO(slave)->port.aggregator;
-		if (agg)
-			return sprintf(buf, "%d\n",
-				       agg->aggregator_identifier);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_aggregator_id);
-
-static ssize_t ad_actor_oper_port_state_show(struct slave *slave, char *buf)
-{
-	const struct port *ad_port;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		if (ad_port->aggregator)
-			return sprintf(buf, "%u\n",
-				       ad_port->actor_oper_port_state);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_actor_oper_port_state);
-
-static ssize_t ad_partner_oper_port_state_show(struct slave *slave, char *buf)
-{
-	const struct port *ad_port;
-
-	if (BOND_MODE(slave->bond) == BOND_MODE_8023AD) {
-		ad_port = &SLAVE_AD_INFO(slave)->port;
-		if (ad_port->aggregator)
-			return sprintf(buf, "%u\n",
-				       ad_port->partner_oper.port_state);
-	}
-
-	return sprintf(buf, "N/A\n");
-}
-static SLAVE_ATTR_RO(ad_partner_oper_port_state);
-
-static const struct slave_attribute *slave_attrs[] = {
-	&slave_attr_state,
-	&slave_attr_mii_status,
-	&slave_attr_link_failure_count,
-	&slave_attr_perm_hwaddr,
-	&slave_attr_queue_id,
-	&slave_attr_ad_aggregator_id,
-	&slave_attr_ad_actor_oper_port_state,
-	&slave_attr_ad_partner_oper_port_state,
-	NULL
-};
-
-#define to_slave_attr(_at) container_of(_at, struct slave_attribute, attr)
-#define to_slave(obj)	container_of(obj, struct slave, kobj)
-
-static ssize_t slave_show(struct kobject *kobj,
-			  struct attribute *attr, char *buf)
-{
-	struct slave_attribute *slave_attr = to_slave_attr(attr);
-	struct slave *slave = to_slave(kobj);
-
-	return slave_attr->show(slave, buf);
-}
-
-static const struct sysfs_ops slave_sysfs_ops = {
-	.show = slave_show,
-};
-
-static struct kobj_type slave_ktype = {
-#ifdef CONFIG_SYSFS
-	.sysfs_ops = &slave_sysfs_ops,
-#endif
-};
-
-int bond_sysfs_slave_add(struct slave *slave)
-{
-	const struct slave_attribute **a;
-	int err;
-
-	err = kobject_init_and_add(&slave->kobj, &slave_ktype,
-				   &(slave->dev->dev.kobj), "bonding_slave");
-	if (err)
-		return err;
-
-	for (a = slave_attrs; *a; ++a) {
-		err = sysfs_create_file(&slave->kobj, &((*a)->attr));
-		if (err) {
-			kobject_put(&slave->kobj);
-			return err;
-		}
-	}
-
-	return 0;
-}
-
-void bond_sysfs_slave_del(struct slave *slave)
-{
-	const struct slave_attribute **a;
-
-	for (a = slave_attrs; *a; ++a)
-		sysfs_remove_file(&slave->kobj, &((*a)->attr));
-
-	kobject_put(&slave->kobj);
-}
diff -r 30 src/network/bonding/BONDING_KDIRS/5.6.0/bonding_priv.h
--- a/src/network/bonding/BONDING_KDIRS/5.6.0/bonding_priv.h	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,25 +0,0 @@
-/*
- * Bond several ethernet interfaces into a Cisco, running 'Etherchannel'.
- *
- * Portions are (c) Copyright 1995 Simon "Guru Aleph-Null" Janes
- * NCM: Network and Communications Management, Inc.
- *
- * BUT, I'm the one who modified it for ethernet, so:
- * (c) Copyright 1999, Thomas Davis, tadavis@lbl.gov
- *
- *	This software may be used and distributed according to the terms
- *	of the GNU Public License, incorporated herein by reference.
- *
- */
-
-#ifndef _BONDING_PRIV_H
-#define _BONDING_PRIV_H
-
-#define DRV_VERSION	"3.7.1-chelsio"
-#define DRV_RELDATE	"April 27, 2011"
-#define DRV_NAME	"bonding"
-#define DRV_DESCRIPTION	"Ethernet Channel Bonding Driver with Offload"
-
-#define bond_version DRV_DESCRIPTION ": v" DRV_VERSION " (" DRV_RELDATE ")\n"
-
-#endif
diff -r 30 src/network/bonding/Makefile
--- a/src/network/bonding/Makefile	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/bonding/Makefile	Tue May 18 15:02:47 2021 +0530
@@ -89,7 +89,7 @@
 	@[ -L BONDING_KDIR ] && /bin/rm -f BONDING_KDIR; true
 	@BONDING_KDIR=""; \
 	for ver in $(kversions); do \
-	    k_sublevel=`echo $$ver | cut -d '.' -f3 | tr -dc '0-9'`; \
+	    k_sublevel=`echo $$ver | cut -d '.' -f3`; \
 	    if [[ -z $$k_sublevel ]]; then \
 		k_sublevel=0; \
 	    fi; \
diff -r 30 src/network/chcr/Makefile
--- a/src/network/chcr/Makefile	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/chcr/Makefile	Tue May 18 15:02:47 2021 +0530
@@ -52,7 +52,6 @@
 build:
 	@$(MAKE) $(symverfile) -C $(KOBJ) KBUILD_EXTMOD=$(shell pwd) \
 		KBUILD_EXTRA_SYMBOLS="$(EXTRA_SYMFILE)" modules
-
 .PHONY: install
 install:
 	@-if [ -e "$(old_install_path)/$(driver)" ]; then \
diff -r 30 src/network/chcr/chcr_algo.c
--- a/src/network/chcr/chcr_algo.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/chcr/chcr_algo.c	Tue May 18 15:02:47 2021 +0530
@@ -44,6 +44,7 @@
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/crypto.h>
+#include <linux/cryptohash.h>
 #include <linux/skbuff.h>
 #include <linux/rtnetlink.h>
 #include <linux/highmem.h>
@@ -90,7 +91,7 @@
 	0x1B000000, 0x36000000, 0x6C000000
 };
 
-static int chcr_handle_cipher_resp(struct skcipher_request *req,
+static int chcr_handle_cipher_resp(struct ablkcipher_request *req,
 				   unsigned char *input, int err);
 
 static inline  struct chcr_aead_ctx *AEAD_CTX(struct chcr_context *ctx)
@@ -286,10 +287,10 @@
 #ifdef CIPHER_KERNEL_TEST // remove this flag after kernel 4.10.3
 	case CRYPTO_ALG_TYPE_BLKCIPHER:
 #else
-	case CRYPTO_ALG_TYPE_SKCIPHER:
+	case CRYPTO_ALG_TYPE_ABLKCIPHER:
 #endif
-		chcr_handle_cipher_resp(skcipher_request_cast(req),
-					input, err);
+		chcr_handle_cipher_resp(ablkcipher_request_cast(req),
+					       input, err);
 		break;
 	case CRYPTO_ALG_TYPE_AHASH:
 		chcr_handle_ahash_resp(ahash_request_cast(req), input, err);
@@ -636,11 +637,11 @@
 	}
 }
 
-static inline int get_cryptoalg_subtype(struct crypto_skcipher *tfm)
+static inline int get_cryptoalg_subtype(struct crypto_tfm *tfm)
 {
-	struct skcipher_alg *alg = crypto_skcipher_alg(tfm);
+	struct crypto_alg *alg = tfm->__crt_alg;
 	struct chcr_alg_template *chcr_crypto_alg =
-		container_of(alg, struct chcr_alg_template, alg.skcipher);
+		container_of(alg, struct chcr_alg_template, alg.crypto);
 
 	return chcr_crypto_alg->type & CRYPTO_ALG_SUB_TYPE_MASK;
 }
@@ -740,7 +741,7 @@
 	return min(srclen, dstlen);
 }
 
-static int chcr_cipher_fallback(struct crypto_sync_skcipher *cipher,
+static int chcr_cipher_fallback(struct crypto_skcipher *cipher,
 				u32 flags,
 				struct scatterlist *src,
 				struct scatterlist *dst,
@@ -750,8 +751,8 @@
 {
 	int err;
 
-	SYNC_SKCIPHER_REQUEST_ON_STACK(subreq, cipher);
-	skcipher_request_set_sync_tfm(subreq, cipher);
+	SKCIPHER_REQUEST_ON_STACK(subreq, cipher);
+	skcipher_request_set_tfm(subreq, cipher);
 	skcipher_request_set_callback(subreq, flags, NULL, NULL);
 	skcipher_request_set_crypt(subreq, src, dst,
 				   nbytes, iv);
@@ -780,12 +781,12 @@
 		*rxqidx = reqctx->rxqidx;
 		break;
 	}
-	case CRYPTO_ALG_TYPE_SKCIPHER:
+	case CRYPTO_ALG_TYPE_ABLKCIPHER:
 	{
-		struct skcipher_request *ablk_req =
-			container_of(req, struct skcipher_request, base);
-		struct chcr_skcipher_req_ctx *reqctx =
-			skcipher_request_ctx(ablk_req);
+		struct ablkcipher_request *ablk_req =
+			container_of(req, struct ablkcipher_request, base);
+		struct chcr_blkcipher_req_ctx *reqctx =
+			ablkcipher_request_ctx(ablk_req);
 		*txqidx = reqctx->txqidx;
 		*rxqidx = reqctx->rxqidx;
 		break;
@@ -867,15 +868,15 @@
  */
 static struct sk_buff *create_cipher_wr(struct cipher_wr_param *wrparam)
 {
-	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(wrparam->req);
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(wrparam->req);
 	struct chcr_context *ctx = c_ctx(tfm);
 	struct ablk_ctx *ablkctx = ABLK_CTX(ctx);
 	struct sk_buff *skb = NULL;
 	struct chcr_wr *chcr_req;
 	struct cpl_rx_phys_dsgl *phys_cpl;
 	struct ulptx_sgl *ulptx;
-	struct chcr_skcipher_req_ctx *reqctx =
-		skcipher_request_ctx(wrparam->req);
+	struct chcr_blkcipher_req_ctx *reqctx =
+		ablkcipher_request_ctx(wrparam->req);
 	unsigned int temp = 0, transhdr_len, dst_size;
 	int error;
 	int nents;
@@ -919,9 +920,9 @@
 
 	chcr_req->key_ctx.ctx_hdr = ablkctx->key_ctx_hdr;
 	if ((reqctx->op == CHCR_DECRYPT_OP) &&
-	    (!(get_cryptoalg_subtype(tfm) ==
+	    (!(get_cryptoalg_subtype(crypto_ablkcipher_tfm(tfm)) ==
 	       CRYPTO_ALG_SUB_TYPE_CTR)) &&
-	    (!(get_cryptoalg_subtype(tfm) ==
+	    (!(get_cryptoalg_subtype(crypto_ablkcipher_tfm(tfm)) ==
 	       CRYPTO_ALG_SUB_TYPE_CTR_RFC3686))) {
 		generate_copy_rrkey(ablkctx, &chcr_req->key_ctx);
 	} else {
@@ -954,7 +955,7 @@
 	if (reqctx->op && (ablkctx->ciph_mode ==
 			   CHCR_SCMD_CIPHER_MODE_AES_CBC))
 		sg_pcopy_to_buffer(wrparam->req->src,
-			sg_nents(wrparam->req->src), wrparam->req->iv, 16,
+			sg_nents(wrparam->req->src), wrparam->req->info, 16,
 			reqctx->processed + wrparam->bytes - AES_BLOCK_SIZE);
 
 	return skb;
@@ -977,21 +978,26 @@
 
 	return ck_size;
 }
-
-static int chcr_cipher_fallback_setkey(struct crypto_skcipher *cipher,
+static int chcr_cipher_fallback_setkey(struct crypto_ablkcipher *cipher,
 				       const u8 *key,
 				       unsigned int keylen)
 {
+	struct crypto_tfm *tfm = crypto_ablkcipher_tfm(cipher);
 	struct ablk_ctx *ablkctx = ABLK_CTX(c_ctx(cipher));
-
-	crypto_sync_skcipher_clear_flags(ablkctx->sw_cipher,
-				CRYPTO_TFM_REQ_MASK);
-	crypto_sync_skcipher_set_flags(ablkctx->sw_cipher,
-				cipher->base.crt_flags & CRYPTO_TFM_REQ_MASK);
-	return crypto_sync_skcipher_setkey(ablkctx->sw_cipher, key, keylen);
+	int err = 0;
+
+	crypto_skcipher_clear_flags(ablkctx->sw_cipher, CRYPTO_TFM_REQ_MASK);
+	crypto_skcipher_set_flags(ablkctx->sw_cipher, cipher->base.crt_flags &
+				  CRYPTO_TFM_REQ_MASK);
+	err = crypto_skcipher_setkey(ablkctx->sw_cipher, key, keylen);
+	tfm->crt_flags &= ~CRYPTO_TFM_RES_MASK;
+	tfm->crt_flags |=
+		crypto_skcipher_get_flags(ablkctx->sw_cipher) &
+		CRYPTO_TFM_RES_MASK;
+	return err;
 }
 
-static int chcr_aes_cbc_setkey(struct crypto_skcipher *cipher,
+static int chcr_aes_cbc_setkey(struct crypto_ablkcipher *cipher,
 			       const u8 *key,
 			       unsigned int keylen)
 {
@@ -1018,14 +1024,15 @@
 
 	return 0;
 badkey_err:
+	crypto_ablkcipher_set_flags(cipher, CRYPTO_TFM_RES_BAD_KEY_LEN);
 	ablkctx->enckey_len = 0;
 
 	return err;
 }
 
-static int chcr_aes_ctr_setkey(struct crypto_skcipher *cipher,
-			       const u8 *key,
-			       unsigned int keylen)
+static int chcr_aes_ctr_setkey(struct crypto_ablkcipher *cipher,
+				   const u8 *key,
+				   unsigned int keylen)
 {
 	struct ablk_ctx *ablkctx = ABLK_CTX(c_ctx(cipher));
 	unsigned int ck_size, context_size;
@@ -1048,12 +1055,13 @@
 
 	return 0;
 badkey_err:
+	crypto_ablkcipher_set_flags(cipher, CRYPTO_TFM_RES_BAD_KEY_LEN);
 	ablkctx->enckey_len = 0;
 
 	return err;
 }
 
-static int chcr_aes_rfc3686_setkey(struct crypto_skcipher *cipher,
+static int chcr_aes_rfc3686_setkey(struct crypto_ablkcipher *cipher,
 				   const u8 *key,
 				   unsigned int keylen)
 {
@@ -1084,6 +1092,7 @@
 
 	return 0;
 badkey_err:
+	crypto_ablkcipher_set_flags(cipher, CRYPTO_TFM_RES_BAD_KEY_LEN);
 	ablkctx->enckey_len = 0;
 
 	return err;
@@ -1119,12 +1128,12 @@
 	return bytes;
 }
 
-static int chcr_update_tweak(struct skcipher_request *req, u8 *iv,
+static int chcr_update_tweak(struct ablkcipher_request *req, u8 *iv,
 			     u32 isfinal)
 {
-	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
 	struct ablk_ctx *ablkctx = ABLK_CTX(c_ctx(tfm));
-	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
+	struct chcr_blkcipher_req_ctx *reqctx = ablkcipher_request_ctx(req);
 	struct crypto_cipher *cipher;
 	int ret, i;
 	u8 *key;
@@ -1160,17 +1169,17 @@
 	return ret;
 }
 
-static int chcr_update_cipher_iv(struct skcipher_request *req,
-				 struct cpl_fw6_pld *fw6_pld, u8 *iv)
+static int chcr_update_cipher_iv(struct ablkcipher_request *req,
+				   struct cpl_fw6_pld *fw6_pld, u8 *iv)
 {
-	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
-	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
-	int subtype = get_cryptoalg_subtype(tfm);
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
+	struct chcr_blkcipher_req_ctx *reqctx = ablkcipher_request_ctx(req);
+	int subtype = get_cryptoalg_subtype(crypto_ablkcipher_tfm(tfm));
 	int ret = 0;
 
 	if (subtype == CRYPTO_ALG_SUB_TYPE_CTR)
-		ctr_add_iv(iv, req->iv, (reqctx->processed /
-			  AES_BLOCK_SIZE));
+		ctr_add_iv(iv, req->info, (reqctx->processed /
+			   AES_BLOCK_SIZE));
 	else if (subtype == CRYPTO_ALG_SUB_TYPE_CTR_RFC3686)
 		*(__be32 *)(reqctx->iv + CTR_RFC3686_NONCE_SIZE +
 			CTR_RFC3686_IV_SIZE) = cpu_to_be32((reqctx->processed /
@@ -1180,7 +1189,7 @@
 	else if (subtype == CRYPTO_ALG_SUB_TYPE_CBC) {
 		if (reqctx->op)
 			/*Updated before sending last WR*/
-			memcpy(iv, req->iv, AES_BLOCK_SIZE);
+			memcpy(iv, req->info, AES_BLOCK_SIZE);
 		else
 			memcpy(iv, &fw6_pld->data[2], AES_BLOCK_SIZE);
 	}
@@ -1194,17 +1203,17 @@
  * for subsequent update requests
  */
 
-static int chcr_final_cipher_iv(struct skcipher_request *req,
-				struct cpl_fw6_pld *fw6_pld, u8 *iv)
+static int chcr_final_cipher_iv(struct ablkcipher_request *req,
+				   struct cpl_fw6_pld *fw6_pld, u8 *iv)
 {
-	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
-	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
-	int subtype = get_cryptoalg_subtype(tfm);
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
+	struct chcr_blkcipher_req_ctx *reqctx = ablkcipher_request_ctx(req);
+	int subtype = get_cryptoalg_subtype(crypto_ablkcipher_tfm(tfm));
 	int ret = 0;
 
 	if (subtype == CRYPTO_ALG_SUB_TYPE_CTR)
-		ctr_add_iv(iv, req->iv, DIV_ROUND_UP(reqctx->processed,
-						     AES_BLOCK_SIZE));
+		ctr_add_iv(iv, req->info, DIV_ROUND_UP(reqctx->processed,
+			   AES_BLOCK_SIZE));
 	else if (subtype == CRYPTO_ALG_SUB_TYPE_XTS) {
 		if(!reqctx->partial_req)
 			memcpy(iv, reqctx->iv, AES_BLOCK_SIZE);
@@ -1222,26 +1231,26 @@
 }
 
 
-static int chcr_handle_cipher_resp(struct skcipher_request *req,
+static int chcr_handle_cipher_resp(struct ablkcipher_request *req,
 				   unsigned char *input, int err)
 {
-	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
         struct chcr_context *ctx = c_ctx(tfm);
 	struct uld_ctx *u_ctx = ULD_CTX(c_ctx(tfm));
 	struct ablk_ctx *ablkctx = ABLK_CTX(c_ctx(tfm));
 	struct sk_buff *skb;
 	struct cpl_fw6_pld *fw6_pld = (struct cpl_fw6_pld *)input;
-	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
+	struct chcr_blkcipher_req_ctx *reqctx = ablkcipher_request_ctx(req);
 	struct  cipher_wr_param wrparam;
 	struct adapter *adap = padap(ctx->dev);
 	int bytes;
 
 	if (err)
 		goto unmap;
-	if (req->cryptlen == reqctx->processed) {
+	if (req->nbytes == reqctx->processed) {
 		chcr_cipher_dma_unmap(&ULD_CTX(c_ctx(tfm))->lldi.pdev->dev,
 				      req);
-		err = chcr_final_cipher_iv(req, fw6_pld, req->iv);
+		err = chcr_final_cipher_iv(req, fw6_pld, req->info);
 		goto complete;
 	}
 
@@ -1249,13 +1258,13 @@
 		bytes = chcr_sg_ent_in_wr(reqctx->srcsg, reqctx->dstsg, 0,
 					  CIP_SPACE_LEFT(ablkctx->enckey_len),
 					  reqctx->src_ofst, reqctx->dst_ofst);
-		if ((bytes + reqctx->processed) >= req->cryptlen)
-			bytes  = req->cryptlen - reqctx->processed;
+		if ((bytes + reqctx->processed) >= req->nbytes)
+			bytes  = req->nbytes - reqctx->processed;
 		else
 			bytes = rounddown(bytes, 16);
 	} else {
 		/*CTR mode counter overfloa*/
-		bytes  = req->cryptlen - reqctx->processed;
+		bytes  = req->nbytes - reqctx->processed;
 	}
 	err = chcr_update_cipher_iv(req, fw6_pld, reqctx->iv);
 	if (err)
@@ -1264,19 +1273,19 @@
 	if (unlikely(bytes == 0)) {
 		chcr_cipher_dma_unmap(&ULD_CTX(c_ctx(tfm))->lldi.pdev->dev,
 				      req);
-		memcpy(req->iv, reqctx->init_iv, IV);
+		memcpy(req->info, reqctx->init_iv, IV);
 		atomic_inc(&adap->chcr_stats.fallback);
 		err = chcr_cipher_fallback(ablkctx->sw_cipher,
 				     req->base.flags,
 				     req->src,
 				     req->dst,
-				     req->cryptlen,
-				     req->iv,
+				     req->nbytes,
+				     req->info,
 				     reqctx->op);
 		goto complete;
 	}
 
-	if (get_cryptoalg_subtype(tfm) ==
+	if (get_cryptoalg_subtype(crypto_ablkcipher_tfm(tfm)) ==
 	    CRYPTO_ALG_SUB_TYPE_CTR)
 		bytes = adjust_ctr_overflow(reqctx->iv, bytes);
 	wrparam.qid = u_ctx->lldi.rxq_ids[reqctx->rxqidx];
@@ -1293,7 +1302,7 @@
 	chcr_send_wr(skb);
 	reqctx->last_req_len = bytes;
 	reqctx->processed += bytes;
-	if (get_cryptoalg_subtype(tfm) ==
+	if (get_cryptoalg_subtype(crypto_ablkcipher_tfm(tfm)) ==
                 CRYPTO_ALG_SUB_TYPE_CBC && req->base.flags ==
                   CRYPTO_TFM_REQ_MAY_SLEEP ) {
                 complete(&ctx->cbc_aes_aio_done);
@@ -1302,7 +1311,7 @@
 unmap:
 	chcr_cipher_dma_unmap(&ULD_CTX(c_ctx(tfm))->lldi.pdev->dev, req);
 complete:
-	if (get_cryptoalg_subtype(tfm) ==
+	if (get_cryptoalg_subtype(crypto_ablkcipher_tfm(tfm)) ==
                 CRYPTO_ALG_SUB_TYPE_CBC && req->base.flags ==
                   CRYPTO_TFM_REQ_MAY_SLEEP ) {
                 complete(&ctx->cbc_aes_aio_done);
@@ -1312,14 +1321,14 @@
 	return err;
 }
 
-static int process_cipher(struct skcipher_request *req,
-			  unsigned short qid,
-			  struct sk_buff **skb,
-			  unsigned short op_type)
+static int process_cipher(struct ablkcipher_request *req,
+				  unsigned short qid,
+				  struct sk_buff **skb,
+				  unsigned short op_type)
 {
-	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
-	unsigned int ivsize = crypto_skcipher_ivsize(tfm);
-	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
+	unsigned int ivsize = crypto_ablkcipher_ivsize(tfm);
+	struct chcr_blkcipher_req_ctx *reqctx = ablkcipher_request_ctx(req);
 	struct ablk_ctx *ablkctx = ABLK_CTX(c_ctx(tfm));
 	struct	cipher_wr_param wrparam;
 	struct adapter *adap = padap(c_ctx(tfm)->dev);
@@ -1328,24 +1337,24 @@
 
 	reqctx->processed = 0;
 	reqctx->partial_req = 0;
-	if (!req->iv)
+	if (!req->info)
 		goto error;
 
-	subtype = get_cryptoalg_subtype(tfm);
+	subtype = get_cryptoalg_subtype(crypto_ablkcipher_tfm(tfm));
 	if ((ablkctx->enckey_len == 0) || (ivsize > AES_BLOCK_SIZE) ||
-	    (req->cryptlen == 0) ||
-	    (req->cryptlen % crypto_skcipher_blocksize(tfm))) {
-		if (req->cryptlen == 0 && subtype != CRYPTO_ALG_SUB_TYPE_XTS)
+	    (req->nbytes == 0) ||
+	    (req->nbytes % crypto_ablkcipher_blocksize(tfm))) {
+		if (req->nbytes == 0 && subtype != CRYPTO_ALG_SUB_TYPE_XTS)
 			goto fallback;
-		else if (req->cryptlen % crypto_skcipher_blocksize(tfm) &&
+		else if (req->nbytes % crypto_ablkcipher_blocksize(tfm) &&
 			 subtype == CRYPTO_ALG_SUB_TYPE_XTS)
 			goto fallback;
 		pr_err("AES: Invalid value of Key Len %d nbytes %d IV Len %d\n",
-		       ablkctx->enckey_len, req->cryptlen, ivsize);
+		       ablkctx->enckey_len, req->nbytes, ivsize);
 		goto error;
 	}
 	chcr_cipher_dma_map(&ULD_CTX(c_ctx(tfm))->lldi.pdev->dev, req);
-	if (req->cryptlen < (SGE_MAX_WR_LEN - (sizeof(struct chcr_wr) +
+	if (req->nbytes < (SGE_MAX_WR_LEN - (sizeof(struct chcr_wr) +
 					    AES_MIN_KEY_SIZE +
 					    sizeof(struct cpl_rx_phys_dsgl) +
 					/*Min dsgl size*/
@@ -1353,14 +1362,14 @@
 		/* Can be sent as Imm*/
 		unsigned int dnents = 0, transhdr_len, phys_dsgl, kctx_len;
 
-		dnents = sg_nents_xlen(req->dst, req->cryptlen,
+		dnents = sg_nents_xlen(req->dst, req->nbytes,
 				       CHCR_DST_SG_SIZE, 0);
 		phys_dsgl = get_space_for_phys_dsgl(dnents);
 		kctx_len = roundup(ablkctx->enckey_len, 16);
 		transhdr_len = CIPHER_TRANSHDR_SIZE(kctx_len, phys_dsgl);
-		reqctx->imm = (transhdr_len + IV + req->cryptlen) <=
+		reqctx->imm = (transhdr_len + IV + req->nbytes) <=
 			SGE_MAX_WR_LEN;
-		bytes = IV + req->cryptlen;
+		bytes = IV + req->nbytes;
 
 	} else {
 		reqctx->imm = 0;
@@ -1370,19 +1379,19 @@
 		bytes = chcr_sg_ent_in_wr(req->src, req->dst, 0,
 					  CIP_SPACE_LEFT(ablkctx->enckey_len),
 					  0, 0);
-		if ((bytes + reqctx->processed) >= req->cryptlen)
-			bytes  = req->cryptlen - reqctx->processed;
+		if ((bytes + reqctx->processed) >= req->nbytes)
+			bytes  = req->nbytes - reqctx->processed;
 		else
 			bytes = rounddown(bytes, 16);
 	} else {
-		bytes = req->cryptlen;
+		bytes = req->nbytes;
 	}
 	if (subtype == CRYPTO_ALG_SUB_TYPE_CTR)
-		bytes = adjust_ctr_overflow(req->iv, bytes);
+		bytes = adjust_ctr_overflow(req->info, bytes);
 	if (subtype == CRYPTO_ALG_SUB_TYPE_CTR_RFC3686) {
 		memcpy(reqctx->iv, ablkctx->nonce, CTR_RFC3686_NONCE_SIZE);
-		memcpy(reqctx->iv + CTR_RFC3686_NONCE_SIZE, req->iv,
-		       CTR_RFC3686_IV_SIZE);
+		memcpy(reqctx->iv + CTR_RFC3686_NONCE_SIZE, req->info,
+				CTR_RFC3686_IV_SIZE);
 
 		/* initialize counter portion of counter block */
 		*(__be32 *)(reqctx->iv + CTR_RFC3686_NONCE_SIZE +
@@ -1390,8 +1399,8 @@
 		memcpy(reqctx->init_iv, reqctx->iv, IV);
 
 	} else {
-		memcpy(reqctx->iv, req->iv, IV);
-		memcpy(reqctx->init_iv, req->iv, IV);
+		memcpy(reqctx->iv, req->info, IV);
+		memcpy(reqctx->init_iv, req->info, IV);
 	}
 	if (unlikely(bytes == 0)) {
 		chcr_cipher_dma_unmap(&ULD_CTX(c_ctx(tfm))->lldi.pdev->dev,
@@ -1401,10 +1410,10 @@
 					   req->base.flags,
 					   req->src,
 					   req->dst,
-					   req->cryptlen,
+					   req->nbytes,
 					   subtype ==
 					   CRYPTO_ALG_SUB_TYPE_CTR_RFC3686 ?
-					   reqctx->iv : req->iv,
+					   reqctx->iv : req->info,
 					   op_type);
 		goto error;
 	}
@@ -1423,7 +1432,7 @@
 	}
 	reqctx->processed = bytes;
 	reqctx->last_req_len = bytes;
-	reqctx->partial_req = !!(req->cryptlen - reqctx->processed);
+	reqctx->partial_req = !!(req->nbytes - reqctx->processed);
 
 	return 0;
 unmap:
@@ -1432,10 +1441,10 @@
 	return err;
 }
 
-static int chcr_aes_encrypt(struct skcipher_request *req)
+static int chcr_aes_encrypt(struct ablkcipher_request *req)
 {
-	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
-	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
+	struct chcr_blkcipher_req_ctx *reqctx = ablkcipher_request_ctx(req);
 	struct sk_buff *skb = NULL;
 	int err;
 	struct uld_ctx *u_ctx = ULD_CTX(c_ctx(tfm));
@@ -1464,7 +1473,7 @@
 	set_wr_txq(skb, CPL_PRIORITY_DATA, reqctx->txqidx);
 	chcr_send_wr(skb);
 
-	if (get_cryptoalg_subtype(tfm) ==
+	if (get_cryptoalg_subtype(crypto_ablkcipher_tfm(tfm)) ==
             CRYPTO_ALG_SUB_TYPE_CBC && req->base.flags ==
                 CRYPTO_TFM_REQ_MAY_SLEEP ) {
                 ctx=c_ctx(tfm);
@@ -1475,10 +1484,10 @@
 	return -EINPROGRESS;
 }
 
-static int chcr_aes_decrypt(struct skcipher_request *req)
+static int chcr_aes_decrypt(struct ablkcipher_request *req)
 {
-	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
-	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
+	struct chcr_blkcipher_req_ctx *reqctx = ablkcipher_request_ctx(req);
 	struct uld_ctx *u_ctx = ULD_CTX(c_ctx(tfm));
 	struct sk_buff *skb = NULL;
 	int err;
@@ -1542,17 +1551,16 @@
 	return err;
 }
 
-static int chcr_init_tfm(struct crypto_skcipher *tfm)
+static int chcr_cra_init(struct crypto_tfm *tfm)
 {
-	struct skcipher_alg *alg = crypto_skcipher_alg(tfm);
-	struct chcr_context *ctx = crypto_skcipher_ctx(tfm);
+	struct crypto_alg *alg = tfm->__crt_alg;
+	struct chcr_context *ctx = crypto_tfm_ctx(tfm);
 	struct ablk_ctx *ablkctx = ABLK_CTX(ctx);
 
-	ablkctx->sw_cipher = crypto_alloc_sync_skcipher(alg->base.cra_name, 0,
-						CRYPTO_ALG_NEED_FALLBACK);
+	ablkctx->sw_cipher = crypto_alloc_skcipher(alg->cra_name, 0,
+				CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK);
 	if (IS_ERR(ablkctx->sw_cipher)) {
-		pr_err("failed to allocate fallback for %s\n",
-		       alg->base.cra_name);
+		pr_err("failed to allocate fallback for %s\n", alg->cra_name);
 		return PTR_ERR(ablkctx->sw_cipher);
 	}
 
@@ -1567,37 +1575,37 @@
 		ablkctx->aes_generic = NULL;
 
 	init_completion(&ctx->cbc_aes_aio_done);
-	crypto_skcipher_set_reqsize(tfm, sizeof(struct chcr_skcipher_req_ctx));
-	return chcr_device_init(ctx);
+
+	tfm->crt_ablkcipher.reqsize =  sizeof(struct chcr_blkcipher_req_ctx);
+	return chcr_device_init(crypto_tfm_ctx(tfm));
 }
 
-static int chcr_rfc3686_init(struct crypto_skcipher *tfm)
+static int chcr_rfc3686_init(struct crypto_tfm *tfm)
 {
-	struct skcipher_alg *alg = crypto_skcipher_alg(tfm);
-	struct chcr_context *ctx = crypto_skcipher_ctx(tfm);
+	struct crypto_alg *alg = tfm->__crt_alg;
+	struct chcr_context *ctx = crypto_tfm_ctx(tfm);
 	struct ablk_ctx *ablkctx = ABLK_CTX(ctx);
 
 	/*RFC3686 initialises IV counter value to 1, rfc3686(ctr(aes))
 	 * cannot be used as fallback in chcr_handle_cipher_response
 	 */
-	ablkctx->sw_cipher = crypto_alloc_sync_skcipher("ctr(aes)", 0,
-				CRYPTO_ALG_NEED_FALLBACK);
+	ablkctx->sw_cipher = crypto_alloc_skcipher("ctr(aes)", 0,
+				CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK);
 	if (IS_ERR(ablkctx->sw_cipher)) {
-		pr_err("failed to allocate fallback for %s\n",
-		       alg->base.cra_name);
+		pr_err("failed to allocate fallback for %s\n", alg->cra_name);
 		return PTR_ERR(ablkctx->sw_cipher);
 	}
-	crypto_skcipher_set_reqsize(tfm, sizeof(struct chcr_skcipher_req_ctx));
-	return chcr_device_init(ctx);
+	tfm->crt_ablkcipher.reqsize =  sizeof(struct chcr_blkcipher_req_ctx);
+	return chcr_device_init(crypto_tfm_ctx(tfm));
 }
 
 
-static void chcr_exit_tfm(struct crypto_skcipher *tfm)
+static void chcr_cra_exit(struct crypto_tfm *tfm)
 {
-	struct chcr_context *ctx = crypto_skcipher_ctx(tfm);
+	struct chcr_context *ctx = crypto_tfm_ctx(tfm);
 	struct ablk_ctx *ablkctx = ABLK_CTX(ctx);
 
-	crypto_free_sync_skcipher(ablkctx->sw_cipher);
+	crypto_free_skcipher(ablkctx->sw_cipher);
 	if (ablkctx->aes_generic)
 		crypto_free_cipher(ablkctx->aes_generic);
 }
@@ -2182,6 +2190,7 @@
 	 * ipad in hmacctx->ipad and opad in hmacctx->opad location
 	 */
 	shash->tfm = hmacctx->base_hash;
+	shash->flags = crypto_shash_get_flags(hmacctx->base_hash);
 	if (keylen > bs) {
 		err = crypto_shash_digest(shash, key, keylen,
 					  hmacctx->ipad);
@@ -2219,7 +2228,7 @@
 	return err;
 }
 
-static int chcr_aes_xts_setkey(struct crypto_skcipher *cipher, const u8 *key,
+static int chcr_aes_xts_setkey(struct crypto_ablkcipher *cipher, const u8 *key,
 			       unsigned int key_len)
 {
 	struct ablk_ctx *ablkctx = ABLK_CTX(c_ctx(cipher));
@@ -2258,6 +2267,7 @@
 	ablkctx->ciph_mode = CHCR_SCMD_CIPHER_MODE_AES_XTS;
 	return 0;
 badkey_err:
+	crypto_ablkcipher_set_flags(cipher, CRYPTO_TFM_RES_BAD_KEY_LEN);
 	ablkctx->enckey_len = 0;
 
 	return err;
@@ -2635,32 +2645,31 @@
 	int src_len, dst_len;
 
 	/* calculate and handle src and dst sg length separately
- 	 * for inplace and out-of place operations  */
-        if (req->src == req->dst) {
-                src_len = req->assoclen + req->cryptlen + (op_type ?
-                                                0 : authsize);
-                dst_len = src_len;
-        }
-        else {
-                src_len = req->assoclen + req->cryptlen;
-                dst_len = req->assoclen + req->cryptlen + (op_type ?
-                                                -authsize : authsize);
-        }
-
-        if (!req->cryptlen || !src_len || !dst_len)
-                return;
+	 * for inplace and out-of place operations  */
+	if (req->src == req->dst) {
+		src_len = req->assoclen + req->cryptlen + (op_type ?
+						0 : authsize);
+		dst_len = src_len;
+	} else {
+		src_len = req->assoclen + req->cryptlen;
+		dst_len = req->assoclen + req->cryptlen + (op_type ?
+						-authsize : authsize);
+	}
+
+	if (!req->cryptlen || !src_len || !dst_len)
+		return;
 
 	if (reqctx->imm) {
 		dma_unmap_sg(dev, req->dst, sg_nents_for_len(req->dst, dst_len),
-				   DMA_FROM_DEVICE);
+				DMA_FROM_DEVICE);
 		return;
 	}
 
 	dma_unmap_single(dev, reqctx->iv_dma, (IV + reqctx->b0_len),
 					DMA_TO_DEVICE);
 	if (req->src == req->dst) {
-		dma_unmap_sg(dev, req->src, sg_nents_for_len(req->src
-			     , src_len), DMA_BIDIRECTIONAL);
+		dma_unmap_sg(dev, req->src, sg_nents_for_len(req->src,
+				src_len), DMA_BIDIRECTIONAL);
 	} else {
 		dma_unmap_sg(dev, req->src, sg_nents_for_len(req->src, src_len),
 				   DMA_TO_DEVICE);
@@ -2727,12 +2736,12 @@
 	dsgl_walk_end(&dsgl_walk, qid, rx_channel_id);
 }
 
-void chcr_add_cipher_src_ent(struct skcipher_request *req,
+void chcr_add_cipher_src_ent(struct ablkcipher_request *req,
 					   void *ulptx,
 					   struct  cipher_wr_param *wrparam)
 {
 	struct ulptx_walk ulp_walk;
-	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
+	struct chcr_blkcipher_req_ctx *reqctx = ablkcipher_request_ctx(req);
 	u8 *buf = ulptx;
 
 	memcpy(buf, reqctx->iv, IV);
@@ -2750,13 +2759,13 @@
 	}
 }
 
-void chcr_add_cipher_dst_ent(struct skcipher_request *req,
+void chcr_add_cipher_dst_ent(struct ablkcipher_request *req,
 			   struct cpl_rx_phys_dsgl *phys_cpl,
 			   struct  cipher_wr_param *wrparam,
 			   unsigned short qid)
 {
-	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
-	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(wrparam->req);
+	struct chcr_blkcipher_req_ctx *reqctx = ablkcipher_request_ctx(req);
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(wrparam->req);
 	struct chcr_context *ctx = c_ctx(tfm);
 	struct dsgl_walk dsgl_walk;
 	unsigned int rx_channel_id = reqctx->rxqidx/ctx->rxq_perchan;
@@ -2831,7 +2840,7 @@
 }
 
 int chcr_cipher_dma_map(struct device *dev,
-			struct skcipher_request *req)
+			struct ablkcipher_request *req)
 {
 	int error;
 
@@ -2860,7 +2869,7 @@
 }
 
 void chcr_cipher_dma_unmap(struct device *dev,
-			   struct skcipher_request *req)
+			   struct ablkcipher_request *req)
 {
 	if (req->src == req->dst) {
 		dma_unmap_sg(dev, req->src, sg_nents(req->src),
@@ -3356,6 +3365,9 @@
 		aeadctx->mayverify = VERIFY_SW;
 		break;
 	default:
+
+		  crypto_tfm_set_flags((struct crypto_tfm *) tfm,
+			CRYPTO_TFM_RES_BAD_KEY_LEN);
 		return -EINVAL;
 	}
 	return crypto_aead_setauthsize(aeadctx->sw_cipher, authsize);
@@ -3380,6 +3392,8 @@
 		aeadctx->mayverify = VERIFY_HW;
 		break;
 	default:
+		crypto_tfm_set_flags((struct crypto_tfm *)tfm,
+				     CRYPTO_TFM_RES_BAD_KEY_LEN);
 		return -EINVAL;
 	}
 	return crypto_aead_setauthsize(aeadctx->sw_cipher, authsize);
@@ -3420,6 +3434,8 @@
 		aeadctx->mayverify = VERIFY_HW;
 		break;
 	default:
+		crypto_tfm_set_flags((struct crypto_tfm *)tfm,
+				     CRYPTO_TFM_RES_BAD_KEY_LEN);
 		return -EINVAL;
 	}
 	return crypto_aead_setauthsize(aeadctx->sw_cipher, authsize);
@@ -3444,6 +3460,8 @@
 		ck_size = CHCR_KEYCTX_CIPHER_KEY_SIZE_256;
 		mk_size = CHCR_KEYCTX_MAC_KEY_SIZE_256;
 	} else {
+		crypto_tfm_set_flags((struct crypto_tfm *)aead,
+					CRYPTO_TFM_RES_BAD_KEY_LEN);
 		aeadctx->enckey_len = 0;
 		return  -EINVAL;
 	}
@@ -3466,6 +3484,9 @@
 	crypto_aead_set_flags(aeadctx->sw_cipher, crypto_aead_get_flags(aead) &
 			      CRYPTO_TFM_REQ_MASK);
 	error = crypto_aead_setkey(aeadctx->sw_cipher, key, keylen);
+	crypto_aead_clear_flags(aead, CRYPTO_TFM_RES_MASK);
+	crypto_aead_set_flags(aead, crypto_aead_get_flags(aeadctx->sw_cipher) &
+			      CRYPTO_TFM_RES_MASK);
 	if (error)
 		return error;
 	return chcr_ccm_common_setkey(aead, key, keylen);
@@ -3478,6 +3499,8 @@
 	int error;
 
 	if (keylen < 3) {
+		crypto_tfm_set_flags((struct crypto_tfm *)aead,
+				     CRYPTO_TFM_RES_BAD_KEY_LEN);
 		aeadctx->enckey_len = 0;
 		return	-EINVAL;
 	}
@@ -3485,6 +3508,9 @@
 	crypto_aead_set_flags(aeadctx->sw_cipher, crypto_aead_get_flags(aead) &
 			      CRYPTO_TFM_REQ_MASK);
 	error = crypto_aead_setkey(aeadctx->sw_cipher, key, keylen);
+	crypto_aead_clear_flags(aead, CRYPTO_TFM_RES_MASK);
+	crypto_aead_set_flags(aead, crypto_aead_get_flags(aeadctx->sw_cipher) &
+			      CRYPTO_TFM_RES_MASK);
 	if (error)
 		return error;
 	keylen -= 3;
@@ -3506,6 +3532,9 @@
 	crypto_aead_set_flags(aeadctx->sw_cipher, crypto_aead_get_flags(aead)
 			      & CRYPTO_TFM_REQ_MASK);
 	ret = crypto_aead_setkey(aeadctx->sw_cipher, key, keylen);
+	crypto_aead_clear_flags(aead, CRYPTO_TFM_RES_MASK);
+	crypto_aead_set_flags(aead, crypto_aead_get_flags(aeadctx->sw_cipher) &
+			      CRYPTO_TFM_RES_MASK);
 	if (ret)
 		goto out;
 
@@ -3521,6 +3550,8 @@
 	} else if (keylen == AES_KEYSIZE_256) {
 		ck_size = CHCR_KEYCTX_CIPHER_KEY_SIZE_256;
 	} else {
+		crypto_tfm_set_flags((struct crypto_tfm *)aead,
+				     CRYPTO_TFM_RES_BAD_KEY_LEN);
 		pr_err("GCM: Invalid key length %d\n", keylen);
 		ret = -EINVAL;
 		goto out;
@@ -3578,11 +3609,16 @@
 	crypto_aead_set_flags(aeadctx->sw_cipher, crypto_aead_get_flags(authenc)
 			      & CRYPTO_TFM_REQ_MASK);
 	err = crypto_aead_setkey(aeadctx->sw_cipher, key, keylen);
+	crypto_aead_clear_flags(authenc, CRYPTO_TFM_RES_MASK);
+	crypto_aead_set_flags(authenc, crypto_aead_get_flags(aeadctx->sw_cipher)
+			      & CRYPTO_TFM_RES_MASK);
 	if (err)
 		goto out;
 
-	if (crypto_authenc_extractkeys(&keys, key, keylen) != 0)
+	if (crypto_authenc_extractkeys(&keys, key, keylen) != 0) {
+		crypto_aead_set_flags(authenc, CRYPTO_TFM_RES_BAD_KEY_LEN);
 		goto out;
+	}
 
 	if (get_alg_config(&param, max_authsize)) {
 		pr_err("chcr : Unsupported digest size\n");
@@ -3630,6 +3666,7 @@
 	{
 		SHASH_DESC_ON_STACK(shash, base_hash);
 		shash->tfm = base_hash;
+		shash->flags = crypto_shash_get_flags(base_hash);
 		bs = crypto_shash_blocksize(base_hash);
 		align = KEYCTX_ALIGN_PAD(max_authsize);
 		o_ptr =  actx->h_iopad + param.result_size + align;
@@ -3702,12 +3739,16 @@
 	crypto_aead_set_flags(aeadctx->sw_cipher, crypto_aead_get_flags(authenc)
 			      & CRYPTO_TFM_REQ_MASK);
 	err = crypto_aead_setkey(aeadctx->sw_cipher, key, keylen);
+	crypto_aead_clear_flags(authenc, CRYPTO_TFM_RES_MASK);
+	crypto_aead_set_flags(authenc, crypto_aead_get_flags(aeadctx->sw_cipher)
+			      & CRYPTO_TFM_RES_MASK);
 	if (err)
 		goto out;
 
-	if (crypto_authenc_extractkeys(&keys, key, keylen) != 0)
+	if (crypto_authenc_extractkeys(&keys, key, keylen) != 0) {
+		crypto_aead_set_flags(authenc, CRYPTO_TFM_RES_BAD_KEY_LEN);
 		goto out;
-
+	}
 	subtype = get_aead_subtype(authenc);
 	if (subtype == CRYPTO_ALG_SUB_TYPE_CTR_SHA ||
 	    subtype == CRYPTO_ALG_SUB_TYPE_CTR_NULL) {
@@ -3769,12 +3810,6 @@
 #else
 			return -EBUSY;
 #endif
-	if (get_aead_subtype(tfm) == CRYPTO_ALG_SUB_TYPE_AEAD_RFC4106 &&
-	    crypto_ipsec_check_assoclen(req->assoclen) != 0) {
-		pr_err("RFC4106: Invalid value of assoclen %d\n",
-		       req->assoclen);
-		return -EINVAL;
-	}
 
 	/* Form a WR from req */
 	skb = create_wr_fn(req, u_ctx->lldi.rxq_ids[reqctx->rxqidx], size);
@@ -3857,74 +3892,83 @@
 static struct chcr_alg_template driver_algs[] = {
 	/* AES-CBC */
 	{
-		.type = CRYPTO_ALG_TYPE_SKCIPHER | CRYPTO_ALG_SUB_TYPE_CBC,
+		.type = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_SUB_TYPE_CBC,
 		.is_registered = 0,
-		.alg.skcipher = {
-			.base.cra_name		= "cbc(aes)",
-			.base.cra_driver_name	= "cbc-aes-chcr",
-			.base.cra_blocksize	= AES_BLOCK_SIZE,
-			.init			= chcr_init_tfm,
-			.exit			= chcr_exit_tfm,
-			.min_keysize		= AES_MIN_KEY_SIZE,
-			.max_keysize		= AES_MAX_KEY_SIZE,
-			.ivsize			= AES_BLOCK_SIZE,
-			.setkey			= chcr_aes_cbc_setkey,
-			.encrypt		= chcr_aes_encrypt,
-			.decrypt		= chcr_aes_decrypt,
+		.alg.crypto = {
+			.cra_name		= "cbc(aes)",
+			.cra_driver_name	= "cbc-aes-chcr",
+			.cra_blocksize		= AES_BLOCK_SIZE,
+			.cra_init		= chcr_cra_init,
+			.cra_exit		= chcr_cra_exit,
+			.cra_u.ablkcipher	= {
+				.min_keysize	= AES_MIN_KEY_SIZE,
+				.max_keysize	= AES_MAX_KEY_SIZE,
+				.ivsize		= AES_BLOCK_SIZE,
+				.setkey		= chcr_aes_cbc_setkey,
+				.encrypt	= chcr_aes_encrypt,
+				.decrypt	= chcr_aes_decrypt,
+			}
 		}
 	},
 	{
-		.type = CRYPTO_ALG_TYPE_SKCIPHER | CRYPTO_ALG_SUB_TYPE_XTS,
+		.type = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_SUB_TYPE_XTS,
 		.is_registered = 0,
-		.alg.skcipher =   {
-			.base.cra_name		= "xts(aes)",
-			.base.cra_driver_name	= "xts-aes-chcr",
-			.base.cra_blocksize	= AES_BLOCK_SIZE,
-			.init		= chcr_init_tfm,
-			.exit		= chcr_exit_tfm,
-			.min_keysize	= 2 * AES_MIN_KEY_SIZE,
-			.max_keysize	= 2 * AES_MAX_KEY_SIZE,
-			.ivsize		= AES_BLOCK_SIZE,
-			.setkey		= chcr_aes_xts_setkey,
-			.encrypt	= chcr_aes_encrypt,
-			.decrypt	= chcr_aes_decrypt,
+		.alg.crypto =   {
+			.cra_name		= "xts(aes)",
+			.cra_driver_name	= "xts-aes-chcr",
+			.cra_blocksize		= AES_BLOCK_SIZE,
+			.cra_init		= chcr_cra_init,
+			.cra_exit		= NULL,
+			.cra_u .ablkcipher = {
+				.min_keysize	= 2 * AES_MIN_KEY_SIZE,
+				.max_keysize	= 2 * AES_MAX_KEY_SIZE,
+				.ivsize		= AES_BLOCK_SIZE,
+				.setkey		= chcr_aes_xts_setkey,
+				.encrypt	= chcr_aes_encrypt,
+				.decrypt	= chcr_aes_decrypt,
+			}
 		}
 	},
 	{
-		.type = CRYPTO_ALG_TYPE_SKCIPHER | CRYPTO_ALG_SUB_TYPE_CTR,
+		.type = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_SUB_TYPE_CTR,
 		.is_registered = 0,
-		.alg.skcipher = {
-			.base.cra_name		= "ctr(aes)",
-			.base.cra_driver_name	= "ctr-aes-chcr",
-			.base.cra_blocksize	= 1,
-			.init		= chcr_init_tfm,
-			.exit		= chcr_exit_tfm,
-			.min_keysize	= AES_MIN_KEY_SIZE,
-			.max_keysize	= AES_MAX_KEY_SIZE,
-			.ivsize		= AES_BLOCK_SIZE,
-			.setkey		= chcr_aes_ctr_setkey,
-			.encrypt	= chcr_aes_encrypt,
-			.decrypt	= chcr_aes_decrypt,
+		.alg.crypto = {
+			.cra_name		= "ctr(aes)",
+			.cra_driver_name	= "ctr-aes-chcr",
+			.cra_blocksize		= 1,
+			.cra_init		= chcr_cra_init,
+			.cra_exit		= chcr_cra_exit,
+			.cra_u.ablkcipher	= {
+				.min_keysize	= AES_MIN_KEY_SIZE,
+				.max_keysize	= AES_MAX_KEY_SIZE,
+				.ivsize		= AES_BLOCK_SIZE,
+				.setkey		= chcr_aes_ctr_setkey,
+				.encrypt	= chcr_aes_encrypt,
+				.decrypt	= chcr_aes_decrypt,
+			}
 		}
 	},
 	{
-		.type = CRYPTO_ALG_TYPE_SKCIPHER |
+		.type = CRYPTO_ALG_TYPE_ABLKCIPHER |
 			CRYPTO_ALG_SUB_TYPE_CTR_RFC3686,
 		.is_registered = 0,
-		.alg.skcipher = {
-			.base.cra_name		= "rfc3686(ctr(aes))",
-			.base.cra_driver_name	= "rfc3686-ctr-aes-chcr",
-			.base.cra_blocksize	= 1,
-			.init			= chcr_rfc3686_init,
-			.exit			= chcr_exit_tfm,
-			.min_keysize	= AES_MIN_KEY_SIZE +
-						CTR_RFC3686_NONCE_SIZE,
-			.max_keysize	= AES_MAX_KEY_SIZE +
+		.alg.crypto = {
+			.cra_name		= "rfc3686(ctr(aes))",
+			.cra_driver_name	= "rfc3686-ctr-aes-chcr",
+			.cra_blocksize		= 1,
+			.cra_init		= chcr_rfc3686_init,
+			.cra_exit		= chcr_cra_exit,
+			.cra_u.ablkcipher	= {
+				.min_keysize	= AES_MIN_KEY_SIZE +
 					CTR_RFC3686_NONCE_SIZE,
-			.ivsize		= CTR_RFC3686_IV_SIZE,
-			.setkey		= chcr_aes_rfc3686_setkey,
-			.encrypt	= chcr_aes_encrypt,
-			.decrypt	= chcr_aes_decrypt,
+				.max_keysize	= AES_MAX_KEY_SIZE +
+					CTR_RFC3686_NONCE_SIZE,
+				.ivsize		= CTR_RFC3686_IV_SIZE,
+				.setkey		= chcr_aes_rfc3686_setkey,
+				.encrypt	= chcr_aes_encrypt,
+				.decrypt	= chcr_aes_decrypt,
+				.geniv          = "seqiv",
+			}
 		}
 	},
 	/* SHA */
@@ -4391,11 +4435,11 @@
 
 	for (i = 0; i < ARRAY_SIZE(driver_algs); i++) {
 		switch (driver_algs[i].type & CRYPTO_ALG_TYPE_MASK) {
-		case CRYPTO_ALG_TYPE_SKCIPHER:
+		case CRYPTO_ALG_TYPE_ABLKCIPHER:
 			if (driver_algs[i].is_registered && refcount_read(
-			    &driver_algs[i].alg.skcipher.base.cra_refcnt) == 1) {
-				crypto_unregister_skcipher(
-						&driver_algs[i].alg.skcipher);
+			    &driver_algs[i].alg.crypto.cra_refcnt) == 1) {
+				crypto_unregister_alg(
+						&driver_algs[i].alg.crypto);
 				driver_algs[i].is_registered = 0;
 			}
 			break;
@@ -4440,19 +4484,21 @@
 		if (driver_algs[i].is_registered)
 			continue;
 		switch (driver_algs[i].type & CRYPTO_ALG_TYPE_MASK) {
-		case CRYPTO_ALG_TYPE_SKCIPHER:
-			driver_algs[i].alg.skcipher.base.cra_priority =
+		case CRYPTO_ALG_TYPE_ABLKCIPHER:
+			driver_algs[i].alg.crypto.cra_priority =
 				CHCR_CRA_PRIORITY;
-			driver_algs[i].alg.skcipher.base.cra_module = THIS_MODULE;
-			driver_algs[i].alg.skcipher.base.cra_flags =
-				CRYPTO_ALG_TYPE_SKCIPHER | CRYPTO_ALG_ASYNC |
+			driver_algs[i].alg.crypto.cra_module = THIS_MODULE;
+			driver_algs[i].alg.crypto.cra_flags =
+				CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC |
 				CRYPTO_ALG_NEED_FALLBACK;
-			driver_algs[i].alg.skcipher.base.cra_ctxsize =
+			driver_algs[i].alg.crypto.cra_ctxsize =
 				sizeof(struct chcr_context) +
 				sizeof(struct ablk_ctx);
-			driver_algs[i].alg.skcipher.base.cra_alignmask = 0;
-			err = crypto_register_skcipher(&driver_algs[i].alg.skcipher);
-			name = driver_algs[i].alg.skcipher.base.cra_driver_name;
+			driver_algs[i].alg.crypto.cra_alignmask = 0;
+			driver_algs[i].alg.crypto.cra_type =
+				&crypto_ablkcipher_type;
+			err = crypto_register_alg(&driver_algs[i].alg.crypto);
+			name = driver_algs[i].alg.crypto.cra_driver_name;
 			break;
 		case CRYPTO_ALG_TYPE_AEAD:
 			driver_algs[i].alg.aead.base.cra_flags =
@@ -4480,6 +4526,7 @@
 			a_hash->halg.base.cra_flags = AHASH_CRA_FLAGS;
 			a_hash->halg.base.cra_alignmask = 0;
 			a_hash->halg.base.cra_exit = NULL;
+			a_hash->halg.base.cra_type = &crypto_ahash_type;
 
 			if (driver_algs[i].type == CRYPTO_ALG_TYPE_HMAC) {
 				a_hash->halg.base.cra_init = chcr_hmac_cra_init;
diff -r 30 src/network/chcr/chcr_algo.h
--- a/src/network/chcr/chcr_algo.h	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/chcr/chcr_algo.h	Tue May 18 15:02:47 2021 +0530
@@ -245,7 +245,7 @@
 };
 
 struct cipher_wr_param {
-	struct skcipher_request *req;
+	struct ablkcipher_request *req;
 	char *iv;
 	int bytes;
 	unsigned short qid;
@@ -291,26 +291,26 @@
 };
 
 
-static const u32 chcr_sha1_init[SHA1_DIGEST_SIZE / 4] = {
+static const u32 sha1_init[SHA1_DIGEST_SIZE / 4] = {
 		SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4,
 };
 
-static const u32 chcr_sha224_init[SHA256_DIGEST_SIZE / 4] = {
+static const u32 sha224_init[SHA256_DIGEST_SIZE / 4] = {
 		SHA224_H0, SHA224_H1, SHA224_H2, SHA224_H3,
 		SHA224_H4, SHA224_H5, SHA224_H6, SHA224_H7,
 };
 
-static const u32 chcr_sha256_init[SHA256_DIGEST_SIZE / 4] = {
+static const u32 sha256_init[SHA256_DIGEST_SIZE / 4] = {
 		SHA256_H0, SHA256_H1, SHA256_H2, SHA256_H3,
 		SHA256_H4, SHA256_H5, SHA256_H6, SHA256_H7,
 };
 
-static const u64 chcr_sha384_init[SHA512_DIGEST_SIZE / 8] = {
+static const u64 sha384_init[SHA512_DIGEST_SIZE / 8] = {
 		SHA384_H0, SHA384_H1, SHA384_H2, SHA384_H3,
 		SHA384_H4, SHA384_H5, SHA384_H6, SHA384_H7,
 };
 
-static const u64 chcr_sha512_init[SHA512_DIGEST_SIZE / 8] = {
+static const u64 sha512_init[SHA512_DIGEST_SIZE / 8] = {
 		SHA512_H0, SHA512_H1, SHA512_H2, SHA512_H3,
 		SHA512_H4, SHA512_H5, SHA512_H6, SHA512_H7,
 };
@@ -320,21 +320,21 @@
 	u8 i;
 	__be32 *dkey = (__be32 *)key;
 	u64 *ldkey = (u64 *)key;
-	__be64 *sha384 = (__be64 *)chcr_sha384_init;
-	__be64 *sha512 = (__be64 *)chcr_sha512_init;
+	__be64 *sha384 = (__be64 *)sha384_init;
+	__be64 *sha512 = (__be64 *)sha512_init;
 
 	switch (digestsize) {
 	case SHA1_DIGEST_SIZE:
 		for (i = 0; i < SHA1_INIT_STATE; i++)
-			dkey[i] = cpu_to_be32(chcr_sha1_init[i]);
+			dkey[i] = cpu_to_be32(sha1_init[i]);
 		break;
 	case SHA224_DIGEST_SIZE:
 		for (i = 0; i < SHA224_INIT_STATE; i++)
-			dkey[i] = cpu_to_be32(chcr_sha224_init[i]);
+			dkey[i] = cpu_to_be32(sha224_init[i]);
 		break;
 	case SHA256_DIGEST_SIZE:
 		for (i = 0; i < SHA256_INIT_STATE; i++)
-			dkey[i] = cpu_to_be32(chcr_sha256_init[i]);
+			dkey[i] = cpu_to_be32(sha256_init[i]);
 		break;
 	case SHA384_DIGEST_SIZE:
 		for (i = 0; i < SHA384_INIT_STATE; i++)
diff -r 30 src/network/chcr/chcr_crypto.h
--- a/src/network/chcr/chcr_crypto.h	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/chcr/chcr_crypto.h	Tue May 18 15:02:47 2021 +0530
@@ -234,9 +234,9 @@
 	return crypto_aead_ctx(tfm);
 }
 
-static inline struct chcr_context *c_ctx(struct crypto_skcipher *tfm)
+static inline struct chcr_context *c_ctx(struct crypto_ablkcipher *tfm)
 {
-	return crypto_skcipher_ctx(tfm);
+	return crypto_ablkcipher_ctx(tfm);
 }
 
 static inline struct chcr_context *h_ctx(struct crypto_ahash *tfm)
@@ -245,7 +245,7 @@
 }
 
 struct ablk_ctx {
-	struct crypto_sync_skcipher *sw_cipher;
+	struct crypto_skcipher *sw_cipher;
 	struct crypto_cipher *aes_generic;
 	__be32 key_ctx_hdr;
 	unsigned int enckey_len;
@@ -372,7 +372,7 @@
 	u8 bfr2[CHCR_HASH_MAX_BLOCK_SIZE_128];
 };
 
-struct chcr_skcipher_req_ctx {
+struct chcr_blkcipher_req_ctx {
 	struct sk_buff *skb;
 	struct scatterlist *dstsg;
 	unsigned int processed;
@@ -393,7 +393,7 @@
 	u32 type;
 	u32 is_registered;
 	union {
-		struct skcipher_alg skcipher;
+		struct crypto_alg crypto;
 		struct ahash_alg hash;
 		struct aead_alg aead;
 	} alg;
@@ -412,14 +412,14 @@
 		    unsigned short qid, unsigned int esp_iv_size);
 void chcr_add_aead_src_ent(struct aead_request *req,
 		    struct ulptx_sgl *ulptx);
-void chcr_add_cipher_src_ent(struct skcipher_request *req,
-			     void *ulptx,
-			     struct  cipher_wr_param *wrparam);
+void chcr_add_cipher_src_ent(struct ablkcipher_request *req,
+			   void *ulptx,
+			   struct  cipher_wr_param *wrparam);
 int chcr_cipher_dma_map(struct device *dev,
-		       struct skcipher_request *req);
+		       struct ablkcipher_request *req);
 void chcr_cipher_dma_unmap(struct device *dev,
-			  struct skcipher_request *req);
-inline void chcr_add_cipher_dst_ent(struct skcipher_request *req,
+			  struct ablkcipher_request *req);
+inline void chcr_add_cipher_dst_ent(struct ablkcipher_request *req,
 				   struct cpl_rx_phys_dsgl *phys_cpl,
 				   struct  cipher_wr_param *wrparam,
 				   unsigned short qid);
diff -r 30 src/network/chtcp/Makefile
--- a/src/network/chtcp/Makefile	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,114 +0,0 @@
-# Makefile for Chelsio chtcp driver.
-#
-# Copyright (c) 2020-2021 Chelsio Communications. All rights reserved.
-
-# This software is available to you under a choice of one of two
-# licenses.  You may choose to be licensed under the terms of the GNU
-# General Public License (GPL) Version 2 or the OpenIB.org BSD license
-# below:
-
-#     Redistribution and use in source and binary forms, with or
-#     without modification, are permitted provided that the following
-#     conditions are met:
-
-#      - Redistributions of source code must retain the above
-#	  copyright notice, this list of conditions and the following
-#	  disclaimer.
-#      - Redistributions in binary form must reproduce the above
-#	  copyright notice, this list of conditions and the following
-#	  disclaimer in the documentation and/or other materials
-#	  provided with the distribution.
-
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
-# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
-# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
-# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
-# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
-# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
-# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-#
-
-SHELL = /bin/sh
-
-# The top-level makefile defines required variables and flags.
-ifneq ($(shell [ $(MAKELEVEL) -ge 1 ] && echo 1),1)
-  $(error Please use the top-level Makefile to build this driver)
-endif
-
-EXTRA_CFLAGS += $(FLAGS)
-EXTRA_CFLAGS += -I$(srcdir)/include
-EXTRA_CFLAGS += -I$(srcdir)/cxgb4
-EXTRA_CFLAGS += -I$(KSRC)/include
-EXTRA_CFLAGS += -I. -g -O1
-
-CFILES  = chtcp_kmain.c chtcp_kcm.c chtcp_ksge.c
-TARGET  = chtcp.o
-CLEAN_FILES := $(wildcard *.c)
-CLEAN_FILES := $(CLEAN_FILES:.c=.o)
-
-lib_path     := $(PREFIX)/lib/modules/$(utsrelease)
-module_path   = updates/drivers/chtcp
-install_path := $(lib_path)/$(module_path)
-old_install_path := $(lib_path)/$(module_path)
-
-ifeq ($(kseries),2.4)
-  $(error offload driver is not supported on 2.4 series kernel)
-  driver := $(TARGET)
-  $(TARGET): $(filter-out $(TARGET),$(CFILES:.c=.o))
-	$(LD) -r $^ -o $@
-else
-  driver := $(TARGET:.o=.ko)
-endif
-
-ifneq ($(modulesymfile),)
-  override symverfile = symverfile="$(topdir)/$(modulesymfile) \
-				   -o $(drvdir)/$(modulesymfile)"
-else
-  override symverfile =
-endif
-
-EXTRA_SYMFILE = "$(srcdir)/cxgb4/$(modulesymfile)"
-
-obj-m := $(TARGET)
-$(TARGET:.o=)-objs := $(CFILES:.c=.o)
-
-.SUFFIXES:
-.SUFFIXES: .c .o
-
-.PHONY: default
-default: prep build
-
-.PHONY: prep
-prep:
-
-
-.PHONY: build
-build:
-	@$(MAKE) $(symverfile) -C $(KOBJ) KBUILD_EXTMOD=$(shell pwd) \
-		KBUILD_EXTRA_SYMBOLS="$(EXTRA_SYMFILE)" modules
-
-.PHONY: install
-install:
-	@-if [ -e "$(old_install_path)/$(driver)" ]; then \
-		echo "* Removing old driver at $(old_install_path)/$(driver)"; \
-		/bin/rm -f "$(old_install_path)/$(driver)"; \
-	fi;
-	@install -D $(verbose) -m 644 $(driver) $(install_path)/$(driver)
-
-.PHONY: uninstall
-uninstall:
-	@-if [ -n "$(verbose)" ]; then \
-	    echo "Removing $(install_path)/$(driver)";\
-		if [ -e "$(old_install_path)/$(driver)" ]; then \
-		    echo "Removing $(old_install_path)/$(driver)";\
-		fi; \
-	  fi;\
-	  /bin/rm -f "$(install_path)/$(driver)"; \
-	  /bin/rm -f "$(old_install_path)/$(driver)";
-
-.PHONY: clean
-clean:
-	-/bin/rm -rf $(driver) $(TARGET) $(TARGET:.o=.mod.c) \
-	             $(TARGET:.o=.mod.o) $(CLEAN_FILES) \
-		     .*cmd .tmp_versions *.symvers
diff -r 30 src/network/chtcp/chtcp_ioctl.h
--- a/src/network/chtcp/chtcp_ioctl.h	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,239 +0,0 @@
-/*
- * Copyright (c) 2020-2021 Chelsio Communications. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2 or the OpenIB.org BSD license
- * below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer.
- *      - Redistributions in binary form must reproduce the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer in the documentation and/or other materials
- *	  provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#ifndef __CHTCP_IOCTL_H__
-#define __CHTCP_IOCTL_H__
-
-#define CHTCP_MODULE_VERSION		"3.14.0.3"
-
-#define CHTCP_MAX_ADAPTER_NUM	(4)
-#define CHTCP_MAX_PORT		(4)
-#define CHTCP_PCI_DEVNAME_LEN	(32)
-
-enum {
-	CHTCP_IOCTL_GET_DEV_INFO 	= 0,
-	CHTCP_IOCTL_ALLOC_TXQ,
-	CHTCP_IOCTL_ALLOC_RXQ,
-	CHTCP_IOCTL_CPL_PASS_OPEN,
-	CHTCP_IOCTL_CPL_CLOSE_LISTSRV_REQ,
-	CHTCP_IOCTL_CPL_PASS_ACCEPT_REQ,
-	CHTCP_IOCTL_CPL_CLOSE_LISTSRV_RPL,
-	CHTCP_IOCTL_GET_TID_INFO,
-	CHTCP_IOCTL_FREE_SOCK,
-	CHTCP_IOCTL_FREE_TXQ,
-	CHTCP_IOCTL_FREE_RXQ,
-	CHTCP_IOCTL_CHECK_ARP_FAILURE,
-	CHTCP_IOCTL_RELEASE_TID,
-	CHTCP_IOCTL_SETUP_CONM_CTX,
-	CHTCP_IOCTL_MAXNR,			
-};
-
-#define	CHTCP_IOCTL_MAGIC	(0x5D)
-
-/* IOCTLs for CHTCP  */
-#define CHTCP_IOCTL_GET_DEV_INFO_CMD	\
-_IOR(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_GET_DEV_INFO, struct chtcp_adapter_info)
-
-struct chtcp_adapter_info {
-	__u64 bar2_length;
-	__u8 pci_devname[CHTCP_PCI_DEVNAME_LEN];
-	__u8 nports;
-	__u8 pf;
-	__u8 wr_cred;
-	__u8 fl_buf_idx;
-	__u32 fl_buf_size;
-	__u32 fl_starve_thres;
-	__u32 fl_align;
-	__u32 sge_fl_db;
-	__u32 stat_len;
-	__u32 pktshift;
-	__u16 mtus[NMTUS];
-	enum chip_type adapter_type;
-};
-
-#define CHTCP_IOCTL_ALLOC_TXQ_CMD	\
-_IOWR(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_ALLOC_TXQ, struct chtcp_txq_info)
-
-struct chtcp_txq_info {
-	union {
-		struct {
-			__u64 phys_addr;
-			__u32 nentries;
-			__u8 port_id;
-		} in;
-		struct {
-			__u32 cntxt_id;
-			__u32 bar2_qid;
-			__u64 bar2_offset;
-		} out;
-	} u;
-};
-
-
-#define CHTCP_IOCTL_ALLOC_RXQ_CMD	\
-_IOWR(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_ALLOC_RXQ, struct chtcp_rxq_info)
-
-struct chtcp_rxq_info {
-	union {
-		struct {
-			__u64 q_phys_addr;
-			__u32 q_size;
-			__u32 iqe_len;
-			__u64 fl_addr;
-			__u32 fl_size;
-			__u8 port_id;
-			__u8 pack_en;
-		} in;
-		struct {
-			__u16 q_cntxt_id;
-			__u16 q_abs_id;
-			__u32 q_bar2_qid;
-			__u64 q_bar2_offset;
-			__u8 pack_en;
-			__u16 fl_cntxt_id;
-			__u32 fl_bar2_qid;
-			__u64 fl_bar2_offset;
-		} out;
-	} u;
-};
-
-#define	CHTCP_IOCTL_CPL_PASS_OPEN_CMD	\
-_IOWR(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_CPL_PASS_OPEN, struct chtcp_create_server_info)
-
-struct chtcp_sock_addr {
-	__u32 tcp_port;
-	__u8 ip_addr[16];
-};
-
-struct chtcp_create_server_info {
-	union {
-		struct {
-			struct chtcp_sock_addr addr;
-			__u16 rss_iq[CHTCP_MAX_PORT];
-			__u8 is_ipv4;
-		} in;
-		struct {
-			__u32 stid;
-			__u32 port_id;
-			__u16 ss_family;
-		} out;
-	} u;
-};
-
-#define CHTCP_IOCTL_CPL_CLOSE_LISTSRV_REQ_CMD	\
-_IOW(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_CPL_CLOSE_LISTSRV_REQ, struct chtcp_free_server_info)
-
-#define CHTCP_IOCTL_CPL_CLOSE_LISTSRV_RPL_CMD	\
-_IOW(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_CPL_CLOSE_LISTSRV_RPL, struct chtcp_free_server_info)
-
-struct chtcp_free_server_info {
-	__u32 stid;
-	__u16 rss_qid;
-};
-
-#define CHTCP_IOCTL_CPL_PASS_ACCEPT_REQ_CMD	\
-_IOWR(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_CPL_PASS_ACCEPT_REQ, struct chtcp_conn_info)
-
-#ifndef __user
-#define __user
-#endif
-struct chtcp_conn_info {
-	void __user *res;
-	union {
-		struct {
-			__u32 pkt_len;
-			__u32 tid;
-			__u16 port_id;
-			__u16 rss_qid;
-		} in;
-		struct {
-			__u32 tx_chan;
-			__u32 snd_win;
-			__u32 rcv_win;
-			__u8 is_ipv4;
-			struct chtcp_sock_addr local_addr;
-			struct chtcp_sock_addr remote_addr;
-		} out;
-	} u;
-};
-
-#define CHTCP_IOCTL_GET_TID_INFO_CMD	\
-_IOR(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_GET_TID_INFO, struct chtcp_tid_info)
-
-struct chtcp_tid_info {
-	__u32 ntids;
-	__u32 nstids;
-	__u32 natids;
-	__u32 tid_base;
-	__u32 stid_base;
-};
-
-#define CHTCP_IOCTL_FREE_TXQ_CMD	\
-_IOW(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_FREE_TXQ, struct chtcp_free_txq_info)
-
-struct chtcp_free_txq_info {
-	__u8 port_id;
-	__u32 eq_id;
-};
-
-#define CHTCP_IOCTL_FREE_RXQ_CMD	\
-_IOW(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_FREE_RXQ, struct chtcp_free_rxq_info)
-
-struct chtcp_free_rxq_info {
-	__u8 port_id;
-	__u32 iq_id;
-	__u32 fl_id;
-};
-
-#define CHTCP_IOCTL_CHECK_ARP_FAILURE_CMD	\
-_IOWR(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_CHECK_ARP_FAILURE, struct chtcp_arp_info)
-
-struct chtcp_arp_info {
-	union {
-		__u32 tid;
-		__u8 arp_failed;
-	} u;
-};
-
-#define CHTCP_IOCTL_FREE_SOCK_CMD 	\
-_IOW(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_FREE_SOCK, __u32)
-
-#define CHTCP_IOCTL_RELEASE_TID_CMD	\
-_IOW(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_RELEASE_TID, __u32)
-
-#define CHTCP_IOCTL_SETUP_CONM_CTX_CMD	\
-_IOWR(CHTCP_IOCTL_MAGIC, CHTCP_IOCTL_SETUP_CONM_CTX, struct chtcp_conm_ctx_info)
-
-/* congestion manager context info */
-struct chtcp_conm_ctx_info {
-	__u8 port_id;
-	__u32 iq_id;
-};
- 
-#endif /* __CHTCP_IOCTL_H__ */
diff -r 30 src/network/chtcp/chtcp_kcm.c
--- a/src/network/chtcp/chtcp_kcm.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1102 +0,0 @@
-/*
- * Copyright (c) 2020-2021 Chelsio Communications. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2 or the OpenIB.org BSD license
- * below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer.
- *      - Redistributions in binary form must reproduce the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer in the documentation and/or other materials
- *	  provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#include <linux/net.h>
-#include <linux/inet.h>
-#include <net/tcp.h>
-#include "common.h"
-#include "cxgb4_ofld.h"
-#include "chtcp_kmain.h"
-#include "chtcp_ioctl.h"
-#include "chtcp_kcm.h"
-#include "t4_msg.h"
-#include "clip_tbl.h"
-
-static int chtcp_release_tid(struct chtcp_kadapter *dev, u32 tid);
-
-static int chtcp_inaddr_any(struct sockaddr_storage *sockaddr)
-{
-	u16 ss_family = sockaddr->ss_family;
-	int ret = -1;
-
-	if (ss_family == AF_INET) {
-		struct sockaddr_in *sin;
-
-		sin = (struct sockaddr_in *)sockaddr;
-		ret = (sin->sin_addr.s_addr == cpu_to_be32(INADDR_ANY)) ? 1 : 0;
-	}
-#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-	else if (ss_family == AF_INET6) {
-		struct sockaddr_in6 *sin6;
-		int addr_type;
-
-		sin6 = (struct sockaddr_in6 *)sockaddr;
-		addr_type = ipv6_addr_type((const struct in6_addr *)
-				&sin6->sin6_addr);
-		ret = (addr_type == IPV6_ADDR_ANY) ? 1 : 0;
-	}
-#endif
-
-	return ret;
-}
-
-static struct net_device *chtcp_get_real_dev(struct net_device *ndev)
-{
-	if (ndev->priv_flags & IFF_BONDING) {
-		pr_err("Bond devices are not supported. Interface:%s\n",
-			ndev->name);
-		return NULL;
-	}
-
-	if (is_vlan_dev(ndev))
-		return vlan_dev_real_dev(ndev);
-
-	return ndev;
-}
-
-static struct net_device *chtcp_ipv4_netdev(__be32 saddr)
-{
-	struct net_device *ndev;
-
-	ndev = __ip_dev_find(&init_net, saddr, false);
-	if (!ndev)
-		return NULL;
-
-	return chtcp_get_real_dev(ndev);
-}
-
-static struct net_device *chtcp_ipv6_netdev(struct in6_addr *addr6)
-{
-	struct net_device *ndev = NULL;
-	bool found = false;
-
-#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-	for_each_netdev_rcu(&init_net, ndev) {
-		if (ipv6_chk_addr(&init_net, addr6, ndev, 1)) {
-			found = true;
-			break;
-		}
-	}
-#endif
-
-	if (!found)
-		return NULL;
-
-	return chtcp_get_real_dev(ndev);
-}
-
-static struct net_device *
-chtcp_find_np_device(struct chtcp_kadapter *dev,
-		     struct sockaddr_storage *sockaddr, u16 ss_family)
-{
-	struct net_device *ndev = NULL;
-
-	if (ss_family == AF_INET) {
-		struct sockaddr_in *sin;
-
-		sin = (struct sockaddr_in *)sockaddr;
-		ndev = 	chtcp_ipv4_netdev(sin->sin_addr.s_addr);
-
-	} else if (ss_family == AF_INET6){
-		struct sockaddr_in6 *sin6;
-
-		sin6 = (struct sockaddr_in6 *)sockaddr;
-		ndev = chtcp_ipv6_netdev(&sin6->sin6_addr);
-	}
-
-	return ndev;
-}
-
-static int chtcp_find_device(struct chtcp_kadapter *dev,
-			     struct net_device *ndev, u8 *port_id)
-{
-	u8 i;
-	struct cxgb4_lld_info *lldi = &dev->lldi;
-
-	for (i = 0; i < lldi->nports ; i++) {
-		if (lldi->ports[i] == ndev) {
-			if (port_id)
-				*port_id = i;
-			return i;
-		}
-	}
-
-	return -1;
-}
-
-static int chtcp_create_server4(struct chtcp_kadapter *dev,
-		struct net_device *ndev, int stid,
-		struct sockaddr_storage *sockaddr, u16 rss_iq)
-{
-	struct sockaddr_in *sin = (struct sockaddr_in *)sockaddr;
-	struct port_info *p_info;
-	int ret = 0;
-
-	p_info = netdev_priv(ndev);
-	ret = __cxgb4_create_server(ndev, stid, sin->sin_addr.s_addr,
-				    sin->sin_port, 0, rss_iq,
-				    &p_info->tx_chan);
-	if (!ret) {
-		pr_info("created server4: stid %d laddr %pI4 lport %d\n",
-			stid, &sin->sin_addr, cpu_to_be16(sin->sin_port));
-	}
-	if (ret) {
-		pr_err("create server failed err %d stid %d laddr %pI4 lport %d\n",
-			ret, stid, &sin->sin_addr, cpu_to_be16(sin->sin_port));
-		ret = -ENOMEM;
-	}
-	return ret;
-}
-
-static int chtcp_create_server6(struct chtcp_kadapter *dev,
-		struct net_device *ndev, int stid,
-		struct sockaddr_storage *sockaddr, u16 rss_iq)
-{
-	struct sockaddr_in6 *sin6 = (struct sockaddr_in6 *)sockaddr;
-	struct port_info *p_info;
-	int ret;
-
-	pr_debug("%s: dev = %s; stid = %d; sin6_port = %u\n",
-		__func__, ndev->name, stid, sin6->sin6_port);
-
-	p_info = netdev_priv(ndev);
-	ret = __cxgb4_create_server6(ndev, stid, &sin6->sin6_addr,
-				     sin6->sin6_port, rss_iq,
-				     &p_info->tx_chan);
-	if (!ret) {
-		pr_info("created server6: stid %d laddr %pI6 lport %d\n",
-			stid, sin6->sin6_addr.s6_addr,
-			cpu_to_be16(sin6->sin6_port));
-	}
-	if (ret) {
-		pr_err("create server6 err %d stid %d laddr %pI6 lport %d\n",
-			ret, stid, sin6->sin6_addr.s6_addr,
-			cpu_to_be16(sin6->sin6_port));
-		ret = -ENOMEM;
-	}
-
-	return 0;
-}
-
-static int
-chtcp_setup_cdev_np(struct chtcp_kadapter *dev,
-		    struct sockaddr_storage *sockaddr,
-		    struct chtcp_create_server_info *serv_info)
-{
-	struct net_device *ndev = NULL;
-	int stid, port;
-	u16 ss_family = sockaddr->ss_family;
-	int ret = 0;
-	u16 rss_iq;
-
-	ndev = chtcp_find_np_device(dev, sockaddr, ss_family);
-	if (!ndev) {
-		pr_err("%s: unable to get network device\n",
-			pci_name(dev->lldi.pdev));
-		return -ENODEV;
-	}
-	port = chtcp_find_device(dev, ndev, NULL);
-	if (port < 0) {
-		pr_err("%s: failed to match network device\n",
-			pci_name(dev->lldi.pdev));
-		return -ENXIO;
-	}
-
-	rss_iq = serv_info->u.in.rss_iq[port];
-
-	stid = cxgb4_alloc_stid(dev->lldi.tids, ss_family, dev);
-	if (stid < 0) {
-		pr_err("failed to allocate stid\n");
-		return -ENOMEM;
-	}
-	if (ss_family == AF_INET)
-		ret = chtcp_create_server4(dev, ndev, stid, sockaddr, rss_iq);
-	else
-		ret = chtcp_create_server6(dev, ndev, stid, sockaddr, rss_iq);
-
-	if (ret < 0) {
-		cxgb4_free_stid(dev->lldi.tids, stid, ss_family);
-		goto out;
-	}
-
-	serv_info->u.out.port_id = port;
-	serv_info->u.out.stid = stid;
-	serv_info->u.out.ss_family = ss_family;
-out:
-	return ret;
-}
-
-int chtcp_handle_pass_open_req(struct chtcp_kadapter *dev,
-			       void __user *useraddr)
-{
-	struct chtcp_create_server_info s_info;
-	struct chtcp_klisten_sock *lcsk;
-	struct sockaddr_storage addr;
-	int rc = 0;
-
-	rc = copy_from_user(&s_info, useraddr, sizeof(s_info));
-	if (rc)
-		return -EFAULT;
-
-	lcsk = kzalloc(sizeof(struct chtcp_klisten_sock), GFP_KERNEL);
-	if (!lcsk) {
-		pr_err("%s: failed to allocated memory for lcsk\n", __func__);
-		return -ENOMEM;
-	}
-
-	memset(&addr, 0, sizeof(addr));
-	if (s_info.u.in.is_ipv4) {
-		struct sockaddr_in *sin = (struct sockaddr_in *)&addr;
-		sin->sin_family = AF_INET;
-		sin->sin_port = cpu_to_be16(s_info.u.in.addr.tcp_port);
-		sin->sin_addr.s_addr = *(__be32 *)s_info.u.in.addr.ip_addr;
-	}else {
-		struct sockaddr_in6 *sin6 = (struct sockaddr_in6 *)&addr;
-		sin6->sin6_family = AF_INET6;
-		sin6->sin6_port = cpu_to_be16(s_info.u.in.addr.tcp_port);
-		memcpy(sin6->sin6_addr.s6_addr, s_info.u.in.addr.ip_addr,
-		       sizeof(s_info.u.in.addr.ip_addr));
-	}
-
-	rc = chtcp_inaddr_any(&addr);
-	if (rc)
-		return -ENOTSUPP; /* IPV6 kernel config disabled */
-
-	rc = chtcp_setup_cdev_np(dev, &addr, &s_info);
-	if (rc < 0) {
-		pr_err("%s: failed to create server\n", pci_name(dev->lldi.pdev));
-		return rc;
-	}
-
-	pr_info("%s: server created successfully, stid: %u, port iface: %u\n",
-		 pci_name(dev->lldi.pdev), s_info.u.out.stid, s_info.u.out.port_id);
-
-	if (copy_to_user(useraddr, &s_info, sizeof(s_info))) {
-		rc = -EFAULT;
-		goto out;
-	}
-
-	lcsk->port_id = s_info.u.out.port_id;
-	lcsk->stid = s_info.u.out.stid;
-	lcsk->ss_family = s_info.u.out.ss_family;
-
-	INIT_LIST_HEAD(&lcsk->acsk_list);
-	mutex_init(&lcsk->acsk_lock);
-
-	mutex_lock(&dev->lcsk_lock);
-	list_add_tail(&lcsk->lcsk_link, &dev->lcsk_list);
-	mutex_unlock(&dev->lcsk_lock);
-	return 0;
-
-out:
-	return rc;
-}
-
-static struct chtcp_klisten_sock *
-chtcp_get_klisten_sock(struct chtcp_kadapter *dev, u32 stid)
-{
-	struct chtcp_klisten_sock *lcsk, *tmp;
-
-	list_for_each_entry_safe(lcsk, tmp, &dev->lcsk_list, lcsk_link) {
-		if (lcsk->stid == stid) {
-			return lcsk;
-		}
-	}
-
-	return NULL;
-}
-
-int chtcp_remove_server(struct chtcp_kadapter *dev,
-			struct chtcp_klisten_sock *lcsk, u16 rss_qid)
-{
-	u32 stid = lcsk->stid;
- 	u32 port_id = lcsk->port_id;
-	u16 ss_family = lcsk->ss_family;
- 	struct net_device *ndev = dev->lldi.ports[port_id];
- 	int ret = 0;
-
-	if (!ndev) {
-		pr_err("Invalid net device\n");
-		return -ENODEV;
-	}
-
-	ret = cxgb4_remove_server(ndev, stid, rss_qid, ss_family == PF_INET6);
-	if (!ret) {
-		pr_info("%s: server removed successfully stid: %u\n",
-			pci_name(dev->lldi.pdev), stid);
-	} else if (ret) {
-		pr_err("%s: failed to destory server tid: %u\n",
-			pci_name(dev->lldi.pdev), stid);
-		ret = -ENOMEM;
-	}
-	return ret;
-}
-
-int chtcp_handle_close_listsrv_req(struct chtcp_kadapter *dev,
-				   void __user *useraddr)
-{
-	struct chtcp_free_server_info s_info;
-	struct chtcp_klisten_sock *lcsk;
-	int rc = 0;
-
-	rc = copy_from_user(&s_info, useraddr, sizeof(s_info));
-	if (rc)
-		return -EFAULT;
-
-	mutex_lock(&dev->lcsk_lock);
-	lcsk = chtcp_get_klisten_sock(dev, s_info.stid); 
-	if (!lcsk) {
-		pr_err("Error: No listen sock found with stid %u\n",
-		       s_info.stid);
-		mutex_unlock(&dev->lcsk_lock);
-		return -EFAULT;
-	}
-
-	rc = chtcp_remove_server(dev, lcsk, s_info.rss_qid);
-	mutex_unlock(&dev->lcsk_lock);
-
-	return rc;
-}
-
-static void
-chtcp_get_tuple_info(struct cpl_pass_accept_req *req,
-		     enum chip_type adapter_type, u32 *iptype,
-		     __u8 *local_ip, __u8 *peer_ip,
-		     __be16 *local_port, __be16 *peer_port)
-{
-	u32 eth_len = is_t5(adapter_type) ?
-			G_ETH_HDR_LEN(be32_to_cpu(req->hdr_len)) :
-			G_T6_ETH_HDR_LEN(be32_to_cpu(req->hdr_len));
-	u32 ip_len = is_t5(adapter_type) ?
-			G_IP_HDR_LEN(be32_to_cpu(req->hdr_len)) :
-			G_T6_IP_HDR_LEN(be32_to_cpu(req->hdr_len));
-	struct iphdr *ip = (struct iphdr *)((u8 *)(req + 1) + eth_len);
-	struct ipv6hdr *ip6 = (struct ipv6hdr *)((u8 *)(req + 1) + eth_len);
-	struct tcphdr *tcp = (struct tcphdr *)
-                               ((u8 *)(req + 1) + eth_len + ip_len);
-	if (ip->version == 4) {
-		pr_debug("%s saddr 0x%x daddr 0x%x sport %u dport %u\n",
-			 __func__, be32_to_cpu(ip->saddr), be32_to_cpu(ip->daddr),
-			 be16_to_cpu(tcp->source), be16_to_cpu(tcp->dest));
-
-		*iptype = 4;
-		memcpy(peer_ip, &ip->saddr, 4);
-		memcpy(local_ip, &ip->daddr, 4);
-	} else {
-		pr_debug("%s saddr %pI6 daddr %pI6 sport %u dport %u\n",
-			  __func__, ip6->saddr.s6_addr, ip6->daddr.s6_addr,
-			  be16_to_cpu(tcp->source), be16_to_cpu(tcp->dest));
-		*iptype = 6;
-		memcpy(peer_ip, ip6->saddr.s6_addr, 16);
-		memcpy(local_ip, ip6->daddr.s6_addr, 16);
-	}
-	*peer_port = tcp->source;
-	*local_port = tcp->dest;
-}
-
-static int
-chtcp_our_interface(struct chtcp_kadapter *dev, struct net_device *egress_dev)
-{
-	u8 i;
-	egress_dev = chtcp_get_real_dev(egress_dev);
-	for (i = 0; i < dev->lldi.nports; i++)
-		if (dev->lldi.ports[i] == egress_dev)
-			return 1;
-	return 0;
-}
-
-static struct dst_entry *
-chtcp_find_route(struct chtcp_kadapter *dev, __be32 local_ip,
-		 __be32 peer_ip, __be16 local_port,
-		 __be16 peer_port, u8 tos, struct net_device *ndev)
-{
-	struct rtable *rt;
-	struct flowi4 fl4;
-	struct neighbour *n;
-
-	rt = ip_route_output_ports(&init_net, &fl4, NULL, peer_ip,
-				   local_ip, peer_port, local_port,
-				   IPPROTO_TCP, tos, ndev->ifindex);
-	if (IS_ERR(rt))
-		return NULL;
-	n = dst_neigh_lookup(&rt->dst, &peer_ip);
-	if(!n)
-		return NULL;
-	if ((ndev != n->dev) ||
-	    (!chtcp_our_interface(dev, n->dev) &&
-	     !(n->dev->flags & IFF_LOOPBACK))) {
-		neigh_release(n);
-		dst_release(&rt->dst);
-		return NULL;
-	}
-	neigh_release(n);
-	return &rt->dst;
-}
-
-static struct dst_entry *
-chtcp_find_route6(struct chtcp_kadapter *dev, __u8 *local_ip, __u8 *peer_ip,
-		  __be16 local_port, __be16 peer_port, u8 tos,
-		  struct net_device *ndev)
-{
-	struct dst_entry *dst = NULL;
-
-#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-	if (IS_ENABLED(CONFIG_IPV6)) {
-		struct flowi6 fl6;
-
-		memset(&fl6, 0, sizeof(fl6));
-		memcpy(&fl6.daddr, peer_ip, 16);
-		memcpy(&fl6.saddr, local_ip, 16);
-		fl6.flowi6_oif = ndev->ifindex;
-		dst = ip6_route_output(&init_net, NULL, &fl6);
-		if (dst->error ||
-		    (ndev != ip6_dst_idev(dst)->dev) ||
-		    (!chtcp_our_interface(dev, ip6_dst_idev(dst)->dev) &&
-		     !(ip6_dst_idev(dst)->dev->flags & IFF_LOOPBACK))) {
-			dst_release(dst);
-			return NULL;
-		}
-	}
-#endif
-	return dst;
-}
-
-static unsigned int chtcp_snd_win = 128 * 1024;
-module_param(chtcp_snd_win, uint, S_IRUGO);
-MODULE_PARM_DESC(chtcp_snd_win, "TCP send window in bytes (default = 128KB)");
-
-static unsigned int chtcp_rcv_win = 128 * 1024;
-module_param(chtcp_rcv_win, uint, S_IRUGO);
-MODULE_PARM_DESC(chtcp_rcv_win, "TCP receive window in bytes (default = 128KB)");
-
-static void
-chtcp_set_tcp_window(struct chtcp_sock_info *csk_info)
-{
-
-	csk_info->snd_win = min(chtcp_snd_win, 512U * 1024);
-	csk_info->rcv_win = min3(chtcp_rcv_win, M_RCV_BUFSIZ << 10,
-				 512U * 1024);
-
-	pr_debug("%s snd_win %d rcv_win %d\n",
-		 __func__, csk_info->snd_win, csk_info->rcv_win);
-}
-
-static int
-chtcp_offload_init(struct chtcp_sock_info *csk_info, int iptype, __u8 *peer_ip,
-		    u16 local_port, struct dst_entry *dst,
-		    struct chtcp_kadapter *cdev)
-{
-	struct neighbour *n;
-	struct net_device *ndev;
-	u16 port_id;
-	struct port_info *pi;
-	int ret;
-
-	n = dst_neigh_lookup(dst, peer_ip);
-	if (!n)
-		return -ENODEV;
-	rcu_read_lock();
-	if (!(n->nud_state & NUD_VALID))
-		neigh_event_send(n, NULL);
-
-	ret = -ENOMEM;
-	ndev = chtcp_get_real_dev(n->dev);
-	if (!ndev) {
-		ret = -ENODEV;
-		goto out;
-	}
-	csk_info->l2t = cxgb4_l2t_get(cdev->lldi.l2t, n, ndev, 0);
-	if (!csk_info->l2t)
-		goto out;
-	port_id = cxgb4_port_idx(ndev);
-	csk_info->mtu = dst_mtu(dst);
-	csk_info->tx_chan = cxgb4_port_chan(ndev);
-	csk_info->rx_chan = cxgb4_port_e2cchan(ndev);
-	pi = (struct port_info *)netdev_priv(ndev);
-	csk_info->smac_idx = pi->smt_idx;
-	csk_info->ctrlq_idx = cxgb4_port_idx(ndev);
-	csk_info->port_id = port_id;
-	chtcp_set_tcp_window(csk_info);
-	ret = 0;
-out:
-	rcu_read_unlock();
-	neigh_release(n);
-	return ret;
-}
-
-static void
-chtcp_best_mtu(struct chtcp_sock_info *csk_info, unsigned int *idx, int use_ts)
-{
-	const struct chtcp_kadapter *cdev = csk_info->com.dev;
-	const struct cxgb4_lld_info *lldi = &cdev->lldi;
-	const unsigned short *mtus = csk_info->com.dev->lldi.mtus;
-	bool ipv6 = csk_info->com.remote_addr.ss_family == AF_INET;
-	unsigned short hdr_size = (ipv6 ? sizeof(struct ipv6hdr) :
-				sizeof(struct iphdr)) +
-				sizeof(struct tcphdr) +
-				(use_ts ? round_up(TCPOLEN_TIMESTAMP, 4) : 0);
-	unsigned short data_size = csk_info->mtu - hdr_size;
-	unsigned short data_align_size = 8;
-	if (CHELSIO_CHIP_VERSION(lldi->adapter_type) > CHELSIO_T5)
-		data_align_size = 1;
-	cxgb4_best_aligned_mtu(mtus, hdr_size, data_size, data_align_size, idx);
-}
-
-static u32 chtcp_compute_wscale(u32 win)
-{
-	u32 wscale = 0;
-
-	while (wscale < 14 && (65535 << wscale) < win)
-		wscale++;
-
-	return wscale;
-}
-
-static void chtcp_pass_accept_rpl_arp_failure(void *handle, struct sk_buff *skb)
-{
-	struct chtcp_ksock *csk = (struct chtcp_ksock *)handle;
-
-	pr_err("debug: %s: WARN: arp failed tid %u\n", __func__, csk->tid);
-	atomic_set(&csk->arp_failed, 1);
-}
-
-static int
-chtcp_pass_accept_rpl(struct chtcp_sock_info *csk_info,
-		      struct cpl_pass_accept_req *req)
-{
-	struct sk_buff *skb;
-	const struct tcphdr *tcph;
-	struct cxgb4_lld_info *lldi = &csk_info->com.dev->lldi;
-	struct cpl_t5_pass_accept_rpl *rpl5;
-	u32 len = roundup(sizeof(*rpl5), 16);
-	u32 mtu_idx;
-	u64 opt0;
-	u32 opt2, hlen;
-	u32 wscale;
-	u32 win;
-	int ret = 0;
-
-	skb = alloc_skb(len, GFP_KERNEL);
-	if (!skb) {
-		pr_err("failed to allocate skb\n");
-		return -ENOMEM;
-	}
-	rpl5 = (struct cpl_t5_pass_accept_rpl *)__skb_put(skb, len);
-	memset(rpl5, 0, len);
-
-	INIT_TP_WR(rpl5, csk_info->tid);
-	OPCODE_TID(rpl5) = cpu_to_be32(MK_OPCODE_TID(CPL_PASS_ACCEPT_RPL,
-				       csk_info->tid));
-	chtcp_best_mtu(csk_info, &mtu_idx, req->tcpopt.tstamp);
-	wscale = chtcp_compute_wscale(csk_info->rcv_win);
-	win = csk_info->rcv_win >> 10;
-	if (win > M_RCV_BUFSIZ)
-		win = M_RCV_BUFSIZ;
-	opt0 =  F_TCAM_BYPASS |
-		V_WND_SCALE(wscale) |
-		V_MSS_IDX(mtu_idx) |
-		V_L2T_IDX(csk_info->l2t->idx) |
-		V_TX_CHAN(csk_info->tx_chan) |
-		V_SMAC_SEL(csk_info->smac_idx) |
-		V_DSCP(csk_info->tos >> 2) |
-		V_ULP_MODE(ULP_MODE_TCPDDP) |
-		V_RCV_BUFSIZ(win);
-
-	opt2 = V_RX_CHANNEL(csk_info->rx_chan) |
-		F_RSS_QUEUE_VALID | V_RSS_QUEUE(csk_info->rss_qid);
-
-	opt2 |= F_RX_FC_DISABLE;
-
-	if (req->tcpopt.tstamp)
-		opt2 |= F_TSTAMPS_EN;
-
-	if (req->tcpopt.sack)
-		opt2 |= F_SACK_EN;
-
-	if (wscale)
-		opt2 |= F_WND_SCALE_EN;
-
-	hlen = be32_to_cpu(req->hdr_len);
-
-	if (is_t5(lldi->adapter_type))
-		tcph = (const void *)(req + 1) + G_ETH_HDR_LEN(hlen) +
-			G_IP_HDR_LEN(hlen);
-	else
-		tcph = (const void *)(req + 1) + G_T6_ETH_HDR_LEN(hlen) +
-			G_T6_IP_HDR_LEN(hlen);
-	if (tcph->ece && tcph->cwr)
-		opt2 |= V_CCTRL_ECN(1);
-
-	opt2 |= V_CONG_CNTRL(CONG_ALG_NEWRENO);
-	opt2 |= F_T5_ISS;
-	rpl5->iss = cpu_to_be32((prandom_u32() & ~7UL) - 1);
-	opt2 |= F_T5_OPT_2_VALID;
-	rpl5->opt0 = cpu_to_be64(opt0);
-	rpl5->opt2 = cpu_to_be32(opt2);
-	set_wr_txq(skb, CPL_PRIORITY_SETUP, csk_info->ctrlq_idx);
-	t4_set_arp_err_handler(skb, csk_info, chtcp_pass_accept_rpl_arp_failure);
-	ret = cxgb4_l2t_send(csk_info->com.dev->lldi.ports[0], skb,
-			     csk_info->l2t);
-	if (net_xmit_eval(ret) != NET_XMIT_SUCCESS) {
-		kfree_skb(skb) ;
-		ret = -EINVAL;
-	}
-	return ret;
-}
-
-struct net_device *
-chtcp_get_ipv4_netdev(__be32 saddr)
-{
-	struct net_device *ndev = NULL;
-	ndev = __ip_dev_find(&init_net, saddr, false);
-
-	return ndev;
-}
-
-struct net_device *
-chtcp_get_ipv6_netdev(struct in6_addr *addr6)
-{
-	struct net_device *ndev = NULL;
-
-#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-	for_each_netdev_rcu(&init_net, ndev) {
-		if (ipv6_chk_addr(&init_net, addr6, ndev, 1))
-			break;
-	}
-#endif
-
-	return ndev;
-}
-
-static struct net_device *
-chtcp_find_ndev(struct chtcp_kadapter *dev, u8 *saddr, u16 ss_family,
-		u16 port_id)
-{
-	struct net_device *ndev = NULL;
-
-	if (ss_family == AF_INET)
-		ndev = chtcp_get_ipv4_netdev(*(__be32 *)saddr);
-	else {
-		struct sockaddr_in6 sin6;
-
-		memset(&sin6, 0, sizeof(sin6));
-		sin6.sin6_family = AF_INET6;
-		memcpy(&sin6.sin6_addr.s6_addr, saddr, 16);
-		ndev = chtcp_get_ipv6_netdev(&sin6.sin6_addr);
-	}
-
-	if (!ndev) {
-		pr_err("failed to find the network device\n");
-		return NULL;
-	}
-
-	if (ndev->priv_flags & IFF_BONDING) {
-		pr_err("Bond devices are not supported. Interface:%s\n",
-			ndev->name);
-		return NULL;
-	}
-
-	if (is_vlan_dev(ndev)) {
-		struct net_device *real = vlan_dev_real_dev(ndev);
-
-		if (real == dev->lldi.ports[port_id])
-			return ndev;
-	} else {
-		if (ndev == dev->lldi.ports[port_id])
-			return ndev;
-	}
-
-	return NULL;
-}
-
-static int
-chtcp_pass_accept_req(struct chtcp_kadapter *dev,
-		      struct chtcp_conn_info *conn_info)
-{
-	struct chtcp_klisten_sock *lcsk;
-	struct cpl_pass_accept_req *req;
-	struct tid_info *t = dev->lldi.tids;
-	struct chtcp_ksock *csk;
-	struct net_device *ndev;
-	struct chtcp_sock_info csk_info;
-	void *mbuf;
-	u32 stid, tid;
-	u16 peer_mss;
-	struct dst_entry *dst;
-	__u8 local_ip[16], peer_ip[16];
-	__be16 local_port, peer_port;
-	u16 hdrs;
-	u32 iptype;
-	int rc = 0;
-
-	mbuf = kzalloc(conn_info->u.in.pkt_len, GFP_KERNEL);
-	if (!mbuf) {
-		pr_err("Memory allocation failed\n");
-		rc = -ENOMEM;
-		goto reject;
-	}
-	rc = copy_from_user(mbuf, conn_info->res, conn_info->u.in.pkt_len);
-	if (rc) {
-		pr_err("Failed to copy user data\n");
-		rc = -EFAULT;
-		goto out;
-	}
-
-	req = (struct cpl_pass_accept_req *)mbuf;
-	stid = G_PASS_OPEN_TID(be32_to_cpu(req->tos_stid));
-	tid = GET_TID(req);
-	peer_mss = be16_to_cpu(req->tcpopt.mss);
-
-	
-	chtcp_get_tuple_info(req, dev->lldi.adapter_type, &iptype,
-			     local_ip, peer_ip, &local_port, &peer_port);
-	if (iptype == 4)  {
-		pr_info("%s: tid %u laddr %pI4 raddr %pI4 "
-			"lport %d rport %d peer_mss %u\n",
-			pci_name(dev->lldi.pdev), tid, local_ip,
-			peer_ip, be16_to_cpu(local_port),
-			be16_to_cpu(peer_port), peer_mss);
-		ndev = chtcp_find_ndev(dev, local_ip, AF_INET,
-					     conn_info->u.in.port_id);
-		if (!ndev) {
-			pr_err("%s: failed to find ndev for ip %pI4\n",
-				pci_name(dev->lldi.pdev), local_ip);
-			goto out;
-		}
-
-		dst = chtcp_find_route(dev, *(__be32 *)local_ip,
-				*(__be32 *)peer_ip,
-				local_port, peer_port,
-				G_PASS_OPEN_TOS(be32_to_cpu(req->tos_stid)),
-				ndev);
-	} else {
-		pr_info("%s: tid %u laddr %pI6 raddr %pI6 "
-			"lport %d rport %d peer_mss %u\n",
-			pci_name(dev->lldi.pdev), tid, local_ip, peer_ip,
-			be16_to_cpu(local_port),
-			be16_to_cpu(peer_port), peer_mss);
-		ndev = chtcp_find_ndev(dev, local_ip, AF_INET6,
-				       conn_info->u.in.port_id);
-		if (!ndev) {
-			pr_err("%s: failed to find ndev for ip %pI4\n",
-				pci_name(dev->lldi.pdev), local_ip);
-			goto out;
-		}
-
-		dst = chtcp_find_route6(dev, local_ip, peer_ip,
-					local_port, peer_port,
-					G_PASS_OPEN_TOS(be32_to_cpu(req->tos_stid)),
-					ndev);
-	}
-	if (!dst) {
-		pr_err("%s - failed to find dst entry!\n",
-			__func__);
-		rc = -EHOSTUNREACH;
-		goto out;
-	}
-	csk = kzalloc(sizeof(struct chtcp_ksock), GFP_KERNEL);
-	if (!csk) {
-		dst_release(dst);
-		rc = -ENOMEM;
-		goto out;
-	}
-
-	rc = chtcp_offload_init(&csk_info, iptype, peer_ip,
-				be16_to_cpu(local_port), dst, dev);
-	if (rc) {
-		pr_err("%s - failed to allocate l2t entry!\n",
-			__func__);
-		dst_release(dst);
-		kfree(csk);
-		goto out;
-	}
-	hdrs = (iptype == 4 ? sizeof(struct iphdr) : sizeof(struct ipv6hdr)) +
-		sizeof(struct tcphdr) + (req->tcpopt.tstamp ? 12 : 0);
-
-	if (peer_mss && (csk_info.mtu > (peer_mss + hdrs)))
-		csk_info.mtu = peer_mss + hdrs;
-	atomic_set(&csk->arp_failed, 0);
-	csk_info.com.dev = dev;
-	csk_info.tos = G_PASS_OPEN_TOS(be32_to_cpu(req->tos_stid));
-	csk_info.dst = dst;
-	csk_info.tid = tid;
-	csk_info.wr_cred = dev->lldi.wr_cred -
-			    DIV_ROUND_UP(sizeof(struct cpl_abort_req), 16);
-	csk_info.wr_max_cred = csk_info.wr_cred;
-	csk_info.wr_una_cred = 0;
-	csk_info.rss_qid = conn_info->u.in.rss_qid;
-	if (iptype == 4) {
-		struct sockaddr_in *sin = (struct sockaddr_in *)&csk_info.com.local_addr;
-		sin->sin_family = AF_INET;
-		sin->sin_port = local_port;
-		sin->sin_addr.s_addr = *(__be32 *)local_ip;
-		sin = (struct sockaddr_in *)&csk_info.com.remote_addr;
-		sin->sin_family = AF_INET;
-		sin->sin_port = peer_port;
-		sin->sin_addr.s_addr = *(__be32 *)peer_ip;
-
-		conn_info->u.out.is_ipv4 = 1;
-		conn_info->u.out.local_addr.tcp_port = local_port;
-		memcpy(conn_info->u.out.local_addr.ip_addr, local_ip,
-		       sizeof(conn_info->u.out.local_addr.ip_addr));
-		conn_info->u.out.remote_addr.tcp_port = peer_port;
-		memcpy(conn_info->u.out.remote_addr.ip_addr, peer_ip,
-		       sizeof(conn_info->u.out.remote_addr.ip_addr));
-	} else {
-		struct sockaddr_in6 *sin6 = (struct sockaddr_in6 *)
-					    &csk_info.com.local_addr;
-		sin6->sin6_family = PF_INET6;
-		sin6->sin6_port = local_port;
-		memcpy(sin6->sin6_addr.s6_addr, local_ip, 16);
-		cxgb4_clip_get(dev->lldi.ports[0],
-				(const u32 *)&sin6->sin6_addr.s6_addr,
-				1);
-		sin6 = (struct sockaddr_in6 *)&csk_info.com.remote_addr;
-		sin6->sin6_family = PF_INET6;
-		sin6->sin6_port = peer_port;
-		memcpy(sin6->sin6_addr.s6_addr, peer_ip, 16);
-
-		conn_info->u.out.is_ipv4 = 0;
-		conn_info->u.out.local_addr.tcp_port = local_port;
-		memcpy(conn_info->u.out.local_addr.ip_addr, local_ip,
-		       sizeof(conn_info->u.out.local_addr.ip_addr));
-		conn_info->u.out.remote_addr.tcp_port = peer_port;
-		memcpy(conn_info->u.out.remote_addr.ip_addr, peer_ip,
-		       sizeof(conn_info->u.out.remote_addr.ip_addr));
-	}
-
-	csk->dev = csk_info.com.dev;
-	csk->local_addr = csk_info.com.local_addr;
-	csk->l2t = csk_info.l2t;
-	csk->dst = csk_info.dst;
-	csk->tid = csk_info.tid;
-	if (iptype == 4)
-		cxgb4_insert_tid(t, csk, tid,
-				((struct sockaddr_in*)&csk->local_addr)->sin_family);
-	else
-		cxgb4_insert_tid(t, csk, tid,
-				((struct sockaddr_in6 *)&csk->local_addr)->sin6_family);
-
-	rc = chtcp_pass_accept_rpl(&csk_info, req);
-	if (rc < 0) {
-		chtcp_free_kcsk(dev, tid);
-		kfree(mbuf);
-		return rc;
-	}
-	conn_info->u.out.tx_chan = csk_info.tx_chan;
-	conn_info->u.out.snd_win = csk_info.snd_win;
-	conn_info->u.out.rcv_win = csk_info.rcv_win;
-	mutex_lock(&dev->lcsk_lock);
-	lcsk = chtcp_get_klisten_sock(dev, stid); 
-	if (!lcsk) {
-		pr_err("Error: No listen sock found with stid %u\n", stid);
-		mutex_unlock(&dev->lcsk_lock);
-		goto out;
-	}
-
-	mutex_lock(&lcsk->acsk_lock);
-	list_add_tail(&csk->acsk_link, &lcsk->acsk_list);
-	mutex_unlock(&lcsk->acsk_lock);
-	mutex_unlock(&dev->lcsk_lock);
-	kfree(mbuf);
-
-	return rc;
-out:
-	kfree(mbuf);
-reject:
-	chtcp_release_tid(dev, conn_info->u.in.tid);
-	return rc;
-}
-
-int chtcp_handle_pass_accept_req(struct chtcp_kadapter *dev,
-				 void __user *useraddr)
-{
-	struct chtcp_conn_info conn_info;
-	int rc = 0;
-
-	rc = copy_from_user(&conn_info, useraddr, sizeof(conn_info));
-	if (rc)
-		return -EFAULT;
-
-	rc = chtcp_pass_accept_req(dev, &conn_info);
-	if (rc < 0)
-		return rc;
-
-	if (copy_to_user(useraddr, &conn_info, sizeof(conn_info)))
-		return -EFAULT;
-
-	return rc;
-}
-
-int chtcp_handle_close_listsrv_rpl(struct chtcp_kadapter *dev, u32 stid)
-{
-	struct chtcp_klisten_sock *lcsk;
-	int rc = 0;
-	u16 ss_family;
-
-	mutex_lock(&dev->lcsk_lock);
-	lcsk = chtcp_get_klisten_sock(dev, stid); 
-	if (!lcsk) {
-		pr_err("Error: No listen sock found with stid %u\n", stid);
-		mutex_unlock(&dev->lcsk_lock);
-		return -EFAULT;
-	}
-	ss_family = lcsk->ss_family;
-	list_del(&lcsk->lcsk_link);
-	kfree(lcsk);
-	mutex_unlock(&dev->lcsk_lock);
-
-	cxgb4_free_stid(dev->lldi.tids, stid, ss_family);
-	return rc;
-}
-
-void chtcp_free_kcsk(struct chtcp_kadapter *dev, u32 tid)
-{
-	struct chtcp_ksock *csk;
-
-	csk = lookup_tid(dev->lldi.tids, tid);
-	if (unlikely(!csk)) {
-		pr_err("%s: can't find connection for tid %u.\n",
-			pci_name(dev->lldi.pdev), tid);
-		return;
-	}
-
-	if (csk->tid != tid) {
-		pr_err("%s: WARNING: %s: csk->tid %u != tid %u\n",
-			pci_name(dev->lldi.pdev), __func__, csk->tid, tid);
-		return;
-	}
-
-	if (csk->local_addr.ss_family == AF_INET6) {
-		struct sockaddr_in6 *sin6 = (struct sockaddr_in6 *)
-			&csk->local_addr;
-		cxgb4_clip_release(dev->lldi.ports[0],
-				(const u32 *)
-				&sin6->sin6_addr.s6_addr, 1);
-	}
-
-	cxgb4_remove_tid(dev->lldi.tids, 0, tid,
-			 csk->local_addr.ss_family);
-
-	dst_release(csk->dst);
-	cxgb4_l2t_release(csk->l2t);
-	list_del(&csk->acsk_link);
-
-	kfree(csk);
-}
-
-int chtcp_handle_free_sock(struct chtcp_kadapter *dev, void __user *useraddr)
-{
-	int rc = 0;
-	u32 tid;
-
-	rc = copy_from_user(&tid, useraddr, sizeof(u32));
-	if(rc)
-		return -EFAULT;
-	chtcp_free_kcsk(dev, tid);
-
-	return rc;
-}
-
-static int chtcp_release_tid(struct chtcp_kadapter *dev, u32 tid)
-{
-	struct cpl_tid_release *req;
-	u32 len = roundup(sizeof(*req), 16);
-	struct sk_buff *skb;
-	int ret = 0;
-
-	skb = alloc_skb(len, GFP_KERNEL);
-	if (!skb)
-		return -ENOMEM;
-
-	req = (struct cpl_tid_release *)__skb_put(skb, len);
-	memset(req, 0, len);
-	INIT_TP_WR(req, tid);
-	OPCODE_TID(req) = cpu_to_be32(MK_OPCODE_TID(
-			CPL_TID_RELEASE, tid));
-
-	set_wr_txq(skb, CPL_PRIORITY_SETUP, 0);
-	ret = cxgb4_ofld_send(dev->lldi.ports[0], skb);
-	if (ret < 0)
-		kfree_skb(skb);
-
-	return ret < 0 ? ret : 0;
-}
-
-int chtcp_handle_release_tid(struct chtcp_kadapter *dev, void __user *useraddr)
-{
-	int rc = 0;
-	u32 tid;
-
-	rc = copy_from_user(&tid, useraddr, sizeof(tid));
-	if (rc)
-		return -EFAULT;
-	rc = chtcp_release_tid(dev, tid);
-	return rc;
-}
-
-static bool check_arp_failure(struct chtcp_kadapter *dev, u32 tid)
-{
-	struct chtcp_ksock *csk;
-
-	csk = lookup_tid(dev->lldi.tids, tid);
-	if (unlikely(!csk)) {
-		pr_err("%s: WARNING: can't find connection for tid %u.\n",
-			pci_name(dev->lldi.pdev), tid);
-		WARN_ON(1);
-		return false;
-	}
-
-	if (csk->tid != tid) {
-		pr_err("%s: WARNING: %s: csk->tid %u != tid %u\n",
-			pci_name(dev->lldi.pdev), __func__, csk->tid, tid);
-		WARN_ON(1);
-		return false;
-	}
-
-	if (atomic_read(&csk->arp_failed))
-		return true;
-
-	return false;
-}
-
-int chtcp_handle_arp_failure(struct chtcp_kadapter *dev, void __user *useraddr)
-{
-	struct chtcp_arp_info arp_info;
-	int rc = 0;
-
-	rc = copy_from_user(&arp_info, useraddr, sizeof(struct chtcp_arp_info));
-	if(rc)
-		return -EFAULT;
-	arp_info.u.arp_failed = check_arp_failure(dev, arp_info.u.tid);
-	if (copy_to_user(useraddr, &arp_info, sizeof(struct chtcp_arp_info)))
-		return -EFAULT;
-
-	return rc;
-}
diff -r 30 src/network/chtcp/chtcp_kcm.h
--- a/src/network/chtcp/chtcp_kcm.h	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,43 +0,0 @@
-/*
- * Copyright (c) 2020-2021 Chelsio Communications. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2 or the OpenIB.org BSD license
- * below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer.
- *      - Redistributions in binary form must reproduce the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer in the documentation and/or other materials
- *	  provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#ifndef	__CHTCP_KCM_H__
-#define	__CHTCP_KCM_H__
-
-int chtcp_handle_pass_open_req(struct chtcp_kadapter *dev, void __user *useraddr);
-int chtcp_handle_close_listsrv_req(struct chtcp_kadapter *dev, void __user *useraddr);
-int chtcp_handle_pass_accept_req(struct chtcp_kadapter *dev, void __user *useraddr);
-int chtcp_handle_close_listsrv_rpl(struct chtcp_kadapter *dev, u32 stid);
-int chtcp_handle_free_sock(struct chtcp_kadapter *dev, void __user *useraddr);
-int chtcp_handle_release_tid(struct chtcp_kadapter *dev, void __user *useraddr);
-int chtcp_handle_arp_failure(struct chtcp_kadapter *dev, void __user *useraddr);
-void chtcp_free_kcsk(struct chtcp_kadapter *dev, u32 tid);
-int chtcp_remove_server(struct chtcp_kadapter *dev,
-			struct chtcp_klisten_sock *lcsk, u16 rss_qid);
-#endif
diff -r 30 src/network/chtcp/chtcp_kmain.c
--- a/src/network/chtcp/chtcp_kmain.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,550 +0,0 @@
-/*
- * Copyright (c) 2020-2021 Chelsio Communications. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2 or the OpenIB.org BSD license
- * below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer.
- *      - Redistributions in binary form must reproduce the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer in the documentation and/or other materials
- *	  provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#include<linux/version.h>
-#include<linux/module.h>
-#include<linux/moduleparam.h>
-#include<linux/kernel.h>
-#include<linux/pci.h>
-#include<linux/net.h>
-#include<linux/inet.h>
-#include<linux/errno.h>
-#include "common.h"
-#include "t4_regs.h"
-#include "cxgb4_ofld.h"
-#include "chtcp_kmain.h"
-#include "chtcp_kcm.h"
-#include "chtcp_ioctl.h"
-#include "t4_msg.h"
-#include "clip_tbl.h"
-
-#define CHTCP_DRV_MODULE_NAME         "chtcp"
-
-static LIST_HEAD(chtcp_list);
-static DEFINE_MUTEX(chtcp_list_lock);
-static	atomic_t index = ATOMIC_INIT(0);
-
-static dev_t chtcp_dev;
-static struct class *chtcp_class;
-static void chtcp_free_all_queues(struct chtcp_kadapter *dev);
-static void chtcp_del_sock_list(struct chtcp_kadapter *dev);
-
-static char *chtcp_pci_address = NULL;
-module_param(chtcp_pci_address, charp, S_IRUGO);
-MODULE_PARM_DESC(chtcp_pci_address, " PCI device address of the adapters to be"
-		 " enabled (e.g 0000:01:00.4,0000:02:00.4 ). "
-		 "All T5/T6 adapters are enabled by default");
-
-int chtcp_open(struct inode *inode, struct file *filp)
-{
-	struct chtcp_kadapter *dev;
-	struct cdev *cdev = filp->f_inode->i_cdev;
-
-	dev = container_of(cdev, struct chtcp_kadapter, chtcp_cdev);
-
-	mutex_lock(&dev->adap_lock);
-	if (dev->file_in_use) {
-		/* don't allow device file open more than 1 time */
-		pr_err("%s: %s device file already opened\n",
-			pci_name(dev->lldi.pdev), __func__);
-
-		mutex_unlock(&dev->adap_lock);
-		return -EPERM;
-	}
-	dev->file_in_use = true;
-	mutex_unlock(&dev->adap_lock);
-
-	return 0;
-}
-
-int chtcp_close(struct inode *inode, struct file *filp)
-{
-	struct chtcp_kadapter *dev;
-	struct cdev *cdev = filp->f_inode->i_cdev;
-
-	dev = container_of(cdev, struct chtcp_kadapter, chtcp_cdev);
-
-	/* check if app terminated abnormally */
-	if (!list_empty(&dev->lcsk_list) &&
-	    (!list_empty(&dev->ktxq_list) || !list_empty(&dev->krxq_list)))
-		chtcp_infinite_wait();
-
-	chtcp_del_sock_list(dev);
-
-	mutex_lock(&dev->adap_lock);
-	chtcp_free_all_queues(dev);
-	dev->file_in_use = false;
-	mutex_unlock(&dev->adap_lock);
-
-	return 0;
-}
-
-static void
-chtcp_get_tid_info(struct chtcp_kadapter *dev, struct chtcp_tid_info *t)
-{
-	struct tid_info *tid = dev->lldi.tids;
-
-	memset(t, 0, sizeof(*t));
-	t->ntids = tid->ntids;
-	t->nstids = tid->nstids;
-	t->natids = tid->natids;
-	t->tid_base = tid->tid_base;
-	t->stid_base = tid->stid_base;
-}
-
-static int chtcp_mmap(struct file *flip, struct vm_area_struct *vma)
-{
-	struct cdev *cdev = flip->f_inode->i_cdev;
-	size_t size;
-	struct chtcp_kadapter *dev;
-	struct pci_dev *pdev;
-	int ret = 0;
-
-	if (((phys_addr_t)vma->vm_pgoff) != 0)
-		return -EINVAL;
-
-	size = vma->vm_end - vma->vm_start;
-
-	dev = container_of(cdev, struct chtcp_kadapter, chtcp_cdev);
-	pdev = dev->lldi.pdev;
-	if (size != pci_resource_len(pdev, CHTCP_PCI_BAR_NUM))
-		return -EINVAL;
-
-	vma->vm_pgoff += (pci_resource_start(pdev, CHTCP_PCI_BAR_NUM) >> PAGE_SHIFT);
-	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
-
-	ret = io_remap_pfn_range(vma, vma->vm_start, vma->vm_pgoff, size,
-				vma->vm_page_prot);
-
-	return ret;
-}
-
-static int chtcp_handle_get_device_info(struct chtcp_kadapter *dev,
-					void __user *useraddr)
-{
-	struct chtcp_adapter_info adap_info;
-	struct adapter *adap;
-	struct sge *s;
-	u32 i;
-
-	adap = dev->adap;
-	s = &adap->sge;
-	adap_info.nports = dev->lldi.nports;
-	adap_info.pf = dev->lldi.pf;
-	adap_info.fl_starve_thres = s->fl_starve_thres;
-	adap_info.stat_len = dev->lldi.sge_egrstatuspagesize;
-	adap_info.fl_align = dev->lldi.sge_ingpadboundary;
-	adap_info.sge_fl_db = adap->params.arch.sge_fl_db;
-	adap_info.bar2_length = pci_resource_len(dev->lldi.pdev,
-						 CHTCP_PCI_BAR_NUM);
-	if (!PAGE_ALIGNED(adap_info.bar2_length))
-		return -EINVAL;
-	adap_info.pktshift = dev->lldi.sge_pktshift;
-	adap_info.adapter_type = dev->lldi.adapter_type;
-	adap_info.wr_cred = dev->lldi.wr_cred;
-
-	adap_info.fl_buf_size = 0;
-	for (i = 0; i < 16; i++) {
-		u32 reg_addr = A_SGE_FL_BUFFER_SIZE0 + (i * sizeof(u32));
-		u32 fl_buf_size = t4_read_reg(adap, reg_addr);
-
-#define CHTCP_FL_BUF_SIZE	9216
-		if (fl_buf_size == CHTCP_FL_BUF_SIZE) {
-			adap_info.fl_buf_idx = i;
-			adap_info.fl_buf_size = fl_buf_size;
-			break;
-		}
-	}
-
-	if (!adap_info.fl_buf_size) {
-		pr_err("%s: %s: fl buffer idx not found\n",
-		       pci_name(dev->lldi.pdev), __func__);
-		return -EINVAL;
-	}
-
-	memcpy(adap_info.mtus, dev->lldi.mtus, sizeof(adap_info.mtus));
-
-	strlcpy(adap_info.pci_devname, pci_name(dev->lldi.pdev),
-		sizeof(adap_info.pci_devname));
-
-	if (copy_to_user(useraddr, &adap_info,
-			sizeof(struct chtcp_adapter_info)))
-		return -EFAULT;
-	return 0;
-}
-
-static long chtcp_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
-{
-	struct chtcp_kadapter *dev;
-	struct cdev *cdev = filp->f_inode->i_cdev;
-	struct chtcp_txq_info txq_info;
-	struct chtcp_rxq_info rxq_info;
-	struct chtcp_free_txq_info fti;
-	struct chtcp_free_rxq_info fri;
-	struct chtcp_conm_ctx_info conm_ctx;
-	struct chtcp_tid_info t;
-	void *useraddr;
-	u32 stid;
-	int rc = 0;
-
-	if (_IOC_TYPE(cmd) != CHTCP_IOCTL_MAGIC)
-		return -ENOTTY;
-
-	if (_IOC_NR(cmd) > CHTCP_IOCTL_MAXNR)
-		return -ENOTTY;
-
-	useraddr = (void __user *)arg;
-	dev = container_of(cdev, struct chtcp_kadapter, chtcp_cdev);
-
-	mutex_lock(&dev->adap_lock);
-	switch (cmd) {
-	case CHTCP_IOCTL_GET_DEV_INFO_CMD:
-		rc = chtcp_handle_get_device_info(dev, useraddr);
-		break;
-	case CHTCP_IOCTL_ALLOC_TXQ_CMD:
-		rc = copy_from_user(&txq_info, useraddr, sizeof(txq_info));
-		if (rc) {
-			rc = -EFAULT;
-			goto out;
-		}
-		rc = chtcp_ksge_alloc_ofld_txq(dev, &txq_info);
-		if (rc)
-			goto out;
-
-		if (copy_to_user(useraddr, &txq_info, sizeof(txq_info))) {
-			rc = -EFAULT;
-			goto out;
-		}
-
-		break;
-	case CHTCP_IOCTL_ALLOC_RXQ_CMD:
-		rc = copy_from_user(&rxq_info, useraddr, sizeof(rxq_info));
-		if (rc) {
-			rc = -EFAULT;
-			goto out;
-		}
-		rc = chtcp_ksge_alloc_ofld_rxq(dev, &rxq_info);
-		if (rc)
-			goto out;
-
-		if (copy_to_user(useraddr, &rxq_info, sizeof(rxq_info))) {
-			rc = -EFAULT;
-			goto out;
-		}
-		break;
-	case CHTCP_IOCTL_CPL_PASS_OPEN_CMD:
-		rc = chtcp_handle_pass_open_req(dev, useraddr);
-		break;
-	case CHTCP_IOCTL_CPL_CLOSE_LISTSRV_REQ_CMD:
-		rc = chtcp_handle_close_listsrv_req(dev, useraddr);
-		break;
-	case CHTCP_IOCTL_CPL_PASS_ACCEPT_REQ_CMD:
-		rc = chtcp_handle_pass_accept_req(dev, useraddr);
-		break;
-	case CHTCP_IOCTL_CPL_CLOSE_LISTSRV_RPL_CMD:
-		rc = copy_from_user(&stid, useraddr, sizeof(u32));
-		if(rc) {
-			rc = -EFAULT;
-			goto out;
-		}
-		rc = chtcp_handle_close_listsrv_rpl(dev, stid);
-		break;
-	case CHTCP_IOCTL_GET_TID_INFO_CMD:
-		chtcp_get_tid_info(dev, &t);
-		rc = copy_to_user(useraddr, &t, sizeof(t));
-		if (rc) {
-			rc = -EFAULT;
-			goto out;
-		}
-		break;
-	case CHTCP_IOCTL_FREE_SOCK_CMD:
-		rc = chtcp_handle_free_sock(dev, useraddr);
-		break;
-	case CHTCP_IOCTL_FREE_TXQ_CMD:
-		rc = copy_from_user(&fti, useraddr, sizeof(fti));
-		if(rc) {
-			rc = -EFAULT;
-			goto out;
-		}
-		rc = chtcp_kofld_eq_free(dev, &fti);
-		if (!rc)
-			chtcp_free_ktxq_info(dev, &fti);
-		break;
-	case CHTCP_IOCTL_FREE_RXQ_CMD:
-		rc = copy_from_user(&fri, useraddr, sizeof(fri));
-		if(rc) {
-			rc = -EFAULT;
-			goto out;
-		}
-		rc = chtcp_kofld_iq_free(dev, &fri);
-		if (!rc)
-			chtcp_free_krxq_info(dev, &fri);
-		break;
-	case CHTCP_IOCTL_CHECK_ARP_FAILURE_CMD:
-		rc = chtcp_handle_arp_failure(dev, useraddr);
-		break;
-	case CHTCP_IOCTL_RELEASE_TID_CMD:
-		rc = chtcp_handle_release_tid(dev, useraddr);
-		break;
-	case CHTCP_IOCTL_SETUP_CONM_CTX_CMD:
-		rc = copy_from_user(&conm_ctx, useraddr, sizeof(conm_ctx));
-		if(rc) {
-			rc = -EFAULT;
-			goto out;
-		}
-		rc = chtcp_setup_conm_ctx(dev, &conm_ctx);
-		break;
-	default:
-		pr_err("%s: %s Invalid ioctl %u", pci_name(dev->lldi.pdev),
-			__func__, _IOC_NR(cmd));
-	}
-
-out:
-	mutex_unlock(&dev->adap_lock);
-	return rc;
-}
-
-const struct file_operations chtcp_fops = {
-	.owner	=	THIS_MODULE,
-	.open	=	chtcp_open,
-	.mmap   =	chtcp_mmap,
-	.unlocked_ioctl	= chtcp_ioctl,
-	.release	= chtcp_close,
-};
-
-static void *setup_chtcp_device(const struct cxgb4_lld_info *lldi)
-{
-	int ret = 0;
-	struct chtcp_kadapter *dev;
-	struct port_info *pi;
-	char cdevname[20];
-	const char *pci_addr = pci_name(lldi->pdev);
-
-	dev = kzalloc(sizeof(struct chtcp_kadapter), GFP_KERNEL);
-	if (!dev) {
-		pr_err("%s: %s: out of memory\n", pci_addr, __func__);
-		ret = -ENOMEM;
-		goto out;
-	}
-
-	dev->devno = MKDEV(MAJOR(chtcp_dev), (MINOR(chtcp_dev) +
-			   atomic_read(&index)));
-	cdev_init(&dev->chtcp_cdev, &chtcp_fops);
-	if ((ret = cdev_add(&dev->chtcp_cdev, dev->devno, 1)) < 0) {
-		pr_err("%s: %s: failed to add char device\n", pci_addr,
-			__func__);
-		goto free_cdev;
-	}
-
-	scnprintf(cdevname, sizeof(cdevname), "chtcp-%d", atomic_read(&index));
-	dev->pdev = device_create(chtcp_class, NULL, dev->devno, NULL,
-				  cdevname);
-	if (IS_ERR(dev->pdev)) {
-		ret = PTR_ERR(dev->pdev);
-		goto out_unregister_devnode;
-	}
-
-	memcpy(&dev->lldi, lldi ,sizeof(struct cxgb4_lld_info));
-	dev->nports = lldi->nports;
-	pi = netdev_priv(lldi->ports[0]);
-	dev->adap = pi->adapter;
-	INIT_LIST_HEAD(&dev->lcsk_list);
-	INIT_LIST_HEAD(&dev->ktxq_list);
-	INIT_LIST_HEAD(&dev->krxq_list);
-	mutex_init(&dev->lcsk_lock);
-	mutex_init(&dev->adap_lock);
-	mutex_lock(&chtcp_list_lock);
-	list_add_tail(&dev->list_node, &chtcp_list);
-	mutex_unlock(&chtcp_list_lock);
-	atomic_inc(&index);
-
-	return dev;
-out_unregister_devnode:
-	cdev_del(&dev->chtcp_cdev);
-free_cdev:
-	kfree(dev);
-out:
-	return NULL;
-}
-
-static void *chtcp_uld_add(const struct cxgb4_lld_info *lldi)
-{
-	void *handle;
-	const char *pci_addr = pci_name(lldi->pdev);
-
-	if (chtcp_pci_address && !strstr(chtcp_pci_address, pci_addr)) {
-		pr_info("chtcp: adapter %s is not enabled\n", pci_addr);
-		return NULL;
-	}
-
-	handle = setup_chtcp_device(lldi);
-	if (!handle) {
-		pr_err("%s: %s chtcp device bringup failed\n",pci_addr,
-			__func__);
-		goto out;
-	}
-out:
-	return handle;
-}
-
-static int chtcp_uld_state_change(void *handle, enum cxgb4_state new_state)
-{
-	return 0;
-}
-
-const static struct cxgb4_uld_info chtcp_uld_info = {
-	.name =	CHTCP_DRV_MODULE_NAME,
-	.add =	chtcp_uld_add,
-	.state_change =	chtcp_uld_state_change,
-};
-
-#define CHTCP_DRV_MODULE_DESC		"Chelsio T5-T6 CHTCP Driver"
-
-static __init int chtcp_init_module(void)
-{
-	int rc = 0;
-
-	pr_info("%s. \n", CHTCP_DRV_MODULE_DESC " " CHTCP_DRV_MODULE_NAME" v" CHTCP_MODULE_VERSION);
-
-	rc = alloc_chrdev_region(&chtcp_dev, 0, CHTCP_MAX_ADAPTER_NUM,
-				 CHTCP_DRV_MODULE_NAME);
-	if (rc < 0) {
-		pr_err("%s: could not allocate major number\n", __func__);
-		goto out;
-	}
-
-	chtcp_class = class_create(THIS_MODULE, CHTCP_DRV_MODULE_NAME);
-	if (IS_ERR(chtcp_class)) {
-		pr_err("%s: failed to create class\n",__func__);
-		rc = PTR_ERR(chtcp_class);
-		goto destory_chrdev;
-	}
-
-	rc = cxgb4_register_uld_type(CXGB4_ULD_CHTCP, &chtcp_uld_info);
-	if (rc < 0) {
-		pr_err("%s: failed to register uld\n",__func__);
-		goto unregister_uld;
-	}
-
-	return rc;
-
-unregister_uld:
-	class_destroy(chtcp_class);
-destory_chrdev:
-	unregister_chrdev_region(chtcp_dev, CHTCP_MAX_ADAPTER_NUM);
-out:
-	return rc;
-}
-
-static void chtcp_del_sock_list(struct chtcp_kadapter *dev)
-{
-	struct chtcp_klisten_sock *lcsk, *lcsk_tmp;
-
-	mutex_lock(&dev->lcsk_lock);
-	list_for_each_entry_safe(lcsk, lcsk_tmp, &dev->lcsk_list, lcsk_link) {
-		struct chtcp_ksock *acsk, *acsk_tmp;
-
-		mutex_lock(&lcsk->acsk_lock);
-		list_for_each_entry_safe(acsk, acsk_tmp, &lcsk->acsk_list, acsk_link) {
-			/* free accept sock */
-			chtcp_free_kcsk(dev, acsk->tid);
-		}
-		mutex_unlock(&lcsk->acsk_lock);
-
-		/*ret = chtcp_remove_server(dev, lcsk,
-					  dev->lldi.rxq_ids[lcsk->port_id]);
-		if (ret)
-			pr_err("chtcp_remove_server failed: %d\n", ret);*/
-
-	}
-	mutex_unlock(&dev->lcsk_lock);
-}
-
-static void chtcp_free_all_queues(struct chtcp_kadapter *dev)
-{
-	struct chtcp_ktxq_info *txqi, *txq_tmp;
-	struct chtcp_krxq_info *rxqi, *rxq_tmp;
-	int rc;
-
-	list_for_each_entry_safe(txqi, txq_tmp, &dev->ktxq_list, ktxq_link) {
-		struct chtcp_free_txq_info fti;
-
-		list_del(&txqi->ktxq_link);
-		fti.port_id = txqi->port_id;
-		fti.eq_id = txqi->eq_id;
-		rc = chtcp_kofld_eq_free(dev, &fti);
-		if (rc)
-			pr_err("%s: %s: chtcp_kofld_eq_free failed: port id %u eq "
-			       "id %u: rc %d\n", pci_name(dev->lldi.pdev), __func__,
-				fti.port_id, fti.eq_id, rc);
-
-		kfree(txqi);
-	}
-
-	list_for_each_entry_safe(rxqi, rxq_tmp, &dev->krxq_list, krxq_link) {
-		struct chtcp_free_rxq_info fri;
-
-		list_del(&rxqi->krxq_link);
-		fri.port_id = rxqi->port_id;
-		fri.iq_id = rxqi->iq_id;
-		fri.fl_id = rxqi->fl_id;
-		rc = chtcp_kofld_iq_free(dev, &fri);
-		if (rc)
-			pr_err("%s: %s: chtcp_kofld_iq_free failed: port id %u eq "
-			       "id %u: fl id %u: rc %d\n", pci_name(dev->lldi.pdev), __func__,
-				fri.port_id, fri.iq_id, fri.fl_id, rc);
-		kfree(rxqi);
-	}
-}
-
-static __exit void chtcp_exit_module(void)
-{
-	struct chtcp_kadapter *dev, *tmp;
-
-	mutex_lock(&chtcp_list_lock);
-	list_for_each_entry_safe(dev, tmp, &chtcp_list, list_node) {
-		device_destroy(chtcp_class, dev->devno);
-		cdev_del(&dev->chtcp_cdev);
-		list_del(&dev->list_node);
-		kfree(dev);
-	}
-	mutex_unlock(&chtcp_list_lock);
-
-	cxgb4_unregister_uld_type(CXGB4_ULD_CHTCP);
-	class_destroy(chtcp_class);
-	unregister_chrdev_region(chtcp_dev, CHTCP_MAX_ADAPTER_NUM);
-}
-
-module_init(chtcp_init_module);
-module_exit(chtcp_exit_module);
-
-MODULE_AUTHOR("Chelsio Communications, Inc.");
-MODULE_DESCRIPTION(CHTCP_DRV_MODULE_DESC);
-MODULE_VERSION(CHTCP_MODULE_VERSION);
-MODULE_LICENSE("Dual BSD/GPL");
diff -r 30 src/network/chtcp/chtcp_kmain.h
--- a/src/network/chtcp/chtcp_kmain.h	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,138 +0,0 @@
-/*
- * Copyright (c) 2020-2021 Chelsio Communications. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2 or the OpenIB.org BSD license
- * below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer.
- *      - Redistributions in binary form must reproduce the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer in the documentation and/or other materials
- *	  provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#ifndef __CHTCP_K_H__
-#define __CHTCP_K_H__
-
-#include "chtcp_ioctl.h"
-
-#define	CHTCP_PCI_BAR_NUM	(2)
-
-struct chtcp_kadapter {
-	struct list_head list_node;
-	struct cxgb4_lld_info lldi;
-	struct adapter *adap;
-	struct device *pdev;
-	struct cdev chtcp_cdev;
-	dev_t devno;
-	u8 nports;
-	bool file_in_use;
-	struct mutex adap_lock;
-	struct list_head lcsk_list;
-	struct mutex lcsk_lock;
-	struct list_head ktxq_list;
-	struct list_head krxq_list;
-};
-
-struct chtcp_sock_common {
-	struct chtcp_kadapter *dev;
-	struct sockaddr_storage local_addr;
-	struct sockaddr_storage remote_addr;
-	unsigned long flags;
-};
-
-struct chtcp_ksock {
-	struct chtcp_kadapter *dev;
-	struct sockaddr_storage local_addr;
-	struct l2t_entry *l2t;
-	struct dst_entry *dst;
-	atomic_t arp_failed;
-	u32 tid;
-	struct list_head acsk_link;  /* accept sock link */
-};
-
-struct chtcp_klisten_sock {
-	struct chtcp_kadapter *dev;
-	u32 stid;
-	u16 ss_family;
-	u8 port_id;
-	struct list_head lcsk_link;  /* listen sock link */
-	struct list_head acsk_list;  /* accept sock list */
-	struct mutex acsk_lock;
-};
-
-
-struct chtcp_sock_info {
-	struct chtcp_sock_common com;
-	struct l2t_entry *l2t;
-	struct dst_entry *dst;
-	u32 wr_cred;
-	u32 wr_una_cred;
-	u32 wr_max_cred;
-	u32 tid;
-	u32 smac_idx;
-	u32 tx_chan;
-	u32 rx_chan;
-	u32 mtu;
-	u32 snd_win;
-	u32 rcv_win;
-	u16 rss_qid;
-	u16 ctrlq_idx;
-	u8 tos;
-	u8 port_id;
-};
-
-struct chtcp_ktxq_info {
-	__u8 port_id;
-	__u32 eq_id;
-	struct list_head ktxq_link;
-};
-
-struct chtcp_krxq_info {
-	__u8 port_id;
-	__u32 iq_id;
-	__u32 fl_id;
-	struct list_head krxq_link;
-};
-
-static inline void chtcp_infinite_wait(void)
-{
-	struct completion cmpl;
-
-	pr_err("%s: app terminated abnormally: Reboot required\n", __func__);
-	init_completion(&cmpl);
-	wait_for_completion(&cmpl);
-}
-
-
-int chtcp_ksge_alloc_ofld_txq(struct chtcp_kadapter *dev,
-			       struct chtcp_txq_info *txq_info);
-int chtcp_ksge_alloc_ofld_rxq(struct chtcp_kadapter *dev,
-			       struct chtcp_rxq_info *rxq_info);
-int chtcp_kofld_eq_free(struct chtcp_kadapter *dev,
-			 struct chtcp_free_txq_info *fti);
-int chtcp_kofld_iq_free(struct chtcp_kadapter *dev,
-			 struct chtcp_free_rxq_info *fri);
-int chtcp_setup_conm_ctx(struct chtcp_kadapter *dev,
-			 struct chtcp_conm_ctx_info *ctx_info);
-void chtcp_free_krxq_info(struct chtcp_kadapter *dev,
-			  struct chtcp_free_rxq_info *fri);
-void chtcp_free_ktxq_info(struct chtcp_kadapter *dev,
-			  struct chtcp_free_txq_info *fti);
-#endif /* __CHTCP_K_H__ */
diff -r 30 src/network/chtcp/chtcp_ksge.c
--- a/src/network/chtcp/chtcp_ksge.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,369 +0,0 @@
-/*
- * Copyright (c) 2020-2021 Chelsio Communications. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2 or the OpenIB.org BSD license
- * below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer.
- *      - Redistributions in binary form must reproduce the above
- *	  copyright notice, this list of conditions and the following
- *	  disclaimer in the documentation and/or other materials
- *	  provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#include "common.h"
-#include "cxgb4_ofld.h"
-#include "chtcp_ioctl.h"
-#include "chtcp_kmain.h"
-
-void
-chtcp_free_ktxq_info(struct chtcp_kadapter *dev,
-		     struct chtcp_free_txq_info *fti)
-{
-	struct chtcp_ktxq_info *txqi, *txq_tmp;
-
-	list_for_each_entry_safe(txqi, txq_tmp, &dev->ktxq_list, ktxq_link) {
-		if ((txqi->port_id != fti->port_id) ||
-		    (txqi->eq_id != fti->eq_id))
-			continue;
-
-		list_del(&txqi->ktxq_link);
-		kfree(txqi);
-		break;
-	}
-}
-
-void
-chtcp_free_krxq_info(struct chtcp_kadapter *dev,
-		     struct chtcp_free_rxq_info *fri)
-{
-	struct chtcp_krxq_info *rxqi, *rxq_tmp;
-
-	list_for_each_entry_safe(rxqi, rxq_tmp, &dev->krxq_list, krxq_link) {
-		if ((rxqi->port_id != fri->port_id) ||
-		    (rxqi->iq_id != fri->iq_id) ||
-		    (rxqi->fl_id != fri->fl_id))
-			continue;
-
-		list_del(&rxqi->krxq_link);
-		kfree(rxqi);
-		break;
-	}
-}
-
-
-int chtcp_kofld_eq_free(struct chtcp_kadapter *dev,
-			struct chtcp_free_txq_info *fti)
-{
-	struct net_device *ndev = dev->lldi.ports[fti->port_id];
-	struct fw_eq_ofld_cmd c;
-	int ret;
-
-	memset(&c, 0, sizeof(c));
-	c.op_to_vfn = cpu_to_be32(V_FW_CMD_OP(FW_EQ_OFLD_CMD) |
-				  F_FW_CMD_REQUEST | F_FW_CMD_EXEC |
-				  V_FW_EQ_OFLD_CMD_PFN(dev->lldi.pf) |
-				  V_FW_EQ_OFLD_CMD_VFN(0));
-	c.alloc_to_len16 = cpu_to_be32(F_FW_EQ_OFLD_CMD_FREE | FW_LEN16(c));
-	c.eqid_pkd = cpu_to_be32(V_FW_EQ_OFLD_CMD_EQID(fti->eq_id));
-	rtnl_lock();
-	ret = cxgb4_wr_mbox(ndev, &c, sizeof(c), &c);
-	rtnl_unlock();
-	if (ret)
-		pr_err("%s: cxgb4_wr_mbox failed: %d", __FUNCTION__, ret);
-
-	return ret;
-}
-
-int chtcp_kofld_iq_free(struct chtcp_kadapter *dev,
-			 struct chtcp_free_rxq_info *fri)
-{
-	struct net_device *ndev = dev->lldi.ports[fri->port_id];
-	struct fw_iq_cmd c;
-	int ret;
-
-	memset(&c, 0, sizeof(c));
-	c.op_to_vfn = cpu_to_be32(V_FW_CMD_OP(FW_IQ_CMD) | F_FW_CMD_REQUEST |
-				  F_FW_CMD_EXEC | V_FW_IQ_CMD_PFN(dev->lldi.pf) |
-				  V_FW_IQ_CMD_VFN(0));
-	c.alloc_to_len16 = cpu_to_be32(F_FW_IQ_CMD_FREE | FW_LEN16(c));
-	c.type_to_iqandstindex =
-		cpu_to_be32(V_FW_IQ_CMD_TYPE(FW_IQ_TYPE_FL_INT_CAP));
-	c.iqid = cpu_to_be16(fri->iq_id);
-	c.fl0id = cpu_to_be16(fri->fl_id);
-	c.fl1id = cpu_to_be16(0xffff);
-	rtnl_lock();
-	ret = cxgb4_wr_mbox(ndev, &c, sizeof(c), &c);
-	rtnl_unlock();
-	if (ret)
-		pr_err("%s: cxgb4_wr_mbox failed: %d", __FUNCTION__, ret);
-
-	return ret;
-}
-
-int chtcp_ksge_alloc_ofld_txq(struct chtcp_kadapter *dev,
-			       struct chtcp_txq_info *txq_info)
-{
-	u32 nentries = txq_info->u.in.nentries;
-	struct chtcp_free_txq_info fti;
-	struct chtcp_ktxq_info *txqi;
-	struct fw_eq_ofld_cmd c;
-	unsigned int chip_ver;
-	struct adapter *adap;
-	struct net_device *ndev;
-	struct sge *s;
-	u32 cntx_id;
-	u8 port_id;
-	int ret;
-
-	port_id = txq_info->u.in.port_id;
-	ndev = dev->lldi.ports[port_id];
-	adap = dev->adap;
-	s = &adap->sge;
-	cntx_id = s->fw_evtq.cntxt_id;
-
-	chip_ver = CHELSIO_CHIP_VERSION(dev->lldi.adapter_type);
-
-	memset(&c, 0, sizeof(c));
-	c.op_to_vfn = cpu_to_be32(V_FW_CMD_OP(FW_EQ_OFLD_CMD) | F_FW_CMD_REQUEST |
-			    F_FW_CMD_WRITE | F_FW_CMD_EXEC |
-			    V_FW_EQ_OFLD_CMD_PFN(dev->lldi.pf) |
-			    V_FW_EQ_OFLD_CMD_VFN(0));
-	c.alloc_to_len16 = cpu_to_be32(F_FW_EQ_OFLD_CMD_ALLOC |
-				 F_FW_EQ_OFLD_CMD_EQSTART | (sizeof(c) / 16));
-	c.fetchszm_to_iqid =
-		cpu_to_be32(V_FW_EQ_OFLD_CMD_HOSTFCMODE(X_HOSTFCMODE_STATUS_PAGE) |
-		      V_FW_EQ_OFLD_CMD_PCIECHN(cxgb4_port_chan(ndev)) |
-		      F_FW_EQ_OFLD_CMD_FETCHRO | V_FW_EQ_OFLD_CMD_IQID(cntx_id));
-	c.dcaen_to_eqsize =
-		cpu_to_be32(V_FW_EQ_OFLD_CMD_FBMIN(chip_ver <= CHELSIO_T5
-					     ? X_FETCHBURSTMIN_64B
-					     : X_FETCHBURSTMIN_64B_T6) |
-		      V_FW_EQ_OFLD_CMD_FBMAX(X_FETCHBURSTMAX_512B) |
-		      V_FW_EQ_OFLD_CMD_CIDXFTHRESH(X_CIDXFLUSHTHRESH_32) |
-		      V_FW_EQ_OFLD_CMD_EQSIZE(nentries));
-	c.eqaddr = cpu_to_be64(txq_info->u.in.phys_addr);
-
-	rtnl_lock();
-	ret = cxgb4_wr_mbox(ndev, &c, sizeof(c), &c);
-	rtnl_unlock();
-	if (ret) {
-		pr_err("%s: cxgb4_wr_mbox failed: %d", __FUNCTION__, ret);
-		return ret;
-	}
-
-	txq_info->u.out.cntxt_id = G_FW_EQ_OFLD_CMD_EQID(be32_to_cpu(c.eqid_pkd));
-
-	ret = cxgb4_bar2_sge_qregs(ndev, txq_info->u.out.cntxt_id,
-				   T4_BAR2_QTYPE_EGRESS, 1,
-				   &txq_info->u.out.bar2_offset,
-				   &txq_info->u.out.bar2_qid);
-	if (ret) {
-		pr_err("%s: cxgb4_wr_mbox failed: %d", __FUNCTION__, ret);
-		goto free_q;
-	}
-
-	txqi = kzalloc(sizeof(struct chtcp_ktxq_info), GFP_KERNEL);
-        if (!txqi) {
-		pr_err("%s: kzalloc failed for chtcp_ktxq_info: %d",
-		       __FUNCTION__, ret);
-                ret = -ENOMEM;
-		goto free_q;
-        }
-	txqi->eq_id = txq_info->u.out.cntxt_id;
-	txqi->port_id = port_id;
-	list_add_tail(&txqi->ktxq_link, &dev->ktxq_list);
-
-	return 0;
-
-free_q:
-	fti.port_id = port_id;
-	fti.eq_id = txq_info->u.out.cntxt_id;
-	chtcp_kofld_eq_free(dev, &fti);
-	return ret;
-}
-
-/* setup congestion manager context */
-int chtcp_setup_conm_ctx(struct chtcp_kadapter *dev,
-			 struct chtcp_conm_ctx_info *conm_info)
-{
-	struct net_device *ndev;
-	u32 param, val;
-	int ret;
-
-	ndev = dev->lldi.ports[conm_info->port_id];
-
-	/* For T5 and later we attempt to set up the Congestion Manager values
-	 * of the new RX Ethernet Queue.  This should really be handled by
-	 * firmware because it's more complex than any host driver wants to
-	 * get involved with and it's different per chip and this is almost
-	 * certainly wrong.  Firmware would be wrong as well, but it would be
-	 * a lot easier to fix in one place ...  For now we do something very
-	 * simple (and hopefully less wrong).
-	 */
-
-	param = (V_FW_PARAMS_MNEM(FW_PARAMS_MNEM_DMAQ) |
-		 V_FW_PARAMS_PARAM_X(FW_PARAMS_PARAM_DMAQ_CONM_CTXT) |
-		 V_FW_PARAMS_PARAM_YZ(conm_info->iq_id));
-
-	val = V_CONMCTXT_CNGTPMODE(X_CONMCTXT_CNGTPMODE_QUEUE);
-
-	ret = cxgb4_set_params(ndev, 1, &param, &val);
-	if (ret)
-		pr_err("Failed to set Congestion Manager Context for Ingress"
-		       "Queue %d: %d\n", conm_info->iq_id, -ret);
-
-	return ret;
-}
-
-int chtcp_ksge_alloc_ofld_rxq(struct chtcp_kadapter *dev,
-			       struct chtcp_rxq_info *rxq_info)
-{
-	struct chtcp_free_rxq_info fri;
-	struct chtcp_krxq_info *rxqi;
-	int ret;
-	struct fw_iq_cmd c;
-	unsigned int chip_ver;
-	struct net_device *ndev;
-	int pciechan;
-	u32 fl_size;
-	u8 port_id;
-
-	fl_size = rxq_info->u.in.fl_size;
-	port_id = rxq_info->u.in.port_id;
-	ndev = dev->lldi.ports[port_id];
-
-	chip_ver = CHELSIO_CHIP_VERSION(dev->lldi.adapter_type);
-
-	pciechan = cxgb4_port_chan(ndev);
-
-	memset(&c, 0, sizeof(c));
-	c.op_to_vfn = cpu_to_be32(V_FW_CMD_OP(FW_IQ_CMD) | F_FW_CMD_REQUEST |
-			    F_FW_CMD_WRITE | F_FW_CMD_EXEC |
-			    V_FW_IQ_CMD_PFN(dev->lldi.pf) | V_FW_IQ_CMD_VFN(0));
-	c.alloc_to_len16 = cpu_to_be32(F_FW_IQ_CMD_ALLOC | F_FW_IQ_CMD_IQSTART |
-				 FW_LEN16(c));
-	c.type_to_iqandstindex =
-			cpu_to_be32(V_FW_IQ_CMD_TYPE(FW_IQ_TYPE_FL_INT_CAP) |
-			      V_FW_IQ_CMD_IQASYNCH(0) |
-			      V_FW_IQ_CMD_VIID(cxgb4_port_viid(ndev)) |
-			      V_FW_IQ_CMD_IQANDST(0) |
-			      V_FW_IQ_CMD_IQANUD(X_UPDATEDELIVERY_STATUS_PAGE) |
-			      V_FW_IQ_CMD_IQANDSTINDEX(0));
-	c.iqdroprss_to_iqesize = cpu_to_be16(V_FW_IQ_CMD_IQPCIECH(pciechan) |
-				       F_FW_IQ_CMD_IQGTSMODE |
-				       V_FW_IQ_CMD_IQINTCNTTHRESH(0) |
-				       V_FW_IQ_CMD_IQESIZE(
-					ilog2(rxq_info->u.in.iqe_len) - 4));
-
-	c.iqsize = cpu_to_be16(rxq_info->u.in.q_size);
-	c.iqaddr = cpu_to_be64(rxq_info->u.in.q_phys_addr);
-	c.iqns_to_fl0congen = cpu_to_be32(F_FW_IQ_CMD_IQFLINTCONGEN |
-				    V_FW_IQ_CMD_IQTYPE(FW_IQ_IQTYPE_OFLD));
-
-
-	/* filling fl info */
-	c.iqns_to_fl0congen |=
-			cpu_to_be32(V_FW_IQ_CMD_FL0HOSTFCMODE(X_HOSTFCMODE_NONE) |
-			      (rxq_info->u.in.pack_en ?
-			      F_FW_IQ_CMD_FL0PACKEN : 0) |
-			      V_FW_IQ_CMD_FL0FETCHRO(0) |
-			      V_FW_IQ_CMD_FL0DATARO(0) |
-			      F_FW_IQ_CMD_FL0PADEN);
-	c.iqns_to_fl0congen |=
-			cpu_to_be32(F_FW_IQ_CMD_FL0CONGCIF | F_FW_IQ_CMD_FL0CONGEN);
-
-	/* In T6, for egress queue type FL there is internal overhead
-	 * of 16B for header going into FLM module.  Hence the maximum
-	 * allowed burst size is 448 bytes.  For T4/T5, the hardware
-	 * doesn't coalesce fetch requests if more than 64 bytes of
-	 * Free List pointers are provided, so we use a 128-byte Fetch
-	 * Burst Minimum there (T6 implements coalescing so we can use
-	 * the smaller 64-byte value there).
-	 */
-	c.fl0dcaen_to_fl0cidxfthresh =
-		cpu_to_be16(V_FW_IQ_CMD_FL0FBMIN(chip_ver <= CHELSIO_T5
-					   ? X_FETCHBURSTMIN_128B
-					   : X_FETCHBURSTMIN_64B_T6) |
-		      V_FW_IQ_CMD_FL0FBMAX(chip_ver <= CHELSIO_T5
-					   ? X_FETCHBURSTMAX_512B
-					   : X_FETCHBURSTMAX_256B) |
-		      V_FW_IQ_CMD_FL0CIDXFTHRESH(X_CIDXFLUSHTHRESH_1));
-	c.fl0size = cpu_to_be16(rxq_info->u.in.fl_size);
-	c.fl0addr = cpu_to_be64(rxq_info->u.in.fl_addr);
-
-	rtnl_lock();
-	ret = cxgb4_wr_mbox(ndev, &c, sizeof(c), &c);
-	rtnl_unlock();
-	if (ret) {
-		pr_err("%s: cxgb4_wr_mbox failed: %d", __FUNCTION__, ret);
-		return ret;
-	}
-
-	rxq_info->u.out.q_cntxt_id = be16_to_cpu(c.iqid);
-	rxq_info->u.out.q_abs_id = be16_to_cpu(c.physiqid);
-	ret = cxgb4_bar2_sge_qregs(ndev, rxq_info->u.out.q_cntxt_id,
-				   T4_BAR2_QTYPE_INGRESS, 1,
-				   &rxq_info->u.out.q_bar2_offset,
-				   &rxq_info->u.out.q_bar2_qid);
-	if (ret) {
-		pr_err("%s: cxgb4_bar2_sge_qregs failed: %d", __FUNCTION__,
-		       ret);
-		goto free_q;
-	}
-
-	rxq_info->u.out.fl_cntxt_id = be16_to_cpu(c.fl0id);
-
-	/* Note, we must initialize the BAR2 Free List User Doorbell
-	 * information before refilling the Free List!
-	 */
-	ret = cxgb4_bar2_sge_qregs(ndev, rxq_info->u.out.fl_cntxt_id,
-				   T4_BAR2_QTYPE_EGRESS, 1,
-				   &rxq_info->u.out.fl_bar2_offset,
-				   &rxq_info->u.out.fl_bar2_qid);
-	if (ret) {
-		pr_err("%s: cxgb4_bar2_sge_qregs failed: %d", __FUNCTION__,
-		       ret);
-		goto free_q;
-	}
-
-	rxqi = kzalloc(sizeof(struct chtcp_krxq_info), GFP_KERNEL);
-        if (!rxqi) {
-		pr_err("%s: kzalloc failed for chtcp_krxq_info: %d",
-		       __FUNCTION__, ret);
-                ret = -ENOMEM;
-		goto free_q;
-        }
-	rxqi->iq_id = rxq_info->u.out.q_cntxt_id;
-	if (fl_size)
-		rxqi->fl_id = rxq_info->u.out.fl_cntxt_id;
-	else
-		rxqi->fl_id = 0xffff;
-	rxqi->port_id = port_id;
-	list_add_tail(&rxqi->krxq_link, &dev->krxq_list);
-
-	return 0;
-
-free_q:
-	fri.port_id = port_id;
-	fri.iq_id = rxq_info->u.out.q_cntxt_id;
-	fri.fl_id = rxq_info->u.out.fl_cntxt_id;
-	chtcp_kofld_iq_free(dev, &fri);
-	return ret;
-}
diff -r 30 src/network/csiostor/csio_os_dfs.c
--- a/src/network/csiostor/csio_os_dfs.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/csiostor/csio_os_dfs.c	Tue May 18 15:02:47 2021 +0530
@@ -934,11 +934,7 @@
 	int i, r = (uintptr_t)v - 1;
 	int n, base_qset;
 	int iq_cnt = sge_q_entries(seq->private, CSIO_INGRESS);
-	struct dump_q_arr *dq_arr;
-
-	dq_arr = (struct  dump_q_arr *)vmalloc(iq_cnt);
-	if (dq_arr == NULL)
-		return 0;
+	struct dump_q_arr dq_arr[iq_cnt];
 
 	fill_dq(wrm, dq_arr, CSIO_INGRESS);
 
@@ -973,8 +969,6 @@
 	ST("stray_comp:", n_stray_comp);
 	ST("flq_refill:", n_flq_refill);
 
-	vfree(dq_arr);
-
 	return 0;
 }
 
@@ -986,11 +980,7 @@
 	int i, r = (uintptr_t)v - 1;
 	int n, base_qset;
 	int iq_cnt = sge_q_entries(seq->private, CSIO_EGRESS);
-	struct dump_q_arr *dq_arr;
-
-	dq_arr = (struct  dump_q_arr *)vmalloc(iq_cnt);
-	if (dq_arr == NULL)
-		return 0;
+	struct dump_q_arr dq_arr[iq_cnt];
 
 	fill_dq(wrm, dq_arr, CSIO_EGRESS);
 
@@ -1024,7 +1014,6 @@
 	ST("stray_comp:", n_stray_comp);
 	ST("flq_refill:", n_flq_refill);
 
-	vfree(dq_arr);
 	return 0;
 }
 
@@ -1034,14 +1023,10 @@
 	int iq_cnt = sge_q_entries(seq->private, CSIO_FREELIST);
 	struct csio_hw *hw = csio_oshw_to_hw(oshw);
 	struct csio_wrm *wrm = csio_hw_to_wrm(hw);
-	struct dump_q_arr *dq_arr;
+	struct dump_q_arr dq_arr[iq_cnt];
 	int i, r = (uintptr_t)v - 1;
 	int n, base_qset;
 
-	dq_arr = (struct  dump_q_arr *)vmalloc(iq_cnt);
-	if (dq_arr == NULL)
-		return 0;
-
 	fill_dq(wrm, dq_arr, CSIO_FREELIST);
 
 	if (r)
@@ -1075,7 +1060,6 @@
 	ST("stray_comp:", n_stray_comp);
 	ST("flq_refill:", n_flq_refill);
 
-	vfree(dq_arr);
 	return 0;
 }
 
diff -r 30 src/network/csiostor/csio_os_init.c
--- a/src/network/csiostor/csio_os_init.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/csiostor/csio_os_init.c	Tue May 18 15:02:47 2021 +0530
@@ -3287,7 +3287,7 @@
 	pci_set_master(pdev);
 	pci_restore_state(pdev);
 	pci_save_state(pdev);
-	pci_aer_clear_nonfatal_status(pdev);
+	pci_cleanup_aer_uncorrect_error_status(pdev);
 
 	/* Bring HW s/m to ready state.
 	 * but don't resume IOs.
diff -r 30 src/network/csiostor/csio_os_scsi.c
--- a/src/network/csiostor/csio_os_scsi.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/csiostor/csio_os_scsi.c	Tue May 18 15:02:47 2021 +0530
@@ -800,13 +800,21 @@
 		if (sbit_to_uflow & (F_FW_SCSI_ISCSI_RSP_BIDIR_UFLOW |
 					F_FW_SCSI_ISCSI_RSP_BIDIR_OFLOW)) {
 
+			int res_cnt = be32_to_cpu(iresp->bidir_res_cnt);
+
+
 			csio_scsi_vdbg(hw,
 			     "Under-run cmnd:0x%x expected len:0x%x"
 			     " resid:0x%x underflow:0x%x\n",
 			     cmnd->cmnd[0], scsi_bufflen(cmnd),
 			     scsi_get_resid(cmnd), cmnd->underflow);
 			
-			host_status = DID_BAD_TARGET;
+			if (scsi_bidi_cmnd(cmnd) && res_cnt > 0 &&
+				(sbit_to_uflow & F_FW_SCSI_ISCSI_RSP_BIDIR_OFLOW ||
+				 res_cnt <= scsi_in(cmnd)->length))
+				scsi_in(cmnd)->resid = res_cnt;
+			else
+				host_status = DID_BAD_TARGET;
 		}
 		
 		if (sbit_to_uflow & (F_FW_SCSI_ISCSI_RSP_UFLOW |
@@ -1029,13 +1037,16 @@
 	uint32_t nsge = 0;
 	int rv = SCSI_MLQUEUE_HOST_BUSY, nr;
 	enum csio_oss_error retval;
+	int cpu = cmnd->request->cpu;
 	struct csio_scsi_qset *sqset = NULL;
 
 	if(csio_is_fcoe(hw)) {
 		csio_scsi_vdbg(hw, "portid:%d req->cpu:%d curcpu:%d\n",
-			    ln->portid, blk_mq_rq_cpu(cmnd->request),
-			    smp_processor_id());
-		sqset = &oshw->sqset[ln->portid][blk_mq_rq_cpu(cmnd->request)];
+			    ln->portid, cpu, smp_processor_id());
+		if (cpu < 0)
+			cpu = smp_processor_id();
+
+		sqset = &oshw->sqset[ln->portid][cpu]; 
 	}
 
 	nr = csio_os_rnode_chkrdy(hw, osrn, cmnd);
@@ -1380,14 +1391,13 @@
 	/* FW successfully aborted the request */
 	if (host_byte(cmnd->result) == DID_REQUEUE) {
 		csio_info(hw,
-		    	"Aborted SCSI req:%p cmnd:%p to LUN:%llu tag %u\n",
-		    	ioreq, cmnd, (uint64_t)cmnd->device->lun,
-			cmnd->request->tag);
+		    	"Aborted SCSI req:%p cmnd:%p to LUN:%llu slnum:0x%lx\n",
+		    	ioreq, cmnd, (uint64_t)cmnd->device->lun, cmnd->serial_number);
 		return SUCCESS;
 	} else {
 		csio_info(hw,
-		    	"Failed to abort SCSI req:%p to LUN:%llu tag %u\n",
-		    	ioreq, (uint64_t)cmnd->device->lun, cmnd->request->tag);
+		    	"Failed to abort SCSI req:%p to LUN:%llu slnum:0x%lx\n",
+		    	ioreq, (uint64_t)cmnd->device->lun, cmnd->serial_number);
 		return FAILED;
 	}
 }
@@ -1951,7 +1961,7 @@
 	.this_id		= -1,
 	.sg_tablesize		= CSIO_SCSI_FCOE_MAX_SGE,
 	.cmd_per_lun		= CSIO_MAX_CMD_PER_LUN, /* REVISIT */
-	.dma_boundary		= PAGE_SIZE - 1,
+	.use_clustering		= ENABLE_CLUSTERING,
 	.shost_attrs		= csio_fcoe_lport_attrs,
 	.max_sectors		= CSIO_MAX_SECTOR_SIZE,	/* maxIO size */
 };
@@ -1973,7 +1983,7 @@
 	.this_id		= -1,
 	.sg_tablesize		= CSIO_SCSI_FCOE_MAX_SGE,
 	.cmd_per_lun		= CSIO_MAX_CMD_PER_LUN,	/* REVISIT */
-	.dma_boundary		= PAGE_SIZE - 1,
+	.use_clustering		= ENABLE_CLUSTERING,
 	.shost_attrs		= csio_fcoe_vport_attrs,
 	.max_sectors		= CSIO_MAX_SECTOR_SIZE,	/* maxIO size */
 };
@@ -2001,7 +2011,7 @@
 	.this_id		= -1,
 	.sg_tablesize		= CSIO_SCSI_ISCSI_MAX_SGE,
 	.cmd_per_lun		= CSIO_MAX_CMD_PER_LUN,
-	.dma_boundary		= PAGE_SIZE - 1,
+	.use_clustering		= ENABLE_CLUSTERING,
 /* REVISIT: ISCSI */
 #if 0
 	.shost_attrs		= csio_iscsi_attrs,
diff -r 30 src/network/csiostor/t4_linux_debugfs.c
--- a/src/network/csiostor/t4_linux_debugfs.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/csiostor/t4_linux_debugfs.c	Tue May 18 15:02:47 2021 +0530
@@ -2950,6 +2950,7 @@
 	};
 
 	int i;
+	struct dentry *de;
 
 	if (!adap->debugfs_root)
 		return -1;
@@ -2991,7 +2992,7 @@
 					A_MA_EXT_MEMORY1_BAR)));
 	}
 
-	debugfs_create_file_size("flash", S_IRUSR, adap->debugfs_root, adap,
+	de = debugfs_create_file_size("flash", S_IRUSR, adap->debugfs_root, adap,
 				 &flash_debugfs_fops, adap->params.sf_size);
 	debugfs_create_bool("use_backdoor", S_IWUSR | S_IRUSR,
 			    adap->debugfs_root, &adap->use_bd);
@@ -3003,7 +3004,7 @@
 	if (adap->dma_virt) {
 		printk("DMA buffer at bus address %#llx, virtual 0x%p\n",
 			(unsigned long long)adap->dma_phys, adap->dma_virt);
-		debugfs_create_file_size("dmabuf", 0644, adap->debugfs_root,
+		de = debugfs_create_file_size("dmabuf", 0644, adap->debugfs_root,
 					 adap, &dma_debugfs_fops, DMABUF_SZ);
 	}
 #endif
diff -r 30 src/network/cudbg_inc/osdep.h
--- a/src/network/cudbg_inc/osdep.h	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/cudbg_inc/osdep.h	Tue May 18 15:02:47 2021 +0530
@@ -1,4 +1,3 @@
-
 #ifndef __CXGB4_OSDEP_H
 #define __CXGB4_OSDEP_H
 
@@ -14,15 +13,5 @@
 #define strncpy_s(dst, dst_size, src, count) strncpy(dst, src, count)
 #endif
 
-
-#if defined(WIN32) || defined(__NT__) || defined(_WIN32) || defined(__WIN32__)
-#define memcpy_s( p_dest, count, p_src, count1)           \
-				do {								      \
-                 ASSERT(count >= count1)    ;              \
-                 RtlCopyMemory(p_dest, p_src, count1);    \
-				} while (0)                               //Use the universal api instead of  CRT
-#endif              
- 
-
 #endif  /* !__CXGB4_OSDEP_H */
 
diff -r 30 src/network/cxgb4/cxgb4_cudbg.c
--- a/src/network/cxgb4/cxgb4_cudbg.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/cxgb4/cxgb4_cudbg.c	Tue May 18 15:02:47 2021 +0530
@@ -59,8 +59,8 @@
 static void do_collect(struct adapter *adap, void *buf, unsigned long size)
 {
 	struct cudbg_param *dbg_param;
-	struct timespec64 ts;
 	void *handle = NULL;
+	struct timespec ts;
 	int ret;
 	u32 i;
 
@@ -95,7 +95,7 @@
 
 	cxgb4_cudbg_fill_default_dbg_params(adap);
 
-	ktime_get_ts64(&ts);
+	getnstimeofday(&ts);
 	cudbg.dbg_params[CUDBG_TIMESTAMP_PARAM].u.time = ts.tv_sec;
 	cudbg.dbg_params[CUDBG_TIMESTAMP_PARAM].param_type =
 			CUDBG_TIMESTAMP_PARAM;
diff -r 30 src/network/cxgb4/cxgb4_ethtool.c
--- a/src/network/cxgb4/cxgb4_ethtool.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/cxgb4/cxgb4_ethtool.c	Tue May 18 15:02:47 2021 +0530
@@ -1667,10 +1667,6 @@
 }
 
 static const struct ethtool_ops cxgb_ethtool_ops = {
-	.supported_coalesce_params = ETHTOOL_COALESCE_USECS |
-				     ETHTOOL_COALESCE_RX_MAX_FRAMES |
-				     ETHTOOL_COALESCE_TX_USECS_IRQ |
-				     ETHTOOL_COALESCE_USE_ADAPTIVE_RX,
 	.get_link_ksettings = get_link_ksettings,
 	.set_link_ksettings = set_link_ksettings,
 	.get_fecparam      = get_fecparam,
diff -r 30 src/network/cxgb4/cxgb4_main.c
--- a/src/network/cxgb4/cxgb4_main.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/cxgb4/cxgb4_main.c	Tue May 18 15:02:47 2021 +0530
@@ -6967,7 +6967,7 @@
 	pci_save_state(pdev);
 
 	if (aer)
-		pci_aer_clear_nonfatal_status(pdev);
+		pci_cleanup_aer_uncorrect_error_status(pdev);
 
 	if (t4_wait_dev_ready(adap) < 0) {
 		if (cxgb_enable_pci_device(adap))
diff -r 30 src/network/cxgb4/sge.c
--- a/src/network/cxgb4/sge.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/cxgb4/sge.c	Tue May 18 15:02:47 2021 +0530
@@ -312,7 +312,7 @@
 		const skb_frag_t *fp = &si->frags[i];
 
 		sg_set_page(s, skb_frag_page(fp),
-			    skb_frag_size(fp), skb_frag_off(fp));
+			    skb_frag_size(fp), fp->page_offset);
 	}
 	*nents = dma_map_sg(dev, sgl, orig_nents, DMA_TO_DEVICE);
 	if (!(*nents))
diff -r 30 src/network/cxgb4/t4_linux_debugfs.c
--- a/src/network/cxgb4/t4_linux_debugfs.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/cxgb4/t4_linux_debugfs.c	Tue May 18 15:02:47 2021 +0530
@@ -2950,6 +2950,7 @@
 	};
 
 	int i;
+	struct dentry *de;
 
 	if (!adap->debugfs_root)
 		return -1;
@@ -2991,7 +2992,7 @@
 					A_MA_EXT_MEMORY1_BAR)));
 	}
 
-	debugfs_create_file_size("flash", S_IRUSR, adap->debugfs_root, adap,
+	de = debugfs_create_file_size("flash", S_IRUSR, adap->debugfs_root, adap,
 				 &flash_debugfs_fops, adap->params.sf_size);
 	debugfs_create_bool("use_backdoor", S_IWUSR | S_IRUSR,
 			    adap->debugfs_root, &adap->use_bd);
@@ -3003,7 +3004,7 @@
 	if (adap->dma_virt) {
 		printk("DMA buffer at bus address %#llx, virtual 0x%p\n",
 			(unsigned long long)adap->dma_phys, adap->dma_virt);
-		debugfs_create_file_size("dmabuf", 0644, adap->debugfs_root,
+		de = debugfs_create_file_size("dmabuf", 0644, adap->debugfs_root,
 					 adap, &dma_debugfs_fops, DMABUF_SZ);
 	}
 #endif
diff -r 30 src/network/cxgb4vf/cxgb4vf_main.c
--- a/src/network/cxgb4vf/cxgb4vf_main.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/cxgb4vf/cxgb4vf_main.c	Tue May 18 15:02:47 2021 +0530
@@ -2359,8 +2359,6 @@
                    NETIF_F_GRO | NETIF_F_IPV6_CSUM | NETIF_F_HIGHDMA)
 
 static struct ethtool_ops cxgb4vf_ethtool_ops = {
-	.supported_coalesce_params = ETHTOOL_COALESCE_RX_USECS |
-				     ETHTOOL_COALESCE_RX_MAX_FRAMES,
 	.get_link_ksettings	= cxgb4vf_get_link_ksettings,
 	.get_fecparam		= cxgb4vf_get_fecparam,
 	.get_drvinfo		= cxgb4vf_get_drvinfo,
diff -r 30 src/network/iw_cxgb4/Makefile
--- a/src/network/iw_cxgb4/Makefile	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/iw_cxgb4/Makefile	Tue May 18 15:02:47 2021 +0530
@@ -55,7 +55,7 @@
 
 endif
 
-CFILES  = ev.c cm.c mem.c device.c resource.c provider.c cq.c qp.c id_table.c iw_cxgb4_compat.c restrack.c
+CFILES  = ev.c cm.c mem.c device.c resource.c provider.c cq.c qp.c id_table.c iw_cxgb4_compat.c
 TARGET  = iw_cxgb4.o
 CLEAN_FILES := $(wildcard *.c)
 CLEAN_FILES := $(CLEAN_FILES:.c=.o)
diff -r 30 src/network/iw_cxgb4/cm.c
--- a/src/network/iw_cxgb4/cm.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/iw_cxgb4/cm.c	Tue May 18 15:02:47 2021 +0530
@@ -358,24 +358,22 @@
 {
 	unsigned long flags;
 
-	xa_lock_irqsave(&ep->com.dev->hwtids, flags);
-	__xa_erase(&ep->com.dev->hwtids, ep->hwtid);
-	if (xa_empty(&ep->com.dev->hwtids))
+	spin_lock_irqsave(&ep->com.dev->lock, flags);
+	_remove_handle(ep->com.dev, &ep->com.dev->hwtid_idr, ep->hwtid, 0);
+	if (idr_is_empty(&ep->com.dev->hwtid_idr))
 		wake_up(&ep->com.dev->wait);
-	xa_unlock_irqrestore(&ep->com.dev->hwtids, flags);
+	spin_unlock_irqrestore(&ep->com.dev->lock, flags);
 }
 
-static int insert_ep_tid(struct c4iw_ep *ep)
+static void insert_ep_tid(struct c4iw_ep *ep)
 {
 	unsigned long flags;
-	int err;
-
-	xa_lock_irqsave(&ep->com.dev->hwtids, flags);
-	err = __xa_insert(&ep->com.dev->hwtids, ep->hwtid, ep, GFP_KERNEL);
-	xa_unlock_irqrestore(&ep->com.dev->hwtids, flags);
-
-	return err;
+
+	spin_lock_irqsave(&ep->com.dev->lock, flags);
+	_insert_handle(ep->com.dev, &ep->com.dev->hwtid_idr, ep, ep->hwtid, 0);
+	spin_unlock_irqrestore(&ep->com.dev->lock, flags);
 }
+
 /*
  * Atomically lookup the ep ptr given the tid and grab a reference on the ep.
  */
@@ -384,11 +382,11 @@
 	struct c4iw_ep *ep;
 	unsigned long flags;
 
-	xa_lock_irqsave(&dev->hwtids, flags);
-	ep = xa_load(&dev->hwtids, tid);
+	spin_lock_irqsave(&dev->lock, flags);
+	ep = idr_find(&dev->hwtid_idr, tid);
 	if (ep)
 		c4iw_get_ep(&ep->com);
-	xa_unlock_irqrestore(&dev->hwtids, flags);
+	spin_unlock_irqrestore(&dev->lock, flags);
 	return ep;
 }
 
@@ -400,11 +398,11 @@
 	struct c4iw_listen_ep *ep;
 	unsigned long flags;
 
-	xa_lock_irqsave(&dev->stids, flags);
-	ep = xa_load(&dev->stids, stid);
+	spin_lock_irqsave(&dev->lock, flags);
+	ep = idr_find(&dev->stid_idr, stid);
 	if (ep)
 		c4iw_get_ep(&ep->com);
-	xa_unlock_irqrestore(&dev->stids, flags);
+	spin_unlock_irqrestore(&dev->lock, flags);
 	return ep;
 }
 
@@ -441,7 +439,8 @@
 			dst_release(ep->dst);
 		if (ep->l2t)
 			cxgb4_l2t_release(ep->l2t);
-		kfree_skb(ep->mpa_skb);
+		if (ep->mpa_skb)
+			kfree_skb(ep->mpa_skb);
 	}
 	if (!skb_queue_empty(&ep->com.ep_skb_list))
 		skb_queue_purge(&ep->com.ep_skb_list);
@@ -663,7 +662,7 @@
 		cxgb4_clip_release(ep->com.dev->rdev.lldi.ports[0],
 				   (const u32 *)&sin6->sin6_addr.s6_addr, 1);
 	}
-	xa_erase_irq(&ep->com.dev->atids, ep->atid);
+	remove_handle(ep->com.dev, &ep->com.dev->atid_idr, ep->atid);
 	cxgb4_free_atid(ep->com.dev->rdev.lldi.tids, ep->atid);
 	queue_arp_failure_cpl(ep, skb, FAKE_CPL_PUT_EP_SAFE);
 }
@@ -766,7 +765,7 @@
 	return c4iw_l2t_send(&ep->com.dev->rdev, skb, ep);
 }
 
-static void read_tcb(struct c4iw_ep *ep)
+void read_tcb(struct c4iw_ep *ep)
 {
 	struct sk_buff *skb;
 	struct cpl_get_tcb *req;
@@ -1365,7 +1364,7 @@
 	set_emss(ep, ntohs(req->tcp_opt));
 
 	/* dealloc the atid */
-	xa_erase_irq(&ep->com.dev->atids, atid);
+	remove_handle(ep->com.dev, &ep->com.dev->atid_idr, atid);
 	cxgb4_free_atid(t, atid);
 	set_bit(ACT_ESTAB, &ep->com.history);
 
@@ -2331,9 +2330,7 @@
 		err = -ENOMEM;
 		goto fail2;
 	}
-	err = xa_insert_irq(&ep->com.dev->atids, ep->atid, ep, GFP_KERNEL);
-	if (err)
-		goto fail2a;
+	insert_handle(ep->com.dev, &ep->com.dev->atid_idr, ep, ep->atid);
 
 	/* find a route */
 	if (ep->com.cm_id->m_local_addr.ss_family == AF_INET) {
@@ -2384,8 +2381,7 @@
 fail4:
 	dst_release(ep->dst);
 fail3:
-	xa_erase_irq(&ep->com.dev->atids, ep->atid);
-fail2a:
+	remove_handle(ep->com.dev, &ep->com.dev->atid_idr, ep->atid);
 	cxgb4_free_atid(ep->com.dev->rdev.lldi.tids, ep->atid);
 fail2:
 	/*
@@ -2467,7 +2463,8 @@
 					(const u32 *)
 					&sin6->sin6_addr.s6_addr, 1);
 			}
-			xa_erase_irq(&ep->com.dev->atids, atid);
+			remove_handle(ep->com.dev, &ep->com.dev->atid_idr,
+				      atid);
 			cxgb4_free_atid(t, atid);
 			dst_release(ep->dst);
 			cxgb4_l2t_release(ep->l2t);
@@ -2509,7 +2506,7 @@
 		cxgb4_remove_tid(ep->com.dev->rdev.lldi.tids, 0, GET_TID(rpl),
 				 ep->com.local_addr.ss_family);
 
-	xa_erase_irq(&ep->com.dev->atids, atid);
+	remove_handle(ep->com.dev, &ep->com.dev->atid_idr, atid);
 	cxgb4_free_atid(t, atid);
 	dst_release(ep->dst);
 	cxgb4_l2t_release(ep->l2t);
@@ -2874,7 +2871,7 @@
 
 static int pick_local_ip6addrs(struct c4iw_dev *dev, struct iw_cm_id *cm_id)
 {
-	struct in6_addr addr;
+	struct in6_addr uninitialized_var(addr);
 	struct sockaddr_in6 *la6 = (struct sockaddr_in6 *)&cm_id->m_local_addr;
 	struct sockaddr_in6 *ra6 = (struct sockaddr_in6 *)&cm_id->m_remote_addr;
 
@@ -3170,7 +3167,7 @@
 					(const u32 *)&sin6->sin6_addr.s6_addr,
 					1);
 		}
-		xa_erase_irq(&ep->com.dev->hwtids, ep->hwtid);
+		remove_handle(ep->com.dev, &ep->com.dev->hwtid_idr, ep->hwtid);
 		cxgb4_remove_tid(ep->com.dev->rdev.lldi.tids, 0, ep->hwtid,
 				 ep->com.local_addr.ss_family);
 		dst_release(ep->dst);
@@ -3239,17 +3236,15 @@
 	struct c4iw_qp_attributes attrs;
 
 	ep = get_ep_from_tid(dev, tid);
-	if (ep) {
-		if (ep && ep->com.qp) {
-			pr_warn("TERM received tid %u qpid %u\n", tid,
-			       ep->com.qp->wq.sq.qid);
-			attrs.next_state = C4IW_QP_STATE_TERMINATE;
-			c4iw_modify_rc_qp(ep->com.qp, C4IW_QP_ATTR_NEXT_STATE,
-					  &attrs, 1);
-		}
-		c4iw_put_ep(&ep->com);
+	if (ep && ep->com.qp) {
+		pr_warn("TERM received tid %u qpid %u\n", tid,
+		       ep->com.qp->wq.sq.qid);
+		attrs.next_state = C4IW_QP_STATE_TERMINATE;
+		c4iw_modify_rc_qp(ep->com.qp, C4IW_QP_ATTR_NEXT_STATE, &attrs,
+				  1);
 	} else
 		pr_warn("TERM received tid %u no ep/qp\n", tid);
+	c4iw_put_ep(&ep->com);
 
 	return 0;
 }
@@ -3438,18 +3433,17 @@
 	int found = 0;
 	struct sockaddr_in *laddr = (struct sockaddr_in *)&cm_id->m_local_addr;
 	struct sockaddr_in *raddr = (struct sockaddr_in *)&cm_id->m_remote_addr;
-	const struct in_ifaddr *ifa;
 
 	ind = in_dev_get(dev->rdev.lldi.ports[0]);
 	if (!ind)
 		return -EADDRNOTAVAIL;
-	in_dev_for_each_ifa_rcu(ifa, ind) {
+	for_primary_ifa(ind) {
 		laddr->sin_addr.s_addr = ifa->ifa_address;
 		raddr->sin_addr.s_addr = ifa->ifa_address;
 		found = 1;
 		break;
 	}
-
+	endfor_ifa(ind);
 	in_dev_put(ind);
 	return found ? 0 : -EADDRNOTAVAIL;
 }
@@ -3525,9 +3519,7 @@
 		err = -ENOMEM;
 		goto fail2;
 	}
-	err = xa_insert_irq(&dev->atids, ep->atid, ep, GFP_KERNEL);
-	if (err)
-		goto fail5;
+	insert_handle(dev, &dev->atid_idr, ep, ep->atid);
 
 	memcpy(&ep->com.local_addr, &cm_id->m_local_addr,
 			sizeof(ep->com.local_addr));
@@ -3626,8 +3618,7 @@
 fail4:
 	dst_release(ep->dst);
 fail3:
-	xa_erase_irq(&ep->com.dev->atids, ep->atid);
-fail5:
+	remove_handle(ep->com.dev, &ep->com.dev->atid_idr, ep->atid);
 	cxgb4_free_atid(ep->com.dev->rdev.lldi.tids, ep->atid);
 fail2:
 	skb_queue_purge(&ep->com.ep_skb_list);
@@ -3745,10 +3736,7 @@
 		err = -ENOMEM;
 		goto fail2;
 	}
-	err = xa_insert_irq(&dev->stids, ep->stid, ep, GFP_KERNEL);
-	if (err)
-		goto fail3;
-
+	insert_handle(dev, &dev->stid_idr, ep, ep->stid);
 
 	state_set(&ep->com, LISTEN);
 	if (ep->com.local_addr.ss_family == AF_INET)
@@ -3759,8 +3747,7 @@
 		cm_id->provider_data = ep;
 		goto out;
 	}
-	xa_erase_irq(&ep->com.dev->stids, ep->stid);
-fail3:
+	remove_handle(ep->com.dev, &ep->com.dev->stid_idr, ep->stid);
 	cxgb4_free_stid(ep->com.dev->rdev.lldi.tids, ep->stid,
 			ep->com.local_addr.ss_family);
 fail2:
@@ -3803,7 +3790,7 @@
 					1);
 		}
 	}
-	xa_erase_irq(&ep->com.dev->stids, ep->stid);
+	remove_handle(ep->com.dev, &ep->com.dev->stid_idr, ep->stid);
 	cxgb4_free_stid(ep->com.dev->rdev.lldi.tids, ep->stid,
 			ep->com.local_addr.ss_family);
 done:
@@ -3970,7 +3957,7 @@
 		cxgb4_clip_release(ep->com.dev->rdev.lldi.ports[0],
 				(const u32 *)&sin6->sin6_addr.s6_addr, 1);
 	}
-	xa_erase_irq(&ep->com.dev->atids, atid);
+	remove_handle(dev, &dev->atid_idr, atid);
 	cxgb4_free_atid(dev->rdev.lldi.tids, atid);
 	dst_release(ep->dst);
 	cxgb4_l2t_release(ep->l2t);
@@ -4307,7 +4294,7 @@
 	} else {
 		vlan_eh = (struct vlan_ethhdr *)(req + 1);
 		iph = (struct iphdr *)(vlan_eh + 1);
-		__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), ntohs(cpl->vlan));
+		skb->vlan_tci = ntohs(cpl->vlan);
 	}
 
 	if (iph->version != 0x4)
@@ -4654,7 +4641,7 @@
 	case CONNECTING:
 		if (!ep->parent_ep) {
 			connect_reply_upcall(ep, -EIO);
-			xa_erase_irq(&ep->com.dev->atids, ep->atid);
+			remove_handle(epc->dev, &epc->dev->atid_idr, ep->atid);
 			cxgb4_free_atid(epc->dev->rdev.lldi.tids, ep->atid);
 			dst_release(ep->dst);
 			cxgb4_l2t_release(ep->l2t);
diff -r 30 src/network/iw_cxgb4/cq.c
--- a/src/network/iw_cxgb4/cq.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/iw_cxgb4/cq.c	Tue May 18 15:02:47 2021 +0530
@@ -32,15 +32,15 @@
 
 #include "iw_cxgb4.h"
 #include <rdma/ib_user_verbs.h>
-#include <rdma/uverbs_ioctl.h>
 
-static void destroy_cq(struct c4iw_rdev *rdev, struct t4_cq *cq,
-		       struct c4iw_dev_ucontext *uctx, struct sk_buff *skb,
-		       struct c4iw_wr_wait *wr_waitp)
+static int destroy_cq(struct c4iw_rdev *rdev, struct t4_cq *cq,
+		      struct c4iw_dev_ucontext *uctx, struct sk_buff *skb,
+		      struct c4iw_wr_wait *wr_waitp)
 {
 	struct fw_ri_res_wr *res_wr;
 	struct fw_ri_res *res;
 	int wr_len;
+	int ret;
 
 	wr_len = sizeof *res_wr + sizeof *res;
 	set_wr_txq(skb, CPL_PRIORITY_CONTROL, NCHAN);
@@ -59,13 +59,14 @@
 	res->u.cq.iqid = cpu_to_be32(cq->cqid);
 
 	c4iw_init_wr_wait(wr_waitp);
-	c4iw_ref_send_wait(rdev, skb, wr_waitp, 0, 0, __func__);
+	ret = c4iw_ref_send_wait(rdev, skb, wr_waitp, 0, 0, __func__);
 
 	kfree(cq->sw_queue);
 	dma_free_coherent(&(rdev->lldi.pdev->dev),
 			  cq->memsize, cq->queue,
-			  dma_unmap_addr(cq, mapping));
+			  pci_unmap_addr(cq, mapping));
 	c4iw_put_cqid(rdev, cq->cqid, uctx);
+	return ret;
 }
 
 static int create_cq(struct c4iw_rdev *rdev, struct t4_cq *cq,
@@ -98,7 +99,8 @@
 		ret = -ENOMEM;
 		goto err3;
 	}
-	dma_unmap_addr_set(cq, mapping, cq->dma_addr);
+	pci_unmap_addr_set(cq, mapping, cq->dma_addr);
+	memset(cq->queue, 0, cq->memsize);
 
 	/* build fw_ri_res_wr */
 	wr_len = sizeof *res_wr + sizeof *res;
@@ -157,7 +159,7 @@
 	return 0;
 err4:
 	dma_free_coherent(&rdev->lldi.pdev->dev, cq->memsize, cq->queue,
-			  dma_unmap_addr(cq, mapping));
+			  pci_unmap_addr(cq, mapping));
 err3:
 	kfree(cq->sw_queue);
 err2:
@@ -755,7 +757,7 @@
 static int c4iw_poll_cq_one(struct c4iw_cq *chp, struct ib_wc *wc)
 {
 	struct c4iw_qp *qhp = NULL;
-	struct t4_cqe cqe, *rd_cqe;
+	struct t4_cqe uninitialized_var(cqe), *rd_cqe;
 	struct t4_wq *wq;
 	u32 credit = 0;
 	u8 cqe_flushed;
@@ -950,7 +952,7 @@
 	return !err || err == -ENODATA ? npolled : err;
 }
 
-int c4iw_destroy_cq(struct ib_cq *ib_cq, struct ib_udata *udata)
+int c4iw_destroy_cq(struct ib_cq *ib_cq)
 {
 	struct c4iw_cq *chp;
 	struct c4iw_ucontext *ucontext;
@@ -958,42 +960,92 @@
 	pr_debug("ib_cq %p\n", ib_cq);
 	chp = to_c4iw_cq(ib_cq);
 
-	xa_erase_irq(&chp->rhp->cqs, chp->cq.cqid);
+	remove_handle(chp->rhp, &chp->rhp->cqidr, chp->cq.cqid);
 	atomic_dec(&chp->refcnt);
 	wait_event(chp->wait, !atomic_read(&chp->refcnt));
 
-	ucontext = rdma_udata_to_drv_context(udata, struct c4iw_ucontext,
-					     ibucontext);
+	ucontext = ib_cq->uobject ? to_c4iw_ucontext(ib_cq->uobject->context)
+				  : NULL;
 	destroy_cq(&chp->rhp->rdev, &chp->cq,
 		   ucontext ? &ucontext->uctx : &chp->cq.rdev->uctx,
 		   chp->destroy_skb, chp->wr_waitp);
 	c4iw_put_wr_wait(chp->wr_waitp);
-
+	kfree(chp);
 	return 0;
 }
 
-int c4iw_create_cq(struct ib_cq *ibcq, const struct ib_cq_init_attr *attr,
-		   struct ib_udata *udata)
+struct ib_cq *c4iw_create_cq(struct ib_device *ibdev,
+#ifdef IWARP_HAVE_CQ_INIT_ATTR
+			     const struct ib_cq_init_attr *attr,
+			     struct ib_ucontext *ib_context,
+			     struct ib_udata *udata)
 {
-	struct ib_device *ibdev = ibcq->device;
 	int entries = attr->cqe;
 	int vector = attr->comp_vector;
-	struct c4iw_dev *rhp = to_c4iw_dev(ibcq->device);
-	struct c4iw_cq *chp = to_c4iw_cq(ibcq);
+#else
+			     int entries, int vector,
+			     struct ib_ucontext *ib_context,
+			     struct ib_udata *udata)
+{
+#endif
+	struct c4iw_dev *rhp;
+	struct c4iw_cq *chp;
+	struct c4iw_create_cq_req ureq;
 	struct c4iw_create_cq_resp uresp;
+	struct c4iw_ucontext *ucontext = NULL;
 	int ret, wr_len;
 	size_t memsize, hwentries;
 	struct c4iw_mm_entry *mm, *mm2;
-	struct c4iw_ucontext *ucontext = rdma_udata_to_drv_context(
-		udata, struct c4iw_ucontext, ibucontext);
+	static int warned;
 
 	pr_debug("ib_dev %p entries %d\n", ibdev, entries);
+#ifdef IWARP_HAVE_CQ_INIT_ATTR
 	if (attr->flags)
-		return -EINVAL;
+		return ERR_PTR(-EINVAL);
+#endif
+
+	rhp = to_c4iw_dev(ibdev);
+
+	if (ib_context) {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,14,0)
+		if (udata->inlen !=
+#else
+		if (udata->inlen - sizeof(struct ib_uverbs_cmd_hdr) !=
+#endif
+		    sizeof ureq) {
+			if (!warned) {
+				warned = 1;
+				pr_warn("WARNING: downlevel libcxgb4. "
+					"RDMA cannot be supported with this "
+					"driver/lib combination.  Please update "
+					"libcxgb4.\n");
+			}
+			return ERR_PTR(-EINVAL);
+		}
+		ret = ib_copy_from_udata(&ureq, udata, sizeof ureq);
+		if (ret)
+			return ERR_PTR(-EFAULT);
+		if (ureq.cqe_size != sizeof(struct t4_cqe)) {
+			if (!warned) {
+				warned = 1;
+				pr_warn("WARNING: driver/lib cqe_size mismatch. "
+					"RDMA cannot be supported with this "
+					"driver/lib combination.  Please update "
+					"libcxgb4.\n");
+			}
+			return ERR_PTR(-EINVAL);
+		}
+	}
 
 	if (vector >= rhp->rdev.lldi.nciq)
-		return -EINVAL;
+		return ERR_PTR(-EINVAL);
 
+	if (ib_context)
+		ucontext = to_c4iw_ucontext(ib_context);
+
+	chp = kzalloc(sizeof(*chp), GFP_KERNEL);
+	if (!chp)
+		return ERR_PTR(-ENOMEM);
 	chp->wr_waitp = c4iw_alloc_wr_wait(GFP_KERNEL);
 	if (!chp->wr_waitp) {
 		ret = -ENOMEM;
@@ -1031,14 +1083,13 @@
 	if (hwentries < 64)
 		hwentries = 64;
 
-	memsize = hwentries * sizeof(*chp->cq.queue);
+	memsize = hwentries * sizeof *chp->cq.queue;
 
 	/*
 	 * memsize must be a multiple of the page size if its a user cq.
 	 */
-	if (udata)
+	if (ucontext)
 		memsize = roundup(memsize, PAGE_SIZE);
-
 	chp->cq.size = hwentries;
 	chp->cq.memsize = memsize;
 	chp->cq.vector = vector;
@@ -1056,16 +1107,15 @@
 	spin_lock_init(&chp->comp_handler_lock);
 	atomic_set(&chp->refcnt, 1);
 	init_waitqueue_head(&chp->wait);
-	ret = xa_insert_irq(&rhp->cqs, chp->cq.cqid, chp, GFP_KERNEL);
+	ret = insert_handle(rhp, &rhp->cqidr, chp, chp->cq.cqid);
 	if (ret)
 		goto err_destroy_cq;
 
 	if (ucontext) {
-		ret = -ENOMEM;
-		mm = kmalloc(sizeof(*mm), GFP_KERNEL);
+		mm = kmalloc(sizeof *mm, GFP_KERNEL);
 		if (!mm)
 			goto err_remove_handle;
-		mm2 = kmalloc(sizeof(*mm2), GFP_KERNEL);
+		mm2 = kmalloc(sizeof *mm2, GFP_KERNEL);
 		if (!mm2)
 			goto err_free_mm;
 
@@ -1079,10 +1129,9 @@
 		ucontext->key += PAGE_SIZE;
 		uresp.gts_key = ucontext->key;
 		ucontext->key += PAGE_SIZE;
-
 		spin_unlock(&ucontext->mmap_lock);
 		ret = ib_copy_to_udata(udata, &uresp,
-				       sizeof(uresp));
+				       sizeof(uresp) - sizeof(uresp.reserved));
 		if (ret)
 			goto err_free_mm2;
 
@@ -1092,31 +1141,34 @@
 		insert_mmap(ucontext, mm);
 
 		mm2->key = uresp.gts_key;
-		mm2->addr = chp->cq.bar2_pa;
+		mm2->addr = (u64)(unsigned long)chp->cq.bar2_pa;
 		mm2->len = PAGE_SIZE;
 		insert_mmap(ucontext, mm2);
 	}
-
-	pr_debug("cqid 0x%0x chp %p size %u memsize %zu, dma_addr %pad\n",
-		 chp->cq.cqid, chp, chp->cq.size, chp->cq.memsize,
-		 &chp->cq.dma_addr);
-	return 0;
+	pr_debug("cqid 0x%0x chp %p IQ size %u CQ size %u ULP size %u "
+	     "memsize %lu, dma_addr 0x%0llx\n", chp->cq.cqid, chp,
+	     chp->cq.size + 1, chp->cq.size, chp->ibcq.cqe,
+	     (unsigned long)chp->cq.memsize,
+	     (unsigned long long) chp->cq.dma_addr);
+	return &chp->ibcq;
 err_free_mm2:
 	kfree(mm2);
 err_free_mm:
 	kfree(mm);
 err_remove_handle:
-	xa_erase_irq(&rhp->cqs, chp->cq.cqid);
+	remove_handle(rhp, &rhp->cqidr, chp->cq.cqid);
 err_destroy_cq:
 	destroy_cq(&chp->rhp->rdev, &chp->cq,
 		   ucontext ? &ucontext->uctx : &rhp->rdev.uctx,
 		   chp->destroy_skb, chp->wr_waitp);
 err_free_skb:
-	kfree_skb(chp->destroy_skb);
+	if(chp->destroy_skb)
+		kfree_skb(chp->destroy_skb);
 err_free_wr_wait:
 	c4iw_put_wr_wait(chp->wr_waitp);
 err_free_chp:
-	return ret;
+	kfree(chp);
+	return ERR_PTR(ret);
 }
 
 int c4iw_resize_cq(struct ib_cq *cq, int cqe, struct ib_udata *udata)
diff -r 30 src/network/iw_cxgb4/device.c
--- a/src/network/iw_cxgb4/device.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/iw_cxgb4/device.c	Tue May 18 15:02:47 2021 +0530
@@ -82,6 +82,14 @@
 	int pos;
 };
 
+static int count_idrs(int id, void *p, void *data)
+{
+	int *countp = data;
+
+	*countp = *countp + 1;
+	return 0;
+}
+
 static ssize_t debugfs_read(struct file *file, char __user *buf, size_t count,
 			    loff_t *ppos)
 {
@@ -134,19 +142,19 @@
 	idx = (atomic_inc_return(&wq->rdev->wr_log_idx) - 1) &
 		  (wq->rdev->wr_log_size - 1);
 	le.poll_sge_ts = cxgb4_read_sge_timestamp(wq->rdev->lldi.ports[0]);
-	le.poll_host_time = ktime_get();
+	getnstimeofday(&le.poll_host_ts);
 	le.valid = 1;
 	le.cqe_sge_ts = CQE_TS(cqe);
 	if (SQ_TYPE(cqe)) {
 		le.qid = wq->sq.qid;
 		le.opcode = CQE_OPCODE(cqe);
-		le.post_host_time = wq->sq.sw_sq[wq->sq.cidx].host_time;
+		le.post_host_ts = wq->sq.sw_sq[wq->sq.cidx].host_ts;
 		le.post_sge_ts = wq->sq.sw_sq[wq->sq.cidx].sge_ts;
 		le.wr_id = CQE_WRID_SQ_IDX(cqe);
 	} else {
 		le.qid = wq->rq.qid;
 		le.opcode = FW_RI_RECEIVE;
-		le.post_host_time = wq->rq.sw_rq[wq->rq.cidx].host_time;
+		le.post_host_ts = wq->rq.sw_rq[wq->rq.cidx].host_ts;
 		le.post_sge_ts = wq->rq.sw_rq[wq->rq.cidx].sge_ts;
 		le.wr_id = CQE_WRID_MSN(cqe);
 	}
@@ -156,9 +164,9 @@
 static int wr_log_show(struct seq_file *seq, void *v)
 {
 	struct c4iw_dev *dev = seq->private;
-	ktime_t prev_time;
+	struct timespec prev_ts = {0, 0};
 	struct wr_log_entry *lep;
-	int prev_time_set = 0;
+	int prev_ts_set = 0;
 	int idx, end;
 
 #define ts2ns(ts) div64_u64((ts) * dev->rdev.lldi.cclk_ps, 1000)
@@ -171,28 +179,31 @@
 	lep = &dev->rdev.wr_log[idx];
 	while (idx != end) {
 		if (lep->valid) {
-			if (!prev_time_set) {
-				prev_time_set = 1;
-				prev_time = lep->poll_host_time;
+			if (!prev_ts_set) {
+				prev_ts_set = 1;
+				prev_ts = lep->poll_host_ts;
 			}
-			seq_printf(seq, "%04u: nsec %llu qid %u opcode "
-				"%u %s 0x%x host_wr_delta nsec %llu "
+			seq_printf(seq, "%04u: sec %lu nsec %lu qid %u opcode "
+				"%u %s 0x%x host_wr_delta sec %lu nsec %lu "
 				"post_sge_ts 0x%llx cqe_sge_ts 0x%llx "
 				"poll_sge_ts 0x%llx post_poll_delta_ns %llu "
 				"cqe_poll_delta_ns %llu\n",
 				idx,
-				ktime_to_ns(ktime_sub(lep->poll_host_time,
-						      prev_time)),
+				timespec_sub(lep->poll_host_ts, prev_ts).tv_sec,
+				timespec_sub(lep->poll_host_ts,
+					     prev_ts).tv_nsec,
 			        lep->qid, lep->opcode,
 				lep->opcode == FW_RI_RECEIVE ? "msn" : "wrid",
 				lep->wr_id,
-				ktime_to_ns(ktime_sub(lep->poll_host_time,
-						      lep->post_host_time)),
+				timespec_sub(lep->poll_host_ts,
+				     lep->post_host_ts).tv_sec,
+				timespec_sub(lep->poll_host_ts,
+				     lep->post_host_ts).tv_nsec,
 				lep->post_sge_ts, lep->cqe_sge_ts,
 				lep->poll_sge_ts,
 				ts2ns(lep->poll_sge_ts - lep->post_sge_ts),
 				ts2ns(lep->poll_sge_ts - lep->cqe_sge_ts));
-			prev_time = lep->poll_host_time;
+			prev_ts = lep->poll_host_ts;
 		}
 		idx++;
 		if (idx > (dev->rdev.wr_log_size - 1))
@@ -275,9 +286,10 @@
 	}
 }
 
-static int dump_qp(unsigned long id, struct c4iw_qp *qp,
-		   struct c4iw_debugfs_data *qpd)
+static int dump_qp(int id, void *p, void *data)
 {
+	struct c4iw_qp *qp = p;
+	struct c4iw_debugfs_data *qpd = data;
 	int space;
 	int cc;
 
@@ -343,9 +355,10 @@
 	return 0;
 }
 
-static
-int dump_raw_qp(int id, struct c4iw_raw_qp *rqp, struct c4iw_debugfs_data *qpd)
+static int dump_raw_qp(int id, void *p, void *data)
 {
+	struct c4iw_raw_qp *rqp = p;
+	struct c4iw_debugfs_data *qpd = data;
 	int space;
 	int cc;
 	struct c4iw_raw_srq *srq = to_c4iw_raw_srq(rqp->ibqp.srq);
@@ -383,10 +396,7 @@
 
 static int qp_open(struct inode *inode, struct file *file)
 {
-	struct c4iw_qp *qp;
-	struct c4iw_raw_qp *rqp;
 	struct c4iw_debugfs_data *qpd;
-	unsigned long index;
 	int ret = 0;
 	int count = 1;
 
@@ -398,10 +408,10 @@
 	qpd->devp = inode->i_private;
 	qpd->pos = 0;
 
-	xa_for_each(&qpd->devp->qps, index, qp)
-		count++;
-	xa_for_each(&qpd->devp->rawqps, index, rqp)
-		count++;
+	spin_lock_irq(&qpd->devp->lock);
+	idr_for_each(&qpd->devp->qpidr, count_idrs, &count);
+	idr_for_each(&qpd->devp->rawqpidr, count_idrs, &count);
+	spin_unlock_irq(&qpd->devp->lock);
 
 	qpd->bufsize = count * 180;
 	qpd->buf = vmalloc(qpd->bufsize);
@@ -410,14 +420,10 @@
 		goto err_free_qpd;
 	}
 
-	xa_lock_irq(&qpd->devp->qps);
-	xa_for_each(&qpd->devp->qps, index, qp)
-		dump_qp(index, qp, qpd);
-	xa_unlock_irq(&qpd->devp->qps);
-	xa_lock_irq(&qpd->devp->rawqps);
-	xa_for_each(&qpd->devp->rawqps, index, rqp)
-		dump_raw_qp(index, rqp, qpd);
-	xa_unlock_irq(&qpd->devp->rawqps);
+	spin_lock_irq(&qpd->devp->lock);
+	idr_for_each(&qpd->devp->qpidr, dump_qp, qpd);
+	idr_for_each(&qpd->devp->rawqpidr, dump_raw_qp, qpd);
+	spin_unlock_irq(&qpd->devp->lock);
 
 	file->private_data = qpd;
 	goto out;
@@ -434,8 +440,9 @@
 	.read    = debugfs_read,
 };
 
-static int dump_stag(unsigned long id, struct c4iw_debugfs_data *stagd)
+static int dump_stag(int id, void *p, void *data)
 {
+	struct c4iw_debugfs_data *stagd = data;
 	int space;
 	int cc;
 	struct fw_ri_tpte tpte;
@@ -484,8 +491,6 @@
 static int stag_open(struct inode *inode, struct file *file)
 {
 	struct c4iw_debugfs_data *stagd;
-	void *p;
-	unsigned long index;
 	int ret = 0;
 	int count = 1;
 
@@ -497,8 +502,9 @@
 	stagd->devp = inode->i_private;
 	stagd->pos = 0;
 
-	xa_for_each(&stagd->devp->mrs, index, p)
-		count++;
+	spin_lock_irq(&stagd->devp->lock);
+	idr_for_each(&stagd->devp->mmidr, count_idrs, &count);
+	spin_unlock_irq(&stagd->devp->lock);
 
 	stagd->bufsize = count * 256;
 	stagd->buf = vmalloc(stagd->bufsize);
@@ -507,10 +513,9 @@
 		goto err1;
 	}
 
-	xa_lock_irq(&stagd->devp->mrs);
-	xa_for_each(&stagd->devp->mrs, index, p)
-		dump_stag(index, stagd);
-	xa_unlock_irq(&stagd->devp->mrs);
+	spin_lock_irq(&stagd->devp->lock);
+	idr_for_each(&stagd->devp->mmidr, dump_stag, stagd);
+	spin_unlock_irq(&stagd->devp->lock);
 
 	file->private_data = stagd;
 	goto out;
@@ -615,8 +620,10 @@
 	.write   = stats_clear,
 };
 
-static int dump_ep(struct c4iw_ep *ep, struct c4iw_debugfs_data *epd)
+static int dump_ep(int id, void *p, void *data)
 {
+	struct c4iw_ep *ep = p;
+	struct c4iw_debugfs_data *epd = data;
 	int space;
 	int cc;
 
@@ -667,9 +674,10 @@
 	return 0;
 }
 
-static
-int dump_listen_ep(struct c4iw_listen_ep *ep, struct c4iw_debugfs_data *epd)
+static int dump_listen_ep(int id, void *p, void *data)
 {
+	struct c4iw_listen_ep *ep = p;
+	struct c4iw_debugfs_data *epd = data;
 	int space;
 	int cc;
 
@@ -725,9 +733,6 @@
 
 static int ep_open(struct inode *inode, struct file *file)
 {
-	struct c4iw_ep *ep;
-	struct c4iw_listen_ep *lep;
-	unsigned long index;
 	struct c4iw_debugfs_data *epd;
 	int ret = 0;
 	int count = 1;
@@ -740,12 +745,11 @@
 	epd->devp = inode->i_private;
 	epd->pos = 0;
 
-	xa_for_each(&epd->devp->hwtids, index, ep)
-		count++;
-	xa_for_each(&epd->devp->atids, index, ep)
-		count++;
-	xa_for_each(&epd->devp->stids, index, lep)
-		count++;
+	spin_lock_irq(&epd->devp->lock);
+	idr_for_each(&epd->devp->hwtid_idr, count_idrs, &count);
+	idr_for_each(&epd->devp->atid_idr, count_idrs, &count);
+	idr_for_each(&epd->devp->stid_idr, count_idrs, &count);
+	spin_unlock_irq(&epd->devp->lock);
 
 	epd->bufsize = count * 240;
 	epd->buf = vmalloc(epd->bufsize);
@@ -754,18 +758,11 @@
 		goto err1;
 	}
 
-	xa_lock_irq(&epd->devp->hwtids);
-	xa_for_each(&epd->devp->hwtids, index, ep)
-		dump_ep(ep, epd);
-	xa_unlock_irq(&epd->devp->hwtids);
-	xa_lock_irq(&epd->devp->atids);
-	xa_for_each(&epd->devp->atids, index, ep)
-		dump_ep(ep, epd);
-	xa_unlock_irq(&epd->devp->atids);
-	xa_lock_irq(&epd->devp->stids);
-	xa_for_each(&epd->devp->stids, index, lep)
-		dump_listen_ep(lep, epd);
-	xa_unlock_irq(&epd->devp->stids);
+	spin_lock_irq(&epd->devp->lock);
+	idr_for_each(&epd->devp->hwtid_idr, dump_ep, epd);
+	idr_for_each(&epd->devp->atid_idr, dump_ep, epd);
+	idr_for_each(&epd->devp->stid_idr, dump_listen_ep, epd);
+	spin_unlock_irq(&epd->devp->lock);
 
 	file->private_data = epd;
 	goto out;
@@ -807,10 +804,13 @@
 	.llseek  = seq_lseek,
 };
 
-static void setup_debugfs(struct c4iw_dev *devp)
+static int setup_debugfs(struct c4iw_dev *devp)
 {
 	struct dentry *de;
 
+	if (!devp->debugfs_root)
+		return -1;
+
 	de = debugfs_create_file("qps", S_IWUSR, devp->debugfs_root,
 				 (void *)devp, &qp_debugfs_fops);
 	if (de && de->d_inode)
@@ -842,6 +842,8 @@
 		if (de && de->d_inode)
 			de->d_inode->i_size = 4096;
 	}
+
+	return 0;
 }
 
 void c4iw_release_dev_ucontext(struct c4iw_rdev *rdev,
@@ -1065,15 +1067,21 @@
 void c4iw_dealloc(struct uld_ctx *ctx)
 {
 	c4iw_rdev_close(&ctx->dev->rdev);
-	WARN_ON(!xa_empty(&ctx->dev->cqs));
-	WARN_ON(!xa_empty(&ctx->dev->qps));
-	WARN_ON(!xa_empty(&ctx->dev->mrs));
-	wait_event(ctx->dev->wait, xa_empty(&ctx->dev->hwtids));
-	WARN_ON(!xa_empty(&ctx->dev->stids));
-	WARN_ON(!xa_empty(&ctx->dev->atids));
-	WARN_ON(!xa_empty(&ctx->dev->rawqps));
-	WARN_ON(!xa_empty(&ctx->dev->rawiqs));
-	WARN_ON(!xa_empty(&ctx->dev->fids));
+	WARN_ON_ONCE(!idr_is_empty(&ctx->dev->cqidr));
+	idr_destroy(&ctx->dev->cqidr);
+	WARN_ON_ONCE(!idr_is_empty(&ctx->dev->qpidr));
+	idr_destroy(&ctx->dev->qpidr);
+	WARN_ON_ONCE(!idr_is_empty(&ctx->dev->rawqpidr));
+	idr_destroy(&ctx->dev->rawqpidr);
+	WARN_ON_ONCE(!idr_is_empty(&ctx->dev->rawiqidr));
+	idr_destroy(&ctx->dev->rawiqidr);
+	WARN_ON_ONCE(!idr_is_empty(&ctx->dev->mmidr));
+	idr_destroy(&ctx->dev->mmidr);
+	wait_event(ctx->dev->wait, idr_is_empty(&ctx->dev->hwtid_idr));
+	idr_destroy(&ctx->dev->hwtid_idr);
+	idr_destroy(&ctx->dev->stid_idr);
+	idr_destroy(&ctx->dev->atid_idr);
+	idr_destroy(&ctx->dev->fididr);
 	if (ctx->dev->rdev.bar2_kva)
 		iounmap(ctx->dev->rdev.bar2_kva);
 	if (ctx->dev->rdev.oc_mw_kva)
@@ -1114,7 +1122,7 @@
 			pci_name(infop->pdev));
 	}
 
-	devp = ib_alloc_device(c4iw_dev, ibdev);
+	devp = (struct c4iw_dev *)ib_alloc_device(sizeof(*devp));
 	if (!devp) {
 		pr_err("Cannot allocate ib device\n");
 		return ERR_PTR(-ENOMEM);
@@ -1183,16 +1191,15 @@
 		return ERR_PTR(ret);
 	}
 
-	xa_init_flags(&devp->cqs, XA_FLAGS_LOCK_IRQ);
-	xa_init_flags(&devp->qps, XA_FLAGS_LOCK_IRQ);
-	xa_init_flags(&devp->rawqps, XA_FLAGS_LOCK_IRQ);
-	xa_init_flags(&devp->rawiqs, XA_FLAGS_LOCK_IRQ);
-	xa_init_flags(&devp->mrs, XA_FLAGS_LOCK_IRQ);
-	xa_init_flags(&devp->hwtids, XA_FLAGS_LOCK_IRQ);
-	xa_init_flags(&devp->stids, XA_FLAGS_LOCK_IRQ);
-	xa_init_flags(&devp->atids, XA_FLAGS_LOCK_IRQ);
-	xa_init_flags(&devp->fids, XA_FLAGS_LOCK_IRQ);
-	/* remove this */
+	idr_init(&devp->cqidr);
+	idr_init(&devp->qpidr);
+	idr_init(&devp->rawqpidr);
+	idr_init(&devp->rawiqidr);
+	idr_init(&devp->mmidr);
+	idr_init(&devp->hwtid_idr);
+	idr_init(&devp->stid_idr);
+	idr_init(&devp->atid_idr);
+	idr_init(&devp->fididr);
 	spin_lock_init(&devp->lock);
 	mutex_init(&devp->rdev.stats.lock);
 	mutex_init(&devp->db_mutex);
@@ -1269,8 +1276,8 @@
 
 		ssi = skb_shinfo(skb);
 		skb_frag_set_page(skb, 0, gl->frags[0].page);
-		skb_frag_off_set(&ssi->frags[0], gl->frags[0].offset + pull_len);
-		skb_frag_size_set(&ssi->frags[0], gl->frags[0].size - pull_len);
+		ssi->frags[0].page_offset = gl->frags[0].offset + pull_len;
+		ssi->frags[0].size = gl->frags[0].size - pull_len;
 		if (gl->nfrags > 1)
 			memcpy(&ssi->frags[1], &gl->frags[1],
 			       (gl->nfrags - 1) * sizeof(skb_frag_t));
@@ -1456,26 +1463,52 @@
 	return 0;
 }
 
+static int disable_qp_db(int id, void *p, void *data)
+{
+	struct c4iw_qp *qp = p;
+
+	t4_disable_wq_db(&qp->wq);
+	return 0;
+}
+
+static int disable_rqp_db(int id, void *p, void *data)
+{
+	struct c4iw_raw_qp *rqp = p;
+
+	t4_disable_fl_db(&rqp->fl);
+	return 0;
+}
+
 static void stop_queues(struct uld_ctx *ctx)
 {
-	unsigned long index, flags;
-	struct c4iw_raw_qp *rqp;
-	struct c4iw_qp *qp;
+	unsigned long flags;
 
-	xa_lock_irqsave(&ctx->dev->qps, flags);
-	xa_lock_irqsave(&ctx->dev->rawqps, flags);
+	spin_lock_irqsave(&ctx->dev->lock, flags);
 	ctx->dev->rdev.stats.db_state_transitions++;
 	ctx->dev->db_state = STOPPED;
 	if (ctx->dev->rdev.flags & T4_STATUS_PAGE_DISABLED) {
-		xa_for_each(&ctx->dev->qps, index, qp)
-			t4_disable_wq_db(&qp->wq);
-		xa_for_each(&ctx->dev->rawqps, index, rqp)
-			t4_disable_fl_db(&rqp->fl);
+		idr_for_each(&ctx->dev->qpidr, disable_qp_db, NULL);
+		idr_for_each(&ctx->dev->rawqpidr, disable_rqp_db, NULL);
 	} else {
 		ctx->dev->rdev.status_page->db_off = 1;
 	}
-	xa_unlock_irqrestore(&ctx->dev->rawqps, flags);
-	xa_unlock_irqrestore(&ctx->dev->qps, flags);
+	spin_unlock_irqrestore(&ctx->dev->lock, flags);
+}
+
+static int enable_qp_db(int id, void *p, void *data)
+{
+	struct c4iw_qp *qp = p;
+
+	t4_enable_wq_db(&qp->wq);
+	return 0;
+}
+
+static int enable_rqp_db(int id, void *p, void *data)
+{
+	struct c4iw_raw_qp *rqp = p;
+
+	t4_enable_fl_db(&rqp->fl);
+	return 0;
 }
 
 static void resume_rc_qp(struct c4iw_qp *qp)
@@ -1565,21 +1598,20 @@
 
 static void resume_queues(struct uld_ctx *ctx)
 {
-	xa_lock_irq(&ctx->dev->qps);
+	spin_lock_irq(&ctx->dev->lock);
 	if (ctx->dev->db_state != STOPPED)
 		goto out;
 	ctx->dev->db_state = FLOW_CONTROL;
 	while (1) {
 		if (list_empty(&ctx->dev->db_fc_list)) {
-			struct c4iw_qp *qp;
-			unsigned long index;
-
 			WARN_ON(ctx->dev->db_state != FLOW_CONTROL);
 			ctx->dev->db_state = NORMAL;
 			ctx->dev->rdev.stats.db_state_transitions++;
 			if (ctx->dev->rdev.flags & T4_STATUS_PAGE_DISABLED) {
-				xa_for_each(&ctx->dev->rawqps, index, qp)
-					t4_enable_wq_db(&qp->wq);
+				idr_for_each(&ctx->dev->qpidr, enable_qp_db,
+					     NULL);
+				idr_for_each(&ctx->dev->rawqpidr, enable_rqp_db,
+					     NULL);
 			} else
 				ctx->dev->rdev.status_page->db_off = 0;
 			break;
@@ -1590,12 +1622,12 @@
 				resume_a_chunk(ctx);
 			}
 			if (!list_empty(&ctx->dev->db_fc_list)) {
-				xa_unlock_irq(&ctx->dev->qps);
+				spin_unlock_irq(&ctx->dev->lock);
 				if (db_fc_resume_delay) {
 					set_current_state(TASK_UNINTERRUPTIBLE);
 					schedule_timeout(db_fc_resume_delay);
 				}
-				xa_lock_irq(&ctx->dev->qps);
+				spin_lock_irq(&ctx->dev->lock);
 				if (ctx->dev->db_state != FLOW_CONTROL)
 					break;
 			}
@@ -1604,7 +1636,7 @@
 out:
 	if (ctx->dev->db_state != NORMAL)
 		ctx->dev->rdev.stats.db_fc_interruptions++;
-	xa_unlock_irq(&ctx->dev->qps);
+	spin_unlock_irq(&ctx->dev->lock);
 }
 
 struct qp_list {
@@ -1614,6 +1646,33 @@
 	struct c4iw_raw_qp **rqps;
 };
 
+static int add_and_ref_qp(int id, void *p, void *data)
+{
+	struct qp_list *qp_listp = data;
+	struct c4iw_qp *qp = p;
+
+	c4iw_qp_add_ref(&qp->ibqp);
+	qp_listp->qps[qp_listp->idx++] = qp;
+	return 0;
+}
+
+static int add_and_ref_rqp(int id, void *p, void *data)
+{
+	struct qp_list *qp_listp = data;
+	struct c4iw_raw_qp *rqp = p;
+
+	c4iw_qp_add_ref(&rqp->ibqp);
+	qp_listp->rqps[qp_listp->ridx++] = rqp;
+	return 0;
+}
+
+static int count_qps(int id, void *p, void *data)
+{
+	unsigned *countp = data;
+	(*countp)++;
+	return 0;
+}
+
 static void deref_qps(struct qp_list *qp_list)
 {
 	int idx;
@@ -1634,7 +1693,7 @@
 	for (idx = 0; idx < qp_list->idx; idx++) {
 		struct c4iw_qp *qp = qp_list->qps[idx];
 
-		xa_lock_irq(&qp->rhp->qps);
+		spin_lock_irq(&qp->rhp->lock);
 		spin_lock(&qp->lock);
 		ret = cxgb4_sync_txq_pidx(qp->rhp->rdev.lldi.ports[0],
 					  qp->wq.sq.qid,
@@ -1663,7 +1722,7 @@
 		}
 		qp->wq.rq.wq_pidx_inc = 0;
 		spin_unlock(&qp->lock);
-		xa_unlock_irq(&qp->rhp->qps);
+		spin_unlock_irq(&qp->rhp->lock);
 
 		/* Wait for the dbfifo to drain */
 		while (cxgb4_dbfifo_count(qp->rhp->rdev.lldi.ports[0], 1) > 0) {
@@ -1714,9 +1773,6 @@
 
 static void recover_queues(struct uld_ctx *ctx)
 {
-	struct c4iw_qp *qp;
-	struct c4iw_raw_qp *rqp;
-	unsigned long index;
 	int count = 0;
 	struct qp_list qp_list;
 	int ret;
@@ -1734,52 +1790,38 @@
 	}
 
 	/* Count active queues so we can build a list of queues to recover */
-	xa_lock_irq(&ctx->dev->qps);
-	xa_lock_irq(&ctx->dev->rawqps);
+	spin_lock_irq(&ctx->dev->lock);
 	WARN_ON(ctx->dev->db_state != STOPPED);
 	ctx->dev->db_state = RECOVERY;
-	xa_for_each(&ctx->dev->qps, index, qp)
-		count++;
+	idr_for_each(&ctx->dev->qpidr, count_qps, &count);
 
 	qp_list.qps = kzalloc(count * sizeof *qp_list.qps, GFP_ATOMIC);
 	if (!qp_list.qps) {
 		pr_err("%s: Fatal error - DB overflow recovery failed\n",
 		       pci_name(ctx->lldi.pdev));
-		xa_unlock_irq(&ctx->dev->rawqps);
-		xa_unlock_irq(&ctx->dev->qps);
+		spin_unlock_irq(&ctx->dev->lock);
 		return;
 	}
 	qp_list.idx = 0;
 
-	/* add and ref each qp so it doesn't get freed */
-	xa_for_each(&ctx->dev->qps, index, qp) {
-		c4iw_qp_add_ref(&qp->ibqp);
-		qp_list.qps[qp_list.idx++] = qp;
-	}
-
 	count = 0;
-	xa_for_each(&ctx->dev->rawqps, index, rqp)
-		count++;
+	idr_for_each(&ctx->dev->rawqpidr, count_qps, &count);
 
 	qp_list.rqps = kzalloc(count * sizeof *qp_list.rqps, GFP_ATOMIC);
 	if (!qp_list.rqps) {
 		pr_err("%s: Fatal error - DB overflow recovery failed\n",
 		       pci_name(ctx->lldi.pdev));
-		xa_unlock_irq(&ctx->dev->rawqps);
-		xa_unlock_irq(&ctx->dev->qps);
+		spin_unlock_irq(&ctx->dev->lock);
 		kfree(qp_list.qps);
 		return;
 	}
 	qp_list.ridx = 0;
 	
 	/* add and ref each qp so it doesn't get freed */
-	xa_for_each(&ctx->dev->rawqps, index, rqp) {
-		c4iw_qp_add_ref(&rqp->ibqp);
-		qp_list.rqps[qp_list.ridx++] = rqp;
-	}
+	idr_for_each(&ctx->dev->qpidr, add_and_ref_qp, &qp_list);
+	idr_for_each(&ctx->dev->rawqpidr, add_and_ref_rqp, &qp_list);
 
-	xa_unlock_irq(&ctx->dev->rawqps);
-	xa_unlock_irq(&ctx->dev->qps);
+	spin_unlock_irq(&ctx->dev->lock);
 	
         /* now traverse the list in a safe context to recover the db state*/
 	recover_lost_dbs(ctx, &qp_list);
@@ -1789,10 +1831,10 @@
 	kfree(qp_list.qps);
 	kfree(qp_list.rqps);
 
-	xa_lock_irq(&ctx->dev->qps);
+	spin_lock_irq(&ctx->dev->lock);
 	WARN_ON(ctx->dev->db_state != RECOVERY);
 	ctx->dev->db_state = STOPPED;
-	xa_unlock_irq(&ctx->dev->qps);
+	spin_unlock_irq(&ctx->dev->lock);
 }
 
 void c4iw_dispatch_event(struct ib_device* ibdev,
@@ -1891,6 +1933,8 @@
 		return err;
 
 	c4iw_debugfs_root = debugfs_create_dir(DRV_NAME, NULL);
+	if (!c4iw_debugfs_root)
+		pr_warn("could not create debugfs entry, continuing\n");
 
 	reg_workq = create_singlethread_workqueue("Register_iWARP_device");
 	if (!reg_workq) {
diff -r 30 src/network/iw_cxgb4/ev.c
--- a/src/network/iw_cxgb4/ev.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/iw_cxgb4/ev.c	Tue May 18 15:02:47 2021 +0530
@@ -123,15 +123,15 @@
 	struct c4iw_qp *qhp;
 	u32 cqid;
 
-	xa_lock_irq(&dev->qps);
-	qhp = xa_load(&dev->qps, CQE_QPID(err_cqe));
+	spin_lock_irq(&dev->lock);
+	qhp = get_qhp(dev, CQE_QPID(err_cqe));
 	if (!qhp) {
 		pr_err("BAD AE qpid 0x%x opcode %d status 0x%x type %d wrid.hi 0x%x wrid.lo 0x%x\n",
 		       CQE_QPID(err_cqe),
 		       CQE_OPCODE(err_cqe), CQE_STATUS(err_cqe),
 		       CQE_TYPE(err_cqe), CQE_WRID_HI(err_cqe),
 		       CQE_WRID_LOW(err_cqe));
-		xa_unlock_irq(&dev->qps);
+		spin_unlock_irq(&dev->lock);
 		goto out;
 	}
 
@@ -146,13 +146,13 @@
 		       CQE_OPCODE(err_cqe), CQE_STATUS(err_cqe),
 		       CQE_TYPE(err_cqe), CQE_WRID_HI(err_cqe),
 		       CQE_WRID_LOW(err_cqe));
-		xa_unlock_irq(&dev->qps);
+		spin_unlock_irq(&dev->lock);
 		goto out;
 	}
 
 	c4iw_qp_add_ref(&qhp->ibqp);
 	atomic_inc(&chp->refcnt);
-	xa_unlock_irq(&dev->qps);
+	spin_unlock_irq(&dev->lock);
 
 	/* Bad incoming write */
 	if (RQ_TYPE(err_cqe) &&
@@ -225,7 +225,7 @@
 				   struct c4iw_raw_srq **srq)
 {
 	enum obj_type ret = UNKNOWN;
-	struct db_fcl *f = xa_load(&dev->rawiqs, qid);
+	struct db_fcl *f = idr_find(&dev->rawiqidr, qid);
 	if (f) {
 		ret = f->type;
 		if (ret == RAW_QP)
@@ -248,11 +248,11 @@
 	/*
 	 * RDMA CQ Event
 	 */
-	xa_lock_irqsave(&dev->cqs, flag);
-	chp = xa_load(&dev->cqs, qid);
+	spin_lock_irqsave(&dev->lock, flag);
+	chp = get_chp(dev, qid);
 	if (chp) {
 		atomic_inc(&chp->refcnt);
-		xa_unlock_irqrestore(&dev->cqs, flag);
+		spin_unlock_irqrestore(&dev->lock, flag);
 		t4_clear_cq_armed(&chp->cq, chp->ibcq.uobject);
 		spin_lock_irqsave(&chp->comp_handler_lock, flag);
 		(*chp->ibcq.comp_handler)(&chp->ibcq, chp->ibcq.cq_context);
@@ -261,7 +261,7 @@
 			wake_up(&chp->wait);
 		return 0;
 	}
-	xa_unlock_irqrestore(&dev->cqs, flag);
+	spin_unlock_irqrestore(&dev->lock, flag);
 
 	/*
 	 * WD IQ Event
diff -r 30 src/network/iw_cxgb4/iw_cxgb4.h
--- a/src/network/iw_cxgb4/iw_cxgb4.h	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/iw_cxgb4/iw_cxgb4.h	Tue May 18 15:02:47 2021 +0530
@@ -34,6 +34,7 @@
 #include <linux/mutex.h>
 #include <linux/list.h>
 #include <linux/spinlock.h>
+#include <linux/idr.h>
 #include <linux/completion.h>
 #include <linux/netdevice.h>
 #include <linux/sched.h>
@@ -54,7 +55,6 @@
 
 #include <rdma/ib_verbs.h>
 #include <rdma/iw_cm.h>
-#include <rdma/restrack.h>
 
 #include "common.h"
 #include "l2t.h"
@@ -157,8 +157,8 @@
 };
 
 struct wr_log_entry {
-	ktime_t post_host_time;
-	ktime_t poll_host_time;
+	struct timespec post_host_ts;
+	struct timespec poll_host_ts;
 	u64 post_sge_ts;
 	u64 cqe_sge_ts;
 	u64 poll_sge_ts;
@@ -375,19 +375,19 @@
 	struct ib_device ibdev;
 	struct c4iw_rdev rdev;
 	u32 device_cap_flags;
-	struct xarray cqs;
-	struct xarray qps;
-	struct xarray rawqps;
-	struct xarray rawiqs;
-	struct xarray mrs;
+	struct idr cqidr;
+	struct idr qpidr;
+	struct idr rawqpidr;
+	struct idr rawiqidr;
+	struct idr fididr;
+	struct idr mmidr;
 	spinlock_t lock;
 	struct mutex db_mutex;
 	struct dentry *debugfs_root;
 	enum db_state db_state;
-	struct xarray hwtids;
-	struct xarray atids;
-	struct xarray stids;
-	struct xarray fids;
+	struct idr hwtid_idr;
+	struct idr atid_idr;
+	struct idr stid_idr;
 	struct list_head db_fc_list;
 	u32 avail_ird;
 	wait_queue_head_t wait;
@@ -412,17 +412,88 @@
 
 static inline struct c4iw_cq *get_chp(struct c4iw_dev *rhp, u32 cqid)
 {
-	return xa_load(&rhp->cqs, cqid);
+	return idr_find(&rhp->cqidr, cqid);
 }
 
 static inline struct c4iw_qp *get_qhp(struct c4iw_dev *rhp, u32 qpid)
 {
-	return xa_load(&rhp->qps, qpid);
+	return idr_find(&rhp->qpidr, qpid);
 }
 
 static inline struct c4iw_cq *fidx2cq(struct c4iw_dev *rhp, u32 fidx)
 {
-	return xa_load(&rhp->fids, fidx);
+	return idr_find(&rhp->fididr, fidx);
+}
+
+static inline struct c4iw_mr *get_mhp(struct c4iw_dev *rhp, u32 mmid)
+{
+	return idr_find(&rhp->mmidr, mmid);
+}
+
+static inline int _insert_handle(struct c4iw_dev *rhp, struct idr *idr,
+				 void *handle, u32 id, int lock)
+{
+	int ret;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,9,0)
+	if (lock) {
+		idr_preload(GFP_KERNEL);
+		spin_lock_irq(&rhp->lock);
+	}
+
+	ret = idr_alloc(idr, handle, id, id + 1, GFP_ATOMIC);
+
+	if (lock) {
+		spin_unlock_irq(&rhp->lock);
+		idr_preload_end();
+	}
+
+	return ret < 0 ? ret : 0;
+#else
+	int newid;
+
+	do {
+		if (!idr_pre_get(idr, lock ? GFP_KERNEL : GFP_ATOMIC))
+			return -ENOMEM;
+		if (lock)
+			spin_lock_irq(&rhp->lock);
+		ret = idr_get_new_above(idr, handle, id, &newid);
+		if (lock)
+			spin_unlock_irq(&rhp->lock);
+	} while (ret == -EAGAIN);
+
+	return ret;
+#endif
+}
+
+static inline int insert_handle(struct c4iw_dev *rhp, struct idr *idr,
+				void *handle, u32 id)
+{
+	return _insert_handle(rhp, idr, handle, id, 1);
+}
+
+static inline int insert_handle_nolock(struct c4iw_dev *rhp, struct idr *idr,
+				       void *handle, u32 id)
+{
+	return _insert_handle(rhp, idr, handle, id, 0);
+}
+
+static inline void _remove_handle(struct c4iw_dev *rhp, struct idr *idr, u32 id, int lock)
+{
+	if (lock)
+		spin_lock_irq(&rhp->lock);
+	idr_remove(idr, id);
+	if (lock)
+		spin_unlock_irq(&rhp->lock);
+}
+
+static inline void remove_handle(struct c4iw_dev *rhp, struct idr *idr, u32 id)
+{
+	_remove_handle(rhp, idr, id, 1);
+}
+
+static inline void remove_handle_nolock(struct c4iw_dev *rhp, struct idr *idr, u32 id)
+{
+	_remove_handle(rhp, idr, id, 0);
 }
 
 extern uint c4iw_max_read_depth;
@@ -584,13 +655,13 @@
 	struct t4_wq wq;
 	spinlock_t lock;
 	struct mutex mutex;
+	struct kref kref;
 	wait_queue_head_t wait;
 	int sq_sig_all;
 	struct c4iw_srq *srq;
+	struct work_struct free_work;
 	struct c4iw_ucontext *ucontext;
 	struct c4iw_wr_wait *wr_waitp;
-	struct completion qp_rel_comp;
-	refcount_t qp_refcnt;
 };
 
 static inline struct c4iw_qp *to_c4iw_qp(struct ib_qp *ibqp)
@@ -678,6 +749,7 @@
 	u32 key;
 	spinlock_t mmap_lock;
 	struct list_head mmaps;
+	struct kref kref;
 };
 
 static inline struct c4iw_ucontext *to_c4iw_ucontext(struct ib_ucontext *c)
@@ -685,6 +757,18 @@
 	return container_of(c, struct c4iw_ucontext, ibucontext);
 }
 
+void _c4iw_free_ucontext(struct kref *kref);
+
+static inline void c4iw_put_ucontext(struct c4iw_ucontext *ucontext)
+{
+	kref_put(&ucontext->kref, _c4iw_free_ucontext);
+}
+
+static inline void c4iw_get_ucontext(struct c4iw_ucontext *ucontext)
+{
+	kref_get(&ucontext->kref);
+}
+
 struct c4iw_mm_entry {
 	struct list_head entry;
 	u64 addr;
@@ -1146,7 +1230,8 @@
 int c4iw_reject_cr(struct iw_cm_id *cm_id, const void *pdata, u8 pdata_len);
 void c4iw_qp_add_ref(struct ib_qp *qp);
 void c4iw_qp_rem_ref(struct ib_qp *qp);
-struct ib_mr *c4iw_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
+struct ib_mr *c4iw_alloc_mr(struct ib_pd *pd,
+			    enum ib_mr_type mr_type,
 			    u32 max_num_sg);
 int c4iw_map_mr_sg(struct ib_mr *ibmr,
 		   struct scatterlist *sg,
@@ -1160,16 +1245,18 @@
 void c4iw_dispatch_event(struct ib_device* ibdev,
 			  u8 port_num,
 			  enum ib_event_type type);
-int c4iw_alloc_mw(struct ib_mw *ibmw, struct ib_udata *udata);
+struct ib_mw *c4iw_alloc_mw(struct ib_pd *pd, enum ib_mw_type type,
+			    struct ib_udata *udata);
 struct ib_mr *c4iw_reg_user_mr(struct ib_pd *pd, u64 start,
 					   u64 length, u64 virt, int acc,
 					   struct ib_udata *udata);
 struct ib_mr *c4iw_get_dma_mr(struct ib_pd *pd, int acc);
-int c4iw_dereg_mr(struct ib_mr *ib_mr, struct ib_udata *udata);
-int c4iw_destroy_cq(struct ib_cq *ib_cq, struct ib_udata *udata);
-int c4iw_create_cq(struct ib_cq *ibcq,
+int c4iw_dereg_mr(struct ib_mr *ib_mr);
+int c4iw_destroy_cq(struct ib_cq *ib_cq);
+struct ib_cq *c4iw_create_cq(struct ib_device *ibdev,
 #ifdef IWARP_HAVE_CQ_INIT_ATTR
 			     const struct ib_cq_init_attr *attr,
+			     struct ib_ucontext *ib_context,
 			     struct ib_udata *udata);
 #else
 			     int entries, int vector,
@@ -1181,11 +1268,11 @@
 int c4iw_modify_srq(struct ib_srq *ib_srq, struct ib_srq_attr *attr,
 		    enum ib_srq_attr_mask srq_attr_mask,
 		    struct ib_udata *udata);
-int c4iw_destroy_srq(struct ib_srq *ib_srq, struct ib_udata *udata);
-int c4iw_create_srq(struct ib_srq *srq,
-		    struct ib_srq_init_attr *attrs,
-		    struct ib_udata *udata);
-int c4iw_destroy_qp(struct ib_qp *ib_qp, struct ib_udata *udata);
+int c4iw_destroy_srq(struct ib_srq *ib_srq);
+struct ib_srq *c4iw_create_srq(struct ib_pd *pd,
+			     struct ib_srq_init_attr *attrs,
+			     struct ib_udata *udata);
+int c4iw_destroy_qp(struct ib_qp *ib_qp);
 struct ib_qp *c4iw_create_qp(struct ib_pd *pd,
 			     struct ib_qp_init_attr *attrs,
 			     struct ib_udata *udata);
@@ -1242,11 +1329,4 @@
 void c4iw_invalidate_mr(struct c4iw_dev *rhp, u32 rkey);
 struct c4iw_wr_wait *c4iw_alloc_wr_wait(gfp_t gfp);
 
-typedef int c4iw_restrack_func(struct sk_buff *msg,
-			       struct rdma_restrack_entry *res);
-int c4iw_fill_res_mr_entry(struct sk_buff *msg, struct ib_mr *ibmr);
-int c4iw_fill_res_cq_entry(struct sk_buff *msg, struct ib_cq *ibcq);
-int c4iw_fill_res_qp_entry(struct sk_buff *msg, struct ib_qp *ibqp);
-int c4iw_fill_res_cm_id_entry(struct sk_buff *msg, struct rdma_cm_id *cm_id);
-
 #endif
diff -r 30 src/network/iw_cxgb4/mem.c
--- a/src/network/iw_cxgb4/mem.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/iw_cxgb4/mem.c	Tue May 18 15:02:47 2021 +0530
@@ -272,14 +272,10 @@
 			   struct sk_buff *skb, struct c4iw_wr_wait *wr_waitp)
 {
 	int err;
-	struct fw_ri_tpte *tpt;
+	struct fw_ri_tpte tpt;
 	u32 stag_idx;
 	static atomic_t key;
 
-	tpt = kmalloc(sizeof(*tpt), GFP_KERNEL);
-	if (!tpt)
-		return -ENOMEM;
-
 	stag_state = stag_state > 0;
 	stag_idx = (*stag) >> 8;
 
@@ -289,7 +285,6 @@
 			mutex_lock(&rdev->stats.lock);
 			rdev->stats.stag.fail++;
 			mutex_unlock(&rdev->stats.lock);
-			kfree(tpt);
 			return -ENOMEM;
 		}
 		mutex_lock(&rdev->stats.lock);
@@ -304,30 +299,30 @@
 
 	/* write TPT entry */
 	if (reset_tpt_entry)
-		memset(tpt, 0, sizeof(*tpt));
+		memset(&tpt, 0, sizeof(tpt));
 	else {
 		if (page_size > T6_MAX_PAGE_SIZE)
 			return -EINVAL;
-		tpt->valid_to_pdid = cpu_to_be32(F_FW_RI_TPTE_VALID |
+		tpt.valid_to_pdid = cpu_to_be32(F_FW_RI_TPTE_VALID |
 			V_FW_RI_TPTE_STAGKEY((*stag & M_FW_RI_TPTE_STAGKEY)) |
 			V_FW_RI_TPTE_STAGSTATE(stag_state) |
 			V_FW_RI_TPTE_STAGTYPE(type) | V_FW_RI_TPTE_PDID(pdid));
-		tpt->locread_to_qpid = cpu_to_be32(V_FW_RI_TPTE_PERM(perm) |
+		tpt.locread_to_qpid = cpu_to_be32(V_FW_RI_TPTE_PERM(perm) |
 			(bind_enabled ? F_FW_RI_TPTE_MWBINDEN : 0) |
 			V_FW_RI_TPTE_ADDRTYPE((zbva ? FW_RI_ZERO_BASED_TO :
 						      FW_RI_VA_BASED_TO))|
 			V_FW_RI_TPTE_PS(page_size));
-		tpt->nosnoop_pbladdr = !pbl_size ? 0 : cpu_to_be32(
+		tpt.nosnoop_pbladdr = !pbl_size ? 0 : cpu_to_be32(
 			V_FW_RI_TPTE_PBLADDR(PBL_OFF(rdev, pbl_addr)>>3));
-		tpt->len_lo = cpu_to_be32((u32)(len & 0xffffffffUL));
-		tpt->va_hi = cpu_to_be32((u32)(to >> 32));
-		tpt->va_lo_fbo = cpu_to_be32((u32)(to & 0xffffffffUL));
-		tpt->dca_mwbcnt_pstag = cpu_to_be32(0);
-		tpt->len_hi = cpu_to_be32((u32)(len >> 32));
+		tpt.len_lo = cpu_to_be32((u32)(len & 0xffffffffUL));
+		tpt.va_hi = cpu_to_be32((u32)(to >> 32));
+		tpt.va_lo_fbo = cpu_to_be32((u32)(to & 0xffffffffUL));
+		tpt.dca_mwbcnt_pstag = cpu_to_be32(0);
+		tpt.len_hi = cpu_to_be32((u32)(len >> 32));
 	}
 	err = write_adapter_mem(rdev, stag_idx +
 				(rdev->lldi.vr->stag.start >> 5),
-				sizeof(*tpt), tpt, skb, wr_waitp);
+				sizeof(tpt), &tpt, skb, wr_waitp);
 
 	if (reset_tpt_entry) {
 		c4iw_put_resource(&rdev->resource.tpt_table, stag_idx);
@@ -335,7 +330,6 @@
  		rdev->stats.stag.cur -= 32;
 		mutex_unlock(&rdev->stats.lock);
 	}
-	kfree(tpt);
 	return err;
 }
 
@@ -395,7 +389,7 @@
 	mmid = stag >> 8;
 	mhp->ibmr.rkey = mhp->ibmr.lkey = stag;
 	pr_debug("mmid 0x%x mhp %p\n", mmid, mhp);
-	return xa_insert_irq(&mhp->rhp->mrs, mmid, mhp, GFP_KERNEL);
+	return insert_handle(mhp->rhp, &mhp->rhp->mmidr, mhp, mmid);
 }
 
 static int register_mem(struct c4iw_dev *rhp, struct c4iw_pd *php,
@@ -512,7 +506,7 @@
 	unsigned dsize;
 	dma_addr_t daddr;
 	unsigned cur_size = 0;
-	dma_addr_t cur_addr;
+	dma_addr_t uninitialized_var(cur_addr);
 	int n;
 	struct ib_umem *umem = mhp->umem;
 	int err;
@@ -522,6 +516,7 @@
 	__u64 __user *usr_pbl_ptr;
 	int onepbl = 1;
 	int s;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5,2,0)
 	unsigned int pg_sz;
 
 	/* Allow only those MRs that are backed by huge pages(of size: HPAGE_SIZE). */
@@ -530,6 +525,7 @@
 		err = -EINVAL;
 		goto err;
 	}
+#endif
 
 	n = DIV_ROUND_UP(off + umem->length, HPAGE_SIZE);
 	err = alloc_pbl(mhp, n);
@@ -653,7 +649,7 @@
 	u32 mmid;
 
 	mmid = mr->attr.stag >> 8;
-	xa_erase_irq(&dev->mrs, mmid);
+	remove_handle(dev, &dev->mmidr, mmid);
 	if (mr->mpl)
 		dma_free_coherent(&mr->rhp->rdev.lldi.pdev->dev,
 				  mr->max_mpl_len, mr->mpl, mr->mpl_addr);
@@ -664,7 +660,8 @@
 				  mr->attr.pbl_size << 3);
 	if (mr->kva)
 		kfree((void *) (unsigned long) mr->kva);
-	ib_umem_release(mr->umem);
+	if (mr->umem)
+		ib_umem_release(mr->umem);
 	pr_debug("%s mmid 0x%x ptr %p\n", __func__, mmid, mr);
 	return;
 }
@@ -758,20 +755,16 @@
 
 #ifdef HAVE_PEER_MEM_SUPPORT
 	mutex_init(&mhp->live_lock);
-	mhp->umem = ib_umem_get(udata, start, length, acc, 0,
+	mhp->umem = ib_umem_get(pd->uobject->context, start, length, acc, 0,
 				IB_PEER_MEM_ALLOW | IB_PEER_MEM_INVAL_SUPP);
 #else
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-	mhp->umem = ib_umem_get(pd->device, start, length, acc);
-#else
-	mhp->umem = ib_umem_get(udata, start, length, acc, 0);
-#endif
+	mhp->umem = ib_umem_get(pd->uobject->context, start, length, acc, 0);
 #endif
 	if (IS_ERR(mhp->umem)) {
 		goto err_free_skb;
 	}
 
-	if (oldlib ||
+	if (oldlib || !mhp->umem->hugetlb ||
 	    try_huge_pbl(rhp, mhp, start, virt, udata, &shift)) {
 
 #ifdef HAVE_PEER_MEM_SUPPORT
@@ -797,9 +790,9 @@
 #endif
 
 #ifdef HAVE_IB_UMEM_PAGE_SHIFT
-		shift = PAGE_SHIFT;
+		shift = mhp->umem->page_shift;
 #else
-		shift = ffs(PAGE_SIZE) - 1;
+		shift = ffs(mhp->umem->page_size) - 1;
 #endif
 
 #ifdef HAVE_IB_UMEM_CHUNK
@@ -807,7 +800,7 @@
 		list_for_each_entry(chunk, &mhp->umem->chunk_list, list)
 			n += chunk->nents;
 #else
-		n = ib_umem_num_pages(mhp->umem);
+		n = mhp->umem->nmap;
 #endif
 
 		err = alloc_pbl(mhp, n);
@@ -854,7 +847,7 @@
 #ifdef HAVE_IB_UMEM_PAGE_SHIFT
 								(k << shift);
 #else
-						 PAGE_SIZE * k;
+						 mhp->umem->page_size * k;
 #endif /* HAVE_IB_UMEM_PAGE_SHIFT */
 #endif /* HAVE_IB_UMEM_CHUNK */
 
@@ -933,7 +926,8 @@
 	return ERR_PTR(err);
 }
 
-int c4iw_alloc_mw(struct ib_mw *ibmw, struct ib_udata *udata)
+struct ib_mw *c4iw_alloc_mw(struct ib_pd *pd, enum ib_mw_type type,
+			    struct ib_udata *udata)
 {
 	struct c4iw_dev *rhp;
 	struct c4iw_pd *php;
@@ -942,14 +936,14 @@
 	u32 stag = 0;
 	int ret;
 
-	if (ibmw->type != IB_MW_TYPE_1)
-		return -EINVAL;
+	if (type != IB_MW_TYPE_1)
+		return ERR_PTR(-EINVAL);
 
-	php = to_c4iw_pd(ibmw->pd);
+	php = to_c4iw_pd(pd);
 	rhp = php->rhp;
 	mhp = kzalloc(sizeof(*mhp), GFP_KERNEL);
 	if (!mhp)
-		return -ENOMEM;
+		return ERR_PTR(-ENOMEM);
 
 	mhp->wr_waitp = c4iw_alloc_wr_wait(GFP_KERNEL);
 	if (!mhp->wr_waitp) {
@@ -973,12 +967,12 @@
 	mhp->attr.stag = stag;
 	mmid = (stag) >> 8;
 	mhp->ibmw.rkey = stag;
-	if (xa_insert_irq(&rhp->mrs, mmid, mhp, GFP_KERNEL)) {
+	if (insert_handle(rhp, &rhp->mmidr, mhp, mmid)) {
 		ret = -ENOMEM;
 		goto dealloc_win;
 	}
 	pr_debug("mmid 0x%x mhp %p stag 0x%x\n", mmid, mhp, stag);
-	return 0;
+	return &(mhp->ibmw);
 
 dealloc_win:
 	deallocate_window(&rhp->rdev, mhp->attr.stag, mhp->dereg_skb,
@@ -990,7 +984,7 @@
 	c4iw_put_wr_wait(mhp->wr_waitp);
 free_mhp:
 	kfree(mhp);
-	return ret;
+	return ERR_PTR(ret);
 }
 
 int c4iw_dealloc_mw(struct ib_mw *mw)
@@ -1002,7 +996,7 @@
 	mhp = to_c4iw_mw(mw);
 	rhp = mhp->rhp;
 	mmid = (mw->rkey) >> 8;
-	xa_erase_irq(&rhp->mrs, mmid);
+	remove_handle(rhp, &rhp->mmidr, mmid);
 	deallocate_window(&rhp->rdev, mhp->attr.stag, mhp->dereg_skb,
 			  mhp->wr_waitp);
 	if (mhp->dereg_skb)
@@ -1069,7 +1063,7 @@
 	mhp->attr.state = 0;
 	mmid = (stag) >> 8;
 	mhp->ibmr.rkey = mhp->ibmr.lkey = stag;
-	if (xa_insert_irq(&rhp->mrs, mmid, mhp, GFP_KERNEL)) {
+	if (insert_handle(rhp, &rhp->mmidr, mhp, mmid)) {
 		ret = -ENOMEM;
 		goto err_dereg;
 	}
@@ -1123,7 +1117,7 @@
 #endif
 }
 
-int c4iw_dereg_mr(struct ib_mr *ib_mr, struct ib_udata *udata)
+int c4iw_dereg_mr(struct ib_mr *ib_mr)
 {
 #ifdef HAVE_PEER_MEM_SUPPORT
 	struct c4iw_mr *mhp;
@@ -1154,7 +1148,7 @@
 	mhp = to_c4iw_mr(ib_mr);
 	rhp = mhp->rhp;
 	mmid = mhp->attr.stag >> 8;
-	xa_erase_irq(&rhp->mrs, mmid);
+	remove_handle(rhp, &rhp->mmidr, mmid);
 	if (mhp->mpl)
 		dma_free_coherent(&mhp->rhp->rdev.lldi.pdev->dev,
 				  mhp->max_mpl_len, mhp->mpl, mhp->mpl_addr);
@@ -1180,9 +1174,9 @@
 	struct c4iw_mr *mhp;
 	unsigned long flags;
 
-	xa_lock_irqsave(&rhp->mrs, flags);
-	mhp = xa_load(&rhp->mrs, rkey >> 8);
+	spin_lock_irqsave(&rhp->lock, flags);
+	mhp = get_mhp(rhp, rkey >> 8);
 	if (mhp)
 		mhp->attr.state = 0;
-	xa_unlock_irqrestore(&rhp->mrs, flags);
+	spin_unlock_irqrestore(&rhp->lock, flags);
 }
diff -r 30 src/network/iw_cxgb4/provider.c
--- a/src/network/iw_cxgb4/provider.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/iw_cxgb4/provider.c	Tue May 18 15:02:47 2021 +0530
@@ -52,7 +52,6 @@
 #include <rdma/ib_smi.h>
 #include <rdma/ib_umem.h>
 #include <rdma/ib_user_verbs.h>
-//#include <rdma/cxgb4-abi.h>
 
 #include "iw_cxgb4.h"
 
@@ -71,19 +70,30 @@
 	return -ENOSYS;
 }
 
-static int c4iw_ah_create(struct ib_ah *ah,
-			  struct rdma_ah_init_attr *ah_attr,
-			  struct ib_udata *udata)
+static struct ib_ah *c4iw_ah_create(struct ib_pd *pd,
+#ifdef HAVE_EXT_CREATE_AH
+  #ifdef HAVE_IB_RDMA_AH_ATTR
+				    struct rdma_ah_attr *ah_attr,
+  #else
+				    struct ib_ah_attr *ah_attr,
+  #endif
+				    struct ib_udata *udata)
+#else
+  #ifdef HAVE_IB_RDMA_AH_ATTR
+				    struct rdma_ah_attr *ah_attr)
+  #else
+				    struct ib_ah_attr *ah_attr)
+  #endif
+#endif
+{
+	return ERR_PTR(-ENOSYS);
+}
+
+static int c4iw_ah_destroy(struct ib_ah *ah)
 {
 	return -ENOSYS;
 }
 
-static int c4iw_ah_destroy(struct ib_ah *ah, u32 flags)
-{
-	return -ENOSYS;
-}
-
-#if 0
 static int c4iw_multicast_attach(struct ib_qp *ibqp, union ib_gid *gid, u16 lid)
 {
 	struct c4iw_raw_qp *rqp;
@@ -139,46 +149,64 @@
 {
 	return -ENOSYS;
 }
-#endif
 
-static void c4iw_dealloc_ucontext(struct ib_ucontext *context)
+void _c4iw_free_ucontext(struct kref *kref)
 {
-	struct c4iw_ucontext *ucontext = to_c4iw_ucontext(context);
+	struct c4iw_ucontext *ucontext;
 	struct c4iw_dev *rhp;
 	struct c4iw_mm_entry *mm, *tmp;
 
-	pr_debug("context %p\n", context);
+	ucontext = container_of(kref, struct c4iw_ucontext, kref);
 	rhp = to_c4iw_dev(ucontext->ibucontext.device);
 
+	pr_debug("ucontext %p\n", ucontext);
 	list_for_each_entry_safe(mm, tmp, &ucontext->mmaps, entry)
 		kfree(mm);
 	c4iw_release_dev_ucontext(&rhp->rdev, &ucontext->uctx);
+	kfree(ucontext);
 }
 
-static int c4iw_alloc_ucontext(struct ib_ucontext *ucontext,
-			       struct ib_udata *udata)
+static int c4iw_dealloc_ucontext(struct ib_ucontext *context)
 {
-	struct ib_device *ibdev = ucontext->device;
-	struct c4iw_ucontext *context = to_c4iw_ucontext(ucontext);
+	struct c4iw_ucontext *ucontext = to_c4iw_ucontext(context);
+
+	pr_debug("context %p\n", context);
+	c4iw_put_ucontext(ucontext);
+	return 0;
+}
+
+static struct ib_ucontext *c4iw_alloc_ucontext(struct ib_device *ibdev,
+					       struct ib_udata *udata)
+{
+	struct c4iw_ucontext *context;
 	struct c4iw_dev *rhp = to_c4iw_dev(ibdev);
+	static int warned;
 	struct c4iw_alloc_ucontext_resp uresp;
 	int ret = 0;
 	struct c4iw_mm_entry *mm = NULL;
 
 	pr_debug("ibdev %p\n", ibdev);
+	context = kzalloc(sizeof(*context), GFP_KERNEL);
+	if (!context) {
+		ret = -ENOMEM;
+		goto err;
+	}
+
 	c4iw_init_dev_ucontext(&rhp->rdev, &context->uctx);
 	INIT_LIST_HEAD(&context->mmaps);
 	spin_lock_init(&context->mmap_lock);
+	kref_init(&context->kref);
 
 	if (udata->outlen < sizeof(uresp) - sizeof(uresp.reserved)) {
-		pr_err_once("Warning - downlevel libcxgb4 (non-fatal), device status page disabled\n");
+		if (!warned++)
+			pr_warn("Warning - downlevel libcxgb4 "
+				"(non-fatal), device status page disabled\n");
 		rhp->rdev.flags |= T4_STATUS_PAGE_DISABLED;
 	} else {
-		mm = kmalloc(sizeof(*mm), GFP_KERNEL);
-		if (!mm) {
-			ret = -ENOMEM;
-			goto err;
-		}
+
+		mm = kmalloc(sizeof *mm, GFP_KERNEL);
+		if (!mm)
+			goto err_free;
 
 		uresp.status_page_size = PAGE_SIZE;
 
@@ -197,11 +225,13 @@
 		mm->len = PAGE_SIZE;
 		insert_mmap(context, mm);
 	}
-	return 0;
+	return &context->ibucontext;
 err_mm:
 	kfree(mm);
+err_free:
+	kfree(context);
 err:
-	return ret;
+	return ERR_PTR(ret);
 }
 
 static int c4iw_mmap(struct ib_ucontext *context, struct vm_area_struct *vma)
@@ -278,7 +308,7 @@
 	return ret;
 }
 
-static int c4iw_deallocate_pd(struct ib_pd *pd, struct ib_udata *udata)
+static int c4iw_deallocate_pd(struct ib_pd *pd)
 {
 	struct c4iw_dev *rhp;
 	struct c4iw_pd *php;
@@ -290,14 +320,15 @@
 	mutex_lock(&rhp->rdev.stats.lock);
  	rhp->rdev.stats.pd.cur--;
 	mutex_unlock(&rhp->rdev.stats.lock);
-
+	kfree(php);
 	return 0;
 }
 
-static int c4iw_allocate_pd(struct ib_pd *pd, struct ib_udata *udata)
+static struct ib_pd *c4iw_allocate_pd(struct ib_device *ibdev,
+				      struct ib_ucontext *context,
+				      struct ib_udata *udata)
 {
-	struct c4iw_pd *php = to_c4iw_pd(pd);
-	struct ib_device *ibdev = pd->device;
+	struct c4iw_pd *php;
 	u32 pdid;
 	struct c4iw_dev *rhp;
 
@@ -305,14 +336,18 @@
 	rhp = (struct c4iw_dev *) ibdev;
 	pdid =  c4iw_get_resource(&rhp->rdev.resource.pdid_table);
 	if (!pdid)
-		return -EINVAL;
-
+		return ERR_PTR(-EINVAL);
+	php = kzalloc(sizeof(*php), GFP_KERNEL);
+	if (!php) {
+		c4iw_put_resource(&rhp->rdev.resource.pdid_table, pdid);
+		return ERR_PTR(-ENOMEM);
+	}
 	php->pdid = pdid;
 	php->rhp = rhp;
-	if (udata) {
+	if (context) {
 		if (ib_copy_to_udata(udata, &php->pdid, sizeof(u32))) {
-			c4iw_deallocate_pd(&php->ibpd, udata);
-			return -EFAULT;
+			c4iw_deallocate_pd(&php->ibpd);
+			return ERR_PTR(-EFAULT);
 		}
 	}
 	mutex_lock(&rhp->rdev.stats.lock);
@@ -321,7 +356,7 @@
 		rhp->rdev.stats.pd.max = rhp->rdev.stats.pd.cur;
 	mutex_unlock(&rhp->rdev.stats.lock);
 	pr_debug("pdid 0x%0x ptr 0x%p\n", pdid, php);
-	return 0;
+	return &php->ibpd;
 }
 
 static int c4iw_query_pkey(struct ib_device *ibdev, u8 port, u16 index,
@@ -399,6 +434,8 @@
 	props->local_ca_ack_delay = 0;
 	props->max_fast_reg_page_list_len = 
 		t4_max_fr_depth(dev->rdev.lldi.ulptx_memwrite_dsgl && use_dsgl);
+	props->max_fmr = dev->rdev.lldi.tids->ftid_base;
+	props->max_map_per_fmr = dev->rdev.nfids;
 	props->max_ah = dev->rdev.lldi.tids->nhpftids;
 	props->max_ee = dev->rdev.lldi.sge_ingpadboundary;
 	props->max_raw_ethy_qp = dev->rdev.lldi.neq;
@@ -409,8 +446,42 @@
 static int c4iw_query_port(struct ib_device *ibdev, u8 port,
 			   struct ib_port_attr *props)
 {
+	struct c4iw_dev *dev;
+	struct net_device *netdev;
+	struct in_device *inetdev;
+
 	pr_debug("ibdev %p\n", ibdev);
 
+	dev = to_c4iw_dev(ibdev);
+	netdev = dev->rdev.lldi.ports[port-1];
+
+	memset(props, 0, sizeof(struct ib_port_attr));
+	props->max_mtu = IB_MTU_4096;
+	if (netdev->mtu >= 4096)
+		props->active_mtu = IB_MTU_4096;
+	else if (netdev->mtu >= 2048)
+		props->active_mtu = IB_MTU_2048;
+	else if (netdev->mtu >= 1024)
+		props->active_mtu = IB_MTU_1024;
+	else if (netdev->mtu >= 512)
+		props->active_mtu = IB_MTU_512;
+	else
+		props->active_mtu = IB_MTU_256;
+
+	if (!netif_carrier_ok(netdev))
+		props->state = IB_PORT_DOWN;
+	else {
+		inetdev = in_dev_get(netdev);
+		if (inetdev) {
+			if (inetdev->ifa_list)
+				props->state = IB_PORT_ACTIVE;
+			else
+				props->state = IB_PORT_INIT;
+			in_dev_put(inetdev);
+		} else
+			props->state = IB_PORT_INIT;
+	}
+
 	props->port_cap_flags =
 	    IB_PORT_CM_SUP |
 	    IB_PORT_SNMP_TUNNEL_SUP |
@@ -429,8 +500,8 @@
 static ssize_t show_rev(struct device *dev, struct device_attribute *attr,
 			char *buf)
 {
-	struct c4iw_dev *c4iw_dev =
-			rdma_device_to_drv_device(dev, struct c4iw_dev, ibdev);
+	struct c4iw_dev *c4iw_dev = container_of(dev, struct c4iw_dev,
+						 ibdev.dev);
 	pr_debug("dev 0x%p\n", dev);
 	return sprintf(buf, "%d\n",
 		       CHELSIO_CHIP_RELEASE(c4iw_dev->rdev.lldi.adapter_type));
@@ -439,8 +510,8 @@
 static ssize_t show_hca(struct device *dev, struct device_attribute *attr,
 			char *buf)
 {
-	struct c4iw_dev *c4iw_dev =
-			rdma_device_to_drv_device(dev, struct c4iw_dev, ibdev);
+	struct c4iw_dev *c4iw_dev = container_of(dev, struct c4iw_dev,
+						 ibdev.dev);
 	struct ethtool_drvinfo info;
 	struct net_device *lldev = c4iw_dev->rdev.lldi.ports[0];
 
@@ -452,8 +523,8 @@
 static ssize_t show_board(struct device *dev, struct device_attribute *attr,
 			  char *buf)
 {
-	struct c4iw_dev *c4iw_dev =
-			rdma_device_to_drv_device(dev, struct c4iw_dev, ibdev);
+	struct c4iw_dev *c4iw_dev = container_of(dev, struct c4iw_dev,
+						 ibdev.dev);
 	pr_debug("dev 0x%p\n", dev);
 	return sprintf(buf, "%x.%x\n", c4iw_dev->rdev.lldi.pdev->vendor,
 		       c4iw_dev->rdev.lldi.pdev->device);
@@ -581,81 +652,22 @@
 		 G_FW_HDR_FW_VER_BUILD(c4iw_dev->rdev.lldi.fw_vers));
 }
 
-static const struct ib_device_ops c4iw_dev_ops = {
-	.owner = THIS_MODULE,
-	.driver_id = RDMA_DRIVER_CXGB4,
-	.uverbs_abi_ver = C4IW_UVERBS_ABI_VERSION,
+static struct net_device *get_netdev(struct ib_device *dev, u8 port)
+{
+	struct c4iw_dev *c4iw_dev = container_of(dev, struct c4iw_dev, ibdev);
+	struct c4iw_rdev *rdev = &c4iw_dev->rdev;
+	struct net_device *ndev;
 
-#ifdef IWARP_DEV_COUNTER_DYNAMIC
-	.alloc_hw_stats = c4iw_alloc_stats,
-	.get_hw_stats = c4iw_get_mib,
-#endif
-	.alloc_mr = c4iw_alloc_mr,
-	.alloc_mw = c4iw_alloc_mw,
-	.alloc_pd = c4iw_allocate_pd,
-	.alloc_ucontext = c4iw_alloc_ucontext,
-	.create_cq = c4iw_create_cq,
-	.create_qp = c4iw_create_qp,
-	.create_srq = c4iw_create_srq,
-	.dealloc_mw = c4iw_dealloc_mw,
-	.dealloc_pd = c4iw_deallocate_pd,
-	.create_ah = c4iw_ah_create,
-	.dealloc_ucontext = c4iw_dealloc_ucontext,
-	.dereg_mr = c4iw_dereg_mr,
-	.destroy_cq = c4iw_destroy_cq,
-	.destroy_qp = c4iw_destroy_qp,
-	.destroy_srq = c4iw_destroy_srq,
-	.fill_res_cm_id_entry = c4iw_fill_res_cm_id_entry,
-	.destroy_ah = c4iw_ah_destroy, 
-	.fill_res_cq_entry = c4iw_fill_res_cq_entry,
-	.fill_res_mr_entry = c4iw_fill_res_mr_entry,
-	.get_dev_fw_str = get_dev_fw_str,
-	.get_dma_mr = c4iw_get_dma_mr,
-#ifdef IWARP_HAVE_CQ_INIT_ATTR
-	.get_port_immutable = c4iw_port_immutable,
-#endif
-	.iw_accept = c4iw_accept_cr,
-	.iw_add_ref = c4iw_qp_add_ref,
-	.iw_connect = c4iw_connect,
-	.iw_create_listen = c4iw_create_listen,
-	.iw_destroy_listen = c4iw_destroy_listen,
-	.iw_get_qp = c4iw_get_qp,
-	.iw_reject = c4iw_reject_cr,
-	.iw_rem_ref = c4iw_qp_rem_ref,
-	.map_mr_sg = c4iw_map_mr_sg,
-	.mmap = c4iw_mmap,
-	.modify_qp = c4iw_ib_modify_qp,
-	.modify_srq = c4iw_modify_srq,
-	.poll_cq = c4iw_poll_cq,
-	.post_recv = c4iw_post_receive,
-	.post_send = c4iw_post_send,
-	.post_srq_recv = c4iw_post_srq_recv,
-	.query_device = c4iw_query_device,
-	.query_gid = c4iw_query_gid,
-	.query_pkey = c4iw_query_pkey,
-	.query_port = c4iw_query_port,
-	.modify_port = c4iw_modify_port,
-	.query_qp = c4iw_ib_query_qp,
-	.reg_user_mr = c4iw_reg_user_mr,
-	.req_notify_cq = c4iw_arm_cq,
-	INIT_RDMA_OBJ_SIZE(ib_pd, c4iw_pd, ibpd),
-	INIT_RDMA_OBJ_SIZE(ib_cq, c4iw_cq, ibcq),
-	INIT_RDMA_OBJ_SIZE(ib_srq, c4iw_srq, ibsrq),
-	INIT_RDMA_OBJ_SIZE(ib_ucontext, c4iw_ucontext, ibucontext),
-};
+	if (!port || port > rdev->lldi.nports)
+		return NULL;
 
-static int set_netdevs(struct ib_device *ib_dev, struct c4iw_rdev *rdev)
-{
-	int ret;
-	int i;
+	rcu_read_lock();
+	ndev = rdev->lldi.ports[port - 1];
+	if (ndev)
+		dev_hold(ndev);
+	rcu_read_unlock();
 
-	for (i = 0; i < rdev->lldi.nports; i++) {
-		ret = ib_device_set_netdev(ib_dev, rdev->lldi.ports[i],
-					   i + 1);
-		if (ret)
-			return ret;
-	}
-	return 0;
+	return ndev;
 }
 
 void c4iw_register_device(struct work_struct *work)
@@ -669,6 +681,7 @@
 	strlcpy(dev->ibdev.name, "cxgb4_%d", IB_DEVICE_NAME_MAX);
 	memset(&dev->ibdev.node_guid, 0, sizeof(dev->ibdev.node_guid));
 	memcpy(&dev->ibdev.node_guid, dev->rdev.lldi.ports[0]->dev_addr, 6);
+	dev->ibdev.owner = THIS_MODULE;
 	dev->device_cap_flags = IB_DEVICE_LOCAL_DMA_LKEY | IB_DEVICE_MEM_WINDOW;
 	if (fastreg_support)
 		dev->device_cap_flags |= IB_DEVICE_MEM_MGT_EXTENSIONS;
@@ -709,21 +722,79 @@
 #else
 	dev->ibdev.dma_device = &(dev->rdev.lldi.pdev->dev);
 #endif
-#ifndef IWARP_DEV_COUNTER_DYNAMIC
+	dev->ibdev.query_device = c4iw_query_device;
+	dev->ibdev.query_port = c4iw_query_port;
+	dev->ibdev.modify_port = c4iw_modify_port;
+	dev->ibdev.query_pkey = c4iw_query_pkey;
+	dev->ibdev.query_gid = c4iw_query_gid;
+	dev->ibdev.alloc_ucontext = c4iw_alloc_ucontext;
+	dev->ibdev.dealloc_ucontext = c4iw_dealloc_ucontext;
+	dev->ibdev.mmap = c4iw_mmap;
+	dev->ibdev.alloc_pd = c4iw_allocate_pd;
+	dev->ibdev.dealloc_pd = c4iw_deallocate_pd;
+	dev->ibdev.create_ah = c4iw_ah_create;
+	dev->ibdev.destroy_ah = c4iw_ah_destroy;
+	dev->ibdev.create_qp = c4iw_create_qp;
+	dev->ibdev.modify_qp = c4iw_ib_modify_qp;
+	dev->ibdev.query_qp = c4iw_ib_query_qp;
+	dev->ibdev.destroy_qp = c4iw_destroy_qp;
+	dev->ibdev.create_srq = c4iw_create_srq;
+	dev->ibdev.modify_srq = c4iw_modify_srq;
+	dev->ibdev.destroy_srq = c4iw_destroy_srq;
+	dev->ibdev.create_cq = c4iw_create_cq;
+	dev->ibdev.destroy_cq = c4iw_destroy_cq;
+	dev->ibdev.resize_cq = c4iw_resize_cq;
+	dev->ibdev.poll_cq = c4iw_poll_cq;
+	dev->ibdev.get_dma_mr = c4iw_get_dma_mr;
+	dev->ibdev.reg_user_mr = c4iw_reg_user_mr;
+	dev->ibdev.dereg_mr = c4iw_dereg_mr;
+	dev->ibdev.alloc_mw = c4iw_alloc_mw;
+	dev->ibdev.dealloc_mw = c4iw_dealloc_mw;
+	dev->ibdev.alloc_mr = c4iw_alloc_mr;
+	dev->ibdev.map_mr_sg = c4iw_map_mr_sg;
+	dev->ibdev.attach_mcast = c4iw_multicast_attach;
+	dev->ibdev.detach_mcast = c4iw_multicast_detach;
+	dev->ibdev.process_mad = c4iw_process_mad;
+	dev->ibdev.req_notify_cq = c4iw_arm_cq;
+	dev->ibdev.post_send = c4iw_post_send;
+	dev->ibdev.post_recv = c4iw_post_receive;
+	dev->ibdev.post_srq_recv = c4iw_post_srq_recv;
+#ifdef IWARP_DEV_COUNTER_DYNAMIC
+	dev->ibdev.alloc_hw_stats = c4iw_alloc_stats;
+	dev->ibdev.get_hw_stats = c4iw_get_mib;
+#else
 	dev->ibdev.get_protocol_stats = c4iw_get_mib;
 #endif
-	ib_set_device_ops(&dev->ibdev, &c4iw_dev_ops);
-	ret = set_netdevs(&dev->ibdev, &dev->rdev);
-	if (ret)
+	dev->ibdev.uverbs_abi_ver = C4IW_UVERBS_ABI_VERSION;
+	dev->ibdev.num_comp_vectors = dev->rdev.lldi.nciq;
+#ifdef IWARP_HAVE_CQ_INIT_ATTR
+	dev->ibdev.get_port_immutable = c4iw_port_immutable;
+#endif
+	dev->ibdev.get_dev_fw_str = get_dev_fw_str;
+	dev->ibdev.get_netdev = get_netdev;
+
+	dev->ibdev.iwcm = kmalloc(sizeof(struct iw_cm_verbs), GFP_KERNEL);
+	if (!dev->ibdev.iwcm) {
+		ret = -ENOMEM;
 		goto err_dealloc_ctx;
+	}
+
+	dev->ibdev.iwcm->connect = c4iw_connect;
+	dev->ibdev.iwcm->accept = c4iw_accept_cr;
+	dev->ibdev.iwcm->reject = c4iw_reject_cr;
+	dev->ibdev.iwcm->create_listen = c4iw_create_listen;
+	dev->ibdev.iwcm->destroy_listen = c4iw_destroy_listen;
+	dev->ibdev.iwcm->add_ref = c4iw_qp_add_ref;
+	dev->ibdev.iwcm->rem_ref = c4iw_qp_rem_ref;
+	dev->ibdev.iwcm->get_qp = c4iw_get_qp;
+	dev->ibdev.driver_id = RDMA_DRIVER_CXGB4;
 #ifdef IBREGDEV2
-	ret = ib_register_device(&dev->ibdev, "cxgb4_%d");
+	ret = ib_register_device(&dev->ibdev, NULL);
 #else
-	ret = ib_register_device(&dev->ibdev, "cxgb4_%d",
-				 &dev->rdev.lldi.pdev->dev);
+	ret = ib_register_device(&dev->ibdev);
 #endif
 	if (ret)
-		goto err_dealloc_ctx;
+		goto err_kfree_iwcm;
 
 	for (i = 0; i < ARRAY_SIZE(c4iw_class_attributes); ++i) {
 		ret = device_create_file(&dev->ibdev.dev,
@@ -734,6 +805,8 @@
 	return;
 err_unregister_device:
 	ib_unregister_device(&dev->ibdev);
+err_kfree_iwcm:
+	kfree(dev->ibdev.iwcm);
 err_dealloc_ctx:
 	pr_err("%s - Failed registering iwarp device: %d\n",
 	       pci_name(ctx->lldi.pdev), ret);
@@ -750,5 +823,6 @@
 		device_remove_file(&dev->ibdev.dev,
 				   c4iw_class_attributes[i]);
 	ib_unregister_device(&dev->ibdev);
+	kfree(dev->ibdev.iwcm);
 	return;
 }
diff -r 30 src/network/iw_cxgb4/qp.c
--- a/src/network/iw_cxgb4/qp.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/iw_cxgb4/qp.c	Tue May 18 15:02:47 2021 +0530
@@ -37,7 +37,6 @@
 #include <linux/pci.h>
 
 #include <rdma/ib_user_verbs.h>
-#include <rdma/uverbs_ioctl.h>
 
 #include <cxgbtool.h>
 
@@ -56,7 +55,7 @@
 
 static int max_fr_immd = T4_MAX_FR_IMMD;
 module_param(max_fr_immd, int, 0644);
-MODULE_PARM_DESC(max_fr_immd, "fastreg threshold for using DSGL instead of immediate");
+MODULE_PARM_DESC(max_fr_immd, "fastreg threshold for using DSGL instead of immedate");
 
 #ifdef ARCH_HAS_IOREMAP_WC
 int t5_en_wc = 1;
@@ -71,7 +70,7 @@
 {
 	int ret;
 
-	xa_lock_irq(&dev->qps);
+	spin_lock_irq(&dev->lock);
 	if (ird <= dev->avail_ird) {
 		dev->avail_ird -= ird;
 		ret = 0;
@@ -80,15 +79,15 @@
 		pr_warn("%s: device IRD resources exhausted\n",
 		       pci_name(dev->rdev.lldi.pdev));
 	}
-	xa_unlock_irq(&dev->qps);
+	spin_unlock_irq(&dev->lock);
 	return ret;
 }
 
 static void free_ird(struct c4iw_dev *dev, int ird)
 {
-	xa_lock_irq(&dev->qps);
+	spin_lock_irq(&dev->lock);
 	dev->avail_ird += ird;
-	xa_unlock_irq(&dev->qps);
+	spin_unlock_irq(&dev->lock);
 }
 
 static void set_state(struct c4iw_qp *qhp, enum c4iw_qp_state state)
@@ -107,7 +106,7 @@
 static void dealloc_host_sq(struct c4iw_rdev *rdev, struct t4_sq *sq)
 {
 	dma_free_coherent(&(rdev->lldi.pdev->dev), sq->memsize, sq->queue,
-			  dma_unmap_addr(sq, mapping));
+			  pci_unmap_addr(sq, mapping));
 }
 
 static void dealloc_sq(struct c4iw_rdev *rdev, struct t4_sq *sq)
@@ -140,7 +139,7 @@
 	if (!sq->queue)
 		return -ENOMEM;
 	sq->phys_addr = virt_to_phys(sq->queue);
-	dma_unmap_addr_set(sq, mapping, sq->dma_addr);
+	pci_unmap_addr_set(sq, mapping, sq->dma_addr);
 	return 0;
 }
 
@@ -215,7 +214,8 @@
 	mm_segment_t oldfs;
 	int i;
 
-	oldfs = force_uaccess_begin();
+	oldfs = get_fs();
+	set_fs(KERNEL_DS);
 	for (i = 0; i < rqp->nfids; i++) {
 		do {
 			int filter_id;
@@ -236,7 +236,7 @@
 			schedule_timeout(usecs_to_jiffies(500));
 		} while (1);
 	}
-	force_uaccess_end(oldfs);
+	set_fs(oldfs);
 
 	if (ret && ret != -E2BIG)
 		pr_warn("del filter %u failed ret %d\n",
@@ -283,7 +283,7 @@
 
 	dma_free_coherent(&(rdev->lldi.pdev->dev),
 			  wq->memsize, wq->queue,
-			  dma_unmap_addr(wq, mapping));
+			  pci_unmap_addr(wq, mapping));
 	c4iw_rqtpool_free(rdev, wq->rqt_hwaddr, wq->rqt_size);
 	kfree(wq->sw_rq);
 	c4iw_put_qpid(rdev, wq->qid, uctx);
@@ -331,7 +331,8 @@
 	if (!wq->queue)
 		goto err_free_rqtpool;
 
-	dma_unmap_addr_set(wq, mapping, wq->dma_addr);
+	memset(wq->queue, 0, wq->memsize);
+	pci_unmap_addr_set(wq, mapping, wq->dma_addr);
 
 	wq->bar2_va = c4iw_bar2_addrs(rdev, wq->qid, T4_BAR2_QTYPE_EGRESS,
 					 &wq->bar2_qid,
@@ -350,7 +351,7 @@
 	/* build fw_ri_res_wr */
 	wr_len = sizeof *res_wr + sizeof *res;
 
-	skb = alloc_skb(wr_len, GFP_KERNEL);
+	skb = alloc_skb(wr_len, GFP_KERNEL | __GFP_NOFAIL);
 	if (!skb)
 		goto err_free_queue;
 	set_wr_txq(skb, CPL_PRIORITY_CONTROL, NCHAN);
@@ -409,7 +410,7 @@
 err_free_queue:
 	dma_free_coherent(&(rdev->lldi.pdev->dev),
 			  wq->memsize, wq->queue,
-			  dma_unmap_addr(wq, mapping));
+			  pci_unmap_addr(wq, mapping));
 err_free_rqtpool:
 	c4iw_rqtpool_free(rdev, wq->rqt_hwaddr, wq->rqt_size);
 err_free_pending_wrs:
@@ -876,7 +877,7 @@
 	if (has_rq)
 		dma_free_coherent(&(rdev->lldi.pdev->dev),
 				  wq->rq.memsize, wq->rq.queue,
-				  dma_unmap_addr(&wq->rq, mapping));
+				  pci_unmap_addr(&wq->rq, mapping));
 	dealloc_sq(rdev, &wq->sq);
 	if (has_rq) {
 		c4iw_rqtpool_free(rdev, wq->rq.rqt_hwaddr, wq->rq.rqt_size);
@@ -978,7 +979,8 @@
 						  GFP_KERNEL);
 		if (!wq->rq.queue)
 			goto err6;
-		dma_unmap_addr_set(&wq->rq, mapping, wq->rq.dma_addr);
+		memset(wq->rq.queue, 0, wq->rq.memsize);
+		pci_unmap_addr_set(&wq->rq, mapping, wq->rq.dma_addr);
 	}
 	wq->db = rdev->lldi.db_reg;
 
@@ -1096,7 +1098,7 @@
 	if (need_rq)
 		dma_free_coherent(&(rdev->lldi.pdev->dev),
 				  wq->rq.memsize, wq->rq.queue,
-				  dma_unmap_addr(&wq->rq, mapping));
+				  pci_unmap_addr(&wq->rq, mapping));
 err6:
 	dealloc_sq(rdev, &wq->sq);
 err5:
@@ -1544,12 +1546,40 @@
 	return 0;
 }
 
+static void free_qp_work(struct work_struct *work)
+{
+	struct c4iw_ucontext *ucontext;
+	struct c4iw_qp *qhp;
+	struct c4iw_dev *rhp;
+
+	qhp = container_of(work, struct c4iw_qp, free_work);
+	ucontext = qhp->ucontext;
+	rhp = qhp->rhp;
+
+	pr_debug("qhp %p ucontext %p\n", qhp, ucontext);
+	free_rc_queues(&rhp->rdev, &qhp->wq, ucontext ?
+		       &ucontext->uctx : &rhp->rdev.uctx, !qhp->srq);
+	if (ucontext)
+		c4iw_put_ucontext(ucontext);
+	c4iw_put_wr_wait(qhp->wr_waitp);
+	kfree(qhp);
+}
+
+static void queue_qp_free(struct kref * kref)
+{
+	struct c4iw_qp *qhp;
+
+	qhp = container_of(kref, struct c4iw_qp, kref);
+	pr_debug("qhp %p\n", qhp);
+	queue_work(qhp->rhp->rdev.free_workq, &qhp->free_work);
+}
+
 void c4iw_qp_add_ref(struct ib_qp *qp)
 {
 	pr_debug("ib_qp %p\n", qp);
 	switch (qp->qp_type) {
 	case IB_QPT_RC:
-		refcount_inc(&to_c4iw_qp(qp)->qp_refcnt);
+		kref_get(&to_c4iw_qp(qp)->kref);
 		break;
 	case IB_QPT_RAW_ETH:
 		atomic_inc(&(to_c4iw_raw_qp(qp)->refcnt));
@@ -1564,8 +1594,7 @@
 	pr_debug("ib_qp %p\n", qp);
 	switch (qp->qp_type) {
 	case IB_QPT_RC:
-		if (refcount_dec_and_test(&to_c4iw_qp(qp)->qp_refcnt))
-			complete(&to_c4iw_qp(qp)->qp_rel_comp);
+		kref_put(&to_c4iw_qp(qp)->kref, queue_qp_free);
 		break;
 	case IB_QPT_RAW_ETH:
 		if (atomic_dec_and_test(&(to_c4iw_raw_qp(qp)->refcnt)))
@@ -1602,7 +1631,7 @@
 {
 	unsigned long flags;
 
-	xa_lock_irqsave(&qhp->rhp->qps, flags);
+	spin_lock_irqsave(&qhp->rhp->lock, flags);
 	spin_lock(&qhp->lock);
 	if (qhp->rhp->db_state == NORMAL)
 		t4_ring_sq_db(&qhp->wq, inc, NULL);
@@ -1611,7 +1640,7 @@
 		qhp->wq.sq.wq_pidx_inc += inc;
 	}
 	spin_unlock(&qhp->lock);
-	xa_unlock_irqrestore(&qhp->rhp->qps, flags);
+	spin_unlock_irqrestore(&qhp->rhp->lock, flags);
 	return 0;
 }
 
@@ -1679,7 +1708,7 @@
 {
 	unsigned long flags;
 
-	xa_lock_irqsave(&qhp->rhp->qps, flags);
+	spin_lock_irqsave(&qhp->rhp->lock, flags);
 	spin_lock(&qhp->lock);
 	if (qhp->rhp->db_state == NORMAL)
 		t4_ring_rq_db(&qhp->wq, inc, NULL);
@@ -1688,7 +1717,7 @@
 		qhp->wq.rq.wq_pidx_inc += inc;
 	}
 	spin_unlock(&qhp->lock);
-	xa_unlock_irqrestore(&qhp->rhp->qps, flags);
+	spin_unlock_irqrestore(&qhp->rhp->lock, flags);
 	return 0;
 }
 
@@ -1855,7 +1884,7 @@
 	if (c4iw_wr_log) {
 		swsqe->sge_ts =
 			cxgb4_read_sge_timestamp(qhp->rhp->rdev.lldi.ports[0]);
-		swsqe->host_time = ktime_get();
+		getnstimeofday(&swsqe->host_ts);
 	}
 
 	write_wrid = qhp->wq.sq.pidx;
@@ -1879,7 +1908,7 @@
 	if (c4iw_wr_log) {
 		swsqe->sge_ts =
 			cxgb4_read_sge_timestamp(qhp->rhp->rdev.lldi.ports[0]);
-		swsqe->host_time = ktime_get();
+		getnstimeofday(&swsqe->host_ts);
 	}
 
 	wqe->write_cmpl.flags_send = send_signaled ? FW_RI_COMPLETION_FLAG : 0;
@@ -2053,7 +2082,7 @@
 		if (c4iw_wr_log) {
 			swsqe->sge_ts =
 				cxgb4_read_sge_timestamp(qhp->rhp->rdev.lldi.ports[0]);
-			swsqe->host_time = ktime_get();
+			getnstimeofday(&swsqe->host_ts);
 		}
 
 		init_wr_hdr(wqe, qhp->wq.sq.pidx, fw_opcode, fw_flags, len16);
@@ -2142,7 +2171,7 @@
 		if (c4iw_wr_log) {
 			qhp->wq.rq.sw_rq[qhp->wq.rq.pidx].sge_ts =
 				cxgb4_read_sge_timestamp(qhp->rhp->rdev.lldi.ports[0]);
-			qhp->wq.rq.sw_rq[qhp->wq.rq.pidx].host_time = ktime_get();
+			getnstimeofday(&qhp->wq.rq.sw_rq[qhp->wq.rq.pidx].host_ts);
 		}
 
 		wqe->recv.opcode = FW_RI_RECV_WR;
@@ -3015,9 +3044,9 @@
 	modify_raw_qp(rqp, C4IW_QP_ATTR_NEXT_STATE, &attrs);
 
 	if (!ib_qp->srq)
-		xa_erase_irq(&rhp->rawiqs, rqp->iq.cntxt_id);
-	xa_erase_irq(&rhp->rawqps, rqp->txq.cntxt_id);
-	xa_erase_irq(&rhp->fids, rqp->fid);
+		remove_handle(rhp, &rhp->rawiqidr, rqp->iq.cntxt_id);
+	remove_handle(rhp, &rhp->rawqpidr, rqp->txq.cntxt_id);
+	remove_handle(rhp, &rhp->fididr, rqp->fid);
 
 	atomic_dec(&rqp->refcnt);
 	wait_event(rqp->wait, !atomic_read(&rqp->refcnt));
@@ -3056,12 +3085,10 @@
 {
 	struct c4iw_dev *rhp;
 	struct c4iw_qp *qhp;
-	struct c4iw_ucontext *ucontext;
 	struct c4iw_qp_attributes attrs;
 
 	qhp = to_c4iw_qp(ib_qp);
 	rhp = qhp->rhp;
-	ucontext = qhp->ucontext;
 
 	attrs.next_state = C4IW_QP_STATE_ERROR;
 	if (qhp->attr.state == C4IW_QP_STATE_TERMINATE)
@@ -3070,32 +3097,21 @@
 		c4iw_modify_rc_qp(qhp, C4IW_QP_ATTR_NEXT_STATE, &attrs, 0);
 	wait_event(qhp->wait, !qhp->ep);
 
-
-	xa_lock_irq(&rhp->qps);
-	__xa_erase(&rhp->qps, qhp->wq.sq.qid);
+	remove_handle(rhp, &rhp->qpidr, qhp->wq.sq.qid);
+
+	spin_lock_irq(&rhp->lock);
 	if (!list_empty(&qhp->fcl.db_fc_entry)) {
 		list_del_init(&qhp->fcl.db_fc_entry);
 	}
-	xa_unlock_irq(&rhp->qps);
+	spin_unlock_irq(&rhp->lock);
 	free_ird(rhp, qhp->attr.max_ird);
 
+	pr_debug("ib_qp %p qpid 0x%0x\n", ib_qp, qhp->wq.sq.qid);
 	c4iw_qp_rem_ref(ib_qp);
-
-	wait_for_completion(&qhp->qp_rel_comp);
-
-	pr_debug("ib_qp %p qpid 0x%0x\n", ib_qp, qhp->wq.sq.qid);
-	pr_debug("qhp %p ucontext %p\n", qhp, ucontext);
-
-	free_rc_queues(&rhp->rdev, &qhp->wq, ucontext ?
-		       &ucontext->uctx : &rhp->rdev.uctx, !qhp->srq);
-
-	c4iw_put_wr_wait(qhp->wr_waitp);
-
-	kfree(qhp);
 	return;
 }
 
-int c4iw_destroy_qp(struct ib_qp *ib_qp, struct ib_udata *udata)
+int c4iw_destroy_qp(struct ib_qp *ib_qp)
 {
 	pr_debug("qpid %d\n", ib_qp->qp_num);
 	switch (ib_qp->qp_type) {
@@ -3123,8 +3139,7 @@
 	struct c4iw_cq *rchp;
 	struct c4iw_create_qp_resp uresp = {0};
 	int sqsize, rqsize = 0;
-	struct c4iw_ucontext *ucontext = rdma_udata_to_drv_context(
-			udata, struct c4iw_ucontext, ibucontext);
+	struct c4iw_ucontext *ucontext;
 	int ret;
 	struct c4iw_mm_entry *sq_key_mm, *rq_key_mm = NULL, *sq_db_key_mm;
 	struct c4iw_mm_entry *rq_db_key_mm = NULL, *ma_sync_key_mm = NULL;
@@ -3152,6 +3167,8 @@
 	if (attrs->cap.max_send_wr > rhp->rdev.hw_queue.t4_max_sq_size)
 		return ERR_PTR(-E2BIG);
 
+	ucontext = pd->uobject ? to_c4iw_ucontext(pd->uobject->context) : NULL;
+
 	/* 
 	 * Temporary workaround for iSER. iSER needs relatively large SQ for iw_cxgb4.
 	 * Therefore we factor max_send_wr with 3 based on unique SQ size of iSER
@@ -3224,10 +3241,10 @@
 	spin_lock_init(&qhp->lock);
 	mutex_init(&qhp->mutex);
 	init_waitqueue_head(&qhp->wait);
-	init_completion(&qhp->qp_rel_comp);
-	refcount_set(&qhp->qp_refcnt, 1);
-
-	ret = xa_insert_irq(&rhp->qps, qhp->wq.sq.qid, qhp, GFP_KERNEL);
+	kref_init(&qhp->kref);
+	INIT_WORK(&qhp->free_work, free_qp_work);
+
+	ret = insert_handle(rhp, &rhp->qpidr, qhp, qhp->wq.sq.qid);
 	if (ret)
 		goto err_destroy_qp;
 
@@ -3327,6 +3344,7 @@
 			insert_mmap(ucontext, ma_sync_key_mm);
 		}
 
+		c4iw_get_ucontext(ucontext);
 		qhp->ucontext = ucontext;
 	}
 	if (!attrs->srq)
@@ -3362,7 +3380,7 @@
 err_free_sq_key:
 	kfree(sq_key_mm);
 err_remove_handle:
-	xa_erase_irq(&rhp->qps, qhp->wq.sq.qid);
+	remove_handle(rhp, &rhp->qpidr, qhp->wq.sq.qid);
 err_destroy_qp:
 	free_rc_queues(&rhp->rdev, &qhp->wq,
 		   ucontext ? &ucontext->uctx : &rhp->rdev.uctx, !attrs->srq);
@@ -3450,8 +3468,7 @@
 		iqsize = rchp->cq.size + 1;
 	}
 
-	ucontext = rdma_udata_to_drv_context(udata, struct c4iw_ucontext,
-					     ibucontext);
+	ucontext = to_c4iw_ucontext(pd->uobject->context);
 
 	rqp = kzalloc(sizeof(*rqp), GFP_KERNEL);
 	if (!rqp)
@@ -3503,7 +3520,8 @@
 	attrs->cap.max_inline_data = T4_MAX_SEND_INLINE;
 
 	if (!attrs->srq) {
-		ret = xa_insert_irq(&rhp->rawiqs, rqp->iq.cntxt_id, &rqp->fcl, GFP_KERNEL);
+		ret = insert_handle(rhp, &rhp->rawiqidr, &rqp->fcl,
+				    rqp->iq.cntxt_id);
 		if (ret)
 			goto err3;
 		fl_key_mm = kmalloc(sizeof *fl_key_mm, GFP_KERNEL);
@@ -3661,10 +3679,10 @@
 	}
 	rqp->ibqp.qp_num = rqp->txq.cntxt_id;
 
-	ret = xa_insert_irq(&rhp->rawqps, rqp->txq.cntxt_id, rqp, GFP_KERNEL);
+	ret = insert_handle(rhp, &rhp->rawqpidr, rqp, rqp->txq.cntxt_id);
 	if (ret)
 		goto err8;
-	ret = xa_insert_irq(&rhp->fids, rqp->fid, rchp, GFP_KERNEL);
+	ret = insert_handle(rhp, &rhp->fididr, rchp, rqp->fid);
 	if (ret)
 		goto err9;
 
@@ -3681,7 +3699,7 @@
 
 	return &rqp->ibqp;
 err9:
-	xa_erase_irq(&rhp->rawqps, rqp->txq.cntxt_id);
+	remove_handle(rhp, &rhp->rawqpidr, rqp->txq.cntxt_id);
 err8:
 	if (!is_t4(rhp->rdev.lldi.adapter_type))
 		remove_mmap(ucontext, fl_db_key_mm->key, fl_db_key_mm->len);
@@ -3718,7 +3736,7 @@
 		kfree(fl_key_mm);
 err4:
 	if (!attrs->srq)
-		xa_erase_irq(&rhp->rawiqs, rqp->iq.cntxt_id);
+		remove_handle(rhp, &rhp->rawiqidr, rqp->iq.cntxt_id);
 err3:
 	put_fid(rqp);
 err2a:
@@ -3905,15 +3923,17 @@
 
 	pr_debug("iqid %d\n", srq->iq.cntxt_id);
 
-	xa_erase_irq(&rhp->rawiqs, srq->iq.cntxt_id);
+	remove_handle(rhp, &rhp->rawiqidr, srq->iq.cntxt_id);
 	spin_lock_irq(&rhp->lock);
 	if (!list_empty(&srq->fcl.db_fc_entry))
 		list_del_init(&srq->fcl.db_fc_entry);
 	spin_unlock_irq(&rhp->lock);
 	free_raw_srq(rhp, srq);
+	kfree(srq);
+	return;
 }
 
-static void destroy_srq(struct ib_srq *ib_srq, struct ib_udata *udata)
+static void destroy_srq(struct ib_srq *ib_srq)
 {
 	struct c4iw_dev *rhp;
 	struct c4iw_srq *srq;
@@ -3924,21 +3944,23 @@
 
 	pr_debug("id %d\n", srq->wq.qid);
 
-	ucontext = rdma_udata_to_drv_context(udata, struct c4iw_ucontext,
-					     ibucontext);
+	remove_handle(rhp, &rhp->qpidr, srq->wq.qid);
+	ucontext = ib_srq->uobject ?
+		   to_c4iw_ucontext(ib_srq->uobject->context) : NULL;
 	free_srq_queue(srq, ucontext ? &ucontext->uctx : &rhp->rdev.uctx,
 		       srq->wr_waitp);
 	c4iw_free_srq_idx(&rhp->rdev, srq->idx);
 	c4iw_put_wr_wait(srq->wr_waitp);
+	kfree(srq);
+	return;
 }
 
-static int create_raw_srq(struct ib_srq *ib_srq,
-			  struct ib_srq_init_attr *attrs,
-			  struct ib_udata *udata)
+static struct ib_srq *create_raw_srq(struct ib_pd *pd,
+				     struct ib_srq_init_attr *attrs,
+				     struct ib_udata *udata)
 {
-	struct c4iw_raw_srq *srq = to_c4iw_raw_srq(ib_srq);
-	struct ib_pd *pd = ib_srq->pd;
 	struct c4iw_dev *rhp;
+	struct c4iw_raw_srq *srq;
 	struct c4iw_pd *php;
 	struct c4iw_create_raw_srq_req ureq;
 	struct c4iw_create_raw_srq_resp uresp;
@@ -3951,31 +3973,34 @@
 	pr_debug("ib_pd %p\n", pd);
 
 	if (!(pd->uobject))
-		return -EINVAL;
+		return ERR_PTR(-EINVAL);
 
 	if (!allow_nonroot_rawqps && !capable(CAP_NET_RAW))
-		return -EPERM;
+		return ERR_PTR(-EPERM);
 
 	php = to_c4iw_pd(pd);
 	rhp = php->rhp;
 
 	ret = ib_copy_from_udata(&ureq, udata, sizeof ureq);
 	if (ret)
-		return -EFAULT;
+		return ERR_PTR(-EFAULT);
 
 	if (ureq.port == 0 || ureq.port > rhp->rdev.lldi.nports)
-		return -EINVAL;
+		return ERR_PTR(-EINVAL);
 
 	ureq.port--;
 	if (attrs->attr.max_wr > rhp->rdev.hw_queue.t4_max_sq_size)
-		return -E2BIG;
+		return ERR_PTR(-E2BIG);
 	flsize = attrs->attr.max_wr + 1;
 
 	iqsize = roundup(flsize * 4, 16);
 	if (iqsize > rhp->rdev.hw_queue.t4_max_iq_size)
 		iqsize = rhp->rdev.hw_queue.t4_max_iq_size;
-	ucontext = rdma_udata_to_drv_context(udata, struct c4iw_ucontext,
-					     ibucontext);
+	ucontext = to_c4iw_ucontext(pd->uobject->context);
+
+	srq = kzalloc(sizeof(*srq), GFP_KERNEL);
+	if (!srq)
+		return ERR_PTR(-ENOMEM);
 
 	srq->fl.size = flsize;
 	srq->iq.size = iqsize;
@@ -3991,7 +4016,7 @@
 	attrs->attr.max_wr = srq->fl.size - 1;
 	attrs->attr.max_sge = 4;
 
-	ret = xa_insert_irq(&rhp->rawiqs, srq->iq.cntxt_id, &srq->fcl, GFP_KERNEL);
+	ret = insert_handle(rhp, &rhp->rawiqidr, &srq->fcl, srq->iq.cntxt_id);
 	if (ret)
 		goto err3;
 
@@ -4100,7 +4125,7 @@
 	     srq->fl.cntxt_id, srq->fl.size, srq->fl.memsize,
 	     attrs->attr.max_wr, srq->iq.cntxt_id, srq->iq.size,
 	     srq->iq.memsize, srq->iq.size - 1);
-	return 0;
+	return &srq->ibsrq;
 err11:
 	remove_mmap(ucontext, fl_db_key_mm->key, fl_db_key_mm->len);
 err10:
@@ -4122,19 +4147,20 @@
 	if (fl_key_mm)
 		kfree(fl_key_mm);
 err4:
-	xa_erase_irq(&rhp->rawiqs, srq->iq.cntxt_id);
+	remove_handle(rhp, &rhp->rawiqidr, srq->iq.cntxt_id);
 err3:
 	free_raw_srq(rhp, srq);
 err1:
-	return ret;
+	kfree(srq);
+	return ERR_PTR(ret);
 }
 
-int create_srq(struct ib_srq *ib_srq, struct ib_srq_init_attr *attrs,
-			       struct ib_udata *udata)
+static struct ib_srq *create_srq(struct ib_pd *pd,
+				 struct ib_srq_init_attr *attrs,
+				 struct ib_udata *udata)
 {
-	struct ib_pd *pd = ib_srq->pd;
 	struct c4iw_dev *rhp;
-	struct c4iw_srq *srq = to_c4iw_srq(ib_srq);
+	struct c4iw_srq *srq;
 	struct c4iw_pd *php;
 	struct c4iw_create_srq_resp uresp;
 	struct c4iw_ucontext *ucontext;
@@ -4143,17 +4169,17 @@
 	int ret;
 	int wr_len;
 
-	pr_debug("%s ib_pd %p\n", __func__, pd);
+	pr_debug("ib_pd %p\n", pd);
 
 	php = to_c4iw_pd(pd);
 	rhp = php->rhp;
 
 	if (!rhp->rdev.lldi.vr->srq.size)
-		return -EINVAL;
+		return ERR_PTR(-ENOSYS);
 	if (attrs->attr.max_wr > rhp->rdev.hw_queue.t4_max_rq_size)
-		return -E2BIG;
+		return ERR_PTR(-E2BIG);
 	if (attrs->attr.max_sge > T4_MAX_RECV_SGE)
-		return -E2BIG;
+		return ERR_PTR(-E2BIG);
 
 	/*
 	 * SRQ RQT and RQ must be a power of 2 and at least 16 deep.
@@ -4161,17 +4187,21 @@
 	rqsize = attrs->attr.max_wr + 1;
 	rqsize = roundup_pow_of_two(max_t(u16, rqsize, 16));
 
-	ucontext = rdma_udata_to_drv_context(udata, struct c4iw_ucontext,
-					     ibucontext);
-
+	ucontext = pd->uobject ? to_c4iw_ucontext(pd->uobject->context) : NULL;
+
+	srq = kzalloc(sizeof(*srq), GFP_KERNEL);
+	if (!srq)
+		return ERR_PTR(-ENOMEM);
 	srq->wr_waitp = c4iw_alloc_wr_wait(GFP_KERNEL);
-	if (!srq->wr_waitp)
-		return -ENOMEM;
+	if (!srq->wr_waitp) {
+		ret = -ENOMEM;
+		goto err_free_srq;
+	}
 
 	srq->idx = c4iw_alloc_srq_idx(&rhp->rdev);
 	if (srq->idx < 0) {
 		ret = -ENOMEM;
-		goto err_free_wr_wait;
+		goto err_free_srq_wait;
 	}
 
 	wr_len = sizeof(struct fw_ri_res_wr) + sizeof(struct fw_ri_res);
@@ -4187,31 +4217,35 @@
 	srq->wq.size = rqsize;
 	srq->wq.memsize =
 		(rqsize + rhp->rdev.hw_queue.t4_eq_status_entries) *
-		sizeof(*srq->wq.queue);
+		sizeof *srq->wq.queue;
 	if (ucontext)
 		srq->wq.memsize = roundup(srq->wq.memsize, PAGE_SIZE);
 
 	ret = alloc_srq_queue(srq, ucontext ? &ucontext->uctx :
-			&rhp->rdev.uctx, srq->wr_waitp);
+			      &rhp->rdev.uctx, srq->wr_waitp);
 	if (ret)
 		goto err_free_skb;
+
 	attrs->attr.max_wr = rqsize - 1;
 
 	if (CHELSIO_CHIP_VERSION(rhp->rdev.lldi.adapter_type) > CHELSIO_T6)
 		srq->flags = T4_SRQ_LIMIT_SUPPORT;
 
+	ret = insert_handle(rhp, &rhp->qpidr, srq, srq->wq.qid);
+	if (ret)
+		goto err_free_queue;
+
 	if (udata) {
-		srq_key_mm = kmalloc(sizeof(*srq_key_mm), GFP_KERNEL);
+		srq_key_mm = kmalloc(sizeof *srq_key_mm, GFP_KERNEL);
 		if (!srq_key_mm) {
 			ret = -ENOMEM;
-			goto err_free_queue;
+			goto err_remove_handle;
 		}
-		srq_db_key_mm = kmalloc(sizeof(*srq_db_key_mm), GFP_KERNEL);
+		srq_db_key_mm = kmalloc(sizeof *srq_db_key_mm, GFP_KERNEL);
 		if (!srq_db_key_mm) {
 			ret = -ENOMEM;
 			goto err_free_srq_key_mm;
 		}
-		memset(&uresp, 0, sizeof(uresp));
 		uresp.flags = srq->flags;
 		uresp.qid_mask = rhp->rdev.qpmask;
 		uresp.srqid = srq->wq.qid;
@@ -4224,7 +4258,7 @@
 		uresp.srq_db_gts_key = ucontext->key;
 		ucontext->key += PAGE_SIZE;
 		spin_unlock(&ucontext->mmap_lock);
-		ret = ib_copy_to_udata(udata, &uresp, sizeof(uresp));
+		ret = ib_copy_to_udata(udata, &uresp, sizeof uresp);
 		if (ret)
 			goto err_free_srq_db_key_mm;
 		srq_key_mm->key = uresp.srq_key;
@@ -4237,48 +4271,53 @@
 		insert_mmap(ucontext, srq_db_key_mm);
 	}
 
-	pr_debug("%s srq qid %u idx %u size %u memsize %lu num_entries %u\n",
-		 __func__, srq->wq.qid, srq->idx, srq->wq.size,
-			(unsigned long)srq->wq.memsize, attrs->attr.max_wr);
-
+	pr_debug("srq qid %u idx %u size %u memsize %lu num_entries %u\n",
+	     srq->wq.qid, srq->idx, srq->wq.size,
+	     (unsigned long)srq->wq.memsize, attrs->attr.max_wr);
+
+	srq->fcl.type = BASIC_SRQ;
 	spin_lock_init(&srq->lock);
-	return 0;
-
+	return &srq->ibsrq;
 err_free_srq_db_key_mm:
 	kfree(srq_db_key_mm);
 err_free_srq_key_mm:
 	kfree(srq_key_mm);
+err_remove_handle:
+	remove_handle(rhp, &rhp->qpidr, srq->wq.qid);
 err_free_queue:
 	free_srq_queue(srq, ucontext ? &ucontext->uctx : &rhp->rdev.uctx,
 		       srq->wr_waitp);
 err_free_skb:
-	kfree_skb(srq->destroy_skb);
+	if (srq->destroy_skb)
+		kfree_skb(srq->destroy_skb);
 err_free_srq_idx:
 	c4iw_free_srq_idx(&rhp->rdev, srq->idx);
-err_free_wr_wait:
+err_free_srq_wait:
 	c4iw_put_wr_wait(srq->wr_waitp);
-	return ret;
+err_free_srq:
+	kfree(srq);
+	return ERR_PTR(ret);
 }
 
-int c4iw_create_srq(struct ib_srq *ib_srq, struct ib_srq_init_attr *attrs,
+struct ib_srq *c4iw_create_srq(struct ib_pd *pd, struct ib_srq_init_attr *attrs,
 			       struct ib_udata *udata)
 {
 	/*
 	 * XXX attrs->attr.srq_limit[31:31] == 1 indicates a raw SRQ!
 	 */
 	if (((attrs->attr.srq_limit >> 31) & 1) == 1)
-		return create_raw_srq(ib_srq, attrs, udata);
-	return create_srq(ib_srq, attrs, udata);
+		return create_raw_srq(pd, attrs, udata);
+
+	return create_srq(pd, attrs, udata);
 }
 
-int c4iw_destroy_srq(struct ib_srq *ibsrq, struct ib_udata *udata)
+int c4iw_destroy_srq(struct ib_srq *ibsrq)
 {
 	struct c4iw_srq *srq = to_c4iw_srq(ibsrq);
 
 	if (srq->fcl.type == RAW_SRQ)
 		destroy_raw_srq(ibsrq);
 	else
-		destroy_srq(ibsrq, udata);
-
+		destroy_srq(ibsrq);
 	return 0;
 }
diff -r 30 src/network/iw_cxgb4/restrack.c
--- a/src/network/iw_cxgb4/restrack.c	Tue May 18 14:52:03 2021 +0530
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,487 +0,0 @@
-/*
- * Copyright (c) 2018 Chelsio, Inc. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * OpenIB.org BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include <rdma/rdma_cm.h>
-
-#include "iw_cxgb4.h"
-#include <rdma/restrack.h>
-#include <uapi/rdma/rdma_netlink.h>
-
-static int fill_sq(struct sk_buff *msg, struct t4_wq *wq)
-{
-	/* WQ+SQ */
-	if (rdma_nl_put_driver_u32(msg, "sqid", wq->sq.qid))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "flushed", wq->flushed))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "memsize", wq->sq.memsize))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "cidx", wq->sq.cidx))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "pidx", wq->sq.pidx))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "wq_pidx", wq->sq.wq_pidx))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "flush_cidx", wq->sq.flush_cidx))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "in_use", wq->sq.in_use))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "size", wq->sq.size))
-		goto err;
-	if (rdma_nl_put_driver_u32_hex(msg, "flags", wq->sq.flags))
-		goto err;
-	return 0;
-err:
-	return -EMSGSIZE;
-}
-
-static int fill_rq(struct sk_buff *msg, struct t4_wq *wq)
-{
-	/* RQ */
-	if (rdma_nl_put_driver_u32(msg, "rqid", wq->rq.qid))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "memsize", wq->rq.memsize))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "cidx", wq->rq.cidx))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "pidx", wq->rq.pidx))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "wq_pidx", wq->rq.wq_pidx))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "msn", wq->rq.msn))
-		goto err;
-	if (rdma_nl_put_driver_u32_hex(msg, "rqt_hwaddr", wq->rq.rqt_hwaddr))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "rqt_size", wq->rq.rqt_size))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "in_use", wq->rq.in_use))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "size", wq->rq.size))
-		goto err;
-	return 0;
-err:
-	return -EMSGSIZE;
-}
-
-static int fill_swsqe(struct sk_buff *msg, struct t4_sq *sq, u16 idx,
-		      struct t4_swsqe *sqe)
-{
-	if (rdma_nl_put_driver_u32(msg, "idx", idx))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "opcode", sqe->opcode))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "complete", sqe->complete))
-		goto err;
-	if (sqe->complete &&
-	    rdma_nl_put_driver_u32(msg, "cqe_status", CQE_STATUS(&sqe->cqe)))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "signaled", sqe->signaled))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "flushed", sqe->flushed))
-		goto err;
-	return 0;
-err:
-	return -EMSGSIZE;
-}
-
-/*
- * Dump the first and last pending sqes.
- */
-static int fill_swsqes(struct sk_buff *msg, struct t4_sq *sq,
-		       u16 first_idx, struct t4_swsqe *first_sqe,
-		       u16 last_idx, struct t4_swsqe *last_sqe)
-{
-	if (!first_sqe)
-		goto out;
-	if (fill_swsqe(msg, sq, first_idx, first_sqe))
-		goto err;
-	if (!last_sqe)
-		goto out;
-	if (fill_swsqe(msg, sq, last_idx, last_sqe))
-		goto err;
-out:
-	return 0;
-err:
-	return -EMSGSIZE;
-}
-
-int c4iw_fill_res_qp_entry(struct sk_buff *msg, struct ib_qp *ibqp)
-{
-	struct t4_swsqe *fsp = NULL, *lsp = NULL;
-	struct c4iw_qp *qhp = to_c4iw_qp(ibqp);
-	u16 first_sq_idx = 0, last_sq_idx = 0;
-	struct t4_swsqe first_sqe, last_sqe;
-	struct nlattr *table_attr;
-	struct t4_wq wq;
-
-	/* User qp state is not available, so don't dump user qps */
-	if (qhp->ucontext)
-		return 0;
-
-	table_attr = nla_nest_start_noflag(msg, RDMA_NLDEV_ATTR_DRIVER);
-	if (!table_attr)
-		goto err;
-
-	/* Get a consistent snapshot */
-	spin_lock_irq(&qhp->lock);
-	wq = qhp->wq;
-
-	/* If there are any pending sqes, copy the first and last */
-	if (wq.sq.cidx != wq.sq.pidx) {
-		first_sq_idx = wq.sq.cidx;
-		first_sqe = qhp->wq.sq.sw_sq[first_sq_idx];
-		fsp = &first_sqe;
-		last_sq_idx = wq.sq.pidx;
-		if (last_sq_idx-- == 0)
-			last_sq_idx = wq.sq.size - 1;
-		if (last_sq_idx != first_sq_idx) {
-			last_sqe = qhp->wq.sq.sw_sq[last_sq_idx];
-			lsp = &last_sqe;
-		}
-	}
-	spin_unlock_irq(&qhp->lock);
-
-	if (fill_sq(msg, &wq))
-		goto err_cancel_table;
-
-	if (fill_swsqes(msg, &wq.sq, first_sq_idx, fsp, last_sq_idx, lsp))
-		goto err_cancel_table;
-
-	if (fill_rq(msg, &wq))
-		goto err_cancel_table;
-
-	nla_nest_end(msg, table_attr);
-	return 0;
-
-err_cancel_table:
-	nla_nest_cancel(msg, table_attr);
-err:
-	return -EMSGSIZE;
-}
-
-union union_ep {
-	struct c4iw_listen_ep lep;
-	struct c4iw_ep ep;
-};
-
-int c4iw_fill_res_cm_id_entry(struct sk_buff *msg,
-			      struct rdma_cm_id *cm_id)
-{
-	struct nlattr *table_attr;
-	struct c4iw_ep_common *epcp;
-	struct c4iw_listen_ep *listen_ep = NULL;
-	struct c4iw_ep *ep = NULL;
-	struct iw_cm_id *iw_cm_id;
-	union union_ep *uep;
-
-	iw_cm_id = rdma_iw_cm_id(cm_id);
-	if (!iw_cm_id)
-		return 0;
-	epcp = (struct c4iw_ep_common *)iw_cm_id->provider_data;
-	if (!epcp)
-		return 0;
-	uep = kcalloc(1, sizeof(*uep), GFP_KERNEL);
-	if (!uep)
-		return 0;
-
-	table_attr = nla_nest_start_noflag(msg, RDMA_NLDEV_ATTR_DRIVER);
-	if (!table_attr)
-		goto err_free_uep;
-
-	/* Get a consistent snapshot */
-	mutex_lock(&epcp->mutex);
-	if (epcp->state == LISTEN) {
-		uep->lep = *(struct c4iw_listen_ep *)epcp;
-		mutex_unlock(&epcp->mutex);
-		listen_ep = &uep->lep;
-		epcp = &listen_ep->com;
-	} else {
-		uep->ep = *(struct c4iw_ep *)epcp;
-		mutex_unlock(&epcp->mutex);
-		ep = &uep->ep;
-		epcp = &ep->com;
-	}
-
-	if (rdma_nl_put_driver_u32(msg, "state", epcp->state))
-		goto err_cancel_table;
-	if (rdma_nl_put_driver_u64_hex(msg, "flags", epcp->flags))
-		goto err_cancel_table;
-	if (rdma_nl_put_driver_u64_hex(msg, "history", epcp->history))
-		goto err_cancel_table;
-
-	if (epcp->state == LISTEN) {
-		if (rdma_nl_put_driver_u32(msg, "stid", listen_ep->stid))
-			goto err_cancel_table;
-		if (rdma_nl_put_driver_u32(msg, "backlog", listen_ep->backlog))
-			goto err_cancel_table;
-	} else {
-		if (rdma_nl_put_driver_u32(msg, "hwtid", ep->hwtid))
-			goto err_cancel_table;
-		if (rdma_nl_put_driver_u32(msg, "ord", ep->ord))
-			goto err_cancel_table;
-		if (rdma_nl_put_driver_u32(msg, "ird", ep->ird))
-			goto err_cancel_table;
-		if (rdma_nl_put_driver_u32(msg, "emss", ep->emss))
-			goto err_cancel_table;
-
-		if (!ep->parent_ep && rdma_nl_put_driver_u32(msg, "atid",
-							     ep->atid))
-			goto err_cancel_table;
-	}
-	nla_nest_end(msg, table_attr);
-	kfree(uep);
-	return 0;
-
-err_cancel_table:
-	nla_nest_cancel(msg, table_attr);
-err_free_uep:
-	kfree(uep);
-	return -EMSGSIZE;
-}
-
-static int fill_cq(struct sk_buff *msg, struct t4_cq *cq)
-{
-	if (rdma_nl_put_driver_u32(msg, "cqid", cq->cqid))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "memsize", cq->memsize))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "size", cq->size))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "cidx", cq->cidx))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "cidx_inc", cq->cidx_inc))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "sw_cidx", cq->sw_cidx))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "sw_pidx", cq->sw_pidx))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "sw_in_use", cq->sw_in_use))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "vector", cq->vector))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "gen", cq->gen))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "error", cq->error))
-		goto err;
-	if (rdma_nl_put_driver_u64_hex(msg, "bits_type_ts",
-					 be64_to_cpu(cq->bits_type_ts)))
-		goto err;
-	if (rdma_nl_put_driver_u64_hex(msg, "flags", cq->flags))
-		goto err;
-
-	return 0;
-
-err:
-	return -EMSGSIZE;
-}
-
-static int fill_cqe(struct sk_buff *msg, struct t4_cqe *cqe, u16 idx,
-		    const char *qstr)
-{
-	if (rdma_nl_put_driver_u32(msg, qstr, idx))
-		goto err;
-	if (rdma_nl_put_driver_u32_hex(msg, "header",
-					 be32_to_cpu(cqe->header)))
-		goto err;
-	if (rdma_nl_put_driver_u32(msg, "len", be32_to_cpu(cqe->len)))
-		goto err;
-	if (rdma_nl_put_driver_u32_hex(msg, "wrid_hi",
-					 be32_to_cpu(cqe->u.gen.wrid_hi)))
-		goto err;
-	if (rdma_nl_put_driver_u32_hex(msg, "wrid_low",
-					 be32_to_cpu(cqe->u.gen.wrid_low)))
-		goto err;
-	if (rdma_nl_put_driver_u64_hex(msg, "bits_type_ts",
-					 be64_to_cpu(cqe->bits_type_ts)))
-		goto err;
-
-	return 0;
-
-err:
-	return -EMSGSIZE;
-}
-
-static int fill_hwcqes(struct sk_buff *msg, struct t4_cq *cq,
-		       struct t4_cqe *cqes)
-{
-	u16 idx;
-
-	idx = (cq->cidx > 0) ? cq->cidx - 1 : cq->size - 1;
-	if (fill_cqe(msg, cqes, idx, "hwcq_idx"))
-		goto err;
-	idx = cq->cidx;
-	if (fill_cqe(msg, cqes + 1, idx, "hwcq_idx"))
-		goto err;
-
-	return 0;
-err:
-	return -EMSGSIZE;
-}
-
-static int fill_swcqes(struct sk_buff *msg, struct t4_cq *cq,
-		       struct t4_cqe *cqes)
-{
-	u16 idx;
-
-	if (!cq->sw_in_use)
-		return 0;
-
-	idx = cq->sw_cidx;
-	if (fill_cqe(msg, cqes, idx, "swcq_idx"))
-		goto err;
-	if (cq->sw_in_use == 1)
-		goto out;
-	idx = (cq->sw_pidx > 0) ? cq->sw_pidx - 1 : cq->size - 1;
-	if (fill_cqe(msg, cqes + 1, idx, "swcq_idx"))
-		goto err;
-out:
-	return 0;
-err:
-	return -EMSGSIZE;
-}
-
-int c4iw_fill_res_cq_entry(struct sk_buff *msg, struct ib_cq *ibcq)
-{
-	struct c4iw_cq *chp = to_c4iw_cq(ibcq);
-	struct nlattr *table_attr;
-	struct t4_cqe hwcqes[2];
-	struct t4_cqe swcqes[2];
-	struct t4_cq cq;
-	u16 idx;
-
-	/* User cq state is not available, so don't dump user cqs */
-	if (ibcq->uobject)
-		return 0;
-
-	table_attr = nla_nest_start_noflag(msg, RDMA_NLDEV_ATTR_DRIVER);
-	if (!table_attr)
-		goto err;
-
-	/* Get a consistent snapshot */
-	spin_lock_irq(&chp->lock);
-
-	/* t4_cq struct */
-	cq = chp->cq;
-
-	/* get 2 hw cqes: cidx-1, and cidx */
-	idx = (cq.cidx > 0) ? cq.cidx - 1 : cq.size - 1;
-	hwcqes[0] = chp->cq.queue[idx];
-
-	idx = cq.cidx;
-	hwcqes[1] = chp->cq.queue[idx];
-
-	/* get first and last sw cqes */
-	if (cq.sw_in_use) {
-		swcqes[0] = chp->cq.sw_queue[cq.sw_cidx];
-		if (cq.sw_in_use > 1) {
-			idx = (cq.sw_pidx > 0) ? cq.sw_pidx - 1 : cq.size - 1;
-			swcqes[1] = chp->cq.sw_queue[idx];
-		}
-	}
-
-	spin_unlock_irq(&chp->lock);
-
-	if (fill_cq(msg, &cq))
-		goto err_cancel_table;
-
-	if (fill_swcqes(msg, &cq, swcqes))
-		goto err_cancel_table;
-
-	if (fill_hwcqes(msg, &cq, hwcqes))
-		goto err_cancel_table;
-
-	nla_nest_end(msg, table_attr);
-	return 0;
-
-err_cancel_table:
-	nla_nest_cancel(msg, table_attr);
-err:
-	return -EMSGSIZE;
-}
-
-int c4iw_fill_res_mr_entry(struct sk_buff *msg, struct ib_mr *ibmr)
-{
-	struct c4iw_mr *mhp = to_c4iw_mr(ibmr);
-	struct c4iw_dev *dev = mhp->rhp;
-	u32 stag = mhp->attr.stag;
-	struct nlattr *table_attr;
-	struct fw_ri_tpte tpte;
-	int ret;
-
-	if (!stag)
-		return 0;
-
-	table_attr = nla_nest_start_noflag(msg, RDMA_NLDEV_ATTR_DRIVER);
-	if (!table_attr)
-		goto err;
-
-	ret = cxgb4_read_tpte(dev->rdev.lldi.ports[0], stag, (__be32 *)&tpte);
-	if (ret) {
-		dev_err(&dev->rdev.lldi.pdev->dev,
-			"%s cxgb4_read_tpte err %d\n", __func__, ret);
-		return 0;
-	}
-
-	if (rdma_nl_put_driver_u32_hex(msg, "idx", stag >> 8))
-		goto err_cancel_table;
-	if (rdma_nl_put_driver_u32(msg, "valid",
-			G_FW_RI_TPTE_VALID(ntohl(tpte.valid_to_pdid))))
-		goto err_cancel_table;
-	if (rdma_nl_put_driver_u32_hex(msg, "key", stag & 0xff))
-		goto err_cancel_table;
-	if (rdma_nl_put_driver_u32(msg, "state",
-			G_FW_RI_TPTE_STAGSTATE(ntohl(tpte.valid_to_pdid))))
-		goto err_cancel_table;
-	if (rdma_nl_put_driver_u32(msg, "pdid",
-			G_FW_RI_TPTE_PDID(ntohl(tpte.valid_to_pdid))))
-		goto err_cancel_table;
-	if (rdma_nl_put_driver_u32_hex(msg, "perm",
-			G_FW_RI_TPTE_PERM(ntohl(tpte.locread_to_qpid))))
-		goto err_cancel_table;
-	if (rdma_nl_put_driver_u32(msg, "ps",
-			G_FW_RI_TPTE_PS(ntohl(tpte.locread_to_qpid))))
-		goto err_cancel_table;
-	if (rdma_nl_put_driver_u64(msg, "len",
-		      ((u64)ntohl(tpte.len_hi) << 32) | ntohl(tpte.len_lo)))
-		goto err_cancel_table;
-	if (rdma_nl_put_driver_u32_hex(msg, "pbl_addr",
-			G_FW_RI_TPTE_PBLADDR(ntohl(tpte.nosnoop_pbladdr))))
-		goto err_cancel_table;
-
-	nla_nest_end(msg, table_attr);
-	return 0;
-
-err_cancel_table:
-	nla_nest_cancel(msg, table_attr);
-err:
-	return -EMSGSIZE;
-}
diff -r 30 src/network/iw_cxgb4/t4.h
--- a/src/network/iw_cxgb4/t4.h	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/iw_cxgb4/t4.h	Tue May 18 15:02:47 2021 +0530
@@ -303,7 +303,7 @@
 	int			signaled;
 	u16			idx;
 	int                     flushed;
-	ktime_t                 host_time;
+	struct timespec		host_ts;
 	u64			sge_ts;
 };
 
@@ -324,7 +324,7 @@
 	union t4_wr *queue;
 	dma_addr_t dma_addr;
 	unsigned long phys_addr;
-	DEFINE_DMA_UNMAP_ADDR(mapping);
+	DECLARE_PCI_UNMAP_ADDR(mapping);
 	struct t4_swsqe *sw_sq;
 	struct t4_swsqe *oldest_read;
 	void __iomem *bar2_va;
@@ -344,7 +344,7 @@
 
 struct t4_swrqe {
 	u64 wr_id;
-	ktime_t host_time;
+	struct timespec host_ts;
 	u64 sge_ts;
 	int valid;
 };
@@ -352,7 +352,7 @@
 struct t4_rq {
 	union  t4_recv_wr *queue;
 	dma_addr_t dma_addr;
-	DEFINE_DMA_UNMAP_ADDR(mapping);
+	DECLARE_PCI_UNMAP_ADDR(mapping);
 	struct t4_swrqe *sw_rq;
 	void __iomem *bar2_va;
 	u64 bar2_pa;
@@ -389,7 +389,7 @@
 struct t4_srq {
 	union  t4_recv_wr *queue;
 	dma_addr_t dma_addr;
-	DEFINE_DMA_UNMAP_ADDR(mapping);
+	DECLARE_PCI_UNMAP_ADDR(mapping);
 	struct t4_swrqe *sw_rq;
 	void __iomem *bar2_va;
 	u64 bar2_pa;
@@ -699,7 +699,7 @@
 struct t4_cq {
 	struct t4_cqe *queue;
 	dma_addr_t dma_addr;
-	DEFINE_DMA_UNMAP_ADDR(mapping);
+	DECLARE_PCI_UNMAP_ADDR(mapping);
 	struct t4_cqe *sw_queue;
 	void __iomem *gts;
 	void __iomem *bar2_va;
diff -r 30 src/network/t4_tom/cpl_io.c
--- a/src/network/t4_tom/cpl_io.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/cpl_io.c	Tue May 18 15:02:47 2021 +0530
@@ -520,11 +520,12 @@
 		opt2 |= F_T5_OPT_2_VALID;
 		opt2 |= F_T5_ISS;
 	}
+	opt2 |= V_RX_COALESCE(M_RX_COALESCE);
 
 	if (cplios->ulp_mode == ULP_MODE_TCPDDP) {
 		opt2 |= F_RX_FC_VALID | F_RX_FC_DDP;
-		if (cplios->port_speed <= 50000)
-			opt2 |= V_RX_COALESCE(M_RX_COALESCE);
+		if (cplios->port_speed > 50000)
+			opt2 &= ~V_RX_COALESCE(M_RX_COALESCE);
 	} else if (cplios->ulp_mode == ULP_MODE_TLS) {
 		opt2 |= F_RX_FC_VALID;
 		opt2 &= ~V_RX_COALESCE(M_RX_COALESCE);
@@ -2235,7 +2236,6 @@
 		rxq_idx += td->round_robin_cnt++ % rxq_perchan;
 	}
 
-	cplios->rxq_idx = rxq_idx;
 	cplios->rss_qid = td->lldi->rxq_ids[rxq_idx];
 	cplios->txq_idx = (rxq_idx < td->lldi->ntxq) ? rxq_idx :
 		cplios->port_id*td->lldi->ntxq/td->lldi->nchan;
@@ -4753,15 +4753,6 @@
 		sock_set_flag(newsk, SOCK_NO_DDP);
 	init_offload_sk(newcplios, tdev, tid,
 			e, dst, egress, s, ntohs(req->tcpopt.mss));
-
-	/* Some applications (nvmet-tcp) have queue io_work context
-	 * run on sk->sk_incoming_cpu (for better affinitization)
-	 * rather than spreading queues on all online cpus.
-	 * To achieve this, we rely on rxq_idx associated with
-	 * this sock.
-	 */
-	newsk->sk_incoming_cpu = newcplios->rxq_idx;
-
 	newcplios->passive_reap_next = oreq;
 	newcplios->delack_seq = newtp->rcv_nxt;
 	ma_fail_mk_pass_sock(newcplios);
@@ -5212,7 +5203,7 @@
 	 */
 	oreq->rsk_rcv_wnd = 0;
 	oreq->rsk_window_clamp = 0;
-	oreq->syncookie = 0;
+	oreq->cookie_ts = 0;
 	oreq->mss = 0;
 	oreq->ts_recent = 0;
 
@@ -5265,7 +5256,7 @@
 #if LINUX_VERSION_CODE < KERNEL_VERSION(5, 0, 0)
 	cplios->idr = bh_insert_handle(d, newsk, tid);
 #else
-	ret = xa_insert_bh(&d->hwtid_idr, tid, newsk, GFP_NOWAIT);
+	ret = xa_insert_bh(&d->hwtid_idr, tid, sk, GFP_NOWAIT);
 	cplios->idr = tid;
 #endif
 	listen_ctx = (struct listen_ctx *)lookup_stid(d->tids, stid);
@@ -6826,10 +6817,9 @@
 	/* Append the data to the skb frags */
 	ssi = skb_shinfo(skb);
 	skb_frag_set_page(skb, nr_frags, gl->frags[0].page);
-	skb_frag_off_set(&ssi->frags[nr_frags],
-			gl->frags[0].offset + cpl_hdr_size);
-	skb_frag_size_set(&ssi->frags[nr_frags],
-			gl->frags[0].size - cpl_hdr_size);
+	ssi->frags[nr_frags].page_offset = gl->frags[0].offset +
+					   cpl_hdr_size;
+	ssi->frags[nr_frags].size = gl->frags[0].size - cpl_hdr_size;
 	if (gl->nfrags > 1)
 		memcpy(&ssi->frags[nr_frags + 1], &gl->frags[1],
 		       (gl->nfrags - 1) * sizeof(skb_frag_t));
diff -r 30 src/network/t4_tom/cpl_io_state.h
--- a/src/network/t4_tom/cpl_io_state.h	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/cpl_io_state.h	Tue May 18 15:02:47 2021 +0530
@@ -230,7 +230,6 @@
 	struct listen_ctx *listen_ctx;
 	struct sock *lsk;
 	struct tcb_ofld_info tcb_info;
-	unsigned int rxq_idx;		/* TOE RX queue index */
 #ifdef UDP_OFFLOAD
 	int sk_gso_type;
 #endif
diff -r 30 src/network/t4_tom/cpl_sock.c
--- a/src/network/t4_tom/cpl_sock.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/cpl_sock.c	Tue May 18 15:02:47 2021 +0530
@@ -288,7 +288,7 @@
  * suite of tests for a Tx packet and therefore must be called for the last
  * packet added by the various send*() APIs.
  */
-static void t4_tcp_push(struct sock *sk, int flags)
+static void tcp_push(struct sock *sk, int flags)
 {
 	struct cpl_io_state *cplios = CPL_IO_STATE(sk);
 	int qlen = skb_queue_len(&cplios->tx_queue);
@@ -319,7 +319,7 @@
 
 	if (tp->nonagle & TCP_NAGLE_CORK) {
 		tp->nonagle &= ~TCP_NAGLE_CORK;
-		t4_tcp_push(sk, 0);
+		tcp_push(sk, 0);
 	}
 }
 
@@ -328,7 +328,7 @@
  * to be called as full packets are added to the send queue by the various
  * send*() APIs when we expect additional packets to be generated by the
  * current API call.  It should not be called for the last packet generated,
- * use the full t4_tcp_push call above for that.
+ * use the full tcp_push call above for that.
  */
 static inline void push_frames_if_head(struct sock *sk)
 {
@@ -449,7 +449,7 @@
 
 		i = skb_shinfo(skb)->nr_frags;
 		if (skb_can_coalesce(skb, i, page, offset)) {
-			skb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);
+			skb_shinfo(skb)->frags[i - 1].size += copy;
 		} else if (i < MAX_SKB_FRAGS) {
 			get_page(page);
 			skb_fill_page_desc(skb, i, page, offset, copy);
@@ -491,7 +491,7 @@
 out:
 	cplios_reset_flag(cplios, CPLIOS_TX_MORE_DATA);
 	if (copied)
-		t4_tcp_push(sk, flags);
+		tcp_push(sk, flags);
 done:
 	release_sock(sk);
 	return copied;
@@ -750,11 +750,11 @@
 
 	address &= PAGE_MASK;
 
-	mmap_write_lock(current->mm);
+	down_write(&current->mm->mmap_sem);
 	vma = find_vma(current->mm, skb_vaddr(skb));
 	if (!(vma->vm_flags & VM_WRITE)) {
 		vma->vm_flags &= ~VM_MAYWRITE;
-		mmap_write_unlock(current->mm);
+		up_write(&current->mm->mmap_sem);
 		ULP_SKB_CB(skb)->flags &= ~ULPCB_FLAG_ZCOPY;
 		ULP_SKB_CB(skb)->flags |= ULPCB_FLAG_ZCOPY_COW_SKIP;
 		cplios->zcopy_dma_unacked -= len;
@@ -832,7 +832,7 @@
 	mprotect_page_table_unlock(current->mm);
 
 	t4_flush_tlb_range(vma, skb_vaddr(skb), end);
-	mmap_write_unlock(current->mm);
+	up_write(&current->mm->mmap_sem);
 
 	ULP_SKB_CB(skb)->flags &= ~ULPCB_FLAG_ZCOPY;
 	ULP_SKB_CB(skb)->flags |= ULPCB_FLAG_ZCOPY_COW;
@@ -1066,7 +1066,7 @@
 	    && !cplios_flag(sk, CPLIOS_ABORT_SHUTDOWN)
 	    && !corked(tp, flags)
 	    && can_do_mlock()
-	    && !uaccess_kernel()
+	    && !segment_eq(get_fs(), KERNEL_DS)
 	    && !is_tls_offload(sk))
 		zcopy_size = size -
 				TOM_TUNABLE(tdev, zcopy_sendmsg_partial_copy);
@@ -1095,7 +1095,7 @@
 		const struct iovec *iov;
 		struct vm_area_struct *vma;
 
-		mmap_read_lock(current->mm);
+		down_read(&current->mm->mmap_sem);
 		for (iovlen = msg->msg_iter.nr_segs, iov = msg->msg_iter.iov;
 		     iovlen--; iov++) {
 			unsigned long from = (unsigned long)iov->iov_base;
@@ -1108,7 +1108,7 @@
 				break;
 			}
 		}
-		mmap_read_unlock(current->mm);
+		up_read(&current->mm->mmap_sem);
 	}
 #endif
 	cplios_set_flag(cplios, CPLIOS_TX_MORE_DATA);
@@ -1296,8 +1296,7 @@
 
 			/* Update the skb. */
 			if (merge) {
-				skb_frag_size_add(&skb_shinfo(skb)->frags[i - 1],
-						 copy);
+				skb_shinfo(skb)->frags[i - 1].size += copy;
 			} else {
 				skb_fill_page_desc(skb, i, page, off, copy);
 				if (off + copy < pg_size) {
@@ -1341,7 +1340,7 @@
 out:
 	cplios_reset_flag(cplios, CPLIOS_TX_MORE_DATA);
 	if (copied)
-		t4_tcp_push(sk, flags);
+		tcp_push(sk, flags);
 done:
 #if defined(CONFIG_T4_ZCOPY_SENDMSG) || defined(CONFIG_T4_ZCOPY_SENDMSG_MODULE)
 	if (zcopied > 0 && tdev)
@@ -1492,7 +1491,7 @@
 	unsigned int wsf;
 	int should_ddp = cplios->ulp_mode == ULP_MODE_TCPDDP &&
 			!DDP_STATE(sk)->ddp_setup &&
-			((can_do_mlock() && !uaccess_kernel()) ||
+			((can_do_mlock() && !segment_eq(get_fs(), KERNEL_DS)) ||
 			TOM_TUNABLE(tdev, kseg_ddp));
 
 	if (cplios->opt2 & V_RX_COALESCE(M_RX_COALESCE))
@@ -1711,7 +1710,10 @@
  */
 static inline unsigned long long get_ns_cycles(void)
 {
-	return (unsigned long long)ktime_to_ns(ktime_get());
+	struct timespec ts;
+
+	ktime_get_ts(&ts);
+	return (unsigned long long)ktime_to_ns(timespec_to_ktime(ts));
 }
 #endif
 
@@ -2867,7 +2869,7 @@
  * and the rest are directed to the SW IP for their usual processing.
  */
 static int t4_ip_setsockopt(struct sock *sk, int level, int optname,
-			    sockptr_t optval, int optlen, int call_compat)
+			    char __user *optval, int optlen, int call_compat)
 {
 
 	if (level != SOL_IP)
@@ -2887,12 +2889,12 @@
 		int val = 0, err = 0;
 
 		if (optlen >= sizeof(int)) {
-			if (copy_from_sockptr(&val, optval, sizeof(val)))
+			if (get_user(val, (int __user *)optval))
 				return -EFAULT;
 		} else if (optlen >= sizeof(char)) {
 			unsigned char ucval;
 
-			if (copy_from_sockptr(&ucval, optval, sizeof(ucval)))
+			if (get_user(ucval, (unsigned char __user *)optval))
 				return -EFAULT;
 			val = (int)ucval;
 		}
@@ -2914,6 +2916,11 @@
 		return err;
 	}
 
+#ifdef TOM_CONFIG_COMPAT
+	if (call_compat && inet_csk(sk)->icsk_af_ops->compat_setsockopt)
+		return inet_csk(sk)->icsk_af_ops->compat_setsockopt(sk, level,
+						optname, optval, optlen);
+#endif
 	return inet_csk(sk)->icsk_af_ops->setsockopt(sk, level, optname,
 						     optval, optlen);
 }
@@ -2923,7 +2930,7 @@
  * be handled specially for a TOE and leave the other options to SW TCP.
  */
 static int do_t4_tcp_setsockopt(struct sock *sk, int level, int optname,
-				sockptr_t optval, socklen_t optlen)
+				char __user * optval, socklen_t optlen)
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 	int val, err = 0;
@@ -2933,9 +2940,9 @@
 
 		if (optlen < 1)
 			return -EINVAL;
-		val = strncpy_from_sockptr(name, optval,
+		val = strncpy_from_user(name, optval,
 					min((socklen_t)(TCP_CA_NAME_MAX - 1),
-					     optlen));
+					    optlen));
 		if (val < 0)
 			return -EFAULT;
 		name[val] = 0;
@@ -2945,7 +2952,7 @@
 	if (optlen < sizeof(int))
 		return -EINVAL;
 
-	if (copy_from_sockptr(&val, optval, sizeof(val)))
+	if (get_user(val, (int __user *)optval))
 		return -EFAULT;
 
 	lock_sock(sk);
@@ -3049,7 +3056,7 @@
 }
 
 static int t4_tcp_setsockopt(struct sock *sk, int level, int optname,
-			     sockptr_t optval, socklen_t optlen)
+			     char __user *optval, socklen_t optlen)
 {
         if (sk->sk_prot->setsockopt != t4_tcp_setsockopt)
                 return sk->sk_prot->setsockopt(sk, level, optname, optval,
@@ -3060,6 +3067,20 @@
 		do_t4_tcp_setsockopt(sk, level, optname, optval, optlen);
 }
 
+#ifdef TOM_CONFIG_COMPAT
+static int t4_compat_tcp_setsockopt(struct sock *sk, int level, int optname,
+				    char __user *optval, socklen_t optlen)
+{
+        if (sk->sk_prot->compat_setsockopt != t4_compat_tcp_setsockopt)
+                return sk->sk_prot->compat_setsockopt(sk, level, optname,
+						      optval, optlen);
+
+	return level != SOL_TCP ?
+		t4_ip_setsockopt(sk, level, optname, optval, optlen, 1) :
+		do_t4_tcp_setsockopt(sk, level, optname, optval, optlen);
+}
+#endif
+
 #if defined(CONFIG_TCP_OFFLOAD)
 static void set_keepalive(struct sock *sk, int on_off)
 {
@@ -3139,6 +3160,9 @@
 	t4_tcp_prot.proto.read_sock     = t4_read_sock;
 	t4_tcp_prot.proto.set_keepalive = set_keepalive;
 #endif
+#ifdef TOM_CONFIG_COMPAT
+	t4_tcp_prot.proto.compat_setsockopt = t4_compat_tcp_setsockopt;
+#endif
 	t4_tcp_prot.read_sock = t4_read_sock;
 	t4_tcp_prot.splice_read = chelsio_splice_read;
 
@@ -3158,6 +3182,9 @@
         t4_tcp_v6_prot.proto.read_sock     = t4_read_sock;
         t4_tcp_v6_prot.proto.set_keepalive = set_keepalive;
 #endif
+#ifdef TOM_CONFIG_COMPAT
+        t4_tcp_v6_prot.proto.compat_setsockopt = t4_compat_tcp_setsockopt;
+#endif
         t4_tcp_v6_prot.read_sock = t4_read_sock;
         t4_tcp_v6_prot.splice_read = chelsio_splice_read;
 	t4_init_rsk6_ops(&t4_tcp_v6_prot.proto, &t4_rsk6_ops, tcpv6_prot_p, PF_INET6);
diff -r 30 src/network/t4_tom/failover.c
--- a/src/network/t4_tom/failover.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/failover.c	Tue May 18 15:02:47 2021 +0530
@@ -110,7 +110,7 @@
 
 	struct flowc_packed {
 		struct fw_flowc_wr fc;
-		struct fw_flowc_mnemval mnem[1];
+		struct fw_flowc_mnemval mnem[nparams];
 		} __packed sflowc;
 
 	struct fw_flowc_wr *flowc = &sflowc.fc;
@@ -184,7 +184,8 @@
 	struct tcp_sock *tp;
 	struct cpl_io_state *cplios;
 
-	if (!sk)
+	/* Avoid sending FlowC WR when in post ESTABLISHED state */
+	if (!sk || sk->sk_state >= TCP_FIN_WAIT1)
 		return 0;
 
 	sock_hold(sk);
@@ -231,16 +232,15 @@
 	struct tom_data *td = TOM_DATA(tdev);
 
 #if LINUX_VERSION_CODE < KERNEL_VERSION(5, 0, 0)
-	spin_lock(&td->idr_lock);
+	rcu_read_lock();
 	idr_for_each(&td->hwtid_idr, t4_switch_channel_idr, NULL);
-	spin_unlock(&td->idr_lock);
+	rcu_read_unlock();
 #else
 	unsigned long index;
 	struct sock *sk;
 
-	xa_for_each(&td->hwtid_idr, index, sk) {
+	xa_for_each(&td->hwtid_idr, index, sk);
 		t4_switch_channel_idr(index, sk, NULL);
-	}
 #endif
 }
 
diff -r 30 src/network/t4_tom/listen.c
--- a/src/network/t4_tom/listen.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/listen.c	Tue May 18 15:02:47 2021 +0530
@@ -576,14 +576,6 @@
 	return rc;
 }
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-static struct proc_ops proc_listeners_fops = {
-	.proc_open = proc_listeners_open,
-	.proc_read = seq_read,
-	.proc_lseek = seq_lseek,
-	.proc_release = seq_release
-};
-#else
 static struct file_operations proc_listeners_fops = {
 	.owner = THIS_MODULE,
 	.open = proc_listeners_open,
@@ -591,7 +583,6 @@
 	.llseek = seq_lseek,
 	.release = seq_release
 };
-#endif
 
 /*
  * Create the proc entry for the listening servers under dir.
diff -r 30 src/network/t4_tom/module_support/module_support-tom-4.14.0.c
--- a/src/network/t4_tom/module_support/module_support-tom-4.14.0.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/module_support/module_support-tom-4.14.0.c	Tue May 18 15:02:47 2021 +0530
@@ -2,7 +2,7 @@
  * This file contains pieces of the Linux TCP/IP stack needed for modular
  * TOE support.
  *
- * Copyright (C) 2006-2021 Chelsio Communications.  All rights reserved.
+ * Copyright (C) 2006-2019 Chelsio Communications.  All rights reserved.
  * See the corresponding files in the Linux tree for copyrights of the
  * original Linux code a lot of this file is based on.
  *
diff -r 30 src/network/t4_tom/module_support/module_support-tom-5.0.0.c
--- a/src/network/t4_tom/module_support/module_support-tom-5.0.0.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/module_support/module_support-tom-5.0.0.c	Tue May 18 15:02:47 2021 +0530
@@ -20,9 +20,6 @@
  * $SUPPORTED KERNEL 5.0$
  * $SUPPORTED KERNEL 5.1$
  * $SUPPORTED KERNEL 5.2$
- * $SUPPORTED KERNEL 5.4$
- * $SUPPORTED KERNEL 5.6$
- * $SUPPORTED KERNEL 5.10$
  */
 
 #include <net/tcp.h>
@@ -33,8 +30,6 @@
 #include <asm/tlbflush.h>
 #include <linux/hash.h>
 
-static unsigned long (*kallsyms_lookup_name_p)(const char *name);
-
 #if defined(CONFIG_PPC64)
 static void (*hpte_need_flush_p)(struct mm_struct *mm, unsigned long addr,
 		pte_t *ptep, unsigned long pte, int huge);
@@ -93,6 +88,7 @@
 void (*ipv6_local_rxpmtu_p)(struct sock *sk, struct flowi6 *fl6, u32 mtu);
 void (*ipv6_local_error_p)(struct sock *sk, int err, struct flowi6 *fl6,
 			   u32 info);
+void (*ipv6_select_ident_p)(struct frag_hdr *fhdr, struct rt6_info *rt);
 void (*ipv6_push_nfrag_opts_p)(struct sk_buff *skb, struct ipv6_txoptions *opt,
 			      u8 *proto,
 				struct in6_addr **daddr, struct in6_addr *saddr);
@@ -420,88 +416,137 @@
 	return 0;
 }
 
-static int find_kallsyms_lookup_name(void)
-{
-	int err = 0;
-
-#if defined(KPROBES_KALLSYMS)
-	struct kprobe kp;
-
-	memset(&kp, 0, sizeof(kp));
-	kp.symbol_name = "kallsyms_lookup_name";
-	err = register_kprobe(&kp);
-	if (!err) {
-		kallsyms_lookup_name_p = (void *)kp.addr;
-		unregister_kprobe(&kp);
-	}
-#else
-	kallsyms_lookup_name_p = (void *)KALLSYMS_LOOKUP;
-#endif
-	if (!err)
-		err = kallsyms_lookup_name_p == NULL;
-
-	return err;
-}
-
-#define FIND_SYMBOL(name, ptr) do { \
-	ptr = (void *)kallsyms_lookup_name_p(name); \
-	if (!ptr) { \
-		pr_err("Could not locate " name "\n"); \
-		return -1; \
-	} \
-} while (0)
-
 int prepare_tom_for_offload(void)
 {
-	if (!kallsyms_lookup_name_p) {
-		int err = find_kallsyms_lookup_name();
-
-		if (err) {
-			pr_err("find_kallsyms_lookup_name failed\n");
-			return err;
-		}
-	}
-
 #if defined(CONFIG_SMP) && !defined(PPC64_TLB_BATCH_NR)
 #if defined(CONFIG_T4_ZCOPY_SENDMSG) || defined(CONFIG_T4_ZCOPY_SENDMSG_MODULE)
 #if defined(CONFIG_X86) || defined(CONFIG_X86_64)
-	FIND_SYMBOL("flush_tlb_mm_range", flush_tlb_mm_range_p);
+	flush_tlb_mm_range_p = (void *)kallsyms_lookup_name("flush_tlb_mm_range");
+        if (!flush_tlb_mm_range_p) {
+                printk(KERN_ERR "Could not locate flush_tlb_mm_range");
+                return -1;
+        }
 #endif
 #if defined(CONFIG_PPC64)
-	FIND_SYMBOL("flush_tlb_page", flush_tlb_page_p);
+	flush_tlb_page_p = (void *)kallsyms_lookup_name("flush_tlb_page");
+        if (!flush_tlb_page_p) {
+                printk(KERN_ERR "Could not locate flush_tlb_page");
+                return -1;
+        }
 #endif
 #endif
 #endif
 
-	FIND_SYMBOL("secure_tcp_seq", secure_tcp_seq_p);
-	FIND_SYMBOL("tcp_update_metrics", tcp_update_metrics_p);
-	FIND_SYMBOL("tcp_reno", tcp_reno_p);
+	secure_tcp_seq_p = (void *)kallsyms_lookup_name("secure_tcp_seq");
+	if (!secure_tcp_seq_p) {
+		printk(KERN_ERR "Could not locate secure_tcp_seq");
+		return -1;
+	}
+
+	tcp_update_metrics_p = (void *)kallsyms_lookup_name("tcp_update_metrics");
+	if (!tcp_update_metrics_p) {
+		printk(KERN_ERR "Could not locate tcp_update_metrics");
+		return -1;
+	}
+
+	tcp_reno_p = (void *)kallsyms_lookup_name("tcp_reno");
+        if (!tcp_reno_p) {
+                printk(KERN_ERR "Could not locate tcp_reno");
+                return -1;
+        }
 
 #if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-	FIND_SYMBOL("tcpv6_prot", tcpv6_prot_p);
-	FIND_SYMBOL("ip6_route_input", ip6_route_input_p);
+	tcpv6_prot_p = (void *)kallsyms_lookup_name("tcpv6_prot");
+	if (!tcpv6_prot_p) {
+		printk(KERN_ERR "Could not locate tcpv6_prot");
+		return -1;
+	}
+
+	ip6_route_input_p = (void *)kallsyms_lookup_name("ip6_route_input");
+	if (!ip6_route_input_p) {
+		printk(KERN_ERR "Could not locate ip6_route_input");
+		return -1;
+	}
 #endif
 
-	FIND_SYMBOL("sk_filter_charge", sk_filter_charge_p);
-	FIND_SYMBOL("sk_filter_uncharge", sk_filter_uncharge_p);
+	sk_filter_charge_p = (void *)kallsyms_lookup_name("sk_filter_charge");
+	if (!sk_filter_charge_p) {
+		printk(KERN_ERR "Could not locate sk_filter_charge");
+		return -1;
+	}
+
+	sk_filter_uncharge_p = (void *)kallsyms_lookup_name("sk_filter_uncharge");
+	if (!sk_filter_uncharge_p) {
+		printk(KERN_ERR "Could not locate sk_filter_uncharge");
+		return -1;
+	}
 
 #if defined(CONFIG_PPC64)
-	FIND_SYMBOL("hpte_need_flush", hpte_need_flush_p);
-	FIND_SYMBOL("pmd_page", pmd_page_p);
+	hpte_need_flush_p = (void *)kallsyms_lookup_name("hpte_need_flush");
+        if (!hpte_need_flush_p) {
+                printk(KERN_ERR "Could not locate hpte_need_flush");
+                return -1;
+        }
+
+	pmd_page_p = (void *)kallsyms_lookup_name("pmd_page");
+	if (!pmd_page_p) {
+		printk(KERN_ERR "Could not locate pmd_page");
+		return -1;
+	}
 #if defined(CONFIG_PPC_BOOK3S)
-	FIND_SYMBOL("radix__flush_tlb_pte_p9_dd1",
-		    radix__flush_tlb_pte_p9_dd1_p);
+	radix__flush_tlb_pte_p9_dd1_p = (void *)kallsyms_lookup_name("radix__flush_tlb_pte_p9_dd1");
+	if (!radix__flush_tlb_pte_p9_dd1_p) {
+		printk(KERN_ERR "Could not locate radix__flush_tlb_pte_p9_dd1");
+		return -1;
+	}
 #endif
 #endif
 
-	FIND_SYMBOL("tcp_init_xmit_timers", tcp_xmit_timers_init_p);
-	FIND_SYMBOL("sk_stream_write_space", sk_stream_write_space_p);
+	tcp_xmit_timers_init_p = (void *)kallsyms_lookup_name("tcp_init_xmit_timers");
+	if (!tcp_xmit_timers_init_p) {
+		printk(KERN_ERR "Could not locate tcp_init_xmit_timers");
+		return -1;
+	}
+
+	sk_stream_write_space_p = (void *)kallsyms_lookup_name("sk_stream_write_space");
+	if (!sk_stream_write_space_p) {
+		printk(KERN_ERR "Could not locate sk_stream_write_space_p");
+		return -1;
+	}
 
 #ifdef CONFIG_UDPV6_OFFLOAD
-	FIND_SYMBOL("udpv6_prot", udpv6_prot_p);
-	FIND_SYMBOL("ipv6_local_rxpmtu", ipv6_local_rxpmtu_p);
-	FIND_SYMBOL("ipv6_local_error", ipv6_local_error_p);
-	FIND_SYMBOL("ipv6_push_nfrag_opts", ipv6_push_nfrag_opts_p);
+	udpv6_prot_p = (void *)kallsyms_lookup_name("udpv6_prot");
+	if (!udpv6_prot_p) {
+		pr_err("Could not locate udpv6_prot");
+		return -1;
+	}
+
+	ipv6_local_rxpmtu_p = (void *)kallsyms_lookup_name(
+						"ipv6_local_rxpmtu");
+	if (!ipv6_local_rxpmtu_p) {
+		pr_err("Could not locate ipv6_local_rxpmtu");
+		return -1;
+	}
+
+	ipv6_local_error_p = (void *)kallsyms_lookup_name("ipv6_local_error");
+	if (!ipv6_local_error_p) {
+		pr_err("Could not locate ipv6_local_error");
+		return -1;
+	}
+
+	ipv6_select_ident_p = (void *)kallsyms_lookup_name(
+						"ipv6_select_ident");
+	if (!ipv6_select_ident_p) {
+		pr_err("Could not locate ipv6_select_ident");
+		return -1;
+	}
+
+	ipv6_push_nfrag_opts_p = (void *)kallsyms_lookup_name(
+						"ipv6_push_nfrag_opts");
+	if (!ipv6_push_nfrag_opts_p) {
+		pr_err("Could not locate ipv6_push_nfrag_opts");
+		return -1;
+	}
 #endif /* CONFIG_UDPV6_OFFLOAD */
 
 	return 0;
diff -r 30 src/network/t4_tom/t4_ddp.c
--- a/src/network/t4_tom/t4_ddp.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/t4_ddp.c	Tue May 18 15:02:47 2021 +0530
@@ -162,7 +162,7 @@
 	err = t4_get_user_pages_locked_with_flags(addr, npages, FOLL_WRITE,
 				    p->pages, &mm_locked);
 	if (mm_locked)
-		mmap_read_unlock(current->mm);
+		up_read(&current->mm->mmap_sem);
 	if (err != npages) {
 		if (err < 0)
 			goto free_gl;
@@ -383,7 +383,7 @@
 		len = M_TCB_RX_DDP_BUF0_LEN;
 	len = min_t(int, len, iov_iter_single_seg_count(&msg->msg_iter));
 
-	if (!uaccess_kernel())
+	if (!segment_eq(get_fs(), KERNEL_DS))
 		err = t4_pin_pages(p->pdev, addr, len, &gl, p);
 	else
 		err = t4_map_pages(p->pdev, addr, len, &gl, p);
diff -r 30 src/network/t4_tom/t4_tls.c
--- a/src/network/t4_tom/t4_tls.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/t4_tls.c	Tue May 18 15:02:47 2021 +0530
@@ -89,7 +89,11 @@
  */
 static inline unsigned long long get_ns_cycles(void)
 {
-	return (unsigned long long)ktime_to_ns(ktime_get());
+	struct timespec ts;
+
+	ktime_get_ts(&ts);
+	return (unsigned long
+		long)ktime_to_ns(timespec_to_ktime(ts));
 }
 #endif
 
diff -r 30 src/network/t4_tom/t4_tlskey.h
--- a/src/network/t4_tom/t4_tlskey.h	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/t4_tlskey.h	Tue May 18 15:02:47 2021 +0530
@@ -1,16 +1,16 @@
 #include <crypto/sha.h>
 #include <linux/scatterlist.h>
 
-static const u32 chcr_sha1_init[SHA1_DIGEST_SIZE / 4] = {
+static const u32 sha1_init[SHA1_DIGEST_SIZE / 4] = {
 	SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4,
 };
 
-static const u32 cxgb4_sha224_init[SHA256_DIGEST_SIZE / 4] = {
+static const u32 sha224_init[SHA256_DIGEST_SIZE / 4] = {
 	SHA224_H0, SHA224_H1, SHA224_H2, SHA224_H3,
 	SHA224_H4, SHA224_H5, SHA224_H6, SHA224_H7,
 };
 
-static const u32 cxgb4_sha256_init[SHA256_DIGEST_SIZE / 4] = {
+static const u32 sha256_init[SHA256_DIGEST_SIZE / 4] = {
 	SHA256_H0, SHA256_H1, SHA256_H2, SHA256_H3,
 	SHA256_H4, SHA256_H5, SHA256_H6, SHA256_H7,
 };
diff -r 30 src/network/t4_tom/t4_uom.c
--- a/src/network/t4_tom/t4_uom.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/t4_uom.c	Tue May 18 15:02:47 2021 +0530
@@ -1064,64 +1064,6 @@
 	return sk->sk_prot->sendmsg(sk, msg, len);
 }
 
-/**
-* skb_append_datato_frags - append the user data to a skb
-* @sk: sock  structure
-* @skb: skb structure to be appended with user data.
-* @getfrag: call back function to be used for getting the user data
-* @from: pointer to user message iov
-* @length: length of the iov message
-*
-* Description: This procedure append the user data in the fragment part
-* of the skb if any page alloc fails user this procedure returns  -ENOMEM
-*/
-int skb_append_datato_frags(struct sock *sk, struct sk_buff *skb,
-			    int (*getfrag)(void *from, char *to, int offset,
-					   int len, int odd, struct sk_buff *skb),
-			    void *from, int length)
-{
-	int frg_cnt = skb_shinfo(skb)->nr_frags;
-	int copy;
-	int offset = 0;
-	int ret;
-	struct page_frag *pfrag = &current->task_frag;
-
-	do {
-		/* Return error if we don't have space for new frag */
-		if (frg_cnt >= MAX_SKB_FRAGS)
-			return -EMSGSIZE;
-
-		if (!sk_page_frag_refill(sk, pfrag))
-			return -ENOMEM;
-
-		/* copy the user data to page */
-		copy = min_t(int, length, pfrag->size - pfrag->offset);
-
-		ret = getfrag(from, page_address(pfrag->page) + pfrag->offset,
-			      offset, copy, 0, skb);
-		if (ret < 0)
-			return -EFAULT;
-
-		/* copy was successful so update the size parameters */
-		skb_fill_page_desc(skb, frg_cnt, pfrag->page, pfrag->offset,
-				   copy);
-		frg_cnt++;
-		pfrag->offset += copy;
-		get_page(pfrag->page);
-
-		skb->truesize += copy;
-		refcount_add(copy, &sk->sk_wmem_alloc);
-		skb->len += copy;
-		skb->data_len += copy;
-		offset += copy;
-		length -= copy;
-
-	} while (length > 0);
-
-	return 0;
-}
-EXPORT_SYMBOL(skb_append_datato_frags);
-
 #ifdef CONFIG_UDPV6_OFFLOAD
 static inline int chelsio_ip6_ufo_append_data(struct sock *sk,
 			int getfrag(void *from, char *to, int offset, int len,
@@ -2091,7 +2033,7 @@
 }
 
 int udpoffload_setsockopt(struct sock *sk, int level, int optname,
-				sockptr_t optval, unsigned int optlen)
+				char __user *optval, unsigned int optlen)
 {
 	int ret, val;
 	struct cpl_io_state *cplios;
@@ -2105,7 +2047,7 @@
 		if (optlen < sizeof(int))
 			return -EINVAL;
 
-		if (copy_from_sockptr(&val, optval, sizeof(val)))
+		if (get_user(val, (int __user *)optval))
 			return -EFAULT;
 
 		ret = chelsio_uo_init(sk, &udpoffload_prot);
@@ -2149,7 +2091,7 @@
 
 #ifdef CONFIG_UDPV6_OFFLOAD
 int udpv6offload_setsockopt(struct sock *sk, int level, int optname,
-			    sockptr_t optval, unsigned int optlen)
+			    char __user *optval, unsigned int optlen)
 {
 	int ret, val;
 	struct cpl_io_state *cplios;
@@ -2163,7 +2105,7 @@
 		if (optlen < sizeof(int))
 			return -EINVAL;
 
-		if (copy_from_sockptr(&val, optval, sizeof(val)))
+		if (get_user(val, (int __user *)optval))
 			return -EFAULT;
 
 		ret = chelsio_uo_init(sk, &udpv6offload_prot);
@@ -2207,6 +2149,24 @@
 }
 #endif /* CONFIG_UDPV6_OFFLOAD */
 
+#ifdef CONFIG_COMPAT
+int compat_udpoffload_setsockopt(struct sock *sk, int level, int optname,
+                          char __user *optval, unsigned int optlen)
+{
+	return orig_udp_prot.compat_setsockopt(sk, level, optname,
+					       optval, optlen);
+}
+
+#ifdef CONFIG_UDPV6_OFFLOAD
+int compat_udpv6offload_setsockopt(struct sock *sk, int level, int optname,
+				   char __user *optval, unsigned int optlen)
+{
+	return orig_udpv6_prot.compat_setsockopt(sk, level, optname,
+						 optval, optlen);
+}
+#endif /* CONFIG_UDPV6_OFFLOAD */
+#endif
+
 void __init udpoffload4_register(void)
 {
 	/*
@@ -2231,6 +2191,9 @@
 	 * the socket's Protocol Vector to our UDP Offload Vector above.
 	 */
 	udp_prot.setsockopt = udpoffload_setsockopt;
+#ifdef CONFIG_COMPAT
+	udp_prot.compat_setsockopt = compat_udpoffload_setsockopt;
+#endif
 
 #ifdef CONFIG_UDPV6_OFFLOAD
 	/*
@@ -2245,6 +2208,9 @@
 	udpv6offload_prot.destroy = udpv6offload_destroy;
 
 	udpv6_prot_p->setsockopt = udpv6offload_setsockopt;
+#ifdef CONFIG_COMPAT
+	udpv6_prot_p->compat_setsockopt = compat_udpv6offload_setsockopt;
+#endif
 #endif /* CONFIG_UDPV6_OFFLOAD */
 	return;
 }
diff -r 30 src/network/t4_tom/t4tom_ma_failover.c
--- a/src/network/t4_tom/t4tom_ma_failover.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/t4tom_ma_failover.c	Tue May 18 15:02:47 2021 +0530
@@ -1712,9 +1712,9 @@
 		= failed_dev;
 
 #if LINUX_VERSION_CODE < KERNEL_VERSION(5, 0, 0)
-	spin_lock(&t->idr_lock);
+	rcu_read_lock();
 	idr_for_each(&t->hwtid_idr, t4_toe_ma_failover_idr, pi);
-	spin_unlock(&t->idr_lock);
+	rcu_read_unlock();
 #else
 	xa_for_each(&t->hwtid_idr, index, sk)
 		t4_toe_ma_failover_idr(index, sk, pi);
diff -r 30 src/network/t4_tom/tom.c
--- a/src/network/t4_tom/tom.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/tom.c	Tue May 18 15:02:47 2021 +0530
@@ -593,11 +593,11 @@
         return single_open(file, proc_cop_show, PDE_DATA(inode));
 }
 
-static const struct proc_ops proc_cop_fops = {
-        .proc_open = proc_cop_open,
-        .proc_read = seq_read,
-        .proc_lseek = seq_lseek,
-        .proc_release = single_release,
+static const struct file_operations proc_cop_fops = {
+        .open = proc_cop_open,
+        .read = seq_read,
+        .llseek = seq_lseek,
+        .release = single_release,
 };
 
 static void tom_cop_proc_free(struct proc_dir_entry *dir)
@@ -642,21 +642,12 @@
 	return single_open(file, proc_info_show, PDE_DATA(inode));
 }
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-static const struct proc_ops proc_info_fops = {
-	.proc_open = proc_info_open,
-	.proc_read = seq_read,
-	.proc_lseek = seq_lseek,
-	.proc_release = single_release,
-};
-#else
 static const struct file_operations proc_info_fops = {
 	.open = proc_info_open,
 	.read = seq_read,
 	.llseek = seq_lseek,
 	.release = single_release,
 };
-#endif
 
 static void tom_info_proc_free(struct proc_dir_entry *dir)
 {
@@ -935,13 +926,13 @@
 	struct tom_data *td = TOM_DATA(dev);
 
 #if LINUX_VERSION_CODE < KERNEL_VERSION(5, 0, 0)
-	spin_lock(&td->idr_lock);
+	rcu_read_lock();
 	idr_for_each(&td->hwtid_idr, abort_ofld_conn, egress_dev);
-	spin_unlock(&td->idr_lock);
+	rcu_read_unlock();
 
-	spin_lock(&td->aidr_lock);
+	rcu_read_lock();
 	idr_for_each(&td->aidr, abort_ofld_conn, egress_dev);
-	spin_unlock(&td->aidr_lock);
+	rcu_read_unlock();
 #else
 	unsigned long index;
 	struct sock *sk;
@@ -969,23 +960,21 @@
 	struct tom_data *td = TOM_DATA(dev);
 
 #if LINUX_VERSION_CODE < KERNEL_VERSION(5, 0, 0)
-	spin_lock_bh(&td->idr_lock);
+	rcu_read_lock();
 	idr_for_each(&td->hwtid_idr, t4tom_set_tx_wait_idle, NULL);
-	spin_unlock(&td->idr_lock);
+	rcu_read_unlock();
 
-	spin_lock(&td->aidr_lock);
+	rcu_read_lock();
 	idr_for_each(&td->aidr, t4tom_set_tx_wait_idle, NULL);
-	spin_unlock_bh(&td->aidr_lock);
+	rcu_read_unlock();
 #else
 	unsigned long index;
 	struct sock *sk;
 
-	xa_for_each(&td->hwtid_idr, index, sk) {
+	xa_for_each(&td->hwtid_idr, index, sk);
 		t4tom_set_tx_wait_idle(index, sk, NULL);
-	}
-	xa_for_each(&td->aidr, index, sk) {
+	xa_for_each(&td->aidr, index, sk);
 		t4tom_set_tx_wait_idle(index, sk, NULL);
-	}
 #endif
 }
 
diff -r 30 src/network/t4_tom/tom.h
--- a/src/network/t4_tom/tom.h	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/tom.h	Tue May 18 15:02:47 2021 +0530
@@ -45,13 +45,6 @@
 #define G_TP_VERSION_MICRO(x)           \
             (((x) >> S_TP_VERSION_MICRO) & M_TP_VERSION_MICRO)
 
-#ifdef UDP_OFFLOAD
-int skb_append_datato_frags(struct sock *sk, struct sk_buff *skb,
-			    int getfrag(void *from, char *to, int offset,
-				        int len, int odd, struct sk_buff *skb),
-			    void *from, int length);
-#endif
-
 enum {
 	TP_VERSION_MAJOR = 1,
 	TP_VERSION_MINOR = 1,
diff -r 30 src/network/t4_tom/tom_compat.h
--- a/src/network/t4_tom/tom_compat.h	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/tom_compat.h	Tue May 18 15:02:47 2021 +0530
@@ -111,6 +111,10 @@
 extern __u32 secure_tcp_sequence_number_offload(__be32 saddr, __be32 daddr, __be16 sport, __be16 dport);
 extern struct page *pmd_page_offload(pmd_t pmd);
 
+#if defined(CONFIG_COMPAT)
+# define TOM_CONFIG_COMPAT
+#endif
+
 #if defined(CONFIG_T4_ZCOPY_SENDMSG) || defined(CONFIG_T4_ZCOPY_SENDMSG_MODULE)
 #if defined(CONFIG_PPC64)
 #if defined(CONFIG_PPC_BOOK3S)
@@ -666,15 +670,13 @@
 {
 	return vlan_insert_tag(skb, vlan_proto, vlan_tci);
 }
-
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(5,4,5)
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(4,19,118)
 #define ip6_dst_lookup_flow_compat(__sk, __fl6, __final_dst, __can_sleep) \
 	ip6_dst_lookup_flow(__sk, __fl6, __final_dst)
 #else
 #define ip6_dst_lookup_flow_compat(__sk, __fl6, __final_dst, __can_sleep) \
 	ip6_dst_lookup_flow(sock_net(__sk), __sk, __fl6, __final_dst)
 #endif
-
 #define ip6_sk_dst_lookup_flow_compat(__sk, __fl6, __final_dst, __can_sleep, connected) \
 	ip6_sk_dst_lookup_flow(__sk, __fl6, __final_dst, connected)
 
diff -r 30 src/network/t4_tom/tom_sysctl.c
--- a/src/network/t4_tom/tom_sysctl.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/tom_sysctl.c	Tue May 18 15:02:47 2021 +0530
@@ -110,7 +110,7 @@
 	.max_conn = -1,
 	.soft_backlog_limit = 1,
 	.kseg_ddp = 0,
-	.ddp = 0,
+	.ddp = 1,
 	.ddp_thres = 40960,
 	.ddp_xlthres = DDP_RSVD_WIN<<2,
 #if PAGE_SHIFT >= 14
diff -r 30 src/network/t4_tom/tom_sysctl.txt
--- a/src/network/t4_tom/tom_sysctl.txt	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/t4_tom/tom_sysctl.txt	Tue May 18 15:02:47 2021 +0530
@@ -71,9 +71,3 @@
   chooses an adequate default. Programs the value in
   FW_FLOWC_MNEM_TXDATAPLEN_MAX mnemonic of flowc wr when initializing
   the connection. This value should be only either 0 or 64000.
-
-- ddp: If 0 (default) ddp is disabled. If 1 ddp is enabled. t4_tom currently
-  supports ddp to user-space applications (such as iperf, netperf) only,
-  it does not support DDP to kernel applications (such as NVMEoTOE and NFSoTOE).
-  Enabling ddp for kernel applications may result in undefined behavior.
-
diff -r 30 src/network/toecore/module_support/module_support-toe-4.14.0.c
--- a/src/network/toecore/module_support/module_support-toe-4.14.0.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/toecore/module_support/module_support-toe-4.14.0.c	Tue May 18 15:02:47 2021 +0530
@@ -2,7 +2,7 @@
  * This file contains pieces of the Linux TCP/IP stack needed for modular
  * TOE support.
  *
- * Copyright (C) 2006-2021 Chelsio Communications.  All rights reserved.
+ * Copyright (C) 2006-2019 Chelsio Communications.  All rights reserved.
  * See the corresponding files in the Linux tree for copyrights of the
  * original Linux code a lot of this file is based on.
  *
@@ -34,7 +34,6 @@
 #include <linux/module.h>
 #include "toe_compat.h"
 #include <linux/toedev.h>
-#include <linux/sunrpc/xprt.h>
 #include <net/inet_common.h>
 #include <net/offload.h>
 #include <linux/highmem.h>
@@ -83,8 +82,6 @@
 static sk_read_actor_t iscsi_tcp_recv_p;
 static sk_read_actor_t iscsi_sw_tcp_recv_p;
 static sk_read_actor_t iscsi_tcp_data_recv_p;
-static void (*xs_data_ready_p)(struct sock *sk);
-static sk_read_actor_t xs_tcp_data_recv_p;
 static void (*lustre_tcp_data_ready_p)(struct sock *sk);
 static void (*sock_def_readable_p)(struct sock *sk);
 #if LINUX_VERSION_CODE < KERNEL_VERSION(4, 20, 0)
@@ -104,9 +101,6 @@
 		(void *)kallsyms_lookup_name("iscsi_sw_tcp_recv");
 	iscsi_tcp_data_recv_p =
 		(void *)kallsyms_lookup_name("iscsi_tcp_data_recv");
-	xs_data_ready_p =
-		(void *)kallsyms_lookup_name("xs_data_ready");
-	xs_tcp_data_recv_p = (void *)kallsyms_lookup_name("xs_tcp_data_recv");
 	sock_def_readable_p = (void *)kallsyms_lookup_name("sock_def_readable");
 	lustre_tcp_data_ready_p = (void *)kallsyms_lookup_name("ksocknal_data_ready");
 
@@ -123,14 +117,12 @@
 {
 	switch (event) {
 	case MODULE_STATE_GOING:
-		if (xs_data_ready_p || iscsi_tcp_data_ready_p ||
-			lustre_tcp_data_ready_p) 
-				find_rpc_iscsi_callbacks();
+		if (iscsi_tcp_data_ready_p || lustre_tcp_data_ready_p)
+			find_rpc_iscsi_callbacks();
 		break;
 	case MODULE_STATE_COMING:
-		if (!xs_data_ready_p || !iscsi_tcp_data_ready_p ||
-			!lustre_tcp_data_ready_p)	
-				find_rpc_iscsi_callbacks();
+		if (!iscsi_tcp_data_ready_p || !lustre_tcp_data_ready_p)
+			find_rpc_iscsi_callbacks();
 		break;
 	}
 	return NOTIFY_DONE;
@@ -899,7 +891,11 @@
 	 * Underlying function will use this to retrieve the network
 	 * namespace
 	 */
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(4,19,118)
 	dst = ip6_dst_lookup_flow(ctl_sk, &fl6, NULL);
+#else
+	dst = ip6_dst_lookup_flow(sock_net(ctl_sk), ctl_sk, &fl6, NULL);
+#endif
 	if (!IS_ERR(dst)) {
 		skb_dst_set(buff, dst);
 		ip6_xmit(ctl_sk, buff, &fl6, fl6.flowi6_mark, NULL, tclass);
@@ -1279,7 +1275,11 @@
 
 	security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(4,19,118)
 	dst = ip6_dst_lookup_flow(sk, &fl6, final_p);
+#else
+	dst = ip6_dst_lookup_flow(sock_net(sk), sk, &fl6, final_p);
+#endif
 	if (IS_ERR(dst)) {
 		err = PTR_ERR(dst);
 		goto failure;
@@ -1464,7 +1464,7 @@
 	offload_inet6_stream_ops.splice_read = tcp_splice_read_offload;
 #endif
 
-	walk_listens(NULL, offload_listen_cb);
+	walk_listens(NULL, offload_listen_cb, DISABLE_WALK_SUPPORT);
 #else
 	{
 		struct proto_ops *iso = (struct proto_ops *)&inet_stream_ops;
@@ -1505,7 +1505,7 @@
 	if (offload_enabled) {
 		unregister_module_notifier(&module_notifier);
 #ifdef CONFIG_STRICT_KERNEL_RWX
-		walk_listens(NULL, restore_listen_cb);
+		walk_listens(NULL, restore_listen_cb, ENABLE_WALK_SUPPORT);
 #else
 		{
 			struct proto_ops *iso = (struct proto_ops *)&inet_stream_ops;
@@ -1549,23 +1549,6 @@
 	return tcp_read_sock(sk, desc, recv_actor);
 }
 
-static inline struct rpc_xprt *xprt_from_sock(struct sock *sk)
-{
-        return (struct rpc_xprt *) sk->sk_user_data;
-}
-
-static void ofld_read_sock_work_fn(struct work_struct *work)
-{
-	struct xs_data_work *xs_work = container_of(work, struct xs_data_work,
-						    read_sock_work);
-
-	lock_sock(xs_work->sk);
-	ofld_read_sock(xs_work->sk, &xs_work->rd_desc, xs_tcp_data_recv_p);
-	release_sock(xs_work->sk);
-
-	kfree(xs_work);
-}
-
 struct nvme_tcp_ctrl;
 struct nvme_tcp_queue_header {
 	struct socket           *sock;
@@ -1614,39 +1597,6 @@
 }
 #endif
 
-/* Offload version of Linux kernel xs_tcp_data_ready() */
-/* Replacement for RPC's ->data_ready callback */
-static void xs_ofld_tcp_data_ready(struct sock *sk)
-{
-	struct rpc_xprt *xprt;
-	struct xs_data_work *xs_work;
-
-	read_lock_bh(&sk->sk_callback_lock);
-	if (!(xprt = xprt_from_sock(sk)))
-		goto out;
-	/* Any data means we had a useful conversation, so
-	 * the we don't need to delay the next reconnect
-	 */
-	if (xprt->reestablish_timeout)
-		xprt->reestablish_timeout = 0;
-
-	xs_work = kmalloc(sizeof(struct xs_data_work), GFP_ATOMIC);
-	if (!xs_work) {
-		printk(KERN_WARNING "Could not allocate xs_data_work\n");
-		goto out;
-	}
-	xs_work->sk = sk;
-	/* We use rd_desc to pass struct xprt to xs_tcp_data_recv */
-	xs_work->rd_desc.arg.data = xprt;
-	xs_work->rd_desc.count = 65536;
-
-	INIT_WORK(&xs_work->read_sock_work, ofld_read_sock_work_fn);
-	schedule_work(&xs_work->read_sock_work);
-
-out:
-	read_unlock_bh(&sk->sk_callback_lock);
-}
-
 static inline void iscsi_tcp_segment_unmap(struct iscsi_segment *segment)
 {
 	if (segment->sg_mapped) {
@@ -1787,13 +1737,13 @@
 	if (!sk->sk_user_data)
 		return 0;
 
-	if (sk->sk_data_ready == xs_data_ready_p)
-		sk->sk_data_ready = xs_ofld_tcp_data_ready;
 #if LINUX_VERSION_CODE < KERNEL_VERSION(4, 20, 0)
-	else if (sk->sk_data_ready == nvme_data_ready_p)
+	if (sk->sk_data_ready == nvme_data_ready_p)
 		sk->sk_data_ready = nvme_ofld_tcp_data_ready;
+	else if (sk->sk_data_ready == iscsi_tcp_data_ready_p) {
+#else
+	if (sk->sk_data_ready == iscsi_tcp_data_ready_p) {
 #endif
-	else if (sk->sk_data_ready == iscsi_tcp_data_ready_p) {
 		if (iscsi_tcp_recv_p)
 			sk->sk_data_ready = iscsi_ofld_tcp_data_ready_0;
 		else if (iscsi_tcp_data_recv_p)
@@ -1810,13 +1760,13 @@
 
 void restore_special_data_ready(struct sock *sk)
 {
-	if (sk->sk_data_ready == xs_ofld_tcp_data_ready)
-		sk->sk_data_ready = xs_data_ready_p;
 #if LINUX_VERSION_CODE < KERNEL_VERSION(4, 20, 0)
-	else if (sk->sk_data_ready == nvme_ofld_tcp_data_ready)
+	if (sk->sk_data_ready == nvme_ofld_tcp_data_ready)
 		sk->sk_data_ready = nvme_data_ready_p;
+	else if (sk->sk_data_ready == iscsi_ofld_tcp_data_ready_0)
+#else
+	if (sk->sk_data_ready == iscsi_ofld_tcp_data_ready_0)
 #endif
-	else if (sk->sk_data_ready == iscsi_ofld_tcp_data_ready_0)
 		sk->sk_data_ready = iscsi_tcp_data_ready_p;
 
 	else if (sk->sk_data_ready == iscsi_ofld_tcp_data_ready_1)
diff -r 30 src/network/toecore/module_support/module_support-toe-5.0.0.c
--- a/src/network/toecore/module_support/module_support-toe-5.0.0.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/toecore/module_support/module_support-toe-5.0.0.c	Tue May 18 15:02:47 2021 +0530
@@ -21,9 +21,6 @@
  * $SUPPORTED KERNEL 5.0$
  * $SUPPORTED KERNEL 5.1$
  * $SUPPORTED KERNEL 5.2$
- * $SUPPORTED KERNEL 5.4$
- * $SUPPORTED KERNEL 5.6$
- * $SUPPORTED KERNEL 5.10$
  */
 #include <linux/kconfig.h>
 #include <net/tcp.h>
@@ -57,7 +54,7 @@
 
 #ifdef CONFIG_TCPV6_OFFLOAD
 static const struct inet_connection_sock_af_ops ipv6_mapped;
-static const struct inet_connection_sock_af_ops *ipv6_specific_p;
+static const struct inet_connection_sock_af_ops ipv6_specific;
 
 static struct proto orig_tcpv6_prot;
 static struct proto *tcpv6_prot_p;
@@ -71,7 +68,6 @@
 #endif
 #endif
 
-static unsigned long (*kallsyms_lookup_name_p)(const char *name);
 static __u32 (*secure_tcp_seq_p)(__u32 saddr, __u32 daddr,
 					     __u16 sport, __u16 dport);
 static __u32 (*secure_tcp_ts_off_p)(struct net *net, __u32 saddr, __u32 daddr);
@@ -91,19 +87,16 @@
 {
 	/* All of these may fail since RPC/iSCSI may not be loaded */
 	iscsi_tcp_data_ready_p =
-		(void *)kallsyms_lookup_name_p("iscsi_tcp_data_ready");
+		(void *)kallsyms_lookup_name("iscsi_tcp_data_ready");
 	iscsi_sw_tcp_data_ready_p =
-		(void *)kallsyms_lookup_name_p("iscsi_sw_tcp_data_ready");
-	iscsi_tcp_recv_p =
-		(void *)kallsyms_lookup_name_p("iscsi_tcp_recv");
+		(void *)kallsyms_lookup_name("iscsi_sw_tcp_data_ready");
+	iscsi_tcp_recv_p = (void *)kallsyms_lookup_name("iscsi_tcp_recv");
 	iscsi_sw_tcp_recv_p =
-		(void *)kallsyms_lookup_name_p("iscsi_sw_tcp_recv");
+		(void *)kallsyms_lookup_name("iscsi_sw_tcp_recv");
 	iscsi_tcp_data_recv_p =
-		(void *)kallsyms_lookup_name_p("iscsi_tcp_data_recv");
-	sock_def_readable_p =
-		(void *)kallsyms_lookup_name_p("sock_def_readable");
-	lustre_tcp_data_ready_p =
-		(void *)kallsyms_lookup_name_p("ksocknal_data_ready");
+		(void *)kallsyms_lookup_name("iscsi_tcp_data_recv");
+	sock_def_readable_p = (void *)kallsyms_lookup_name("sock_def_readable");
+	lustre_tcp_data_ready_p = (void *)kallsyms_lookup_name("ksocknal_data_ready");
 }
 
 static int module_notify_handler(struct notifier_block *this,
@@ -437,51 +430,29 @@
 	return 1;
 }
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-static struct tcp_md5sig_key *tcp_v6_md5_do_lookup(const struct sock *sk,
-						   const struct in6_addr *addr,
-						   int l3index)
-{
-	return tcp_md5_do_lookup(sk, l3index,
-				 (union tcp_md5_addr *)addr, AF_INET6);
-}
-#else
 static struct tcp_md5sig_key *tcp_v6_md5_do_lookup(const struct sock *sk,
 						   const struct in6_addr *addr)
 {
 	return tcp_md5_do_lookup(sk, (union tcp_md5_addr *)addr, AF_INET6);
 }
-#endif
 
 static struct tcp_md5sig_key *tcp_v6_md5_lookup(const struct sock *sk,
 						const struct sock *addr_sk)
 {
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-	int l3index;
-
-	l3index = l3mdev_master_ifindex_by_index(sock_net(sk),
-						 addr_sk->sk_bound_dev_if);
-	return tcp_v6_md5_do_lookup(sk, &addr_sk->sk_v6_daddr,
-				    l3index);
-#else
 	return tcp_v6_md5_do_lookup(sk, &addr_sk->sk_v6_daddr);
-#endif
 }
 
 static int tcp_v6_parse_md5_keys(struct sock *sk, int optname,
-				 sockptr_t optval, int optlen)
+				 char __user *optval, int optlen)
 {
 	struct tcp_md5sig cmd;
 	struct sockaddr_in6 *sin6 = (struct sockaddr_in6 *)&cmd.tcpm_addr;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-	int l3index = 0;
-#endif
 	u8 prefixlen;
 
 	if (optlen < sizeof(cmd))
 		return -EINVAL;
 
-	if (copy_from_sockptr(&cmd, optval, sizeof(cmd)))
+	if (copy_from_user(&cmd, optval, sizeof(cmd)))
 		return -EFAULT;
 
 	if (sin6->sin6_family != AF_INET6)
@@ -497,56 +468,17 @@
 		prefixlen = ipv6_addr_v4mapped(&sin6->sin6_addr) ? 32 : 128;
 	}
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-	if (optname == TCP_MD5SIG_EXT &&
-	    cmd.tcpm_flags & TCP_MD5SIG_FLAG_IFINDEX) {
-		struct net_device *dev;
-
-		rcu_read_lock();
-		dev = dev_get_by_index_rcu(sock_net(sk), cmd.tcpm_ifindex);
-		if (dev && netif_is_l3_master(dev))
-			l3index = dev->ifindex;
-		rcu_read_unlock();
-
-		/* ok to reference set/not set outside of rcu;
-		 * right now device MUST be an L3 master
-		 */
-		if (!dev || !l3index)
-			return -EINVAL;
-	}
-#endif
-
 	if (!cmd.tcpm_keylen) {
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-		if (ipv6_addr_v4mapped(&sin6->sin6_addr))
-			return tcp_md5_do_del(sk, (union tcp_md5_addr *)&sin6->sin6_addr.s6_addr32[3],
-					      AF_INET, prefixlen,
-					      l3index);
-		return tcp_md5_do_del(sk, (union tcp_md5_addr *)&sin6->sin6_addr,
-				      AF_INET6, prefixlen, l3index);
-#else
 		if (ipv6_addr_v4mapped(&sin6->sin6_addr))
 			return tcp_md5_do_del(sk, (union tcp_md5_addr *)&sin6->sin6_addr.s6_addr32[3],
 					      AF_INET, prefixlen);
 		return tcp_md5_do_del(sk, (union tcp_md5_addr *)&sin6->sin6_addr,
 				      AF_INET6, prefixlen);
-#endif
 	}
 
 	if (cmd.tcpm_keylen > TCP_MD5SIG_MAXKEYLEN)
 		return -EINVAL;
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-	if (ipv6_addr_v4mapped(&sin6->sin6_addr))
-		return tcp_md5_do_add(sk, (union tcp_md5_addr *)&sin6->sin6_addr.s6_addr32[3],
-				      AF_INET, prefixlen, l3index,
-				      cmd.tcpm_key, cmd.tcpm_keylen,
-				      GFP_KERNEL);
-
-	return tcp_md5_do_add(sk, (union tcp_md5_addr *)&sin6->sin6_addr,
-			      AF_INET6, prefixlen, l3index,
-			      cmd.tcpm_key, cmd.tcpm_keylen, GFP_KERNEL);
-#else
 	if (ipv6_addr_v4mapped(&sin6->sin6_addr))
 		return tcp_md5_do_add(sk, (union tcp_md5_addr *)&sin6->sin6_addr.s6_addr32[3],
 				      AF_INET, prefixlen, cmd.tcpm_key,
@@ -555,7 +487,6 @@
 	return tcp_md5_do_add(sk, (union tcp_md5_addr *)&sin6->sin6_addr,
 			      AF_INET6, prefixlen, cmd.tcpm_key,
 			      cmd.tcpm_keylen, GFP_KERNEL);
-#endif
 }
 
 static int tcp_v6_md5_hash_hdr(char *md5_hash, struct tcp_md5sig_key *key,
@@ -611,7 +542,7 @@
 };
 #endif
 
-static const struct tcp_request_sock_ops toecore_tcp_request_sock_ipv6_ops = {
+static const struct tcp_request_sock_ops tcp_request_sock_ipv6_ops = {
 	.mss_clamp	=	IPV6_MIN_MTU - sizeof(struct tcphdr) -
 				sizeof(struct ipv6hdr),
 #ifdef CONFIG_TCP_MD5SIG
@@ -641,7 +572,7 @@
 		goto drop;
 
 	return tcp_conn_request(tcp6_request_sock_ops_p,
-				&toecore_tcp_request_sock_ipv6_ops, sk, skb);
+				&tcp_request_sock_ipv6_ops, sk, skb);
 
 drop:
 	tcp_listendrop(sk);
@@ -664,9 +595,6 @@
 	struct sock *newsk;
 #ifdef CONFIG_TCP_MD5SIG
 	struct tcp_md5sig_key *key;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-	int l3index;
-#endif
 #endif
 	struct flowi6 fl6;
 
@@ -812,29 +740,17 @@
 	newinet->inet_rcv_saddr = LOOPBACK4_IPV6;
 
 #ifdef CONFIG_TCP_MD5SIG
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-	l3index = l3mdev_master_ifindex_by_index(sock_net(sk), ireq->ir_iif);
-
 	/* Copy over the MD5 key from the original socket */
-	key = tcp_v6_md5_do_lookup(sk, &newsk->sk_v6_daddr, l3index);
-#else
 	key = tcp_v6_md5_do_lookup(sk, &newsk->sk_v6_daddr);
-#endif
 	if (key) {
 		/* We're using one, so create a matching key
 		 * on the newsk structure. If we fail to get
 		 * memory, then we end up not copying the key
 		 * across. Shucks.
 		 */
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-		tcp_md5_do_add(newsk, (union tcp_md5_addr *)&newsk->sk_v6_daddr,
-			       AF_INET6, 128, l3index, key->key, key->keylen,
-			       sk_gfp_mask(sk, GFP_ATOMIC));
-#else
 		tcp_md5_do_add(newsk, (union tcp_md5_addr *)&newsk->sk_v6_daddr,
 			       AF_INET6, 128, key->key, key->keylen,
 			       sk_gfp_mask(sk, GFP_ATOMIC));
-#endif
 	}
 #endif
 
@@ -843,7 +759,7 @@
 		tcp_done(newsk);
 		goto out;
 	}
-        *own_req = inet_ehash_nolisten(newsk, req_to_sk(req_unhash), NULL);
+        *own_req = inet_ehash_nolisten(newsk, req_to_sk(req_unhash));
         if (*own_req) {
                 tcp_move_syn(newtp, req);
 
@@ -881,6 +797,10 @@
 	.getsockopt	   = ipv6_getsockopt,
 	.addr2sockaddr	   = inet6_csk_addr2sockaddr,
 	.sockaddr_len	   = sizeof(struct sockaddr_in6),
+#ifdef CONFIG_COMPAT
+	.compat_setsockopt = compat_ipv6_setsockopt,
+	.compat_getsockopt = compat_ipv6_getsockopt,
+#endif
 	.mtu_reduced	   = tcp_v4_mtu_reduced,
 };
 
@@ -970,14 +890,10 @@
 	 * Underlying function will use this to retrieve the network
 	 * namespace
 	 */
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(5,4,5)
 	dst = ip6_dst_lookup_flow(ctl_sk, &fl6, NULL);
-#else
-	dst = ip6_dst_lookup_flow(sock_net(ctl_sk), ctl_sk, &fl6, NULL);
-#endif
 	if (!IS_ERR(dst)) {
 		skb_dst_set(buff, dst);
-		ip6_xmit(ctl_sk, buff, &fl6, fl6.flowi6_mark, NULL, tclass, 0);
+		ip6_xmit(ctl_sk, buff, &fl6, fl6.flowi6_mark, NULL, tclass);
 		TCP_INC_STATS(net, TCP_MIB_OUTSEGS);
 		if (rst)
 			TCP_INC_STATS(net, TCP_MIB_OUTRSTS);
@@ -999,7 +915,6 @@
 	int genhash;
 	struct sock *sk1 = NULL;
 #endif
-	struct net *net;
 	int oif;
 
 	if (th->rst)
@@ -1011,28 +926,12 @@
 	if (!sk && !ipv6_unicast_destination(skb))
 		return;
 
-	net = sk ? sock_net(sk) : dev_net(skb_dst(skb)->dev);
 #ifdef CONFIG_TCP_MD5SIG
 	rcu_read_lock();
 	hash_location = tcp_parse_md5sig_option(th);
 	if (sk && sk_fullsock(sk)) {
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-		int l3index;
-
-		/* sdif set, means packet ingressed via a device
-		 * in an L3 domain and inet_iif is set to it.
-		 */
-		l3index = tcp_v6_sdif(skb) ? tcp_v6_iif_l3_slave(skb) : 0;
-		key = tcp_v6_md5_do_lookup(sk, &ipv6h->saddr, l3index);
-#else
 		key = tcp_v6_md5_do_lookup(sk, &ipv6h->saddr);
-#endif
 	} else if (hash_location) {
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-		int dif = tcp_v6_iif_l3_slave(skb);
-		int sdif = tcp_v6_sdif(skb);
-		int l3index;
-
 		/*
 		 * active side is lost. Try to find listening socket through
 		 * source port, and then find md5 key through listening socket.
@@ -1040,32 +939,16 @@
 		 * Incoming packet is checked with md5 hash with finding key,
 		 * no RST generated if md5 hash doesn't match.
 		 */
-		sk1 = inet6_lookup_listener(net,
-					    &tcp_hashinfo, NULL, 0,
-					    &ipv6h->saddr,
-					    th->source, &ipv6h->daddr,
-					    ntohs(th->source), dif, sdif);
-#else
-		sk1 = inet6_lookup_listener(net,
+		sk1 = inet6_lookup_listener(dev_net(skb_dst(skb)->dev),
 					   &tcp_hashinfo, NULL, 0,
 					   &ipv6h->saddr,
 					   th->source, &ipv6h->daddr,
 					   ntohs(th->source), tcp_v6_iif(skb),
 					   tcp_v6_sdif(skb));
-#endif
 		if (!sk1)
 			goto out;
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-		/* sdif set, means packet ingressed via a device
-		 * in an L3 domain and dif is set to it.
-		 */
-		l3index = tcp_v6_sdif(skb) ? dif : 0;
-
-		key = tcp_v6_md5_do_lookup(sk1, &ipv6h->saddr, l3index);
-#else
 		key = tcp_v6_md5_do_lookup(sk1, &ipv6h->saddr);
-#endif
 		if (!key)
 			goto out;
 
@@ -1359,7 +1242,7 @@
 
 		if (err) {
 			icsk->icsk_ext_hdr_len = exthdrlen;
-			icsk->icsk_af_ops = ipv6_specific_p;
+			icsk->icsk_af_ops = &ipv6_specific;
 			sk->sk_backlog_rcv = tcp_v6_do_rcv;
 #ifdef CONFIG_TCP_MD5SIG
 			tp->af_specific = &tcp_sock_ipv6_specific;
@@ -1387,11 +1270,7 @@
 
 	security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(5,4,5)
 	dst = ip6_dst_lookup_flow(sk, &fl6, final_p);
-#else
-	dst = ip6_dst_lookup_flow(sock_net(sk), sk, &fl6, final_p);
-#endif
 	if (IS_ERR(dst)) {
 		err = PTR_ERR(dst);
 		goto failure;
@@ -1454,6 +1333,25 @@
 	return err;
 }
 
+static const struct inet_connection_sock_af_ops ipv6_specific = {
+	.queue_xmit	   = inet6_csk_xmit,
+	.send_check	   = tcp_v6_send_check,
+	.rebuild_header	   = inet6_sk_rebuild_header,
+	.sk_rx_dst_set	   = inet6_sk_rx_dst_set,
+	.conn_request	   = tcp_v6_conn_request,
+	.syn_recv_sock	   = tcp_v6_syn_recv_sock,
+	.net_header_len	   = sizeof(struct ipv6hdr),
+	.net_frag_header_len = sizeof(struct frag_hdr),
+	.setsockopt	   = ipv6_setsockopt,
+	.getsockopt	   = ipv6_getsockopt,
+	.addr2sockaddr	   = inet6_csk_addr2sockaddr,
+	.sockaddr_len	   = sizeof(struct sockaddr_in6),
+#ifdef CONFIG_COMPAT
+	.compat_setsockopt = compat_ipv6_setsockopt,
+	.compat_getsockopt = compat_ipv6_getsockopt,
+#endif
+};
+
 static struct proto_ops *orig_inet6_stream_ops_p;
 #endif //CONFIG_TCPV6_OFFLOAD
 
@@ -1511,31 +1409,8 @@
 }
 #endif
 
-static int find_kallsyms_lookup_name(void)
-{
-	int err = 0;
-
-#if defined(KPROBES_KALLSYMS)
-	struct kprobe kp;
-
-	memset(&kp, 0, sizeof(kp));
-	kp.symbol_name = "kallsyms_lookup_name";
-	err = register_kprobe(&kp);
-	if (!err) {
-		kallsyms_lookup_name_p = (void *)kp.addr;
-		unregister_kprobe(&kp);
-	}
-#else
-	kallsyms_lookup_name_p = (void *)KALLSYMS_LOOKUP;
-#endif
-	if (!err)
-		err = kallsyms_lookup_name_p == NULL;
-
-	return err;
-}
-
 #define FIND_SYMBOL(name, ptr) do { \
-	ptr = (void *)kallsyms_lookup_name_p(name); \
+	ptr = (void *)kallsyms_lookup_name(name); \
 	if (!ptr) { \
 		printk("toecore failure: could not get " name "\n"); \
 		return -ENOENT; \
@@ -1547,15 +1422,6 @@
 	if (offload_enabled)   /* already done */
 		return 0;
 
-	if (!kallsyms_lookup_name_p) {
-		int err = find_kallsyms_lookup_name();
-
-		if (err) {
-			pr_err("find_kallsyms_lookup_name failed\n");
-			return err;
-		}
-	}
-
 	FIND_SYMBOL("skb_splice_bits", skb_splice_bits_p);
 	FIND_SYMBOL("secure_tcp_seq", secure_tcp_seq_p);
 	FIND_SYMBOL("secure_tcp_ts_off", secure_tcp_ts_off_p);
@@ -1571,7 +1437,6 @@
 	FIND_SYMBOL("tcp6_request_sock_ops", tcp6_request_sock_ops_p);
 	FIND_SYMBOL("tcpv6_prot", tcpv6_prot_p);
 	FIND_SYMBOL("inet6_stream_ops", orig_inet6_stream_ops_p);
-	FIND_SYMBOL("ipv6_specific", ipv6_specific_p);
 #endif
 
 	find_rpc_iscsi_callbacks();
diff -r 30 src/network/toecore/offload.c
--- a/src/network/toecore/offload.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/toecore/offload.c	Tue May 18 15:02:47 2021 +0530
@@ -197,7 +197,7 @@
 	 * offloaded _after_ the offload driver is installed.
 	 */
 	struct inet_listen_hashbucket *ilb;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 8)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 19, 93)
 	struct hlist_nulls_node *node;
 #endif
 	struct sock *sk;
@@ -209,7 +209,7 @@
 		for (i = 0; i < INET_LHTABLE_SIZE; i++) {
 			ilb = &tcp_hashinfo.listening_hash[i];
 			spin_lock(&ilb->lock);
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 8)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 19, 93)
 			sk_nulls_for_each(sk, node, &ilb->nulls_head) {
 #else
 			sk_for_each(sk, &ilb->head) {
diff -r 30 src/network/toecore/toe_bonding.c
--- a/src/network/toecore/toe_bonding.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/toecore/toe_bonding.c	Tue May 18 15:02:47 2021 +0530
@@ -126,7 +126,7 @@
 					       int context)
 {
 	struct bonding *bond = (struct bonding *)netdev_priv(hash_params->dev);
-	struct bond_up_slave *slaves = rcu_dereference(bond->usable_slaves);
+	struct bond_up_slave *slaves = rcu_dereference(bond->slave_arr);
 	struct net_device *slave_dev = NULL;
 	unsigned int count;
 	int slave_no;
@@ -163,7 +163,7 @@
 static int toe_bond_3ad_get_active_agg_info(struct bonding *bond,
 					    struct ad_info *ad_info)
 {
-	struct bond_up_slave *slaves = rcu_dereference(bond->usable_slaves);
+	struct bond_up_slave *slaves = rcu_dereference(bond->slave_arr);
 	struct aggregator *aggregator = NULL;
 	bond_list_iter bond_list_iter;
 	struct slave *slave;
diff -r 30 src/network/toecore/toedev.c
--- a/src/network/toecore/toedev.c	Tue May 18 14:52:03 2021 +0530
+++ b/src/network/toecore/toedev.c	Tue May 18 15:02:47 2021 +0530
@@ -214,21 +214,12 @@
 	return single_open(file, proc_devices_show, PDE_DATA(inode));
 }
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-static const struct proc_ops proc_devices_fops = {
-	.proc_open = proc_devices_open,
-	.proc_read = seq_read,
-	.proc_lseek = seq_lseek,
-	.proc_release = single_release,
-};
-#else
 static const struct file_operations proc_devices_fops = {
 	.open = proc_devices_open,
 	.read = seq_read,
 	.llseek = seq_lseek,
 	.release = single_release,
 };
-#endif
 
 static int proc_ipv6_offload_show(struct seq_file *seq, void *v)
 {
@@ -247,21 +238,12 @@
 	return single_open(file, proc_ipv6_offload_show, PDE_DATA(inode));
 }
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
-static const struct proc_ops proc_ipv6_offload_fops = {
-	.proc_open = proc_ipv6_offload_open,
-	.proc_read = seq_read,
-	.proc_lseek = seq_lseek,
-	.proc_release = single_release,
-};
-#else
 static const struct file_operations proc_ipv6_offload_fops = {
 	.open = proc_ipv6_offload_open,
 	.read = seq_read,
 	.llseek = seq_lseek,
 	.release = single_release,
 };
-#endif
 
 static void offload_proc_cleanup(void)
 {
 
